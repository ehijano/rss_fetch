<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Nov 2025 05:01:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Note on the Complexity of Bilevel Linear Programs in Fixed Dimensions</title>
      <link>https://arxiv.org/abs/2511.15592</link>
      <description>arXiv:2511.15592v1 Announce Type: new 
Abstract: Bilevel linear programs (BLPs) form a class of hierarchical decision-making problems in which both the upper-level and the lower-level decision-makers, known as the leader and the follower, respectively, solve linear optimization problems. It is well-known that general BLPs are strongly $NP$-hard, even when the leader's and the follower's objective functions are exact opposites. However, the complexity classification of BLPs remains incomplete when one of the decision-makers has a fixed number of variables or constraints. In particular, it has been shown that optimistic BLPs are polynomially solvable when the number of follower variables is fixed, whereas both optimistic and pessimistic BLPs remain $NP$-hard even with a single leader variable and no upper-level constraints. In this note, we close the remaining gap in this complexity landscape. Specifically, we prove that BLPs are polynomially solvable in both the optimistic and the pessimistic settings when the number of follower constraints is fixed. In contrast, we also show that the pessimistic problem with a fixed number of follower variables is strongly $NP$-hard. To the best of our knowledge, this is the first result demonstrating that, under comparable assumptions, the pessimistic formulation is one complexity class harder than its optimistic counterpart.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15592v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sergey S. Ketkov, Oleg A. Prokopyev</dc:creator>
    </item>
    <item>
      <title>Phylogenetic Network Diversity Parameterized by Reticulation Number and Beyond</title>
      <link>https://arxiv.org/abs/2405.01091</link>
      <description>arXiv:2405.01091v2 Announce Type: replace 
Abstract: Network Phylogenetic Diversity (Network-PD) is a measure for the diversity of a set of species based on a rooted phylogenetic network (with branch lengths and inheritance probabilities on the reticulation edges) describing the evolution of those species. We consider the Max-Network-PD problem: Given such a network, find k species with maximum Network-PD score. We show that this problem is fixed-parameter tractable (FPT) for binary networks, by describing an optimal algorithm running in O(2r log(k)(n + r)) time, with n the total number of species in the network and r its reticulation number. Furthermore, we show that Max-Network-PD is NP-hard for level-1 networks, proving that, unless P=NP, the FPT approach cannot be extended by using the level as parameter instead of the reticulation number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01091v2</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leo van Iersel, Mark Jones, Jannik Schestag, Celine Scornavacca, Mathias Weller</dc:creator>
    </item>
    <item>
      <title>Computational Complexity in Property Testing</title>
      <link>https://arxiv.org/abs/2510.05927</link>
      <description>arXiv:2510.05927v3 Announce Type: replace 
Abstract: We initiate a systematic study of the computational complexity of property testing, focusing on the relationship between query and time complexity. While traditional work in property testing has emphasized query complexity, relatively little is known about the computational hardness of property testers. Our goal is to chart the landscape of time-query interplay and develop tools for proving time complexity lower bounds. Our first contribution is a pair of time-query hierarchy theorems for property testing. For all suitable nondecreasing functions $q(n)$ and $t(n)$ with $t(n)\geq q(n)$, we construct properties with query complexity $\tilde{\Theta}(q(n))$ and time complexity $\tilde\Omega(t(n))$. Our weak hierarchy holds unconditionally, whereas the strong version-assuming the Strong Exponential Time Hypothesis-provides better control over the time complexity of the constructed properties.
  We then turn to halfspaces in $\mathbb{R}^d$, a fundamental class in property testing and learning theory. We study the problem of approximating the distance from the input function to the nearest halfspace within additive error $\epsilon$. For the distribution-free distance approximation problem, known algorithms achieve query complexity $O(d/\epsilon^2)$, but take time $\tilde{\Theta}(1/\epsilon^d)$. We provide a fine-grained justification for this gap: assuming the $k$-SUM conjecture, any algorithm must have running time ${\Omega}(1/\epsilon^{d/2})$. This fine-grained lower bound yields a provable separation between query and time complexity for a natural and well-studied (tolerant) testing problem. We also prove that any Statistical Query (SQ) algorithm under the standard Gaussian distribution requires $(1/\epsilon)^{\Omega(d)}$ queries if the queries are answered with additive error up to $\epsilon^{\Omega(d)}$, revealing a fundamental barrier even in the distribution-specific setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05927v3</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renato Ferreira Pinto Jr., Diptaksho Palit, Sofya Raskhodnikova</dc:creator>
    </item>
    <item>
      <title>Tighter Bounds for the Randomized Polynomial-Time Simplex Algorithm for Linear Programming</title>
      <link>https://arxiv.org/abs/2511.14244</link>
      <description>arXiv:2511.14244v2 Announce Type: replace 
Abstract: We present a randomized polynomial-time simplex algorithm with higher probability and tighter bounds for linear programming by applying improved quasi-convex properties, a logarithmic rounding on a given polytope and its logarithmic perturbation. We base our work on the first randomized polynomial-time simplex method by Jonathan A. Kelner and Daniel A. Spielman [KS06].
  We obtain stronger bounds for the expected number of edges in the projection of a perturbed polytope onto a two-dimensional shadow plane. In the $k$-round case, we obtain a bound of $16 \sqrt{2} \pi k (1 + \lambda H_n) \sqrt{d} n / 3 \lambda$. In the non-$k$-round case, we obtain a bound of $26 \pi t (1 + \lambda H_n) \sqrt{d} n / \lambda \rho$. To achieve this, we provide a slightly lower bound of $3 \sqrt{2} \lambda / (16 n \sqrt{d})$ on the expected edge length that appears in the shadow. Another tool we employ is a tighter bound for $1$-quasi-concave minimization and $1$-quasi-convex maximization. In the $k$-round case, we obtain a quasi-convex bound of $(d - 2) \epsilon^2 / 2$. In the non-$k$-round case, we obtain a quasi-convex bound of $3.4 \epsilon^2 / \rho^2$.
  We propose a modification of the Kelner and Spielman randomized simplex algorithm (STOC'06) [KS06] that achieves a higher success probability. To accomplish this, we apply our tighter bounds with a new expected value of $\lambda = c \log n$ for independent exponentially distributed random variables and with $\log(k)$-rounding. The desired properties resulting from the construction of an artificial vertex during initialization hold with a higher probability of at least $1 - (d + 2), e^{-\log n}$. The pivot rule of the randomized simplex modification holds with a probability of at least $3/4$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14244v2</guid>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Gibor</dc:creator>
    </item>
    <item>
      <title>Intrinsic Barriers and Practical Pathways for Human-AI Alignment: An Agreement-Based Complexity Analysis</title>
      <link>https://arxiv.org/abs/2502.05934</link>
      <description>arXiv:2502.05934v3 Announce Type: replace-cross 
Abstract: We formalize AI alignment as a multi-objective optimization problem called $\langle M,N,\varepsilon,\delta\rangle$-agreement, in which a set of $N$ agents (including humans) must reach approximate ($\varepsilon$) agreement across $M$ candidate objectives, with probability at least $1-\delta$. Analyzing communication complexity, we prove an information-theoretic lower bound showing that once either $M$ or $N$ is large enough, no amount of computational power or rationality can avoid intrinsic alignment overheads. This establishes rigorous limits to alignment *itself*, not merely to particular methods, clarifying a "No-Free-Lunch" principle: encoding "all human values" is inherently intractable and must be managed through consensus-driven reduction or prioritization of objectives. Complementing this impossibility result, we construct explicit algorithms as achievability certificates for alignment under both unbounded and bounded rationality with noisy communication. Even in these best-case regimes, our bounded-agent and sampling analysis shows that with large task spaces ($D$) and finite samples, *reward hacking is globally inevitable*: rare high-loss states are systematically under-covered, implying scalable oversight must target safety-critical slices rather than uniform coverage. Together, these results identify fundamental complexity barriers -- tasks ($M$), agents ($N$), and state-space size ($D$) -- and offer principles for more scalable human-AI collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05934v3</guid>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aran Nayebi</dc:creator>
    </item>
    <item>
      <title>How Hard is it to be a Star? Convex Geometry and the Real Hierarchy</title>
      <link>https://arxiv.org/abs/2506.18818</link>
      <description>arXiv:2506.18818v2 Announce Type: replace-cross 
Abstract: A set is star-shaped if there is a point in the set that can see every other point in the set in the sense that the line-segment connecting the points lies within the set. We show that testing whether a non-empty compact smooth region is star-shaped is $\forall\mathbb{R}$-complete. Since the obvious definition of star-shapedness has logical form $\exists\forall$, this is a somewhat surprising result, based on Krasnosel'ski\u{\i}'s theorem from convex geometry; we study several related complexity classifications in the real hierarchy based on other results from convex geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18818v2</guid>
      <category>cs.CG</category>
      <category>cs.CC</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcus Schaefer, Daniel \v{S}tefankovi\v{c}</dc:creator>
    </item>
    <item>
      <title>Core Safety Values for Provably Corrigible Agents</title>
      <link>https://arxiv.org/abs/2507.20964</link>
      <description>arXiv:2507.20964v2 Announce Type: replace-cross 
Abstract: We introduce the first complete formal solution to corrigibility in the off-switch game, with provable guarantees in multi-step, partially observed environments. Our framework consists of five *structurally separate* utility heads -- deference, switch-access preservation, truthfulness, low-impact behavior via a belief-based extension of Attainable Utility Preservation, and bounded task reward -- combined lexicographically by strict weight gaps. Theorem 1 proves exact single-round corrigibility in the partially observable off-switch game; Theorem 3 extends the guarantee to multi-step, self-spawning agents, showing that even if each head is *learned* to mean-squared error $\varepsilon$ and the planner is $\varepsilon$-sub-optimal, the probability of violating *any* safety property is bounded while still ensuring net human benefit. In contrast to Constitutional AI or RLHF/RLAIF, which merge all norms into one learned scalar, our separation makes obedience and impact-limits provably dominate even when incentives conflict. For settings where adversaries can modify the agent, we prove that deciding whether an arbitrary post-hack agent will ever violate corrigibility is undecidable by reduction to the halting problem, then carve out a finite-horizon "decidable island" where safety can be certified in randomized polynomial time and verified with privacy-preserving, constant-round zero-knowledge proofs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.20964v2</guid>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 20 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aran Nayebi</dc:creator>
    </item>
  </channel>
</rss>
