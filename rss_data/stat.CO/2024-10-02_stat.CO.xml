<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Oct 2024 02:10:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Grand Challenges in Bayesian Computation</title>
      <link>https://arxiv.org/abs/2410.00496</link>
      <description>arXiv:2410.00496v1 Announce Type: new 
Abstract: This article appeared in the September 2024 issue (Vol. 31, No. 3) of the Bulletin of the International Society for Bayesian Analysis (ISBA).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00496v1</guid>
      <category>stat.CO</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anirban Bhattacharya, Antonio Linero, Chris. J. Oates</dc:creator>
    </item>
    <item>
      <title>Parallel state estimation for systems with integrated measurements</title>
      <link>https://arxiv.org/abs/2410.00627</link>
      <description>arXiv:2410.00627v1 Announce Type: new 
Abstract: This paper presents parallel-in-time state estimation methods for systems with Slow-Rate inTegrated Measurements (SRTM). Integrated measurements are common in various applications, and they appear in analysis of data resulting from processes that require material collection or integration over the sampling period. Current state estimation methods for SRTM are inherently sequential, preventing temporal parallelization in their standard form. This paper proposes parallel Bayesian filters and smoothers for linear Gaussian SRTM models. For that purpose, we develop a novel smoother for SRTM models and develop parallel-in-time filters and smoother for them using an associative scan-based parallel formulation. Empirical experiments ran on a GPU demonstrate the superior time complexity of the proposed methods over traditional sequential approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00627v1</guid>
      <category>stat.CO</category>
      <category>cs.DC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fatemeh Yaghoobi, Simo S\"arkk\"a</dc:creator>
    </item>
    <item>
      <title>Entropy contraction of the Gibbs sampler under log-concavity</title>
      <link>https://arxiv.org/abs/2410.00858</link>
      <description>arXiv:2410.00858v1 Announce Type: cross 
Abstract: The Gibbs sampler (a.k.a. Glauber dynamics and heat-bath algorithm) is a popular Markov Chain Monte Carlo algorithm which iteratively samples from the conditional distributions of a probability measure $\pi$ of interest. Under the assumption that $\pi$ is strongly log-concave, we show that the random scan Gibbs sampler contracts in relative entropy and provide a sharp characterization of the associated contraction rate. Assuming that evaluating conditionals is cheap compared to evaluating the joint density, our results imply that the number of full evaluations of $\pi$ needed for the Gibbs sampler to mix grows linearly with the condition number and is independent of the dimension. If $\pi$ is non-strongly log-concave, the convergence rate in entropy degrades from exponential to polynomial. Our techniques are versatile and extend to Metropolis-within-Gibbs schemes and the Hit-and-Run algorithm. A comparison with gradient-based schemes and the connection with the optimization literature are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00858v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Ascolani, Hugo Lavenant, Giacomo Zanella</dc:creator>
    </item>
    <item>
      <title>DsubCox: A Fast Subsampling Algorithm for Cox Model with Distributed and Massive Survival Data</title>
      <link>https://arxiv.org/abs/2310.08208</link>
      <description>arXiv:2310.08208v2 Announce Type: replace 
Abstract: To ensure privacy protection and alleviate computational burden, we propose a fast subsmaling procedure for the Cox model with massive survival datasets from multi-centered, decentralized sources. The proposed estimator is computed based on optimal subsampling probabilities that we derived and enables transmission of subsample-based summary level statistics between different storage sites with only one round of communication. For inference, the asymptotic properties of the proposed estimator were rigorously established. An extensive simulation study demonstrated that the proposed approach is effective. The methodology was applied to analyze a large dataset from the U.S. airlines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08208v2</guid>
      <category>stat.CO</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haixiang Zhang, Yang Li, HaiYing Wang</dc:creator>
    </item>
    <item>
      <title>Exploring Spatial Context: A Comprehensive Bibliography of GWR and MGWR</title>
      <link>https://arxiv.org/abs/2404.16209</link>
      <description>arXiv:2404.16209v2 Announce Type: replace-cross 
Abstract: Local spatial models such as Geographically Weighted Regression (GWR) and Multiscale Geographically Weighted Regression (MGWR) serve as instrumental tools to capture intrinsic contextual effects through the estimates of the local intercepts and behavioral contextual effects through estimates of the local slope parameters. GWR and MGWR provide simple implementation yet powerful frameworks that could be extended to various disciplines that handle spatial data. This bibliography aims to serve as a comprehensive compilation of peer-reviewed papers that have utilized GWR or MGWR as a primary analytical method to conduct spatial analyses and acts as a useful guide to anyone searching the literature for previous examples of local statistical modeling in a wide variety of application fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16209v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Stewart Fotheringham, Chen-Lun Kao, Hanchen Yu, Sarah Bardin, Taylor Oshan, Ziqi Li, Mehak Sachdeva, Wei Luo</dc:creator>
    </item>
  </channel>
</rss>
