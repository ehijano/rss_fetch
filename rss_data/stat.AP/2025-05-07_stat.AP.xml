<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 May 2025 01:44:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Mixed-Effects Modeling of NYC Subway Ridership Using MTA and Weather Data</title>
      <link>https://arxiv.org/abs/2505.02990</link>
      <description>arXiv:2505.02990v1 Announce Type: new 
Abstract: This study investigates monthly trends in New York City subway ridership throughout 2023 by integrating Metropolitan Transportation Authority (MTA) origin-destination data with weather data from Weather Underground. Using a longitudinal mixed-effects modeling framework, we assess how origin borough, seasonal variation, and weather, particularly maximum gust speed, influence average monthly ridership. The dataset was processed using an automated ETL pipeline built with Apache Airflow and PostgreSQL to handle over 115 million records. Principal component analysis (PCA) was applied to reduce multicollinearity among weather covariates. Our findings indicate that origin borough, especially Manhattan, plays a dominant role in ridership levels, while maximum gust speed significantly reduces ridership, primarily for trips originating in Manhattan. Further analysis reveals that December's ridership drop is largely explained by gust speed, suggesting wind-related confounding. These results underscore the nuanced impact of borough-specific and weather-related factors on public transit use, offering insight into commuter behavior and resilience of subway systems to environmental conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02990v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zoe Curtis, Jake Haines</dc:creator>
    </item>
    <item>
      <title>Statistical Performance of Generalized Direction Detectors with Known Spatial Steering Vector</title>
      <link>https://arxiv.org/abs/2505.03076</link>
      <description>arXiv:2505.03076v1 Announce Type: new 
Abstract: The generalized direction detection (GDD) problem involves determining the presence of a signal of interest within matrix-valued data, where the row and column spaces of the signal (if present) are known, but the speciffc coordinates are unknown. Many detectors have been proposed for GDD, yet there is a lack of analytical results regarding their statistical detection performance. This paper presents a theoretical analysis of two adaptive detectors for GDD in scenarios with known spatial steering vectors. Speciffcally, we establish their statistical distributions and develop closed-form expressions for both detection probability (PD) and false alarm probability (PFA). Simulation experiments are carried out to validate the theoretical results, demonstrating good agreement between theoretical and simulated results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03076v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenyu Xu, Weijian Liu, Changfei Wu, Ming Liu, Qinglei Du, Jun Liu</dc:creator>
    </item>
    <item>
      <title>BayVel: A Bayesian Framework for RNA Velocity Estimation in Single-Cell Transcriptomics</title>
      <link>https://arxiv.org/abs/2505.03083</link>
      <description>arXiv:2505.03083v1 Announce Type: new 
Abstract: RNA velocity is a model of gene expression dynamics designed to analyze single-cell RNA sequencing (scRNA-seq) data, and it has recently gained significant attention. However, despite its popularity, the model has raised several concerns, primarily related to three issues: its heavy dependence on data preprocessing, the need for post-processing of the results, and the limitations of the underlying statistical methodology. Current approaches, such as scVelo, suffer from notable statistical shortcomings. These include identifiability problems, reliance on heuristic preprocessing steps, and the absence of uncertainty quantification. To address these limitations, we propose BayVel, a Bayesian hierarchical model that directly models raw count data. BayVel resolves identifiability issues and provides posterior distributions for all parameters, including the RNA velocities themselves, without the need for any post processing. We evaluate BayVel's performance using simulated datasets. While scVelo fails to accurately reconstruct parameters, even when data are simulated directly from the model assumptions, BayVel demonstrates strong accuracy and robustness. This highlights BayVel as a statistically rigorous and reliable framework for studying transcriptional dynamics in the context of RNA velocity modeling. When applied to a real dataset of pancreatic epithelial cells previously analyzed with scVelo, BayVel does not replicate their findings, which appears to be strongly influenced by the postprocessing, supporting concerns raised in other studies about the reliability of scVelo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03083v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elena Sabbioni, Enrico Bibbona, Gianluca Mastrantonio, Guido Sanguinetti</dc:creator>
    </item>
    <item>
      <title>Real-time small area estimation of food security in Zimbabwe: integrating mobile-phone and face-to-face surveys using joint multilevel regression and poststratification</title>
      <link>https://arxiv.org/abs/2505.03517</link>
      <description>arXiv:2505.03517v1 Announce Type: new 
Abstract: Real-time, fine-grained monitoring of food security is essential for enabling timely and targeted interventions, thereby supporting the global goal of achieving zero hunger - a key objective of the 2030 Agenda for Sustainable Development. Mobile phone surveys provide a scalable and temporally rich data source that can be tailored to different administrative levels. However, due to cost and operational constraints, maintaining high-frequency data collection while ensuring representativeness at lower administrative levels is often infeasible. We propose a joint multilevel regression and poststratification (jMRP) approach that combines high-frequency and up-to-date mobile phone survey data, designed for higher administrative levels, with an annual face-to-face survey representative at lower levels to produce reliable food security estimates at spatially and temporally finer scales than those originally targeted by the surveys. This methodology accounts for systematic differences in survey responses due to modality and socio-economic characteristics, reducing both sampling and modality bias. We implement the approach in a fully Bayesian manner to quantify uncertainty. We demonstrate the effectiveness of our method using data from Zimbabwe, thus offering a cost-effective solution for real-time monitoring and strengthening decision-making in resource-constrained settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03517v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sahoko Ishida, Adam Howes, Valerie Bradley, Elizaveta Semenova, Theo Rashid, Silinganisiwe Dzumbunu, Sumali Bajaj, Gaurav Singhal, Dino Sejdinovic, Herbert Zvirere, Duccio Piovani, Silvia Passeri, Kusum Hachhethu, Arif Husain, George D. Kembo, Terrence Kairiza, Seth Flaxman</dc:creator>
    </item>
    <item>
      <title>Joint Generalized Cosine Similarity: A Novel Method for N-Modal Semantic Alignment Based on Contrastive Learning</title>
      <link>https://arxiv.org/abs/2505.03532</link>
      <description>arXiv:2505.03532v1 Announce Type: new 
Abstract: Alignment remains a crucial task in multi-modal deep learning, and contrastive learning has been widely applied in this field. However, when there are more than two modalities, existing methods typically calculate pairwise loss function and aggregate them into a composite loss function for the optimization of model parameters. This limitation mainly stems from the drawbacks of traditional similarity measurement method (i.e. they can only calculate the similarity between two vectors). To address this issue, we propose a novel similarity measurement method: the Joint Generalized Cosine Similarity (JGCS). Unlike traditional pairwise methods (e.g., dot product or cosine similarity), JGCS centers around the angle derived from the Gram determinant. To the best of our knowledge, this is the first similarity measurement method capable of handling tasks involving an arbitrary number of vectors. Based on this, we introduce the corresponding contrastive learning loss function , GHA Loss, and the new inter-modal contrastive learning paradigm. Additionally, comprehensive experiments conducted on the Derm7pt dataset and simulated datasets demonstrate that our method achieves superior performance while exhibiting remarkable advantages such as noise robustness, computational efficiency, and scalability. Finally, it is worth mentioning that the Joint Generalized Cosine Similarity proposed by us can not only be applied in contrastive learning, but also be easily extended to other domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03532v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiqiao Chen, Zijian Huang</dc:creator>
    </item>
    <item>
      <title>An Explainable Anomaly Detection Framework for Monitoring Depression and Anxiety Using Consumer Wearable Devices</title>
      <link>https://arxiv.org/abs/2505.03039</link>
      <description>arXiv:2505.03039v1 Announce Type: cross 
Abstract: Continuous monitoring of behavior and physiology via wearable devices offers a novel, objective method for the early detection of worsening depression and anxiety. In this study, we present an explainable anomaly detection framework that identifies clinically meaningful increases in symptom severity using consumer-grade wearable data. Leveraging data from 2,023 participants with defined healthy baselines, our LSTM autoencoder model learned normal health patterns of sleep duration, step count, and resting heart rate. Anomalies were flagged when self-reported depression or anxiety scores increased by &gt;=5 points (a threshold considered clinically significant). The model achieved an adjusted F1-score of 0.80 (precision = 0.73, recall = 0.88) in detecting 393 symptom-worsening episodes across 341 participants, with higher performance observed for episodes involving concurrent depression and anxiety escalation (F1 = 0.84) and for more pronounced symptom changes (&gt;=10-point increases, F1 = 0.85). Model interpretability was supported by SHAP-based analysis, which identified resting heart rate as the most influential feature in 71.4 percentage of detected anomalies, followed by physical activity and sleep. Together, our findings highlight the potential of explainable anomaly detection to enable personalized, scalable, and proactive mental health monitoring in real-world settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03039v1</guid>
      <category>cs.CV</category>
      <category>stat.AP</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuezhou Zhang, Amos A. Folarin, Callum Stewart, Heet Sankesara, Yatharth Ranjan, Pauline Conde, Akash Roy Choudhury, Shaoxiong Sun, Zulqarnain Rashid, Richard J. B. Dobson</dc:creator>
    </item>
    <item>
      <title>The ISAC systems aided by MIMO, RIS and with Beamforming Techniques</title>
      <link>https://arxiv.org/abs/2505.03090</link>
      <description>arXiv:2505.03090v1 Announce Type: cross 
Abstract: This paper explores the integration of communication and sensing in modern wireless systems through the configuration of BS and RIS antenna elements. By leveraging time multiplexing for both communication and sensing, the proposed system optimizes spectral efficiency and operational performance. The use of static RIS configurations tailored to specific environments eliminates the need for dynamic reconfigurations, enhancing system agility, reducing processing complexity, and improving sensing accuracy. The system incorporates trilateration, angle of arrival, and time of arrival techniques to enable precise user localization by combining signals reflected along multiple paths. This method helps choose the best connections and lowers sensing costs while preventing interference with communication data, highlighting the need to bring together new technologies like passive and adaptive beamforming in one system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03090v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>stat.AP</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafael Augusto Pedriali, Isadora Martines Ferreira, Jose Carlos Marinello, Taufik Abrao</dc:creator>
    </item>
    <item>
      <title>CUI-MET: Clinical Utility Index Dose Optimization Approach for Multiple-Dose, Multiple-Outcome Randomized Trial Designs</title>
      <link>https://arxiv.org/abs/2505.03633</link>
      <description>arXiv:2505.03633v1 Announce Type: cross 
Abstract: Dose optimization in oncology clinical trials has shifted from seeking the maximum tolerated dose to identifying the Optimal Biological Dose (OBD) that balances therapeutic benefits and risks across multiple clinical attributes. Existing advanced dose-finding methods can integrate multiple endpoints and compare dose levels but are often complex or computationally intensive, limiting their use in early-phase trials. To address these challenges, we propose the Clinical Utility Index Dose Optimization Approach for Multiple-dose Multiple-Outcome Randomized Trial Designs (CUI-MET). This framework integrates multiple binary endpoints using a clinical utility-based approach, calculating a combined clinical utility index (CUI) for each dose level by weighting endpoint responses. Both empirical and modeling methods can estimate marginal probabilities for each endpoint. These estimated probabilities are then combined using endpoint-specific weights to compute a utility score for each dose, and the dose with the highest score is selected as optimal. To enhance usability, we implemented these methods in an interactive R Shiny application and demonstrated their functionality through case examples. The framework's flexibility allows for different model selections and endpoint weighting schemes to reflect specific clinical priorities. Bootstrap analysis provides confidence intervals for the CUI and estimates the probability that each dose is selected as optimal, thereby evaluating the robustness of dose selection. By integrating multiple endpoints into a single utility index and incorporating user-friendly visualizations, CUI-MET offers a flexible and accessible solution for dose optimization in early-phase oncology trials, supporting informed decision-making and advancing patient-centered care.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03633v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fanni Zhang, Kristine Broglio, Michael Sweeting, Gina D'Angelo</dc:creator>
    </item>
    <item>
      <title>On the optimal stopping of Gauss-Markov bridges with random pinning points</title>
      <link>https://arxiv.org/abs/2505.03636</link>
      <description>arXiv:2505.03636v1 Announce Type: cross 
Abstract: We consider the optimal stopping problem for a Gauss-Markov process conditioned to adopt a prescribed terminal distribution. By applying a time-space transformation, we show it is equivalent to stopping a Brownian bridge pinned at a random endpoint with a time-dependent payoff. We prove that the optimal rule is the first entry into the stopping region, and establish that the value function is Lipschitz continuous on compacts via a coupling of terminal pinning points across different initial conditions. A comparison theorems then order value functions according to likelihood-ratio ordering of terminal densities, and when these densities have bounded support, we bound the optimal boundary by that of a Gauss-Markov bridge. Although the stopping boundary need not be the graph of a function in general, we provide sufficient conditions under which this property holds, and identify strongly log-concave terminal densities that guarantee this structure. Numerical experiments illustrate representative boundary shapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03636v1</guid>
      <category>math.PR</category>
      <category>stat.AP</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Abel Azze, Bernardo D'Auria</dc:creator>
    </item>
    <item>
      <title>Sparse-Group Boosting with Balanced Selection Frequencies: A Simulation-Based Approach and R Implementation</title>
      <link>https://arxiv.org/abs/2405.21037</link>
      <description>arXiv:2405.21037v2 Announce Type: replace 
Abstract: This paper introduces a novel framework for reducing variable selection bias by balancing selection frequencies of base-learners in boosting and introduces the sgboost package in R, which implements this framework combined with sparse-group boosting. The group bias reduction algorithm employs a simulation-based approach to iteratively adjust the degrees of freedom for both individual and group base-learners, ensuring balanced selection probabilities and mitigating the tendency to over-select more complex groups. The efficacy of the group balancing algorithm is demonstrated through simulations. Sparse-group boosting offers a flexible approach for both group and individual variable selection, reducing overfitting and enhancing model interpretability for modeling high-dimensional data with natural groupings in covariates. The package uses regularization techniques based on the degrees of freedom of individual and group base-learners. Through comparisons with existing methods and demonstration of its unique functionalities, this paper provides a practical guide on utilizing sparse-group boosting in R, accompanied by code examples to facilitate its application in various research domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.21037v2</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabian Obster, Christian Heumann</dc:creator>
    </item>
    <item>
      <title>Probabilistic Record Linkage of Two Gun Violence Data Sets</title>
      <link>https://arxiv.org/abs/2503.01054</link>
      <description>arXiv:2503.01054v2 Announce Type: replace 
Abstract: Objective: Gun violence is a serious public health problem in the United States. The Gun Violence Archive (GVA) provides detailed geographic information, while the National Violent Death Reporting System (NVDRS) offers demographic, socioeconomic, and narrative data on gun homicides. We developed and tested a method for merging datasets to inform analysis and strategies to reduce gun violence rates in the United States.
  Methods: After preprocessing the data, we used a probabilistic record linkage program to link records from the GVA (n = 36,245) with records from the NVDRS (n = 30,592). We evaluated sensitivity (the false match rate) by using a manual approach.
  Results: The linkage returned 27,420 matches of gun violence incidents from the GVA and NVDRS datasets. Because of restricted details accessible from GVA online records, only 942 of these matched records could be manually evaluated. Our framework achieved a 90.12% (849 of 942 accuracy rate in linking GVA incidents with corresponding NVDRS records.
  Practice Implications: Electronic linkage of gun violence data from 2 sources is feasible and can be used to increase the utility of the datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01054v2</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iris Horng, Qishuo Yin, William Chan, Jared Murray, Dylan S. Small</dc:creator>
    </item>
    <item>
      <title>Evaluating Multilevel Regression and Poststratification with Spatial Priors with a Big Data Behavioural Survey</title>
      <link>https://arxiv.org/abs/2503.05915</link>
      <description>arXiv:2503.05915v2 Announce Type: replace 
Abstract: Multilevel regression and poststratification (MRP) is a computationally efficient indirect estimation method that can quickly produce improved population-adjusted estimates with limited data. Recent computational advancements allow efficient, relatively simple, and quick approximate Bayesian estimation for MRP. As population health outcomes of interest including vaccination uptake are known to have spatial structure, precision may be gained by including space in the model. We test a recently proposed spatial MRP method that includes a BYM2 spatial term that smooths across demographics and geographic areas using a large, unrepresentative survey. We produce California county-level estimates of first-dose COVID-19 vaccination up to June 2021 using classic and spatial MRP models, and poststratify using data from the American Community Survey (US Census Bureau). We assess validity using reported first-dose vaccination counts from the Centers for Disease Control (CDC). Neither classic nor spatial MRP models performed well, highlighting: 1. spatial MRP may be most appropriate for richer data contexts, 2. some demographics in the survey data are over-sampled and -aggregated, producing model over-smoothing, and 3. a need for survey producers to share user-representative metrics to better benchmark estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05915v2</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Aja Sutton, Zack W. Almquist, Jon Wakefield</dc:creator>
    </item>
    <item>
      <title>A Bayesian Age-Period-Cohort approach for modeling fertility in Puerto Rico</title>
      <link>https://arxiv.org/abs/2504.01148</link>
      <description>arXiv:2504.01148v2 Announce Type: replace 
Abstract: Puerto Rico has one of the lowest total fertility rates (TFR) in the world. Combined with a negative net migration and a high proportion of older adults, its unique situation motivates the need for further demographic analysis. Determining whether low fertility rates are mostly due to period or cohort effects is crucial for developing effective public policies that adapt to changes in fertility and population structures. The main objective of this work is to develop an Age-Period-Cohort model, in order to describe fertility data in Puerto Rico, from 1948-1952 and determine the contribution of period and cohort effects to fertility decline. The APC model was developed following a Bayesian framework, with a Poisson likelihood, RW(2) autorregressive priors for the APC parameters, and Scaled Beta2 priors for the precision parameters. Both frequentist and Bayesian methodologies attribute more importance to cohort effects when explaining fertility changes in Puerto Rico. Birth cohorts born in 1963-1967 onward have notably low fertility rates. There is no evidence of postponement of births in Puerto Rico, contrary to other countries with lowest-low fertility. Birth cohorts born in 1963-1967 onward have notably low fertility rates. This is the first application of APC analysis to fertility data in Puerto Rico, which describes fertility changes in a unique scenario in terms of demographic indicators, and the first APC analysis that shows the predominance of cohort effects when explaining fertility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01148v2</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jomarie Jim\'enez Gonz\'alez, Ang\'elica M. Rosario Santos, Luis R. Pericchi Guerra, Hernando Mattei</dc:creator>
    </item>
    <item>
      <title>FreDF: Learning to Forecast in the Frequency Domain</title>
      <link>https://arxiv.org/abs/2402.02399</link>
      <description>arXiv:2402.02399v2 Announce Type: replace-cross 
Abstract: Time series modeling presents unique challenges due to autocorrelation in both historical data and future sequences. While current research predominantly addresses autocorrelation within historical data, the correlations among future labels are often overlooked. Specifically, modern forecasting models primarily adhere to the Direct Forecast (DF) paradigm, generating multi-step forecasts independently and disregarding label autocorrelation over time. In this work, we demonstrate that the learning objective of DF is biased in the presence of label autocorrelation. To address this issue, we propose the Frequency-enhanced Direct Forecast (FreDF), which mitigates label autocorrelation by learning to forecast in the frequency domain, thereby reducing estimation bias. Our experiments show that FreDF significantly outperforms existing state-of-the-art methods and is compatible with a variety of forecast models. Code is available at https://github.com/Master-PLC/FreDF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02399v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wang, Licheng Pan, Zhichao Chen, Degui Yang, Sen Zhang, Yifei Yang, Xinggao Liu, Haoxuan Li, Dacheng Tao</dc:creator>
    </item>
    <item>
      <title>Machine Learning and the Yield Curve: Tree-Based Macroeconomic Regime Switching</title>
      <link>https://arxiv.org/abs/2408.12863</link>
      <description>arXiv:2408.12863v2 Announce Type: replace-cross 
Abstract: We explore tree-based macroeconomic regime-switching in the context of the dynamic Nelson-Siegel (DNS) yield-curve model. In particular, we customize the tree-growing algorithm to partition macroeconomic variables based on the DNS model's marginal likelihood, thereby identifying regime-shifting patterns in the yield curve. Compared to traditional Markov-switching models, our model offers clear economic interpretation via macroeconomic linkages and ensures computational simplicity. In an empirical application to U.S. Treasury yields, we find (1) important yield-curve regime switching, and (2) evidence that macroeconomic variables have predictive power for the yield curve when the federal funds rate is high, but not in other regimes, thereby refining the notion of yield curve ''macro-spanning''.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12863v2</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siyu Bie, Francis X. Diebold, Jingyu He, Junye Li</dc:creator>
    </item>
    <item>
      <title>Nonparametric IPSS: Fast, flexible feature selection with false discovery control</title>
      <link>https://arxiv.org/abs/2410.02208</link>
      <description>arXiv:2410.02208v2 Announce Type: replace-cross 
Abstract: Feature selection is a critical task in machine learning and statistics. However, existing feature selection methods either (i) rely on parametric methods such as linear or generalized linear models, (ii) lack theoretical false discovery control, or (iii) identify few true positives. Here, we introduce a general feature selection method with finite-sample false discovery control based on applying integrated path stability selection (IPSS) to arbitrary feature importance scores. The method is nonparametric whenever the importance scores are nonparametric, and it estimates q-values, which are better suited to high-dimensional data than p-values. We focus on two special cases using importance scores from gradient boosting (IPSSGB) and random forests (IPSSRF). Extensive nonlinear simulations with RNA sequencing data show that both methods accurately control the false discovery rate and detect more true positives than existing methods. Both methods are also efficient, running in under 20 seconds when there are 500 samples and 5000 features. We apply IPSSGB and IPSSRF to detect microRNAs and genes related to cancer, finding that they yield better predictions with fewer features than existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02208v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omar Melikechi, David B. Dunson, Jeffrey W. Miller</dc:creator>
    </item>
  </channel>
</rss>
