<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Apr 2024 04:01:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 11 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>EVLearn: Extending the CityLearn Framework with Electric Vehicle Simulation</title>
      <link>https://arxiv.org/abs/2404.06521</link>
      <description>arXiv:2404.06521v1 Announce Type: new 
Abstract: Intelligent energy management strategies, such as Vehicle-to-Grid (V2G) and Grid-to-Vehicle (G2V) emerge as a potential solution to the Electric Vehicles' (EVs) integration into the energy grid. These strategies promise enhanced grid resilience and economic benefits for both vehicle owners and grid operators. Despite the announced prospective, the adoption of these strategies is still hindered by an array of operational problems. Key among these is the lack of a simulation platform that allows to validate and refine V2G and G2V strategies. Including the development, training, and testing in the context of Energy Communities (ECs) incorporating multiple flexible energy assets. Addressing this gap, first we introduce the EVLearn, a simulation module for researching in both V2G and G2V energy management strategies, that models EVs, their charging infrastructure and associated energy flexibility dynamics; second, this paper integrates EVLearn with the existing CityLearn framework, providing V2G and G2V simulation capabilities into the study of broader energy management strategies. Results validated EVLearn and its integration into CityLearn, where the impact of these strategies is highlighted through a comparative simulation scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06521v1</guid>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tiago Fonseca, Luis Ferreira, Bernardo Cabral, Ricardo Severino, Kingsley Nweye, Dipanjan Ghose, Zoltan Nagy</dc:creator>
    </item>
    <item>
      <title>Best Response Shaping</title>
      <link>https://arxiv.org/abs/2404.06519</link>
      <description>arXiv:2404.06519v1 Announce Type: cross 
Abstract: We investigate the challenge of multi-agent deep reinforcement learning in partially competitive environments, where traditional methods struggle to foster reciprocity-based cooperation. LOLA and POLA agents learn reciprocity-based cooperative policies by differentiation through a few look-ahead optimization steps of their opponent. However, there is a key limitation in these techniques. Because they consider a few optimization steps, a learning opponent that takes many steps to optimize its return may exploit them. In response, we introduce a novel approach, Best Response Shaping (BRS), which differentiates through an opponent approximating the best response, termed the "detective." To condition the detective on the agent's policy for complex games we propose a state-aware differentiable conditioning mechanism, facilitated by a question answering (QA) method that extracts a representation of the agent based on its behaviour on specific environment states. To empirically validate our method, we showcase its enhanced performance against a Monte Carlo Tree Search (MCTS) opponent, which serves as an approximation to the best response in the Coin Game. This work expands the applicability of multi-agent RL in partially competitive environments and provides a new pathway towards achieving improved social welfare in general sum games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06519v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Milad Aghajohari, Tim Cooijmans, Juan Agustin Duque, Shunichi Akatsuka, Aaron Courville</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Soft Actor-Critic with Global Loss for Autonomous Mobility-on-Demand Fleet Control</title>
      <link>https://arxiv.org/abs/2404.06975</link>
      <description>arXiv:2404.06975v1 Announce Type: cross 
Abstract: We study a sequential decision-making problem for a profit-maximizing operator of an Autonomous Mobility-on-Demand system. Optimizing a central operator's vehicle-to-request dispatching policy requires efficient and effective fleet control strategies. To this end, we employ a multi-agent Soft Actor-Critic algorithm combined with weighted bipartite matching. We propose a novel vehicle-based algorithm architecture and adapt the critic's loss function to appropriately consider global actions. Furthermore, we extend our algorithm to incorporate rebalancing capabilities. Through numerical experiments, we show that our approach outperforms state-of-the-art benchmarks by up to 12.9% for dispatching and up to 38.9% with integrated rebalancing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06975v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeno Woywood, Jasper I. Wiltfang, Julius Luy, Tobias Enders, Maximilian Schiffer</dc:creator>
    </item>
    <item>
      <title>Compressed Gradient Tracking for Decentralized Optimization Over General Directed Networks</title>
      <link>https://arxiv.org/abs/2106.07243</link>
      <description>arXiv:2106.07243v4 Announce Type: replace-cross 
Abstract: In this paper, we propose two communication efficient decentralized optimization algorithms over a general directed multi-agent network. The first algorithm, termed Compressed Push-Pull (CPP), combines the gradient tracking Push-Pull method with communication compression. We show that CPP is applicable to a general class of unbiased compression operators and achieves linear convergence rate for strongly convex and smooth objective functions. The second algorithm is a broadcast-like version of CPP (B-CPP), and it also achieves linear convergence rate under the same conditions on the objective functions. B-CPP can be applied in an asynchronous broadcast setting and further reduce communication costs compared to CPP. Numerical experiments complement the theoretical analysis and confirm the effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.07243v4</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TSP.2022.3160238</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Signal Processing, 70(2022), 1775-1787</arxiv:journal_reference>
      <dc:creator>Zhuoqing Song, Lei Shi, Shi Pu, Ming Yan</dc:creator>
    </item>
    <item>
      <title>On Incentivizing Social Information Sharing in Routing Games</title>
      <link>https://arxiv.org/abs/2308.13301</link>
      <description>arXiv:2308.13301v4 Announce Type: replace-cross 
Abstract: Crowdsourcing services, such as Waze, leverage a mass of mobile users to learn massive point-of-interest (PoI) information while traveling and share it as a public good. Given that crowdsourced users mind their travel costs and possess various preferences over the PoI information along different paths, we formulate the problem as a novel non-atomic multi-path routing game with positive network externalities among users in social information sharing. In the absence of any incentive design, our price of anarchy (PoA) analysis shows that users' selfish routing on the path with the lowest cost will limit information diversity and lead to $PoA = 0$ with an arbitrarily large efficiency loss from the social optimum. This motivates us to design effective incentive mechanisms to remedy while upholding desirable properties such as individual rationality, incentive compatibility, and budget balance for practical users. Without requiring a specific user's path preference, we present a non-monetary mechanism called Adaptive Information Restriction (AIR) that reduces non-cooperative users' access to the public good as an indirect penalty, which meets all the desirable properties. By meticulously adapting penalty fractions to the actual user flows along different paths, our AIR achieves non-trivial $PoA = \frac{1}{4}$ with low complexity $O(k\log k+\log m)$, where $k$ and $m$ denote the numbers of involved paths and user types, respectively. If the system can further enable pricing for users, we then propose a new monetary mechanism called Adaptive Side-Payment (ASP), which adaptively charges and rewards users according to their chosen paths, respectively. Our ASP mechanism successively achieves a $PoA = \frac{1}{2}$ with even reduced complexity $O(k\log k)$. Finally, our theoretical findings are well corroborated by our experimental results using a real-world public dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13301v4</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Songhua Li, Lingjie Duan</dc:creator>
    </item>
    <item>
      <title>Social Learning in Community Structured Graphs</title>
      <link>https://arxiv.org/abs/2312.12186</link>
      <description>arXiv:2312.12186v2 Announce Type: replace-cross 
Abstract: Traditional social learning frameworks consider environments with a homogeneous state, where each agent receives observations conditioned on that true state of nature. In this work, we relax this assumption and study the distributed hypothesis testing problem in a heterogeneous environment, where each agent can receive observations conditioned on their own personalized state of nature (or truth). We particularly focus on community structured networks, where each community admits their own true hypothesis. This scenario is common in various contexts, such as when sensors are spatially distributed, or when individuals in a social network have differing views or opinions. We show that the adaptive social learning strategy is a preferred choice for nonstationary environments, and allows each cluster to discover its own truth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.12186v2</guid>
      <category>cs.SI</category>
      <category>cs.MA</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valentina Shumovskaia, Mert Kayaalp, Ali H. Sayed</dc:creator>
    </item>
    <item>
      <title>Distributed Multi-Task Learning for Stochastic Bandits with Context Distribution and Stage-wise Constraints</title>
      <link>https://arxiv.org/abs/2401.11563</link>
      <description>arXiv:2401.11563v2 Announce Type: replace-cross 
Abstract: We present the problem of conservative distributed multi-task learning in stochastic linear contextual bandits with heterogeneous agents. This extends conservative linear bandits to a distributed setting where M agents tackle different but related tasks while adhering to stage-wise performance constraints. The exact context is unknown, and only a context distribution is available to the agents as in many practical applications that involve a prediction mechanism to infer context, such as stock market prediction and weather forecast. We propose a distributed upper confidence bound (UCB) algorithm, DiSC-UCB. Our algorithm constructs a pruned action set during each round to ensure the constraints are met. Additionally, it includes synchronized sharing of estimates among agents via a central server using well-structured synchronization steps. We prove the regret and communication bounds on the algorithm. We extend the problem to a setting where the agents are unaware of the baseline reward. For this setting, we provide a modified algorithm, DiSC-UCB2, and we show that the modified algorithm achieves the same regret and communication bounds. We empirically validated the performance of our algorithm on synthetic data and real-world Movielens-100K data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11563v2</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiabin Lin, Shana Moothedath</dc:creator>
    </item>
  </channel>
</rss>
