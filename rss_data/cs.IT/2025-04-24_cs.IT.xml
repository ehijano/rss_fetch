<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Apr 2025 04:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Towards Quantum Universal Hypothesis Testing</title>
      <link>https://arxiv.org/abs/2504.16299</link>
      <description>arXiv:2504.16299v1 Announce Type: new 
Abstract: Hoeffding's formulation and solution to the universal hypothesis testing (UHT) problem had a profound impact on many subsequent works dealing with asymmetric hypotheses. In this work, we introduce a quantum universal hypothesis testing framework that serves as a quantum analog to Hoeffding's UHT. Motivated by Hoeffding's approach, which estimates the empirical distribution and uses it to construct the test statistic, we employ quantum state tomography to reconstruct the unknown state prior to forming the test statistic. Leveraging the concentration properties of quantum state tomography, we establish the exponential consistency of the proposed test: the type II error probability decays exponentially quickly, with the exponent determined by the trace distance between the true state and the nominal state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16299v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arick Grootveld, Haodong Yang, Biao Chen, Venkata Gandikota, Jason Pollack</dc:creator>
    </item>
    <item>
      <title>Tight Exponential Strong Converses for Lossy Source Coding with Side-Information and Distributed Function Computation</title>
      <link>https://arxiv.org/abs/2504.16380</link>
      <description>arXiv:2504.16380v1 Announce Type: new 
Abstract: The exponential strong converse for a coding problem states that, if a coding rate is beyond the theoretical limit, the correct probability converges to zero exponentially. For the lossy source coding with side-information, also known as the Wyner-Ziv (WZ) problem, a lower bound on the strong converse exponent was derived by Oohama. In this paper, we derive the tight strong converse exponent for the WZ problem; as a special case, we also derive the tight strong converse exponent for the distributed function computation problem. For the converse part, we use the change-of-measure argument developed in the literature and the soft Markov constraint introduced by Oohama; the matching achievability is proved via the Poisson matching approach recently introduced by Li and Anantharam. Our result is build upon the recently derived tight strong converse exponent for the Wyner-Ahlswede-Korner (WAK) problem; however, compared to the WAK problem, more sophisticated argument is needed. As an illustration of the necessity of the soft Markov constraint, we present an example such that the soft Markov constraint is strictly positive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16380v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shun Watanabe</dc:creator>
    </item>
    <item>
      <title>Partial orders and contraction for BISO channels</title>
      <link>https://arxiv.org/abs/2504.16726</link>
      <description>arXiv:2504.16726v1 Announce Type: new 
Abstract: A fundamental question in information theory is to quantify the loss of information under a noisy channel. Partial orders and contraction coefficients are typical tools to that end, however, they are often also challenging to evaluate. For the special class of binary input symmetric output (BISO) channels, Geng et al. showed that among channels with the same capacity, the binary symmetric channel (BSC) and binary erasure channel (BEC) are extremal with respect to the more capable order. Here, we show two main results. First, for channels with the same KL contraction coefficient, the same holds with respect to the less noisy order. Second, for channels with the same Dobrushin coefficient, or equiv. maximum leakage or Doeblin coefficient, the same holds with respect to the degradability order. In the process, we provide a closed-form expression for the contraction coefficients of BISO channels. We also discuss the comparability of BISO channels and extensions to binary channels in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16726v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Hirche, Oxana Shaya</dc:creator>
    </item>
    <item>
      <title>Performance Analysis of IEEE 802.11bn Non-Primary Channel Access</title>
      <link>https://arxiv.org/abs/2504.15774</link>
      <description>arXiv:2504.15774v1 Announce Type: cross 
Abstract: This paper presents a performance analysis of the Non-Primary Channel Access (NPCA) mechanism, a new feature introduced in IEEE 802.11bn to enhance spectrum utilization in Wi-Fi networks. NPCA enables devices to contend for and transmit on the secondary channel when the primary channel is occupied by transmissions from an Overlapping Basic Service Set (OBSS). We develop a Continuous-Time Markov Chain (CTMC) model that captures the interactions among OBSSs in dense WLAN environments when NPCA is enabled, incorporating new NPCA-specific states and transitions. In addition to the analytical insights offered by the model, we conduct numerical evaluations and simulations to quantify NPCA's impact on throughput and channel access delay across various scenarios. Our results show that NPCA can significantly improve throughput and reduce access delays in favorable conditions for BSSs that support the mechanism. Moreover, NPCA helps mitigate the OBSS performance anomaly, where low-rate OBSS transmissions degrade network performance for all nearby devices. However, we also observe trade-offs: NPCA may increase contention on secondary channels, potentially reducing transmission opportunities for BSSs operating there.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15774v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boris Bellalta, Francesc Wilhelmi, Lorenzo Galati-Giordano, Giovanni Geraci</dc:creator>
    </item>
    <item>
      <title>Two-Timescale Joint Transmit and Pinching Beamforming for Pinching-Antenna Systems</title>
      <link>https://arxiv.org/abs/2504.16099</link>
      <description>arXiv:2504.16099v1 Announce Type: cross 
Abstract: Pinching antenna systems (PASS) have been proposed as a revolutionary flexible antenna technology which facilitates line-of-sight links via numerous low-cost pinching antennas with adjustable activation positions over waveguides. This letter proposes a two-timescale joint transmit and pinching beamforming design for the maximization of sum rate of a PASS-based downlink multi-user multiple input single output system. A primal dual decomposition method is developed to decouple the two-timescale problem into two sub-problems: 1) A Karush-Kuhn-Tucker-guided dual learning-based approach is proposed to solve the short-term transmit beamforming design sub-problem; 2) The long-term pinching beamforming design sub-problem is tackled by adopting a stochastic successive convex approximation method. Simulation results demonstrate that the proposed two-timescale algorithm achieves a significant performance gain compared to other baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16099v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luyuan Zhang, Xidong Mu, An Liu, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>Phased Array Calibration based on Rotating-Element Harmonic Electric-Field Vector with Time Modulation</title>
      <link>https://arxiv.org/abs/2504.16107</link>
      <description>arXiv:2504.16107v1 Announce Type: cross 
Abstract: Calibration is crucial for ensuring the performance of phased array since amplitude-phase imbalance between elements results in significant performance degradation. While amplitude-only calibration methods offer advantages when phase measurements are impractical, conventional approaches face two key challenges: they typically require high-resolution phase shifters and remain susceptible to phase errors inherent in these components. To overcome these limitations, we propose a Rotating element Harmonic Electric-field Vector (RHEV) strategy, which enables precise calibration through time modulation principles. The proposed technique functions as follows. Two 1-bit phase shifters are periodically phase-switched at the same frequency, each generating corresponding harmonics. By adjusting the relative delay between their modulation timings, the phase difference between the $+1$st harmonics produced by the two elements can be precisely controlled, utilizing the time-shift property of the Fourier transform. Furthermore, the +1st harmonic generated by sequential modulation of individual elements exhibits a linear relationship with the amplitude of the modulated element, enabling amplitude ambiguity resolution. The proposed RHEV-based calibration method generates phase shifts through relative timing delays rather than physical phase shifter adjustments, rendering it less susceptible to phase shift errors. Additionally, since the calibration process exclusively utilizes the $+1$st harmonic, which is produced solely by the modulated unit, the method demonstrates consistent performance regardless of array size. Extensive numerical simulations, practical in-channel and over-the-air (OTA) calibration experiments demonstrate the effectiveness and distinct advantages of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16107v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiyuan Li, Yuyue Zhou, Chi Zhang, Liang Kong, Kebin Liu, Yihan Xie, Chong He</dc:creator>
    </item>
    <item>
      <title>Aerial Active STAR-RIS-assisted Satellite-Terrestrial Covert Communications</title>
      <link>https://arxiv.org/abs/2504.16146</link>
      <description>arXiv:2504.16146v1 Announce Type: cross 
Abstract: An integration of satellites and terrestrial networks is crucial for enhancing performance of next generation communication systems. However, the networks are hindered by the long-distance path loss and security risks in dense urban environments. In this work, we propose a satellite-terrestrial covert communication system assisted by the aerial active simultaneous transmitting and reflecting reconfigurable intelligent surface (AASTAR-RIS) to improve the channel capacity while ensuring the transmission covertness. Specifically, we first derive the minimal detection error probability (DEP) under the worst condition that the Warden has perfect channel state information (CSI). Then, we formulate an AASTAR-RIS-assisted satellite-terrestrial covert communication optimization problem (ASCCOP) to maximize the sum of the fair channel capacity for all ground users while meeting the strict covert constraint, by jointly optimizing the trajectory and active beamforming of the AASTAR-RIS. Due to the challenges posed by the complex and high-dimensional state-action spaces as well as the need for efficient exploration in dynamic environments, we propose a generative deterministic policy gradient (GDPG) algorithm, which is a generative deep reinforcement learning (DRL) method to solve the ASCCOP. Concretely, the generative diffusion model (GDM) is utilized as the policy representation of the algorithm to enhance the exploration process by generating diverse and high-quality samples through a series of denoising steps. Moreover, we incorporate an action gradient mechanism to accomplish the policy improvement of the algorithm, which refines the better state-action pairs through the gradient ascent. Simulation results demonstrate that the proposed approach significantly outperforms important benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16146v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuang Zhang, Geng Sun, Jiahui Li, Jiacheng Wang, Ruichen Zhang, Dusit Niyato, Shiwen Mao, Tony Q. S. Quek</dc:creator>
    </item>
    <item>
      <title>Towards a Generalized Theory of Observers</title>
      <link>https://arxiv.org/abs/2504.16225</link>
      <description>arXiv:2504.16225v1 Announce Type: cross 
Abstract: We propose a formal framework for understanding and unifying the concept of observers across physics, computer science, philosophy, and related fields. Building on cybernetic feedback models, we introduce an operational definition of minimal observers, explore their role in shaping foundational concepts, and identify what remains unspecified in their absence. Drawing upon insights from quantum gravity, digital physics, second-order cybernetics, and recent ruliological and pregeometric approaches, we argue that observers serve as indispensable reference points for measurement, reference frames, and the emergence of meaning. We show how this formalism sheds new light on debates related to consciousness, quantum measurement, and computational boundaries; by way of theorems on observer equivalences and complexity measures. This perspective opens new avenues for investigating how complexity and structure arise in both natural and artificial systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16225v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.comp-ph</category>
      <category>physics.hist-ph</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hatem Elshatlawy, Dean Rickles, Xerxes D. Arsiwalla, Alexander Blum</dc:creator>
    </item>
    <item>
      <title>Detecting Correlation between Multiple Unlabeled Gaussian Networks</title>
      <link>https://arxiv.org/abs/2504.16279</link>
      <description>arXiv:2504.16279v1 Announce Type: cross 
Abstract: This paper studies the hypothesis testing problem to determine whether m &gt; 2 unlabeled graphs with Gaussian edge weights are correlated under a latent permutation. Previously, a sharp detection threshold for the correlation parameter \rho was established by Wu, Xu and Yu for this problem when m = 2. Presently, their result is leveraged to derive necessary and sufficient conditions for general m. In doing so, an interval for \rho is uncovered for which detection is impossible using 2 graphs alone but becomes possible with m &gt; 2 graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16279v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taha Ameen, Bruce Hajek</dc:creator>
    </item>
    <item>
      <title>Key-agreement exists if and only if the "interactive vs non interactive Kolmogorov problem" is not in ioBPP: a short proof</title>
      <link>https://arxiv.org/abs/2504.16311</link>
      <description>arXiv:2504.16311v1 Announce Type: cross 
Abstract: Ball, Liu, Mazor and Pass proved that the existence of key-agreement protocols is equivalent to the hardness of a certain problem about interactive Kolmogorov complexity. We generalize the statement and give a short proof of the difficult implication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16311v1</guid>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bruno Bauwens, Bruno Loff</dc:creator>
    </item>
    <item>
      <title>Property-Preserving Hashing for $\ell_1$-Distance Predicates: Applications to Countering Adversarial Input Attacks</title>
      <link>https://arxiv.org/abs/2504.16355</link>
      <description>arXiv:2504.16355v1 Announce Type: cross 
Abstract: Perceptual hashing is used to detect whether an input image is similar to a reference image with a variety of security applications. Recently, they have been shown to succumb to adversarial input attacks which make small imperceptible changes to the input image yet the hashing algorithm does not detect its similarity to the original image. Property-preserving hashing (PPH) is a recent construct in cryptography, which preserves some property (predicate) of its inputs in the hash domain. Researchers have so far shown constructions of PPH for Hamming distance predicates, which, for instance, outputs 1 if two inputs are within Hamming distance $t$. A key feature of PPH is its strong correctness guarantee, i.e., the probability that the predicate will not be correctly evaluated in the hash domain is negligible. Motivated by the use case of detecting similar images under adversarial setting, we propose the first PPH construction for an $\ell_1$-distance predicate. Roughly, this predicate checks if the two one-sided $\ell_1$-distances between two images are within a threshold $t$. Since many adversarial attacks use $\ell_2$-distance (related to $\ell_1$-distance) as the objective function to perturb the input image, by appropriately choosing the threshold $t$, we can force the attacker to add considerable noise to evade detection, and hence significantly deteriorate the image quality. Our proposed scheme is highly efficient, and runs in time $O(t^2)$. For grayscale images of size $28 \times 28$, we can evaluate the predicate in $0.0784$ seconds when pixel values are perturbed by up to $1 \%$. For larger RGB images of size $224 \times 224$, by dividing the image into 1,000 blocks, we achieve times of $0.0128$ seconds per block for $1 \%$ change, and up to $0.2641$ seconds per block for $14\%$ change.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16355v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hassan Asghar, Chenhan Zhang, Dali Kaafar</dc:creator>
    </item>
    <item>
      <title>Closed-form analysis of Multi-RIS Reflected Signals in RIS-Aided Networks Using Stochastic Geometry</title>
      <link>https://arxiv.org/abs/2504.16469</link>
      <description>arXiv:2504.16469v1 Announce Type: cross 
Abstract: Reconfigurable intelligent surfaces (RISs) enhance wireless communication by creating engineered signal reflection paths in addition to direct links. This work presents a stochastic geometry framework using point processes (PPs) to model multiple randomly deployed RISs conditioned on their associated base station (BS) locations. By characterizing aggregated reflections from multiple RISs using the Laplace transform, we analytically assess the performance impact of RIS-reflected signals by integrating this characterization into well-established stochastic geometry frameworks. Specifically, we derive closed-form expressions for the Laplace transform of the reflected signal power in several deployment scenarios. These analytical results facilitate performance evaluation of RIS-enabled enhancements. Numerical simulations validate that optimal RIS placement favors proximity to BSs or user equipment (UEs), and further quantify the impact of reflected interference, various fading assumptions, and diverse spatial deployment strategies. Importantly, our analytical approach shows superior computational efficiency compared to Monte Carlo simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16469v1</guid>
      <category>cs.PF</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guodong Sun, Francois Baccelli</dc:creator>
    </item>
    <item>
      <title>LiDAL-Assisted RLNC-NOMA in OWC Systems</title>
      <link>https://arxiv.org/abs/2504.16498</link>
      <description>arXiv:2504.16498v1 Announce Type: cross 
Abstract: Optical wireless communication (OWC) is envisioned as a key enabler for immersive indoor data transmission in future wireless communication networks. However, multi-user interference management arises as a challenge in dense indoor OWC systems composed of multiple optical access points (APs) serving multiple users. In this paper, we propose a novel dual-function OWC system for communication and localization. Non-orthogonal multiple access (NOMA) with random linear network coding (RLNC) is designed for data transmission, where NOMA allows the serving of multiple users simultaneously through controlling the power domain, and RLNC helps minimize errors that might occur during signal processing phase. This setup is assisted with a light detection and localization system (LiDAL) that can passively obtain spatio-temporal indoor information of user presence and location for dynamic-user grouping. The designed LiDAL system helps to improve the estimation of channel state information (CSI) in realistic indoor network scenarios, where the CSI of indoor users might be noisy and/or highly correlated. We evaluate the performance of NOMA combined with RLNC by analyzing the probability of successful decoding compared to conventional NOMA and orthogonal schemes. In addition, we derive the Cramer-Rao Lower Bound (CRLB) to evaluate the accuracy of location estimation. The results show that the proposed RLNC-NOMA improves the probability of successful decoding and the overall system performance. The results also show the high accuracy of the unbiased location estimator and its assistant in reducing the imperfection of CSI, leading to high overall system performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16498v1</guid>
      <category>eess.SY</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed A. Hassan, Ahmad Adnan Qidan, Taisir Elgorashi, Jaafar Elmirghani</dc:creator>
    </item>
    <item>
      <title>Uplink Sum Rate Maximization for Pinching Antenna-Assisted Multiuser MISO</title>
      <link>https://arxiv.org/abs/2504.16577</link>
      <description>arXiv:2504.16577v1 Announce Type: cross 
Abstract: This article investigates the application of pinching-antenna systems (PASS) in multiuser multiple-input single-output (MISO) communications. Two sum-rate maximization problems are formulated under minimum mean square error (MMSE) decoding, with and without successive interference cancellation (SIC). To address the joint optimization of pinching antenna locations and user transmit powers, a fractional programming-based approach is proposed. Numerical results validate the effectiveness of the proposed method and show that PASS can significantly enhance uplink sum-rate performance compared to conventional fixed-antenna designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16577v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiarui Zhang, Hao Xu, Chongjun Ouyang, Qiuyun Zou, Hongwen Yang</dc:creator>
    </item>
    <item>
      <title>Security Science (SecSci), Basic Concepts and Mathematical Foundations</title>
      <link>https://arxiv.org/abs/2504.16617</link>
      <description>arXiv:2504.16617v1 Announce Type: cross 
Abstract: This textbook compiles the lecture notes from security courses taught at Oxford in the 2000s, at Royal Holloway in the 2010s, and currently in Hawaii. The early chapters are suitable for a first course in security. The middle chapters have been used in advanced courses. Towards the end there are also some research problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16617v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.IT</category>
      <category>cs.SI</category>
      <category>math.IT</category>
      <category>math.LO</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dusko Pavlovic, Peter-Michael Seidel</dc:creator>
    </item>
    <item>
      <title>I-Con: A Unifying Framework for Representation Learning</title>
      <link>https://arxiv.org/abs/2504.16929</link>
      <description>arXiv:2504.16929v1 Announce Type: cross 
Abstract: As the field of representation learning grows, there has been a proliferation of different loss functions to solve different classes of problems. We introduce a single information-theoretic equation that generalizes a large collection of modern loss functions in machine learning. In particular, we introduce a framework that shows that several broad classes of machine learning methods are precisely minimizing an integrated KL divergence between two conditional distributions: the supervisory and learned representations. This viewpoint exposes a hidden information geometry underlying clustering, spectral methods, dimensionality reduction, contrastive learning, and supervised learning. This framework enables the development of new loss functions by combining successful techniques from across the literature. We not only present a wide array of proofs, connecting over 23 different approaches, but we also leverage these theoretical results to create state-of-the-art unsupervised image classifiers that achieve a +8% improvement over the prior state-of-the-art on unsupervised classification on ImageNet-1K. We also demonstrate that I-Con can be used to derive principled debiasing methods which improve contrastive representation learners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16929v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaden Alshammari, John Hershey, Axel Feldmann, William T. Freeman, Mark Hamilton</dc:creator>
    </item>
    <item>
      <title>The Mutual Information In The Vicinity of Capacity-Achieving Input Distributions</title>
      <link>https://arxiv.org/abs/2304.14219</link>
      <description>arXiv:2304.14219v5 Announce Type: replace 
Abstract: The mutual information is bounded from above by a decreasing affine function of the square of the distance between the input distribution and the set of all capacity-achieving input distributions $\Pi_{\mathcal{A}}$, on small enough neighborhoods of $\Pi_{\mathcal{A}}$, using an identity due to Tops{\o}e and the Pinsker's inequality, assuming that the input set of the channel is finite and the constraint set $\mathcal{A}$ is polyhedral, i.e., can be described by (possibly multiple but) finitely many linear constraints. Counterexamples demonstrating nonexistence of such a quadratic bound are provided for the case of infinitely many linear constraints and the case of infinite input sets. Using Taylor's theorem with the remainder term, rather than the Pinsker's inequality and invoking Moreau's decomposition theorem the exact characterization of the slowest decrease of the mutual information with the distance to $\Pi_{\mathcal{A}}$ is determined on small neighborhoods of $\Pi_{\mathcal{A}}$. Corresponding results for classical-quantum channels are established under separable output Hilbert space assumption for the quadratic bound and under finite-dimensional output Hilbert space assumption for the exact characterization. Implications of these observations for the channel coding problem and applications of the proof techniques to related problems are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.14219v5</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TIT.2025.3562098</arxiv:DOI>
      <dc:creator>Bar{\i}\c{s} Nakibo\u{g}lu, Hao-Chung Cheng</dc:creator>
    </item>
    <item>
      <title>Two-timescale joint power control and beamforming design with applications to cell-free massive MIMO</title>
      <link>https://arxiv.org/abs/2312.02080</link>
      <description>arXiv:2312.02080v5 Announce Type: replace 
Abstract: In this study we derive novel optimal algorithms for joint power control and beamforming design in modern large-scale MIMO systems, such as those based on the cell-free massive MIMO and XL-MIMO concepts. In particular, motivated by the need for scalable system architectures, we formulate and solve nontrivial two-timescale extensions of the classical uplink power minimization and max-min fair resource allocation problems. In our formulations, we let the beamformers be functions mapping partial instantaneous channel state information (CSI) to beamforming weights, and we jointly optimize these functions and the power control coefficients based on long-term statistical CSI. This long-term approach mitigates the severe scalability issues of competing short-term iterative algorithms in the literature, where a central controller endowed with global instantaneous CSI must solve a complex optimization problem for every channel realization, hence imposing very demanding requirements in terms of computational complexity and signaling overhead. Moreover, our approach outperforms the available long-term approaches, which do not jointly optimize powers and beamformers. The obtained optimal long-term algorithms are then illustrated and compared against existing short-term and long-term algorithms via numerical simulations in a cell-free massive MIMO setup with different levels of cooperation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02080v5</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Miretti, Renato L. G. Cavalcante, S{\l}awomir Sta\'nczak</dc:creator>
    </item>
    <item>
      <title>Coding for Gaussian Two-Way Channels: Linear and Learning-Based Approaches</title>
      <link>https://arxiv.org/abs/2401.00477</link>
      <description>arXiv:2401.00477v2 Announce Type: replace 
Abstract: Although user cooperation cannot improve the capacity of Gaussian two-way channels (GTWCs) with independent noises, it can improve communication reliability. In this work, we aim to enhance and balance the communication reliability in GTWCs by minimizing the sum of error probabilities via joint design of encoders and decoders at the users. We first formulate general encoding/decoding functions, where the user cooperation is captured by the coupling of user encoding processes. The coupling effect renders the encoder/decoder design non-trivial, requiring effective decoding to capture this effect, as well as efficient power management at the encoders within power constraints. To address these challenges, we propose two different two-way coding strategies: linear coding and learning-based coding. For linear coding, we propose optimal linear decoding and discuss new insights on encoding regarding user cooperation to balance reliability. We then propose an efficient algorithm for joint encoder/decoder design. For learning-based coding, we introduce a novel recurrent neural network (RNN)-based coding architecture, where we propose interactive RNNs and a power control layer for encoding, and we incorporate bi-directional RNNs with an attention mechanism for decoding. Through simulations, we show that our two-way coding methodologies outperform conventional channel coding schemes (that do not utilize user cooperation) significantly in sum-error performance. We also demonstrate that our linear coding excels at high signal-to-noise ratios (SNRs), while our RNN-based coding performs best at low SNRs. We further investigate our two-way coding strategies in terms of power distribution, two-way coding benefit, different coding rates, and block-length gain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00477v2</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junghoon Kim, Taejoon Kim, Anindya Bijoy Das, Seyyedali Hosseinalipour, David J. Love, Christopher G. Brinton</dc:creator>
    </item>
    <item>
      <title>Sequential Outlier Hypothesis Testing under Universality Constraints</title>
      <link>https://arxiv.org/abs/2404.14221</link>
      <description>arXiv:2404.14221v5 Announce Type: replace 
Abstract: We revisit sequential outlier hypothesis testing and derive bounds on achievable exponents when both the nominal and anomalous distributions are unknown. The task of outlier hypothesis testing is to identify the set of outliers that are generated from an anomalous distribution among all observed sequences where the rest majority are generated from a nominal distribution. In the sequential setting, one obtains a symbol from each sequence per unit time until a reliable decision could be made. For the case with exactly one outlier, our exponent bounds are tight, providing exact large deviations characterization of sequential tests and strengthening a previous result of Li, Nitinawarat and Veeravalli (2017). In particular, the average sample size of our sequential test is bounded universally under any pair of nominal and anomalous distributions and our sequential test achieves larger Bayesian exponent than the fixed-length test, which could not be guaranteed by the sequential test of Li, Nitinawarat and Veeravalli (2017). For the case with at most one outlier, we propose a threshold-based test that has bounded expected stopping time under mild conditions and we bound the exponential decay rate of error probabilities under each non-null hypothesis and the null hypothesis. Our sequential test resolves the tradeoff among the exponential decay rates of misclassification, false reject and false alarm probabilities for the fixed-length test of Zhou, Wei and Hero (TIT 2022). Finally, with a further step towards practical applications, we generalize our results to the cases of multiple outliers and show that there is a penalty in the error exponents when the number of outliers is unknown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14221v5</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Diao, Lin Zhou</dc:creator>
    </item>
    <item>
      <title>Coded Downlink Massive Random Access and a Finite de Finetti Theorem</title>
      <link>https://arxiv.org/abs/2405.08301</link>
      <description>arXiv:2405.08301v3 Announce Type: replace 
Abstract: This paper considers a massive connectivity setting in which a base-station (BS) aims to communicate sources $(X_1,\cdots,X_k)$ to a randomly activated subset of $k$ users, among a large pool of $n$ users, via a common message in the downlink. Although the identities of the $k$ active users are assumed to be known at the BS, each active user only knows whether itself is active and does not know the identities of the other active users. A naive coding strategy is to transmit the sources alongside the identities of the users for which the source information is intended. This requires $H(X_1,\cdots,X_k) + k\log(n)$ bits, because the cost of specifying the identity of one out of $n$ users is $\log(n)$ bits. For large $n$, this overhead can be significant. This paper shows that it is possible to develop coding techniques that eliminate the dependency of the overhead on $n$, if the source distribution follows certain symmetry. Specifically, if the source distribution is independently and identically distributed (i.i.d.) then the overhead can be reduced to at most $O(\log(k))$ bits, and in case of uniform i.i.d. sources, the overhead can be further reduced to $O(1)$ bits. For sources that follow a more general exchangeable distribution, the overhead is at most $O(k)$ bits, and in case of finite-alphabet exchangeable sources, the overhead can be further reduced to $O(\log(k))$ bits. The downlink massive random access problem is closely connected to the study of finite exchangeable sequences. The proposed coding strategy allows bounds on the Kullback-Leibler (KL) divergence between finite exchangeable distributions and i.i.d. mixture distributions to be developed, and gives a new KL divergence version of the finite de Finetti theorem which is scaling optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08301v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Song, Kareem M. Attiah, Wei Yu</dc:creator>
    </item>
    <item>
      <title>Memory Complexity of Estimating Entropy and Mutual Information</title>
      <link>https://arxiv.org/abs/2406.06312</link>
      <description>arXiv:2406.06312v3 Announce Type: replace 
Abstract: We observe an infinite sequence of independent identically distributed random variables $X_1,X_2,\ldots$ drawn from an unknown distribution $p$ over $[n]$, and our goal is to estimate the entropy $H(p)=-\mathbb{E}[\log p(X)]$ within an $\varepsilon$-additive error. To that end, at each time point we are allowed to update a finite-state machine with $S$ states, using a possibly randomized but time-invariant rule, where each state of the machine is assigned an entropy estimate. Our goal is to characterize the minimax memory complexity $S^*$ of this problem, which is the minimal number of states for which the estimation task is feasible with probability at least $1-\delta$ asymptotically, uniformly in $p$. Specifically, we show that there exist universal constants $C_1$ and $C_2$ such that $ S^* \leq C_1\cdot\frac{n (\log n)^4}{\varepsilon^2\delta}$ for $\varepsilon$ not too small, and $S^* \geq C_2 \cdot \max \{n, \frac{\log n}{\varepsilon}\}$ for $\varepsilon$ not too large. The upper bound is proved using approximate counting to estimate the logarithm of $p$, and a finite memory bias estimation machine to estimate the expectation operation. The lower bound is proved via a reduction of entropy estimation to uniformity testing. We also apply these results to derive bounds on the memory complexity of mutual information estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06312v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Tomer Berg, Or Ordentlich, Ofer Shayevitz</dc:creator>
    </item>
    <item>
      <title>Pre-Chirp-Domain Index Modulation for Full-Diversity Affine Frequency Division Multiplexing towards 6G</title>
      <link>https://arxiv.org/abs/2410.00313</link>
      <description>arXiv:2410.00313v4 Announce Type: replace 
Abstract: Affine frequency division multiplexing (AFDM), tailored as a superior multicarrier technique utilizing chirp signals for high-mobility communications, is envisioned as a promising candidate for the sixth-generation (6G) wireless network. AFDM is based on the discrete affine Fourier transform (DAFT) with two adjustable parameters of the chirp signals, termed as the pre-chirp and post-chirp parameters, respectively. We show that the pre-chirp counterpart can be flexibly manipulated for additional degree-of-freedom (DoF). Therefore, this paper proposes a novel AFDM scheme with the pre-chirp index modulation (PIM) philosophy (AFDM-PIM), which can implicitly convey extra information bits through dynamic pre-chirp parameter assignment, thus enhancing both spectral and energy efficiency. Specifically, we first demonstrate that the subcarrier orthogonality is still maintained by applying distinct pre-chirp parameters to various subcarriers in the AFDM modulation process. Inspired by this property, each AFDM subcarrier is constituted with a unique pre-chirp signal according to the incoming bits. By such arrangement, extra binary bits can be embedded into the index patterns of pre-chirp parameter assignment without additional energy consumption. For performance analysis, we derive the asymptotically tight upper bounds on the average bit error rates (BERs) of the proposed schemes with maximum-likelihood (ML) detection, and validate that the proposed AFDM-PIM can achieve the optimal diversity order under doubly dispersive channels. Based on the derivations, we further propose an optimal pre-chirp alphabet design to enhance the BER performance via intelligent optimization algorithms. Simulations demonstrate that the proposed AFDM-PIM outperforms the classical benchmarks under doubly dispersive channel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00313v4</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangyao Liu, Tianqi Mao, Zhenyu Xiao, Miaowen Wen, Ruiqi Liu, Jingjing Zhao, Ertugrul Basar, Zhaocheng Wang, Sheng Chen</dc:creator>
    </item>
    <item>
      <title>A High-Resolution Analysis of Receiver Quantization in Communication</title>
      <link>https://arxiv.org/abs/2501.09961</link>
      <description>arXiv:2501.09961v3 Announce Type: replace 
Abstract: We investigate performance limits and design of communication in the presence of uniform output quantization with moderate to high resolution. Under independent and identically distributed (i.i.d.) complex Gaussian codebook and nearest neighbor decoding rule, an achievable rate is derived in an analytical form by the generalized mutual information (GMI). The gain control before quantization is shown to be increasingly important as the resolution decreases, due to the fact that the loading factor (normalized one-sided quantization range) has increasing impact on performance. The impact of imperfect gain control in the high-resolution regime is characterized by two asymptotic results: 1) the rate loss due to overload distortion decays exponentially as the loading factor increases, and 2) the rate loss due to granular distortion decays quadratically as the step size vanishes. For a $2K$-level uniform quantizer, we prove that the optimal loading factor that maximizes the achievable rate scales like $2\sqrt{\ln (2K)}$ as the resolution increases. An asymptotically tight estimate of the optimal loading factor is further given, which is also highly accurate for finite resolutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09961v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jing Zhou, Shuqin Pang, Wenyi Zhang</dc:creator>
    </item>
    <item>
      <title>Removal of Small Weight Stopping Sets for Asynchronous Unsourced Multiple Access</title>
      <link>https://arxiv.org/abs/2501.12186</link>
      <description>arXiv:2501.12186v2 Announce Type: replace 
Abstract: In this paper, we analyze the formation of small stopping sets in joint factor graphs describing a frame-asynchronous two-user transmission. Furthermore, we propose an algorithm to completely avoid small stopping sets in the joint factor graph over the entire range of symbol delays. The error floor caused by these stopping sets is completely mitigated. Our key observation is that, while the order of bits in the codeword is irrelevant in a single-user environment, it turns out to be crucial in an asynchronous, unsourced two-user system. Subsequently, our algorithm finds a reordering of variable nodes which avoids the smallest stopping set in the joint graph. We show that further improvements can be achieved when girth optimization of the single-user graphs by progressive edge growth (PEG) is used in combination with our proposed algorithm. Starting with a randomized code construction with optimized degree distribution, our simulation results show that PEG followed by the proposed algorithm can improve the average per user probability of error in a noiseless channel by almost two orders of magnitude for a broad range of frame delays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12186v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frederik Ritter, Jonathan Mandelbaum, Alexander Fengler, Holger J\"akel, Laurent Schmalen</dc:creator>
    </item>
    <item>
      <title>Strong Converse Exponent for Remote Lossy Source Coding</title>
      <link>https://arxiv.org/abs/2501.14620</link>
      <description>arXiv:2501.14620v2 Announce Type: replace 
Abstract: Past works on remote lossy source coding studied the rate under average distortion and the error exponent of excess distortion probability. In this work, we look into how fast the excess distortion probability converges to 1 at small rates, also known as exponential strong converse. We characterize its exponent by establishing matched upper and lower bounds. From the exponent, we also recover two previous results on lossy source coding and biometric authentication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14620v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Wu, Hamdi Joudeh</dc:creator>
    </item>
    <item>
      <title>Characterization of Deletion/Substitution Channel Capacity for Small Deletion and Substitution Probabilities</title>
      <link>https://arxiv.org/abs/2503.02545</link>
      <description>arXiv:2503.02545v2 Announce Type: replace 
Abstract: We consider binary input deletion/substitution channels, which model certain channels with synchronization errors encountered in practice. Specifically, we focus on the regime of small deletion and substitution probabilities, and by extending an approach developed for the deletion-only channel, we obtain an asymptotic characterization of the channel capacity for independent and identically distributed deletion/substitution channels. We first present an upper bound on the capacity for arbitrary but fixed numbers of deletions and substitutions, and then we extend the result to the case of random deletions and substitutions. Our final result is as follows: The i.i.d. deletion/substitution channel capacity is approximately $1 - H(p_d) - H(p_s)$, for $p_d, p_s \approx0$, where $p_d$ is the deletion probability, and $p_s$ is the substitution probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02545v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Kazemi, Tolga M. Duman</dc:creator>
    </item>
    <item>
      <title>A Short Proof of Coding Theorems for Reed-Muller Codes Under a Mild Assumption</title>
      <link>https://arxiv.org/abs/2504.14842</link>
      <description>arXiv:2504.14842v2 Announce Type: replace 
Abstract: In this paper, by treating Reed-Muller (RM) codes as a special class of low-density parity-check (LDPC) codes and assuming that sub-blocks of the parity-check matrix are randomly interleaved to each other as Gallager's codes, we present a short proof that RM codes are entropy-achieving as source coding for Bernoulli sources and capacity-achieving as channel coding for binary memoryless symmetric (BMS) channels, also known as memoryless binary-input output-symmetric (BIOS) channels, in terms of bit error rate (BER) under maximum-likelihood (ML) decoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14842v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao Ma</dc:creator>
    </item>
    <item>
      <title>Random Number Generation from Pulsars</title>
      <link>https://arxiv.org/abs/2502.18430</link>
      <description>arXiv:2502.18430v2 Announce Type: replace-cross 
Abstract: Pulsars exhibit signals with precise inter-arrival times that are on the order of milliseconds to seconds, depending on the individual pulsar. There are subtle variations in the timing of pulsar signals. We show that these variations can serve as a natural entropy source for the creation of Random Number Generators (RNGs). We also explore the effects of using randomness extractors to increase the entropy of random bits extracted from Pulsar timing data. To evaluate the quality of the Pulsar RNG, we model its entropy as a $k$-source and use well-known cryptographic results to show its closeness to a theoretically ideal uniformly random source. To remain consistent with prior work, we also show that the Pulsar RNG passes well-known statistical tests such as the NIST test suite.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18430v2</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hayder Tirmazi</dc:creator>
    </item>
    <item>
      <title>SuperARC: An Agnostic Test for Narrow, General, and Super Intelligence Based On the Principles of Recursive Compression and Algorithmic Probability</title>
      <link>https://arxiv.org/abs/2503.16743</link>
      <description>arXiv:2503.16743v3 Announce Type: replace-cross 
Abstract: We introduce an open-ended test grounded in algorithmic probability that can avoid benchmark contamination in the quantitative evaluation of frontier models in the context of their Artificial General Intelligence (AGI) and Superintelligence (ASI) claims. Unlike other tests, this test does not rely on statistical compression methods (such as GZIP or LZW), which are more closely related to Shannon entropy than to Kolmogorov complexity and are not able to test beyond simple pattern matching. The test challenges aspects of AI, in particular LLMs, related to features of intelligence of fundamental nature such as synthesis and model creation in the context of inverse problems (generating new knowledge from observation). We argue that metrics based on model abstraction and abduction (optimal Bayesian `inference') for predictive `planning' can provide a robust framework for testing intelligence, including natural intelligence (human and animal), narrow AI, AGI, and ASI. We found that LLM model versions tend to be fragile and incremental as a result of memorisation only with progress likely driven by the size of training data. The results were compared with a hybrid neurosymbolic approach that theoretically guarantees universal intelligence based on the principles of algorithmic probability and Kolmogorov complexity. The method outperforms LLMs in a proof-of-concept on short binary sequences. We prove that compression is equivalent and directly proportional to a system's predictive power and vice versa. That is, if a system can better predict it can better compress, and if it can better compress, then it can better predict. Our findings strengthen the suspicion regarding the fundamental limitations of LLMs, exposing them as systems optimised for the perception of mastery over human language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16743v3</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Hern\'andez-Espinosa, Luan Ozelim, Felipe S. Abrah\~ao, Hector Zenil</dc:creator>
    </item>
    <item>
      <title>Transport f divergences</title>
      <link>https://arxiv.org/abs/2504.15515</link>
      <description>arXiv:2504.15515v2 Announce Type: replace-cross 
Abstract: We define a class of divergences to measure differences between probability density functions in one-dimensional sample space. The construction is based on the convex function with the Jacobi operator of mapping function that pushforwards one density to the other. We call these information measures transport f-divergences. We present several properties of transport $f$-divergences, including invariances, convexities, variational formulations, and Taylor expansions in terms of mapping functions. Examples of transport f-divergences in generative models are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15515v2</guid>
      <category>math.ST</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wuchen Li</dc:creator>
    </item>
  </channel>
</rss>
