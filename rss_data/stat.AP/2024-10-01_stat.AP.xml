<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 01 Oct 2024 20:51:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Calibrating microscopic traffic models with macroscopic data</title>
      <link>https://arxiv.org/abs/2409.19090</link>
      <description>arXiv:2409.19090v1 Announce Type: new 
Abstract: Traffic microsimulation is a crucial tool that uses microscopic traffic models, such as car-following and lane-change models, to simulate the trajectories of individual agents. This digital platform allows for the assessment of the impact of emerging technologies on transportation system performance. While these microscopic models are based on mathematical structures, their parameters must be fitted to real-world data through a process called model calibration. Despite extensive studies on calibration, the focus has predominantly been on fitting microscopic data, such as trajectories, rather than evaluating how well the models reproduce macroscopic traffic patterns, such as congestion, bottlenecks, and traffic waves. In this work, we address this gap by calibrating microscopic traffic flow models using macroscopic (aggregated) data, which is more readily accessible. We designed a SUMO-in-the-loop calibration framework with the goal of replicating observed macroscopic traffic features. To assess calibration accuracy, we developed a set of performance measures that evaluate the models' ability to replicate traffic states across the entire spatiotemporal domain and other qualitative characteristics of traffic flow. The calibration method was applied to both a synthetic scenario and a real-world scenario on a segment of Interstate 24, to demonstrate its effectiveness in reproducing observed traffic patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19090v1</guid>
      <category>stat.AP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yanbing Wang, Felipe de Souza, Dominik Karbowski</dc:creator>
    </item>
    <item>
      <title>Re-evaluating the impact of reduced malaria prevalence on birthweight in sub-Saharan Africa: A pair-of-pairs study via two-stage bipartite and non-bipartite matching</title>
      <link>https://arxiv.org/abs/2409.19314</link>
      <description>arXiv:2409.19314v1 Announce Type: new 
Abstract: According to the WHO, in 2021, about 32% of pregnant women in sub-Saharan Africa were infected with malaria during pregnancy. Malaria infection during pregnancy can cause various adverse birth outcomes such as low birthweight. Over the past two decades, while some sub-Saharan African areas have experienced a large reduction in malaria prevalence due to improved malaria control and treatments, others have observed little change. Individual-level interventional studies have shown that preventing malaria infection during pregnancy can improve birth outcomes such as birthweight; however, it is still unclear whether natural reductions in malaria prevalence may help improve community-level birth outcomes. We conduct an observational study using 203,141 children's records in 18 sub-Saharan African countries from 2000 to 2018. Using heterogeneity of changes in malaria prevalence, we propose and apply a novel pair-of-pairs design via two-stage bipartite and non-bipartite matching to conduct a difference-in-differences study with a continuous measure of malaria prevalence, namely the Plasmodium falciparum parasite rate among children aged 2 to 10 ($\text{PfPR}_{2-10}$). The proposed novel statistical methodology allows us to apply difference-in-differences without dichotomizing $\text{PfPR}_{2-10}$, which can substantially increase the effective sample size, improve covariate balance, and facilitate the dose-response relationship during analysis. Our outcome analysis finds that among the pairs of clusters we study, the largest reduction in $\text{PfPR}_{2-10}$ over early and late years is estimated to increase the average birthweight by 98.899 grams (95% CI: $[39.002, 158.796]$), which is associated with reduced risks of several adverse birth or life-course outcomes. The proposed novel statistical methodology can be replicated in many other disease areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19314v1</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pengyun Wang, Ping Huang, Yifan Jin, Yanxin Shen, Omar El Shahawy, Dae Woong Ham, Wendy P. O'Meara, Siyu Heng</dc:creator>
    </item>
    <item>
      <title>Examining Exams Using Rasch Models and Assessment of Measurement Invariance</title>
      <link>https://arxiv.org/abs/2409.19522</link>
      <description>arXiv:2409.19522v1 Announce Type: new 
Abstract: Many statisticians regularly teach large lecture courses on statistics, probability, or mathematics for students from other fields such as business and economics, social sciences and psychology, etc. The corresponding exams often use a multiple-choice or single-choice format and are typically evaluated and graded automatically, either by scanning printed exams or via online learning management systems. Although further examinations of these exams would be of interest, these are frequently not carried out. For example a measurement scale for the difficulty of the questions (or items) and the ability of the students (or subjects) could be established using psychometric item response theory (IRT) models. Moreover, based on such a model it could be assessed whether the exam is really fair for all participants or whether certain items are easier (or more difficult) for certain subgroups of students.
  Here, several recent methods for assessing measurement invariance and for detecting differential item functioning in the Rasch IRT model are discussed and applied to results from a first-year mathematics exam with single-choice items. Several categorical, ordered, and numeric covariates like gender, prior experience, and prior mathematics knowledge are available to form potential subgroups with differential item functioning. Specifically, all analyses are demonstrated with a hands-on R tutorial using the psycho* family of R packages (psychotools, psychotree, psychomix) which provide a unified approach to estimating, visualizing, testing, mixing, and partitioning a range of psychometric models.
  The paper is dedicated to the memory of Fritz Leisch (1968-2024) and his contributions to various aspects of this work are highlighted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19522v1</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Achim Zeileis</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Guide to Simulation-based Inference in Computational Biology</title>
      <link>https://arxiv.org/abs/2409.19675</link>
      <description>arXiv:2409.19675v1 Announce Type: new 
Abstract: Computational models are invaluable in capturing the complexities of real-world biological processes. Yet, the selection of appropriate algorithms for inference tasks, especially when dealing with real-world observational data, remains a challenging and underexplored area. This gap has spurred the development of various parameter estimation algorithms, particularly within the realm of Simulation-Based Inference (SBI), such as neural and statistical SBI methods. Limited research exists on how to make informed choices on SBI methods when faced with real-world data, which often results in some form of model misspecification. In this paper, we provide comprehensive guidelines for deciding between SBI approaches for complex biological models. We apply the guidelines to two agent-based models that describe cellular dynamics using real-world data. Our study unveils a critical insight: while neural SBI methods demand significantly fewer simulations for inference results, they tend to yield biased estimations, a trend persistent even with robust variants of these algorithms. On the other hand, the accuracy of statistical SBI methods enhances substantially as the number of simulations increases. This finding suggests that, given a sufficient computational budget, statistical SBI can surpass neural SBI in performance. Our results not only shed light on the efficacy of different SBI methodologies in real-world scenarios but also suggest potential avenues for enhancing neural SBI approaches. This study is poised to be a useful resource for computational biologists navigating the intricate landscape of SBI in biological modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19675v1</guid>
      <category>stat.AP</category>
      <category>q-bio.QM</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyu Wang, Ryan P. Kelly, Adrianne L. Jenner, David J. Warne, Christopher Drovandi</dc:creator>
    </item>
    <item>
      <title>Nonparametric Covariance Regression for Massive Neural Data on Restricted Covariates via Graph</title>
      <link>https://arxiv.org/abs/2409.19717</link>
      <description>arXiv:2409.19717v1 Announce Type: new 
Abstract: Modern recording techniques enable neuroscientists to simultaneously study neural activity across large populations of neurons, with capturing predictor-dependent correlations being a fundamental challenge in neuroscience. Moreover, the fact that input covariates often lie in restricted subdomains, according to experimental settings, makes inference even more challenging. To address these challenges, we propose a set of nonparametric mean-covariance regression models for high-dimensional neural activity with restricted inputs. These models reduce the dimensionality of neural responses by employing a lower-dimensional latent factor model, where both factor loadings and latent factors are predictor-dependent, to jointly model mean and covariance across covariates. The smoothness of neural activity across experimental conditions is modeled nonparametrically using two Gaussian processes (GPs), applied to both loading basis and latent factors. Additionally, to account for the covariates lying in restricted subspace, we incorporate graph information into the covariance structure. To flexibly infer the model, we use an MCMC algorithm to sample from posterior distributions. After validating and studying the properties of proposed methods by simulations, we apply them to two neural datasets (local field potential and neural spiking data) to demonstrate the usage of models for continuous and counting observations. Overall, the proposed methods provide a framework to jointly model covariate-dependent mean and covariance in high dimensional neural data, especially when the covariates lie in restricted domains. The framework is general and can be easily adapted to various applications beyond neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19717v1</guid>
      <category>stat.AP</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganchao Wei</dc:creator>
    </item>
    <item>
      <title>Learning non-Gaussian spatial distributions via Bayesian transport maps with parametric shrinkage</title>
      <link>https://arxiv.org/abs/2409.19208</link>
      <description>arXiv:2409.19208v1 Announce Type: cross 
Abstract: Many applications, including climate-model analysis and stochastic weather generators, require learning or emulating the distribution of a high-dimensional and non-Gaussian spatial field based on relatively few training samples. To address this challenge, a recently proposed Bayesian transport map (BTM) approach consists of a triangular transport map with nonparametric Gaussian-process (GP) components, which is trained to transform the distribution of interest distribution to a Gaussian reference distribution. To improve the performance of this existing BTM, we propose to shrink the map components toward a ``base'' parametric Gaussian family combined with a Vecchia approximation for scalability. The resulting ShrinkTM approach is more accurate than the existing BTM, especially for small numbers of training samples. It can even outperform the ``base'' family when trained on a single sample of the spatial field. We demonstrate the advantage of ShrinkTM though numerical experiments on simulated data and on climate-model output.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19208v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anirban Chakraborty, Matthias Katzfuss</dc:creator>
    </item>
    <item>
      <title>Estimating Interpretable Heterogeneous Treatment Effect with Causal Subgroup Discovery in Survival Outcomes</title>
      <link>https://arxiv.org/abs/2409.19241</link>
      <description>arXiv:2409.19241v1 Announce Type: cross 
Abstract: Estimating heterogeneous treatment effect (HTE) for survival outcomes has gained increasing attention, as it captures the variation in treatment efficacy across patients or subgroups in delaying disease progression. However, most existing methods focus on post-hoc subgroup identification rather than simultaneously estimating HTE and selecting relevant subgroups. In this paper, we propose an interpretable HTE estimation framework that integrates three meta-learners that simultaneously estimate CATE for survival outcomes and identify predictive subgroups. We evaluated the performance of our method through comprehensive simulation studies across various randomized clinical trial (RCT) settings. Additionally, we demonstrated its application in a large RCT for age-related macular degeneration (AMD), a polygenic progressive eye disease, to estimate the HTE of an antioxidant and mineral supplement on time-to-AMD progression and to identify genetics-based subgroups with enhanced treatment effects. Our method offers a direct interpretation of the estimated HTE and provides evidence to support precision healthcare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19241v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Na Bo, Ying Ding</dc:creator>
    </item>
    <item>
      <title>Robust Multi-view Co-expression Network Inference</title>
      <link>https://arxiv.org/abs/2409.19991</link>
      <description>arXiv:2409.19991v1 Announce Type: cross 
Abstract: Unraveling the co-expression of genes across studies enhances the understanding of cellular processes. Inferring gene co-expression networks from transcriptome data presents many challenges, including spurious gene correlations, sample correlations, and batch effects. To address these complexities, we introduce a robust method for high-dimensional graph inference from multiple independent studies. We base our approach on the premise that each dataset is essentially a noisy linear mixture of gene loadings that follow a multivariate $t$-distribution with a sparse precision matrix, which is shared across studies. This allows us to show that we can identify the co-expression matrix up to a scaling factor among other model parameters. Our method employs an Expectation-Maximization procedure for parameter estimation. Empirical evaluation on synthetic and gene expression data demonstrates our method's improved ability to learn the underlying graph structure compared to baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19991v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Teodora Pandeva, Martijs Jonker, Leendert Hamoen, Joris Mooij, Patrick Forr\'e</dc:creator>
    </item>
    <item>
      <title>Ensemble WSINDy for Data Driven Discovery of Governing Equations from Laser-based Full-field Measurements</title>
      <link>https://arxiv.org/abs/2409.20510</link>
      <description>arXiv:2409.20510v1 Announce Type: cross 
Abstract: This work leverages laser vibrometry and the weak form of the sparse identification of nonlinear dynamics (WSINDy) for partial differential equations to learn macroscale governing equations from full-field experimental data. In the experiments, two beam-like specimens, one aluminum and one IDOX/Estane composite, are subjected to shear wave excitation in the low frequency regime and the response is measured in the form of particle velocity on the specimen surface. The WSINDy for PDEs algorithm is applied to the resulting spatio-temporal data to discover the effective dynamics of the specimens from a family of potential PDEs. The discovered PDE is of the recognizable Euler-Bernoulli beam model form, from which the Young's modulus for the two materials are estimated. An ensemble version of the WSINDy algorithm is also used which results in information about the uncertainty in the PDE coefficients and Young's moduli. The discovered PDEs are also simulated with a finite element code to compare against the experimental data with reasonable accuracy. Using full-field experimental data and WSINDy together is a powerful non-destructive approach for learning unknown governing equations and gaining insights about mechanical systems in the dynamic regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20510v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>stat.AP</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abigail C. Schmid, Alireza Doostan, Fatemeh Pourahmadian</dc:creator>
    </item>
    <item>
      <title>Fast spatial simulation of extreme high-resolution radar precipitation data using INLA</title>
      <link>https://arxiv.org/abs/2307.11390</link>
      <description>arXiv:2307.11390v3 Announce Type: replace 
Abstract: Aiming to deliver improved precipitation simulations for hydrological impact assessment studies, we develop a methodology for modelling and simulating high-dimensional spatial precipitation extremes, focusing on both their marginal distributions and tail dependence structures. Tail dependence is crucial for assessing the consequences of extreme precipitation events, yet most stochastic weather generators do not attempt to capture this property. The spatial distribution of precipitation occurrences is modelled with four competing models, while the spatial distribution of nonzero extreme precipitation intensities are modelled with a latent Gaussian version of the spatial conditional extremes model. Nonzero precipitation marginal distributions are modelled using latent Gaussian models with gamma and generalised Pareto likelihoods. Fast inference is achieved using integrated nested Laplace approximations (INLA). We model and simulate spatial precipitation extremes in Central Norway, using 13 years of hourly radar data with a spatial resolution of $1 \times 1$~km$^2$, over an area of size $6461$~km$^2$, to describe the behaviour of extreme precipitation over a small drainage area. Inference on this high-dimensional data set is achieved within hours, and the simulations capture the main trends of the observed precipitation well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.11390v3</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Silius M. Vandeskog, Rapha\"el Huser, Oddbj{\o}rn Bruland, Sara Martino</dc:creator>
    </item>
    <item>
      <title>Statistical Estimation of Mean Lorentzian Line Width in Spectra by Gaussian Processes</title>
      <link>https://arxiv.org/abs/2404.06338</link>
      <description>arXiv:2404.06338v2 Announce Type: replace 
Abstract: We propose a statistical approach for estimating the mean line width in spectra comprising Lorentzian, Gaussian, or Voigt line shapes. Our approach uses Gaussian processes in two stages to jointly model a spectrum and its Fourier transform. We generate statistical samples for the mean line width by drawing realizations for the Fourier transform and its derivative using Markov chain Monte Carlo methods. In addition to being fully automated, our method enables well-calibrated uncertainty quantification of the mean line width estimate through Bayesian inference. We validate our method using a simulation study and apply it to an experimental Raman spectrum of $\beta$-carotene.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06338v2</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erik Kuitunen, Matthew T. Moores, Teemu H\"ark\"onen</dc:creator>
    </item>
    <item>
      <title>Classification Modeling with RNN-Based, Random Forest, and XGBoost for Imbalanced Data: A Case of Early Crash Detection in ASEAN-5 Stock Markets</title>
      <link>https://arxiv.org/abs/2406.07888</link>
      <description>arXiv:2406.07888v2 Announce Type: replace 
Abstract: This research aims to evaluate the performance of several Recurrent Neural Network (RNN) architectures including Simple RNN, Gated Recurrent Units (GRU), and Long Short-Term Memory (LSTM), compared to classic algorithms such as Random Forest and XGBoost in building classification models for early crash detection in ASEAN-5 stock markets. The study is examined using imbalanced data, which is common due to the rarity of market crashes. The study analyzes daily data from 2010 to 2023 across the major stock markets of the ASEAN-5 countries, including Indonesia, Malaysia, Singapore, Thailand, and Philippines. Market crash is identified as the target variable when the major stock price indices fall below the Value at Risk (VaR) thresholds of 5%, 2.5% and 1%. predictors involving technical indicators of major local and global markets as well as commodity markets. This study includes 213 predictors with their respective lags (5, 10, 15, 22, 50, 200) and uses a time step of 7, expanding the total number of predictors to 1491. The challenge of data imbalance is addressed with SMOTE-ENN. The results show that all RNN-Based architectures outperform Random Forest and XGBoost. Among the various RNN architectures, Simple RNN stands out as the most superior, mainly due to the data characteristics that are not overly complex and focus more on short-term information. This study enhances and extends the range of phenomena observed in previous studies by incorporating variables like different geographical zones and time periods, as well as methodological adjustments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07888v2</guid>
      <category>stat.AP</category>
      <category>cs.AI</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Deri Siswara, Agus M. Soleh, Aji Hamim Wigena</dc:creator>
    </item>
    <item>
      <title>A Bayesian framework to evaluate evidence in cases of alleged cheating with secret codes in sports</title>
      <link>https://arxiv.org/abs/2409.08172</link>
      <description>arXiv:2409.08172v3 Announce Type: replace 
Abstract: We develop a statistical framework to evaluate evidence of alleged cheating with illegal signalling in sports from a forensic perspective. We explain why instead of a frequenstic procedure, a Bayesian approach is called for. We apply this framework to cases of alleged cheating in professional bridge and professional baseball. The diversity of these applications illustrates the generality of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08172v3</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aafko Boonstra, Ronald Meester</dc:creator>
    </item>
    <item>
      <title>A Sparse Beta Regression Model for Network Analysis</title>
      <link>https://arxiv.org/abs/2010.13604</link>
      <description>arXiv:2010.13604v3 Announce Type: replace-cross 
Abstract: For statistical analysis of network data, the $\beta$-model has emerged as a useful tool, thanks to its flexibility in incorporating nodewise heterogeneity and theoretical tractability. To generalize the $\beta$-model, this paper proposes the Sparse $\beta$-Regression Model (S$\beta$RM) that unites two research themes developed recently in modelling homophily and sparsity. In particular, we employ differential heterogeneity that assigns weights only to important nodes and propose penalized likelihood with an $\ell_1$ penalty for parameter estimation. While our estimation method is closely related to the LASSO method for logistic regression, we develop new theory emphasizing the use of our model for dealing with a parameter regime that can handle sparse networks usually seen in practice. More interestingly, the resulting inference on the homophily parameter demands no debiasing normally employed in LASSO type estimation. We provide extensive simulation and data analysis to illustrate the use of the model. As a special case of our model, we extend the Erd\H{o}s-R\'{e}nyi model by including covariates and develop the associated statistical inference for sparse networks, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.13604v3</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Stein, Rui Feng, Chenlei Leng</dc:creator>
    </item>
    <item>
      <title>Accounting statement analysis at industry level. A gentle introduction to the compositional approach</title>
      <link>https://arxiv.org/abs/2305.16842</link>
      <description>arXiv:2305.16842v5 Announce Type: replace-cross 
Abstract: Compositional data are contemporarily defined as positive vectors, the ratios among whose elements are of interest to the researcher. Financial statement analysis by means of accounting ratios a.k.a. financial ratios fulfils this definition to the letter. Compositional data analysis solves the major problems in statistical analysis of standard financial ratios at industry level, such as skewness, non-normality, non-linearity, outliers, and dependence of the results on the choice of which accounting figure goes to the numerator and to the denominator of the ratio. Despite this, compositional applications to financial statement analysis are still rare. In this article, we present some transformations within compositional data analysis that are particularly useful for financial statement analysis. We show how to compute industry or sub-industry means of standard financial ratios from a compositional perspective by means of geometric means. We show how to visualise firms in an industry with a compositional principal-component-analysis biplot; how to classify them into homogeneous financial performance profiles with compositional cluster analysis; and how to introduce financial ratios as variables in a statistical model, for instance to relate financial performance and firm characteristics with compositional regression models. We show an application to the accounting statements of Spanish wineries using the decomposition of return on equity by means of DuPont analysis, and a step-by-step tutorial to the compositional freeware CoDaPack.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.16842v5</guid>
      <category>q-fin.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Germ\`a Coenders (University of Girona), N\'uria Arimany Serrat (University of Vic - Central University of Catalonia)</dc:creator>
    </item>
    <item>
      <title>Data-Driven Bayesian Network Models of Hurricane Evacuation Decision Making</title>
      <link>https://arxiv.org/abs/2311.10228</link>
      <description>arXiv:2311.10228v2 Announce Type: replace-cross 
Abstract: Hurricanes cause significant economic and human costs, requiring individuals to make critical evacuation decisions under uncertainty and stress. To enhance the understanding of this decision-making process, we propose using Bayesian Networks (BNs) to model evacuation decisions during hurricanes. We collected questionnaire data from two significant hurricane events: Hurricane Harvey and Hurricane Irma. We employed a data-driven approach by first conducting variable selection using mutual information, followed by BN structure learning with two constraint-based algorithms. The robustness of the learned structures was enhanced by model averaging based on bootstrap resampling. We examined and compared the learned structures of both hurricanes, revealing potential causal relationships among key predictors of evacuation, including risk perception, information received from media, suggestions from family and friends, and neighbors evacuating. Our findings highlight the significant role of social influence, providing valuable insights into the process of evacuation decision-making. Our results demonstrate the applicability and effectiveness of data-driven BN modeling in evacuation decision making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10228v2</guid>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hui Sophie Wang, Nutchanon Yongsatianchot, Stacy Marsella</dc:creator>
    </item>
    <item>
      <title>A clustering approach for pairwise comparison matrices</title>
      <link>https://arxiv.org/abs/2402.06061</link>
      <description>arXiv:2402.06061v5 Announce Type: replace-cross 
Abstract: We consider clustering in group decision making where the opinions are given by pairwise comparison matrices. In particular, the k-medoids model is suggested to classify the matrices since it has a linear programming problem formulation that may contain any condition on the properties of the cluster centres. Its objective function depends on the measure of dissimilarity between the matrices but not on the weights derived from them. Our methodology provides a convenient tool for decision support, for instance, it can be used to quantify the reliability of the aggregation. The proposed theoretical framework is applied to a large-scale experimental dataset, on which it is able to automatically detect some mistakes made by the decision-makers, as well as to identify a common source of inconsistency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06061v5</guid>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kolos Csaba \'Agoston, S\'andor Boz\'oki, L\'aszl\'o Csat\'o</dc:creator>
    </item>
    <item>
      <title>Incorporating sparse labels into hidden Markov models using weighted likelihoods improves accuracy and interpretability in biologging studies</title>
      <link>https://arxiv.org/abs/2409.18091</link>
      <description>arXiv:2409.18091v2 Announce Type: replace-cross 
Abstract: Ecologists often use a hidden Markov model to decode a latent process, such as a sequence of an animal's behaviours, from an observed biologging time series. Modern technological devices such as video recorders and drones now allow researchers to directly observe an animal's behaviour. Using these observations as labels of the latent process can improve a hidden Markov model's accuracy when decoding the latent process. However, many wild animals are observed infrequently. Including such rare labels often has a negligible influence on parameter estimates, which in turn does not meaningfully improve the accuracy of the decoded latent process. We introduce a weighted likelihood approach that increases the relative influence of labelled observations. We use this approach to develop two hidden Markov models to decode the foraging behaviour of killer whales (Orcinus orca) off the coast of British Columbia, Canada. Using cross-validated evaluation metrics, we show that our weighted likelihood approach produces more accurate and understandable decoded latent processes compared to existing methods. Thus, our method effectively leverages sparse labels to enhance researchers' ability to accurately decode hidden processes across various fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18091v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evan Sidrow, Nancy Heckman, Tess M. McRae, Beth L. Volpov, Andrew W. Trites, Sarah M. E. Fortune, Marie Auger-M\'eth\'e</dc:creator>
    </item>
    <item>
      <title>Bayesian Event Categorization Matrix Approach for Nuclear Detonations</title>
      <link>https://arxiv.org/abs/2409.18227</link>
      <description>arXiv:2409.18227v2 Announce Type: replace-cross 
Abstract: Current efforts to detect nuclear detonations and correctly categorize explosion sources with ground- and space-collected discriminants presents challenges that remain unaddressed by the Event Categorization Matrix (ECM) model. Smaller events (lower yield explosions) often include only sparse observations among few modalities and can therefore lack a complete set of discriminants. The covariance structures can also vary significantly between such observations of event (source-type) categories. Both obstacles are problematic for ``classic'' ECM. Our work addresses this gap and presents a Bayesian update to the previous ECM model, termed B-ECM, which can be trained on partial observations and does not rely on a pooled covariance structure. We further augment ECM with Bayesian Decision Theory so that false negative or false positive rates of an event categorization can be reduced in an intuitive manner. To demonstrate improved categorization rates with B-ECM, we compare an array of B-ECM and classic ECM models with multiple performance metrics that leverage Monte Carlo experiments. We use both synthetic and real data. Our B-ECM models show consistent gains in overall accuracy and a lower false negative rates relative to the classic ECM model. We propose future avenues to improve B-ECM that expand its decision-making and predictive capability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18227v2</guid>
      <category>physics.geo-ph</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Scott Koermer, Joshua D. Carmichael, Brian J. Williams</dc:creator>
    </item>
  </channel>
</rss>
