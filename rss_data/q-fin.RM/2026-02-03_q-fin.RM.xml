<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.RM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.RM</link>
    <description>q-fin.RM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.RM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Feb 2026 05:02:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Rough Martingale Optimal Transport: Theory, Implementation, and Regulatory Applications for Non-Modelable Risk Factors</title>
      <link>https://arxiv.org/abs/2602.00097</link>
      <description>arXiv:2602.00097v1 Announce Type: new 
Abstract: The Fundamental Review of the Trading Book (FRTB) poses a significant challenge for exotic derivatives pricing, particularly for non-modelable risk factors (NMRF) where sparse market data leads to infinite audit bounds under classical Martingale Optimal Transport (MOT). We propose a unified Rough Martingale Optimal Transport (RMOT) framework that regularizes the transport plan with a rough volatility prior, yielding finite, explicit, and asymptotically tight extrapolation bounds. We establish an identifiability theorem for rough volatility parameters under sparse data, proving that 50 strikes are sufficient to estimate the Hurst exponent within $\pm 0.05$. For the multi-asset case, we prove that the correlation matrix is locally identifiable from marginal option surfaces provided the Hurst exponents are distinct. Model calibration on SPY and QQQ options (2019--2024) confirms that the optimal martingale measure exhibits stretched exponential tail decay ($\sim\exp(-k^{1-H})$), consistent with rough volatility asymptotics, whereas classical MOT yields trivial bounds. We validate the framework on live SPX/NDX data and scale it to $N = 30$ assets using a block-sparse optimization algorithm. Empirical results show that RMOT provides approximately \$880M in capital relief per \$1B exotic book compared to classical methods, while maintaining conservative coverage confirmed by 100-seed cross-validation. This constitutes a pricing framework designed to align with FRTB principles for NMRFs with explicit error quantification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00097v1</guid>
      <category>q-fin.RM</category>
      <category>math.PR</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sri Sairam Gautam B.,  Isha</dc:creator>
    </item>
    <item>
      <title>Non-standard analysis for coherent risk estimation: hyperfinite representations, discrete Kusuoka formulae, and plug-in asymptotics</title>
      <link>https://arxiv.org/abs/2602.00784</link>
      <description>arXiv:2602.00784v1 Announce Type: new 
Abstract: We develop a non-standard analysis framework for coherent risk measures and their finite-sample analogues, coherent risk estimators, building on recent work of Aichele, Cialenco, Jelito, and Pitera. Coherent risk measures on $L^\infty$ are realised as standard parts of internal support functionals on Loeb probability spaces, and coherent risk estimators arise as finite-grid restrictions.
  Our main results are: (i) a hyperfinite robust representation theorem that yields, as finite shadows, the robust representation results for coherent risk estimators; (ii) a discrete Kusuoka representation for law-invariant coherent risk estimators as suprema of mixtures of discrete expected shortfalls on $\{k/n:k=1,\ldots,n\}$; (iii) uniform almost sure consistency (with an explicit rate) for canonical spectral plug-in estimators over Lipschitz spectral classes; (iv) a Kusuoka-type plug-in consistency theorem under tightness and uniform estimation assumptions; (v) bootstrap validity for spectral plug-in estimators via an NSA reformulation of the functional delta method (under standard smoothness assumptions on $F_X$); and (vi) asymptotic normality obtained through a hyperfinite central limit theorem.
  The hyperfinite viewpoint provides a transparent probability-to-statistics dictionary: applying a risk measure to a law corresponds to evaluating an internal functional on a hyperfinite empirical measure and taking the standard part. We include a standardd self-contained introduction to the required non-standard tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00784v1</guid>
      <category>q-fin.RM</category>
      <category>math.LO</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>q-fin.MF</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomasz Kania</dc:creator>
    </item>
    <item>
      <title>A Methodology to Measure Impacts of Scenarios Through Expected Credit Losses</title>
      <link>https://arxiv.org/abs/2602.01361</link>
      <description>arXiv:2602.01361v1 Announce Type: new 
Abstract: In this paper, we present a methodology for measuring the impact of scenarios on the expected losses of exposures by leveraging the existing provisioning infrastructure within financial institutions, where scenario effects are captured through changes in probabilities of default. We then describe how to design and implement a scenario test where risk drivers are given for standardized groupings of exposures, and the groupings are defined based on common features of the exposures. The methodology presented served as a theoretical foundation for the standardized climate scenario exercise conducted in 2024 by the Office of the Superintendent of Financial Institutions of Canada and Quebec's Autorite des Marches Financiers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01361v1</guid>
      <category>q-fin.RM</category>
      <category>q-fin.GN</category>
      <category>q-fin.MF</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahmood Alaghmandan, Meghal Arora, Olga Streltchenko</dc:creator>
    </item>
    <item>
      <title>Reliable Real-Time Value at Risk Estimation via Quantile Regression Forest with Conformal Calibration</title>
      <link>https://arxiv.org/abs/2602.01912</link>
      <description>arXiv:2602.01912v1 Announce Type: cross 
Abstract: Rapidly evolving market conditions call for real-time risk monitoring, but its online estimation remains challenging. In this paper, we study the online estimation of one of the most widely used risk measures, Value at Risk (VaR). Its accurate and reliable estimation is essential for timely risk control and informed decision-making. We propose to use the quantile regression forest in the offline-simulation-online-estimation (OSOA) framework. Specifically, the quantile regression forest is trained offline to learn the relationship between the online VaR and risk factors, and real-time VaR estimates are then produced online by incorporating observed risk factors. To further ensure reliability, we develop a conformalized estimator that calibrates the online VaR estimates. To the best of our knowledge, we are the first to leverage conformal calibration to estimate real-time VaR reliably based on the OSOA formulation. Theoretical analysis establishes the consistency and coverage validity of the proposed estimators. Numerical experiments confirm the proposed method and demonstrate its effectiveness in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01912v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Du-Yi Wang, Guo Liang, Kun Zhang, Qianwen Zhu</dc:creator>
    </item>
    <item>
      <title>Tail Structure and the Ordering of the Standard Deviation and Gini Mean Difference</title>
      <link>https://arxiv.org/abs/2601.12414</link>
      <description>arXiv:2601.12414v2 Announce Type: replace 
Abstract: We investigate the ordering between two fundamental measures of dispersion for real-valued risks: the standard deviation (SD) and the Gini mean difference (GMD). Our analysis is driven by a single structural object, namely the mean excess function of the pairwise difference $|X - X'|$. We show that its monotonicity is determined by the tail behavior of the underlying distribution, giving rise to two distinct dispersion regimes. In a heavy-tailed regime, characterized by decreasing hazard rates or increasing reverse hazard rates, the SD dominates the GMD. Conversely, when both tails of the distribution are light, the GMD dominates the SD. These dominance regimes are shown to be stable under truncation, convolution, and mixtures. Discrete analogues of the main results are also developed. Overall, the results provide an intuitive interpretation of the dispersion ordering phenomena that goes beyond the existing general comparisons, with direct relevance for risk modeling and actuarial applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.12414v2</guid>
      <category>q-fin.RM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nawaf Mohammed</dc:creator>
    </item>
    <item>
      <title>On a risk model with tree-structured Poisson Markov random field frequency, with application to rainfall events</title>
      <link>https://arxiv.org/abs/2412.00607</link>
      <description>arXiv:2412.00607v3 Announce Type: replace-cross 
Abstract: In many insurance contexts, dependence between risks of a portfolio may arise from their frequencies. We investigate a dependent risk model in which we assume the vector of count variables to be a tree-structured Markov random field with Poisson marginals. The tree structure translates into a wide variety of dependence schemes. We study the global risk of the portfolio and the risk allocation to all its constituents. We provide asymptotic results for portfolios defined on infinitely growing trees. To illustrate its flexibility and computational scalability to higher dimensions, we calibrate the risk model on real-world extreme rainfall data and perform a risk analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00607v3</guid>
      <category>stat.ME</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H\'el\`ene Cossette, Benjamin C\^ot\'e, Alexandre Dubeau, Etienne Marceau</dc:creator>
    </item>
  </channel>
</rss>
