<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Mar 2025 02:15:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the Approximability of Unsplittable Flow on a Path with Time Windows</title>
      <link>https://arxiv.org/abs/2503.17802</link>
      <description>arXiv:2503.17802v1 Announce Type: new 
Abstract: In the Time-Windows Unsplittable Flow on a Path problem (twUFP) we are given a resource whose available amount changes over a given time interval (modeled as the edge-capacities of a given path $G$) and a collection of tasks. Each task is characterized by a demand (of the considered resource), a profit, an integral processing time, and a time window. Our goal is to compute a maximum profit subset of tasks and schedule them non-preemptively within their respective time windows, such that the total demand of the tasks using each edge $e$ is at most the capacity of $e$.
  We prove that twUFP is $\mathsf{APX}$-hard which contrasts the setting of the problem without time windows, i.e., Unsplittable Flow on a Path (UFP), for which a PTAS was recently discovered [Grandoni, M\"omke, Wiese, STOC 2022]. Then, we present a quasi-polynomial-time $2+\varepsilon$ approximation for twUFP under resource augmentation. Our approximation ratio improves to $1+\varepsilon$ if all tasks' time windows are identical. Our $\mathsf{APX}$-hardness holds also for this special case and, hence, rules out such a PTAS (and even a QPTAS, unless $\mathsf{NP}\subseteq\mathrm{DTIME}(n^{\mathrm{poly}(\log n)})$) without resource augmentation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17802v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Armbruster (Technical University of Munich), Fabrizio Grandoni (USI-SUPSI, IDSIA), Edin Husi\'c (USI-SUPSI, IDSIA), Antoine Tinguely (USI-SUPSI, IDSIA), Andreas Wiese (Technical University of Munich)</dc:creator>
    </item>
    <item>
      <title>Approximation Schemes for k-Subset Sum Ratio and Multiway Number Partitioning Ratio</title>
      <link>https://arxiv.org/abs/2503.18241</link>
      <description>arXiv:2503.18241v1 Announce Type: new 
Abstract: The Subset Sum Ratio problem (SSR) asks, given a multiset $A$ of positive integers, to find two disjoint subsets of $A$ such that the largest-to-smallest ratio of their sums is minimized. In this paper, we study the $k$-version of SSR, namely $k$-Subset Sum Ratio ($k$-SSR), which asks to minimize the largest-to-smallest ratio of sums of $k$ disjoint subsets of $A$. We develop an approximation scheme for $k$-SSR running in $O({n^{2k}}/{\varepsilon^{k-1}})$ time, where $n=|A|$ and $\varepsilon$ is the error parameter. To the best of our knowledge, this is the first FPTAS for $k$-SSR for fixed $k&gt;2$.
  We also present an FPTAS for the $k$-way Number Partitioning Ratio ($k$-PART) problem, which differs from $k$-SSR in that the $k$ subsets must constitute a partition of $A$. We present a more involved FPTAS for $k$-PART, also achieving $O({n^{2k}}/{\varepsilon^{k-1}})$ time complexity. Notably, $k$-PART is equivalent to the minimum envy-ratio problem with identical valuation functions, which has been studied in the context of fair division of indivisible goods. When restricted to the case of identical valuations, our FPTAS represents a significant improvement over Nguyen and Rothe's FPTAS for minimum envy-ratio, which runs in $O(n^{4k^2+1}/\varepsilon^{2k^2})$ time for all additive valuations.
  Lastly, we propose a second FPTAS for $k$-SSR, which employs carefully designed calls to the first one; the new scheme has a time complexity of $\widetilde{O}(n/{\varepsilon^{3k-1}})$, thus being much faster than the first one when $n\gg 1/ \varepsilon$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18241v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sotiris Kanellopoulos, Giorgos Mitropoulos, Antonis Antonopoulos, Nikos Leonardos, Aris Pagourtzis, Christos Pergaminelis, Stavros Petsalakis, Kanellos Tsitouras</dc:creator>
    </item>
    <item>
      <title>{\epsilon}-Cost Sharding: Scaling Hypergraph-Based Static Functions and Filters to Trillions of Keys</title>
      <link>https://arxiv.org/abs/2503.18397</link>
      <description>arXiv:2503.18397v1 Announce Type: new 
Abstract: We describe a simple and yet very scalable implementation of static functions (VFunc) and of static filters (VFilter) based on hypergraphs. We introduce the idea of {\epsilon}-cost sharding, which allows us to build structures that can manage trillions of keys, at the same time increasing memory locality in hypergraph-based constructions. Contrarily to the commonly used HEM sharding method, {\epsilon}-cost sharding does not require to store of additional information, and does not introduce dependencies in the computation chain; its only cost is that of few arithmetical instructions, and of a relative increase {\epsilon} in space usage. We apply {\epsilon}-cost sharding to the classical MWHC construction, but we obtain the best result by combining Dietzfelbinger and Walzer's fuse graphs for large shards with lazy Gaussian elimination for small shards. We obtain large structures with an overhead of 10.5% with respect to the information-theoretical lower bound and with a query time that is a few nanoseconds away from the query time of the non-sharded version, which is the fastest currently available within the same space bounds. Besides comparing our structures with a non-sharded version, we contrast its tradeoffs with bumped ribbon constructions, a space-saving alternative to hypergraph-based static functions and filters, which provide optimum space consumption but slow construction and query time (though construction can be parallelized very efficiently). We build offline a trillion-key filter using commodity hardware in just 60 ns/key.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18397v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastiano Vigna</dc:creator>
    </item>
    <item>
      <title>Faster Construction of a Planar Distance Oracle with \~{O}(1) Query Time</title>
      <link>https://arxiv.org/abs/2503.18425</link>
      <description>arXiv:2503.18425v1 Announce Type: new 
Abstract: We show how to preprocess a weighted undirected $n$-vertex planar graph in $\tilde O(n^{4/3})$ time, such that the distance between any pair of vertices can then be reported in $\tilde O(1)$ time. This improves the previous $\tilde O(n^{3/2})$ preprocessing time [JACM'23].
  Our main technical contribution is a near optimal construction of \emph{additively weighted Voronoi diagrams} in undirected planar graphs. Namely, given a planar graph $G$ and a face $f$, we show that one can preprocess $G$ in $\tilde O(n)$ time such that given any weight assignment to the vertices of $f$ one can construct the additively weighted Voronoi diagram of $f$ in near optimal $\tilde O(|f|)$ time. This improves the $\tilde O(\sqrt{n |f|})$ construction time of [JACM'23].</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18425v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Itai Boneh, Shay Golan, Shay Mozes, Daniel Prigan, Oren Weimann</dc:creator>
    </item>
    <item>
      <title>\~Optimal Fault-Tolerant Labeling for Reachability and Approximate Distances in Directed Planar Graphs</title>
      <link>https://arxiv.org/abs/2503.18474</link>
      <description>arXiv:2503.18474v1 Announce Type: new 
Abstract: We present a labeling scheme that assigns labels of size $\tilde O(1)$ to the vertices of a directed weighted planar graph $G$, such that for any fixed $\varepsilon&gt;0$ from the labels of any three vertices $s$, $t$ and $f$ one can determine in $\tilde O(1)$ time a $(1+\varepsilon)$-approximation of the $s$-to-$t$ distance in the graph $G\setminus\{f\}$. For approximate distance queries, prior to our work, no efficient solution existed, not even in the centralized oracle setting. Even for the easier case of reachability, $\tilde O(1)$ queries were known only with a centralized oracle of size $\tilde O(n)$ [SODA 21].</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18474v1</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Itai Boneh, Shiri Chechik, Shay Golan, Shay Mozes, Oren Weimann</dc:creator>
    </item>
    <item>
      <title>Duality between Lines and Points</title>
      <link>https://arxiv.org/abs/2503.17372</link>
      <description>arXiv:2503.17372v1 Announce Type: cross 
Abstract: There are several notions of duality between lines and points. In this note, it is shown that all these can be studied in a unified way. Most interesting properties are independent of specific choices.
  It is also shown that either dual mapping can be its own inverse or it can preserve relative order (but not both).
  Generalisation to higher dimensions is also discussed. An elementary and very intuitive treatment of relationship between arrangements in $d+1$ dimensions and searching for $k$-nearest neighbour in $d$-dimensions is also given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17372v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanjeev Saxena</dc:creator>
    </item>
    <item>
      <title>The Entropy and Crossentropy of Generalized Mallows Models</title>
      <link>https://arxiv.org/abs/2503.17521</link>
      <description>arXiv:2503.17521v1 Announce Type: cross 
Abstract: The Generalized Mallows Model (GMM) is a well known family of models for ranking data. A GMM is a distribution over $\mathbb{S}_n$, the set of permutations of n objects, characterized by a location parameter $\sigma \in \mathbb{S}_n$, known as central permutation and a set of dispersion parameters $\theta_{1:n-1}\in(0,1]$. The GMM shares many properties, such as having sufficient statistics, with exponential models, thus it can be seen as an exponential family with a discrete parameter $\sigma$. This paper shows that computing entropy, crossentropy and Kullback-Leibler divergence in the the class of GMM is tractable, paving the way for a better understanding of this exponential family.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17521v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marina Meil\u{a}</dc:creator>
    </item>
    <item>
      <title>A Graph-based Approach to Variant Extraction</title>
      <link>https://arxiv.org/abs/2503.18472</link>
      <description>arXiv:2503.18472v1 Announce Type: cross 
Abstract: Accurate variant descriptions are of paramount importance in the field of genetics. The domain is confronted with increasingly complex variants, making it more challenging to generate proper variant descriptions. We present a graph based on all minimal alignments that is a complete representation of a variant and we provide three complementary extraction methods to derive variant descriptions from this graph. Our experiments show that our method in comparison with dbSNP results in identical HGVS descriptions for simple variants and more meaningful descriptions for complex variants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18472v1</guid>
      <category>q-bio.GN</category>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark A. Santcroos, Walter A. Kosters, Mihai Lefter, Jeroen F. J. Laros, Jonathan K. Vis</dc:creator>
    </item>
    <item>
      <title>The Power of Recursive Embeddings for $\ell_p$ Metrics</title>
      <link>https://arxiv.org/abs/2503.18508</link>
      <description>arXiv:2503.18508v1 Announce Type: cross 
Abstract: Metric embedding is a powerful mathematical tool that is extensively used in mathematics and computer science. We devise a new method of using metric embeddings recursively that turned out to be particularly effective for $\ell_p$ spaces, $p&gt;2$. Our method yields state-of-the-art results for Lipschitz decomposition, nearest neighbor search and embedding into $\ell_2$. In a nutshell, we compose metric embeddings by way of reductions, leading to new reductions that are substantially more effective than the straightforward reduction that employs a single embedding. In fact, we compose reductions recursively, oftentimes using double recursion, which exemplifies this gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18508v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <category>math.MG</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Krauthgamer, Nir Petruschka, Shay Sapir</dc:creator>
    </item>
    <item>
      <title>$k$-Universality of Regular Languages Revisited</title>
      <link>https://arxiv.org/abs/2503.18611</link>
      <description>arXiv:2503.18611v1 Announce Type: cross 
Abstract: A subsequence of a word $w$ is a word $u$ such that $u = w[i_1] w[i_2] \cdots w[i_k]$, for some set of indices $1 \leq i_1 &lt; i_2 &lt; \dots &lt; i_k \leq \vert w \vert$. A word $w$ is \emph{$k$-subsequence universal} over an alphabet $\Sigma$ if every word over $\Sigma$ up to length $k$ appears in $w$ as a subsequence. In this paper, we revisit the problem $k$-ESU of deciding, for a given integer $k$, whether a regular language, given either as nondeterministic finite automaton or as a regular expression, contains a $k$-universal word. [Adamson et al., ISAAC 2023] showed that this problem is NP-hard, even in the case when $k=1$, and an FPT algorithm w.r.t. the size of the input alphabet was given. In this paper, we improve the aforementioned algorithmic result and complete the analysis of this problem w.r.t. other parameters. That is, we propose a more efficient FPT algorithm for $k$-ESU, with respect to the size of the input alphabet, and propose new FPT algorithms for this problem w.r.t.~the number of states of the input automaton and the length of the input regular expression. We also discuss corresponding lower bounds. Our results significantly improve the understanding of this problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18611v1</guid>
      <category>cs.FL</category>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Duncan Adamson, Pamela Fleischmann, Annika Huch, Tore Ko{\ss}, Florin Manea</dc:creator>
    </item>
    <item>
      <title>A Global Analysis of the Primal-Dual Method for Pliable Families</title>
      <link>https://arxiv.org/abs/2308.15714</link>
      <description>arXiv:2308.15714v3 Announce Type: replace 
Abstract: We study a core algorithmic problem in network design called F-augmentation that involves increasing the connectivity of a given family of cuts F. Over 30 years ago, Williamson et al. (STOC `93) provided a 2-approximation primal-dual algorithm when F is a so-called uncrossable family but extending their results to families that are non-uncrossable has remained a challenging question.
  In this paper, we introduce the novel concept of the crossing density of a set family and show how this opens up a completely new approach to analyzing primal-dual algorithms. We study pliable families, a strict generalization of uncrossable families introduced by Bansal et al. (ICALP `23), and provide the first approximation algorithm for F-augmentation of general pliable families.
  We also improve on the results in Bansal et al. (ICALP `23) by providing a 5-approximation algorithm for the F-augmentation problem when F is a family of near min-cuts using the concept of crossing densities. This immediately improves approximation factors for the Capacitated Network Design Problem.
  Finally, we study the $(p,3)$-flexible graph connectivity problem. By carefully analyzing the structure of feasible solutions and using the techniques developed in this paper, we provide the first constant factor approximation algorithm for this problem exhibiting an 11-approximation algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15714v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ishan Bansal</dc:creator>
    </item>
    <item>
      <title>Using Single-Neuron Representations for Hierarchical Concepts as Abstractions of Multi-Neuron Representations</title>
      <link>https://arxiv.org/abs/2406.07297</link>
      <description>arXiv:2406.07297v2 Announce Type: replace 
Abstract: Brain networks exhibit complications such as noise, neuron failures, and partial synaptic connectivity. These can make it difficult to model and analyze their behavior. This paper describes a way to address this difficulty, namely, breaking down the models and analysis using levels of abstraction. We describe the approach for the problem of recognizing hierarchically-structured concepts.
  Realistic models for representing hierarchical concepts use multiple neurons to represent each concept [10,1,7,3]. These models are intended to capture some behaviors of actual brains; however, their analysis can be complicated. Mechanisms based on single-neuron representations can be easier to understand and analyze [2,4], but are less realistic. Here we show that these two types of models are compatible, and in fact, networks with single-neuron representations can be regarded as formal abstractions of networks with multi-neuron representations. We do this by relating networks with multi-neuron representations like those in [3] to networks with single-neuron representations like those in [2].
  Specifically, we consider two networks, H and L, with multi-neuron representations, one with high connectivity and one with low connectivity. We define two abstract networks, A1 and A2, with single-neuron representations, and prove that they recognize concepts correctly. Then we prove correctness of H and L by relating them to A1 and A2. In this way, we decompose the analysis of each multi-neuron network into two parts: analysis of abstract, single-neuron networks, and proofs of formal relationships between the multi-neuron network and single-neuron networks. These examples illustrate what we consider to be a promising, tractable approach to analyzing other complex brain mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07297v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nancy Lynch</dc:creator>
    </item>
    <item>
      <title>Scalable Neighborhood Local Search for Single-Machine Scheduling with Family Setup Times</title>
      <link>https://arxiv.org/abs/2409.00771</link>
      <description>arXiv:2409.00771v3 Announce Type: replace 
Abstract: In this work, we study the task of scheduling jobs on a single machine with sequence dependent family setup times under the goal of minimizing the makespan, that is, the completion time of the last job in the schedule. This notoriously NP-hard problem is highly relevant in practical productions and requires heuristics that provide good solutions quickly in order to deal with large instances. In this paper, we present a heuristic based on the approach of parameterized local search. That is, we aim to replace a given solution by a better solution having distance at most $k$ in a pre-defined distance measure. This is done multiple times in a hill-climbing manner, until a locally optimal solution is reached. We analyze the trade-off between the allowed distance $k$ and the algorithm's running time for four natural distance measures. Example of allowed operations for our considered distance measures are: swapping $k$ pairs of jobs in the sequence, or rearranging $k$ consecutive jobs. For two distance measures, we show that finding an improvement for given $k$ can be done in $f(k) \cdot n^{\mathcal{O}(1)}$ time, while such a running time for the other two distance measures is unlikely. We provide a preliminary experimental evaluation of our local search approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00771v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaja Balzereit, Niels Gr\"uttemeier, Nils Morawietz, Dennis Reinhardt, Stefan Windmann, Petra Wolf</dc:creator>
    </item>
    <item>
      <title>Differentially Private Kernel Density Estimation</title>
      <link>https://arxiv.org/abs/2409.01688</link>
      <description>arXiv:2409.01688v3 Announce Type: replace 
Abstract: We introduce a refined differentially private (DP) data structure for kernel density estimation (KDE), offering not only improved privacy-utility tradeoff but also better efficiency over prior results. Specifically, we study the mathematical problem: given a similarity function $f$ (or DP KDE) and a private dataset $X \subset \mathbb{R}^d$, our goal is to preprocess $X$ so that for any query $y\in\mathbb{R}^d$, we approximate $\sum_{x \in X} f(x, y)$ in a differentially private fashion. The best previous algorithm for $f(x,y) =\| x - y \|_1$ is the node-contaminated balanced binary tree by [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR 2024]. Their algorithm requires $O(nd)$ space and time for preprocessing with $n=|X|$. For any query point, the query time is $d \log n$, with an error guarantee of $(1+\alpha)$-approximation and $\epsilon^{-1} \alpha^{-0.5} d^{1.5} R \log^{1.5} n$.
  In this paper, we improve the best previous result [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR 2024] in three aspects:
  - We reduce query time by a factor of $\alpha^{-1} \log n$.
  - We improve the approximation ratio from $\alpha$ to 1.
  - We reduce the error dependence by a factor of $\alpha^{-0.5}$.
  From a technical perspective, our method of constructing the search tree differs from previous work [Backurs, Lin, Mahabadi, Silwal, and Tarnawski, ICLR 2024]. In prior work, for each query, the answer is split into $\alpha^{-1} \log n$ numbers, each derived from the summation of $\log n$ values in interval tree countings. In contrast, we construct the tree differently, splitting the answer into $\log n$ numbers, where each is a smart combination of two distance values, two counting values, and $y$ itself. We believe our tree structure may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01688v3</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Erzhi Liu, Jerry Yao-Chieh Hu, Alex Reneau, Zhao Song, Han Liu</dc:creator>
    </item>
    <item>
      <title>Parallel $k$-Core Decomposition: Theory and Practice</title>
      <link>https://arxiv.org/abs/2502.08042</link>
      <description>arXiv:2502.08042v2 Announce Type: replace 
Abstract: This paper proposes efficient solutions for $k$-core decomposition with high parallelism. The problem of $k$-core decomposition is fundamental in graph analysis and has applications across various domains. However, existing algorithms face significant challenges in achieving work-efficiency in theory and/or high parallelism in practice, and suffer from various performance bottlenecks.
  We present a simple, work-efficient parallel framework for $k$-core decomposition that is easy to implement and adaptable to various strategies for improving work-efficiency. We introduce two techniques to enhance parallelism: a sampling scheme to reduce contention on high-degree vertices, and vertical granularity control (VGC) to mitigate scheduling overhead for low-degree vertices. Furthermore, we design a hierarchical bucket structure to optimize performance for graphs with high coreness values.
  We evaluate our algorithm on a diverse set of real-world and synthetic graphs. Compared to state-of-the-art parallel algorithms, including ParK, PKC, and Julienne, our approach demonstrates superior performance on 23 out of 25 graphs when tested on a 96-core machine. Our algorithm shows speedups of up to 315$\times$ over ParK, 33.4$\times$ over PKC, and 52.5$\times$ over Julienne.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08042v2</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youzhe Liu, Xiaojun Dong, Yan Gu, Yihan Sun</dc:creator>
    </item>
    <item>
      <title>Optimal mass estimation in the conditional sampling model</title>
      <link>https://arxiv.org/abs/2503.12518</link>
      <description>arXiv:2503.12518v2 Announce Type: replace 
Abstract: The conditional sampling model, introduced by Cannone, Ron and Servedio (SODA 2014, SIAM J. Comput. 2015) and independently by Chakraborty, Fischer, Goldhirsh and Matsliah (ITCS 2013, SIAM J. Comput. 2016), is a common framework for a number of studies concerning strengthened models of distribution testing. A core task in these investigations is that of estimating the mass of individual elements. The above mentioned works, and the improvement of Kumar, Meel and Pote (AISTATS 2025), provided polylogarithmic algorithms for this task.
  In this work we shatter the polylogarithmic barrier, and provide an estimator for the mass of individual elements that uses only $O(\log \log N) + O(\mathrm{poly}(1/\varepsilon))$ conditional samples. We complement this result with an $\Omega(\log\log N)$ lower bound.
  We then show that our mass estimator provides an improvement (and in some cases a unifying framework) for a number of related tasks, such as testing by learning of any label-invariant property, and distance estimation between two (unknown) distribution. By considering some known lower bounds, this also shows that the full power of the conditional model is indeed required for the doubly-logarithmic upper bound.
  Finally, we exponentially improve the previous lower bound on testing by learning of label-invariant properties from double-logarithmic to $\Omega(\log N)$ conditional samples, whereas our testing by learning algorithm provides an upper bound of $O(\mathrm{poly}(1/\varepsilon)\cdot\log N \log \log N)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12518v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomer Adar, Eldar Fischer, Amit Levi</dc:creator>
    </item>
    <item>
      <title>A Tail Estimate with Exponential Decay for the Randomized Incremental Construction of Search Structures</title>
      <link>https://arxiv.org/abs/2101.04914</link>
      <description>arXiv:2101.04914v4 Announce Type: replace-cross 
Abstract: The Randomized Incremental Construction (RIC) of search DAGs for point location in planar subdivisions, nearest-neighbor search in 2D points, and extreme point search in 3D convex hulls, are well known to take ${\cal O}(n \log n)$ expected time for structures of ${\cal O}(n)$ expected size. Moreover, searching takes w.h.p. ${\cal O}(\log n)$ comparisons in the first and w.h.p. ${\cal O}(\log^2 n)$ comparisons in the latter two DAGs. However, the expected depth of the DAGs and high probability bounds for their size are unknown.
  Using a novel analysis technique, we show that the three DAGs have w.h.p. i) a size of ${\cal O}(n)$, ii) a depth of ${\cal O}(\log n)$, and iii) a construction time of ${\cal O}(n \log n)$. One application of these new and improved results are \emph{remarkably simple} Las Vegas verifiers to obtain search DAGs with optimal worst-case bounds. This positively answers the conjectured logarithmic search cost in the DAG of Delaunay triangulations [Guibas et al.; ICALP 1990] and a conjecture on the depth of the DAG of Trapezoidal subdivisions [Hemmer et al.; ESA 2012].</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.04914v4</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joachim Gudmundsson, Martin P. Seybold</dc:creator>
    </item>
    <item>
      <title>Multi-Neuron Representations of Hierarchical Concepts in Spiking Neural Networks</title>
      <link>https://arxiv.org/abs/2401.04628</link>
      <description>arXiv:2401.04628v3 Announce Type: replace-cross 
Abstract: We describe how hierarchical concepts can be represented in three types of layered neural networks. The aim is to support recognition of the concepts when partial information about the concepts is presented, and also when some of the neurons in the network might fail. Our failure model involves initial random failures. The three types of networks are: feed-forward networks with high connectivity, feed-forward networks with low connectivity, and layered networks with low connectivity and with both forward edges and "lateral" edges within layers. In order to achieve fault-tolerance, the representations all use multiple representative neurons for each concept. We show how recognition can work in all three of these settings, and quantify how the probability of correct recognition depends on several parameters, including the number of representatives and the neuron failure probability. We also discuss how these representations might be learned, in all three types of networks. For the feed-forward networks, the learning algorithms are similar to ones used in [4], whereas for networks with lateral edges, the algorithms are generally inspired by work on the assembly calculus [3, 6, 7].</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04628v3</guid>
      <category>cs.NE</category>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nancy A. Lynch</dc:creator>
    </item>
    <item>
      <title>Efficient Top-k s-Biplexes Search over Large Bipartite Graphs</title>
      <link>https://arxiv.org/abs/2409.18473</link>
      <description>arXiv:2409.18473v2 Announce Type: replace-cross 
Abstract: In a bipartite graph, a subgraph is an $s$-biplex if each vertex of the subgraph is adjacent to all but at most $s$ vertices on the opposite set. The enumeration of $s$-biplexes from a given graph is a fundamental problem in bipartite graph analysis. However, in real-world data engineering, finding all $s$-biplexes is neither necessary nor computationally affordable. A more realistic problem is to identify some of the largest $s$-biplexes from the large input graph. We formulate the problem as the {\em top-$k$ $s$-biplex search (TBS) problem}, which aims to find the top-$k$ maximal $s$-biplexes with the most vertices, where $k$ is an input parameter. We prove that the TBS problem is NP-hard for any fixed $k\ge 1$. Then, we propose a branching algorithm, named MVBP, that breaks the simple $2^n$ enumeration algorithm. Furthermore, from a practical perspective, we investigate three techniques to improve the performance of MVBP: 2-hop decomposition, single-side bounds, and progressive search. Complexity analysis shows that the improved algorithm, named FastMVBP, has a running time $O^*(\gamma_s^{d_2})$, where $\gamma_s&lt;2$, and $d_2$ is a parameter much smaller than the number of vertex in the sparse real-world graphs, e.g. $d_2$ is only $67$ in the AmazonRatings dataset which has more than $3$ million vertices. Finally, we conducted extensive experiments on eight real-world and synthetic datasets to demonstrate the empirical efficiency of the proposed algorithms. In particular, FastMVBP outperforms the benchmark algorithms by up to three orders of magnitude in several instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18473v2</guid>
      <category>cs.IR</category>
      <category>cs.DS</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenxiang Xu, Yiping Liu, Yi Zhou, Yimin Hao, Zhengren Wang</dc:creator>
    </item>
  </channel>
</rss>
