<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Oct 2025 04:01:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A decoupled Crank-Nicolson leap-frog scheme for the unsteady bioconvection flows problem with concentration dependent viscosity</title>
      <link>https://arxiv.org/abs/2510.14034</link>
      <description>arXiv:2510.14034v1 Announce Type: new 
Abstract: A fully discrete Crank--Nicolson Leap--Frog (CNLF) scheme is proposed and analyzed for the unsteady bioconvection flow problem with concentration-dependent viscosity. Spatial discretization is handled via the Galerkin finite element method (FEM), while temporal discretization employs the CNLF method for the linear terms and a semi-implicit approach for the nonlinear terms. The scheme is proven to be unconditionally stable, i.e., the time step is not subject to a restrictive upper bound. Using the energy method, $L^2$-optimal error estimates are derived for the velocity and concentration . Finally, numerical experiments are presented to validate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14034v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenyang Li</dc:creator>
    </item>
    <item>
      <title>Geometric local parameterization for solving Hele-Shaw problems with surface tension</title>
      <link>https://arxiv.org/abs/2510.14088</link>
      <description>arXiv:2510.14088v1 Announce Type: new 
Abstract: In this work, we introduce a novel computational framework for solving the two-dimensional Hele-Shaw free boundary problem with surface tension. The moving boundary is represented by point clouds, eliminating the need for a global parameterization. Our approach leverages Generalized Moving Least Squares (GMLS) to construct local geometric charts, enabling high-order approximations of geometric quantities such as curvature directly from the point cloud data. This local parameterization is systematically employed to discretize the governing boundary integral equation, including an analytical formula of the singular integrals. We provide a rigorous convergence analysis for the proposed spatial discretization, establishing consistency and stability under certain conditions. The resulting error bound is derived in terms of the size of the uniformly sampled point cloud data on the moving boundary, the smoothness of the boundary, and the order of the numerical quadrature rule. Numerical experiments confirm the theoretical findings, demonstrating high-order spatial convergence and the expected temporal convergence rates. The method's effectiveness is further illustrated through simulations of complex initial shapes, which correctly evolve towards circular equilibrium states under the influence of surface tension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14088v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zengyan Zhang, Wenrui Hao, John Harlim</dc:creator>
    </item>
    <item>
      <title>A Stochastic Algorithm for Searching Saddle Points with Convergence Guarantee</title>
      <link>https://arxiv.org/abs/2510.14144</link>
      <description>arXiv:2510.14144v1 Announce Type: new 
Abstract: Saddle points provide a hierarchical view of the energy landscape, revealing transition pathways and interconnected basins of attraction, and offering insight into the global structure, metastability, and possible collective mechanisms of the underlying system. In this work, we propose a stochastic saddle-search algorithm to circumvent exact derivative and Hessian evaluations that have been used in implementing traditional and deterministic saddle dynamics. At each iteration, the algorithm uses a stochastic eigenvector-search method, based on a stochastic Hessian, to approximate the unstable directions, followed by a stochastic gradient update with reflections in the approximate unstable direction to advance toward the saddle point. We carry out rigorous numerical analysis to establish the almost sure convergence for the stochastic eigenvector search and local almost sure convergence with an $O(1/n)$ rate for the saddle search, and present a theoretical guarantee to ensure the high-probability identification of the saddle point when the initial point is sufficiently close. Numerical experiments, including the application to a neural network loss landscape and a Landau-de Gennes type model for nematic liquid crystal, demonstrate the practical applicability and the ability for escaping from "bad" areas of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14144v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baoming Shi, Lei Zhang, Qiang Du</dc:creator>
    </item>
    <item>
      <title>Superconvergent and Divergence-Free Finite Element Methods for Stokes Equation</title>
      <link>https://arxiv.org/abs/2510.14192</link>
      <description>arXiv:2510.14192v1 Announce Type: new 
Abstract: Superconvergent and divergence-free finite element methods for the Stokes equation are developed. The velocity and pressure are discretized using $H(\mathrm{div})$-conforming vector elements and discontinuous piecewise polynomials. The discrete formulation employs a weak deviatoric gradient operator built with tangential-normal continuous finite elements for traceless tensors, requiring no stabilization. Optimal and superconvergent error estimates are established. The method connects to nonconforming virtual element and pseudostress-velocity-pressure mixed formulations. Numerical experiments verify the theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14192v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Long Chen, Xuehai Huang, Chao Zhang, Xinyue Zhao</dc:creator>
    </item>
    <item>
      <title>Neural Networks for Bayesian Inverse Problems Governed by a Nonlinear ODE</title>
      <link>https://arxiv.org/abs/2510.14197</link>
      <description>arXiv:2510.14197v1 Announce Type: new 
Abstract: We investigate the use of neural networks (NNs) for the estimation of hidden model parameters and uncertainty quantification from noisy observational data for inverse parameter estimation problems. We formulate the parameter estimation as a Bayesian inverse problem. We consider a parametrized system of nonlinear ordinary differential equations (ODEs), which is the FitzHugh--Nagumo model. The considered problem exhibits significant mathematical and computational challenges for classical parameter estimation methods, including strong nonlinearities, nonconvexity, and sharp gradients. We explore how NNs overcome these challenges by approximating reconstruction maps for parameter estimation from observational data. The considered data are time series of the spiking membrane potential of a biological neuron. We infer parameters controlling the dynamics of the model, noise parameters of autocorrelated additive noise, and noise modeled via stochastic differential equations, as well as the covariance matrix of the posterior distribution to expose parameter uncertainties--all with just one forward evaluation of an appropriate NN. We report results for different NN architectures and study the influence of noise on prediction accuracy. We also report timing results for training NNs on dedicated hardware. Our results demonstrate that NNs are a versatile tool to estimate parameters of the dynamical system, stochastic processes, as well as uncertainties, as they propagate through the governing ODE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14197v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>German Villalobos, Johann Rudi, Andreas Mang</dc:creator>
    </item>
    <item>
      <title>High-Order Meshfree Surface Integration, Including Singular Integrands</title>
      <link>https://arxiv.org/abs/2510.14236</link>
      <description>arXiv:2510.14236v1 Announce Type: new 
Abstract: We develop and test high-order methods for integration on surface point clouds. The task of integrating a function on a surface arises in a range of applications in engineering and the sciences, particularly those involving various integral methods for partial differential equations. Mesh-based methods require a curved mesh for high-order convergence, which can be difficult to reliably obtain on many surfaces, and most meshfree methods require the ability to integrate a set of functions (such as radial basis functions) exactly on the domain of interest; these integrals are generally not known in closed form on most surfaces. We describe two methods for integrating on arbitrary, piecewise-smooth surfaces with or without boundary. Our approaches do not require a particular arrangement of points or an initial triangulation of the surface, making them completely meshfree. We also show how the methods can be extended to handle singular integrals while maintaining high accuracy without changing the point density near singularities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14236v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel R. Venn, Steven J. Ruuth</dc:creator>
    </item>
    <item>
      <title>A DeepLagrangian method for learning and generating aggregation patterns in multi-dimensional Keller-Segel chemotaxis systems</title>
      <link>https://arxiv.org/abs/2510.14297</link>
      <description>arXiv:2510.14297v1 Announce Type: new 
Abstract: The Keller-Segel (KS) chemotaxis system is used to describe the overall behavior of a collection of cells under the influence of chemotaxis. However, solving the KS chemotaxis system and generating its aggregation patterns remain challenging due to the emergence of solutions exhibiting near-singular behavior, such as finite-time blow-up or concentration phenomena. Building on a Lagrangian framework of the KS system, we develop DeepLagrangian, a self-adaptive density estimation method that learns and generates aggregation patterns and near-singular solutions of the KS system in two- and three-dimensional (2D and 3D) space under different physical parameters. The main advantage of the Lagrangian framework is its inherent ability to adapt to near-singular solutions. To develop this framework, we normalize the KS solution into a probability density function (PDF), derive the corresponding normalized KS system, and utilize the property of the continuity equation to rewrite the system into a Lagrangian framework. We then define a physics-informed Lagrangian loss to enforce this framework and incorporate a flow-based generative model, called the time-dependent KRnet, to approximate the PDF by minimizing the loss. Furthermore, we integrate time-marching strategies with the time-dependent KRnet to enhance the accuracy of the PDF approximation. After obtaining the approximate PDF, we recover the original KS solution. We also prove that the Lagrangian loss effectively controls the Kullback-Leibler (KL) divergence between the approximate PDF and the exact PDF. In the numerical experiments, we demonstrate the accuracy of our DeepLagrangian method for the 2D and 3D KS chemotaxis system with/without advection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14297v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yani Feng, Michael K. Ng, Zhiwen Zhang</dc:creator>
    </item>
    <item>
      <title>Numerical Approximation of Electrohydrodynamics Model: A Comparative Study of PINNs and FEM</title>
      <link>https://arxiv.org/abs/2510.14310</link>
      <description>arXiv:2510.14310v1 Announce Type: new 
Abstract: The accurate representation of numerous physical, chemical, and biological processes relies heavily on differential equations (DEs), particularly nonlinear differential equations (NDEs). While understanding these complex systems necessitates obtaining solutions to their governing equations, the derivation of precise approximations for NDEs remains a formidable task in computational mathematics. Although established techniques such as the finite element method (FEM) have long been foundational, remarkable promise for approximating continuous functions with high efficacy has recently been demonstrated by advancements in physics-informed deep-learning feedforward neural networks. In this work, a novel application of PINNs is presented for the approximation of the challenging Electrohydrodynamic (EHD) problem. A specific $L^2$-type \textit{total loss function} is employed, notably without reliance on any prior knowledge of the exact solution. A comprehensive comparative study is conducted, juxtaposing the approximation capabilities of the proposed neural network with those of the conventional FEM. The PINN training regimen is composed of two critical steps: forward propagation for adjustments to gradient and curvature, and backpropagation for the refinement of hyperparameters. The critical challenge of identifying optimal neural network architectures and hyperparameter configurations for efficient optimization is meticulously investigated. Excellent performance is shown to be delivered by the neural network even with a limited training dataset. Simultaneously, it is demonstrated that the accuracy of the FEM can be substantially enhanced through the judicious selection of smaller mesh sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14310v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mara Martinez, B. Veena S. N. Rao, S. M. Mallikarjunaiah</dc:creator>
    </item>
    <item>
      <title>High-order mass- and energy-conserving methods for the nonlinear Schr\"odinger equation and its hyperbolization</title>
      <link>https://arxiv.org/abs/2510.14335</link>
      <description>arXiv:2510.14335v1 Announce Type: new 
Abstract: We propose a class of numerical methods for the nonlinear Schr\"odinger (NLS) equation that conserves mass and energy, is of arbitrarily high-order accuracy in space and time, and requires only the solution of a scalar algebraic equation per time step. We show that some existing spatial discretizations, including the popular Fourier spectral method, are in fact energy-conserving if one considers the appropriate form of the energy density. We develop a new relaxation-type approach for conserving multiple nonlinear functionals that is more efficient and robust for the NLS equation compared to the existing multiple-relaxation approach. The accuracy and efficiency of the new schemes is demonstrated on test problems for both the focusing and defocusing NLS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14335v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hendrik Ranocha, David I. Ketcheson</dc:creator>
    </item>
    <item>
      <title>Asymptotic-preserving semi-Lagrangian discontinuous Galerkin schemes for the Boltzmann equation</title>
      <link>https://arxiv.org/abs/2510.14375</link>
      <description>arXiv:2510.14375v1 Announce Type: new 
Abstract: In this work, we present an asymptotic-preserving semi-Lagrangian discontinuous Galerkin scheme for the Boltzmann equation that effectively handles multi-scale transport phenomena. The main challenge lies in designing appropriate moments update for penalization within the semi-Lagrangian framework. Inspired by [M. Ding, J. M. Qiu, and R. Shu, Multiscale Model. Simul. 21 (2023), no. 1, 143--167], the key ingredient is utilizing the Shu-Osher form of the scheme in the implicit-explicit Runge-Kutta (IMEX-RK) setting, which enables us to capture the correct limiting system by constructing an appropriate moments update procedure. Our theoretical analysis establishes accuracy order conditions for both the IMEX-RK time integration and the new moments update step. We also employ hypocoercivity techniques to establish stability for the linearized model. Numerical experiments for various test problems validate our proposed scheme's accuracy, asymptotic-preserving property, and robustness in various regimes, which demonstrates its effectiveness for multi-scale kinetic simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14375v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaofeng Cai, Zhen Hao, Liu Liu, Jiayu Wan</dc:creator>
    </item>
    <item>
      <title>Preconditioned Conjugate Gradient methods for the estimation of General Linear Models</title>
      <link>https://arxiv.org/abs/2510.14471</link>
      <description>arXiv:2510.14471v1 Announce Type: new 
Abstract: The use of the Preconditioned Conjugate Gradient (PCG) method for computing the Generalized Least Squares (GLS) estimator of the General Linear Model (GLM) is considered. The GLS estimator is expressed in terms of the solution of an augmented system. That system is solved by means of the PCG method using an indefinite preconditioner. The resulting method iterates a sequence Ordinary Least Squares (OLS) estimations that converges, in exact precision, to the GLS estimator within a finite number of steps. The numerical and statistical properties of the estimator computed at an intermediate step are analytically and numerically studied. This approach allows to combine direct methods, used in the OLS step, with those of iterative methods. This advantage is exploited to design PCG methods for the estimation of Constrained GLMs and of some structured multivariate GLMs. The structure of the matrices involved are exploited as much as possible, in the OLS step. The iterative method then solves for the unexploited structure. Numerical experiments shows that the proposed methods can achieve, for these structured problems, the same precision of state of the art direct methods, but in a fraction of the time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14471v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paolo Foschi</dc:creator>
    </item>
    <item>
      <title>A Well-Balanced Space-Time ALE Compact Gas-Kinetic Scheme for the Shallow Water Equations on Unstructured Meshes</title>
      <link>https://arxiv.org/abs/2510.14673</link>
      <description>arXiv:2510.14673v1 Announce Type: new 
Abstract: This study presents a high-order, space-time coupled arbitrary Lagrangian Eulerian (ALE) compact gas-kinetic scheme (GKS) for the shallow water equations on moving unstructured meshes. The proposed method preserves both the geometric conservation law (GCL) and the well-balanced property. Mesh motion effects are directly incorporated by formulating numerical fluxes that account for the spatial temporal nonuniformity of the flow field and the swept area of moving cell interfaces. This allows temporal updates to be performed on the physical moving mesh, avoiding data remapping. The compact GKS provides time accurate evolution of flow variables and fluxes, enabling the scheme to achieve second-order temporal accuracy within a single stage. To consistently treat bottom topography on moving meshes, an evolution equation for the topography is established and discretized using a compatible space-time scheme, in which the fluxes induced by mesh motion are computed accurately. Mathematical proofs demonstrating the GCL preserving and well-balanced properties of the proposed ALE formulation are also provided. For improved accuracy and robustness, a nonlinear fourth-order compact reconstruction technique is employed. A comprehensive set of numerical experiments verifies the scheme's theoretical properties and demonstrates its accuracy, stability, and effectiveness in simulating complex shallow-water flow problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14673v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fengxiang Zhao, Jianping Gan, Kun XU</dc:creator>
    </item>
    <item>
      <title>Generalized Fourier Series: An N log2(N) extension for aperiodic functions that eliminates Gibbs oscillations</title>
      <link>https://arxiv.org/abs/2510.14731</link>
      <description>arXiv:2510.14731v1 Announce Type: new 
Abstract: This article introduces the Generalized Fourier Series (GFS), a novel spectral method that extends the clas- sical Fourier series to non-periodic functions. GFS addresses key challenges such as the Gibbs phenomenon and poor convergence in non-periodic settings by decomposing functions into periodic and aperiodic com- ponents. The periodic part is represented using standard Fourier modes and efficiently computed via the Fast Fourier Transform (FFT). The aperiodic component employs adaptive, low-rank sinusoidal functions with non-harmonic modes, dynamically tuned to capture discontinuities and derivative jumps across domain boundaries. Unlike conventional Fourier extension methods, GFS achieves high accuracy without requiring compu- tational domain extensions, offering a compact and efficient representation of non-periodic functions. The adaptive low-rank approach ensures accuracy while minimizing computational overhead, typically involving additional complex modes for the aperiodic part. Furthermore, GFS demonstrates a high-resolution power, with degrees of freedom comparable to FFT in periodic domains, and maintains N log2(N) computational complexity. The effectiveness of GFS is validated through numerical experiments, showcasing its ability to approximate functions and their derivatives in non-periodic domains accurately. With its robust framework and minimal computational cost, GFS holds significant potential for advancing applications in numerical PDEs, signal processing, machine learning, and computational physics by providing a robust and efficient tool for high-accuracy function approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14731v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Narsimha Reddy Rapakaa, Mohamed Kamel Riahi</dc:creator>
    </item>
    <item>
      <title>On the convergence of stochastic variance reduced gradient for linear inverse problems</title>
      <link>https://arxiv.org/abs/2510.14759</link>
      <description>arXiv:2510.14759v1 Announce Type: new 
Abstract: Stochastic variance reduced gradient (SVRG) is an accelerated version of stochastic gradient descent based on variance reduction, and is promising for solving large-scale inverse problems. In this work, we analyze SVRG and a regularized version that incorporates a priori knowledge of the problem, for solving linear inverse problems in Hilbert spaces. We prove that, with suitable constant step size schedules and regularity conditions, the regularized SVRG can achieve optimal convergence rates in terms of the noise level without any early stopping rules, and standard SVRG is also optimal for problems with nonsmooth solutions under a priori stopping rules. The analysis is based on an explicit error recursion and suitable prior estimates on the inner loop updates with respect to the anchor point. Numerical experiments are provided to complement the theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14759v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bangti Jin, Zehui Zhou</dc:creator>
    </item>
    <item>
      <title>Ghost stabilisation for cut finite element exterior calculus</title>
      <link>https://arxiv.org/abs/2510.14772</link>
      <description>arXiv:2510.14772v1 Announce Type: new 
Abstract: We introduce the cut finite element method in the language of finite element exterior calculus, by formulating a stabilisation -- for any form degree -- that makes the method robust with respect to the position of the interface relative to the mesh. We prove that the $L^2$-norm on the physical domain augmented with this stabilisation is uniformly equivalent to the $L^2$-norm on the ``active'' mesh that contains all the degrees of freedom of the finite element space (including those external to the physical domain). We show how this CutFEEC method can be applied to discretize the Hodge Laplace equations on an unfitted mesh, in any dimension and any topology. A numerical illustration is provided involving a conforming finite element space of $H^{\text{curl}}$ posed on a filled torus, with convergence and condition number scaling independent of the position of the boundary with respect to the background mesh.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14772v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daniele Di Pietro, J\'er\^ome Droniou, Erik Nilsson</dc:creator>
    </item>
    <item>
      <title>Error analysis of Abate--Whitt methods for Inverse Laplace Transforms and a new algorithm for queuing theory applications</title>
      <link>https://arxiv.org/abs/2510.14799</link>
      <description>arXiv:2510.14799v1 Announce Type: new 
Abstract: We study the accuracy of a class of methods to compute the Inverse Laplace Transform, the so-called \emph{Abate--Whitt methods} [Abate, Whitt 2006], which are based on a linear combination of evaluations of $\widehat{f}$ in a few points. We provide error bounds which relate the accuracy of a method to the rational approximation of the exponential function. We specialize our analysis to applications in queuing theory, a field in which Abate--Whitt methods are often used; in particular, we study phase-type distributions and Markov-modulated fluid models (or \emph{fluid queues}).
  We use a recently developed algorithm for rational approximation, the AAA algorithm [Nakatsukasa, S\`ete, Trefethen 2018], to produce a new family of methods, which we call TAME. The parameters of these methods are constructed depending on a function-specific domain $\Omega$; we provide a quasi-optimal choice for certain families of functions. We discuss numerical issues related to floating-point computation, and we validate our results through numerical experiments which show that the new methods require significantly fewer function evaluations to achieve an accuracy that is comparable (or better) to that of the classical methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14799v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikita Deniskin, Federico Poloni</dc:creator>
    </item>
    <item>
      <title>Augmented Lagrangian Method based adjoint space framework for sparse reconstruction of acoustic source with boundary measurements</title>
      <link>https://arxiv.org/abs/2510.14805</link>
      <description>arXiv:2510.14805v1 Announce Type: new 
Abstract: We propose a semismooth Newton-based augmented Lagrangian method for reconstructing sparse sources in inverse acoustic scattering problems. The semismooth Newton method can be iterated in the space of measurements instead of the unknown source to be reconstructed. It is highly efficient, especially when the measurement data is much less than the acoustic source. The source can be calculated from Fenchel-Rockafellar duality theory. We can obtain lots of acceleration and leverage the computational cost. The numerical examples show the high efficiency of the proposed semismooth Newton-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14805v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nirui Tan, Hongpeng Sun</dc:creator>
    </item>
    <item>
      <title>Polynomial Preconditioning for Indefinite Matrices</title>
      <link>https://arxiv.org/abs/2510.14816</link>
      <description>arXiv:2510.14816v1 Announce Type: new 
Abstract: Polynomial preconditioning is an important tool in solving large linear systems and eigenvalue problems. A polynomial from GMRES can be used to precondition restarted GMRES and restarted Arnoldi. Here we give methods for indefinite matrices that make polynomial preconditioning more generally applicable. The new techniques include balancing the polynomial so that it produces a definite spectrum. Then a stability approach is given that is specialized for the indefinite case. Also, very complex spectra are examined. Then convergence estimates are given for polynomial preconditioning of real, indefinite spectra. Finally, tests are preformed of finding interior eigenvalues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14816v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hayden Henson, Ronald B. Morgan</dc:creator>
    </item>
    <item>
      <title>Efficient and Robust Carath\'{e}odory-Steinitz Pruning of Positive Discrete Measures</title>
      <link>https://arxiv.org/abs/2510.14916</link>
      <description>arXiv:2510.14916v1 Announce Type: new 
Abstract: In many applications, one seeks to approximate integration against a positive measure of interest by a positive discrete measure: a numerical quadrature rule with positive weights. One common desired discretization property is moment preservation over a finite dimensional function space, e.g., bounded-degree polynomials. Carath\'{e}odory's theorem asserts that if there is any finitely supported quadrature rule with more nodes than the dimension of the given function space, one can form a smaller (and hence more efficient) positive, nested, quadrature rule that preserves the moments of the original rule.
  We describe an efficient streaming procedure for Carath\'{e}odory-Steinitz pruning, a numerical procedure that implements Carath\'{e}odory's theorem for this measure compression. The new algorithm makes use of Givens rotations and on-demand storage of arrays to successfully prune very large rules whose storage complexity only depends on the dimension of the function space. This approach improves on a naive implementation of Carath\'{e}odory-Steinitz pruning whose runtime and storage complexity are quadratic and linear, respectively, in the size of the original measure. We additionally prove mathematical stability properties of our method with respect to a set of admissible, total-variation perturbations of the original measure. Our method is compared to two alternate approaches with larger storage requirements: non-negative least squares and linear programming, and we demonstrate comparable runtimes, with improved stability and storage robustness. Finally, we demonstrate practical usage of this algorithm to generate quadrature for discontinous Galerkin finite element simulations on cut-cell meshes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14916v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Filip B\v{e}l\'ik, Jesse Chan, Akil Narayan</dc:creator>
    </item>
    <item>
      <title>Rank of Matrices Arising out of Singular Kernel Functions</title>
      <link>https://arxiv.org/abs/2510.14920</link>
      <description>arXiv:2510.14920v1 Announce Type: new 
Abstract: Kernel functions are frequently encountered in differential equations and machine learning applications. In this work, we study the rank of matrices arising out of the kernel function $K: X \times Y \mapsto \mathbb{R}$, where the sets $X, Y \in \mathbb{R}^d$ are hypercubes that share a boundary. The main contribution of this work is the analysis of the rank of such matrices where the particles (sources/targets) are arbitrarily distributed within these hypercubes. To our knowledge, this is the first work to formally investigate the rank of such matrices for an arbitrary distribution of particles. We model the arbitrary distribution of particles to arise from an underlying random distribution and obtain bounds on the expected rank and variance of the rank of the kernel matrix corresponding to various neighbor interactions. These bounds are useful for understanding the performance and complexity of hierarchical matrix algorithms (especially hierarchical matrices satisfying the weak-admissibility criterion) for an arbitrary distribution of particles. We also present numerical experiments in one-, two-, and three-dimensions, showing the expected rank growth and variance of the rank for different types of interactions. The numerical results, not surprisingly, align with our theoretical predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14920v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sumit Singh (IIT Madras, India), Sivaram Ambikasaran (IIT Madras, India)</dc:creator>
    </item>
    <item>
      <title>Finite element methods for electroneutral multicomponent electrolyte flows</title>
      <link>https://arxiv.org/abs/2510.14923</link>
      <description>arXiv:2510.14923v1 Announce Type: new 
Abstract: We present a broad family of high-order finite element algorithms for simulating the flow of electroneutral electrolytes. The governing partial differential equations that we solve are the electroneutral Navier-Stokes-Onsager-Stefan-Maxwell (NSOSM) equations, which model momentum transport, multicomponent diffusion and electrical effects within the electrolyte. Our algorithms can be applied in the steady and transient settings, in two and three spatial dimensions, and under a variety of boundary conditions. Moreover, we allow for the material parameters (e.g. viscosity, diffusivities, thermodynamic factors and density) to be solution-dependent and thermodynamically non-ideal. The flexibility of our approach requires us to address subtleties that arise in the governing equations due to the interplay between boundary conditions and the equation of state. We demonstrate the algorithms in various physical configurations, including (i) electrolyte flow around a microfluidic rotating disk electrode and (ii) the flow in a Hull cell of a cosolvent electrolyte mixture used in lithium-ion batteries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14923v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aaron Baier-Reinio, Patrick E. Farrell, Charles W. Monroe</dc:creator>
    </item>
    <item>
      <title>Efficient and Flexible Multirate Temporal Adaptivity</title>
      <link>https://arxiv.org/abs/2510.14964</link>
      <description>arXiv:2510.14964v1 Announce Type: new 
Abstract: In this work we present two new families of multirate time step adaptivity controllers, that are designed to work with embedded multirate infinitesimal (MRI) time integration methods for adapting time steps when solving problems with multiple time scales. We compare these controllers against competing approaches on two benchmark problems and see that they offer dramatically improved performance and flexibility, with each proposed family excelling on different types of multirate applications. The combination of embedded MRI methods and the proposed controllers enable adaptive simulations of problems with a potentially arbitrary number of time scales, achieving high accuracy while maintaining low computational cost. Additionally, we introduce a new set of embeddings for the family of explicit multirate exponential Runge--Kutta (MERK) methods of orders 2 through 5, resulting in the first-ever fifth-order embedded MRI method. Finally, we compare the performance of a wide range of embedded MRI methods on our benchmark problems to provide guidance on how to select an appropriate MRI method and multirate controller.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14964v1</guid>
      <category>math.NA</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel R. Reynolds, Sylvia Amihere, Dashon Mitchell, Vu Thai Luan</dc:creator>
    </item>
    <item>
      <title>DeepMartingale: Duality of the Optimal Stopping Problem with Expressivity</title>
      <link>https://arxiv.org/abs/2510.13868</link>
      <description>arXiv:2510.13868v1 Announce Type: cross 
Abstract: Using a martingale representation, we introduce a novel deep-learning approach, which we call DeepMartingale, to study the duality of discrete-monitoring optimal stopping problems in continuous time. This approach provides a tight upper bound for the primal value function, even in high-dimensional settings. We prove that the upper bound derived from DeepMartingale converges under very mild assumptions. Even more importantly, we establish the expressivity of DeepMartingale: it approximates the true value function within any prescribed accuracy $\varepsilon$ under our architectural design of neural networks whose size is bounded by $\tilde{c}\,D^{\tilde{q}}\varepsilon^{-\tilde{r}}$, where the constants $\tilde{c}, \tilde{q}, \tilde{r}$ are independent of the dimension $D$ and the accuracy $\varepsilon$. This guarantees that DeepMartingale does not suffer from the curse of dimensionality. Numerical experiments demonstrate the practical effectiveness of DeepMartingale, confirming its convergence, expressivity, and stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13868v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junyan Ye, Hoi Ying Wong</dc:creator>
    </item>
    <item>
      <title>Multi-Period Sparse Optimization for Proactive Grid Blackout Diagnosis</title>
      <link>https://arxiv.org/abs/2510.14045</link>
      <description>arXiv:2510.14045v1 Announce Type: cross 
Abstract: Existing or planned power grids need to evaluate survivability under extreme events, like a number of peak load overloading conditions, which could possibly cause system collapses (i.e. blackouts). For realistic extreme events that are correlated or share similar patterns, it is reasonable to expect that the dominant vulnerability or failure sources behind them share the same locations but with different severity. Early warning diagnosis that proactively identifies the key vulnerabilities responsible for a number of system collapses of interest can significantly enhance resilience. This paper proposes a multi-period sparse optimization method, enabling the discovery of {persistent failure sources} across a sequence of collapsed systems with increasing system stress, such as rising demand or worsening contingencies. This work defines persistency and efficiently integrates persistency constraints to capture the ``hidden'' evolving vulnerabilities. Circuit-theory based power flow formulations and circuit-inspired optimization heuristics are used to facilitate the scalability of the method. Experiments on benchmark systems show that the method reliably tracks persistent vulnerability locations under increasing load stress, and solves with scalability to large systems ({on average} taking {around} 200 s per scenario on 2000+ bus systems).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14045v1</guid>
      <category>eess.SY</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>math.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qinghua Ma, Reetam Sen Biswas, Denis Osipov, Guannan Qu, Soummya Kar, Shimiao Li</dc:creator>
    </item>
    <item>
      <title>Comparative Analysis of the Flow in a Realistic Human Airway</title>
      <link>https://arxiv.org/abs/2510.14320</link>
      <description>arXiv:2510.14320v1 Announce Type: cross 
Abstract: Accurate simulations of the flow in the human airway are essential for advancing diagnostic methods. Many existing computational studies rely on simplified geometries or turbulence models, limiting their simulation's ability to resolve flow features such shear-layer instabilities or secondary vortices. In this study, direct numerical simulations were performed for inspiratory flow through a detailed airway model which covers the nasal mask region to the 6th bronchial bifurcation. Simulations were conducted at two physiologically relevant \textsc{Reynolds} numbers with respect to the pharyngeal diameter, i.e., at Re_p=400 (resting) and Re_p=1200 (elevated breathing). These values characterize resting and moderately elevated breathing conditions. A lattice-Boltzmann method was employed to directly simulate the flow, i.e., no turbulence model was used. The flow field was examined across four anatomical regions: 1) the nasal cavity, 2) the naso- and oropharynx, 3) the laryngopharynx and larynx, and 4) the trachea and carinal bifurcation. The total pressure loss increased from 9.76 Pa at Re_p=400 to 41.93 Pa at Re_p=1200. The nasal cavity accounted for the majority of this loss for both Reynolds numbers, though its relative contribution decreased from 81.3% at Re_p=400 to 73.4% at Re_p=1200. At Re_p=1200, secondary vortices in the nasopharyngeal bend and turbulent shear-layers in the glottis jet enhanced the local pressure losses. In contrast, the carinal bifurcation mitigated upstream unsteadiness and stabilized the flow. A key outcome is the spatial correlation between the pressure loss and the onset of flow instabilities across the four regions. This yields a novel perspective on how the flow resistance and vortex dynamics vary with geometric changes and flow rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14320v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mario R\"uttgers, Julian Vorspohl, Luca Mayolle, Benedikt Johanning-Meiners, Dominik Krug, Michael Klaas, Matthias Meinke, Sangseung Lee, Wolfgang Schr\"oder, Andreas Lintermann</dc:creator>
    </item>
    <item>
      <title>The geometry of PLS shrinkages</title>
      <link>https://arxiv.org/abs/2510.14430</link>
      <description>arXiv:2510.14430v1 Announce Type: cross 
Abstract: The geometrical structure of PLS shrinkages is here considered. Firstly, an explicit formula for the shrinkage vector is provided. In that expression, shrinkage factors are expressed a averages of a set of basic shrinkages that depend only on the data matrix. On the other hand, the weights of that average are multilinear functions of the observed responses. That representation allows to characterise the set of possible shrinkages and identify extreme situations where the PLS estimator has an highly nonlinear behaviour. In these situations, recently proposed measures for the degrees of freedom (DoF), that directly depend on the shrinkages, fail to provide reasonable values. It is also shown that the longstanding conjecture that the DoFs of PLS always exceeds the number PLS directions does not hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14430v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paolo Foschi</dc:creator>
    </item>
    <item>
      <title>Optimality-Based Control Space Reduction for Infinite-Dimensional Control Spaces</title>
      <link>https://arxiv.org/abs/2510.14479</link>
      <description>arXiv:2510.14479v1 Announce Type: cross 
Abstract: We consider linear model reduction in both the control and state variables for unconstrained linear-quadratic optimal control problems subject to time-varying parabolic PDEs. The first-order optimality condition for a state-space reduced model naturally leads to a reduced structure of the optimal control. Thus, we consider a control- and state-reduced problem that admits the same minimizer as the solely state-reduced problem. Lower and upper \emph{a posteriori} error bounds for the optimal control and a representation for the error in the optimal function value are provided. These bounds are used in an adaptive algorithm to solve the control problem. We prove its convergence and numerically demonstrate the advantage of combined control and state space reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14479v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Kartmann, Stefan Volkwein</dc:creator>
    </item>
    <item>
      <title>An analysis of the derivative-free loss method for solving PDEs</title>
      <link>https://arxiv.org/abs/2309.16829</link>
      <description>arXiv:2309.16829v2 Announce Type: replace 
Abstract: This study analyzes the derivative-free loss method to solve a certain class of elliptic PDEs and fluid problems using neural networks. The approach leverages the Feynman-Kac formulation, incorporating stochastic walkers and their averaged values. We investigate how the time interval associated with the Feynman-Kac representation and the walker size influence computational efficiency, trainability, and sampling errors. Our analysis shows that the training loss bias scales proportionally with the time interval and the spatial gradient of the neural network, while being inversely proportional to the walker size. Moreover, we demonstrate that the time interval must be sufficiently long to enable effective training. These results indicate that the walker size can be chosen as small as possible, provided it satisfies the optimal lower bound determined by the time interval. Finally, we present numerical experiments that support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.16829v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jihun Han, Yoonsang Lee</dc:creator>
    </item>
    <item>
      <title>Geometric optics approximation sampling: near-field case</title>
      <link>https://arxiv.org/abs/2403.01655</link>
      <description>arXiv:2403.01655v2 Announce Type: replace 
Abstract: In this paper, we propose a novel gradient-free and dimensionality-independent sampler, the Geometric Optics Approximation Sampling (GOAS), based on a near-field reflector system. The key idea involves constructing a reflecting surface that redirects rays from a source with a prescribed simple distribution toward a target domain, achieving the desired target measure. Once this surface is constructed, an arbitrary number of independent, uncorrelated samples can be drawn by re-simulating (ray-tracing) the reflector system, i.e., push-forward samples from the source distribution under a reflecting map. To compute the reflecting surface, we employ an enhanced supporting ellipsoid method for the near-field reflector problem. This approach does not require gradient information of the target density and discretizes the target measure using either a low-discrepancy or random sequence, ensuring dimensionality independence. Since the resulting surface is non-smooth (being a union of ellipsoidal sheets) but continuous, we apply a softmin smoothing technique to enable sampling. Theoretically, we define the geometric optics approximation measure as the push-forward of the source measure through the reflecting map. We prove that this measure is well-defined and stable with respect to perturbations of the target domain, ensuring robustness in sampling. Additionally, we derive error bounds between the numerical geometric optics approximation measure and the target measure under the Hellinger metric. Our numerical experiments validate the theoretical claims of GOAS, demonstrate its superior performance compared to MCMC for complex distributions, and confirm its practical effectiveness and broad applicability in solving Bayesian inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01655v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zejun Sun, Guang-Hui Zheng</dc:creator>
    </item>
    <item>
      <title>Reduced Order Modeling of Partial Differential Equations on Parameter-Dependent Domains Using Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2407.17171</link>
      <description>arXiv:2407.17171v2 Announce Type: replace 
Abstract: Partial differential equations (PDEs) are widely used for modeling various physical phenomena. These equations often depend on certain parameters, necessitating either the identification of optimal parameters or the solution of the equations over multiple parameters. Performing an exhaustive search over the parameter space requires solving the PDE multiple times, which is generally impractical. To address this challenge, reduced order models (ROMs) are built using a set of precomputed solutions (snapshots) corresponding to different parameter values. Recently, Deep Learning ROMs (DL-ROMs) have been introduced as a new method to obtain ROM, offering improved flexibility and performance. In many cases, the domain on which the PDE is defined also varies. Capturing this variation is important for building accurate ROMs but is often difficult, especially when the domain has a complex structure or changes topology. In this paper, we propose a Deep-ROM framework that can automatically extract useful domain parametrization and incorporate it into the model. Unlike traditional domain parameterization methods, our approach does not require user-defined control points and can effectively handle domains with varying numbers of components. It can also learn from domain data even when no mesh is available. Using deep autoencoders, our approach reduces the dimensionality of both the PDE solution and the domain representation, making it possible to approximate solutions efficiently across a wide range of domain shapes and parameter values. We demonstrate that our approach produces parametrizations that yield solution accuracy comparable to models using exact parameters. Importantly, our model remains stable under moderate geometric variations in the domain, such as boundary deformations and noise - scenarios where traditional ROMs often require remeshing or manual adjustment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17171v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martina Buka\v{c} (University of Notre Dame, Notre Dame, IN, USA), Iva Manojlovi\'c (University of Zagreb Faculty of Electrical Engineering and Computing, Croatia), Boris Muha (Department of Mathematics, Faculty of Science, University of Zagreb, Croatia), Domagoj Vlah (University of Zagreb Faculty of Electrical Engineering and Computing, Croatia)</dc:creator>
    </item>
    <item>
      <title>Enriching continuous Lagrange finite element approximation spaces using neural networks</title>
      <link>https://arxiv.org/abs/2502.04947</link>
      <description>arXiv:2502.04947v2 Announce Type: replace 
Abstract: In this work, we present a study combining two approaches in the context of solving PDEs: the continuous finite element method (FEM) and more recent techniques based on neural networks. In recent years, physics-informed neural networks (PINNs) have become particularly interesting for rapidly solving PDEs, especially in high dimensions. However, their lack of accuracy can be a significant drawback in this context, hence the interest in combining them with FEM, for which error estimates are already known. The complete pipeline proposed here consists in modifying the classical FEM approximation spaces by taking information from a prior, chosen as the prediction of a neural network. On the one hand, this combination improves and certifies the prediction of neural networks, to obtain a fast and accurate solution. On the other hand, error estimates are proven, showing that such strategies outperform classical ones by a factor that depends only on the quality of the prior. We validate our approach with numerical results performed on parametric problems with 1D, 2D and 3D geometries. These experiments demonstrate that to achieve a given accuracy, a coarser mesh can be used with our enriched FEM compared to the standard FEM, leading to reduced computational time, particularly for parametric problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04947v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>H\'el\`ene Barucq, Michel Duprez, Florian Faucher, Emmanuel Franck, Fr\'ed\'erique Lecourtier, Vanessa Lleras, Victor Michel-Dansac, Nicolas Victorion</dc:creator>
    </item>
    <item>
      <title>A hierarchical approach for multicontinuum homogenization in high contrast media</title>
      <link>https://arxiv.org/abs/2503.01276</link>
      <description>arXiv:2503.01276v5 Announce Type: replace 
Abstract: A recently developed upscaling technique, the multicontinuum homogenization method, has gained significant attention for its effectiveness in modeling complex multiscale systems. This method defines multiple continua based on distinct physical properties and solves a series of constrained cell problems to capture localized information for each continuum. However, solving all these cell problems on very fine grids at every macroscopic point is computationally expensive, which is a common limitation of most homogenization approaches for non-periodic problems. To address this challenge, we propose a hierarchical multicontinuum homogenization framework. The core idea is to define hierarchical macroscopic points and solve the constrained problems on grids of varying resolutions. We assume that the local solutions can be represented as a combination of a linear interpolation of local solutions from preceding levels and an additional correction term. This combination is substituted into the original constrained problems, and the correction term is resolved using finite element (FE) grids of varying sizes, depending on the level of the macropoint. By normalizing the computational cost of fully resolving the local problem to $\mathcal{O}(1)$, we establish that our approach incurs a cost of $\mathcal{O}(L \eta^{(1-L)d})$, highlighting substantial computational savings across hierarchical layers $L$, coarsening factor $\eta$, and spatial dimension $d$. Numerical experiments validate the effectiveness of the proposed method in media with slowly varying properties, underscoring its potential for efficient multiscale modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01276v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Xie, Viet Ha Hoang, Yin Yang, Yunqing Huang</dc:creator>
    </item>
    <item>
      <title>Convergence of Ray- and Pixel-Driven Discretization Frameworks in the Strong Operator Topology</title>
      <link>https://arxiv.org/abs/2503.03069</link>
      <description>arXiv:2503.03069v3 Announce Type: replace 
Abstract: Tomography is a central tool in medical applications, allowing doctors to investigate patients' interior features. The Radon transform (in two dimensions) is commonly used to model the measurement process in parallel-beam CT. Suitable discretization of the Radon transform and its adjoint (called the backprojection) is crucial. The most commonly used discretization approach combines what we refer to as the ray-driven Radon transform with what we refer to as the pixel-driven backprojection, as anecdotal reports describe these as showing the best approximation performance. However, there is little rigorous understanding of induced approximation errors. These methods involve three discretization parameters: the spatial-, detector-, and angular resolutions. Most commonly, balanced resolutions are used, i.e., the same (or similar) spatial- and detector resolutions are employed. We present an interpretation of ray- and pixel-driven discretizations as `convolutional methods', a special class of finite-rank operators. This allows for a structured analysis that can explain observed behavior. In particular, we prove convergence in the strong operator topology of the ray-driven Radon transform and the pixel-driven backprojection under balanced resolutions, thus theoretically justifying this approach. In particular, with high enough resolutions one can approximate the Radon transform arbitrarily well. Numerical experiments corroborate these theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03069v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard Huber</dc:creator>
    </item>
    <item>
      <title>A stabilized Two-Step Formulation of Maxwell's Equations in the time-domain</title>
      <link>https://arxiv.org/abs/2507.18235</link>
      <description>arXiv:2507.18235v3 Announce Type: replace 
Abstract: Simulating electromagnetic fields across broad frequency ranges is challenging due to numerical instabilities at low frequencies. This work extends a stabilized two-step formulation of Maxwell's equations to the time-domain. Using a Galerkin discretization in space, we apply two different time-discretization schemes that are tailored to the first- and second-order in time partial differential equations of the two-step solution procedure used here. To address the low-frequency instability, we incorporate a generalized tree-cotree gauge that removes the singularity of the curl-curl operator, ensuring robustness even in the static limit. Numerical results on academic and application-oriented 3D problems confirm stability, accuracy, and the method's applicability to nonlinear, temperature-dependent materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18235v3</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TMAG.2025.3619844</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Magnetics, 2025</arxiv:journal_reference>
      <dc:creator>Leon Herles, Mario Mally, J\"org Ostrowski, Sebastian Sch\"ops, Melina Merkel</dc:creator>
    </item>
    <item>
      <title>D3PINNs: A Novel Physics-Informed Neural Network Framework for Staged Solving of Time-Dependent Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2508.20440</link>
      <description>arXiv:2508.20440v2 Announce Type: replace 
Abstract: In this paper, we propose a novel framework, Dynamic Domain Decomposition Physics-Informed Neural Networks (D3PINNs), for solving time-dependent partial differential equations (PDEs). In this framework, solutions of time-dependent PDEs are dynamically captured. First, an approximate
  solution is obtained by the Physics-Informed Neural Networks (PINNs) containing the domain decomposition, then the time derivative terms in the PDE will be retained and the other terms associated with the solution will be replaced with the approximate solution. As a result, the PDE reduces to an ordinary differential equations (ODEs). Finally, the time-varying solution will be solved by the classical numerical methods for ODEs. D3PINNs retain the computational efffciency and ffexibility inherent to PINNs and enhance the ability for capturing solutions of time-dependent PDEs. Numerical experiments validate the effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20440v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xun Yang, Guanqiu Ma Maohua Ran</dc:creator>
    </item>
    <item>
      <title>A control-based spatial source reconstruction in fractional heat equations</title>
      <link>https://arxiv.org/abs/2510.07528</link>
      <description>arXiv:2510.07528v2 Announce Type: replace 
Abstract: This article addresses the inverse source problem for a nonlocal heat equation involving the fractional Laplacian. The primary goal is to reconstruct the spatial component of the source term from partial observations of the system's state and its time derivative over a subset of the domain. A reconstruction formula for the Fourier coefficients of the unknown source is derived, leveraging the null controllability property of the fractional heat equation when the fractional order lies in the interval $s\in(1/2,1)$. The methodology builds on spectral analysis and Volterra integral equations, providing a robust framework for recovering spatial sources under limited measurement data. Numerical experiments confirm the accuracy and stability of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.07528v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Galina Garc\'ia, Joaqu\'in Vidal, Sebasti\'an Zamorano</dc:creator>
    </item>
    <item>
      <title>DE-Sinc approximation for unilateral rapidly decreasing functions and its computational error bound</title>
      <link>https://arxiv.org/abs/2510.11411</link>
      <description>arXiv:2510.11411v3 Announce Type: replace 
Abstract: The Sinc approximation is known to be a highly efficient approximation formula for rapidly decreasing functions. For unilateral rapidly decreasing functions, which rapidly decrease as $x\to\infty$ but does not as $x\to-\infty$, an appropriate variable transformation makes the functions rapidly decreasing. As such a variable transformation, Stenger proposed $t = \sinh(\log(\operatorname{arsinh}(\exp x)))$, which enables the Sinc approximation to achieve root-exponential convergence. Recently, another variable transformation $t = 2\sinh(\log(\log(1+\exp x)))$ was proposed, which improved the convergence rate. Furthermore, its computational error bound was provided. However, this improvement was not significant because the convergence rate remained root-exponential. To improve the convergence rate significantly, this study proposes a new transformation, $t = 2\sinh(\log(\log(1+\exp(\pi\sinh x))))$, which is categorized as the double-exponential (DE) transformation. Furthermore, this study provides its computational error bound, which shows that the proposed approximation formula can achieve almost exponential convergence. Numerical experiments that confirm the theoretical result are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11411v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomoaki Okayama</dc:creator>
    </item>
    <item>
      <title>Numerical method for approximately optimal solutions of two-stage distributionally robust optimization with marginal constraints</title>
      <link>https://arxiv.org/abs/2205.05315</link>
      <description>arXiv:2205.05315v3 Announce Type: replace-cross 
Abstract: We consider a general class of two-stage distributionally robust optimization (DRO) problems where the ambiguity set is constrained by fixed marginal probability laws that are not necessarily discrete. We derive primal and dual formulations of this class of problems and subsequently develop a numerical algorithm for computing approximate optimizers as well as approximate worst-case probability measures. Moreover, our algorithm computes both an upper bound and a lower bound for the optimal value of the problem, where the difference between the computed bounds provides a direct sub-optimality estimate of the computed solution. Most importantly, the sub-optimality can be controlled to be arbitrarily close to 0 by appropriately choosing the inputs of the algorithm. To demonstrate the effectiveness of the proposed algorithm, we apply it to three prominent instances of two-stage DRO problems in task scheduling, multi-product assembly, and supply chain network design with edge failure. The ambiguity sets in these problem instances involve a large number of continuous or discrete marginals. The numerical results showcase that the proposed algorithm computes high-quality robust decisions along with non-conservative sub-optimality estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.05315v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Qikun Xiang</dc:creator>
    </item>
    <item>
      <title>Kernel Neural Operators (KNOs) for Scalable, Memory-efficient, Geometrically-flexible Operator Learning</title>
      <link>https://arxiv.org/abs/2407.00809</link>
      <description>arXiv:2407.00809v2 Announce Type: replace-cross 
Abstract: This paper introduces the Kernel Neural Operator (KNO), a provably convergent operator-learning architecture that utilizes compositions of deep kernel-based integral operators for function-space approximation of operators (maps from functions to functions). The KNO decouples the choice of kernel from the numerical integration scheme (quadrature), thereby naturally allowing for operator learning with explicitly-chosen trainable kernels on irregular geometries. On irregular domains, this allows the KNO to utilize domain-specific quadrature rules. To help ameliorate the curse of dimensionality, we also leverage an efficient dimension-wise factorization algorithm on regular domains. More importantly, the ability to explicitly specify kernels also allows the use of highly expressive, non-stationary, neural anisotropic kernels whose parameters are computed by training neural networks. Numerical results demonstrate that on existing benchmarks the training and test accuracy of KNOs is comparable to or higher than popular operator learning techniques while typically using an order of magnitude fewer trainable parameters, with the more expressive kernels proving important to attaining high accuracy. KNOs thus facilitate low-memory, geometrically-flexible, deep operator learning, while retaining the implementation simplicity and transparency of traditional kernel methods from both scientific computing and machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00809v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matthew Lowery, John Turnage, Zachary Morrow, John D. Jakeman, Akil Narayan, Shandian Zhe, Varun Shankar</dc:creator>
    </item>
    <item>
      <title>Approximation Rates for Shallow ReLU$^k$ Neural Networks on Sobolev Spaces via the Radon Transform</title>
      <link>https://arxiv.org/abs/2408.10996</link>
      <description>arXiv:2408.10996v3 Announce Type: replace-cross 
Abstract: Let $\Omega\subset \mathbb{R}^d$ be a bounded domain. We consider the problem of how efficiently shallow neural networks with the ReLU$^k$ activation function can approximate functions from Sobolev spaces $W^s(L_p(\Omega))$ with error measured in the $L_q(\Omega)$-norm. Utilizing the Radon transform and recent results from discrepancy theory, we provide a simple proof of nearly optimal approximation rates in a variety of cases, including when $q\leq p$, $p\geq 2$, and $s \leq k + (d+1)/2$. The rates we derive are optimal up to logarithmic factors, and significantly generalize existing results. An interesting consequence is that the adaptivity of shallow ReLU$^k$ neural networks enables them to obtain optimal approximation rates for smoothness up to order $s = k + (d+1)/2$, even though they represent piecewise polynomials of fixed degree $k$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10996v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tong Mao, Jonathan W. Siegel, Jinchao Xu</dc:creator>
    </item>
    <item>
      <title>Stochastic and incremental subgradient methods for convex optimization on Hadamard spaces</title>
      <link>https://arxiv.org/abs/2412.06730</link>
      <description>arXiv:2412.06730v3 Announce Type: replace-cross 
Abstract: As a foundation for optimization, convexity is useful beyond the classical settings of Euclidean and Hilbert space. The broader arena of nonpositively curved metric spaces, which includes manifolds like hyperbolic space, as well as metric trees and more general CAT(0) cubical complexes, supports primal tools like proximal operations for geodesically convex functions. However, the lack of linear structure in such spaces complicates dual constructions like subgradients. To address this hurdle, we introduce a new type of subgradient for functions on Hadamard spaces, based on Busemann functions. Our notion supports generalizations of classical stochastic and incremental subgradient methods, with guaranteed complexity bounds. We illustrate with subgradient algorithms for $p$-mean problems in general Hadamard spaces, in particular computing medians in BHV tree space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06730v3</guid>
      <category>math.OC</category>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Goodwin, Adrian S. Lewis, Genaro L\'opez-Acedo, Adriana Nicolae</dc:creator>
    </item>
    <item>
      <title>HYLU: Hybrid Parallel Sparse LU Factorization</title>
      <link>https://arxiv.org/abs/2509.07690</link>
      <description>arXiv:2509.07690v4 Announce Type: replace-cross 
Abstract: This article introduces HYLU, a hybrid parallel LU factorization-based general-purpose solver designed for efficiently solving sparse linear systems (Ax=b) on multi-core shared-memory architectures. The key technical feature of HYLU is the integration of hybrid numerical kernels so that it can adapt to various sparsity patterns of coefficient matrices. Tests on 34 sparse matrices from SuiteSparse Matrix Collection reveal that HYLU outperforms Intel MKL PARDISO in the numerical factorization phase by geometric means of 1.95X (for one-time solving) and 2.40X (for repeated solving). HYLU can be downloaded from https://github.com/chenxm1986/hylu.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07690v4</guid>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoming Chen</dc:creator>
    </item>
    <item>
      <title>Time-causal and time-recursive wavelets</title>
      <link>https://arxiv.org/abs/2510.05834</link>
      <description>arXiv:2510.05834v2 Announce Type: replace-cross 
Abstract: When to apply wavelet analysis to real-time temporal signals, where the future cannot be accessed, it is essential to base all the steps in the signal processing pipeline on computational mechanisms that are truly time-causal.
  This paper describes how a time-causal wavelet analysis can be performed based on concepts developed in the area of temporal scale-space theory, originating from a complete classification of temporal smoothing kernels that guarantee non-creation of new structures from finer to coarser temporal scale levels. By necessity, convolution with truncated exponential kernels in cascade constitutes the only permissable class of kernels, as well as their temporal derivatives as a natural complement to fulfil the admissibility conditions of wavelet representations. For a particular way of choosing the time constants in the resulting infinite convolution of truncated exponential kernels, to ensure temporal scale covariance and thus self-similarity over temporal scales, we describe how mother wavelets can be chosen as temporal derivatives of the resulting time-causal limit kernel.
  By developing connections between wavelet theory and scale-space theory, we characterize and quantify how the continuous scaling properties transfer to the discrete implementation, demonstrating how the proposed time-causal wavelet representation can reflect the duration of locally dominant temporal structures in the input signals.
  We propose that this notion of time-causal wavelet analysis could be a valuable tool for signal processing tasks, where streams of signals are to be processed in real time, specifically for signals that may contain local variations over a rich span of temporal scales, or more generally for analysing physical or biophysical temporal phenomena, where a fully time-causal analysis is called for to be physically realistic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05834v2</guid>
      <category>eess.SP</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.IV</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Lindeberg</dc:creator>
    </item>
  </channel>
</rss>
