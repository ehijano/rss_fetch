<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Dec 2025 02:34:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the Complexity of Signed Roman Domination</title>
      <link>https://arxiv.org/abs/2512.02083</link>
      <description>arXiv:2512.02083v1 Announce Type: new 
Abstract: Given a graph $G = (V, E)$, a signed Roman dominating function is a function $f: V \rightarrow \{-1, 1, 2\}$ such that for every vertex $u \in V$: $\sum_{v \in N[u]} f(v) \geq 1$ and for every vertex $u \in V$ with $f(u) = -1$, there exists a vertex $v \in N(u)$ with $f(v) = 2$. The weight of a signed Roman dominating function $f$ is $\sum_{u \in V} f(u)$. The objective of \srd{} (SRD) problem is to compute a signed Roman dominating function with minimum weight. The problem is known to be NP-complete even when restricted to bipartite graphs and planar graphs. In this paper, we advance the complexity study by showing that the problem remains NP-complete on split graphs. In the realm of parameterized complexity, we prove that the problem is W[2]-hard parameterized by weight, even on bipartite graphs. We further show that the problem is W[1]-hard parameterized by feedback vertex set number (and hence also when parameterized by treewidth or clique-width). On the positive side, we present an FPT algorithm parameterized by neighbourhood diversity (and by vertex cover number). Finally, we complement this result by proving that the problem does not admit a polynomial kernel parameterized by vertex cover number unless coNP $\subseteq$ NP/poly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02083v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sangam Balchandar Reddy</dc:creator>
    </item>
    <item>
      <title>Optimal-Length Labeling Schemes and Fast Algorithms for k-gathering and k-broadcasting</title>
      <link>https://arxiv.org/abs/2512.02252</link>
      <description>arXiv:2512.02252v2 Announce Type: new 
Abstract: We consider basic communication tasks in arbitrary radio networks: $k$-broadcasting and $k$-gathering. In the case of $k$-broadcasting messages from $k$ sources have to get to all nodes in the network. The goal of $k$-gathering is to collect messages from $k$ source nodes in a designated sink node. We consider these problems in the framework of distributed algorithms with advice. Krisko and Miller showed in 2021 that the optimal size of advice for $k$-broadcasting is $\Theta(\min(\log \Delta,$ $ \log k))$, where $\Delta$ is equal to the maximum degree of a vertex of the input communication graph. We show that the same bound $\Theta(\min(\log \Delta, \log k))$ on the size of optimal labeling scheme holds also for the $k$-gathering problems. Moreover, we design fast algorithms for both problems with asymptotically optimal size of advice. For $k$-gathering our algorithm works in at most $D+k$ rounds, where $D$ is the diameter of the communication graph. This time bound is optimal even for centralized algorithms. We apply the $k$-gathering algorithm for $k$-broadcasting to achieve an algorithm working in time $O(D+\log^2 n+k)$ rounds. We also exhibit a logarithmic time complexity gap between distributed algorithms with advice of optimal size and distributed algorithms with distinct arbitrary labels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02252v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adam Ganczorz, Tomasz Jurdzinski</dc:creator>
    </item>
    <item>
      <title>Markov Chains Approximate Message Passing</title>
      <link>https://arxiv.org/abs/2512.02384</link>
      <description>arXiv:2512.02384v2 Announce Type: new 
Abstract: Markov chain Monte Carlo algorithms have long been observed to obtain near-optimal performance in various Bayesian inference settings. However, developing a supporting theory that makes these studies rigorous has proved challenging.
  In this paper, we study the classical spiked Wigner inference problem, where one aims to recover a planted Boolean spike from a noisy matrix measurement. We relate the recovery performance of Glauber dynamics on the annealed posterior to the performance of Approximate Message Passing (AMP), which is known to achieve Bayes-optimal performance. Our main results rely on the analysis of an auxiliary Markov chain called restricted Gaussian dynamics (RGD). Concretely, we establish the following results:
  1. RGD can be reduced to an effective one-dimensional recursion which mirrors the evolution of the AMP iterates.
  2. From a warm start, RGD rapidly converges to a fixed point in correlation space, which recovers Bayes-optimal performance when run on the posterior.
  3. Conditioned on widely believed mixing results for the SK model, we recover the phase transition for non-trivial inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02384v2</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amit Rajaraman, David X. Wu</dc:creator>
    </item>
    <item>
      <title>New Bounds for Circular Trace Reconstruction</title>
      <link>https://arxiv.org/abs/2512.02412</link>
      <description>arXiv:2512.02412v1 Announce Type: new 
Abstract: The ''trace reconstruction'' problem asks, given an unknown binary string $x$ and a channel that repeatedly returns ''traces'' of $x$ with each bit randomly deleted with some probability $p$, how many traces are needed to recover $x$? There is an exponential gap between the best known upper and lower bounds for this problem. Many variants of the model have been introduced in hopes of motivating or revealing new approaches to narrow this gap. We study the variant of circular trace reconstruction introduced by Narayanan and Ren (ITCS 2021), in which traces undergo a random cyclic shift in addition to random deletions.
  We show an improved lower bound of $\tilde{\Omega}(n^5)$ for circular trace reconstruction. This contrasts with the (previously) best known lower bounds of $\tilde{\Omega}(n^3)$ in the circular case and $\tilde{\Omega}(n^{3/2})$ in the linear case. Our bound shows the indistinguishability of traces from two sparse strings $x,y$ that each have a constant number of nonzeros. Can this technique be extended significantly? How hard is it to reconstruct a sparse string $x$ under a cyclic deletion channel? We resolve these questions by showing, using Fourier techniques, that $\tilde{O}(n^6)$ traces suffice for reconstructing any constant-sparse string in a circular deletion channel, in contrast to the upper bound of $\exp(\tilde{O}(n^{1/3}))$ for general strings in the circular deletion channel. This shows that new algorithms or new lower bounds must focus on non-constant-sparse strings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02412v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnav Burudgunte, Paul Valiant, Hongao Wang</dc:creator>
    </item>
    <item>
      <title>Approximation schemes for covering and packing mixed-integer programs with a fixed number of constraints</title>
      <link>https://arxiv.org/abs/2512.02571</link>
      <description>arXiv:2512.02571v1 Announce Type: new 
Abstract: This paper presents an algorithmic study of a class of covering mixed-integer linear programming problems which encompasses classic cover problems, including multidimensional knapsack, facility location and supplier selection problems. We first show some properties of the vertices of the associated polytope, which are then used to decompose the problem into instances of the multidimensional knapsack cover problem with a single continuous variable per dimension. The proposed decomposition is used to design a polynomial-time approximation scheme for the problem with a fixed number of constraints. To the best of our knowledge, this is the first approximation scheme for such a general class of covering mixed-integer programs. Moreover, we design a fully polynomial-time approximation scheme and an approximate linear programming formulation for the case with a single constraint. These results improve upon the previously best-known 2-approximation algorithm for the knapsack cover problem with a single continuous variable. Finally, we show a perfect compact formulation for the case where all variables have the same lower and upper bounds. Analogous results are derived for the packing and assignment variants of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02571v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kobe Grobben, Phablo F. S. Moura, Hande Yaman</dc:creator>
    </item>
    <item>
      <title>The Support of Bin Packing is Exponential</title>
      <link>https://arxiv.org/abs/2512.02758</link>
      <description>arXiv:2512.02758v1 Announce Type: new 
Abstract: Consider the classical Bin Packing problem with $d$ different item sizes $s_i$ and amounts of items $a_i.$ The support of a Bin Packing solution is the number of differently filled bins. In this work, we show that the lower bound on the support of this problem is $2^{\Omega(d)}$. Our lower bound matches the upper bound of $2^d$ given by Eisenbrand and Shmonin [Oper.Research Letters '06] up to a constant factor. This result has direct implications for the time complexity of several Bin Packing algorithms, such as Goemans and Rothvoss [SODA '14], Jansen and Klein [SODA '17] and Jansen and Solis-Oba [IPCO '10]. To achieve our main result, we develop a technique to aggregate equality constrained ILPs with many constraints into an equivalent ILP with one constraint. Our technique contrasts existing aggregation techniques as we manage to integrate upper bounds on variables into the resulting constraint. We believe this technique can be useful for solving general ILPs or the $d$-dimensional knapsack problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02758v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Klaus Jansen, Lis Pirotton, Malte Tutas</dc:creator>
    </item>
    <item>
      <title>BD-Index: Scalable Biharmonic Distance Queries on Large Graphs via Divide-and-Conquer Indexing</title>
      <link>https://arxiv.org/abs/2512.02929</link>
      <description>arXiv:2512.02929v1 Announce Type: new 
Abstract: Biharmonic distance (\bd) is a powerful graph distance metric with many applications, including identifying critical links in road networks and mitigating over-squashing problem in \gnn. However, computing \bd\ is extremely difficult, especially on large graphs. In this paper, we focus on the problem of \emph{single-pair} \bd\ query. Existing methods mainly rely on random walk-based approaches, which work well on some graphs but become inefficient when the random walk cannot mix rapidly.To overcome this issue, we first show that the biharmonic distance between two nodes $s,t$, denoted by $b(s,t)$, can be interpreted as the distance between two random walk distributions starting from $s$ and $t$. To estimate these distributions, the required random walk length is large when the underlying graph can be easily cut into smaller pieces. Inspired by this observation, we present novel formulas of \bd to represent $b(s,t)$ by independent random walks within two node sets $\mathcal{V}_s$, $\mathcal{V}_t$ separated by a small \emph{cut set} $\mathcal{V}_{cut}$, where $\mathcal{V}_s\cup\mathcal{V}_t\cup\mathcal{V}_{cut}=\mathcal{V}$ is the set of graph nodes. Building upon this idea, we propose \bindex, a novel index structure which follows a divide-and-conquer strategy. The graph is first cut into pieces so that each part can be processed easily. Then, all the required random walk probabilities can be deterministically computed in a bottom-top manner. When a query comes, only a small part of the index needs to be accessed. We prove that \bindex\ requires $O(n\cdot h)$ space, can be built in $O(n\cdot h\cdot (h+d_{max}))$ time, and answers each query in $O(n\cdot h)$ time, where $h$ is the height of a hierarchy partition tree and $d_{max}$ is the maximum degree, which are both usually much smaller than $n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02929v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yueyang Pan, Meihao Liao, Rong-Hua Li</dc:creator>
    </item>
    <item>
      <title>Limitations of Membership Queries in Testable Learning</title>
      <link>https://arxiv.org/abs/2512.02279</link>
      <description>arXiv:2512.02279v1 Announce Type: cross 
Abstract: Membership queries (MQ) often yield speedups for learning tasks, particularly in the distribution-specific setting. We show that in the \emph{testable learning} model of Rubinfeld and Vasilyan [RV23], membership queries cannot decrease the time complexity of testable learning algorithms beyond the complexity of sample-only distribution-specific learning. In the testable learning model, the learner must output a hypothesis whenever the data distribution satisfies a desired property, and if it outputs a hypothesis, the hypothesis must be near-optimal.
  We give a general reduction from sample-based \emph{refutation} of boolean concept classes, as presented in [Vadhan17, KL18], to testable learning with queries (TL-Q). This yields lower bounds for TL-Q via the reduction from learning to refutation given in [KL18]. The result is that, relative to a concept class and a distribution family, no $m$-sample TL-Q algorithm can be super-polynomially more time-efficient than the best $m$-sample PAC learner.
  Finally, we define a class of ``statistical'' MQ algorithms that encompasses many known distribution-specific MQ learners, such as those based on influence estimation or subcube-conditional statistical queries. We show that TL-Q algorithms in this class imply efficient statistical-query refutation and learning algorithms. Thus, combined with known SQ dimension lower bounds, our results imply that these efficient membership query learners cannot be made testable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02279v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jane Lange, Mingda Qiao</dc:creator>
    </item>
    <item>
      <title>Posted Pricing for Online Selection: Limited Price Changes and Risk Sensitivity</title>
      <link>https://arxiv.org/abs/2512.02427</link>
      <description>arXiv:2512.02427v1 Announce Type: cross 
Abstract: Posted-price mechanisms (PPMs) are a widely adopted strategy for online resource allocation due to their simplicity, intuitive nature, and incentive compatibility. To manage the uncertainty inherent in online settings, PPMs commonly employ dynamically increasing prices. While this adaptive pricing achieves strong performance, it introduces practical challenges: dynamically changing prices can lead to fairness concerns stemming from price discrimination and incur operational costs associated with frequent updates. This paper addresses these issues by investigating posted pricing constrained by a limited, pre-specified number of allowed price changes, denoted by $\Delta$. We further extend this framework by incorporating a second critical dimension: risk sensitivity. Instead of evaluating performance based solely on expectation, we utilize a tail-risk objective-specifically, the Conditional Value at Risk (CVaR) of the total social welfare, parameterized by a risk level $\delta \in [0, 1]$.
  We formally introduce a novel problem class kSelection-$(\delta,\Delta)$ in online adversarial selection and propose a correlated PPM that utilizes a single random seed to correlate posted prices. This correlation scheme is designed to address both the limited price changes and simultaneously enhance the tail performance of the online algorithm. Our subsequent analysis provides performance guarantees under these joint constraints, revealing a clear trade-off between the number of allowed price changes and the algorithm's risk sensitivity. We also establish optimality results for several important special cases of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02427v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hossein Nekouyan, Bo Sun, Raouf Boutaba, Xiaoqi Tan</dc:creator>
    </item>
    <item>
      <title>A Tight Double-Exponentially Lower Bound for High-Multiplicity Bin Packing</title>
      <link>https://arxiv.org/abs/2512.02691</link>
      <description>arXiv:2512.02691v1 Announce Type: cross 
Abstract: Consider a high-multiplicity Bin Packing instance $I$ with $d$ distinct item types. In 2014, Goemans and Rothvoss gave an algorithm with runtime ${{|I|}^2}^{O(d)}$ for this problem~[SODA'14], where $|I|$ denotes the encoding length of the instance $I$. Although, Jansen and Klein~[SODA'17] later developed an algorithm that improves upon this runtime in a special case, it has remained a major open problem by Goemans and Rothvoss~[J.ACM'20] whether the doubly exponential dependency on $d$ is necessary.
  We solve this open problem by showing that unless the ETH fails, there is no algorithm solving the high-multiplicity Bin Packing problem in time ${{|I|}^2}^{o(d)}$. To prove this, we introduce a novel reduction from 3-SAT. The core of our construction is efficiently encoding the entire information from a 3-SAT instance with $n$ variables into an ILP with $O(\log(n))$ variables.
  This result confirms that the Goemans and Rothvoss algorithm is best-possible for Bin Packing parameterized by the number $d$ of item sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02691v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Klaus Jansen, Felix Ohnesorge, Lis Pirotton</dc:creator>
    </item>
    <item>
      <title>Sampling Permutations with Cell Probes is Hard</title>
      <link>https://arxiv.org/abs/2512.02724</link>
      <description>arXiv:2512.02724v1 Announce Type: cross 
Abstract: Suppose we are given an infinite sequence of input cells, each initialized with a uniform random symbol from $[n]$. How hard is it to output a sequence in $[n]^n$ that is close to a uniform random permutation? Viola (SICOMP 2020) conjectured that if each output cell is computed by making $d$ probes to input cells, then $d\geq\omega(1)$. Our main result shows that, in fact, $d\geq (\log n)^{\Omega(1)}$, which is tight up to the constant in the exponent. Our techniques also show that if the probes are nonadaptive, then $d\geq n^{\Omega(1)}$, which is an exponential improvement over the previous nonadaptive lower bound due to Yu and Zhan (ITCS 2024). Our results also imply lower bounds against succinct data structures for storing permutations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02724v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaroslav Alekseev, Mika G\"o\"os, Konstantin Myasnikov, Artur Riazanov, Dmitry Sokolov</dc:creator>
    </item>
    <item>
      <title>Revisiting a Successful Reduction Rule for Dominating Set</title>
      <link>https://arxiv.org/abs/2506.14564</link>
      <description>arXiv:2506.14564v2 Announce Type: replace 
Abstract: Given a graph $G = (V, E)$ with $n$ vertices and $m$ edges, the DominatingSet problem asks for a set $D \subseteq V$ of minimal cardinality such that every vertex either is in $D$ or adjacent to a member of $D$. Although there is little hope for a kernelization algorithm on general graphs due to the W[2]-hardness of DominatingSet, data reduction rules are extensively used in practice. In this context, Rule1 due to Alber, Fellows, and Niedermeier [JACM 2004] has been shown to be very powerful, yet its best-known running time is $\mathcal{O}(n^3)$ ($= \mathcal{O}(nm)$) for general graphs. In this work, we propose, to the best of our knowledge, the first $\mathcal{O}(n + m)$-time algorithm for Rule1 on general graphs. We additionally propose simple, but practically significant, extensions to our algorithmic framework to further prune the input instances. We complement our theoretical claims with experiments that confirm the practicality of our approach. On average, we see significant speedups of over one order of magnitude while removing $59.8\times$ more nodes and $410.9\times$ more edges than the original formulation across a large dataset comprised of real-world and synthetic networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14564v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Geis, Alexander Leonhardt, Johannes Meintrup, Ulrich Meyer, Manuel Penschuck, Lukas Retschmeier</dc:creator>
    </item>
    <item>
      <title>An Exponential Separation Between Quantum and Quantum-Inspired Classical Algorithms for Linear Systems</title>
      <link>https://arxiv.org/abs/2411.02087</link>
      <description>arXiv:2411.02087v5 Announce Type: replace-cross 
Abstract: Achieving a provable exponential quantum speedup for an important machine learning task has been a central research goal since the seminal HHL quantum algorithm for solving linear systems and the subsequent quantum recommender systems algorithm by Kerenidis and Prakash. These algorithms were initially believed to be strong candidates for exponential speedups, but a lower bound ruling out similar classical improvements remained absent. In breakthrough work by Tang, it was demonstrated that this lack of progress in classical lower bounds was for good reasons. Concretely, she gave a classical counterpart of the quantum recommender systems algorithm, reducing the quantum advantage to a mere polynomial. Her approach is quite general and was named quantum-inspired classical algorithms. Since then, almost all the initially exponential quantum machine learning speedups have been reduced to polynomial via new quantum-inspired classical algorithms. From the current state-of-affairs, it is unclear whether we can hope for exponential quantum speedups for any natural machine learning task.
  In this work, we present the first such provable exponential separation between quantum and quantum-inspired classical algorithms for the basic problem of solving a linear system when the input matrix is well-conditioned and has sparse rows and columns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02087v5</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Allan Gr{\o}nlund, Kasper Green Larsen</dc:creator>
    </item>
    <item>
      <title>Optimal Binary Variable-Length Codes with a Bounded Number of 1's per Codeword: Design, Analysis, and Applications</title>
      <link>https://arxiv.org/abs/2501.11129</link>
      <description>arXiv:2501.11129v3 Announce Type: replace-cross 
Abstract: In this paper, we consider the problem of constructing optimal average-length binary codes under the constraint that each codeword must contain at most $D$ ones, where $D$ is a given input parameter. We provide an $O(n^2D)$-time complexity algorithm for the construction of such codes, where $n$ is the number of codewords. We also describe several scenarios where the need to design these kinds of codes naturally arises. We also provide a Kraft-like inequality for the existence of (optimal) variable-length binary codes, subject to the above-described constraint on the number of 1's in each codeword.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11129v3</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Bruno, Roberto De Prisco, Ugo Vaccaro</dc:creator>
    </item>
    <item>
      <title>Efficient Turing Machine Simulation with Transformers</title>
      <link>https://arxiv.org/abs/2512.00003</link>
      <description>arXiv:2512.00003v2 Announce Type: replace-cross 
Abstract: Constant bit-size Transformers are known to be Turing complete, but existing constructions require $\Omega(s(n))$ chain-of-thought (CoT) steps per simulated Turing machine (TM) step, leading to impractical reasoning lengths. In this paper, we significantly reduce this efficiency gap by proving that any $(t(n),s(n))$-bounded multi-tape TM can be simulated by a constant bit-size Transformer with an optimal $O(s(n))$-long context window and only $O(s(n)^c)$ CoT steps per TM step, where $c&gt;0$ can be made arbitrarily small by letting the Transformers' head-layer product sufficiently large. In addition, our construction shows that sparse attention with fixed geometric offsets suffices for efficient universal computation. Our proof leverages multi-queue TMs as a bridge. The main technical novelty is a more efficient simulation of multi-tape TMs by synchronous multi-queue TMs, improving both time and space complexity under stricter model assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00003v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qian Li, Yuyi Wang</dc:creator>
    </item>
  </channel>
</rss>
