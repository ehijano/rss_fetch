<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Oct 2025 01:42:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>From Unweighted to Weighted Dynamic Matching in Non-Bipartite Graphs: A Low-Loss Reduction</title>
      <link>https://arxiv.org/abs/2510.19049</link>
      <description>arXiv:2510.19049v1 Announce Type: new 
Abstract: We study the approximate maximum weight matching (MWM) problem in a fully dynamic graph subject to edge insertions and deletions. We design meta-algorithms that reduce the problem to the unweighted approximate maximum cardinality matching (MCM) problem. Despite recent progress on bipartite graphs -- Bernstein-Dudeja-Langley (STOC 2021) and Bernstein-Chen-Dudeja-Langley-Sidford-Tu (SODA 2025) -- the only previous meta-algorithm that applied to non-bipartite graphs suffered a $\frac{1}{2}$ approximation loss (Stubbs-Williams, ITCS 2017). We significantly close the weighted-and-unweighted gap by showing the first low-loss reduction that transforms any fully dynamic $(1-\varepsilon)$-approximate MCM algorithm on bipartite graphs into a fully dynamic $(1-\varepsilon)$-approximate MWM algorithm on general (not necessarily bipartite) graphs, with only a $\mathrm{poly}(\log n/\varepsilon)$ overhead in the update time. Central to our approach is a new primal-dual framework that reduces the computation of an approximate MWM in general graphs to a sequence of approximate induced matching queries on an auxiliary bipartite extension. In addition, we give the first conditional lower bound on approximate partially dynamic matching with worst-case update time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19049v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Bernstein, Jiale Chen</dc:creator>
    </item>
    <item>
      <title>Succinct Dynamic Rank/Select: Bypassing the Tree-Structure Bottleneck</title>
      <link>https://arxiv.org/abs/2510.19175</link>
      <description>arXiv:2510.19175v1 Announce Type: new 
Abstract: We show how to construct a dynamic ordered dictionary, supporting insert/delete/rank/select on a set of $n$ elements from a universe of size $U$, that achieves the optimal amortized expected time complexity of $O(1 + \log n / \log \log U)$, while achieving a nearly optimal space consumption of $\log \binom{U}{n} + n / 2^{(\log n)^{\Omega(1)}} + \text{polylog}\, U$ bits in the regime where $U = \text{poly}(n)$. This resolves an open question by Pibiri and Venturini as to whether a redundancy (a.k.a. space overhead) of $o(n)$ bits is possible, and is the first dynamic solution to bypass the so-called tree-structure bottleneck, in which the bits needed to encode some dynamic tree structure are themselves enough to force a redundancy of $\widetilde{\Omega}(n)$ bits. Our main technical building block is a dynamic balanced binary search tree, which we call the compressed tabulation-weighted treap, that itself achieves a surprising time/space tradeoff. The tree supports $\text{polylog}\, n$-time operations and requires a static lookup table of size $\text{poly}(n) + \text{polylog}\, U$ -- but, in exchange for these, the tree is able to achieve a remarkable space guarantee. Its total space redundancy is $O(\log U)$ bits. In fact, if the tree is given $n$ and $U$ for free, then the redundancy further drops to $O(1)$ bits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19175v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William Kuszmaul, Jingxun Liang, Renfei Zhou</dc:creator>
    </item>
    <item>
      <title>Online Two-Stage Submodular Maximization</title>
      <link>https://arxiv.org/abs/2510.19480</link>
      <description>arXiv:2510.19480v1 Announce Type: new 
Abstract: Given a collection of monotone submodular functions, the goal of Two-Stage Submodular Maximization (2SSM) [Balkanski et al., 2016] is to restrict the ground set so an objective selected u.a.r. from the collection attains a high maximal value, on average, when optimized over the restricted ground set. We introduce the Online Two-Stage Submodular Maximization (O2SSM) problem, in which the submodular objectives are revealed in an online fashion. We study this problem for weighted threshold potential functions, a large and important subclass of monotone submodular functions that includes influence maximization, data summarization, and facility location, to name a few. We design an algorithm that achieves sublinear $(1 - 1/e)^2$-regret under general matroid constraints and $(1 - 1/e)(1-e^{-k}k^k/k!)$-regret in the case of uniform matroids of rank $k$; the latter also yields a state-of-the-art bound for the (offline) 2SSM problem. We empirically validate the performance of our online algorithm with experiments on real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19480v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iasonas Nikolaou, Miltiadis Stouras, Stratis Ioannidis, Evimaria Terzi</dc:creator>
    </item>
    <item>
      <title>Optimal Random Access and Conditional Lower Bounds for 2D Compressed Strings</title>
      <link>https://arxiv.org/abs/2510.19750</link>
      <description>arXiv:2510.19750v1 Announce Type: new 
Abstract: Compressed indexing is a powerful technique that enables efficient querying over data stored in compressed form, significantly reducing memory usage and often accelerating computation. While extensive progress has been made for one-dimensional strings, many real-world datasets (such as images, maps, and adjacency matrices) are inherently two-dimensional and highly compressible. Unfortunately, naively applying 1D techniques to 2D data leads to suboptimal results, as fundamental structural repetition is lost during linearization. This motivates the development of native 2D compressed indexing schemes that preserve both compression and query efficiency.
  We present three main contributions that advance the theory of compressed indexing for 2D strings: (1) We design the first data structure that supports optimal-time random access to a 2D string compressed by a 2D grammar. Specifically, for a 2D string $T\in\Sigma^{r\times c}$ compressed by a 2D grammar $G$ and any constant $\epsilon&gt;0$, we achieve $O(\log n/\log \log n)$ query time and $O(|G|\log^{2+\epsilon}n)$ space, where $n=\max(r,c)$. (2) We prove conditional lower bounds for pattern matching over 2D-grammar compressed strings. Assuming the Orthogonal Vectors Conjecture, no algorithm can solve this problem in time $O(|G|^{2-\epsilon}\cdot |P|^{O(1)})$ for any $\epsilon&gt;0$, demonstrating a separation from the 1D case, where optimal solutions exist. (3) We show that several fundamental 2D queries, such as the 2D longest common extension, rectangle sum, and equality, cannot be supported efficiently under hardness assumptions for rank and symbol occurrence queries on 1D grammar-compressed strings. This is the first evidence connecting the complexity of 2D compressed indexing to long-standing open problems in the 1D setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19750v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rajat De, Dominik Kempa</dc:creator>
    </item>
    <item>
      <title>Strongly Polynomial Parallel Work-Depth Tradeoffs for Directed SSSP</title>
      <link>https://arxiv.org/abs/2510.19780</link>
      <description>arXiv:2510.19780v1 Announce Type: new 
Abstract: In this paper, we show new strongly polynomial work-depth tradeoffs for computing single-source shortest paths (SSSP) in non-negatively weighted directed graphs in parallel. Most importantly, we prove that directed SSSP can be solved within $\tilde{O}(m+n^{2-\epsilon})$ work and $\tilde{O}(n^{1-\epsilon})$ depth for some positive $\epsilon&gt;0$. In particular, for dense graphs with non-negative real weights, we provide the first nearly work-efficient strongly polynomial algorithm with sublinear depth.
  Our result immediately yields improved strongly polynomial parallel algorithms for min-cost flow and the assignment problem. It also leads to the first non-trivial strongly polynomial dynamic algorithm for minimum mean cycle. Moreover, we develop efficient parallel algorithms in the Word RAM model for several variants of SSSP in graphs with exponentially large edge weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19780v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adam Karczmarz, Wojciech Nadara, Marek Soko{\l}owski</dc:creator>
    </item>
    <item>
      <title>A Logic-based Algorithmic Meta-Theorem for Treedepth: Single Exponential FPT Time and Polynomial Space</title>
      <link>https://arxiv.org/abs/2510.19793</link>
      <description>arXiv:2510.19793v1 Announce Type: new 
Abstract: For a graph $G$, the parameter treedepth measures the minimum depth among all forests $F$, called elimination forests, such that $G$ is a subgraph of the ancestor-descendant closure of $F$. We introduce a logic, called neighborhood operator logic with acyclicity, connectivity and clique constraints ($\mathsf{NEO}_2[\mathsf{FRec}]+\mathsf{ACK}$ for short), that captures all NP-hard problems$\unicode{x2013}$like Independent Set or Hamiltonian Cycle$\unicode{x2013}$that are known to be tractable in time $2^{\mathcal{O}(k)}n^{\mathcal{O}(1)}$ and space $n^{\mathcal{O}(1)}$ on $n$-vertex graphs provided with elimination forests of depth $k$. We provide a model checking algorithm for $\mathsf{NEO}_2[\mathsf{FRec}]+\mathsf{ACK}$ with such complexity that unifies and extends these results. For $\mathsf{NEO}_2[\mathsf{FRec}]+\mathsf{k}$, the fragment of the above logic that does not use acyclicity and connectivity constraints, we get a strengthening of this result, where the space complexity is reduced to $\mathcal{O}(k\log(n))$.
  With a similar mechanism as the distance neighborhood logic introduced in [Bergougnoux, Dreier and Jaffke, SODA 2023], the logic $\mathsf{NEO}_2[\mathsf{FRec}]+\mathsf{ACK}$ is an extension of the fully-existential $\mathsf{MSO}_2$ with predicates for (1) querying generalizations of the neighborhoods of vertex sets, (2) verifying the connectivity and acyclicity of vertex and edge sets, and (3) verifying that a vertex set induces a clique. Our results provide $2^{\mathcal{O}(k)}n^{\mathcal{O}(1)}$ time and $n^{\mathcal{O}(1)}$ space algorithms for problems for which the existence of such algorithms was previously unknown. In particular, $\mathsf{NEO}_2[\mathsf{FRec}]$ captures CNF-SAT via the incidence graphs associated to CNF formulas, and it also captures several modulo counting problems like Odd Dominating Set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19793v1</guid>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Bergougnoux, Vera Chekan, Giannos Stamoulis</dc:creator>
    </item>
    <item>
      <title>Explaining the Inherent Tradeoffs for Suffix Array Functionality: Equivalences between String Problems and Prefix Range Queries</title>
      <link>https://arxiv.org/abs/2510.19815</link>
      <description>arXiv:2510.19815v1 Announce Type: new 
Abstract: We study the fundamental question of how efficiently suffix array entries can be accessed when the array cannot be stored explicitly. The suffix array $SA_T[1..n]$ of a text $T$ of length $n$ encodes the lexicographic order of its suffixes and underlies numerous applications in pattern matching, data compression, and bioinformatics. Previous work established one-way reductions showing how suffix array queries can be answered using, for example, rank queries on the Burrows-Wheeler Transform. More recently, a new class of prefix queries was introduced, together with reductions that, among others, transform a simple tradeoff for prefix-select queries into a suffix array tradeoff matching state-of-the-art space and query-time bounds, while achieving sublinear construction time. For binary texts, the resulting data structure achieves space $O(n)$ bits, preprocessing time $O(n / \sqrt{\log n})$, preprocessing space of $O(n)$ bits, and query time $O(\log^{\epsilon} n)$ for any constant $\epsilon &gt; 0$. However, whether these bounds could be improved using different techniques has remained open.
  We resolve this question by presenting the first bidirectional reduction showing that suffix array queries are, up to an additive $O(\log\log n)$ term in query time, equivalent to prefix-select queries in all parameters. This result unifies prior approaches and shows that essentially all efficient suffix array representations can be expressed via prefix-select structures. Moreover, we prove analogous equivalences for inverse suffix array queries, pattern ranking, lexicographic range, and SA-interval queries, identifying six core problem pairs that connect string and prefix query models. Our framework thus provides a unified foundation for analyzing and improving the efficiency of fundamental string-processing problems through the lens of prefix queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19815v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominik Kempa, Tomasz Kociumaka</dc:creator>
    </item>
    <item>
      <title>Tight Lower Bounds for Central String Queries in Compressed Space</title>
      <link>https://arxiv.org/abs/2510.19820</link>
      <description>arXiv:2510.19820v1 Announce Type: new 
Abstract: In this work, we study the limits of compressed data structures, i.e., structures that support various queries on an input text $T\in\Sigma^n$ using space proportional to the size of $T$ in compressed form. Nearly all fundamental queries can currently be efficiently supported in $O(\delta(T)\log^{O(1)}n)$ space, where $\delta(T)$ is the substring complexity, a strong compressibility measure that lower-bounds the optimal space to represent the text [Kociumaka, Navarro, Prezza, IEEE Trans. Inf. Theory 2023]. However, optimal query time has been characterized only for random access.
  We address this gap by developing tight lower bounds for nearly all other fundamental queries: (1) We prove that suffix array (SA), inverse suffix array (SA$^{-1}$), longest common prefix (LCP) array, and longest common extension (LCE) queries all require $\Omega(\log n/\log\log n)$ time within $O(\delta(T)\log^{O(1)}n)$ space, matching known upper bounds. (2) We further show that other common queries, currently supported in $O(\log\log n)$ time and $O(\delta(T)\log^{O(1)}n)$ space, including the Burrows-Wheeler Transform (BWT), permuted longest common prefix (PLCP) array, Last-to-First (LF), inverse LF, lexicographic predecessor ($\Phi$), and inverse $\Phi$ queries, all require $\Omega(\log\log n)$ time, yielding another set of tight bounds.
  Our lower bounds hold even for texts over a binary alphabet. This work establishes a clean dichotomy: the optimal time complexity to support central string queries in compressed space is either $\Theta(\log n/\log\log n)$ or $\Theta(\log\log n)$. This completes the theoretical foundation of compressed indexing, closing a crucial gap between upper and lower bounds and providing a clear target for future data structures: seeking either the optimal time in the smallest space or the fastest time in the optimal space, both of which are now known for central string queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19820v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominik Kempa, Tomasz Kociumaka</dc:creator>
    </item>
    <item>
      <title>On the Randomized Locality of Matching Problems in Regular Graphs</title>
      <link>https://arxiv.org/abs/2510.19151</link>
      <description>arXiv:2510.19151v1 Announce Type: cross 
Abstract: The main goal in distributed symmetry-breaking is to understand the locality of problems; i.e., the radius of the neighborhood that a node needs to explore in order to arrive at its part of a global solution. In this work, we study the locality of matching problems in the family of regular graphs, which is one of the main benchmarks for establishing lower bounds on the locality of symmetry-breaking problems, as well as for obtaining classification results. For approximate matching, we develop randomized algorithms to show that $(1 + \epsilon)$-approximate matching in regular graphs is truly local; i.e., the locality depends only on $\epsilon$ and is independent of all other graph parameters. Furthermore, as long as the degree $\Delta$ is not very small (namely, as long as $\Delta \geq \text{poly}(1/\epsilon)$), this dependence is only logarithmic in $1/\epsilon$. This stands in sharp contrast to maximal matching in regular graphs which requires some dependence on the number of nodes $n$ or the degree $\Delta$. We show matching lower bounds for both results. For maximal matching, our techniques further allow us to establish a strong separation between the node-averaged complexity and worst-case complexity of maximal matching in regular graphs, by showing that the former is only $O(1)$. Central to our main technical contribution is a novel martingale-based analysis for the $\approx 40$-year-old algorithm by Luby. In particular, our analysis shows that applying one round of Luby's algorithm on the line graph of a $\Delta$-regular graph results in an almost $\Delta/2$-regular graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19151v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Seri Khoury, Manish Purohit, Aaron Schild, Joshua Wang</dc:creator>
    </item>
    <item>
      <title>Supermodular Maximization with Cardinality Constraints</title>
      <link>https://arxiv.org/abs/2510.19191</link>
      <description>arXiv:2510.19191v1 Announce Type: cross 
Abstract: Let $V$ be a finite set of $n$ elements, $f: 2^V \rightarrow \mathbb{R}_+$ be a nonnegative monotone supermodular function, and $k$ be a positive integer no greater than $n$. This paper addresses the problem of maximizing $f(S)$ over all subsets $S \subseteq V$ subject to the cardinality constraint $|S| = k$ or $|S|\le k$.
  Let $r$ be a constant integer. The function $f$ is assumed to be {\em $r$-decomposable}, meaning there exist $m\,(\ge1)$ subsets $V_1, \dots, V_m$ of $V$, each with a cardinality at most $r$, and a corresponding set of nonnegative supermodular functions $f_i : 2^{V_i} \rightarrow \mathbb{R}_+$, $i=1,\ldots,m$ such that $f(S) =\sum_{i=1}^m f_i(S \cap V_i)$ holds for each $S \subseteq V$. Given $r$ as an input, we present a polynomial-time $O(n^{(r-1)/2})$-approximation algorithm for this maximization problem, which does not require prior knowledge of the specific decomposition.
  When the decomposition $(V_i,f_i)_{i=1}^m$ is known, an additional connectivity requirement is introduced to the problem. Let $G$ be the graph with vertex set $V$ and edge set $\cup_{i=1}^m \{uv:u,v\in V_i,u\neq v\}$. The cardinality constrained solution set $S$ is required to induce a connected subgraph in $G$. This model generalizes the well-known problem of finding the densest connected $k$-subgraph. We propose a polynomial time $O(n^{(r-1)/2})$-approximation algorithm for this generalization. Notably, this algorithm gives an $O(n^{1/2})$-approximation for the densest connected $k$-subgraph problem, improving upon the previous best-known approximation ratio of $O(n^{2/3})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19191v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xujin Chen, Xiaodong Hu, Changjun Wang, Qingjie Ye</dc:creator>
    </item>
    <item>
      <title>Fine-Grained Dichotomies for Conjunctive Queries with Minimum or Maximum</title>
      <link>https://arxiv.org/abs/2510.19197</link>
      <description>arXiv:2510.19197v1 Announce Type: cross 
Abstract: We investigate the fine-grained complexity of direct access to Conjunctive Query (CQ) answers according to their position, ordered by the minimum (or maximum) value between attributes. We further use the tools we develop to explore a wealth of related tasks. We consider the task of ranked enumeration under min/max orders, as well as tasks concerning CQs with predicates of the form x &lt;= min X , where X is a set of variables and x is a single variable: counting, enumeration, direct access, and predicate elimination (i.e., transforming the pair of query and database to an equivalent pair without min-predicates). For each task, we establish a complete dichotomy for self-join-free CQs, precisely identifying the cases that are solvable in near-ideal time, i.e., (quasi)linear preprocessing time followed by constant or logarithmic time per output.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19197v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nofar Carmeli, Nikolaos Tziavelis</dc:creator>
    </item>
    <item>
      <title>Robust Popular Matchings</title>
      <link>https://arxiv.org/abs/2401.12653</link>
      <description>arXiv:2401.12653v2 Announce Type: replace 
Abstract: We study popularity for matchings under preferences. This solution concept captures matchings that do not lose against any other matching in a majority vote by the agents. A popular matching is said to be robust if it is popular among multiple instances. We present a polynomial-time algorithm for deciding whether there exists a robust popular matching if instances only differ with respect to the preferences of a single agent. The same method applies also to dominant matchings, a subclass of maximum-size popular matchings. By contrast, we obtain NP-completeness if two instances differ only by two agents of the same side or by a swap of two adjacent alternatives by two agents. The first hardness result applies to dominant matchings as well. Moreover, we find another complexity dichotomy based on preference completeness for the case where instances differ by making some options unavailable. We conclude by discussing related models, such as strong and mixed popularity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12653v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Bullinger, Gergely Cs\'aji, Rohith Reddy Gangam, Parnian Shahkar</dc:creator>
    </item>
    <item>
      <title>Parameterized Spanning Tree Congestion</title>
      <link>https://arxiv.org/abs/2410.08314</link>
      <description>arXiv:2410.08314v2 Announce Type: replace 
Abstract: In this paper we study the Spanning Tree Congestion problem, where we are given a graph $G=(V,E)$ and are asked to find a spanning tree $T$ of minimum maximum congestion. Here, the congestion of an edge $e\in T$ is the number of edges $uv\in E$ such that the (unique) path from $u$ to $v$ in $T$ traverses $e$. We consider this well-studied NP-hard problem from the point of view of (structural) parameterized complexity and obtain the following results.
  We resolve a natural open problem by showing that Spanning Tree Congestion is not FPT parameterized by treewidth (under standard assumptions). More strongly, we present a generic reduction which applies to (almost) any parameter of the form ``vertex-deletion distance to class $\mathcal{C}$'', thus obtaining W[1]-hardness for parameters more restricted than treewidth, including tree-depth plus feedback vertex set, or incomparable to treewidth, such as twin cover. Via a slight tweak of the same reduction we also show that the problem is NP-complete on graphs of modular-width $4$.
  Even though it is known that Spanning Tree Congestion remains NP-hard on instances with only one vertex of unbounded degree, it is currently open whether the problem remains hard on bounded-degree graphs. We resolve this question by showing NP-hardness on graphs of maximum degree 8.
  Complementing the problem's W[1]-hardness for treewidth...</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08314v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Lampis, Valia Mitsou, Edouard Nemery, Yota Otachi, Manolis Vasilakis, Daniel Vaz</dc:creator>
    </item>
    <item>
      <title>Entrywise Approximation for Matrix Inversion and Linear Systems</title>
      <link>https://arxiv.org/abs/2504.19054</link>
      <description>arXiv:2504.19054v2 Announce Type: replace 
Abstract: We study the bit complexity of inverting diagonally dominant matrices, which are associated with random walk quantities such as hitting times and escape probabilities. Such quantities can be exponentially small, even on undirected unit-weighted graphs. However, their nonnegativity suggests that they can be approximated entrywise, leading to a stronger notion of approximation than vector norm-based error.
  Under this notion of error, existing Laplacian solvers and fast matrix multiplication approaches have bit complexities of $mn^2$ and $n^{\omega+1}$, respectively, where $m$ is the number of nonzero entries in the matrix, $n$ is its size, and $\omega$ is the matrix multiplication exponent.
  We present algorithms that compute entrywise $\exp(\epsilon)$-approximate inverses of row diagonally dominant $L$-matrices (RDDL) in two settings: (1) when the matrix entries are given in floating-point representation; (2) when they are given in fixed-point representation.
  For floating-point inputs, we present a cubic-time algorithm and show that it has an optimal running time under the all-pairs shortest paths (APSP) conjecture.
  For fixed-point inputs, we present several algorithms for solving linear systems and inverting RDDL and SDDM matrices, all with high probability.
  Omitting logarithmic factors:
  (1) For SDDM matrices, we provide an algorithm for solving a linear system with entrywise approximation guarantees using $\tilde{O}(m\sqrt{n})$ bit operations, and another for computing an entrywise approximate inverse using $\tilde{O}(mn)$ bit operations.
  (2) For RDDL matrices, we present an algorithm for solving a linear system using $\tilde{O}(mn^{1+o(1)})$ bit operations, and two algorithms for computing an entrywise approximate inverse: one using $\tilde{O}(n^{\omega+0.5})$ bit operations, and the other using $\tilde{O}(mn^{1.5+o(1)})$ bit operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19054v2</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>An extended abstract is published in SODA 2026</arxiv:journal_reference>
      <dc:creator>Mehrdad Ghadiri, Hoai-An Nguyen, Junzhao Yang</dc:creator>
    </item>
    <item>
      <title>Approximate Light Spanners in Planar Graphs</title>
      <link>https://arxiv.org/abs/2505.24825</link>
      <description>arXiv:2505.24825v2 Announce Type: replace 
Abstract: In their seminal paper, Alth\"{o}fer et al. (DCG 1993) introduced the {\em greedy spanner} and showed that, for any weighted planar graph $G$, the weight of the greedy $(1+\epsilon)$-spanner is at most $(1+\frac{2}{\epsilon}) \cdot w(MST(G))$, where $w(MST(G))$ is the weight of a minimum spanning tree $MST(G)$ of $G$. This bound is optimal in an {\em existential sense}: there exist planar graphs $G$ for which any $(1+\epsilon)$-spanner has a weight of at least $(1+\frac{2}{\epsilon}) \cdot w(MST(G))$.
  However, as an {\em approximation algorithm}, even for a {\em bicriteria} approximation, the weight approximation factor of the greedy spanner is essentially as large as the existential bound: There exist planar graphs $G$ for which the greedy $(1+x \epsilon)$-spanner (for any $1\leq x = O(\epsilon^{-1/2})$) has a weight of $\Omega(\frac{1}{\epsilon \cdot x^2})\cdot w(G_{OPT, \epsilon})$, where $G_{OPT, \epsilon}$ is a $(1+\epsilon)$-spanner of $G$ of minimum weight.
  Despite the flurry of works over the past three decades on approximation algorithms for spanners as well as on light(-weight) spanners, there is still no (possibly bicriteria) approximation algorithm for light spanners in weighted planar graphs that outperforms the existential bound. As our main contribution, we present a polynomial time algorithm for constructing, in any weighted planar graph $G$, a $(1+\epsilon\cdot 2^{O(\log^* 1/\epsilon)})$-spanner for $G$ of total weight $O(1)\cdot w(G_{OPT, \epsilon})$.
  To achieve this result, we develop a new technique, which we refer to as {\em iterative planar pruning}. It iteratively modifies a spanner [...]</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24825v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hung Le, Shay Solomon, Cuong Than, Csaba D. T\'oth, Tianyi Zhang</dc:creator>
    </item>
    <item>
      <title>Nearly-Linear Time Private Hypothesis Selection with the Optimal Approximation Factor</title>
      <link>https://arxiv.org/abs/2506.01162</link>
      <description>arXiv:2506.01162v2 Announce Type: replace 
Abstract: Estimating the density of a distribution from its samples is a fundamental problem in statistics. Hypothesis selection addresses the setting where, in addition to a sample set, we are given $n$ candidate distributions -- referred to as hypotheses -- and the goal is to determine which one best describes the underlying data distribution. This problem is known to be solvable very efficiently, requiring roughly $O(\log n)$ samples and running in $\tilde{O}(n)$ time. The quality of the output is measured via the total variation distance to the unknown distribution, and the approximation factor of the algorithm determines how large this distance is compared to the optimal distance achieved by the best candidate hypothesis. It is known that $\alpha = 3$ is the optimal approximation factor for this problem. We study hypothesis selection under the constraint of differential privacy. We propose a differentially private algorithm in the central model that runs in nearly-linear time with respect to the number of hypotheses, achieves the optimal approximation factor, and incurs only a modest increase in sample complexity, which remains polylogarithmic in $n$. This resolves an open question posed by [Bun, Kamath, Steinke, Wu, NeurIPS 2019]. Prior to our work, existing upper bounds required quadratic time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01162v2</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maryam Aliakbarpour, Zhan Shi, Ria Stevens, Vincent X. Wang</dc:creator>
    </item>
    <item>
      <title>Better Bounds for Semi-Streaming Single-Source Shortest Paths</title>
      <link>https://arxiv.org/abs/2507.17841</link>
      <description>arXiv:2507.17841v2 Announce Type: replace 
Abstract: In the semi-streaming model, an algorithm must process any $n$-vertex graph by making one or few passes over a stream of its edges, use $O(n \cdot \text{polylog }n)$ words of space, and at the end of the last pass, output a solution to the problem at hand. Approximating (single-source) shortest paths on undirected graphs is a longstanding open question in this model. In this work, we make progress on this question from both upper and lower bound fronts:
  We present a simple randomized algorithm that for any $\epsilon &gt; 0$, with high probability computes $(1+\epsilon)$-approximate shortest paths from a given source vertex in \[
  O\left(\frac{1}{\epsilon} \cdot n \log^3 n \right)~\text{space} \quad \text{and} \quad O\left(\frac{1}{\epsilon} \cdot \left(\frac{\log n}{\log\log n} \right) ^2\right) ~\text{passes}.
  \] The algorithm can also be derandomized and made to work on dynamic streams at a cost of some extra $\text{poly}(\log n, 1/\epsilon)$ factors only in the space. Previously, the best known algorithms for this problem required $1/\epsilon \cdot \log^{c}(n)$ passes, for an unspecified large constant $c$.
  We prove that any semi-streaming algorithm that with large constant probability outputs any constant approximation to shortest paths from a given source vertex (even to a single fixed target vertex and only the distance, not necessarily the path) requires \[ \Omega\left(\frac{\log n}{\log\log n}\right) ~\text{passes}. \] We emphasize that our lower bound holds for any constant-factor approximation of shortest paths. Previously, only constant-pass lower bounds were known and only for small approximation ratios below two.
  Our results collectively reduce the gap in the pass complexity of approximating single-source shortest paths in the semi-streaming model from $\text{polylog } n$ vs $\omega(1)$ to only a quadratic gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17841v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sepehr Assadi, Gary Hoppenworth, Janani Sundaresan</dc:creator>
    </item>
    <item>
      <title>Nearly Optimal Bounds for Stochastic Online Sorting</title>
      <link>https://arxiv.org/abs/2508.07823</link>
      <description>arXiv:2508.07823v3 Announce Type: replace 
Abstract: In the online sorting problem, we have an array $A$ of $n$ cells, and receive a stream of $n$ items $x_1,\dots,x_n\in [0,1]$. When an item arrives, we need to immediately and irrevocably place it into an empty cell. The goal is to minimize the sum of absolute differences between adjacent items, which is called the \emph{cost} of the algorithm. It has been shown by Aamand, Abrahamsen, Beretta, and Kleist (SODA 2023) that when the stream $x_1,\dots,x_n$ is generated adversarially, the optimal cost bound for any deterministic algorithm is $\Theta(\sqrt{n})$.
  In this paper, we study the stochastic version of online sorting, where the input items $x_1,\dots,x_n$ are sampled uniformly at random. Despite the intuition that the stochastic version should yield much better cost bounds, the previous best algorithm for stochastic online sorting by Abrahamsen, Bercea, Beretta, Klausen and Kozma (ESA 2024) only achieves $\tilde{O}(n^{1/4})$ cost, which seems far from optimal. We show that stochastic online sorting indeed allows for much more efficient algorithms, by presenting an algorithm that achieves expected cost $\log n\cdot 2^{O(\log^* n)}$. We also prove a cost lower bound of $\Omega(\log n)$, thus show that our algorithm is nearly optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07823v3</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Hu</dc:creator>
    </item>
    <item>
      <title>Towards Constant Time Multi-Call Rumor Spreading on Small-Set Expanders</title>
      <link>https://arxiv.org/abs/2508.18017</link>
      <description>arXiv:2508.18017v2 Announce Type: replace 
Abstract: We study a multi-call variant of the classic PUSH&amp;PULL rumor spreading process where nodes can contact $k$ of their neighbors instead of a single one during both PUSH and PULL operations. We show that rumor spreading can be made faster at the cost of an increased amount of communication between the nodes. As a motivating example, consider the process on a complete graph of $n$ nodes: while the standard PUSH&amp;PULL protocol takes $\Theta(\log n)$ rounds, we prove that our $k$-PUSH&amp;PULL variant completes in $\Theta(\log_{k} n)$ rounds, with high probability.
  We generalize this result in an expansion-sensitive way, as has been done for the classic PUSH&amp;PULL protocol for different notions of expansion, e.g., conductance and vertex expansion. We consider small-set vertex expanders, graphs in which every sufficiently small subset of nodes has a large neighborhood, ensuring strong local connectivity. In particular, when the expansion parameter satisfies $\phi &gt; 1$, these graphs have a diameter of $o(\log n)$, as opposed to other standard notions of expansion. Since the graph's diameter is a lower bound on the number of rounds required for rumor spreading, this makes small-set expanders particularly well-suited for fast information dissemination. We prove that $k$-PUSH&amp;PULL takes $O(\log_{\phi} n \cdot \log_{k} n)$ rounds in these expanders, with high probability. We complement this with a simple lower bound of $\Omega(\log_{\phi} n+ \log_{k} n)$ rounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18017v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emilio Cruciani, Sebastian Forster, Tijn de Vos</dc:creator>
    </item>
    <item>
      <title>Learning Linear Attention in Polynomial Time</title>
      <link>https://arxiv.org/abs/2410.10101</link>
      <description>arXiv:2410.10101v3 Announce Type: replace-cross 
Abstract: Previous research has explored the computational expressivity of Transformer models in simulating Boolean circuits or Turing machines. However, the learnability of these simulators from observational data has remained an open question. Our study addresses this gap by providing the first polynomial-time learnability results (specifically strong, agnostic PAC learning) for single-layer Transformers with linear attention. We show that linear attention may be viewed as a linear predictor in a suitably defined RKHS. As a consequence, the problem of learning any linear transformer may be converted into the problem of learning an ordinary linear predictor in an expanded feature space, and any such predictor may be converted back into a multiheaded linear transformer. Moving to generalization, we show how to efficiently identify training datasets for which every empirical risk minimizer is equivalent (up to trivial symmetries) to the linear Transformer that generated the data, thereby guaranteeing the learned model will correctly generalize across all inputs. Finally, we provide examples of computations expressible via linear attention and therefore polynomial-time learnable, including associative memories, finite automata, and a class of Universal Turing Machine (UTMs) with polynomially bounded computation histories. We empirically validate our theoretical findings on three tasks: learning random linear attention networks, key--value associations, and learning to execute finite automata. Our findings bridge a critical gap between theoretical expressivity and learnability of Transformers, and show that flexible and general models of computation are efficiently learnable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10101v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Morris Yau, Ekin Aky\"urek, Jiayuan Mao, Joshua B. Tenenbaum, Stefanie Jegelka, Jacob Andreas</dc:creator>
    </item>
    <item>
      <title>Distributed Maximum Flow in Planar Graphs</title>
      <link>https://arxiv.org/abs/2411.11718</link>
      <description>arXiv:2411.11718v4 Announce Type: replace-cross 
Abstract: The dual of a planar graph $G$ is a planar graph $G^*$ that has a vertex for each face of $G$ and an edge for each pair of adjacent faces of $G$. The profound relationship between a planar graph and its dual has been the algorithmic basis for solving numerous (centralized) classical problems on planar graphs. In the distributed setting however, the only use of planar duality is for finding a recursive decomposition of $G$ [DISC 2017, STOC 2019].
  We extend the distributed algorithmic toolkit to work on the dual graph $G^*$. These tools can then facilitate various algorithms on $G$ by solving a suitable dual problem on $G^*$.
  Given a directed planar graph $G$ with positive and negative edge-lengths and hop-diameter $D$, our key result is an $\tilde{O}(D^2)$-round algorithm for Single Source Shortest Paths on $G^*$, which then implies $\tilde{O}(D^2)$-round algorithms for Maximum $st$-Flow and Directed Global Min-Cut on $G$. Prior to our work, no $\tilde{O}(\text{poly}(D))$-round algorithm was known for those problems. We further obtain a $D\cdot n^{o(1)}$-rounds $(1-\epsilon)$-approximation algorithm for Maximum $st$-Flow on $G$ when $G$ is undirected and $st$-planar. Finally, we give a near optimal $\tilde O(D)$-round algorithm for computing the weighted girth of $G$. The main challenges in our work are that $G^*$ is not the communication graph (e.g., a vertex of $G$ is mapped to multiple vertices of $G^*$), and that the diameter of $G^*$ can be much larger than $D$ (i.e., possibly by a linear factor). We overcome these challenges by carefully defining and maintaining subgraphs of the dual graph $G^*$ while applying the recursive decomposition on the primal graph $G$. The main technical difficulty, is that along the recursive decomposition, a face of $G$ gets shattered into (disconnected) components yet we still need to treat it as a dual node.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11718v4</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yaseen Abd-Elhaleem (University of Haifa), Michal Dory (University of Haifa), Merav Parter (Weizmann Institute of Science), Oren Weimann (University of Haifa)</dc:creator>
    </item>
    <item>
      <title>Online Conformal Prediction with Efficiency Guarantees</title>
      <link>https://arxiv.org/abs/2507.02496</link>
      <description>arXiv:2507.02496v2 Announce Type: replace-cross 
Abstract: We study the problem of conformal prediction in a novel online framework that directly optimizes efficiency. In our problem, we are given a target miscoverage rate $\alpha &gt; 0$, and a time horizon $T$. On each day $t \le T$ an algorithm must output an interval $I_t \subseteq [0, 1]$, then a point $y_t \in [0, 1]$ is revealed. The goal of the algorithm is to achieve coverage, that is, $y_t \in I_t$ on (close to) a $(1 - \alpha)$-fraction of days, while maintaining efficiency, that is, minimizing the average volume (length) of the intervals played. This problem is an online analogue to the problem of constructing efficient confidence intervals.
  We study this problem over arbitrary and exchangeable (random order) input sequences. For exchangeable sequences, we show that it is possible to construct intervals that achieve coverage $(1 - \alpha) - o(1)$, while having length upper bounded by the best fixed interval that achieves coverage in hindsight. For arbitrary sequences however, we show that any algorithm that achieves a $\mu$-approximation in average length compared to the best fixed interval achieving coverage in hindsight, must make a multiplicative factor more mistakes than $\alpha T$, where the multiplicative factor depends on $\mu$ and the aspect ratio of the problem. Our main algorithmic result is a matching algorithm that can recover all Pareto-optimal settings of $\mu$ and number of mistakes. Furthermore, our algorithm is deterministic and therefore robust to an adaptive adversary.
  This gap between the exchangeable and arbitrary settings is in contrast to the classical online learning problem. In fact, we show that no single algorithm can simultaneously be Pareto-optimal for arbitrary sequences and optimal for exchangeable sequences. On the algorithmic side, we give an algorithm that achieves the near-optimal tradeoff between the two cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02496v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vaidehi Srinivas</dc:creator>
    </item>
    <item>
      <title>An unconditional lower bound for the active-set method in convex quadratic maximization</title>
      <link>https://arxiv.org/abs/2507.16648</link>
      <description>arXiv:2507.16648v2 Announce Type: replace-cross 
Abstract: We prove that the active-set method needs an exponential number of iterations in the worst-case to maximize a convex quadratic function subject to linear constraints, regardless of the pivot rule used. This substantially improves over the best previously known lower bound [IPCO 2025], which needs objective functions of polynomial degrees $\omega(\log d)$ in dimension $d$, to a bound using a convex polynomial of degree 2. In particular, our result firmly resolves the open question [IPCO 2025] of whether a constant degree suffices, and it represents significant progress towards linear objectives, where the active-set method coincides with the simplex method and a lower bound for all pivot rules would constitute a major breakthrough.
  Our result is based on a novel extended formulation, recursively constructed using deformed products. Its key feature is that it projects onto a polygonal approximation of a parabola while preserving all of its exponentially many vertices. We define a quadratic objective that forces the active-set method to follow the parabolic boundary of this projection, without allowing any shortcuts along chords corresponding to edges of its full-dimensional preimage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16648v2</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eleon Bach, Yann Disser, Sophie Huiberts, Nils Mosis</dc:creator>
    </item>
  </channel>
</rss>
