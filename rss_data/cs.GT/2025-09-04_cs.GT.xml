<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Sep 2025 04:01:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Towards Performatively Stable Equilibria in Decision-Dependent Games for Arbitrary Data Distribution Maps</title>
      <link>https://arxiv.org/abs/2509.02619</link>
      <description>arXiv:2509.02619v1 Announce Type: new 
Abstract: In decision-dependent games, multiple players optimize their decisions under a data distribution that shifts with their joint actions, creating complex dynamics in applications like market pricing. A practical consequence of these dynamics is the \textit{performatively stable equilibrium}, where each player's strategy is a best response under the induced distribution. Prior work relies on $\beta$-smoothness, assuming Lipschitz continuity of loss function gradients with respect to the data distribution, which is impractical as the data distribution maps, i.e., the relationship between joint decision and the resulting distribution shifts, are typically unknown, rendering $\beta$ unobtainable. To overcome this limitation, we propose a gradient-based sensitivity measure that directly quantifies the impact of decision-induced distribution shifts. Leveraging this measure, we derive convergence guarantees for performatively stable equilibria under a practically feasible assumption of strong monotonicity. Accordingly, we develop a sensitivity-informed repeated retraining algorithm that adjusts players' loss functions based on the sensitivity measure, guaranteeing convergence to performatively stable equilibria for arbitrary data distribution maps. Experiments on prediction error minimization game, Cournot competition, and revenue maximization game show that our approach outperforms state-of-the-art baselines, achieving lower losses and faster convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02619v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guangzheng Zhong, Yang Liu, Jiming Liu</dc:creator>
    </item>
    <item>
      <title>Generative Auto-Bidding in Large-Scale Competitive Auctions via Diffusion Completer-Aligner</title>
      <link>https://arxiv.org/abs/2509.03348</link>
      <description>arXiv:2509.03348v1 Announce Type: new 
Abstract: Auto-bidding is central to computational advertising, achieving notable commercial success by optimizing advertisers' bids within economic constraints. Recently, large generative models show potential to revolutionize auto-bidding by generating bids that could flexibly adapt to complex, competitive environments. Among them, diffusers stand out for their ability to address sparse-reward challenges by focusing on trajectory-level accumulated rewards, as well as their explainable capability, i.e., planning a future trajectory of states and executing bids accordingly. However, diffusers struggle with generation uncertainty, particularly regarding dynamic legitimacy between adjacent states, which can lead to poor bids and further cause significant loss of ad impression opportunities when competing with other advertisers in a highly competitive auction environment. To address it, we propose a Causal auto-Bidding method based on a Diffusion completer-aligner framework, termed CBD. Firstly, we augment the diffusion training process with an extra random variable t, where the model observes t-length historical sequences with the goal of completing the remaining sequence, thereby enhancing the generated sequences' dynamic legitimacy. Then, we employ a trajectory-level return model to refine the generated trajectories, aligning more closely with advertisers' objectives. Experimental results across diverse settings demonstrate that our approach not only achieves superior performance on large-scale auto-bidding benchmarks, such as a 29.9% improvement in conversion value in the challenging sparse-reward auction setting, but also delivers significant improvements on the Kuaishou online advertising platform, including a 2.0% increase in target cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03348v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yewen Li, Jingtong Gao, Nan Jiang, Shuai Mao, Ruyi An, Fei Pan, Xiangyu Zhao, Bo An, Qingpeng Cai, Peng Jiang</dc:creator>
    </item>
    <item>
      <title>Can Media Act as a Soft Regulator of Safe AI Development? A Game Theoretical Analysis</title>
      <link>https://arxiv.org/abs/2509.02650</link>
      <description>arXiv:2509.02650v1 Announce Type: cross 
Abstract: When developers of artificial intelligence (AI) products need to decide between profit and safety for the users, they likely choose profit. Untrustworthy AI technology must come packaged with tangible negative consequences. Here, we envisage those consequences as the loss of reputation caused by media coverage of their misdeeds, disseminated to the public. We explore whether media coverage has the potential to push AI creators into the production of safe products, enabling widespread adoption of AI technology. We created artificial populations of self-interested creators and users and studied them through the lens of evolutionary game theory. Our results reveal that media is indeed able to foster cooperation between creators and users, but not always. Cooperation does not evolve if the quality of the information provided by the media is not reliable enough, or if the costs of either accessing media or ensuring safety are too high. By shaping public perception and holding developers accountable, media emerges as a powerful soft regulator -- guiding AI safety even in the absence of formal government oversight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02650v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>q-bio.PE</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henrique Correia da Fonseca, Ant\'onio Fernandes, Zhao Song, Theodor Cimpeanu, Nataliya Balabanova, Adeela Bashir, Paolo Bova, Alessio Buscemi, Alessandro Di Stefano, Manh Hong Duong, Elias Fernandez Domingos, Ndidi Bianca Ogbo, Simon T. Powers, Daniele Proverbio, Zia Ush Shamszaman, Fernando P. Santos, The Anh Han, Marcus Krellner</dc:creator>
    </item>
    <item>
      <title>Too Noisy to Collude? Algorithmic Collusion Under Laplacian Noise</title>
      <link>https://arxiv.org/abs/2509.02800</link>
      <description>arXiv:2509.02800v1 Announce Type: cross 
Abstract: The rise of autonomous pricing systems has sparked growing concern over algorithmic collusion in markets from retail to housing. This paper examines controlled information quality as an ex ante policy lever: by reducing the fidelity of data that pricing algorithms draw on, regulators can frustrate collusion before supracompetitive prices emerge. We show, first, that information quality is the central driver of competitive outcomes, shaping prices, profits, and consumer welfare. Second, we demonstrate that collusion can be slowed or destabilized by injecting carefully calibrated noise into pooled market data, yielding a feasibility region where intervention disrupts cartels without undermining legitimate pricing. Together, these results highlight information control as a lightweight yet practical lever to blunt digital collusion at its source.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02800v1</guid>
      <category>econ.GN</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Niuniu Zhang</dc:creator>
    </item>
    <item>
      <title>Zero-Error Nash Equilibrium: Harnessing Nonlocal Correlation in Incomplete Information Games</title>
      <link>https://arxiv.org/abs/2509.02947</link>
      <description>arXiv:2509.02947v1 Announce Type: cross 
Abstract: Claude Shannon's zero-error communication paradigm reshaped our understanding of fault-tolerant information transfer. Here, we adapt this notion into game theory with incomplete information. We ask: can players with private information coordinate on a Nash equilibrium with zero probability of error? We identify Bayesian games in which such coordination is impossible classically, yet achievable by harnessing Bell nonlocal correlations. We formalize this requirement as zero-error Nash equilibrium coordination, establishing a new bridge between information theory, game theory, and quantum nonlocality. Furthermore, we construct a tripartite Bayesian game that admits zero-error Nash equilibrium coordination with genuine entanglement, and a two-player game where a stronger notion of coordination can be achieved using every two-qubit pure entangled state except the maximally one. Crucially, the advantage persists under experimentally relevant noise, demonstrating nonlocality as a robust resource for near-zero error decision-making under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02947v1</guid>
      <category>quant-ph</category>
      <category>cs.GT</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator> Ambuj,  Tushar, Siddharth R. Pandey, Ram Krishna Patra, Anandamay Das Bhowmik, Kuntal Som, Amit Mukherjee</dc:creator>
    </item>
    <item>
      <title>MFGLib: A Library for Mean-Field Games</title>
      <link>https://arxiv.org/abs/2304.08630</link>
      <description>arXiv:2304.08630v2 Announce Type: replace 
Abstract: Mean-field games (MFGs) are limiting models to approximate $N$-player games, with a number of applications. Despite the ever-growing numerical literature on computation of MFGs, there is no library that allows researchers and practitioners to easily create and solve their own MFG problems. The purpose of this document is to introduce MFGLib, an open-source Python library for solving general MFGs with a user-friendly and customizable interface. It serves as a handy tool for creating and analyzing generic MFG environments, along with embedded auto-tuners for all implemented algorithms. The package is distributed under the MIT license and the source code and documentation can be found at https://github.com/radar-research-lab/MFGLib/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.08630v2</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Guo, Anran Hu, Matteo Santamaria, Mahan Tajrobehkar, Junzi Zhang</dc:creator>
    </item>
    <item>
      <title>Online Resource Allocation with Cancellations</title>
      <link>https://arxiv.org/abs/2210.11570</link>
      <description>arXiv:2210.11570v3 Announce Type: replace-cross 
Abstract: We initiate the study of two-sided online resource allocation with costly cancellations. Our focus is on edge-weighted online bipartite matching (and several of its extensions), where nodes arrive online and request offline resources. In contrast to the classic literature, any fraction of an offline resource that was preallocated to an earlier online node can be reclaimed, resulting in the loss of the previously allocated edge-weight plus an additional penalty equal to a non-negative constant factor $f$ times the edge-weight. Parameterizing the problem by the buyback factor $f$, our main result is the development of optimal competitive algorithms for \emph{all possible values} of $f$ through a novel primal-dual family of algorithms in the fractional (or equivalently, large capacity) setting, and establishing their optimality by deriving matching lower bounds. Interestingly, our results reveal a phase transition: for the small buyback regime ($f &lt; \frac{e-2}{2}$), the optimal competitive ratio is $\frac{e}{e-(1+f)}$, and for the large buyback regime ($f \geq \frac{e-2}{2}$), the competitive ratio is $-W_{-1}\left(\frac{-1}{e(1+f)}\right)$, where $W_{-1}$ is the non-principal branch of the Lambert $W$ function. We also study variants of this model, such as matching with deterministic integral allocations. We again show a phase transition: for the small buyback regime ($f &lt; \frac{1}{3}$), the optimal competitive ratio is $\frac{2}{1-f}$, while for the large buyback regime ($f \geq \frac{1}{3}$), the competitive ratio is $1 + 2f + 2\sqrt{f(1+f)}$. We further consider various extensions, including to configuration allocations and submodular welfare maximization, as well as negative values of $f$, modeling a secondary supply channels or overflow capacities available at discounted rates. Our unifying primal-dual framework achieves the exact optimal competitive ratio across all these variants</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.11570v3</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farbod Ekbatani, Yiding Feng, Rad Niazadeh</dc:creator>
    </item>
    <item>
      <title>An Exponentially Converging Particle Method for the Mixed Nash Equilibrium of Continuous Games</title>
      <link>https://arxiv.org/abs/2211.01280</link>
      <description>arXiv:2211.01280v4 Announce Type: replace-cross 
Abstract: We consider the problem of computing mixed Nash equilibria of two-player zero-sum games with continuous sets of pure strategies and with first-order access to the payoff function. This problem arises for example in game-theory-inspired machine learning applications, such as distributionally-robust learning. In those applications, the strategy sets are high-dimensional and thus methods based on discretisation cannot tractably return high-accuracy solutions.
  In this paper, we introduce and analyze a particle-based method that enjoys guaranteed local convergence for this problem. This method consists in parametrizing the mixed strategies as atomic measures and applying proximal point updates to both the atoms' weights and positions. It can be interpreted as a time-implicit discretization of the "interacting" Wasserstein-Fisher-Rao gradient flow.
  We prove that, under non-degeneracy assumptions, this method converges at an exponential rate to the exact mixed Nash equilibrium from any initialization satisfying a natural notion of closeness to optimality. We illustrate our results with numerical experiments and discuss applications to max-margin and distributionally-robust classification using two-layer neural networks, where our method has a natural interpretation as a simultaneous training of the network's weights and of the adversarial distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.01280v4</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.5802/ojmo.37</arxiv:DOI>
      <arxiv:journal_reference>Open Journal of Mathematical Optimization, Volume 6 (2025), article no. 1, 66 p</arxiv:journal_reference>
      <dc:creator>Guillaume Wang, L\'ena\"ic Chizat</dc:creator>
    </item>
    <item>
      <title>MF-OML: Online Mean-Field Reinforcement Learning with Occupation Measures for Large Population Games</title>
      <link>https://arxiv.org/abs/2405.00282</link>
      <description>arXiv:2405.00282v2 Announce Type: replace-cross 
Abstract: Reinforcement learning for multi-agent games has attracted lots of attention recently. However, given the challenge of solving Nash equilibria for large population games, existing works with guaranteed polynomial complexities either focus on variants of zero-sum and potential games, or aim at solving (coarse) correlated equilibria, or require access to simulators, or rely on certain assumptions that are hard to verify. This work proposes MF-OML (Mean-Field Occupation-Measure Learning), an online mean-field reinforcement learning algorithm for computing approximate Nash equilibria of large population sequential symmetric games. MF-OML is the first fully polynomial multi-agent reinforcement learning algorithm for provably solving Nash equilibria (up to mean-field approximation gaps that vanish as the number of players $N$ goes to infinity) beyond variants of zero-sum and potential games. When evaluated by the cumulative deviation from Nash equilibria, the algorithm is shown to achieve a high probability regret bound of $\tilde{O}(M^{3/4}+N^{-1/2}M)$ for games with the strong Lasry-Lions monotonicity condition, and a regret bound of $\tilde{O}(M^{11/12}+N^{- 1/6}M)$ for games with only the Lasry-Lions monotonicity condition, where $M$ is the total number of episodes and $N$ is the number of agents of the game. As a byproduct, we also obtain the first tractable globally convergent computational algorithm for computing approximate Nash equilibria of monotone mean-field games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00282v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anran Hu, Junzi Zhang</dc:creator>
    </item>
    <item>
      <title>Covering a Few Submodular Constraints and Applications</title>
      <link>https://arxiv.org/abs/2507.09879</link>
      <description>arXiv:2507.09879v2 Announce Type: replace-cross 
Abstract: We consider the problem of covering multiple submodular constraints. Given a finite ground set $N$, a cost function $c: N \rightarrow \mathbb{R}_+$, $r$ monotone submodular functions $f_1,f_2,\ldots,f_r$ over $N$ and requirements $b_1,b_2,\ldots,b_r$ the goal is to find a minimum cost subset $S \subseteq N$ such that $f_i(S) \ge b_i$ for $1 \le i \le r$. When $r=1$ this is the well-known Submodular Set Cover problem. Previous work \cite{chekuri2022covering} considered the setting when $r$ is large and developed bi-criteria approximation algorithms, and approximation algorithms for the important special case when each $f_i$ is a weighted coverage function. These are fairly general models and capture several concrete and interesting problems as special cases. The approximation ratios for these problem are at least $\Omega(\log r)$ which is unavoidable when $r$ is part of the input. In this paper, motivated by some recent applications, we consider the problem when $r$ is a \emph{fixed constant} and obtain two main results. For covering multiple submodular constraints we obtain a randomized bi-criteria approximation algorithm that for any given integer $\alpha \ge 1$ outputs a set $S$ such that $f_i(S) \ge$ $(1-1/e^\alpha -\epsilon)b_i$ for each $i \in [r]$ and $\mathbb{E}[c(S)] \le (1+\epsilon)\alpha \cdot \sf{OPT}$. Second, when the $f_i$ are weighted coverage functions from a deletion-closed set system we obtain a $(1+\epsilon)$ $(\frac{e}{e-1})$ $(1+\beta)$-approximation where $\beta$ is the approximation ratio for the underlying set cover instances via the natural LP. These results show that one can obtain nearly as good an approximation for any fixed $r$ as what one would achieve for $r=1$. We mention some applications that follow easily from these general results and anticipate more in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09879v2</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tanvi Bajpai, Chandra Chekuri, Pooja Kulkarni</dc:creator>
    </item>
  </channel>
</rss>
