<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 May 2024 04:01:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 03 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>WATCH: A Workflow to Assess Treatment Effect Heterogeneity in Drug Development for Clinical Trial Sponsors</title>
      <link>https://arxiv.org/abs/2405.00859</link>
      <description>arXiv:2405.00859v1 Announce Type: new 
Abstract: This paper proposes a Workflow for Assessing Treatment effeCt Heterogeneity (WATCH) in clinical drug development targeted at clinical trial sponsors. The workflow is designed to address the challenges of investigating treatment effect heterogeneity (TEH) in randomized clinical trials, where sample size and multiplicity limit the reliability of findings. The proposed workflow includes four steps: Analysis Planning, Initial Data Analysis and Analysis Dataset Creation, TEH Exploration, and Multidisciplinary Assessment. The workflow aims to provide a systematic approach to explore treatment effect heterogeneity in the exploratory setting, taking into account external evidence and best scientific understanding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00859v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Konstantinos Sechidis, Sophie Sun, Yao Chen, Jiarui Lu, Cong Zang, Mark Baillie, David Ohlssen, Marc Vandemeulebroecke, Rob Hemmings, Stephen Ruberg, Bj\"orn Bornkamp</dc:creator>
    </item>
    <item>
      <title>Tracking and classifying objects with DAS data along railway</title>
      <link>https://arxiv.org/abs/2405.01140</link>
      <description>arXiv:2405.01140v1 Announce Type: new 
Abstract: Distributed acoustic sensing through fiber-optical cables can contribute to traffic monitoring systems. Using data from a day of field testing on a 50 km long fiber-optic cable along a railroad track in Norway, we detect and track cars and trains along a segment of the fiber-optic cable where the road runs parallel to the railroad tracks. We develop a method for automatic detection of events and then use these in a Kalman filter variant known as joint probabilistic data association for object tracking and classification. Model parameters are specified using in-situ log data along with the fiber-optic signals. Running the algorithm over an entire day, we highlight results of counting cars and trains over time and their estimated velocities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01140v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Simon L. B. Fredriksen, The Tien Mai, Kevin Growe, Jo Eidsvik</dc:creator>
    </item>
    <item>
      <title>Strategies for Rare Population Detection and Sampling: A Methodological Approach in Liguria</title>
      <link>https://arxiv.org/abs/2405.01342</link>
      <description>arXiv:2405.01342v1 Announce Type: new 
Abstract: Economic policy sciences are constantly investigating the quality of well-being of broad sections of the population in order to describe the current interdependence between unequal living conditions, low levels of education and a lack of integration into society. Such studies are often carried out in the form of surveys, e.g. as part of the EU-SILC program. If the survey is designed at national or international level, the results of the study are often used as a reference by a broad range of public institutions. However, the sampling strategy per se may not capture enough information to provide an accurate representation of all population strata. Problems might arise from rare, or hard-to-sample, populations and the conclusion of the study may be compromised or unrealistic. We propose here a two-phase methodology to identify rare, poorly sampled populations and then resample the hard-to-sample strata. We focused our attention on the 2019 EU-SILC section concerning the Italian region of Liguria. Methods based on dispersion indices or deep learning were used to detect rare populations. A multi-frame survey was proposed as the sampling design. The results showed that factors such as citizenship, material deprivation and large families are still fundamental characteristics that are difficult to capture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01342v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.OT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>G. Lancia, E. Riccomagno</dc:creator>
    </item>
    <item>
      <title>Integrating socioeconomic and geographic data to enhance infectious disease prediction in Brazilian cities</title>
      <link>https://arxiv.org/abs/2405.01422</link>
      <description>arXiv:2405.01422v1 Announce Type: new 
Abstract: Supervised machine learning models and public surveillance data has been employed for infectious disease forecasting in many settings. These models leverage various data sources capturing drivers of disease spread, such as climate conditions or human behavior. However, few models have incorporated the organizational structure of different geographic locations for forecasting. Traveling waves of seasonal outbreaks have been reported for dengue, influenza, and other infectious diseases, and many of the drivers of infectious disease dynamics may be shared across different cities, either due to their geographic or socioeconomic proximity. In this study, we developed a machine learning model to predict case counts of four infectious diseases across Brazilian cities one week ahead by incorporating information from related cities. We compared selecting related cities using both geographic distance and GDP per capita. Incorporating information from geographically proximate cities improved predictive performance for two of the four diseases, specifically COVID-19 and Zika. We also discuss the impact on forecasts in the presence of anomalous contagion patterns and the limitations of the proposed methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01422v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luiza Lober, Kirstin O. Roster, Francisco A. Rodrigues</dc:creator>
    </item>
    <item>
      <title>A mixed effects cosinor modelling framework for circadian gene expression</title>
      <link>https://arxiv.org/abs/2405.01450</link>
      <description>arXiv:2405.01450v1 Announce Type: new 
Abstract: The cosinor model is frequently used to represent gene expression given the 24 hour day-night cycle time at which a corresponding tissue sample is collected. However, the timing of many biological processes are based on individual-specific internal timing systems that are offset relative to day-night cycle time. When these offsets are unknown, they pose a challenge in performing statistical analyses with a cosinor model. To clarify, when sample collection times are mis-recorded, cosinor regression can yield attenuated parameter estimates, which would also attenuate test statistics. This attenuation bias would inflate type II error rates in identifying genes with oscillatory behavior. This paper proposes a heuristic method to account for unknown offsets when tissue samples are collected in a longitudinal design. Specifically, this method involves first estimating individual-specific cosinor models for each gene. The times of sample collection for that individual are then translated based on the estimated phase-shifts across every gene. Simulation studies confirm that this method mitigates bias in estimation and inference. Illustrations with real data from three circadian biology studies highlight that this method produces parameter estimates and inferences akin to those obtained when each individual's offset is known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01450v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael T. Gorczyca</dc:creator>
    </item>
    <item>
      <title>Pricing Catastrophe Bonds -- A Probabilistic Machine Learning Approach</title>
      <link>https://arxiv.org/abs/2405.00697</link>
      <description>arXiv:2405.00697v1 Announce Type: cross 
Abstract: This paper proposes a probabilistic machine learning method to price catastrophe (CAT) bonds in the primary market. The proposed method combines machine-learning-based predictive models with Conformal Prediction, an innovative algorithm that generates distribution-free probabilistic forecasts for CAT bond prices. Using primary market CAT bond transaction records between January 1999 and March 2021, the proposed method is found to be more robust and yields more accurate predictions of the bond spreads than traditional regression-based methods. Furthermore, the proposed method generates more informative prediction intervals than linear regression and identifies important nonlinear relationships between various risk factors and bond spreads, suggesting that linear regressions could misestimate the bond spreads. Overall, this paper demonstrates the potential of machine learning methods in improving the pricing of CAT bonds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00697v1</guid>
      <category>q-fin.CP</category>
      <category>cs.LG</category>
      <category>q-fin.PR</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaowei Chen, Hong Li, Yufan Lu, Rui Zhou</dc:creator>
    </item>
    <item>
      <title>Overcoming model uncertainty -- how equivalence tests can benefit from model averaging</title>
      <link>https://arxiv.org/abs/2405.00827</link>
      <description>arXiv:2405.00827v1 Announce Type: cross 
Abstract: A common problem in numerous research areas, particularly in clinical trials, is to test whether the effect of an explanatory variable on an outcome variable is equivalent across different groups. In practice, these tests are frequently used to compare the effect between patient groups, e.g. based on gender, age or treatments. Equivalence is usually assessed by testing whether the difference between the groups does not exceed a pre-specified equivalence threshold. Classical approaches are based on testing the equivalence of single quantities, e.g. the mean, the area under the curve (AUC) or other values of interest. However, when differences depending on a particular covariate are observed, these approaches can turn out to be not very accurate. Instead, whole regression curves over the entire covariate range, describing for instance the time window or a dose range, are considered and tests are based on a suitable distance measure of two such curves, as, for example, the maximum absolute distance between them. In this regard, a key assumption is that the true underlying regression models are known, which is rarely the case in practice. However, misspecification can lead to severe problems as inflated type I errors or, on the other hand, conservative test procedures. In this paper, we propose a solution to this problem by introducing a flexible extension of such an equivalence test using model averaging in order to overcome this assumption and making the test applicable under model uncertainty. Precisely, we introduce model averaging based on smooth AIC weights and we propose a testing procedure which makes use of the duality between confidence intervals and hypothesis testing. We demonstrate the validity of our approach by means of a simulation study and demonstrate the practical relevance of the approach considering a time-response case study with toxicological gene expression data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00827v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niklas Hagemann, Kathrin M\"ollenhoff</dc:creator>
    </item>
    <item>
      <title>Stochastic Geometry Analysis of EMF Exposure of Idle Users and Network Performance with Dynamic Beamforming</title>
      <link>https://arxiv.org/abs/2405.01190</link>
      <description>arXiv:2405.01190v1 Announce Type: cross 
Abstract: This paper presents a novel mathematical framework based on stochastic geometry to investigate the electromagnetic field exposure of idle and active users in cellular networks implementing dynamic beamforming. Accurate modeling of antenna gain becomes crucial in this context, encompassing both the main and the side lobes. The marginal distribution of EMF exposure for each type of users is initially derived. Subsequently, network performance is scrutinized by introducing a new metric aimed at ensuring minimal downlink coverage while simultaneously maintaining EMF exposure below distinct thresholds for both idle and active users. The metrics exhibit a high dependency on various parameters, such as the distance between active and idle users and the number of antenna elements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01190v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quentin Gontier, Charles Wiame, Joe Wiart, Fran\c{c}ois Horlin, Christo Tsigros, Claude Oestges, Philippe De Doncker</dc:creator>
    </item>
    <item>
      <title>Spatial Joint Species N-Mixture Models for Multi-Source Observational Data with Application to Wild Deer Population Abundance</title>
      <link>https://arxiv.org/abs/2310.19993</link>
      <description>arXiv:2310.19993v3 Announce Type: replace 
Abstract: Accurate predictions of the populations and spatial distributions of wild animal species is critical from a species management and conservation perspective. Culling is a measure taken for various reasons, including when overpopulation of a species is observed or suspected. Thus accurate estimates of population numbers are essential for specifying, monitoring, and evaluating the impact of such programmes. Population data for wild animals is generally collated from various sources and at differing spatial resolutions. Citizen science projects typically provide point referenced data, whereas site surveys, hunter reports, and official government data may be aggregated and released at a small area or regional level. Jointly modelling these data resources involves overcoming challenges of spatial misalignment.
  In this article, we develop an N mixture modelling methodology for joint modelling of species populations in the presence of spatially misaligned data, motivated by the three main species of wild deer in the Republic of Ireland; fallow, red and sika. Previous studies of deer populations investigated the distribution and abundance on a species by species basis, failing to account for possible correlation between individual species and the impact of ecological covariates on their distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.19993v3</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aoife K. Hurley, Ruth F. Carden, Sally Cook, Irish Deer Commission, Ferdia Marnell, Pieter A. J. Brama, Daniel J. Buckley, James Sweeney</dc:creator>
    </item>
    <item>
      <title>Implementing Bayesian inference on a stochastic CO2-based grey-box model for assessing indoor air quality in Canadian primary schools</title>
      <link>https://arxiv.org/abs/2405.00582</link>
      <description>arXiv:2405.00582v2 Announce Type: replace 
Abstract: The COVID-19 pandemic brought global attention to indoor air quality (IAQ), which is intrinsically linked to clean air change rates. Estimating the air change rate in indoor environments, however, remains challenging. It is primarily due to the uncertainties associated with the air change rate estimation, such as pollutant generation rates, dynamics including weather and occupancies, and the limitations of deterministic approaches to accommodate these factors. In this study, Bayesian inference was implemented on a stochastic CO2-based grey-box model to infer modeled parameters and quantify uncertainties. The accuracy and robustness of the ventilation rate and CO2 emission rate estimated by the model were confirmed with CO2 tracer gas experiments conducted in an airtight chamber. Both prior and posterior predictive checks (PPC) were performed to demonstrate the advantage of this approach. In addition, uncertainties in real-life contexts were quantified with an incremental variance {\sigma} for the Wiener process. This approach was later applied to evaluate the ventilation conditions within two primary school classrooms in Montreal. The Equivalent Clean Airflow Rate (ECAi) was calculated following ASHRAE 241, and an insufficient clean air supply within both classrooms was identified. A supplement of 800 cfm clear air delivery rate (CADR) from air-cleaning devices is recommended for a sufficient ECAi. Finally, steady-state CO2 thresholds (Climit, Ctarget, and Cideal) were carried out to indicate when ECAi requirements could be achieved under various mitigation strategies, such as portable air cleaners and in-room ultraviolet light, with CADR values ranging from 200 to 1000 cfm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00582v2</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shujie Yan (Grace), Jiwei Zou (Grace), Chang Shu (Grace), Justin Berquist (Grace), Vincent Brochu (Grace), Marc Veillette (Grace), Danlin Hou (Grace), Caroline Duchaine (Grace),  Liang (Grace),  Zhou (John),  Zhiqiang (John),  Zhai (Leon),  Liangzhu (Leon),  Wang</dc:creator>
    </item>
    <item>
      <title>Automating the Discovery of Partial Differential Equations in Dynamical Systems</title>
      <link>https://arxiv.org/abs/2404.16444</link>
      <description>arXiv:2404.16444v2 Announce Type: replace-cross 
Abstract: Identifying partial differential equations (PDEs) from data is crucial for understanding the governing mechanisms of natural phenomena, yet it remains a challenging task. We present an extension to the ARGOS framework, ARGOS-RAL, which leverages sparse regression with the recurrent adaptive lasso to identify PDEs from limited prior knowledge automatically. Our method automates calculating partial derivatives, constructing a candidate library, and estimating a sparse model. We rigorously evaluate the performance of ARGOS-RAL in identifying canonical PDEs under various noise levels and sample sizes, demonstrating its robustness in handling noisy and non-uniformly distributed data. We also test the algorithm's performance on datasets consisting solely of random noise to simulate scenarios with severely compromised data quality. Our results show that ARGOS-RAL effectively and reliably identifies the underlying PDEs from data, outperforming the sequential threshold ridge regression method in most cases. We highlight the potential of combining statistical methods, machine learning, and dynamical systems theory to automatically discover governing equations from collected data, streamlining the scientific modeling process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16444v2</guid>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weizhen Li, Rui Carvalho</dc:creator>
    </item>
  </channel>
</rss>
