<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 Aug 2024 02:28:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Identification via Functions</title>
      <link>https://arxiv.org/abs/2408.12730</link>
      <description>arXiv:2408.12730v1 Announce Type: new 
Abstract: We develop a framework for studying the problem of identifying roots of a noisy function. We revisit a previous logarithmic bound on the number of observations and propose a general problem for identification of roots with three errors. As a key finding, we establish a novel logarithmic lower bound on the number of observations which outperforms the previous result across certain regimes of error and accuracy of the identification test. Furthermore, we recover the previous results for root identification as a special case and draw a connection to the message identification problem of Ahlswede.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12730v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Javad Salariseddigh, Feriel Fendri</dc:creator>
    </item>
    <item>
      <title>Decentralized MIMO Systems with LMMSE Receivers and Imperfect CSI</title>
      <link>https://arxiv.org/abs/2408.12811</link>
      <description>arXiv:2408.12811v1 Announce Type: new 
Abstract: Centralized baseband processing (CBP) is required to achieve the full potential of massive multiple-input multiple-output (MIMO) systems. However, due to the large number of antennas, CBP suffers from two major issues: 1) Tremendous data interconnection between radio frequency (RF) circuitry and processing fabrics; and 2) high-dimensional computation. To this end, decentralized baseband processing (DBP) has been proposed, where the antennas at the BS are partitioned into clusters connected to separate RF circuits and equipped with separate computing units. Unfortunately, due to the decentralized structure, the optimal fusion scheme and performance analysis for DBP with general spatial correlation between clusters and imperfect channel state information (CSI) are not available in the literature. In this paper, we consider a decentralized MIMO system where all clusters adopt linear minimum mean-square error (LMMSE) receivers with imperfect CSI. Specifically, we first establish the optimal linear fusion scheme which has high computational and data input/output (I/O) costs. To reduce the costs, we further propose two sub-optimal fusion schemes with reduced complexity. For all three schemes, we derive the closed-form expressions for the signal-to-interference-and-noise ratio (SINR) by leveraging random matrix theory (RMT) and demonstrate the conditions under which the sub-optimal schemes are optimal. Furthermore, we determine the optimal regularization parameter for decentralized LMMSE receivers, identify the best antenna partitioning strategy, and prove that the SINR will decrease as the number of clusters increases. Numerical simulations validate the accuracy of the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12811v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyan Zhuang, Xin Zhang, Dongfang Xu, Shenghui Song, Yonina C. Eldar</dc:creator>
    </item>
    <item>
      <title>Balancing AoI and Rate for Mission-Critical and eMBB Coexistence with Puncturing, NOMA,and RSMA in Cellular Uplink</title>
      <link>https://arxiv.org/abs/2408.12926</link>
      <description>arXiv:2408.12926v1 Announce Type: new 
Abstract: Through the lens of average and peak age-of-information (AoI), this paper takes a fresh look into the uplink medium access solutions for mission-critical (MC) communication coexisting with enhanced mobile broadband (eMBB) service. Considering the stochastic packet arrivals from an MC user, we study three access schemes: orthogonal multiple access (OMA) with eMBB preemption (puncturing), non-orthogonal multiple access (NOMA), and rate-splitting multiple access (RSMA), the latter two both with concurrent eMBB transmissions. Puncturing is found to reduce both average AoI and peak AoI (PAoI) violation probability but at the expense of decreased eMBB user rates and increased signaling complexity. Conversely, NOMA and RSMA offer higher eMBB rates but may lead to MC packet loss and AoI degradation. The paper systematically investigates the conditions under which NOMA or RSMA can closely match the average AoI and PAoI violation performance of puncturing while maintaining data rate gains. Closed-form expressions for average AoI and PAoI violation probability are derived, and conditions on the eMBB and MC channel gain difference with respect to the base station are analyzed. Additionally, optimal power and rate splitting factors in RSMA are determined through an exhaustive search to minimize MC outage probability. Notably, our results indicate that with a small loss in the average AoI and PAoI violation probability the eMBB rate in NOMA and RSMA can be approximately five times higher than that achieved through puncturing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12926v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Farnaz Khodakhah, Aamir Mahmood, \v{C}edomir Stefanovi\'c, Hossam Farag, Patrik \"Osterberg, Mikael Gidlund</dc:creator>
    </item>
    <item>
      <title>Soft Decision Decoding of Recursive Plotkin Constructions Based on Hidden Code Words</title>
      <link>https://arxiv.org/abs/2408.12946</link>
      <description>arXiv:2408.12946v1 Announce Type: new 
Abstract: The Plotkin construction combines two codes to a code of doubled length. It can be applied recursively. The class of Reed-Muller (RM) codes is a particular example. Also, a special class of generalized concatenated codes (GCC) can be described as recursive Plotkin construction. Exploiting a property of the code words constructed by the recursive Plotkin construction, we present novel soft-decision decoders. These are based on the decoding of hidden code words which are inherent contained in the constructed code words and can be uncovered by adding particular parts of the overall code word. The main idea is to use more than one decoding variant where each variant starts with the decoding of a different hidden code word. The final decoding decision selects the best of the decisions of the used variants. The more variants are used the closer the performance gets to the maximum-likelihood (ML) decoding performance. This is verified by an ML-bound for the cases where the ML performance is not known. The decoding algorithms use only additions, comparisons, and sign operations. Further, due to the recursive structure, only relatively short codes have to be decoded, thus, the decoding complexity is very low. In addition, we introduce two novel classes of half-rate codes based on recursive Plotkin constructions with RM codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12946v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Bossert</dc:creator>
    </item>
    <item>
      <title>Symplectic Bregman divergences</title>
      <link>https://arxiv.org/abs/2408.12961</link>
      <description>arXiv:2408.12961v2 Announce Type: new 
Abstract: We present a generalization of Bregman divergences in symplectic vector spaces that we term symplectic Bregman divergences. Symplectic Bregman divergences are derived from a symplectic generalization of the Fenchel-Young inequality which relies on the notion of symplectic subdifferentials. The symplectic Fenchel-Young inequality is obtained using the symplectic Fenchel transform which is defined with respect to a linear symplectic form. When the symplectic form is built from an inner product, we show that the corresponding symplectic Bregman divergences amount to ordinary Bregman divergences with respect to composite inner products. Some potential applications of symplectic divergences in geometric mechanics, information geometry, and learning dynamics in machine learning are touched upon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12961v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank Nielsen</dc:creator>
    </item>
    <item>
      <title>Whispering Secrets in a Crowd: Leveraging Non-Covert Users for Covert Communications</title>
      <link>https://arxiv.org/abs/2408.12962</link>
      <description>arXiv:2408.12962v1 Announce Type: new 
Abstract: This paper establishes the fundamental limits of a multi-access system where multiple users communicate to a legitimate receiver in presence of an external warden. Only a specific subset of the users, called covert users, needs their communication to remain undetected to the warden, while the remaining non-covert users have no such constraint. The fundamental limits show a tradeoff between the different rates that are simultaneously achievable at the various users in function of the secret-key rates that the different users share with the legitimate receiver. Interestingly, the presence of the non-covert users can enhance the capacities of the covert users, especially under stringent secret-key budgets. Our findings underscore the essential requirement of employing a multiplexing (coded time-sharing) strategy to exhaust the fundamental region of all rates that are simultaneously achievable at the covert and the non-covert users. As a side-product of our results, we also establish the covert-capacity secret-key tradeoff for standard single-user and multi-access covert communication systems (without non-covert users), i.e., the largest covert rates that are achievable under given secret-key rate budgets. Previous works had only established the minimum secret-key rates required at largest covert rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12962v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdelaziz Bounhar, Mireille Sarkiss, Mich\`ele Wigger</dc:creator>
    </item>
    <item>
      <title>Cyclic Wrap-Around Multi-Access Coded Caching with Private Caches</title>
      <link>https://arxiv.org/abs/2408.13165</link>
      <description>arXiv:2408.13165v1 Announce Type: new 
Abstract: We consider a variant of the coded caching problem where users connect to two types of caches, called private caches and access caches. The problem setting consists of a server having a library of files and a set of access caches. Every user, equipped with a private cache, connects to $L$ neighboring access caches in a cyclic wrap-around fashion. The server populates the private and access caches with file contents in either coded or uncoded format. For this setting, we derive a lower bound on the optimal worst-case transmission rate using cut-set arguments. This lower bound applies to both coded and uncoded placements. We then provide an achievable scheme with uncoded placement and show that our scheme specializes to the well-known Maddah-Ali-Niesen scheme for the dedicated cache network in the absence of access caches. Finally, we show that the proposed scheme achieves optimality in large memory regimes and provide numerical plots comparing the rate of the proposed scheme with the derived lower bound, demonstrating the optimality of our scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13165v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dhruv Pratap Singh, Anjana A. Mahesh, B. Sundar Rajan</dc:creator>
    </item>
    <item>
      <title>On Information Theoretic Fairness: Compressed Representations With Perfect Demographic Parity</title>
      <link>https://arxiv.org/abs/2408.13168</link>
      <description>arXiv:2408.13168v1 Announce Type: new 
Abstract: In this article, we study the fundamental limits in the design of fair and/or private representations achieving perfect demographic parity and/or perfect privacy through the lens of information theory. More precisely, given some useful data $X$ that we wish to employ to solve a task $T$, we consider the design of a representation $Y$ that has no information of some sensitive attribute or secret $S$, that is, such that $I(Y;S) = 0$. We consider two scenarios. First, we consider a design desiderata where we want to maximize the information $I(Y;T)$ that the representation contains about the task, while constraining the level of compression (or encoding rate), that is, ensuring that $I(Y;X) \leq r$. Second, inspired by the Conditional Fairness Bottleneck problem, we consider a design desiderata where we want to maximize the information $I(Y;T|S)$ that the representation contains about the task which is not shared by the sensitive attribute or secret, while constraining the amount of irrelevant information, that is, ensuring that $I(Y;X|T,S) \leq r$. In both cases, we employ extended versions of the Functional Representation Lemma and the Strong Functional Representation Lemma and study the tightness of the obtained bounds. Every result here can also be interpreted as a coding with perfect privacy problem by considering the sensitive attribute as a secret.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13168v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amirreza Zamani, Borja Rodr\'iguez-G\'alvez, Mikael Skoglund</dc:creator>
    </item>
    <item>
      <title>Target Detection for OTFS-Aided Cell-Free MIMO ISAC System</title>
      <link>https://arxiv.org/abs/2408.13182</link>
      <description>arXiv:2408.13182v1 Announce Type: new 
Abstract: This letter focuses on enhancing target detection performance for a multi-user integrated sensing and communication (ISAC) system using orthogonal time frequency space (OTFS)-aided cell-free multiple-input multiple-output (MIMO) technology in high-speed vehicular environments. We propose a sensing-centric (SC) approach for target detection using communication signals with or without sensing signals. Power allocation is optimized to maximize the sensing signal-to-noise ratio (SNR) of the proposed SC scheme while ensuring a required quality-of-service (QoS) for the communication user equipment (UEs), and adhering to each access points (APs) power budget. Numerical results show that the proposed SC scheme vastly outperforms a communication-centric method that minimizes the total power consumed at the APs subject to the same constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13182v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shivani Singh, Amudheesan Nakkeeran, Prem Singh, Ekant Sharma, Jyotsna Bapat</dc:creator>
    </item>
    <item>
      <title>Bussgang revisited: effect of quantization on signal to distortion plus noise ratio with non-Gaussian signals</title>
      <link>https://arxiv.org/abs/2408.13205</link>
      <description>arXiv:2408.13205v1 Announce Type: new 
Abstract: Quantization plays an important role in the physical layer (PHY) disaggregation which is fundamental to the Open Radio Access Network (O-RAN) architecture, since digitized signals must be transmitted over fronthaul connections. In this paper we explore the effect of quantization on PHY performance, drawing on the Bussgang decomposition and the implications of the Bussgang theorem and extending it to the case of non-Gaussian signals. We first prove several theorems regarding the signal to distortion plus noise ratio for a general non-linearity, applicable to both the Gaussian and the non-Gaussian case, showing that the decomposition can be applied to the non-Gaussian case, but that formulae previously introduced should be amended. We then apply these results to the non-linearity created by quantization, both for Gaussian and non-Gaussian signal distributions, and give numerical results derived from both theory and simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13205v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alister Burr, Abigail Elcock, Junbo Zhao</dc:creator>
    </item>
    <item>
      <title>Information and motor constraints shape melodic diversity across cultures</title>
      <link>https://arxiv.org/abs/2408.12635</link>
      <description>arXiv:2408.12635v1 Announce Type: cross 
Abstract: The number of possible melodies is unfathomably large, yet despite this virtually unlimited potential for melodic variation, melodies from different societies can be surprisingly similar. The motor constraint hypothesis accounts for certain similarities, such as scalar motion and contour shape, but not for other major common features, such as repetition, song length, and scale size. Here we investigate the role of information constraints arising from limitations on human memory in shaping these hallmarks of melodies. We measure determinants of information rate in 62 corpora of Folk melodies spanning several continents, finding multiple trade-offs that all act to constrain the information rate across societies. By contrast, 39 corpora of Art music from Europe (including Turkey) show longer, more complex melodies, and increased complexity over time, suggesting different cultural-evolutionary selection pressures in Art and Folk music, possibly due to the use of written versus oral transmission. Our parameter-free model predicts the empirical scale degree distribution using information constraints on scalar motion, melody length, and, most importantly, information rate. This provides strong evidence that information constraints during cultural transmission of music limit the number of notes in a scale, and proposes that preference for intermediate melodic complexity is a fundamental constraint on the cultural evolution of melody.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12635v1</guid>
      <category>cs.SD</category>
      <category>cs.IT</category>
      <category>eess.AS</category>
      <category>math.IT</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>John M McBride, Nahie Kim, Yuri Nishikawa, Mekhmed Saadakeev, Marcus T Pearce, Tsvi Tlusty</dc:creator>
    </item>
    <item>
      <title>Disentangled Structural and Featural Representation for Task-Agnostic Graph Valuation</title>
      <link>https://arxiv.org/abs/2408.12659</link>
      <description>arXiv:2408.12659v1 Announce Type: cross 
Abstract: With the emergence of data marketplaces, the demand for methods to assess the value of data has increased significantly. While numerous techniques have been proposed for this purpose, none have specifically addressed graphs as the main data modality. Graphs are widely used across various fields, ranging from chemical molecules to social networks. In this study, we break down graphs into two main components: structural and featural, and we focus on evaluating data without relying on specific task-related metrics, making it applicable in practical scenarios where validation requirements may be lacking. We introduce a novel framework called blind message passing, which aligns the seller's and buyer's graphs using a shared node permutation based on graph matching. This allows us to utilize the graph Wasserstein distance to quantify the differences in the structural distribution of graph datasets, called the structural disparities. We then consider featural aspects of buyers' and sellers' graphs for data valuation and capture their statistical similarities and differences, referred to as relevance and diversity, respectively. Our approach ensures that buyers and sellers remain unaware of each other's datasets. Our experiments on real datasets demonstrate the effectiveness of our approach in capturing the relevance, diversity, and structural disparities of seller data for buyers, particularly in graph-based data valuation scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12659v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ali Falahati, Mohammad Mohammadi Amiri</dc:creator>
    </item>
    <item>
      <title>New Bounds on Quantum Sample Complexity of Measurement Classes</title>
      <link>https://arxiv.org/abs/2408.12683</link>
      <description>arXiv:2408.12683v1 Announce Type: cross 
Abstract: This paper studies quantum supervised learning for classical inference from quantum states. In this model, a learner has access to a set of labeled quantum samples as the training set. The objective is to find a quantum measurement that predicts the label of the unseen samples. The hardness of learning is measured via sample complexity under a quantum counterpart of the well-known probably approximately correct (PAC). Quantum sample complexity is expected to be higher than classical one, because of the measurement incompatibility and state collapse. Recent efforts showed that the sample complexity of learning a finite quantum concept class $\mathcal{C}$ scales as $O(|\mathcal{C}|)$. This is significantly higher than the classical sample complexity that grows logarithmically with the class size. This work improves the sample complexity bound to $O(V_{\mathcal{C}^*} \log |\mathcal{C}^*|)$, where $\mathcal{C}^*$ is the set of extreme points of the convex closure of $\mathcal{C}$ and $V_{\mathcal{C}^*}$ is the shadow-norm of this set. We show the tightness of our bound for the class of bounded Hilbert-Schmidt norm, scaling as $O(\log |\mathcal{C}^*|)$. Our approach is based on a new quantum empirical risk minimization (ERM) algorithm equipped with a shadow tomography method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12683v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohsen Heidari, Wojciech Szpankowski</dc:creator>
    </item>
    <item>
      <title>High-distance codes with transversal Clifford and $T$-gates</title>
      <link>https://arxiv.org/abs/2408.12752</link>
      <description>arXiv:2408.12752v1 Announce Type: cross 
Abstract: The non-local interactions in several quantum devices allow for the realization of more compact quantum encodings while retaining the same degree of protection against noise. Anticipating that short to medium-length codes will soon be realizable, it is important to construct stabilizer codes that, for a given code distance, admit fault-tolerant implementations of logical gates with the fewest number of physical qubits. We extract high-distance doubly even codes from the quantum quadratic-residue code family that admit a transversal implementation of the single-qubit Clifford group. Applying a doubling procedure [arXiv:1509.03239] to such codes yields a family of high-distance triply even codes which admit a transversal implementation of the logical $\texttt{T}$-gate. To our knowledge, both code families require a lower qubit overhead than any other qubit stabilizer code of the same distance which can realize their respective gates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12752v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.NT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shubham P. Jain, Victor V. Albert</dc:creator>
    </item>
    <item>
      <title>Informational Embodiment: Computational role of information structure in codes and robots</title>
      <link>https://arxiv.org/abs/2408.12950</link>
      <description>arXiv:2408.12950v1 Announce Type: cross 
Abstract: The body morphology plays an important role in the way information is perceived and processed by an agent. We address an information theory (IT) account on how the precision of sensors, the accuracy of motors, their placement, the body geometry, shape the information structure in robots and computational codes. As an original idea, we envision the robot's body as a physical communication channel through which information is conveyed, in and out, despite intrinsic noise and material limitations. Following this, entropy, a measure of information and uncertainty, can be used to maximize the efficiency of robot design and of algorithmic codes per se. This is known as the principle of Entropy Maximization (PEM) introduced in biology by Barlow in 1969. The Shannon's source coding theorem provides then a framework to compare different types of bodies in terms of sensorimotor information. In line with PME, we introduce a special class of efficient codes used in IT that reached the Shannon limits in terms of information capacity for error correction and robustness against noise, and parsimony. These efficient codes, which exploit insightfully quantization and randomness, permit to deal with uncertainty, redundancy and compacity. These features can be used for perception and control in intelligent systems. In various examples and closing discussions, we reflect on the broader implications of our framework that we called Informational Embodiment to motor theory and bio-inspired robotics, touching upon concepts like motor synergies, reservoir computing, and morphological computation. These insights can contribute to a deeper understanding of how information theory intersects with the embodiment of intelligence in both natural and artificial systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12950v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandre Pitti, Kohei Nakajima, Yasuo Kuniyoshi</dc:creator>
    </item>
    <item>
      <title>Semantic Variational Bayes Based on a Semantic Information Theory for Solving Latent Variables</title>
      <link>https://arxiv.org/abs/2408.13122</link>
      <description>arXiv:2408.13122v1 Announce Type: cross 
Abstract: The Variational Bayesian method (VB) is used to solve the probability distributions of latent variables with the minimum free energy criterion. This criterion is not easy to understand, and the computation is complex. For these reasons, this paper proposes the Semantic Variational Bayes' method (SVB). The Semantic Information Theory the author previously proposed extends the rate-distortion function R(D) to the rate-fidelity function R(G), where R is the minimum mutual information for given semantic mutual information G. SVB came from the parameter solution of R(G), where the variational and iterative methods originated from Shannon et al.'s research on the rate-distortion function. The constraint functions SVB uses include likelihood, truth, membership, similarity, and distortion functions. SVB uses the maximum information efficiency (G/R) criterion, including the maximum semantic information criterion for optimizing model parameters and the minimum mutual information criterion for optimizing the Shannon channel. For the same tasks, SVB is computationally simpler than VB. The computational experiments in the paper include 1) using a mixture model as an example to show that the mixture model converges as G/R increases; 2) demonstrating the application of SVB in data compression with a group of error ranges as the constraint; 3) illustrating how the semantic information measure and SVB can be used for maximum entropy control and reinforcement learning in control tasks with given range constraints, providing numerical evidence for balancing control's purposiveness and efficiency. Further research is needed to apply SVB to neural networks and deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13122v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenguang Lu</dc:creator>
    </item>
    <item>
      <title>Fundamental Limits of Multi-Message Private Computation</title>
      <link>https://arxiv.org/abs/2305.05332</link>
      <description>arXiv:2305.05332v5 Announce Type: replace 
Abstract: In a typical formulation of the private information retrieval (PIR) problem, a single user wishes to retrieve one out of $ K$ files from $N$ servers without revealing the demanded file index to any server. This paper formulates an extended model of PIR, referred to as multi-message private computation (MM-PC), where instead of retrieving a single file, the user wishes to retrieve $P&gt;1$ linear combinations of files while preserving the privacy of the demand information. The MM-PC problem is a generalization of the private computation (PC) problem (where the user requests one linear combination of the files), and the multi-message private information retrieval (MM-PIR) problem (where the user requests $P&gt;1$ files). A baseline achievable scheme repeats the optimal PC scheme by Sun and Jafar $P$ times, or treats each possible demanded linear combination as an independent file and then uses the near optimal MM-PIR scheme by Banawan and Ulukus. In this paper, we propose a new MM-PC scheme that significantly improves upon the baseline schemes. In doing so, we design the queries inspired by the structure in the cache-aided scalar linear function retrieval scheme by Wan {\it et al.}, which leverages the dependency between linear functions to reduce the amount of communications. To ensure the decodability of our scheme, we propose a new method to benefit from the existing dependency, referred to as the sign assignment step. In the end, we use Maximum Distance Separable matrices to code the queries, which allows the reduction of download from the servers, while preserving privacy. By the proposed schemes, we characterize the capacity within a multiplicative factor of $2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.05332v5</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Gholami, Kai Wan, Tayyebeh Jahani-Nezhad, Hua Sun, Mingyue Ji, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>On the Impact of Dynamic Beamforming on EMF Exposure and Network Coverage: A Stochastic Geometry Perspective</title>
      <link>https://arxiv.org/abs/2405.01190</link>
      <description>arXiv:2405.01190v3 Announce Type: replace 
Abstract: This paper introduces a new mathematical framework for dynamic beamforming-based cellular networks, grounded in stochastic geometry. The framework is used to study the electromagnetic field exposure (EMFE) of active and idle users as a function of the distance between them. A novel multi-cosine antenna pattern is introduced, offering more accurate modeling by incorporating both main and side lobes. Results show that the cumulative distribution functions of EMFE and coverage obtained with the multi-cosine pattern align closely with theoretical models, reducing error to less than 2\%, compared to a minimum of 8\% for other models. The marginal distribution of EMFE for each user type is mathematically derived. A unique contribution is the introduction of the SCAIU (\underline{S}patial \underline{C}DF for \underline{A}ctive and \underline{I}dle \underline{U}sers), a metric that ensures coverage for active users while limiting EMFE for idle users. Network performance is analyzed using these metrics across varying distances and antenna elements. The analysis reveals that, for the chosen network parameters, with 64 antenna elements, the impact on idle user EMFE becomes negligible beyond 60~m. However, to maintain active user SINR above 10 dB and idle user EMFE below -50~dBm at 2~m, more than 256 elements are required.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01190v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quentin Gontier, Charles Wiame, Joe Wiart, Fran\c{c}ois Horlin, Christo Tsigros, Claude Oestges, Philippe De Doncker</dc:creator>
    </item>
    <item>
      <title>The phase diagram of compressed sensing with $\ell_0$-norm regularization</title>
      <link>https://arxiv.org/abs/2408.08319</link>
      <description>arXiv:2408.08319v2 Announce Type: replace 
Abstract: Noiseless compressive sensing is a two-steps setting that allows for undersampling a sparse signal and then reconstructing it without loss of information. The LASSO algorithm, based on $\lone$ regularization, provides an efficient and robust to address this problem, but it fails in the regime of very high compression rate. Here we present two algorithms based on $\lzero$-norm regularization instead that outperform the LASSO in terms of compression rate in the Gaussian design setting for measurement matrix. These algorithms are based on the Approximate Survey Propagation, an algorithmic family within the Approximate Message Passing class. In the large system limit, they can be rigorously tracked through State Evolution equations and it is possible to exactly predict the range compression rates for which perfect signal reconstruction is possible. We also provide a statistical physics analysis of the $\lzero$-norm noiseless compressive sensing model. We show the existence of both a replica symmetric state and a 1-step replica symmmetry broken (1RSB) state for sufficiently low $\lzero$-norm regularization. The recovery limits of our algorithms are linked to the behavior of the 1RSB solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08319v2</guid>
      <category>cs.IT</category>
      <category>cond-mat.dis-nn</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Damien Barbier, Carlo Lucibello, Luca Saglietti, Florent Krzakala, Lenka Zdeborov\'a</dc:creator>
    </item>
    <item>
      <title>Optical ISAC: Fundamental Performance Limits and Transceiver Design</title>
      <link>https://arxiv.org/abs/2408.11792</link>
      <description>arXiv:2408.11792v3 Announce Type: replace 
Abstract: This paper characterizes the optimal capacity-distortion (C-D) tradeoff in an optical point-to-point (P2P) system with single-input single-output for communication and single-input multiple-output for sensing (SISO-COM and SIMO-SEN) within an integrated sensing and communication (ISAC) framework. We consider the optimal rate-distortion (R-D) region and explore several inner (IB) and outer (OB) bounds. We introduce practical, asymptotically optimal maximum a posteriori (MAP) and maximum likelihood estimators (MLE) for target distance, addressing nonlinear measurement-to-state relationships and non-conjugate priors. As the number of sensing antennas increases, these estimators converge to the Bayesian Cram\'er-Rao bound (BCRB). We also establish that the achievable rate-CRB (AR-CRB) serves as an OB for the optimal C-D region, valid for both unbiased estimators and asymptotically large numbers of receive antennas. To clarify that the input distribution determines the tradeoff across the Pareto boundary of the C-D region, we propose two algorithms: \textit{i}) an iterative Blahut-Arimoto algorithm (BAA)-type method, and \textit{ii}) a memory-efficient closed-form (CF) approach. The CF approach includes a CF optimal distribution for high optical signal-to-noise ratio (O-SNR) conditions. Additionally, we adapt and refine the Deterministic-Random Tradeoff (DRT) to this optical ISAC context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11792v3</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alireza Ghazavi Khorasgani, Mahtab Mirmohseni, Ahmed Elzanaty</dc:creator>
    </item>
    <item>
      <title>On the connection between least squares, regularization, and classical shadows</title>
      <link>https://arxiv.org/abs/2310.16921</link>
      <description>arXiv:2310.16921v3 Announce Type: replace-cross 
Abstract: Classical shadows (CS) offer a resource-efficient means to estimate quantum observables, circumventing the need for exhaustive state tomography. Here, we clarify and explore the connection between CS techniques and least squares (LS) and regularized least squares (RLS) methods commonly used in machine learning and data analysis. By formal identification of LS and RLS "shadows" completely analogous to those in CS -- namely, point estimators calculated from the empirical frequencies of single measurements -- we show that both RLS and CS can be viewed as regularizers for the underdetermined regime, replacing the pseudoinverse with invertible alternatives. Through numerical simulations, we evaluate RLS and CS from three distinct angles: the tradeoff in bias and variance, mismatch between the expected and actual measurement distributions, and the interplay between the number of measurements and number of shots per measurement. Compared to CS, RLS attains lower variance at the expense of bias, is robust to distribution mismatch, and is more sensitive to the number of shots for a fixed number of state copies -- differences that can be understood from the distinct approaches taken to regularization. Conceptually, our integration of LS, RLS, and CS under a unifying "shadow" umbrella aids in advancing the overall picture of CS techniques, while practically our results highlight the tradeoffs intrinsic to these measurement approaches, illuminating the circumstances under which either RLS or CS would be preferred, such as unverified randomness for the former or unbiased estimation for the latter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.16921v3</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhihui Zhu, Joseph M. Lukens, Brian T. Kirby</dc:creator>
    </item>
    <item>
      <title>Geometric signals</title>
      <link>https://arxiv.org/abs/2403.15978</link>
      <description>arXiv:2403.15978v3 Announce Type: replace-cross 
Abstract: In signal processing, a signal is a function. Conceptually, replacing a function by its graph, and extending this approach to a more abstract setting, we define a signal as a submanifold M of a Riemannian manifold (with corners) that satisfies additional conditions. In particular, it is a relative cobordism between two manifolds with boundaries. We define energy as the integral of the distance function to the first of these boundary manifolds. Composition of signals is composition of cobordisms. A "time variable" can appear explicitly if it is explictly given (for example, if the manifold is of the form $\Sigma\times [0,1]$). Otherwise, there is no designated "time dimension", although the cobordism may implicitly indicate the presence of dynamics. We interpret a local deformation of the metric as noise. The assumptions on M allow to define a map $M\to M$ that we call a Fourier transform. We prove inequalities that illustrate the properties of energy of signals in this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15978v3</guid>
      <category>math.DG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tatyana Barron</dc:creator>
    </item>
    <item>
      <title>Optimal Gaussian Strategies for Vector-valued Witsenhausen Counterexample with Non-causal State Estimator</title>
      <link>https://arxiv.org/abs/2408.02807</link>
      <description>arXiv:2408.02807v2 Announce Type: replace-cross 
Abstract: In this study, we investigate a vector-valued Witsenhausen model where the second decision maker (DM) acquires a vector of observations before selecting a vector of estimations. Here, the first DM acts causally whereas the second DM estimates non-causally. When the vector length grows, we characterize, via a single-letter expression, the optimal trade-off between the power cost at the first DM and the estimation cost at the second DM. In this paper, we show that the best linear scheme is achieved by using the time-sharing method between two affine strategies, which coincides with the convex envelope of the solution of Witsenhausen in 1968. Here also, Witsenhausen's two-point strategy and the scheme of Grover and Sahai in 2010 where both devices operate non-causally, outperform our best linear scheme. Therefore, gains obtained with block-coding schemes are only attainable if all DMs operate non-causally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02807v2</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 26 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mengyuan Zhao, Tobias J. Oechtering, Ma\"el Le Treust</dc:creator>
    </item>
  </channel>
</rss>
