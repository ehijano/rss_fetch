<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Nov 2025 05:01:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Inclusive and Exclusive Vertex Splitting into Specific Graph Classes: NP Hardness and Algorithms</title>
      <link>https://arxiv.org/abs/2510.26938</link>
      <description>arXiv:2510.26938v1 Announce Type: new 
Abstract: We study a family of graph modification problems called the F-Vertex Splitting problem. Given a graph G, the task is to determine whether G can be transformed into a graph G-prime belonging to a graph class F through a sequence of at most k vertex splits. We investigate this problem for several target graph classes, namely constellations, cycle graphs, linear forests, and bipartite graphs. We analyze both inclusive and exclusive variants of vertex splitting, as introduced by Abu-Khzam and collaborators (ISCO 2018). Our results show that the F-Vertex Splitting problem is polynomial-time solvable when F is a cycle graph or a linear forest, for both variants. In contrast, when F is a constellation or a bipartite graph, the problem is NP-complete for both variants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26938v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajinkya Gaikwad, Hitendra Kumar, S. Padmapriya, Praneet Kumar Patra, Harsh Sanklecha, Soumen Maity</dc:creator>
    </item>
    <item>
      <title>Green Bin Packing</title>
      <link>https://arxiv.org/abs/2510.26968</link>
      <description>arXiv:2510.26968v1 Announce Type: new 
Abstract: The online bin packing problem and its variants are regularly used to model server allocation problems. Modern concerns surrounding sustainability and overcommitment in cloud computing motivate bin packing models that capture costs associated with highly utilized servers. In this work, we introduce the green bin packing problem, an online variant with a linear cost $\beta$ for filling above a fixed level $G$. For a given instance, the goal is to minimize the sum of the number of opened bins and the linear cost. We show that when $\beta G \le 1$, classical online bin packing algorithms such as FirstFit or Harmonic perform well, and can achieve competitive ratios lower than in the classic setting. However, when $\beta G &gt; 1$, new algorithmic solutions can improve both worst-case and typical performance. We introduce variants of classic online bin packing algorithms and establish theoretical bounds, as well as test their empirical performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26968v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jackson Bibbens, Cooper Sigrist, Bo Sun, Shahin Kamali, Mohammad Hajiesmaili</dc:creator>
    </item>
    <item>
      <title>A Simple Deterministic Reduction From Gomory-Hu Tree to Maxflow and Expander Decomposition</title>
      <link>https://arxiv.org/abs/2510.27330</link>
      <description>arXiv:2510.27330v1 Announce Type: new 
Abstract: Given an undirected graph $G=(V,E,w)$, a Gomory-Hu tree $T$ (Gomory and Hu, 1961) is a tree on $V$ that preserves all-pairs mincuts of $G$ exactly.
  We present a simple and efficient randomized reduction from Gomory-Hu trees to polylog maxflow computations. On unweighted graphs, our reduction reduces to maxflow computations on graphs of total instance size $\tilde{O}(m)$ and the algorithm requires only $\tilde{O}(m)$ additional time. Our reduction is the first that is tight up to polylog factors. The reduction also seamlessly extends to weighted graphs, however, instance sizes and runtime increase to $\tilde{O}(n^2)$.
  Finally, we show how to extend our reduction to reduce Gomory-Hu trees for unweighted hypergraphs to maxflow in hypergraphs. Again, our reduction is the first that is tight up to polylog factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27330v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Probst Gutenberg, Weixuan Yuan</dc:creator>
    </item>
    <item>
      <title>Learned Static Function Data Structures</title>
      <link>https://arxiv.org/abs/2510.27588</link>
      <description>arXiv:2510.27588v1 Announce Type: new 
Abstract: We consider the task of constructing a data structure for associating a static set of keys with values, while allowing arbitrary output values for queries involving keys outside the set. Compared to hash tables, these so-called static function data structures do not need to store the key set and thus use significantly less memory. Several techniques are known, with compressed static functions approaching the zero-order empirical entropy of the value sequence. In this paper, we introduce learned static functions, which use machine learning to capture correlations between keys and values. For each key, a model predicts a probability distribution over the values, from which we derive a key-specific prefix code to compactly encode the true value. The resulting codeword is stored in a classic static function data structure. This design allows learned static functions to break the zero-order entropy barrier while still supporting point queries. Our experiments show substantial space savings: up to one order of magnitude on real data, and up to three orders of magnitude on synthetic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27588v1</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Hermann, Hans-Peter Lehmann, Giorgio Vinciguerra, Stefan Walzer</dc:creator>
    </item>
    <item>
      <title>Rateless Bloom Filters: Set Reconciliation for Divergent Replicas with Variable-Sized Elements</title>
      <link>https://arxiv.org/abs/2510.27614</link>
      <description>arXiv:2510.27614v1 Announce Type: new 
Abstract: Set reconciliation protocols typically make two critical assumptions: they are designed for fixed-sized elements and they are optimized for when the difference cardinality, d, is very small. When adapting to variable-sized elements, the current practice is to synchronize fixed-size element digests. However, when the number of differences is considerable, such as after a network partition, this approach can be inefficient. Our solution is a two-stage hybrid protocol that introduces a preliminary Bloom filter step, specifically designed for this regime. The novelty of this approach, however, is in solving a core technical challenge: determining the optimal Bloom filter size without knowing d. Our solution is the Rateless Bloom Filter (RBF), a dynamic filter that naturally adapts to arbitrary symmetric differences, closely matching the communication complexity of an optimally configured static filter without requiring any prior parametrization. Our evaluation in sets of variable-sized elements shows that for Jaccard indices below 85%, our RBF-IBLT hybrid protocol reduces the total communication cost by up to over 20% compared to the state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27614v1</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pedro Silva Gomes, Carlos Baquero</dc:creator>
    </item>
    <item>
      <title>Constructive Characterization and Recognition Algorithm for Grafts with a Connected Minimum Join</title>
      <link>https://arxiv.org/abs/2510.26975</link>
      <description>arXiv:2510.26975v1 Announce Type: cross 
Abstract: Minimum joins in a graft $(G, T)$, also known as minimum $T$-joins of a graph $G$, are said to be connected if they determine a connected subgraph of $G$. Grafts with a connected minimum join have gained interest ever since Middendorf and Pfeiffer showed that they satisfy Seymour's min-max formula for joins and $T$-cut packings; that is, in such grafts, the size of a minimum join is equal to the size of a maximum packing of $T$-cuts. In this paper, we provide a constructive characterization of grafts with a connected minimum join. We also obtain a polynomial time algorithm that decides whether a given graft has a connected minimum join and, if so, outputs one. Our algorithm has two bottlenecks; one is the time required to compute a minimum join of a graft, and the other is the time required to solve the single-source all-sink shortest path problem in a graph with conservative $\pm 1$-valued edge weights. Thus, our algorithm runs in $O(n(m + n\log n) )$ time. In the nondense case, it improves upon the time bound for this problem due to Seb\H{o} and Tannier that was introduced as an application of their results on metrics on graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26975v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nanano Kita</dc:creator>
    </item>
    <item>
      <title>Understanding the Cluster LP for Correlation Clustering</title>
      <link>https://arxiv.org/abs/2404.17509</link>
      <description>arXiv:2404.17509v3 Announce Type: replace 
Abstract: In the classic Correlation Clustering problem introduced by Bansal, Blum, and Chawla (FOCS 2002), the input is a complete graph where edges are labeled either $+$ or $-$, and the goal is to find a partition of the vertices that minimizes the sum of the +edges across parts plus the sum of the -edges within parts. In recent years, Chawla, Makarychev, Schramm and Yaroslavtsev (STOC 2015) gave a 2.06-approximation by providing a near-optimal rounding of the standard LP, and Cohen-Addad, Lee, Li, and Newman (FOCS 2022, 2023) finally bypassed the integrality gap of 2 for this LP giving a $1.73$-approximation for the problem.
  In order to create a simple and unified framework for Correlation Clustering similar to those for typical approximate optimization tasks, we propose the cluster LP as a strong linear program for Correlation Clustering. We demonstrate the power of the cluster LP by presenting new rounding algorithms, and providing two analyses, one analytically proving a 1.56-approximation and the other solving a factor-revealing SDP to show a 1.485-approximation. Both proofs introduce principled methods by which to analyze the performance of the algorithm, resulting in a significantly improved approximation guarantee.
  Finally, we prove an integrality gap of $4/3$ for the cluster LP, showing our 1.485-upper bound cannot be drastically improved. Our gap instance directly inspires an improved NP-hardness of approximation with a ratio $24/23 \approx 1.042$; no explicit hardness ratio was known before.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17509v3</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3618260.3649749</arxiv:DOI>
      <dc:creator>Nairen Cao, Vincent Cohen-Addad, Euiwoong Lee, Shi Li, Alantha Newman, Lukas Vogl</dc:creator>
    </item>
    <item>
      <title>Markovian Search with Ex-Ante Constraints: Theory and Applications to Socially Aware Algorithmic Hiring</title>
      <link>https://arxiv.org/abs/2501.13346</link>
      <description>arXiv:2501.13346v2 Announce Type: replace 
Abstract: We develop an algorithmic framework to incorporate "ex-ante" constraints on outcomes (that hold only on average) into stateful sequential search with costly inspection. Our framework encompasses the classical Weitzman's Pandora's box [Weitzman, 1979] as well as its extensions to joint Markovian scheduling [Dumitriu et al., 2003; Gittins, 1979], modeling richer processes such as multistage search with multiple layers of inspection. Ex-ante constraints in search are particularly motivated by social considerations in algorithmic hiring, where they adjust outcome distributions to promote equity and access. Building on the optimality of index-based policies in the unconstrained problems, we show that optimal policies under a single ex-ante constraint (e.g., demographic parity) retain an index-based structure but require (i) dual-based adjustments of the indices and (ii) randomization between two such adjustments via a "tie-breaking rule," both easy to compute and economically interpretable. We then extend our results to handle multiple affine constraints by reduction to a variant of the exact Carath\'eodory problem and providing a polynomial-time algorithm to construct an optimal randomized dual-adjusted index-based policy that satisfies all constraints simultaneously. For general affine and convex constraints, we develop a primal-dual algorithm that randomizes over a polynomial number of dual-based adjustments, yielding a near-feasible, near-optimal policy. All these results rely on the key observation that a suitable relaxation of the Lagrange dual function for these constrained problems admits index-based policies akin to those in the unconstrained setting. Finally, through a numerical study, we investigate the implications of various socially aware ex-ante constraints on the utilitarian loss (price of fairness), and examine whether they achieve their intended socially desirable outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13346v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Reza Aminian, Vahideh Manshadi, Rad Niazadeh</dc:creator>
    </item>
    <item>
      <title>Beer Path Problems in Temporal Graphs</title>
      <link>https://arxiv.org/abs/2507.08685</link>
      <description>arXiv:2507.08685v2 Announce Type: replace 
Abstract: Computing paths in graph structures is a fundamental operation in a wide range of applications, from transportation networks to data analysis. The beer path problem, which captures the option of visiting points of interest, such as gas stations or convenience stops, prior to reaching the final destination, has been recently introduced and extensively studied in static graphs. However, existing approaches do not account for temporal information, which is often crucial in real-world scenarios. For instance, transit services may follow fixed schedules, and shops may only be accessible during certain hours.
  In this work, we introduce the notion of beer paths in temporal graphs, where edges are time-dependent and certain vertices (beer vertices) are active only at specific time instances. We formally define the problems of computing earliest-arrival, latest-departure, fastest, and shortest temporal beer paths and propose efficient algorithms for these problems under both edge stream and adjacency list representations. The time complexity of each of our algorithms is aligned with that of corresponding temporal pathfinding algorithms, thus preserving efficiency.
  Additionally, we present preprocessing techniques that enable efficient query answering under dynamic conditions, for example new openings or closings of shops. We achieve this through appropriate precomputation of selected paths or by transforming a temporal graph into an equivalent static graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08685v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 03 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea D'Ascenzo, Giuseppe F. Italiano, Sotiris Kanellopoulos, Anna Mpanti, Aris Pagourtzis, Christos Pergaminelis</dc:creator>
    </item>
  </channel>
</rss>
