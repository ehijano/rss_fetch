<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Sep 2024 01:39:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Penalty Adversarial Network (PAN): A neural network-based method to solve PDE-constrained optimal control problems</title>
      <link>https://arxiv.org/abs/2409.02260</link>
      <description>arXiv:2409.02260v1 Announce Type: new 
Abstract: In this work, we introduce a novel strategy for tackling constrained optimization problems through a modified penalty method. Conventional penalty methods convert constrained problems into unconstrained ones by incorporating constraints into the loss function via a penalty term. However, selecting an optimal penalty parameter remains challenging; an improper choice, whether excessively high or low, can significantly impede the discovery of the true solution. This challenge is particularly evident when training neural networks for constrained optimization, where tuning parameters can become an extensive and laborious task. To overcome these issues, we propose an adversarial approach that redefines the conventional penalty method by simultaneously considering two competing penalty problems--a technique we term the penalty adversarial problem. Within linear settings, our method not only ensures the fulfillment of constraints but also guarantees solvability, leading to more precise solutions compared to traditional approaches. We further reveal that our method effectively performs an automatic adjustment of penalty parameters by leveraging the relationship between the objective and loss functions, thereby obviating the need for manual parameter tuning. Additionally, we extend this adversarial framework to develop a neural network-based solution for optimal control problems governed by linear or nonlinear partial differential equations. We demonstrate the efficacy of this innovative approach through a series of numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02260v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shilin Ma, Yukun Yue</dc:creator>
    </item>
    <item>
      <title>Parameter estimation of hidden Markov models: comparison of EM and quasi-Newton methods with a new hybrid algorithm</title>
      <link>https://arxiv.org/abs/2409.02477</link>
      <description>arXiv:2409.02477v1 Announce Type: new 
Abstract: Hidden Markov Models (HMM) model a sequence of observations that are dependent on a hidden (or latent) state that follow a Markov chain. These models are widely used in diverse fields including ecology, speech recognition, and genetics.Parameter estimation in HMM is typically performed using the Baum-Welch algorithm, a special case of the Expectation-Maximisation (EM) algorithm. While this method guarantee the convergence to a local maximum, its convergence rates is usually slow.Alternative methods, such as the direct maximisation of the likelihood using quasi-Newton methods (such as L-BFGS-B) can offer faster convergence but can be more complicated to implement due to challenges to deal with the presence of bounds on the space of parameters.We propose a novel hybrid algorithm, QNEM, that combines the Baum-Welch and the quasi-Newton algorithms. QNEM aims to leverage the strength of both algorithms by switching from one method to the other based on the convexity of the likelihood function.We conducted a comparative analysis between QNEM, the Baum-Welch algorithm, an EM acceleration algorithm called SQUAREM (Varadhan, 2008, Scand J Statist), and the L-BFGS-B quasi-Newton method by applying these algorithms to four examples built on different models. We estimated the parameters of each model using the different algorithms and evaluated their performances.Our results show that the best-performing algorithm depends on the model considered. QNEM performs well overall, always being faster or equivalent to L-BFGS-B. The Baum-Welch and SQUAREM algorithms are faster than the quasi-Newton and QNEM algorithms in certain scenarios with multiple optimum. In conclusion, QNEM offers a promising alternative to existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02477v1</guid>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sidonie Foulon (CESP, NeuroDiderot), Th\'er\`ese Truong (CESP), Anne-Louise Leutenegger (NeuroDiderot), Herv\'e Perdry (CESP)</dc:creator>
    </item>
    <item>
      <title>Stochastic maximum principle for optimal control problem with varying terminal time and non-convex control domain</title>
      <link>https://arxiv.org/abs/2409.02491</link>
      <description>arXiv:2409.02491v1 Announce Type: new 
Abstract: In this paper, we consider a varying terminal time structure for the stochastic optimal control problem under state constraints, in which the terminal time varies with the mean value of the state. In this new stochastic optimal control system, the control domain does not need to be convex and the diffusion coefficient contains the control variable. To overcome the difficulty in the proof of the related Pontryagin's stochastic maximum principle, we develop asymptotic first- and second-order adjoint equations for the varying terminal time, and then establish its variational equation. In the end, two examples are given to verify the main results of this study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02491v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Shi, Shuzhen Yang</dc:creator>
    </item>
    <item>
      <title>Revenue Management with Calendar-Aware and Dependent Demands: Asymptotically Tight Fluid Approximations</title>
      <link>https://arxiv.org/abs/2409.02637</link>
      <description>arXiv:2409.02637v1 Announce Type: new 
Abstract: When modeling the demand in revenue management systems, a natural approach is to focus on a canonical interval of time, such as a week, so that we forecast the demand over each week in the selling horizon. Ideally, we would like to use random variables with general distributions to model the demand over each week. The current demand can give a signal for the future demand, so we also would like to capture the dependence between the demands over different weeks. Prevalent demand models in the literature, which are based on a discrete-time approximation to a Poisson process, are not compatible with these needs. In this paper, we focus on revenue management models that are compatible with a natural approach for forecasting the demand. Building such models through dynamic programming is not difficult. We divide the selling horizon into multiple stages, each stage being a canonical interval of time on the calendar. We have random number of customer arrivals in each stage, whose distribution is arbitrary and depends on the number of arrivals in the previous stage. The question we seek to answer is the form of the corresponding fluid approximation. We give the correct fluid approximation in the sense that it yields asymptotically optimal policies. The form of our fluid approximation is surprising as its constraints use expected capacity consumption of a resource up to a certain time period, conditional on the demand in the stage just before the time period in question. As the resource capacities and number of stages increase with the same rate, our performance guarantee converges to one. To our knowledge, this result gives the first asymptotically optimal policy under dependent demands with arbitrary distributions. Our computational experiments indicate that using the correct fluid approximation can make a dramatic impact in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02637v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiyuan Li, Paat Rusmevichientong, Huseyin Topaloglu</dc:creator>
    </item>
    <item>
      <title>Linear Convergence in Hilbert's Projective Metric for Computing Augustin Information and a R\'{e}nyi Information Measure</title>
      <link>https://arxiv.org/abs/2409.02640</link>
      <description>arXiv:2409.02640v1 Announce Type: new 
Abstract: Consider the problems of computing the Augustin information and a R\'{e}nyi information measure of statistical independence, previously explored by Lapidoth and Pfister (\textit{IEEE Information Theory Workshop}, 2018) and Tomamichel and Hayashi (\textit{IEEE Trans. Inf. Theory}, 64(2):1064--1082, 2018). Both quantities are defined as solutions to optimization problems and lack closed-form expressions. This paper analyzes two iterative algorithms: Augustin's fixed-point iteration for computing the Augustin information, and the algorithm by Kamatsuka et al. (arXiv:2404.10950) for the R\'{e}nyi information measure. Previously, it was only known that these algorithms converge asymptotically. We establish the linear convergence of Augustin's algorithm for the Augustin information of order $\alpha \in (1/2, 1) \cup (1, 3/2)$ and Kamatsuka et al.'s algorithm for the R\'{e}nyi information measure of order $\alpha \in [1/2, 1) \cup (1, \infty)$, using Hilbert's projective metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02640v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chung-En Tsai, Guan-Ren Wang, Hao-Chung Cheng, Yen-Huan Li</dc:creator>
    </item>
    <item>
      <title>Optimal Power Grid Operations with Foundation Models</title>
      <link>https://arxiv.org/abs/2409.02148</link>
      <description>arXiv:2409.02148v1 Announce Type: cross 
Abstract: The energy transition, crucial for tackling the climate crisis, demands integrating numerous distributed, renewable energy sources into existing grids. Along with climate change and consumer behavioral changes, this leads to changes and variability in generation and load patterns, introducing significant complexity and uncertainty into grid planning and operations. While the industry has already started to exploit AI to overcome computational challenges of established grid simulation tools, we propose the use of AI Foundation Models (FMs) and advances in Graph Neural Networks to efficiently exploit poorly available grid data for different downstream tasks, enhancing grid operations. For capturing the grid's underlying physics, we believe that building a self-supervised model learning the power flow dynamics is a critical first step towards developing an FM for the power grid. We show how this approach may close the gap between the industry needs and current grid analysis capabilities, to bring the industry closer to optimal grid operation and planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02148v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alban Puech, Jonas Weiss, Thomas Brunschwiler, Hendrik F. Hamann</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Reinforcement Learning for Joint Police Patrol and Dispatch</title>
      <link>https://arxiv.org/abs/2409.02246</link>
      <description>arXiv:2409.02246v1 Announce Type: cross 
Abstract: Police patrol units need to split their time between performing preventive patrol and being dispatched to serve emergency incidents. In the existing literature, patrol and dispatch decisions are often studied separately. We consider joint optimization of these two decisions to improve police operations efficiency and reduce response time to emergency calls. Methodology/results: We propose a novel method for jointly optimizing multi-agent patrol and dispatch to learn policies yielding rapid response times. Our method treats each patroller as an independent Q-learner (agent) with a shared deep Q-network that represents the state-action values. The dispatching decisions are chosen using mixed-integer programming and value function approximation from combinatorial action spaces. We demonstrate that this heterogeneous multi-agent reinforcement learning approach is capable of learning joint policies that outperform those optimized for patrol or dispatch alone. Managerial Implications: Policies jointly optimized for patrol and dispatch can lead to more effective service while targeting demonstrably flexible objectives, such as those encouraging efficiency and equity in response.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02246v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Repasky, He Wang, Yao Xie</dc:creator>
    </item>
    <item>
      <title>Guidance for twisted particle filter: a continuous-time perspective</title>
      <link>https://arxiv.org/abs/2409.02399</link>
      <description>arXiv:2409.02399v1 Announce Type: cross 
Abstract: The particle filter (PF), also known as the sequential Monte Carlo (SMC), is designed to approximate high-dimensional probability distributions and their normalizing constants in the discrete-time setting. To reduce the variance of the Monte Carlo approximation, several twisted particle filters (TPF) have been proposed by researchers, where one chooses or learns a twisting function that modifies the Markov transition kernel. In this paper, we study the TPF from a continuous-time perspective. Under suitable settings, we show that the discrete-time model converges to a continuous-time limit, which can be solved through a series of well-studied control-based importance sampling algorithms. This discrete-continuous connection allows the design of new TPF algorithms inspired by established continuous-time algorithms. As a concrete example, guided by existing importance sampling algorithms in the continuous-time setting, we propose a novel algorithm called ``Twisted-Path Particle Filter" (TPPF), where the twist function, parameterized by neural networks, minimizes specific KL-divergence between path measures. Some numerical experiments are given to illustrate the capability of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02399v1</guid>
      <category>stat.CO</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianfeng Lu, Yuliang Wang</dc:creator>
    </item>
    <item>
      <title>Modelling, Design Optimization and Prototype development of Knee Exoskeleton</title>
      <link>https://arxiv.org/abs/2409.02635</link>
      <description>arXiv:2409.02635v1 Announce Type: cross 
Abstract: This study focuses on enhancing the design of an existing knee exoskeleton by addressing limitations in the range of motion (ROM) during Sit-to-Stand (STS) motions. While current knee exoskeletons emphasize toughness and rehabilitation, their closed-loop mechanisms hinder optimal ROM, which is crucial for effective rehabilitation. This research aims to optimize the exoskeleton design to achieve the necessary ROM, improving its functionality in rehabilitation. This can be achieved by utilizing kinematic modeling and formulation, the existing design was represented in the non-linear and non-convex mathematical functions. Optimization techniques, considering constraints based on human leg measurements, were applied to determine the best dimensions for the exoskeleton. This resulted in a significant increase in ROM compared to existing models. A MATLAB program was developed to compare the ROM of the optimized exoskeleton with the original design.
  To validate the practicality of the optimized design, analysis was conducted using a mannequin with average human dimensions, followed by constructing a cardboard dummy model to confirm simulation results. The STS motion of an average human was captured using a camera and TRACKER software, and the motion was compared with that of the dummy model to identify any misalignments between the human and exoskeleton knee joints. Furthermore, a prototype of the knee joint exoskeleton is being developed to further investigate misalignments and improve the design. Future work includes the use of EMG sensors for more detailed analysis and better results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02635v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Shashank Mani Gautam, Ekta Singla, Ashish Singla</dc:creator>
    </item>
    <item>
      <title>Pinning control of chimera states in systems with higher-order interactions</title>
      <link>https://arxiv.org/abs/2409.02658</link>
      <description>arXiv:2409.02658v1 Announce Type: cross 
Abstract: Understanding and controlling the mechanisms behind synchronization phenomena is of paramount importance in nonlinear science. In particular, chimera states, patterns in which order and disorder coexist simultaneously, continue to puzzle scholars, due to their elusive nature. Recently, it has been shown that higher-order interactions greatly promote the onset of chimera states, which are easier to found and more resilient when the system units interact in group. In this work, we show that the higher-order framework is fertile not only for the emergence of chimera states, but also for their control. Via pinning control, a technique consisting in applying a forcing to a subset of the nodes, we are able to trigger the emergence of chimera states with only a small fraction of controlled nodes, at striking contrast with the case without higher-order interactions. We show that our setting is robust for different higher-order topologies and types of pinning control and, finally, we give a heuristic interpretation of the results via phase reduction theory. Our numerical and theoretical results provide further understanding on how higher-order interactions shape nonlinear dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02658v1</guid>
      <category>nlin.PS</category>
      <category>math.OC</category>
      <category>nlin.AO</category>
      <category>nlin.CD</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Muolo, Lucia Valentina Gambuzza, Hiroya Nakao, Mattia Frasca</dc:creator>
    </item>
    <item>
      <title>First-order algorithms for robust optimization problems via convex-concave saddle-point Lagrangian reformulation</title>
      <link>https://arxiv.org/abs/2101.02669</link>
      <description>arXiv:2101.02669v2 Announce Type: replace 
Abstract: Robust optimization (RO) is one of the key paradigms for solving optimization problems affected by uncertainty. Two principal approaches for RO, the robust counterpart method and the adversarial approach, potentially lead to excessively large optimization problems. For that reason, first order approaches, based on online-convex-optimization, have been proposed (Ben-Tal et al. (2015), Kilinc-Karzan and Ho-Nguyen (2018)) as alternatives for the case of large-scale problems. However, these methods are either stochastic in nature or involve a binary search for the optimal value. We propose deterministic first-order algorithms based on a saddle-point Lagrangian reformulation that avoids both of these issues. Our approach recovers the other approaches' O(1/epsilon^2) convergence rate in the general case, and offers an improved O(1/epsilon) rate for problems with constraints which are affine both in the decision and in the uncertainty. Experiment involving robust quadratic optimization demonstrates the numerical benefits of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.02669v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krzysztof Postek, Shimrit Shtern</dc:creator>
    </item>
    <item>
      <title>Robust Time-inconsistent Linear-Quadratic Stochastic Controls: A Stochastic Differential Game Approach</title>
      <link>https://arxiv.org/abs/2306.16982</link>
      <description>arXiv:2306.16982v2 Announce Type: replace 
Abstract: This paper studies robust time-inconsistent (TIC) linear-quadratic stochastic control problems, formulated by stochastic differential games. By a spike variation approach, we derive sufficient conditions for achieving the Nash equilibrium, which corresponds to a time-consistent (TC) robust policy, under mild technical assumptions. To illustrate our framework, we consider two scenarios of robust mean-variance analysis, namely with state- and control-dependent ambiguity aversion. We find numerically that with time inconsistency haunting the dynamic optimal controls, the ambiguity aversion enhances the effective risk aversion faster than the linear, implying that the ambiguity in the TIC cases is more impactful than that under the TC counterparts, e.g., expected utility maximization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16982v2</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bingyan Han, Chi Seng Pun, Hoi Ying Wong</dc:creator>
    </item>
    <item>
      <title>Improved residual mode separation for finite-dimensional control of PDEs: application to the Euler-Bernoulli beam</title>
      <link>https://arxiv.org/abs/2308.05551</link>
      <description>arXiv:2308.05551v3 Announce Type: replace 
Abstract: We consider a simply-supported Euler-Bernoulli beam with viscous and Kelvin--Voigt damping. Our objective is to attenuate the effect of an unknown distributed disturbance using one piezoelectric actuator. We show how to design a suitable $H_\infty$ state-feedback controller based on a finite number of dominating modes. If the remaining (infinitely many) modes are ignored, the calculated $L^2$ gain is wrong. This happens because of the spillover phenomenon that occurs when the effect of the control on truncated modes is not accounted for in the feedback design. We propose a simple modification of the $H_\infty$ cost that prevents spillover. The key idea is to treat the control as a disturbance in the truncated modes and find the corresponding $L^2$ gains using the bounded real lemma. These $L^2$ gains are added to the control weight in the $H_\infty$ cost for the dominating modes, which prevents spillover. A numerical simulation of an aluminum beam with realistic parameters demonstrates the effectiveness of the proposed method. The presented approach is applicable to other types of PDEs, such as the heat, wave, and Kuramoto-Sivashinsky equations, as well as their semilinear versions. While this work focuses on $H_\infty$ control, the same methodology can be applied to guaranteed cost control, regional stability analysis, input-to-state stability, and systems with time-varying delays, including sampled-data systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.05551v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anton Selivanov, Emilia Fridman</dc:creator>
    </item>
    <item>
      <title>An Efficient Framework for Global Non-Convex Polynomial Optimization with Algebraic Constraints</title>
      <link>https://arxiv.org/abs/2311.02037</link>
      <description>arXiv:2311.02037v2 Announce Type: replace 
Abstract: We present an efficient framework for solving algebraically-constrained global non-convex polynomial optimization problems over subsets of the hypercube. We prove the existence of an equivalent nonlinear reformulation of such problems that possesses essentially no spurious local minima. Through numerical experiments on previously intractable global constrained polynomial optimization problems in high dimension, we show that polynomial scaling in dimension and degree is achievable when computing the optimal value and location.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02037v2</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mitchell Tong Harris, Pierre-David Letourneau, Dalton Jones, M. Harper Langston</dc:creator>
    </item>
    <item>
      <title>Fast System Level Synthesis: Robust Model Predictive Control using Riccati Recursions</title>
      <link>https://arxiv.org/abs/2401.13762</link>
      <description>arXiv:2401.13762v2 Announce Type: replace 
Abstract: System level synthesis enables improved robust MPC formulations by allowing for joint optimization of the nominal trajectory and controller. This paper introduces a tailored algorithm for solving the corresponding disturbance feedback optimization problem for linear time-varying systems. The proposed algorithm iterates between optimizing the controller and the nominal trajectory while converging q-linearly to an optimal solution. We show that the controller optimization can be solved through Riccati recursions leading to a horizon-length, state, and input scalability of $\mathcal{O}(N^2 ( n_x^3 +n_u^3))$ for each iterate. On a numerical example, the proposed algorithm exhibits computational speedups by a factor of up to $10^3$ compared to general-purpose commercial solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13762v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine P. Leeman, Johannes K\"ohler, Florian Messerer, Amon Lahr, Moritz Diehl, Melanie N. Zeilinger</dc:creator>
    </item>
    <item>
      <title>NMPC for Collision Avoidance by Superellipsoid Separation</title>
      <link>https://arxiv.org/abs/2404.14257</link>
      <description>arXiv:2404.14257v2 Announce Type: replace 
Abstract: This paper introduces a novel NMPC formulation for real-time obstacle avoidance on heavy equipment by modeling both vehicle and obstacles as convex superellipsoids. The combination of this approach with the separating hyperplane theorem and Optimization Engine (OpEn) allows to achieve efficient obstacle avoidance in autonomous heavy equipment and robotics. We demonstrate the efficacy of the approach through simulated and experimental results, showcasing a skid-steer loader's capability to navigate in obstructed environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14257v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1115/1.4066388</arxiv:DOI>
      <dc:creator>Ruairi Moran, Sheila Bagley, Seth Kasmann, Rob Martin, David Pasley, Shane Trimble, James Dianics, Pantelis Sopasakis</dc:creator>
    </item>
    <item>
      <title>Low-rank approximated Kalman filter using Oja's principal component flow for discrete-time linear systems</title>
      <link>https://arxiv.org/abs/2407.05675</link>
      <description>arXiv:2407.05675v2 Announce Type: replace 
Abstract: The Kalman filter is indispensable for state estimation across diverse fields but faces computational challenges with higher dimensions. Approaches such as Riccati equation approximations aim to alleviate this complexity, yet ensuring properties like bounded errors remains challenging. Yamada and Ohki introduced low-rank Kalman-Bucy filters for continuous-time systems, ensuring bounded errors. This paper proposes a discrete-time counterpart of the low-rank filter and shows its system theoretic properties and conditions for bounded mean square error estimation. Numerical simulations show the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05675v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daiki Tsuzuki, Kentaro Ohki</dc:creator>
    </item>
    <item>
      <title>Projection onto hyperbolicity cones and beyond: a dual Frank-Wolfe approach</title>
      <link>https://arxiv.org/abs/2407.09213</link>
      <description>arXiv:2407.09213v2 Announce Type: replace 
Abstract: We discuss the problem of projecting a point onto an arbitrary hyperbolicity cone from both theoretical and numerical perspectives. While hyperbolicity cones are furnished with a generalization of the notion of eigenvalues, obtaining closed form expressions for the projection operator as in the case of semidefinite matrices is an elusive endeavour. To address that we propose a Frank-Wolfe method to handle this task and, more generally, strongly convex optimization over closed convex cones. One of our innovations is that the Frank-Wolfe method is actually applied to the dual problem and, by doing so, subproblems can be solved in closed-form using minimum eigenvalue functions and conjugate vectors. To test the validity of our proposed approach, we present numerical experiments where we check the performance of alternative approaches including interior point methods and an earlier accelerated gradient method proposed by Renegar. We also show numerical examples where the hyperbolic polynomial has millions of monomials. Finally, we also discuss the problem of projecting onto p-cones which, although not hyperbolicity cones in general, are still amenable to our techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09213v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takayuki Nagano, Bruno F. Louren\c{c}o, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>A proximal splitting algorithm for generalized DC programming with applications in signal recovery</title>
      <link>https://arxiv.org/abs/2409.01535</link>
      <description>arXiv:2409.01535v2 Announce Type: replace 
Abstract: The difference-of-convex (DC) program is a crucial approach to nonconvex optimization problems due to its structure, which encompasses a wide ranges of practical applications. In this paper, we aim to tackle a generalized class of DC programs, where the objective function is formed by summing a possibly nonsmooth nonconvex function and a differentiable nonconvex function with Lipschitz continuous gradient, and then subtracting a nonsmooth continuous convex function. We develop a proximal splitting algorithm that utilizes proximal evaluation for the concave part and Douglas--Rachford splitting for the remaining components. The algorithm guarantees subsequential convergence to a stationary point of the problem model. Under the widely used Kurdyka--Lojasiewicz property, we establish global convergence of the full sequence of iterates and derive convergence rates for both the iterates and the objective function values, without assuming the concave part is differentiable. The performance of the proposed algorithm is tested on signal recovery problems with a nonconvex regularization term and exhibits competitive results compared to notable algorithms in the literature on both synthetic data and real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01535v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tan Nhat Pham, Minh N. Dao, Nima Amjady, Rakibuzzaman Shah</dc:creator>
    </item>
    <item>
      <title>Growth of nonconvex functionals at strict local minimizers</title>
      <link>https://arxiv.org/abs/2409.01833</link>
      <description>arXiv:2409.01833v2 Announce Type: replace 
Abstract: In this paper, we present new equivalent conditions for the growth of proper lower semicontinuous functionals at strict local minimizers. The main conditions are a variant of the so-called tilt stability property of local minimizers and an analog of the classic Polyak-{\L}ojasiewicz condition, where the gradient is replaced by linear perturbations. We derive the following tilting principle: stability of minimizers under linear perturbations can infer their stability under nonlinear ones. We show how growth conditions can be used to give convergence rates for the proximal point algorithm. Finally, we give an application to elliptic tracking problems, establishing a novel equivalence between second-order conditions and the sensitivity of solutions with respect to uncertainty in data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01833v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Dom\'inguez Corella, Tr\'i Minh L\^e</dc:creator>
    </item>
    <item>
      <title>Recursively Feasible Probabilistic Safe Online Learning with Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2208.10733</link>
      <description>arXiv:2208.10733v3 Announce Type: replace-cross 
Abstract: Learning-based control has recently shown great efficacy in performing complex tasks for various applications. However, to deploy it in real systems, it is of vital importance to guarantee the system will stay safe. Control Barrier Functions (CBFs) offer mathematical tools for designing safety-preserving controllers for systems with known dynamics. In this article, we first introduce a model-uncertainty-aware reformulation of CBF-based safety-critical controllers using Gaussian Process (GP) regression to close the gap between an approximate mathematical model and the real system, which results in a second-order cone program (SOCP)-based control design. We then present the pointwise feasibility conditions of the resulting safety controller, highlighting the level of richness that the available system information must meet to ensure safety. We use these conditions to devise an event-triggered online data collection strategy that ensures the recursive feasibility of the learned safety controller. Our method works by constantly reasoning about whether the current information is sufficient to ensure safety or if new measurements under active safe exploration are required to reduce the uncertainty. As a result, our proposed framework can guarantee the forward invariance of the safe set defined by the CBF with high probability, even if it contains a priori unexplored regions. We validate the proposed framework in two numerical simulation experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.10733v3</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fernando Casta\~neda, Jason J. Choi, Wonsuhk Jung, Bike Zhang, Claire J. Tomlin, Koushil Sreenath</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Variance-reduced Distributionally Robust Q-learning</title>
      <link>https://arxiv.org/abs/2305.18420</link>
      <description>arXiv:2305.18420v2 Announce Type: replace-cross 
Abstract: Dynamic decision-making under distributional shifts is of fundamental interest in theory and applications of reinforcement learning: The distribution of the environment in which the data is collected can differ from that of the environment in which the model is deployed. This paper presents two novel model-free algorithms, namely the distributionally robust Q-learning and its variance-reduced counterpart, that can effectively learn a robust policy despite distributional shifts. These algorithms are designed to efficiently approximate the $q$-function of an infinite-horizon $\gamma$-discounted robust Markov decision process with Kullback-Leibler ambiguity set to an entry-wise $\epsilon$-degree of precision. Further, the variance-reduced distributionally robust Q-learning combines the synchronous Q-learning with variance-reduction techniques to enhance its performance. Consequently, we establish that it attains a minimax sample complexity upper bound of $\tilde O(|\mathbf{S}||\mathbf{A}|(1-\gamma)^{-4}\epsilon^{-2})$, where $\mathbf{S}$ and $\mathbf{A}$ denote the state and action spaces. This is the first complexity result that is independent of the ambiguity size $\delta$, thereby providing new complexity theoretic insights. Additionally, a series of numerical experiments confirm the theoretical findings and the efficiency of the algorithms in handling distributional shifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.18420v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengbo Wang, Nian Si, Jose Blanchet, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>Decision-Focused Learning: Foundations, State of the Art, Benchmark and Future Opportunities</title>
      <link>https://arxiv.org/abs/2307.13565</link>
      <description>arXiv:2307.13565v4 Announce Type: replace-cross 
Abstract: Decision-focused learning (DFL) is an emerging paradigm that integrates machine learning (ML) and constrained optimization to enhance decision quality by training ML models in an end-to-end system. This approach shows significant potential to revolutionize combinatorial decision-making in real-world applications that operate under uncertainty, where estimating unknown parameters within decision models is a major challenge. This paper presents a comprehensive review of DFL, providing an in-depth analysis of both gradient-based and gradient-free techniques used to combine ML and constrained optimization. It evaluates the strengths and limitations of these techniques and includes an extensive empirical evaluation of eleven methods across seven problems. The survey also offers insights into recent advancements and future research directions in DFL.
  Code and benchmark: https://github.com/PredOpt/predopt-benchmarks</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.13565v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1613/jair.1.15320</arxiv:DOI>
      <arxiv:journal_reference>Journal of Artificial Intelligence Research 81 (2024) 1623-1701</arxiv:journal_reference>
      <dc:creator>Jayanta Mandi, James Kotary, Senne Berden, Maxime Mulamba, Victor Bucarey, Tias Guns, Ferdinando Fioretto</dc:creator>
    </item>
    <item>
      <title>Search Games with Predictions</title>
      <link>https://arxiv.org/abs/2401.01149</link>
      <description>arXiv:2401.01149v2 Announce Type: replace-cross 
Abstract: We introduce the study of search games between a mobile Searcher and an immobile Hider in a new setting in which the Searcher has some potentially erroneous information, i.e., a prediction on the Hider's position. The objective is to establish tight tradeoffs between the consistency of a search strategy (i.e., its worst case expected payoff assuming the prediction is correct) and its robustness (i.e., the worst case expected payoff with no assumptions on the quality of the prediction). Our study is the first to address the full power of mixed (randomized) strategies; previous work focused only on deterministic strategies, or relied on stochastic assumptions that do not guarantee worst-case robustness in adversarial situations. We give Pareto-optimal strategies for three fundamental problems, namely searching in discrete locations, searching with stochastic overlook, and searching in the infinite line. As part of our contribution, we provide a novel framework for proving optimal tradeoffs in search games which is applicable, more broadly, to any two-person zero-sum games in learning-augmented settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01149v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Spyros Angelopoulos, Thomas Lidbetter, Konstantinos Panagiotou</dc:creator>
    </item>
  </channel>
</rss>
