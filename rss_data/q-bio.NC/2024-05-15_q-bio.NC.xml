<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 May 2024 04:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 16 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Matching domain experts by training from scratch on domain knowledge</title>
      <link>https://arxiv.org/abs/2405.09395</link>
      <description>arXiv:2405.09395v1 Announce Type: new 
Abstract: Recently, large language models (LLMs) have outperformed human experts in predicting the results of neuroscience experiments (Luo et al., 2024). What is the basis for this performance? One possibility is that statistical patterns in that specific scientific literature, as opposed to emergent reasoning abilities arising from broader training, underlie LLMs' performance. To evaluate this possibility, we trained (next word prediction) a relatively small 124M-parameter GPT-2 model on 1.3 billion tokens of domain-specific knowledge. Despite being orders of magnitude smaller than larger LLMs trained on trillions of tokens, small models achieved expert-level performance in predicting neuroscience results. Small models trained on the neuroscience literature succeeded when they were trained from scratch using a tokenizer specifically trained on neuroscience text or when the neuroscience literature was used to finetune a pretrained GPT-2. Our results indicate that expert-level performance may be attained by even small LLMs through domain-specific, auto-regressive training approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09395v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoliang Luo, Guangzhi Sun, Bradley C. Love</dc:creator>
    </item>
    <item>
      <title>Three Dimensional Spatial Cognition: Bees and Bats</title>
      <link>https://arxiv.org/abs/2405.09413</link>
      <description>arXiv:2405.09413v1 Announce Type: new 
Abstract: The paper describes a program which computes the best possible Bayesian model of 3D space from vision (in bees) or echo location (in bats), at Marrs [1982] Level 2. The model exploits the strong Bayesian prior probability that most other things do not move, as the animal moves. 3D locations of things are computed from successive sightings or echoes, computing structure from the animals motion (SFM). The program can be downloaded and run. It also computes a tracking approximate model, which is more tractable for animal brains than the full Bayesian computation. The tracking model is nearly as good as the full Bayesian model, but only if spatial memory storage errors are small. Neural storage of spatial positions gives too high error levels, and is too slow. Alternatively, a 3D model of space could be stored in a wave excitation, as a Fourier transform of real space. This could give high memory capacity and precision, with low spatial distortion, fast response, and simpler computation. Evidence is summarized from related papers that a wave excitation holds spatial memory in the mammalian thalamus, and in the central body of the insect brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09413v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Worden</dc:creator>
    </item>
    <item>
      <title>On the Shape of Brainscores for Large Language Models (LLMs)</title>
      <link>https://arxiv.org/abs/2405.06725</link>
      <description>arXiv:2405.06725v3 Announce Type: replace 
Abstract: With the rise of Large Language Models (LLMs), the novel metric "Brainscore" emerged as a means to evaluate the functional similarity between LLMs and human brain/neural systems. Our efforts were dedicated to mining the meaning of the novel score by constructing topological features derived from both human fMRI data involving 190 subjects, and 39 LLMs plus their untrained counterparts. Subsequently, we trained 36 Linear Regression Models and conducted thorough statistical analyses to discern reliable and valid features from our constructed ones. Our findings reveal distinctive feature combinations conducive to interpreting existing brainscores across various brain regions of interest (ROIs) and hemispheres, thereby significantly contributing to advancing interpretable machine learning (iML) studies. The study is enriched by our further discussions and analyses concerning existing brainscores. To our knowledge, this study represents the first attempt to comprehend the novel metric brainscore within this interdisciplinary domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06725v3</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingkai Li</dc:creator>
    </item>
    <item>
      <title>Computational Thought Experiments for a More Rigorous Philosophy and Science of the Mind</title>
      <link>https://arxiv.org/abs/2405.08304</link>
      <description>arXiv:2405.08304v2 Announce Type: replace-cross 
Abstract: We offer philosophical motivations for a method we call Virtual World Cognitive Science (VW CogSci), in which researchers use virtual embodied agents that are embedded in virtual worlds to explore questions in the field of Cognitive Science. We focus on questions about mental and linguistic representation and the ways that such computational modeling can add rigor to philosophical thought experiments, as well as the terminology used in the scientific study of such representations. We find that this method forces researchers to take a god's-eye view when describing dynamical relationships between entities in minds and entities in an environment in a way that eliminates the need for problematic talk of belief and concept types, such as the belief that cats are silly, and the concept CAT, while preserving belief and concept tokens in individual cognizers' minds. We conclude with some further key advantages of VW CogSci for the scientific study of mental and linguistic representation and for Cognitive Science more broadly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08304v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iris Oved, Nikhil Krishnaswamy, James Pustejovsky, Joshua Hartshorne</dc:creator>
    </item>
  </channel>
</rss>
