<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Apr 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 26 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Implications of computer science theory for the simulation hypothesis</title>
      <link>https://arxiv.org/abs/2404.16050</link>
      <description>arXiv:2404.16050v1 Announce Type: new 
Abstract: The simulation hypothesis has recently excited renewed interest, especially in the physics and philosophy communities. However, the hypothesis specifically concerns {computers} that simulate physical universes, which means that to properly investigate it we need to couple computer science theory with physics. Here I do this by exploiting the physical Church-Turing thesis. This allows me to introduce a preliminary investigation of some of the computer science theoretic aspects of the simulation hypothesis. In particular, building on Kleene's second recursion theorem, I prove that it is mathematically possible for us to be in a simulation that is being run on a computer \textit{by us}. In such a case, there would be two identical instances of us; the question of which of those is ``really us'' is meaningless. I also show how Rice's theorem provides some interesting impossibility results concerning simulation and self-simulation; briefly describe the philosophical implications of fully homomorphic encryption for (self-)simulation; briefly investigate the graphical structure of universes simulating universes simulating universes, among other issues. I end by describing some of the possible avenues for future research that this preliminary investigation reveals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16050v1</guid>
      <category>cs.LO</category>
      <category>physics.hist-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David H. Wolpert</dc:creator>
    </item>
    <item>
      <title>Dynamic Many Valued Logic Systems in Theoretical Economics</title>
      <link>https://arxiv.org/abs/2404.16061</link>
      <description>arXiv:2404.16061v1 Announce Type: new 
Abstract: This paper is an original attempt to understand the foundations of economic reasoning. It endeavors to rigorously define the relationship between subjective interpretations and objective valuations of such interpretations in the context of theoretical economics. This analysis is substantially expanded through a dynamic approach, where the truth of a valuation results in an updated interpretation or changes in the agent's subjective belief regarding the effectiveness of the selected action as well as the objective reality of the effectiveness of all other possible actions (i.e. consequence realization). Complications arise when the economic agent is presented with a set of actions that render ambiguous preference, or when the effectiveness of an action cannot be perceived upon its selection, thereby necessitating a different theory of choice and consequence realization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16061v1</guid>
      <category>cs.LO</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Lu</dc:creator>
    </item>
    <item>
      <title>Forcing, Transition Algebras, and Calculi</title>
      <link>https://arxiv.org/abs/2404.16111</link>
      <description>arXiv:2404.16111v1 Announce Type: new 
Abstract: We bring forward a logical system of transition algebras that enhances many-sorted first-order logic using features from dynamic logics. The sentences we consider include compositions, unions, and transitive closures of transition relations, which are treated similarly to the actions used in dynamic logics in order to define necessity and possibility operators. This leads to a higher degree of expressivity than that of many-sorted first-order logic. For example, one can finitely axiomatize both the finiteness and the reachability of models, neither of which are ordinarily possible in many-sorted first-order logic. We introduce syntactic entailment and study basic properties such as compactness and completeness, showing that the latter does not hold when standard finitary proof rules are used. Consequently, we define proof rules having both finite and countably infinite premises, and we provide conditions under which completeness can be proved. To that end, we generalize the forcing method introduced in model theory by Robinson from a single signature to a category of signatures, and we apply it to obtain a completeness result for signatures that are at most countable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16111v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hashimoto Go, Daniel G\u{a}in\u{a}, Ionu\c{t} \c{T}u\c{t}u</dc:creator>
    </item>
    <item>
      <title>Generalized Optimization Modulo Theories</title>
      <link>https://arxiv.org/abs/2404.16122</link>
      <description>arXiv:2404.16122v1 Announce Type: new 
Abstract: Optimization Modulo Theories (OMT) has emerged as an important extension of the highly successful Satisfiability Modulo Theories (SMT) paradigm. The OMT problem requires solving an SMT problem with the restriction that the solution must be optimal with respect to a given objective function. We introduce a generalization of the OMT problem where, in particular, objective functions can range over partially ordered sets. We provide a formalization of and an abstract calculus for the generalized OMT problem and prove their key correctness properties. Generalized OMT extends previous work on OMT in several ways. First, in contrast to many current OMT solvers, our calculus is theory-agnostic, enabling the optimization of queries over any theories or combinations thereof. Second, our formalization unifies both single- and multi-objective optimization problems, allowing us to study them both in a single framework and facilitating the use of objective functions that are not supported by existing OMT approaches. Finally, our calculus is sufficiently general to fully capture a wide variety of current OMT approaches (each of which can be realized as a specific strategy for rule application in the calculus) and to support the exploration of new search strategies. Much like the original abstract DPLL(T) calculus for SMT, our Generalized OMT calculus is designed to establish a theoretical foundation for understanding and research and to serve as a framework for studying variations of and extensions to existing OMT methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16122v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nestan Tsiskaridze, Clark Barrett, Cesare Tinelli</dc:creator>
    </item>
    <item>
      <title>A proof theory of (omega-)context-free languages, via non-wellfounded proofs</title>
      <link>https://arxiv.org/abs/2404.16231</link>
      <description>arXiv:2404.16231v1 Announce Type: new 
Abstract: We investigate the proof theory of regular expressions with fixed points, construed as a notation for (omega-)context-free grammars. Starting with a hypersequential system for regular expressions due to Das and Pous, we define its extension by least fixed points and prove soundness and completeness of its non-wellfounded proofs for the standard language model. From here we apply proof-theoretic techniques to recover an infinitary axiomatisation of the resulting equational theory, complete for inclusions of context-free languages. Finally, we extend our syntax by greatest fixed points, now computing omega-context-free languages. We show the soundness and completeness of the corresponding system using a mixture of proof-theoretic and game-theoretic techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16231v1</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anupam Das, Abhishek De</dc:creator>
    </item>
    <item>
      <title>muRelBench: MicroBenchmarks for Zonotope Domains</title>
      <link>https://arxiv.org/abs/2404.16243</link>
      <description>arXiv:2404.16243v1 Announce Type: new 
Abstract: We present \texttt{muRelBench}, a suite of synthetic benchmarks for weakly-relational abstract domains and their operations. For example, the benchmarks can support experimental evaluations of proposed algorithms such as domain closure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16243v1</guid>
      <category>cs.LO</category>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kenny Ballou, Elena Sherman</dc:creator>
    </item>
    <item>
      <title>Revisiting Restarts of CDCL: Should the Search Information be Preserved?</title>
      <link>https://arxiv.org/abs/2404.16387</link>
      <description>arXiv:2404.16387v1 Announce Type: new 
Abstract: SAT solvers are indispensable in formal verification for hardware and software with many important applications. CDCL is the most widely used framework for modern SAT solvers, and restart is an essential technique of CDCL. When restarting, CDCL solvers cancel the current variable assignment while maintaining the branching order, variable phases, and learnt clauses. This type of restart is referred to as warm restart in this paper. Although different restart policies have been studied, there is no study on whether such information should be kept after restarts. This work addresses this question and finds some interesting observations.
  This paper indicates that under this popular warm restart scheme, there is a substantial variation in run-time with different randomized initial orders and phases, which motivates us to forget some learned information periodically to prevent being stuck in a disadvantageous search space. We propose a new type of restart called cold restart, which differs from previous restarts by forgetting some of the learned information. Experiments show that modern CDCL solvers can benefit from periodically conducting cold restarts. Based on the analysis of the cold-restart strategies, we develop a parallel SAT solver. Both the sequential and parallel versions of cold restart are more suitable for satisfiable instances, which suggests that existing CDCL heuristics for information management should be revised if one hopes to construct a satisfiable-oriented SAT solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16387v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xindi Zhang, Zhihan Chen, Shaowei Cai</dc:creator>
    </item>
    <item>
      <title>Regular Typed Unification</title>
      <link>https://arxiv.org/abs/2404.16406</link>
      <description>arXiv:2404.16406v1 Announce Type: new 
Abstract: Here we define a new unification algorithm for terms interpreted in semantic domains denoted by a subclass of regular types here called deterministic regular types. This reflects our intention not to handle the semantic universe as a homogeneous collection of values, but instead, to partition it in a way that is similar to data types in programming languages. We first define the new unification algorithm which is based on constraint generation and constraint solving, and then prove its main properties: termination, soundness, and completeness with respect to the semantics. Finally, we discuss how to apply this algorithm to a dynamically typed version of Prolog.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16406v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jo\~ao Barbosa, M\'ario Florido, V\'itor Santos Costa</dc:creator>
    </item>
    <item>
      <title>Canonical Decision Diagrams Modulo Theories</title>
      <link>https://arxiv.org/abs/2404.16455</link>
      <description>arXiv:2404.16455v1 Announce Type: new 
Abstract: Decision diagrams (DDs) are powerful tools to represent effectively propositional formulas, which are largely used in many domains, in particular in formal verification and in knowledge compilation. Some forms of DDs (e.g., OBDDs, SDDs) are canonical, that is, (under given conditions on the atom list) they univocally represent equivalence classes of formulas. Given the limited expressiveness of propositional logic, a few attempts to leverage DDs to SMT level have been presented in the literature. Unfortunately, these techniques still suffer from some limitations: most procedures are theory-specific; some produce theory DDs (T-DDs) which do not univocally represent T-valid formulas or T-inconsistent formulas; none of these techniques provably produces theory-canonical T-DDs, which (under given conditions on the T-atom list) univocally represent T-equivalence classes of formulas. Also, these procedures are not easy to implement, and very few implementations are actually available. In this paper, we present a novel very-general technique to leverage DDs to SMT level, which has several advantages: it is very easy to implement on top of an AllSMT solver and a DD package, which are used as blackboxes; it works for every form of DDs and every theory, or combination thereof, supported by the AllSMT solver; it produces theory-canonical T-DDs if the propositional DD is canonical. We have implemented a prototype tool for both T-OBDDs and T-SDDs on top of OBDD and SDD packages and the MathSAT SMT solver. Some preliminary empirical evaluation supports the effectiveness of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16455v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Massimo Michelutti, Gabriele Masina, Giuseppe Spallitta, Roberto Sebastiani</dc:creator>
    </item>
    <item>
      <title>Proving Behavioural Apartness</title>
      <link>https://arxiv.org/abs/2404.16588</link>
      <description>arXiv:2404.16588v1 Announce Type: new 
Abstract: Bisimilarity is a central notion for coalgebras. In recent work, Geuvers and Jacobs suggest to focus on apartness, which they define by dualising coalgebraic bisimulations. This yields the possibility of finite proofs of distinguishability for a wide variety of state-based systems.
  We propose behavioural apartness, defined by dualising behavioural equivalence rather than bisimulations. A motivating example is the subdistribution functor, where the proof system based on bisimilarity requires an infinite quantification over couplings, whereas behavioural apartness instantiates to a finite rule. In addition, we provide optimised proof rules for behavioural apartness and show their use in several examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16588v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruben Turkenburg, Harsh Beohar, Clemens Kupke, Jurriaan Rot</dc:creator>
    </item>
    <item>
      <title>Derandomization with Pseudorandomness</title>
      <link>https://arxiv.org/abs/2404.16614</link>
      <description>arXiv:2404.16614v1 Announce Type: new 
Abstract: Derandomization techniques are often used within advanced randomized algorithms. In particular, pseudorandom objects, such as hash families and expander graphs, are key components of such algorithms, but their verification presents a challenge. This work shows how such algorithms can be expressed and verified in Isabelle and presents a pseudorandom objects library that abstracts away the involved deep algebraic/analytic results. Moreover, it presents examples that show how the library eases and enables the verification of advanced randomized algorithms. Highlighting the value of this framework is that it was recently used to verify the optimal-space distinct elements algorithm by Blasiok from 2018, which relies on the combination of many derandomization techniques to achieve its optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16614v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emin Karayel</dc:creator>
    </item>
    <item>
      <title>Uniform Substitution for Differential Refinement Logic</title>
      <link>https://arxiv.org/abs/2404.16734</link>
      <description>arXiv:2404.16734v1 Announce Type: new 
Abstract: This paper introduces a uniform substitution calculus for differential refinement logic dRL. The logic dRL extends the differential dynamic logic dL such that one can simultaneously reason about properties of and relations between hybrid systems. Refinements is useful e.g. for simplifying proofs by relating a concrete hybrid system to an abstract one from which the property can be proved more easily. Uniform substitution is the key to parsimonious prover microkernels. It enables the verbatim use of single axiom formulas instead of axiom schemata with soundness-critical side conditions scattered across the proof calculus. The uniform substitution rule can then be used to instantiate all axioms soundly. Access to differential variables in dRL enables more control over the notion of refinement, which is shown to be decidable on a fragment of hybrid programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16734v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enguerrand Prebet, Andr\'e Platzer</dc:creator>
    </item>
    <item>
      <title>Unifying Asynchronous Logics for Hyperproperties</title>
      <link>https://arxiv.org/abs/2404.16778</link>
      <description>arXiv:2404.16778v1 Announce Type: new 
Abstract: We introduce and investigate a powerful hyper logical framework in the linear-time setting, we call generalized HyperLTL with stuttering and contexts (GHyperLTL_SC for short). GHyperLTL_SC unifies known asynchronous extensions of HyperLTL and the well-known extension KLTL of LTL with knowledge modalities under both the synchronous and asynchronous perfect recall semantics. As a main contribution, we individuate a meaningful fragment of GHyperLTL_SC, we call simple GHyperLTL_SC, with a decidable model-checking problem, which is more expressive than HyperLTL and known fragments of asynchronous extensions of HyperLTL with a decidable model-checking problem. Simple GHyperLTL_SC subsumes KLTL under the synchronous semantics and the one-agent fragment of KLTL under the asynchronous semantics, and to the best of our knowledge, it represents the unique hyper logic with a decidable model-checking problem which can express powerful non-regular trace properties when interpreted on singleton sets of traces. We justify the relevance of simple GHyperLTL_SC by showing that it can express diagnosability properties, interesting classes of information-flow security policies, both in the synchronous and asynchronous settings, and bounded termination (more in general, global promptness in the style of Prompt LTL).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16778v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Bombardelli, Laura Bozzelli, C\'esar S\'anchez, Stefano Tonetta</dc:creator>
    </item>
    <item>
      <title>CESAR: Control Envelope Synthesis via Angelic Refinements</title>
      <link>https://arxiv.org/abs/2311.02833</link>
      <description>arXiv:2311.02833v2 Announce Type: cross 
Abstract: This paper presents an approach for synthesizing provably correct control envelopes for hybrid systems. Control envelopes characterize families of safe controllers and are used to monitor untrusted controllers at runtime. Our algorithm fills in the blanks of a hybrid system's sketch specifying the desired shape of the control envelope, the possible control actions, and the system's differential equations. In order to maximize the flexibility of the control envelope, the synthesized conditions saying which control action can be chosen when should be as permissive as possible while establishing a desired safety condition from the available assumptions, which are augmented if needed. An implicit, optimal solution to this synthesis problem is characterized using hybrid systems game theory, from which explicit solutions can be derived via symbolic execution and sound, systematic game refinements. Optimality can be recovered in the face of approximation via a dual game characterization. The resulting algorithm, Control Envelope Synthesis via Angelic Refinements (CESAR), is demonstrated in a range of safe control synthesis examples with different control challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02833v2</guid>
      <category>eess.SY</category>
      <category>cs.LO</category>
      <category>cs.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-57246-3_9</arxiv:DOI>
      <dc:creator>Aditi Kabra, Jonathan Laurent, Stefan Mitsch, Andr\'e Platzer</dc:creator>
    </item>
    <item>
      <title>Transparent AI: Developing an Explainable Interface for Predicting Postoperative Complications</title>
      <link>https://arxiv.org/abs/2404.16064</link>
      <description>arXiv:2404.16064v1 Announce Type: cross 
Abstract: Given the sheer volume of surgical procedures and the significant rate of postoperative fatalities, assessing and managing surgical complications has become a critical public health concern. Existing artificial intelligence (AI) tools for risk surveillance and diagnosis often lack adequate interpretability, fairness, and reproducibility. To address this, we proposed an Explainable AI (XAI) framework designed to answer five critical questions: why, why not, how, what if, and what else, with the goal of enhancing the explainability and transparency of AI models. We incorporated various techniques such as Local Interpretable Model-agnostic Explanations (LIME), SHapley Additive exPlanations (SHAP), counterfactual explanations, model cards, an interactive feature manipulation interface, and the identification of similar patients to address these questions. We showcased an XAI interface prototype that adheres to this framework for predicting major postoperative complications. This initial implementation has provided valuable insights into the vast explanatory potential of our XAI framework and represents an initial step towards its clinical adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16064v1</guid>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuanfang Ren, Chirayu Tripathi, Ziyuan Guan, Ruilin Zhu, Victoria Hougha, Yingbo Ma, Zhenhong Hu, Jeremy Balch, Tyler J. Loftus, Parisa Rashidi, Benjamin Shickel, Tezcan Ozrazgat-Baslanti, Azra Bihorac</dc:creator>
    </item>
    <item>
      <title>FO logic on cellular automata orbits equals MSO logic</title>
      <link>https://arxiv.org/abs/2404.16430</link>
      <description>arXiv:2404.16430v1 Announce Type: cross 
Abstract: We introduce an extension of classical cellular automata (CA) to arbitrary labeled graphs, and show that FO logic on CA orbits is equivalent to MSO logic.  We deduce various results from that equivalence, including a characterization of finitely generated groups on which FO model checking for CA orbits is undecidable, and undecidability of satisfiability of a fixed FO property for CA over finite graphs. We also show concrete examples of FO formulas for CA orbits whose model checking problem is equivalent to the domino problem, or its seeded or recurring variants respectively, on any finitely generated group. For the recurring domino problem, we use an extension of the FO signature by a relation found in the well-known Garden of Eden theorem, but we also show a concrete FO formula without the extension and with one quantifier alternation whose model checking problem does not belong to the arithmetical hierarchy on group Z^2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16430v1</guid>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <category>math.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Theyssier (I2M)</dc:creator>
    </item>
    <item>
      <title>On the topology of concurrent systems</title>
      <link>https://arxiv.org/abs/2404.16492</link>
      <description>arXiv:2404.16492v1 Announce Type: cross 
Abstract: Higher-dimensional automata, i.e., pointed labeled precubical sets, are a powerful combinatorial-topological model for concurrent systems. In this paper, we show that for every (nonempty) connected polyhedron there exists a shared-variable system such that the higher-dimensional automaton modeling the state space of the system has the homotopy type of the polyhedron.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16492v1</guid>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <category>math.AT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Catarina Faustino, Thomas Kahl, Rodrigo Lopes</dc:creator>
    </item>
    <item>
      <title>Edit Distance of Finite State Transducers</title>
      <link>https://arxiv.org/abs/2404.16518</link>
      <description>arXiv:2404.16518v1 Announce Type: cross 
Abstract: We lift metrics over words to metrics over word-to-word transductions, by defining the distance between two transductions as the supremum of the distances of their respective outputs over all inputs. This allows to compare transducers beyond equivalence.
  Two transducers are close (resp. $k$-close) with respect to a metric if their distance is finite (resp. at most $k$). Over integer-valued metrics computing the distance between transducers is equivalent to deciding the closeness and $k$-closeness problems. For common integer-valued edit distances such as, Hamming, transposition, conjugacy and Levenshtein family of distances, we show that the closeness and the $k$-closeness problems are decidable for functional transducers. Hence, the distance with respect to these metrics is also computable.
  Finally, we relate the notion of distance between functions to the notions of diameter of a relation and index of a relation in another. We show that computing edit distance between functional transducers is equivalent to computing diameter of a rational relation and both are a specific instance of the index problem of rational relations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16518v1</guid>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C. Aiswarya, Amaldev Manuel, Saina Sunny</dc:creator>
    </item>
    <item>
      <title>Formal Specification, Assessment, and Enforcement of Fairness for Generative AIs</title>
      <link>https://arxiv.org/abs/2404.16663</link>
      <description>arXiv:2404.16663v1 Announce Type: cross 
Abstract: The risk of reinforcing or exacerbating societal biases and inequalities is growing as generative AI increasingly produces content that resembles human output, from text to images and beyond. Here we formally characterize the notion of fairness for generative AI as a basis for monitoring and enforcing fairness. We define two levels of fairness utilizing the concept of infinite words. The first is the fairness demonstrated on the generated sequences, which is only evaluated on the outputs while agnostic to the prompts/models used. The second is the inherent fairness of the generative AI model, which requires that fairness be manifested when input prompts are neutral, that is, they do not explicitly instruct the generative AI to produce a particular type of output. We also study relative intersectional fairness to counteract the combinatorial explosion of fairness when considering multiple categories together with lazy fairness enforcement. Our implemented specification monitoring and enforcement tool shows interesting results when tested against several generative AI models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16663v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LO</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chih-Hong Cheng, Changshun Wu, Harald Ruess, Xingyu Zhao, Saddek Bensalem</dc:creator>
    </item>
    <item>
      <title>Effectful Semantics in Bicategories: Strong, Commutative, and Concurrent Pseudomonads</title>
      <link>https://arxiv.org/abs/2304.11014</link>
      <description>arXiv:2304.11014v2 Announce Type: replace 
Abstract: We develop the theory of strong and commutative monads in the 2-dimensional setting of bicategories. This provides a framework for the analysis of effects in many recent models which form bicategories and not categories, such as those based on profunctors, spans, or strategies over games.
  We then show how the 2-dimensional setting provides new insights into the semantics of concurrent functional programs. We introduce concurrent pseudomonads, which capture the fundamental weak interchange law connecting parallel composition and sequential composition. This notion brings to light an intermediate level, strictly between strength and commutativity, which is invisible in traditional categorical models. We illustrate the concept with the continuation pseudomonad in concurrent game semantics.
  In developing this theory, we take care to understand the coherence laws governing the structural 2-cells. We give many examples and prove a number of practical and foundational results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.11014v2</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hugo Paquet, Philip Saville</dc:creator>
    </item>
    <item>
      <title>A Complete Finite Axiomatisation of the Equational Theory of Common Meadows</title>
      <link>https://arxiv.org/abs/2307.04270</link>
      <description>arXiv:2307.04270v2 Announce Type: replace 
Abstract: We analyse abstract data types that model numerical structures with a concept of error. Specifically, we focus on arithmetic data types that contain an error value $\bot$ whose main purpose is to always return a value for division. To rings and fields, we add a division operator $x/y$ and study a class of algebras called common meadows wherein $x/0 = \bot$. The set of equations true in all common meadows is named the equational theory of common meadows. We give a finite equational axiomatisation of the equational theory of common meadows and prove that it is complete and that the equational theory is decidable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.04270v2</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan A Bergstra, John V Tucker</dc:creator>
    </item>
    <item>
      <title>Logarithmic Weisfeiler--Leman and Treewidth</title>
      <link>https://arxiv.org/abs/2303.07985</link>
      <description>arXiv:2303.07985v2 Announce Type: replace-cross 
Abstract: In this paper, we show that the $(3k+4)$-dimensional Weisfeiler--Leman algorithm can identify graphs of treewidth $k$ in $O(\log n)$ rounds. This improves the result of Grohe &amp; Verbitsky (ICALP 2006), who previously established the analogous result for $(4k+3)$-dimensional Weisfeiler--Leman. In light of the equivalence between Weisfeiler--Leman and the logic $\textsf{FO} + \textsf{C}$ (Cai, F\"urer, &amp; Immerman, Combinatorica 1992), we obtain an improvement in the descriptive complexity for graphs of treewidth $k$. Precisely, if $G$ is a graph of treewidth $k$, then there exists a $(3k+5)$-variable formula $\varphi$ in $\textsf{FO} + \textsf{C}$ with quantifier depth $O(\log n)$ that identifies $G$ up to isomorphism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.07985v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Levet, Puck Rombach, Nicholas Sieger</dc:creator>
    </item>
    <item>
      <title>Canonizing Graphs of Bounded Rank-Width in Parallel via Weisfeiler--Leman</title>
      <link>https://arxiv.org/abs/2306.17777</link>
      <description>arXiv:2306.17777v3 Announce Type: replace-cross 
Abstract: In this paper, we show that computing canonical labelings of graphs of bounded rank-width is in $\textsf{TC}^{2}$. Our approach builds on the framework of K\"obler &amp; Verbitsky (CSR 2008), who established the analogous result for graphs of bounded treewidth. Here, we use the framework of Grohe &amp; Neuen (ACM Trans. Comput. Log., 2023) to enumerate separators via split-pairs and flip functions. In order to control the depth of our circuit, we leverage the fact that any graph of rank-width $k$ admits a rank decomposition of width $\leq 2k$ and height $O(\log n)$ (Courcelle &amp; Kant\'e, WG 2007). This allows us to utilize an idea from Wagner (CSR 2011) of tracking the depth of the recursion in our computation.
  Furthermore, after splitting the graph into connected components, it is necessary to decide isomorphism of said components in $\textsf{TC}^{1}$. To this end, we extend the work of Grohe &amp; Neuen (ibid.) to show that the $(6k+3)$-dimensional Weisfeiler--Leman (WL) algorithm can identify graphs of rank-width $k$ using only $O(\log n)$ rounds. As a consequence, we obtain that graphs of bounded rank-width are identified by $\textsf{FO} + \textsf{C}$ formulas with $6k+4$ variables and quantifier depth $O(\log n)$.
  Prior to this paper, isomorphism testing for graphs of bounded rank-width was not known to be in $\textsf{NC}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.17777v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Levet, Puck Rombach, Nicholas Sieger</dc:creator>
    </item>
    <item>
      <title>Lemur: Integrating Large Language Models in Automated Program Verification</title>
      <link>https://arxiv.org/abs/2310.04870</link>
      <description>arXiv:2310.04870v5 Announce Type: replace-cross 
Abstract: The demonstrated code-understanding capability of LLMs raises the question of whether they can be used for automated program verification, a task that demands high-level abstract reasoning about program properties that is challenging for verification tools. We propose a general methodology to combine the power of LLMs and automated reasoners for automated program verification. We formally describe this methodology as a set of transition rules and prove its soundness. We instantiate the calculus as a sound automated verification procedure and demonstrate practical improvements on a set of synthetic and competition benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04870v5</guid>
      <category>cs.FL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Haoze Wu, Clark Barrett, Nina Narodytska</dc:creator>
    </item>
  </channel>
</rss>
