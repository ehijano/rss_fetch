<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Mar 2025 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Short Scalability Study on the SeQUeNCe Parallel Quantum Network Simulator</title>
      <link>https://arxiv.org/abs/2503.09776</link>
      <description>arXiv:2503.09776v1 Announce Type: new 
Abstract: As quantum networking continues to grow in importance, its study is of interest to an ever wider community and at an increasing scale. However, the development of its physical infrastructure remains burdensome, and services providing third party access are not enough to meet demand. A variety of simulation frameworks provide a method for testing aspects of such systems on commodity hardware, but are predominantly serial and thus unable to scale to larger networks and/or workloads. One effort to address this was focused on parallelising the SeQUeNCe discrete event simulator, though it has yet to be proven to work well across system architectures or at larger scales. Therein lies the contribution of this work - to more deeply examine its scalability using ORNL Frontier. Our results provide new insight into its scalability behaviour, and we examine its strategy and how it may be able to be improved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09776v1</guid>
      <category>cs.NI</category>
      <category>quant-ph</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aaron Welch, Mariam Kiran</dc:creator>
    </item>
    <item>
      <title>Computing the Saturation Throughput for Heterogeneous p-CSMA in a General Wireless Network</title>
      <link>https://arxiv.org/abs/2503.09869</link>
      <description>arXiv:2503.09869v1 Announce Type: new 
Abstract: A well-known expression for the saturation throughput of heterogeneous transmitting nodes in a wireless network using p-CSMA, derived from Renewal Theory, implicitly assumes that all transmitting nodes are in range of, and therefore conflicting with, each other. This expression, as well as simple modifications of it, does not correctly capture the saturation throughput values when an arbitrary topology is specified for the conflict graph between transmitting links. For example, we show numerically that calculations based on renewal theory can underestimate throughput by 48-62% for large packet sizes when the conflict graph is represented by a star topology. This is problematic because real-world wireless networks, such as wireless IoT mesh networks, are often deployed over a large area, resulting in non-complete conflict graphs.
  To address this gap, we present a computational approach based on a novel Markov chain formulation that yields the exact saturation throughput for each node in the general network case for any given set of access probabilities, as well as a more compact expression for the special case where the packet length is twice the slot length. Using our approach, we show how the transmit probabilities could be optimized to maximize weighted utility functions of the saturation throughput values. This would allow a wireless system designer to set transmit probabilities to achieve desired throughput trade-offs in any given deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09869v1</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faezeh Dehghan Tarzjani, Bhaskar Krishnamachari</dc:creator>
    </item>
    <item>
      <title>Efficient Neuro-enhanced Video Analytics</title>
      <link>https://arxiv.org/abs/2407.16990</link>
      <description>arXiv:2407.16990v5 Announce Type: replace 
Abstract: Video analytics is widespread in various applications serving our society. Recent advances of content enhancement in video analytics offer significant benefits for the bandwidth saving and accuracy improvement. However, existing content-enhanced video analytics systems are excessively computationally expensive and provide extremely low throughput. In this paper, we present region-based content enhancement, that enhances only the important regions in videos, to improve analytical accuracy. Our system, RegenHance, enables high-accuracy and high-throughput video analytics at the edge by 1) a macroblock-based region importance predictor that identifies the important regions fast and precisely, 2) a region-aware enhancer that stitches sparsely distributed regions into dense tensors and enhances them efficiently, and 3) a profile-based execution planer that allocates appropriate resources for enhancement and analytics components. We prototype RegenHance on five heterogeneous edge devices. Experiments on two analytical tasks reveal that region-based enhancement improves the overall accuracy of 10-19% and achieves 2-3x throughput compared to the state-of-the-art frame-based enhancement methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16990v5</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weijun Wang, Liang Mi, Shaowei Cen, Haipeng Dai, Yuanchun Li, Xiaoming Fu, Yunxin Liu</dc:creator>
    </item>
    <item>
      <title>User-centric Immersive Communications in 6G: A Data-oriented Framework via Digital Twin</title>
      <link>https://arxiv.org/abs/2410.02688</link>
      <description>arXiv:2410.02688v2 Announce Type: replace 
Abstract: In this article, we present a novel user-centric service provision for immersive communications (IC) in 6G to deal with the uncertainty of individual user behaviors while satisfying unique requirements on the quality of multi-sensory experience. To this end, we propose a data-oriented framework for network resource management, featuring personalized data management that can support network modeling tailored to different user demands. Our framework leverages the digital twin (DT) technique as a key enabler. Particularly, a DT is established for each user, and the data attributes in the DT are customized based on the characteristics of the user. The DT functions, corresponding to various data operations, are customized in the development, evaluation, and update of network models to meet unique user demands. A trace-driven case study demonstrates the effectiveness of our framework in achieving user-centric IC and the significance of personalized data management in 6G.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02688v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Conghao Zhou, Shisheng Hu, Jie Gao, Xinyu Huang, Weihua Zhuang, Xuemin Shen</dc:creator>
    </item>
    <item>
      <title>Adaptive Split Learning over Energy-Constrained Wireless Edge Networks</title>
      <link>https://arxiv.org/abs/2403.05158</link>
      <description>arXiv:2403.05158v2 Announce Type: replace-cross 
Abstract: Split learning (SL) is a promising approach for training artificial intelligence (AI) models, in which devices collaborate with a server to train an AI model in a distributed manner, based on a same fixed split point. However, due to the device heterogeneity and variation of channel conditions, this way is not optimal in training delay and energy consumption. In this paper, we design an adaptive split learning (ASL) scheme which can dynamically select split points for devices and allocate computing resource for the server in wireless edge networks. We formulate an optimization problem to minimize the average training latency subject to long-term energy consumption constraint. The difficulties in solving this problem are the lack of future information and mixed integer programming (MIP). To solve it, we propose an online algorithm leveraging the Lyapunov theory, named OPEN, which decomposes it into a new MIP problem only with the current information. Then, a two-layer optimization method is proposed to solve the MIP problem. Extensive simulation results demonstrate that the ASL scheme can reduce the average training delay and energy consumption by 53.7% and 22.1%, respectively, as compared to the existing SL schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05158v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zuguang Li, Wen Wu, Shaohua Wu, Wei Wang</dc:creator>
    </item>
  </channel>
</rss>
