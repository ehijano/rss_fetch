<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.GN</link>
    <description>q-fin.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Mar 2025 04:00:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Study on the Impact of Environmental Liability Insurance on Industrial Carbon Emissions</title>
      <link>https://arxiv.org/abs/2503.15445</link>
      <description>arXiv:2503.15445v1 Announce Type: cross 
Abstract: In order to explore whether environmental liability insurance has an important impact on industrial emission reduction, this paper selects provincial (city) level panel data from 2010 to 2020 and constructs a two-way fixed effect model to analyze the impact of environmental liability insurance on carbon emissions from both direct and indirect levels. The empirical analysis results show that: at the direct level, the development of environmental liability insurance has the effect of reducing industrial carbon emissions, and its effect is heterogeneous. At the indirect level, the role of environmental liability insurance is weaker in areas with developed financial industry and underdeveloped financial industry. Further heterogeneity analysis shows that in the industrial developed areas, the effect of environmental liability insurance on carbon emissions is more obvious. Based on this, countermeasures and suggestions are put forward from the aspects of expanding the coverage of environmental liability insurance, innovating the development of environmental liability insurance and improving the level of industrialization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15445v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>q-fin.GN</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bo Wu</dc:creator>
    </item>
    <item>
      <title>Chronologically Consistent Large Language Models</title>
      <link>https://arxiv.org/abs/2502.21206</link>
      <description>arXiv:2502.21206v2 Announce Type: replace 
Abstract: Large language models are increasingly used in social sciences, but their training data can introduce lookahead bias and training leakage. A good chronologically consistent language model requires efficient use of training data to maintain accuracy despite time-restricted data. Here, we overcome this challenge by training a suite of chronologically consistent large language models, ChronoBERT and ChronoGPT, which incorporate only the text data that would have been available at each point in time. Despite this strict temporal constraint, our models achieve strong performance on natural language processing benchmarks, outperforming or matching widely used models (e.g., BERT), and remain competitive with larger open-weight models. Lookahead bias is model and application-specific because even if a chronologically consistent language model has poorer language comprehension, a regression or prediction model applied on top of the language model can compensate. In an asset pricing application predicting next-day stock returns from financial news, we find that ChronoBERT's real-time outputs achieve a Sharpe ratio comparable to state-of-the-art models, indicating that lookahead bias is modest. Our results demonstrate a scalable, practical framework to mitigate training leakage, ensuring more credible backtests and predictions across finance and other social science domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21206v2</guid>
      <category>q-fin.GN</category>
      <category>q-fin.TR</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Songrun He, Linying Lv, Asaf Manela, Jimmy Wu</dc:creator>
    </item>
    <item>
      <title>Bloated Disclosures: Can ChatGPT Help Investors Process Information?</title>
      <link>https://arxiv.org/abs/2306.10224</link>
      <description>arXiv:2306.10224v4 Announce Type: replace-cross 
Abstract: Generative AI tools such as ChatGPT can fundamentally change the way investors process information. We probe the economic usefulness of these tools in summarizing complex corporate disclosures using the stock market as a laboratory. The unconstrained summaries are remarkably shorter compared to the originals, whereas their information content is amplified. When a document has a positive (negative) sentiment, its summary becomes more positive (negative). Importantly, the summaries are more effective at explaining stock market reactions to the disclosed information. Motivated by these findings, we propose a measure of information ``bloat." We show that bloated disclosure is associated with adverse capital market consequences, such as lower price efficiency and higher information asymmetry. Finally, we show that the model is effective at constructing targeted summaries that identify firms' (non-)financial performance. Collectively, our results indicate that generative AI adds considerable value for investors with information processing constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10224v4</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>q-fin.EC</category>
      <category>q-fin.GN</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alex Kim, Maximilian Muhn, Valeri Nikolaev</dc:creator>
    </item>
    <item>
      <title>Large language models in finance : what is financial sentiment?</title>
      <link>https://arxiv.org/abs/2503.03612</link>
      <description>arXiv:2503.03612v4 Announce Type: replace-cross 
Abstract: Financial sentiment has become a crucial yet complex concept in finance, increasingly used in market forecasting and investment strategies. Despite its growing importance, there remains a need to define and understand what financial sentiment truly represents and how it can be effectively measured. We explore the nature of financial sentiment and investigate how large language models (LLMs) contribute to its estimation. We trace the evolution of sentiment measurement in finance, from market-based and lexicon-based methods to advanced natural language processing techniques. The emergence of LLMs has significantly enhanced sentiment analysis, providing deeper contextual understanding and greater accuracy in extracting sentiment from financial text. We examine how BERT-based models, such as RoBERTa and FinBERT, are optimized for structured sentiment classification, while GPT-based models, including GPT-4, OPT, and LLaMA, excel in financial text generation and real-time sentiment interpretation. A comparative analysis of bidirectional and autoregressive transformer architectures highlights their respective roles in investor sentiment analysis, algorithmic trading, and financial decision-making. By exploring what financial sentiment is and how it is estimated within LLMs, we provide insights into the growing role of AI-driven sentiment analysis in finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03612v4</guid>
      <category>q-fin.ST</category>
      <category>q-fin.GN</category>
      <pubDate>Thu, 20 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kemal Kirtac, Guido Germano</dc:creator>
    </item>
  </channel>
</rss>
