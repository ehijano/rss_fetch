<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Jul 2025 04:03:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Sampled Grid Pairwise Likelihood (SG-PL): An Efficient Approach for Spatial Regression on Large Data</title>
      <link>https://arxiv.org/abs/2507.07113</link>
      <description>arXiv:2507.07113v1 Announce Type: cross 
Abstract: Estimating spatial regression models on large, irregularly structured datasets poses significant computational hurdles. While Pairwise Likelihood (PL) methods offer a pathway to simplify these estimations, the efficient selection of informative observation pairs remains a critical challenge, particularly as data volume and complexity grow. This paper introduces the Sampled Grid Pairwise Likelihood (SG-PL) method, a novel approach that employs a grid-based sampling strategy to strategically select observation pairs. Simulation studies demonstrate SG-PL's principal advantage: a dramatic reduction in computational time -- often by orders of magnitude -- when compared to benchmark methods. This substantial acceleration is achieved with a manageable trade-off in statistical efficiency. An empirical application further validates SG-PL's practical utility. Consequently, SG-PL emerges as a highly scalable and effective tool for spatial analysis on very large datasets, offering a compelling balance where substantial gains in computational feasibility are realized for a limited cost in statistical precision, a trade-off that increasingly favors SG-PL with larger N.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07113v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Arbia, Vincenzo Nardelli, Niccolo Salvini</dc:creator>
    </item>
    <item>
      <title>Bayesian Double Descent</title>
      <link>https://arxiv.org/abs/2507.07338</link>
      <description>arXiv:2507.07338v1 Announce Type: cross 
Abstract: Double descent is a phenomenon of over-parameterized statistical models. Our goal is to view double descent from a Bayesian perspective. Over-parameterized models such as deep neural networks have an interesting re-descending property in their risk characteristics. This is a recent phenomenon in machine learning and has been the subject of many studies. As the complexity of the model increases, there is a U-shaped region corresponding to the traditional bias-variance trade-off, but then as the number of parameters equals the number of observations and the model becomes one of interpolation, the risk can become infinite and then, in the over-parameterized region, it re-descends -- the double descent effect. We show that this has a natural Bayesian interpretation. Moreover, we show that it is not in conflict with the traditional Occam's razor that Bayesian models possess, in that they tend to prefer simpler models when possible. We illustrate the approach with an example of Bayesian model selection in neural networks. Finally, we conclude with directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07338v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Nick Polson, Vadim Sokolov</dc:creator>
    </item>
    <item>
      <title>Scalable Signed Exponential Random Graph Models under Local Dependence</title>
      <link>https://arxiv.org/abs/2507.07660</link>
      <description>arXiv:2507.07660v1 Announce Type: cross 
Abstract: Traditional network analysis focuses on binary edges, while real-world relationships are more nuanced, encompassing cooperation, neutrality, and conflict. The rise of negative edges in social media discussions spurred interest in analyzing signed interactions, especially in polarized debates. However, the vast data generated by digital networks presents challenges for traditional methods like Stochastic Block Models (SBM) and Exponential Family Random Graph Models (ERGM), particularly due to the homogeneity assumption and global dependence, which become increasingly unrealistic as network size grows. To address this, we propose a novel method that combines the strengths of SBM and ERGM while mitigating their weaknesses by incorporating local dependence based on non-overlapping blocks. Our approach involves a two-step process: first, decomposing the network into sub-networks using SBM approximation, and then estimating parameters using ERGM methods. We validate our method on large synthetic networks and apply it to a signed Wikipedia network of thousands of editors. Through the use of local dependence, we find patterns consistent with structural balance theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07660v1</guid>
      <category>cs.SI</category>
      <category>stat.CO</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marc Schalberger, Cornelius Fritz</dc:creator>
    </item>
    <item>
      <title>Vecchia approximated Bayesian heteroskedastic Gaussian processes</title>
      <link>https://arxiv.org/abs/2507.07815</link>
      <description>arXiv:2507.07815v1 Announce Type: cross 
Abstract: Many computer simulations are stochastic and exhibit input dependent noise. In such situations, heteroskedastic Gaussian processes (hetGPs) make ideal surrogates as they estimate a latent, non-constant variance. However, existing hetGP implementations are unable to deal with large simulation campaigns and use point-estimates for all unknown quantities, including latent variances. This limits applicability to small experiments and undercuts uncertainty. We propose a Bayesian hetGP using elliptical slice sampling (ESS) for posterior variance integration, and the Vecchia approximation to circumvent computational bottlenecks. We show good performance for our upgraded hetGP capability, compared to alternatives, on a benchmark example and a motivating corpus of more than 9-million lake temperature simulations. An open source implementation is provided as bhetGP on CRAN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07815v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parul V. Patil, Robert B. Gramacy, Cayelan C. Carey, R. Quinn Thomas</dc:creator>
    </item>
    <item>
      <title>Non-conjugate variational Bayes for pseudo-likelihood mixed effect models</title>
      <link>https://arxiv.org/abs/2206.09444</link>
      <description>arXiv:2206.09444v4 Announce Type: replace-cross 
Abstract: We propose a unified, yet simple to code, non-conjugate variational Bayes algorithm for posterior approximation of generic Bayesian generalized mixed effect models. Specifically, we consider regression models identified by a linear predictor, eventually transformed using a bijective link, where the prediction misfit is measured using, possibly non-differentiable, loss functions. Examples include generalized linear models, quasi-likelihood models, and robust regression. To address the limitations of non-conjugate settings, we employ an efficient message passing optimization strategy under a Gaussian variational approximation of the posterior. The resulting algorithms automatically account for non-conjugate priors and non-smooth losses, without requiring model-specific data-augmented representations. Besides the general formulation, we provide closed-form updates for popular model specifications, including quantile regression and support vector machines. Overall, theoretical and empirical results highlight the effectiveness of the proposed method, demonstrating its computational efficiency and approximation accuracy as an alternative to existing Bayesian techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.09444v4</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/10618600.2025.2527925</arxiv:DOI>
      <arxiv:journal_reference>Journal of Computational and Graphical Statistics, 1-18 (2025)</arxiv:journal_reference>
      <dc:creator>Cristian Castiglione, Mauro Bernardi</dc:creator>
    </item>
  </channel>
</rss>
