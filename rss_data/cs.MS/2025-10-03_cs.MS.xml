<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MS</link>
    <description>cs.MS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Oct 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Improving Runtime Performance of Tensor Computations using Rust From Python</title>
      <link>https://arxiv.org/abs/2510.01495</link>
      <description>arXiv:2510.01495v1 Announce Type: new 
Abstract: In this work, we investigate improving the runtime performance of key computational kernels in the Python Tensor Toolbox (pyttb), a package for analyzing tensor data across a wide variety of applications. Recent runtime performance improvements have been demonstrated using Rust, a compiled language, from Python via extension modules leveraging the Python C API -- e.g., web applications, data parsing, data validation, etc. Using this same approach, we study the runtime performance of key tensor kernels of increasing complexity, from simple kernels involving sums of products over data accessed through single and nested loops to more advanced tensor multiplication kernels that are key in low-rank tensor decomposition and tensor regression algorithms. In numerical experiments involving synthetically generated tensor data of various sizes and these tensor kernels, we demonstrate consistent improvements in runtime performance when using Rust from Python over 1) using Python alone, 2) using Python and the Numba just-in-time Python compiler (for loop-based kernels), and 3) using the NumPy Python package for scientific computing (for pyttb kernels).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01495v1</guid>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kimmie Harding, Daniel M. Dunlavy</dc:creator>
    </item>
    <item>
      <title>Z-scores-based methods and their application to biological monitoring: An extended analysis of professional soccer players and cyclists athletes</title>
      <link>https://arxiv.org/abs/2510.01810</link>
      <description>arXiv:2510.01810v1 Announce Type: new 
Abstract: The increase in the collection of biological data allows for the individual and longitudinal monitoring of hematological or urine biomarkers. However, identifying abnormal behavior in these biological sequences is not trivial. Moreover, the complexity of the biological data (correlation between biomarkers, seasonal effects, etc.) is also an issue. Z-score methods can help assess the abnormality in these longitudinal sequences while capturing some features of the biological complexity. This work details a statistical framework for handling biological sequences using three custom Z-score methods in the intra-individual variability scope. These methods can detect abnormal samples in the longitudinal sequences with respect to the seasonality, chronological time or correlation between biomarkers. One of these methods is an extension of one custom Z-score method to the Gaussian linear model, which allows for including additional variables in the model design. We illustrate the use of the framework on the longitudinal data of 3,936 professional soccer players (5 biomarkers) and 1,683 amateur or professional cyclists (10 biomarkers). The results show that a particular Z-score method, designed to detect a change in a series of consecutive observations, measured a high proportion of abnormal values (more than three times the false positive rate) in the ferritin and IGF1 biomarkers for both data sets. The proposed framework and methods could be applied in other contexts, such as the clinical patient follow-up in monitoring abnormal values of biological markers. The methods are flexible enough to include more complicated biological features, which can be directly incorporated into the model design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01810v1</guid>
      <category>cs.MS</category>
      <category>stat.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geoffroy C. B. Berthelot (IRMES - URP\_7329, RELAIS), Brigitte Gelein (ENSAI, IRMAR), Eric Meinadier (FFC), Emmanuel Orhant (FFF), J\'er\^ome Dedecker (MAP5 - UMR 8145)</dc:creator>
    </item>
    <item>
      <title>cuHPX: GPU-Accelerated Differentiable Spherical Harmonic Transforms on HEALPix Grids</title>
      <link>https://arxiv.org/abs/2510.01785</link>
      <description>arXiv:2510.01785v1 Announce Type: cross 
Abstract: HEALPix (Hierarchical Equal Area isoLatitude Pixelization) is a widely adopted spherical grid system in astrophysics, cosmology, and Earth sciences. Its equal-area, iso-latitude structure makes it particularly well-suited for large-scale data analysis on the sphere. However, implementing high-performance spherical harmonic transforms (SHTs) on HEALPix grids remains challenging due to irregular pixel geometry, latitude-dependent alignments, and the demands for high-resolution transforms at scale. In this work, we present cuHPX, an optimized CUDA library that provides functionality for spherical harmonic analysis and related utilities on HEALPix grids. Beyond delivering substantial performance improvements, cuHPX ensures high numerical accuracy, analytic gradients for integration with deep learning frameworks, out-of-core memory-efficient optimization, and flexible regridding between HEALPix, equiangular, and other common spherical grid formats. Through evaluation, we show that cuHPX achieves rapid spectral convergence and delivers over 20 times speedup compared to existing libraries, while maintaining numerical consistency. By combining accuracy, scalability, and differentiability, cuHPX enables a broad range of applications in climate science, astrophysics, and machine learning, effectively bridging optimized GPU kernels with scientific workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01785v1</guid>
      <category>astro-ph.IM</category>
      <category>cs.MS</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaopo Cheng, Akshay Subramaniam, Shixun Wu, Noah Brenowitz</dc:creator>
    </item>
    <item>
      <title>Integrating Odeint Time Stepping into OpenFPM for Distributed and GPU Accelerated Numerical Solvers</title>
      <link>https://arxiv.org/abs/2309.05331</link>
      <description>arXiv:2309.05331v3 Announce Type: replace 
Abstract: We present a software implementation integrating the time-integration library Odeint from Boost with the OpenFPM framework for scalable scientific computing. This enables compact and scalable codes for multi-stage, multi-step, and adaptive explicit time integration on distributed-memory parallel computers and on Graphics Processing Units (GPUs). The present implementation is based on extending OpenFPM's metaprogramming system to Odeint data types. This makes the time-integration methods from Odeint available in a concise template-expression language for numerical simulations distributed and parallelized using OpenFPM. We benchmark the present software for exponential and sigmoidal dynamics and present application examples to the 3D Gray-Scott reaction-diffusion problem and the "dam break" problem from fluid mechanics. We find a strong-scaling efficiency of 80% on up to 512 CPU cores and a five-fold speedup on a single GPU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05331v3</guid>
      <category>cs.MS</category>
      <category>cs.DC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhinav Singh, Landfried Kraatz, Serhii Yaskovets, Pietro Incardona, Ivo F. Sbalzarini</dc:creator>
    </item>
  </channel>
</rss>
