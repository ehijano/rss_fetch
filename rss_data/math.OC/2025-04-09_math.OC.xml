<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 10 Apr 2025 01:40:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>BC-ADMM: An Efficient Non-convex Constrained Optimizer with Robotic Applications</title>
      <link>https://arxiv.org/abs/2504.05465</link>
      <description>arXiv:2504.05465v1 Announce Type: new 
Abstract: Non-convex constrained optimizations are ubiquitous in robotic applications such as multi-agent navigation, UAV trajectory optimization, and soft robot simulation. For this problem class, conventional optimizers suffer from small step sizes and slow convergence. We propose BC-ADMM, a variant of Alternating Direction Method of Multiplier (ADMM), that can solve a class of non-convex constrained optimizations with biconvex constraint relaxation. Our algorithm allows larger step sizes by breaking the problem into small-scale sub-problems that can be easily solved in parallel. We show that our method has both theoretical convergence speed guarantees and practical convergence guarantees in the asymptotic sense. Through numerical experiments in a row of four robotic applications, we show that BC-ADMM has faster convergence than conventional gradient descent and Newton's method in terms of wall clock time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05465v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>cs.RO</category>
      <category>math.NA</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zherong Pan, Kui Wu</dc:creator>
    </item>
    <item>
      <title>Extended SQP Methods in Nonsmooth Difference Programming Applied to Problems with Variational Inequality Constraints</title>
      <link>https://arxiv.org/abs/2504.05609</link>
      <description>arXiv:2504.05609v1 Announce Type: new 
Abstract: This paper explores a new class of constrained difference programming problems, where the objective and constraints are formulated as differences of functions, without requiring their convexity. To investigate such problems, novel variants of the extended sequential quadratic method are introduced. These algorithms iteratively solve strongly convex quadratic subproblems constructed via linear approximations of the given data by using their gradients and subgradients. The convergence of the proposed methods is rigorously analyzed by employing, in particular, the Polyak-\L ojasiewicz-Kurdyka property that ensures global convergence for various classes of functions in the problem formulation, e.g., semialgebraic ones. The original framework is further extended to address difference programming problems with variational inequality (VI) constraints. By reformulating VI constraints via regularized gap functions, such problems are naturally embedded into constrained difference programming that leads us to direct applications of the proposed algorithms. Numerical experiments for the class of continuous network design problems demonstrate the efficiency of the new methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05609v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boris S. Mordukhovich, Yixia Song, Shangzhi Zeng, Jin Zhang</dc:creator>
    </item>
    <item>
      <title>Distributed Solving of Linear Quadratic Optimal Controller with Terminal State Constraint</title>
      <link>https://arxiv.org/abs/2504.05631</link>
      <description>arXiv:2504.05631v1 Announce Type: new 
Abstract: This paper is concerned with the linear quadratic (LQ) optimal control of continuous-time system with terminal state constraint. In particular, multiple agents exist in the system which can only access partial information of the matrix parameters. This makes the classical solving method based on Riccati equation with global information suffering. The main contribution is to present a distributed algorithm to derive the optimal controller which is consisting of the distributed iterations for the Riccati equation, a backward differential equation driven by the optimal Lagrange multiplier and the optimal state. Finally, a numerical example verifies the effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05631v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjing Yang, Juanjuan Xu</dc:creator>
    </item>
    <item>
      <title>Hamilton-Jacobi-Bellman equation and Viscosity solutions for an optimal control problem for stochastic convective Brinkman-Forchheimer equations</title>
      <link>https://arxiv.org/abs/2504.05707</link>
      <description>arXiv:2504.05707v1 Announce Type: new 
Abstract: In this work, we consider the following two- and three-dimensional stochastic convective Brinkman-Forchheimer (SCBF) equations in torus $\mathbb{T}^d,\ d\in\{2,3\}$:
  \begin{align*}
  \mathrm{d}\boldsymbol{u}+\left[-\mu \Delta\boldsymbol{u}+(\boldsymbol{u}\cdot\nabla)\boldsymbol{u}+\alpha\boldsymbol{u}+\beta|\boldsymbol{u}|^{r-1}\boldsymbol{u}+\nabla p\right]\mathrm{d}t=\mathrm{d}\mathrm{W}, \ \nabla\cdot\boldsymbol{u}=0,
  \end{align*}
  where $\mu,\alpha,\beta&gt;0$, $r\in[1,\infty)$ and $\mathrm{W}$ is a Hilbert space valued $\mathrm{Q}-$Wiener process. The above system can be considered as damped stochastic Navier-Stokes equations. Using the dynamic programming approach, we study the infinite-dimensional second-order Hamilton-Jacobi equation associated with an optimal control problem for SCBF equations. For the supercritical case, that is, $r\in(3,\infty)$ for $d=2$ and $r\in(3,5)$ for $d=3$ ($2\beta\mu\geq 1$ for $r=3$ in $d\in\{2,3\}$), we first prove the existence of a viscosity solution for the infinite-dimensional HJB equation, which we identify with the value function of the associated control problem. By establishing a comparison principle for $r\in(3,\infty)$ and $r=3$ with $2\beta\mu\geq1$ in $d\in\{2,3\}$, we prove that the value function is the unique viscosity solution and hence we resolve the global unique solvability of the HJB equation in both two and three dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05707v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sagar Gautam, Manil T. Mohan</dc:creator>
    </item>
    <item>
      <title>Accelerated Natural Gradient Method for Parametric Manifold Optimization</title>
      <link>https://arxiv.org/abs/2504.05753</link>
      <description>arXiv:2504.05753v1 Announce Type: new 
Abstract: Parametric manifold optimization problems frequently arise in various machine learning tasks, where state functions are defined on infinite-dimensional manifolds. We propose a unified accelerated natural gradient descent (ANGD) framework to address these problems. By incorporating a Hessian-driven damping term into the manifold update, we derive an accelerated Riemannian gradient (ARG) flow that mitigates oscillations. An equivalent first-order system is further presented for the ARG flow, enabling a unified discretization scheme that leads to the ANGD method. In our discrete update, our framework considers various advanced techniques, including least squares approximation of the update direction, projected momentum to accelerate convergence, and efficient approximation methods through the Kronecker product. It accommodates various metrics, including $H^s$, Fisher-Rao, and Wasserstein-2 metrics, providing a computationally efficient solution for large-scale parameter spaces. We establish a convergence rate for the ARG flow under geodesic convexity assumptions. Numerical experiments demonstrate that ANGD outperforms standard NGD, underscoring its effectiveness across diverse deep learning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05753v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenyi Li, Shuchen Zhu, Zhonglin Xie, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>Presolve techniques for quasi-convex chance constraints with finite-support low-dimensional uncertainty</title>
      <link>https://arxiv.org/abs/2504.05785</link>
      <description>arXiv:2504.05785v1 Announce Type: new 
Abstract: Chance-constrained programs (CCP) represent a trade-off between conservatism and robustness in optimization. In many CCPs, one optimizes an objective under a probabilistic constraint continuously parameterized by a random vector $\xi$. In this work, we study the specific case where the constraint is quasi-convex with $\xi$. Moreover, the support of vector $\xi$ is a collection of $N$ scenarios in dimension $p=2$ or $p=3$. In general, even when both the constraint and the objective are convex in the decision variable, the feasible region of a CCP is nonconvex, turning it into a difficult problem. However, under mild assumptions, many CCPs can be recast as big-$M$ mixed-integer convex programs (MICP). Unfortunately, the difficulty of these MICPs explodes with the number of scenarios, restricting the instances practically solvable in decent time. To cut down the effective number of scenarios considered in MICP reformulations and accelerate their solving, we propose and test presolve techniques based on computational geometry. Our techniques produce certificates to discard or select a priori some scenarios before solving a regular MICP. Moreover, the information aggregated during presolve leverages the possibility to strengthen big-$M$ constants. Our numerical experiments suggest that spending some time in presolve is more efficient than a direct solve for a class of probabilistic projection problems, including an interesting type of facility location problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05785v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guillaume Van Dessel, Fran\c{c}ois Glineur</dc:creator>
    </item>
    <item>
      <title>A Simple yet Highly Accurate Prediction-Correction Algorithm for Time-Varying Optimization</title>
      <link>https://arxiv.org/abs/2504.05798</link>
      <description>arXiv:2504.05798v1 Announce Type: new 
Abstract: This paper proposes a simple yet highly accurate prediction-correction algorithm, SHARP, for unconstrained time-varying optimization problems. Its prediction is based on an extrapolation derived from the Lagrange interpolation of past solutions. Since this extrapolation can be computed without Hessian matrices or even gradients, the computational cost is low. To ensure the stability of the prediction, the algorithm includes an acceptance condition that rejects the prediction when the update is excessively large. The proposed method achieves a tracking error of $O(h^{p})$, where $h$ is the sampling period, assuming that the $p$th derivative of the target trajectory is bounded and the convergence of the correction step is locally linear. We also prove that the method can track a trajectory of stationary points even if the objective function is non-convex. Numerical experiments demonstrate the high accuracy of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05798v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomoya Kamijima, Naoki Marumo, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Extending Parametric Model Embedding with Physical Information for Design-space Dimensionality Reduction in Shape Optimization</title>
      <link>https://arxiv.org/abs/2504.05863</link>
      <description>arXiv:2504.05863v1 Announce Type: new 
Abstract: In this work, an extension of the parametric model embedding (PME) approach is presented, aiming to achieve more effective design-space dimensionality reduction for shape optimization in vehicle design. PME, rooted in principal component analysis (PCA), not only identifies a reduced set of critical modes but also re-parameterizes the original design space, enabling direct and interpretable manipulations of shape modifications within the reduced space. Alongside the "physics-informed" version (PI-PME), which enriches geometry with low-fidelity distributed and lumped physical quantities, a "physics-driven" variant (PD-PME) is introduced that focuses exclusively on physical parameters. Both formulations employ PCA to capture the principal modes of variability yet differ in their balance between geometric and physical information, through the ad-hoc definition of a weighted inner product. Through test cases involving the RAE-2822 airfoil, a bio-inspired underwater glider, a naval propeller, and the DTMB-5415 destroyer-type vessel, it is shown how the resulting frameworks provide a first-level assessment of design variability, offer interpretability regarding which original variables most strongly affect performance, and efficiently bridge geometric and physical parameters. Furthermore, lumped physical parameters can serve as a low-fidelity foundation for multi-fidelity optimization, directly leveraging the linear re-parameterization to drive the reduced design variables. Meanwhile, distributed physical parameters enable the construction of machine-learning-based reduced-order models to infer integral quantities of interest. By allowing the user to embed these insights early in the design process, PI-PME and PD-PME facilitate more robust, cost-effective exploration, paving the way for subsequent high-fidelity optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05863v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Serani, Giorgio Palma, Jeroen Wackers, Domenico Quagliarella, Stefano Gaggero, Matteo Diez</dc:creator>
    </item>
    <item>
      <title>Self-sustained oscillations in discrete-time relay feedback systems</title>
      <link>https://arxiv.org/abs/2504.05941</link>
      <description>arXiv:2504.05941v1 Announce Type: new 
Abstract: We study the problem of determining self-sustained oscillations in discrete-time linear time-invariant relay feedback systems. Concretely, we are interested in predicting when such a system admits unimodal oscillations, i.e., when the output has a single-peaked period. Under the assumption that the linear system is stable and has an impulse response that is strictly monotonically decreasing on its infinite support, we take a novel approach in using the framework of total positivity to address our main question. It is shown that unimodal self-oscillations can only exist if the number of positive and negative elements in a period coincides. Based on this result, we derive conditions for the existence of such oscillations, determine bounds on their periods, and address the question of uniqueness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05941v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Kang Tong, Christian Grussler, Michelle S. Chong</dc:creator>
    </item>
    <item>
      <title>Linear time-and-space-invariant relaxation systems</title>
      <link>https://arxiv.org/abs/2504.06009</link>
      <description>arXiv:2504.06009v1 Announce Type: new 
Abstract: This paper generalizes the physical property of relaxation from linear time-invariant (LTI) to linear time-and-space-invariant (LTSI) systems. It is shown that the defining features of relaxation -- complete monotonicity, passivity, and memory-based storage -- carry over seamlessly to the spatio-temporal domain. An LTSI system is shown to be of relaxation type if and only if its associated spatio-temporal Hankel operator is cyclically monotone. This implies the existence of an intrinsic quadratic storage functional defined uniquely by past inputs, independently of any state-space realization. As in the LTI case, LTSI relaxation systems are shown to be those systems for which the state-space concept of storage coincides with the input-output concept of fading memory functional.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06009v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tihol Ivanov Donchev, Brayan M. Shali, Rodolphe Sepulchre</dc:creator>
    </item>
    <item>
      <title>An Adaptive Algorithm for Bilevel Optimization on Riemannian Manifolds</title>
      <link>https://arxiv.org/abs/2504.06042</link>
      <description>arXiv:2504.06042v1 Announce Type: new 
Abstract: Existing methods for solving Riemannian bilevel optimization (RBO) problems require prior knowledge of the problem's first- and second-order information and curvature parameter of the Riemannian manifold to determine step sizes, which poses practical limitations when these parameters are unknown or computationally infeasible to obtain. In this paper, we introduce the Adaptive Riemannian Hypergradient Descent (AdaRHD) algorithm for solving RBO problems. To the best of our knowledge, AdaRHD is the first method to incorporate a fully adaptive step size strategy that eliminates the need for problem-specific parameters. We prove that AdaRHD achieves an $\mathcal{O}(1/\epsilon)$ iteration complexity for finding an $\epsilon$-stationary point, thus matching the complexity of existing non-adaptive methods. Furthermore, we demonstrate that substituting exponential mappings with retraction mappings maintains the same complexity bound. Experiments demonstrate that AdaRHD achieves comparable performance to existing non-adaptive approaches while exhibiting greater robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06042v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xu Shi, Rufeng Xiao, Rujun Jiang</dc:creator>
    </item>
    <item>
      <title>Carbon, Cost and Capacity: Multi-objective Charging of Electric Buses</title>
      <link>https://arxiv.org/abs/2504.06078</link>
      <description>arXiv:2504.06078v1 Announce Type: new 
Abstract: The public transport sector is in the process of decarbonizing by electrifying its bus fleets. This results in challenges if the high electricity demand resulting from battery charging demand is confronted with limited grid capacity and high synchronicity at bus charging sites. In this paper, we explore multi-objective scheduling for bus charging sites to minimize the emissions associated with charging processes and to aid the operation of the electricity grid by mitigating peak consumption. In particular, we discuss and validate optimization approaches for those objectives, as well as their weighted combination, based on data from a real-life bus charging site in the Netherlands. The simulation results show that compared to uncontrolled charging, power peaks can be reduced by up to 57%, while time-of-use emissions associated with the charging of electric buses are also reduced significantly. Furthermore, by using a synthetic baseload, we illustrate the flexibility potential offered by bus charging sites, and advocate that such sites should share a grid connection with other high-load assets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06078v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leoni Winschermann, Leander C. van der Bijl, Marco E. T. Gerards, Johann Hurink</dc:creator>
    </item>
    <item>
      <title>Dictionary-free Koopman Predictive Control for Autonomous Vehicles in Mixed Traffic</title>
      <link>https://arxiv.org/abs/2504.06240</link>
      <description>arXiv:2504.06240v1 Announce Type: new 
Abstract: Koopman Model Predictive Control (KMPC) and Data-EnablEd Predictive Control (DeePC) use linear models to approximate nonlinear systems and integrate them with predictive control. Both approaches have recently demonstrated promising performance in controlling Connected and Autonomous Vehicles (CAVs) in mixed traffic. However, selecting appropriate lifting functions for the Koopman operator in KMPC is challenging, while the data-driven representation from Willems' fundamental lemma in DeePC must be updated to approximate the local linearization when the equilibrium traffic state changes. In this paper, we propose a dictionary-free Koopman model predictive control (DF-KMPC) for CAV control. In particular, we first introduce a behavioral perspective to identify the optimal dictionary-free Koopman linear model. We then utilize an iterative algorithm to compute a data-driven approximation of the dictionary-free Koopman representation. Integrating this data-driven linear representation with predictive control leads to our DF-KMPC, which eliminates the need to select lifting functions and update the traffic equilibrium state. Nonlinear traffic simulations show that DF-KMPC effectively mitigates traffic waves and improves tracking performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06240v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xu Shang, Zhaojian Li, Yang Zheng</dc:creator>
    </item>
    <item>
      <title>Constrained Search in Imaginary Time</title>
      <link>https://arxiv.org/abs/2504.05332</link>
      <description>arXiv:2504.05332v1 Announce Type: cross 
Abstract: An optimization method for the expectation value of a self-adjoint operator under a finite number of expectation-value constraints based on imaginary-time evolution is introduced. It is formulated for finite-dimensional Hilbert spaces and uses linearly independent and commuting self-adjoint operators for the constraints. The method is applied to the problem of finding the universal functional of density-functional theory and allows theoretical insights into the density-potential mapping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05332v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>math.OC</category>
      <category>physics.chem-ph</category>
      <category>quant-ph</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Markus Penz, Robert van Leeuwen</dc:creator>
    </item>
    <item>
      <title>Stability of optimal transport maps on Riemannian manifolds</title>
      <link>https://arxiv.org/abs/2504.05412</link>
      <description>arXiv:2504.05412v1 Announce Type: cross 
Abstract: We prove quantitative bounds on the stability of optimal transport maps and Kantorovich potentials from a fixed source measure $\rho$ under variations of the target measure $\mu$, when the cost function is the squared Riemannian distance on a Riemannian manifold. Previous works were restricted to subsets of Euclidean spaces, or made specific assumptions either on the manifold, or on the regularity of the transport maps. Our proof techniques combine entropy-regularized optimal transport with spectral and integral-geometric techniques. As some of the arguments do not rely on the Riemannian structure, our work also paves the way towards understanding stability of optimal transport in more general geometric spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05412v1</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Kitagawa, Cyril Letrouit, Quentin M\'erigot</dc:creator>
    </item>
    <item>
      <title>Radial Isotropic Position via an Implicit Newton's Method</title>
      <link>https://arxiv.org/abs/2504.05687</link>
      <description>arXiv:2504.05687v1 Announce Type: cross 
Abstract: Placing a dataset $A = \{\mathbf{a}_i\}_{i \in [n]} \subset \mathbb{R}^d$ in radial isotropic position, i.e., finding an invertible $\mathbf{R} \in \mathbb{R}^{d \times d}$ such that the unit vectors $\{(\mathbf{R} \mathbf{a}_i) \|\mathbf{R} \mathbf{a}_i\|_2^{-1}\}_{i \in [n]}$ are in isotropic position, is a powerful tool with applications in functional analysis, communication complexity, coding theory, and the design of learning algorithms. When the transformed dataset has a second moment matrix within a $\exp(\pm \epsilon)$ factor of a multiple of $\mathbf{I}_d$, we call $\mathbf{R}$ an $\epsilon$-approximate Forster transform.
  We give a faster algorithm for computing approximate Forster transforms, based on optimizing an objective defined by Barthe [Barthe98]. When the transform has a polynomially-bounded aspect ratio, our algorithm uses $O(nd^{\omega - 1}(\frac n \epsilon)^{o(1)})$ time to output an $\epsilon$-approximate Forster transform with high probability, when one exists. This is almost the natural limit of this approach, as even evaluating Barthe's objective takes $O(nd^{\omega - 1})$ time. Previously, the state-of-the-art runtime in this regime was based on cutting-plane methods, and scaled at least as $\approx n^3 + n^2 d^{\omega - 1}$. We also provide explicit estimates on the aspect ratio in the smoothed analysis setting, and show that our algorithm similarly improves upon those in the literature.
  To obtain our results, we develop a subroutine of potential broader interest: a reduction from almost-linear time sparsification of graph Laplacians to the ability to support almost-linear time matrix-vector products. We combine this tool with new stability bounds on Barthe's objective to implicitly implement a box-constrained Newton's method [CMTV17, ALOW17].</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05687v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arun Jambulapati, Jonathan Li, Kevin Tian</dc:creator>
    </item>
    <item>
      <title>Architecture independent generalization bounds for overparametrized deep ReLU networks</title>
      <link>https://arxiv.org/abs/2504.05695</link>
      <description>arXiv:2504.05695v2 Announce Type: cross 
Abstract: We prove that overparametrized neural networks are able to generalize with a test error that is independent of the level of overparametrization, and independent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds that only depend on the metric geometry of the test and training sets, on the regularity properties of the activation function, and on the operator norms of the weights and norms of biases. For overparametrized deep ReLU networks with a training sample size bounded by the input space dimension, we explicitly construct zero loss minimizers without use of gradient descent, and prove that the generalization error is independent of the network architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05695v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Chen, Chun-Kai Kevin Chien, Patricia Mu\~noz Ewald, Andrew G. Moore</dc:creator>
    </item>
    <item>
      <title>A Douglas-Rachford Splitting Method for Solving Monotone Variational Inequalities in Linear-quadratic Dynamic Games</title>
      <link>https://arxiv.org/abs/2504.05757</link>
      <description>arXiv:2504.05757v1 Announce Type: cross 
Abstract: This paper considers constrained linear dynamic games with quadratic objective functions, which can be cast as affine variational inequalities. By leveraging the problem structure, we apply the Douglas-Rachford splitting, which generates a solution algorithm with linear convergence rate. The fast convergence of the method enables receding-horizon control architectures. Furthermore, we demonstrate that the associated VI admits a closed-form solution within a neighborhood of the attractor, thus allowing for a further reduction in computation time. Finally, we benchmark the proposed method via numerical experiments in an automated driving application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05757v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Reza Rahimi Baghbadorani, Emilio Benenati, Sergio Grammatico</dc:creator>
    </item>
    <item>
      <title>Quantifying uncertainty in inverse scattering problems set in layered environments</title>
      <link>https://arxiv.org/abs/2504.05776</link>
      <description>arXiv:2504.05776v1 Announce Type: cross 
Abstract: The attempt to solve inverse scattering problems often leads to optimization and sampling problems that require handling moderate to large amounts of partial differential equations acting as constraints. We focus here on determining inclusions in a layered medium from the measurement of wave fields on the surface, while quantifying uncertainty and addressing the effect of wave solver quality. Inclusions are characterized by a few parameters describing their material properties and shapes. We devise algorithms to estimate the most likely configurations by optimizing cost functionals with Bayesian regularizations and wave constraints. In particular, we design an automatic Levenberg-Marquardt-Fletcher type scheme based on the use of algorithmic differentiation and adaptive finite element meshes for time dependent wave equation constraints with changing inclusions. In synthetic tests with a single frequency, this scheme converges in few iterations for increasing noise levels. To attain a global view of other possible high probability configurations and asymmetry effects we resort to parallelizable affine invariant Markov Chain Monte Carlo methods, at the cost of solving a few million wave problems. This forces the use of prefixed meshes. While the optimal configurations remain similar, we encounter additional high probability inclusions influenced by the prior information, the noise level and the layered structure, effect that can be reduced by considering more frequencies. We analyze the effect on the calculations of working with adaptive and fixed meshes, under a simple choice of non-reflecting boundary conditions in truncated layered domains for which we establish wellposedness and convergence results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05776v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <category>physics.geo-ph</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.amc.2025.129453</arxiv:DOI>
      <arxiv:journal_reference>Applied Mathematics and Computation 500 (2025) 129453</arxiv:journal_reference>
      <dc:creator>Carolina Abugattas, Ana Carpio, Elena Cebri\'an, Gerardo Oleaga</dc:creator>
    </item>
    <item>
      <title>Stabilization of solutions of the controlled non-local continuity equation</title>
      <link>https://arxiv.org/abs/2504.05935</link>
      <description>arXiv:2504.05935v1 Announce Type: cross 
Abstract: Non-local continuity equation describes an infinite system of identical particles, which interact with each other through the common field. Solution of this equation is a probability measure that stands for spatial distribution of particles. The paper is concerned with stabilization of this solution in the case of controlled dynamic. By generalizing methods used control-Lyapunov function to the case of Wasserstein spaces, we construct a feedback strategy that provides local stabilization, i.e. leads the trajectory to a small neighbourhood of stabilization target. Based on this strategy, we construct a feedback that makes global stabilization, i.e. leads the trajectory infinitely close to stabilization target.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05935v1</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aleksei Volkov</dc:creator>
    </item>
    <item>
      <title>On the Lipschitz continuity of the Spherical Cap Discrepancy around generic point sets</title>
      <link>https://arxiv.org/abs/2504.05967</link>
      <description>arXiv:2504.05967v1 Announce Type: cross 
Abstract: The spherical cap discrepancy is a prominent measure of uniformity for sets on the d-dimensional sphere. It is particularly important for estimating the integration error for certain classes of functions on the sphere. Building on a recently proven explicit formula for the spherical discrepancy, we show as a main result of this paper that this discrepancy is Lipschitz continuous in a neighbourhood of so-called generic point sets (as they are typical outcomes of Monte-Carlo sampling). This property may have some impact (both algorithmically and theoretically for deriving necessary optimality conditions) on optimal quantization, i.e., on finding point sets of fixed size on the sphere having minimum spherical discrepancy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05967v1</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Holger Heitsch, Ren\'e Henrion</dc:creator>
    </item>
    <item>
      <title>Solving General QUBOs with Warm-Start QAOA via a Reduction to Max-Cut</title>
      <link>https://arxiv.org/abs/2504.06253</link>
      <description>arXiv:2504.06253v1 Announce Type: cross 
Abstract: The Quantum Approximate Optimization Algorithm (QAOA) is a quantum algorithm that finds approximate solutions to problems in combinatorial optimization, especially those that can be formulated as a Quadratic Unconstrained Binary Optimization (QUBO) problem. In prior work, researchers have considered various ways of "warm-starting" QAOA by constructing an initial quantum state using classically-obtained solutions or information; these warm-starts typically cause QAOA to yield better approximation ratios at much lower circuit depths. For the Max-Cut problem, one warm-start approaches constructs the initial state using the high-dimensional vectors that are output from an SDP relaxation of the corresponding Max-Cut problem. This work leverages these semidefinite warmstarts for a broader class of problem instances by using a standard reduction that transforms any QUBO instance into a Max-Cut instance. We empirically compare this approach to a "QUBO-relaxation" approach that relaxes the QUBO directly. Our results consider a variety of QUBO instances ranging from randomly generated QUBOs to QUBOs corresponding to specific problems such as the traveling salesman problem, maximum independent set, and portfolio optimization. We find that the best choice of warmstart approach is strongly dependent on the problem type.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06253v1</guid>
      <category>quant-ph</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bikrant Bhattachayra, Michael Capriotti, Reuben Tate</dc:creator>
    </item>
    <item>
      <title>A Semidefinite Relaxation for Sums of Heterogeneous Quadratic Forms on the Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2205.13653</link>
      <description>arXiv:2205.13653v3 Announce Type: replace 
Abstract: We study the maximization of sums of heterogeneous quadratic forms over the Stiefel manifold, a nonconvex problem that arises in several modern signal processing and machine learning applications such as heteroscedastic probabilistic principal component analysis (HPPCA). In this work, we derive a novel semidefinite program (SDP) relaxation of the original problem and study a few of its theoretical properties. We prove a global optimality certificate for the original nonconvex problem via a dual certificate, which leads to a simple feasibility problem to certify global optimality of a candidate solution on the Stiefel manifold. In addition, our relaxation reduces to an assignment linear program for jointly diagonalizable problems and is therefore known to be tight in that case. We generalize this result to show that it is also tight for close-to jointly diagonalizable problems, and we show that the HPPCA problem has this characteristic. Numerical results validate our global optimality certificate and sufficient conditions for when the SDP is tight in various problem settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.13653v3</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kyle Gilman, Sam Burer, Laura Balzano</dc:creator>
    </item>
    <item>
      <title>On the robust isolated calmness of a class of nonsmooth optimizations on Riemannian manifolds and its applications</title>
      <link>https://arxiv.org/abs/2208.07518</link>
      <description>arXiv:2208.07518v2 Announce Type: replace 
Abstract: This paper studies the robust isolated calmness property of the KKT solution mapping of a class of nonsmooth optimization problems on Riemannian manifolds. The manifold versions of the Robinson constraint qualification, the strict Robinson constraint qualification, and the second order conditions are defined and discussed. We show that the robust isolated calmness of the KKT solution mapping is equivalent to satisfying the M-SRCQ and M-SOSC conditions. Furthermore, under the above two conditions, we show that the Riemannian augmented Lagrangian method achieves a local linear convergence rate. Finally, we verify the proposed conditions and demonstrate the convergence rate on two minimization problems over the sphere and the manifold of fixed rank matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.07518v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenglong Bao, Chao Ding, Yuexin Zhou</dc:creator>
    </item>
    <item>
      <title>A Budget-Adaptive Allocation Rule for Optimal Computing Budget Allocation</title>
      <link>https://arxiv.org/abs/2304.02377</link>
      <description>arXiv:2304.02377v3 Announce Type: replace 
Abstract: Simulation-based ranking and selection (R&amp;S) is a popular technique for optimizing discrete-event systems (DESs). It evaluates the mean performance of system designs by simulation outputs and aims to identify the best system design from a set of alternatives by intelligently allocating a limited simulation budget. In R&amp;S, the optimal computing budget allocation (OCBA) is an efficient budget allocation rule that asymptotically maximizes the probability of correct selection (PCS). In this paper, we first show the asymptotic OCBA rule can be recovered by considering a large-scale problem with a specific large budget. Considering a sufficiently large budget can greatly simplify computations, but it also causes the asymptotic OCBA rule ignoring the impact of budget. To address this, we then derive a budget-adaptive rule under the setting where budget is not large enough to simplify computations. The proposed budget-adaptive rule determines the ratio of total budget allocated to designs based on the budget size, and its budget-adaptive property highlights the significant impact of budget on allocation strategy. Based on the proposed budget-adaptive rule, two heuristic algorithms are developed. In the numerical experiments, the superior efficiency of our proposed allocation rule is shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.02377v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zirui Cao, Haowei Wang, Ek Peng Chew, Haobin Li, Kok Choon Tan</dc:creator>
    </item>
    <item>
      <title>An adaptively inexact first-order method for bilevel optimization with application to hyperparameter learning</title>
      <link>https://arxiv.org/abs/2308.10098</link>
      <description>arXiv:2308.10098v4 Announce Type: replace 
Abstract: Various tasks in data science are modeled utilizing the variational regularization approach, where manually selecting regularization parameters presents a challenge. The difficulty gets exacerbated when employing regularizers involving a large number of hyperparameters. To overcome this challenge, bilevel learning can be employed to learn such parameters from data. However, neither exact function values nor exact gradients with respect to the hyperparameters are attainable, necessitating methods that only rely on inexact evaluation of such quantities. State-of-the-art inexact gradient-based methods a priori select a sequence of the required accuracies and cannot identify an appropriate step size since the Lipschitz constant of the hypergradient is unknown. In this work, we propose an algorithm with backtracking line search that only relies on inexact function evaluations and hypergradients and show convergence to a stationary point. Furthermore, the proposed algorithm determines the required accuracy dynamically rather than manually selected before running it. Our numerical experiments demonstrate the efficiency and feasibility of our approach for hyperparameter estimation on a range of relevant problems in imaging and data science such as total variation and field of experts denoising and multinomial logistic regression. Particularly, the results show that the algorithm is robust to its own hyperparameters such as the initial accuracies and step size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.10098v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Sadegh Salehi, Subhadip Mukherjee, Lindon Roberts, Matthias J. Ehrhardt</dc:creator>
    </item>
    <item>
      <title>Notification Timing for On-Demand Personnel Scheduling</title>
      <link>https://arxiv.org/abs/2312.06139</link>
      <description>arXiv:2312.06139v3 Announce Type: replace 
Abstract: Modern business models have enabled service systems to leverage a large pool of casual employees with flexible hours, paid based on piece rates, to fulfill on-demand work. These systems have been successfully implemented in sectors such as ride-sharing, delivery services, and microtasks. However, because casual employees engage infrequently and may lack experience, maintaining service quality remains a key challenge. We introduce a novel scheduling system designed to provide experienced casual employees to service companies, optimizing their operations through a dynamic, data-driven approach. Similar to traditional on-call systems, it contacts casual personnel in order of seniority to inform them about available work. However, our system offers greater flexibility, allowing employees to take time to decide and freely select from available shifts. Senior employees can also replace (bump) junior employees from the schedule if no other preferred shift is available, subject to certain conditions. While permitted, these replacements create disruptions and dissatisfaction among employees. The management aims to efficiently assign all shifts while minimizing bumps. However, uncertainty arises regarding when an employee will select a shift. The key challenge is determining the optimal timing to notify employees to reduce disruptions. We first establish that this problem is $\mathcal{NP}$-complete even with perfect information. To address this, we propose a two-stage stochastic formulation for the dynamic problem and develop a heuristic algorithm that approximates the optimal policy using a threshold-based structure. These policies are fine-tuned using offline solutions with pre-known uncertainty, allowing for optimization. Testing on real-world data demonstrates that our approach outperforms the current strategy used by our industry partner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06139v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prakash Gawas, Antoine Legrain, Louis-Martin Rousseau</dc:creator>
    </item>
    <item>
      <title>A Survey on Design-space Dimensionality Reduction Methods for Shape Optimization</title>
      <link>https://arxiv.org/abs/2405.13944</link>
      <description>arXiv:2405.13944v2 Announce Type: replace 
Abstract: The rapidly evolving field of engineering design of functional surfaces necessitates sophisticated tools to manage the inherent complexity of high-dimensional design spaces. This survey paper offers a scoping review, i.e., a literature mapping synthesis borrowed from clinical medicine, delving into the field of design-space dimensionality reduction techniques tailored for shape optimization, bridging traditional methods and cutting-edge technologies. Dissecting the spectrum of these techniques, from classical linear approaches like principal component analysis to more nuanced nonlinear methods such as autoencoders, the discussion extends to innovative physics-informed methods that integrate physical data into the dimensionality reduction process, enhancing the physical relevance and effectiveness of reduced design spaces. By integrating these methods into optimization frameworks, it is shown how they significantly mitigate the curse of dimensionality, streamline computational processes, and refine the design exploration and optimization of complex functional surfaces. The survey provides a classification of methods and highlights the transformative impact of these techniques in simplifying design challenges, thereby fostering more efficient and effective engineering solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13944v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Serani, Matteo Diez</dc:creator>
    </item>
    <item>
      <title>Decision-Focused Surrogate Modeling for Mixed-Integer Linear Optimization</title>
      <link>https://arxiv.org/abs/2406.05697</link>
      <description>arXiv:2406.05697v2 Announce Type: replace 
Abstract: Mixed-integer optimization is at the core of many online decision-making systems that demand frequent updates of decisions in real time. However, due to their combinatorial nature, mixed-integer linear programs (MILPs) can be difficult to solve, rendering them often unsuitable for time-critical online applications. To address this challenge, we develop a data-driven approach for constructing surrogate optimization models in the form of linear programs (LPs) that can be solved much more efficiently than the corresponding MILPs. We train these surrogate LPs in a decision-focused manner such that for different model inputs, they achieve the same or close to the same optimal solutions as the original MILPs. One key advantage of the proposed method is that it allows the incorporation of all the original MILP's linear constraints, which significantly increases the likelihood of obtaining feasible predicted solutions. Results from two computational case studies indicate that this decision-focused surrogate modeling approach is highly data-efficient and provides very accurate predictions of the optimal solutions. In these examples, it outperforms more commonly used neural-network-based optimization proxies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05697v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research, 2835-8856, 2025</arxiv:journal_reference>
      <dc:creator>Shivi Dixit, Rishabh Gupta, Qi Zhang</dc:creator>
    </item>
    <item>
      <title>Assortment Optimization Under History-Dependent Effects</title>
      <link>https://arxiv.org/abs/2408.10967</link>
      <description>arXiv:2408.10967v3 Announce Type: replace 
Abstract: This paper examines how to plan multi-period assortments when customer utility depends on historical assortments. We formulate this problem as a nonlinear integer programming model and show it is NP-hard in the presence of a negative history-dependent effect (such as a satiation effect). We build solution methodologies for obtaining global optimal solutions under a general setting that the history-dependent effects could be a mixture of positive and negative. We propose using a lifting-based framework to reformulate the problem as a mixed-integer exponential cone program that state-of-the-art solvers can solve. We also design a sequential revenue-ordered policy and show that it solves our problem to optimality in polynomial time when historical assortments positively affect customer utility (such as an addiction effect). Additionally, we identify an optimal cyclic policy for an asymptotic regime, and we also relate its length to the customer's memory length. Finally, we present a case study using a catering service dataset, showing that our model demonstrates good fitness and can effectively balance variety and revenue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10967v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taotao He, Yating Zhang, Huan Zheng</dc:creator>
    </item>
    <item>
      <title>Addressing misspecification in contextual optimization</title>
      <link>https://arxiv.org/abs/2409.10479</link>
      <description>arXiv:2409.10479v3 Announce Type: replace 
Abstract: We study a linear contextual optimization problem where a decision maker has access to historical data and contextual features to learn a cost prediction model aimed at minimizing decision error. We adopt the predict-then-optimize framework for this analysis. Given that perfect model alignment with reality is often unrealistic in practice, we focus on scenarios where the chosen hypothesis set is misspecified. In this context, it remains unclear whether current contextual optimization approaches can effectively address such model misspecification. In this paper, we present a novel integrated learning and optimization approach designed to tackle model misspecification in contextual optimization. This approach offers theoretical generalizability, tractability, and optimality guarantees, along with strong practical performance. Our method involves minimizing a tractable surrogate loss that aligns with the performance value from cost vector predictions, regardless of whether the model is misspecified, and can be optimized in reasonable time. To our knowledge, no previous work has provided an approach with such guarantees in the context of model misspecification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10479v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omar Bennouna, Jiawei Zhang, Saurabh Amin, Asuman Ozdaglar</dc:creator>
    </item>
    <item>
      <title>Zeroth-order Stochastic Cubic Newton Method Revisited</title>
      <link>https://arxiv.org/abs/2410.22357</link>
      <description>arXiv:2410.22357v2 Announce Type: replace 
Abstract: This paper studies stochastic minimization of a finite-sum loss $ F (\mathbf{x}) = \frac{1}{N} \sum_{\xi=1}^N f(\mathbf{x};\xi) $. In many real-world scenarios, the Hessian matrix of such objectives exhibits a low-rank structure on a batch of data. At the same time, zeroth-order optimization has gained prominence in important applications such as fine-tuning large language models. Drawing on these observations, we propose a novel stochastic zeroth-order cubic Newton method that leverages the low-rank Hessian structure via a matrix recovery-based estimation technique. Our method circumvents restrictive incoherence assumptions, enabling accurate Hessian approximation through finite-difference queries. Theoretically, we establish that for most real-world problems in $\mathbb{R}^n$, $\mathcal{O}\left(\frac{n}{\eta^{\frac{7}{2}}}\right)+\widetilde{\mathcal{O}}\left(\frac{n^2 }{\eta^{\frac{5}{2}}}\right)$ function evaluations suffice to attain a second-order $\eta$-stationary point with high probability. This represents a significant improvement in dimensional dependence over existing methods. This improvement is mostly due to a new Hessian estimator that achieves superior sample complexity; This new Hessian estimation method might be of separate interest. Numerical experiments on matrix recovery and machine learning tasks validate the efficacy and scalability of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22357v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Liu, Weibin Peng, Tianyu Wang, Jiajia Yu</dc:creator>
    </item>
    <item>
      <title>A stochastic first-order method with multi-extrapolated momentum for highly smooth unconstrained optimization</title>
      <link>https://arxiv.org/abs/2412.14488</link>
      <description>arXiv:2412.14488v4 Announce Type: replace 
Abstract: In this paper, we consider an unconstrained stochastic optimization problem where the objective function exhibits high-order smoothness. Specifically, we propose a new stochastic first-order method (SFOM) with multi-extrapolated momentum, in which multiple extrapolations are performed in each iteration, followed by a momentum update based on these extrapolations. We demonstrate that the proposed SFOM can accelerate optimization by exploiting the high-order smoothness of the objective function $f$. Assuming that the $p$th-order derivative of $f$ is Lipschitz continuous for some $p\ge2$, and under additional mild assumptions, we establish that our method achieves a sample complexity of $\widetilde{\mathcal{O}}(\epsilon^{-(3p+1)/p})$ for finding a point $x$ such that $\mathbb{E}[\|\nabla f(x)\|]\le\epsilon$. To the best of our knowledge, this is the first SFOM to leverage arbitrary-order smoothness of the objective function for acceleration, resulting in a sample complexity that improves upon the best-known results without assuming the mean-squared smoothness condition. Preliminary numerical experiments validate the practical performance of our method and support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14488v4</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuan He</dc:creator>
    </item>
    <item>
      <title>A Rank-One-Update Method for the Training of Support Vector Machines</title>
      <link>https://arxiv.org/abs/2503.10482</link>
      <description>arXiv:2503.10482v2 Announce Type: replace 
Abstract: This paper considers convex quadratic programs
  associated with the training of support vector machines (SVM).
  Exploiting the special structure of the SVM problem a new
  type of active set method with long cycles and stable rank-one-updates
  is proposed and tested (CMU: cycling method with updates).
  The structure of the problem allows for a repeated simple increase
  of the set of inactive constraints while controlling its size. This is
  followed by minimization steps with cheap updates of a matrix factorization.
  A widely used approach for solving SVM problems is the
  alternating direction method SMO,
  a method that is very efficient for low accuracy.
  The new active set approach allows for higher accuracy
  results at moderate computational cost. To relate both approaches,
  the effect of the accuracy on the running time and on the
  predictive quality of the SVM is compared with some numerical examples.
  A surprising result of the numerical examples is that only a
  very small number of cycles (each consisting of less than 2n
  steps) was used for CMU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10482v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Florian Jarre</dc:creator>
    </item>
    <item>
      <title>Numerical techniques for geodesic approximation in Riemannian shape optimization</title>
      <link>https://arxiv.org/abs/2504.01564</link>
      <description>arXiv:2504.01564v2 Announce Type: replace 
Abstract: Shape optimization is commonly applied in engineering to optimize shapes with respect to an objective functional relying on PDE solutions. In this paper, we view shape optimization as optimization on Riemannian shape manifolds. We consider so-called outer metrics on the diffeomorphism group to solve PDE-constrained shape optimization problems efficiently. Commonly, the numerical solution of such problems relies on the Riemannian version of the steepest descent method. One key difference between this version and the standard method is that iterates are updated via geodesics or retractions. Due to the lack of explicit expressions for geodesics, for most of the previously proposed metrics, very limited progress has been made in this direction. Leveraging the existence of explicit expressions for the geodesic equations associated to the outer metrics on the diffeomorphism group, we aim to study the viability of using such equations in the context of PDE-constrained shape optimization. However, solving geodesic equations is computationally challenging and often restrictive. Therefore, this paper discusses potential numerical approaches to simplify the numerical burden of using geodesics, making the proposed method computationally competitive with previously established methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01564v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Estefania Loayza-Romero, Kathrin Welker</dc:creator>
    </item>
    <item>
      <title>Extremum Seeking for Controlled Vibrational Stabilization of Mechanical Systems: A Variation-of-Constant Averaging Approach Inspired by Flapping Insects Mechanics</title>
      <link>https://arxiv.org/abs/2504.04174</link>
      <description>arXiv:2504.04174v2 Announce Type: replace 
Abstract: This paper presents a novel extremum seeking control (ESC) approach for the vibrational stabilization of a class of mechanical systems (e.g., systems characterized by equations of motion resulting from Newton second law or Euler-Lagrange mechanics). Inspired by flapping insects mechanics, the proposed ESC approach is operable by only one perturbation signal and can admit generalized forces that are quadratic in velocities. We test our ESC, and compare it against approaches from literature, on some classical mechanical systems (e.g., mass-spring and an inverted pendulum systems). We also provide a novel, first-of-its-kind, application of the introduced ESC by achieving a 1D model-free source-seeking of a flapping system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04174v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed A. Elgohary, Sameh A. Eisa</dc:creator>
    </item>
    <item>
      <title>Initial Error Tolerant Distributed Mean Field Control under Partial and Discrete Information</title>
      <link>https://arxiv.org/abs/2504.04938</link>
      <description>arXiv:2504.04938v2 Announce Type: replace 
Abstract: In this paper, an initial error tolerant distributed mean field control method under partial and discrete information is introduced, where each agent only has discrete observations on its own state. First, we study agents' behavior in linear quadratic mean field games (LQMFGs) under heterogeneous erroneous information of the initial mean field state (MF-S), and formulate the relationships between initial errors and systemic deviations. Next, by capturing the initial error affection on the private trajectory of an agent, we give a distributed error estimation method based on maximum likelihood estimation (MLE), where each agent estimates information errors only based on discrete observations on its private trajectory. Furthermore, we establish an error-based segmented state estimation method, design the initial error tolerant distributed mean field control method (IET-DMFC), and demonstrate the consistent property of state estimation as observation frequency increases. Finally, simulations are performed to verify the efficiency of the algorithm and the consistent properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04938v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxin Jin, Haotian Wang, Wang Yao, Xiao Zhang</dc:creator>
    </item>
    <item>
      <title>Faster Reinforcement Learning by Freezing Slow States</title>
      <link>https://arxiv.org/abs/2301.00922</link>
      <description>arXiv:2301.00922v2 Announce Type: replace-cross 
Abstract: We study infinite horizon Markov decision processes (MDPs) with "fast-slow" structure, where some state variables evolve rapidly ("fast states") while others change more gradually ("slow states"). Such structure is common in real-world problems where sequential decisions need to be made at high frequencies over long horizons, where slowly evolving information also influences optimal decisions. Examples include inventory control under slowly changing demand, or dynamic pricing with gradually shifting consumer behavior. Modeling the problem at the natural decision frequency leads to MDPs with discount factors close to one, making them computationally challenging. We propose a novel approximation strategy that "freezes" slow states during a phase of lower-level planning, solving finite-horizon MDPs conditioned on a fixed slow state, and then applying value iteration to an auxiliary upper-level MDP that evolves on a slower timescale. Freezing states for short periods of time leads to easier-to-solve lower-level problems, while a slower upper-level timescale allows for a more favorable discount factor. On the theoretical side, we analyze the regret incurred by our frozen-state approach, which leads to simple insights on how to trade off computational budget versus regret. Empirically, we demonstrate that frozen-state methods produce high-quality policies with significantly less computation, and we show that simply omitting slow states is often a poor heuristic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.00922v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yijia Wang, Daniel R. Jiang</dc:creator>
    </item>
    <item>
      <title>A Lagrangian approach to totally dissipative evolutions in Wasserstein spaces</title>
      <link>https://arxiv.org/abs/2305.05211</link>
      <description>arXiv:2305.05211v2 Announce Type: replace-cross 
Abstract: We introduce and study the class of totally dissipative multivalued probability vector fields (MPVF) $\boldsymbol{\mathrm F}$ on the Wasserstein space $(\mathcal{P}_2(\mathsf{X}),W_2)$ of Euclidean or Hilbertian probability measures. We show that such class of MPVFs is in one to one correspondence with law-invariant dissipative operators in a Hilbert space $L^2(\Omega,\mathcal{B},\mathbb{P};\mathsf{X})$ of random variables, preserving a natural maximality property. This allows us to import in the Wasserstein framework many of the powerful tools from the theory of maximal dissipative operators in Hilbert spaces, deriving existence, uniqueness, stability, and approximation results for the flow generated by a maximal totally dissipative MPVF and the equivalence of its Eulerian and Lagrangian characterizations. We will show that demicontinuous single-valued probability vector fields satisfying a metric dissipativity condition are in fact totally dissipative. Starting from a sufficiently rich set of discrete measures, we will also show how to recover a unique maximal totally dissipative version of a MPVF, proving that its flow provides a general mean field characterization of the asymptotic limits of the corresponding family of discrete particle systems.Such an approach also reveals new interesting structural properties for gradient flows of displacement convex functionals with a core of discrete measures dense in energy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.05211v2</guid>
      <category>math.FA</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giulia Cavagnari, Giuseppe Savar\'e, Giacomo Enrico Sodini</dc:creator>
    </item>
    <item>
      <title>Regularized Gradient Clipping Provably Trains Wide and Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2404.08624</link>
      <description>arXiv:2404.08624v2 Announce Type: replace-cross 
Abstract: We present and analyze a novel regularized form of the gradient clipping algorithm, proving that it converges to global minima of the loss surface of deep neural networks under the squared loss, provided that the layers are of sufficient width. The algorithm presented here, dubbed $\delta-$GClip, introduces a modification to gradient clipping that leads to a first-of-its-kind example of a step size scheduling for gradient descent that provably minimizes training losses of deep neural nets. We also present empirical evidence that our theoretically founded $\delta-$GClip algorithm is competitive with the state-of-the-art deep learning heuristics on various neural architectures including modern transformer based architectures. The modification we do to standard gradient clipping is designed to leverage the PL* condition, a variant of the Polyak-Lojasiewicz inequality which was recently proven to be true for sufficiently wide neural networks at any depth within a neighbourhood of the initialization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08624v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Tucat, Anirbit Mukherjee, Procheta Sen, Mingfei Sun, Omar Rivasplata</dc:creator>
    </item>
    <item>
      <title>Direct Adaptive Control of Grid-Connected Power Converters via Output-Feedback Data-Enabled Policy Optimization</title>
      <link>https://arxiv.org/abs/2411.03909</link>
      <description>arXiv:2411.03909v2 Announce Type: replace-cross 
Abstract: Power electronic converters are becoming the main components of modern power systems due to the increasing integration of renewable energy sources. However, power converters may become unstable when interacting with the complex and time-varying power grid. In this paper, we propose an adaptive data-driven control method to stabilize power converters by using only online input-output data. Our contributions are threefold. First, we reformulate the output-feedback control problem as a state-feedback linear quadratic regulator (LQR) problem with a controllable non-minimal state, which can be constructed from past input-output signals. Second, we propose a data-enabled policy optimization (DeePO) method for this non-minimal realization to achieve efficient output-feedback adaptive control. Third, we use high-fidelity simulations to verify that the output-feedback DeePO can effectively stabilize grid-connected power converters and quickly adapt to the changes in the power grid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03909v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Feiran Zhao, Ruohan Leng, Linbin Huang, Huanhai Xin, Keyou You, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Differential Flatness-based Fast Trajectory Planning for Fixed-wing Unmanned Aerial Vehicles</title>
      <link>https://arxiv.org/abs/2412.01468</link>
      <description>arXiv:2412.01468v2 Announce Type: replace-cross 
Abstract: Due to the strong nonlinearity and nonholonomic dynamics, despite the various general trajectory optimization methods presented, few of them can guarantee efficient computation and physical feasibility for relatively complicated fixed-wing UAV dynamics. Aiming at this issue, this paper investigates a differential flatness-based trajectory optimization method for fixed-wing UAVs (DFTO-FW). The customized trajectory representation is presented through differential flat characteristics analysis and polynomial parameterization, eliminating equality constraints to avoid the heavy computational burdens of solving complex dynamics. Through the design of integral performance costs and derivation of analytical gradients, the original trajectory optimization is transcribed into a lightweight, unconstrained, gradient-analytical optimization with linear time complexity to improve efficiency further. The simulation experiments illustrate the superior efficiency of the DFTO-FW, which takes sub-second CPU time (on a personal desktop) against other competitors by orders of magnitude to generate fixed-wing UAV trajectories in randomly generated obstacle environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01468v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TSMC.2025.3559591</arxiv:DOI>
      <dc:creator>Junzhi Li, Jingliang Sun, Teng Long, Zhenlin Zhou</dc:creator>
    </item>
    <item>
      <title>Understanding Gradient Orthogonalization for Deep Learning via Non-Euclidean Trust-Region Optimization</title>
      <link>https://arxiv.org/abs/2503.12645</link>
      <description>arXiv:2503.12645v2 Announce Type: replace-cross 
Abstract: Optimization with matrix gradient orthogonalization has recently demonstrated impressive results in the training of deep neural networks (Jordan et al., 2024; Liu et al., 2025). In this paper, we provide a theoretical analysis of this approach. In particular, we show that the orthogonalized gradient method can be seen as a first-order trust-region optimization method, where the trust-region is defined in terms of the matrix spectral norm. Motivated by this observation, we develop the stochastic non-Euclidean trust-region gradient method with momentum, which recovers the Muon optimizer (Jordan et al., 2024) as a special case, along with normalized SGD and signSGD with momentum (Cutkosky and Mehta, 2020; Sun et al., 2023). In addition, we prove state-of-the-art convergence results for the proposed algorithm in a range of scenarios, which involve arbitrary non-Euclidean norms, constrained and composite problems, and non-convex, star-convex, first- and second-order smooth functions. Finally, our theoretical findings provide an explanation for several practical observations, including the practical superiority of Muon compared to the Orthogonal-SGDM algorithm of Tuddenham et al. (2022) and the importance of weight decay in the training of large-scale language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12645v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitry Kovalev</dc:creator>
    </item>
    <item>
      <title>Representation and Stability Analysis of 1D PDEs with Periodic Boundary Conditions</title>
      <link>https://arxiv.org/abs/2503.22896</link>
      <description>arXiv:2503.22896v4 Announce Type: replace-cross 
Abstract: PDEs with periodic boundary conditions are frequently used to model processes in large spatial environments, assuming solutions to extend periodically beyond some bounded interval. However, solutions to these PDEs often do not converge to a unique equilibrium, but instead converge to non-stationary trajectories existing in the nullspace of the spatial differential operator (e.g. $\frac{\partial^2}{\partial x^2}$). To analyse this convergence behaviour, in this paper, it is shown how such trajectories can be modeled for a broad class of linear, 2nd order, 1D PDEs with periodic as well as more general boundary conditions, using the Partial Integral Equation (PIE) representation. In particular, it is first shown how any PDE state satisfying these boundary conditions can be uniquely expressed in terms of two components, existing in the image and the nullspace of the differential operator $\frac{\partial^2}{\partial x^2}$, respectively. An equivalent representation of linear PDEs is then derived as a PIE, explicitly defining the dynamics of both state components. Finally, a notion of exponential stability is defined that requires only one of the state components to converge to zero, and it is shown how this stability notion can be tested by solving a linear operator inequality. The proposed methodology is applied to two examples, demonstrating that exponential stability can be verified with tight bounds on the rate of decay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22896v4</guid>
      <category>math.AP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Declan Jagt, Sergei Chernyshenko, Matthew Peet</dc:creator>
    </item>
  </channel>
</rss>
