<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Dec 2024 05:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Enforcing Mesh Quality Constraints in Shape Optimization with a Gradient Projection Method</title>
      <link>https://arxiv.org/abs/2412.00006</link>
      <description>arXiv:2412.00006v1 Announce Type: new 
Abstract: For the numerical solution of shape optimization problems, particularly those constrained by partial differential equations (PDEs), the quality of the underlying mesh is of utmost importance. Particularly when investigating complex geometries, the mesh quality tends to deteriorate over the course of a shape optimization so that either the optimization comes to a halt or an expensive remeshing operation must be performed before the optimization can be continued. In this paper, we present a novel, semi-discrete approach for enforcing a minimum mesh quality in shape optimization. Our approach is based on Rosen's gradient projection method, which incorporates mesh quality constraints into the shape optimization problem. The proposed constraints bound the angles of triangular and solid angles of tetrahedral mesh cells and, thus, also bound the quality of these mesh cells. The method treats these constraints by projecting the search direction to the linear subspace of the currently active constraints. Additionally, only slight modifications to the usual line search procedure are required to ensure the feasibility of the method. We present our method for two- and three-dimensional simplicial meshes. We investigate the proposed approach numerically for the drag minimization of an obstacle in a two-dimensional flow and for the large-scale, three-dimensional optimization of a structured packing used in a distillation column. Our results show that the proposed method is indeed capable of guaranteeing a minimum mesh quality for both academic examples and challenging industrial applications. Particularly, our approach allows the shape optimization of extremely complex structures while ensuring that the mesh quality does not deteriorate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00006v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Blauth, Christian Leithh\"auser</dc:creator>
    </item>
    <item>
      <title>From entropic transport to martingale transport, and applications to model calibration</title>
      <link>https://arxiv.org/abs/2412.00030</link>
      <description>arXiv:2412.00030v1 Announce Type: new 
Abstract: We propose a discrete time formulation of the semi-martingale optimal transport problem based on multi-marginal entropic transport. This approach offers a new way to formulate and solve numerically the calibration problem proposed by [17], using a multi-marginal extension of Sinkhorn algorithm as in [6, 10, 7]. When the time step goes to zero we recover, as detailed in the companion paper [8], a continuous semi-martingale process, solution to a semi-martingale optimal transport problem, with a cost function involving the so-called 'specific entropy' , introduced in [13], see also [12] and [2].</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00030v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean-David Benamou, Guillaume Chazareix, Gr\'egoire Loeper</dc:creator>
    </item>
    <item>
      <title>Assessing How Ride-hailing Rebalancing Strategies Improve the Resilience of Multi-modal Transportation Systems</title>
      <link>https://arxiv.org/abs/2412.00276</link>
      <description>arXiv:2412.00276v1 Announce Type: new 
Abstract: As the worldwide ride-hailing (RH) industry grows, the integration of multi-modal transportation systems has become increasingly important to reduce traffic congestion and improve user mobility. Most RH studies used nominal scenarios with regular demand patterns. However, disruptions must be considered due to their negative impact on operational efficiency, such as longer travel times, higher costs, increased transfers, and more service delays. Therefore, this study investigates the resilience of RH fleet management strategies in multi-modal transportation systems against disruptions on train lines. Two fleet management strategies, centralized and decentralized, are introduced to evaluate their performance. A traffic simulation is conducted using a 900 km2 toy urban network that includes multiple transportation modes such as trains, metros, buses, and RHs. The results revealed that during the peak of disruption, the centralized strategy maintained a higher level of service but required a longer recovery time. In contrast, the decentralized strategy showed a lower service level but recovered more quickly. The centralized strategy showed higher performance during regular scenarios, while the decentralized strategy showed better resilience during disruptions. Comparing the two strategies provides critical insights for developing intermediate RH strategies to effectively manage disruptions and enhance the seamlessness of multi-modal transportation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00276v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Euntak Lee, Rim Slama Salmi, Ludovic Leclercq</dc:creator>
    </item>
    <item>
      <title>Finite Convergence of Circumcentered-Reflection Method on Closed Polyhedral Cones in Euclidean Spaces</title>
      <link>https://arxiv.org/abs/2412.00512</link>
      <description>arXiv:2412.00512v1 Announce Type: new 
Abstract: The Circumcentered Reflection Method (CRM) is a recently developed projection method for solving convex feasibility problems. It offers preferable convergence properties compared to classic methods such as the Douglas-Rachford and the alternating projections method. In this study, our first main theorem establishes that CRM can identify a feasible point in the intersection of two closed convex cones in \(\mathbb{R}^2\) from any starting point in the Euclidean plane. We then apply this theorem to intersections of two polyhedral sets in \(\mathbb{R}^2\) and two wedge-like sets in \(\mathbb{R}^n\), proving that CRM converges to a point in the intersection from any initial position finitely. Additionally, we introduce a modified technique based on CRM, called the Sphere-Centered Reflection Method. With the help of this technique, we demonstrate that CRM can locate a feasible point in finitely many iterations in the intersection of two proper polyhedral cones in \(\mathbb{R}^3\) when the initial point lies in a subset of the complement of the intersection's polar cone. Lastly, we provide an example illustrating that finite convergence may fail for the intersection of two proper polyhedral cones in \(\mathbb{R}^3\) if the initial guess is outside the designated set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00512v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongzhi Liao</dc:creator>
    </item>
    <item>
      <title>Kantorovich-Rubinstein duality theory for the Hessian</title>
      <link>https://arxiv.org/abs/2412.00516</link>
      <description>arXiv:2412.00516v1 Announce Type: new 
Abstract: The classical Kantorovich-Rubinstein duality theorem establishes a significant connection between Monge optimal transport and the maximization of a linear form on the set of 1-Lipschitz functions. This result has been widely used in various research areas, in particular, to expose the bridge between Monge transport theory and a class of optimal design problems. The aim of this paper is to present a similar theory when the linear form is maximized over real $C^{1,1}$ functions whose Hessian is between minus and plus identity matrix. It turns out that this problem can be viewed as the dual of a specific optimal transport problem. The task is to find a minimal three-point plan with the fixed first two marginals, while the third one must be larger than the other two in the sense of convex order. The existence of optimal plans allows to express solutions of the underlying Beckmann problem as a combination of rank-one tensor measures supported by a graph. In the context of two-dimensional mechanics, this graph encodes the optimal configuration of a grillage that transfers a given load system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00516v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karol Bo{\l}botowski, Guy Bouchitt\'e</dc:creator>
    </item>
    <item>
      <title>Primal-dual proximal bundle and conditional gradient methods for convex problems</title>
      <link>https://arxiv.org/abs/2412.00585</link>
      <description>arXiv:2412.00585v1 Announce Type: new 
Abstract: This paper studies the primal-dual convergence and iteration-complexity of proximal bundle methods for solving nonsmooth problems with convex structures. More specifically, we develop a family of primal-dual proximal bundle methods for solving convex nonsmooth composite optimization problems and establish the iteration-complexity in terms of a primal-dual gap. We also propose a class of proximal bundle methods for solving convex-concave composite saddle-point problems and establish the iteration-complexity to find an approximate saddle-point. This paper places special emphasis on the primal-dual perspective of the proximal bundle method. In particular, we discover an interesting duality between the condition gradient method and the cutting-plane scheme used within the proximal bundle method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00585v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaming Liang</dc:creator>
    </item>
    <item>
      <title>Flow matching for stochastic linear control systems</title>
      <link>https://arxiv.org/abs/2412.00617</link>
      <description>arXiv:2412.00617v1 Announce Type: new 
Abstract: This paper addresses the problem of steering an initial probability distribution to a target probability distribution through a deterministic or stochastic linear control system. Our proposed approach is inspired by the flow matching methodology, with the difference that we can only affect the flow through the given control channels. The motivation comes from applications such as robotic swarms and stochastic thermodynamics, where agents or particles can only be manipulated through control actions. The feedback control law that achieves the task is characterized as the conditional expectation of the control inputs for the stochastic bridges that respect the given control system dynamics. Explicit forms are derived for special cases, and a numerical procedure is presented to approximate the control law, illustrated with examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00617v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhang Mei, Mohammad Al-Jarrah, Amirhossein Taghvaei, Yongxin Chen</dc:creator>
    </item>
    <item>
      <title>Stability of first-order methods in tame optimization</title>
      <link>https://arxiv.org/abs/2412.00640</link>
      <description>arXiv:2412.00640v1 Announce Type: new 
Abstract: Modern data science applications demand solving large-scale optimization problems. The prevalent approaches are first-order methods, valued for their scalability. These methods are implemented to tackle highly irregular problems where assumptions of convexity and smoothness are untenable.
  Seeking to deepen the understanding of these methods, we study first-order methods with constant step size for minimizing locally Lipschitz tame functions. To do so, we propose notions of discrete Lyapunov stability for optimization methods. Concerning common first-order methods, we provide necessary and sufficient conditions for stability. We also show that certain local minima can be unstable, without additional noise in the method. Our analysis relies on the connection between the iterates of the first-order methods and continuous-time dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00640v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lexiao Lai</dc:creator>
    </item>
    <item>
      <title>Linear Convergence Analysis of Single-loop Algorithm for Bilevel Optimization via Small-gain Theorem</title>
      <link>https://arxiv.org/abs/2412.00659</link>
      <description>arXiv:2412.00659v1 Announce Type: new 
Abstract: Bilevel optimization has gained considerable attention due to its broad applicability across various fields. While several studies have investigated the convergence rates in the strongly-convex-strongly-convex (SC-SC) setting, no prior work has proven that a single-loop algorithm can achieve linear convergence. This paper employs a small-gain theorem in {robust control theory} to demonstrate that a single-loop algorithm based on the implicit function theorem attains a linear convergence rate of $\mathcal{O}(\rho^{k})$, where $\rho\in(0,1)$ is specified in Theorem 3. Specifically, We model the algorithm as a dynamical system by identifying its two interconnected components: the controller (the gradient or approximate gradient functions) and the plant (the update rule of variables). We prove that each component exhibits a bounded gain and that, with carefully designed step sizes, their cascade accommodates a product gain strictly less than one. Consequently, the overall algorithm can be proven to achieve a linear convergence rate, as guaranteed by the small-gain theorem. The gradient boundedness assumption adopted in the single-loop algorithm (\cite{hong2023two, chen2022single}) is replaced with a gradient Lipschitz assumption in Assumption 2.2. To the best of our knowledge, this work is first-known result on linear convergence for a single-loop algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00659v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianhui Li, Shi Pu, Jianqi Chen, Junfeng Wu</dc:creator>
    </item>
    <item>
      <title>Trust-Region Stochastic Optimization with Variance Reduction Technique</title>
      <link>https://arxiv.org/abs/2412.00673</link>
      <description>arXiv:2412.00673v1 Announce Type: new 
Abstract: We propose a novel algorithm, TR-SVR, for solving unconstrained stochastic optimization problems. This method builds on the trust-region framework, which effectively balances local and global exploration in optimization tasks. TR-SVR incorporates variance reduction techniques to improve both computational efficiency and stability when addressing stochastic objective functions. The algorithm applies a sequential quadratic programming (SQP) approach within the trust-region framework, solving each subproblem approximately using variance-reduced gradient estimators. This integration ensures a robust convergence mechanism while maintaining efficiency, making TR-SVR particularly suitable for large-scale stochastic optimization challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00673v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinshou Zheng</dc:creator>
    </item>
    <item>
      <title>SCLP-Simplex Algorithm for Robust Fluid Processing Networks</title>
      <link>https://arxiv.org/abs/2412.00901</link>
      <description>arXiv:2412.00901v1 Announce Type: new 
Abstract: Fluid models provide a tractable approach to approximate multiclass processing networks. This tractability is a due to the fact that optimal control for such models is a solution of a Separated Continuous Linear Programming (SCLP) problem. Recently developed revised SCLP-simplex algorithm allows to exactly solve very large instances of SCLPs in a reasonable time. Furthermore, to deal with the inherent stochasticity in arrival and service rates in processing networks, robust optimization approach is applied to SCLP models. However, a robust counterpart of SCLP problem has two important drawbacks limiting its tractability. First, the robust counterpart of SCLP problem is a huge SCLP problem itself, that can be in several orders of magnitude bigger then the nominal SCLP problem. Second, robust counterpart of SCLP is a degenerate optimization problem, that is not suitable for revised SCLP-simplex algorithm. In this paper we develop theoretical results and a corresponding algorithm that allows to preserve dimensions of nominal SCLP problem and avoid degeneracy issues during solution of its robust counterpart.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00901v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evgeny Shindin, Roi Ben Gigi, Odellia Boni</dc:creator>
    </item>
    <item>
      <title>Optimal transport and regularity of weak Kantorovich potentials on a globally hyperbolic spacetime</title>
      <link>https://arxiv.org/abs/2412.01012</link>
      <description>arXiv:2412.01012v1 Announce Type: new 
Abstract: We consider the optimal transportation problem on a globally hyperbolic spacetime for some Lorentzian cost function, which corresponds to the optimal transportation problem on a complete Riemannian manifold where the cost function is the Riemannian distance squared. We establish existence and uniqueness results for the optimal transport map and we investigate the regularity of weak Kantorovich potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01012v1</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.DG</category>
      <category>math.MP</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alec Metsch</dc:creator>
    </item>
    <item>
      <title>An Efficient Unsupervised Framework for Convex Quadratic Programs via Deep Unrolling</title>
      <link>https://arxiv.org/abs/2412.01051</link>
      <description>arXiv:2412.01051v1 Announce Type: new 
Abstract: Quadratic programs (QPs) arise in various domains such as machine learning, finance, and control. Recently, learning-enhanced primal-dual hybrid gradient (PDHG) methods have shown great potential in addressing large-scale linear programs; however, this approach has not been extended to QPs. In this work, we focus on unrolling "PDQP", a PDHG algorithm specialized for convex QPs. Specifically, we propose a neural network model called "PDQP-net" to learn optimal QP solutions. Theoretically, we demonstrate that a PDQP-net of polynomial size can align with the PDQP algorithm, returning optimal primal-dual solution pairs. We propose an unsupervised method that incorporates KKT conditions into the loss function. Unlike the standard learning-to-optimize framework that requires optimization solutions generated by solvers, our unsupervised method adjusts the network weights directly from the evaluation of the primal-dual gap. This method has two benefits over supervised learning: first, it helps generate better primal-dual gap since the primal-dual gap is in the objective function; second, it does not require solvers. We show that PDQP-net trained in this unsupervised manner can effectively approximate optimal QP solutions. Extensive numerical experiments confirm our findings, indicating that using PDQP-net predictions to warm-start PDQP can achieve up to 45% acceleration on QP instances. Moreover, it achieves 14% to 31% acceleration on out-of-distribution instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01051v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linxin Yang, Bingheng Li, Tian Ding, Jianghua Wu, Akang Wang, Yuyi Wang, Jiliang Tang, Ruoyu Sun, Xiaodong Luo</dc:creator>
    </item>
    <item>
      <title>Dynamical System Approach for Optimal Control Problems with Equilibrium Constraints Using Gap-Constraint-Based Reformulation</title>
      <link>https://arxiv.org/abs/2412.01326</link>
      <description>arXiv:2412.01326v1 Announce Type: new 
Abstract: Optimal control problems for nonsmooth dynamical systems governed by differential variational inequalities (DVI) are called optimal control problems with equilibrium constraints (OCPEC). It provides a general formalism for nonsmooth optimal control. However, solving OCPEC using the direct method (i.e., first-discretize-then-optimize) is challenging owing to the lack of correct sensitivity and constraint regularity. This study uses the direct method to solve OCPEC and overcomes the numerical difficulties from two aspects: In the discretization step, we propose a class of novel approaches using gap functions to smooth the DVI, where gap functions are initially proposed for solving variational inequalities. The generated smoothing approximations of discretized OCPEC are called gap-constraint-based reformulations, which have a concise and semismoothly differentiable constraint system; In the optimization step, we propose an efficient dynamical system approach to solve the discretized OCPEC, where a sequence of gap-constraint-based reformulations is solved approximately. This dynamical system approach involves a semismooth Newton flow and achieves local exponential convergence under standard assumptions. The benchmark test shows that the proposed method is computationally tractable and achieves fast local convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01326v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kangyu Lin, Toshiyuki Ohtsuka</dc:creator>
    </item>
    <item>
      <title>The existence and controllability of nonautonomous system influenced by impulses on both state and control</title>
      <link>https://arxiv.org/abs/2412.01355</link>
      <description>arXiv:2412.01355v1 Announce Type: new 
Abstract: This paper examines impulsive controls related to nonautonomous impulsive integro-differential equations in Hilbert space, highlighting their significance. We establish the existence of the mild solution by using fixed point approach and present conditions for approximate controllability using impulsive resolvent operators and the adjoint problem, supported by an illustrative example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01355v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Garima Gupta, Jaydev Dabas</dc:creator>
    </item>
    <item>
      <title>A Bottom-Up Approach to Optimizing the Solar Organic Rankine Cycle for Transactive Energy Trading</title>
      <link>https://arxiv.org/abs/2412.01359</link>
      <description>arXiv:2412.01359v1 Announce Type: new 
Abstract: Solar Organic Rankine Cycle (ORC)-based power generation plants leverage solar irradiation to produce thermal energy, offering a highly compatible renewable technology due to the alignment between solar irradiation temperatures and ORC operating requirements. Their superior performance compared to steam Rankine cycles in small-scale applications makes them particularly relevant within the smart grid and microgrid contexts. This study explores the role of ORC in peer-to-peer (P2P) energy trading within renewable-based community microgrids, where consumers become prosumers, simultaneously producing and consuming energy while engaging in virtual trading at the distribution system level. Focusing on a microgrid integrating solar ORC with a storage system to meet consumer demand, the paper highlights the importance of combining these technologies with storage to enhance predictability and competitiveness with conventional energy plants, despite management challenges. A methodology based on operations research techniques is developed to optimize system performance. Furthermore, the impact of various technological parameters of the solar ORC on the system's performance is examined. The study concludes by assessing the value of solar ORC within the transactive energy trading framework across different configurations and scenarios. Results demonstrate an average 16\% reduction in operational costs, showcasing the benefits of implementing a predictable and manageable system in P2P transactive energy trading.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01359v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Silvia Anna Cordieri, Chiara Bordin, Sambeet Mishra</dc:creator>
    </item>
    <item>
      <title>Existence And Approximate Controllability for a class of Fractional Order Hemivariational Inequalities</title>
      <link>https://arxiv.org/abs/2412.01387</link>
      <description>arXiv:2412.01387v1 Announce Type: new 
Abstract: This paper discusses the approximate controllability of a fractional differential control problem driven by a nonlinear hemivariational inequality in a Hilbert space. First, we prove the existence of a mild solution for a fractional control inclusion problem which is equivalent to a hemivariational inequality by using the nonsmooth analysis and fixed point technique. Further, we established sufficient conditions for the approximate controllability of our inclusion problem by taking corresponding linear system is approximately controllable. The existence and controllability results obtained for the inclusion problem are valid for considered nonlinear hemivariational problem. Finally, we provide an example to illustrate the efficiency of the developed results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01387v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Garima Gupta, Jaydev Dabas</dc:creator>
    </item>
    <item>
      <title>An algorithm for minimum cardinality generators of cones</title>
      <link>https://arxiv.org/abs/2412.01451</link>
      <description>arXiv:2412.01451v1 Announce Type: new 
Abstract: This paper presents a novel proof that for any convex cone, the size of conically independent generators is at most twice that of minimum cardinality generators. While this result is known for linear spaces, we extend it to general cones through a decomposition into linear and pointed components. Our constructive approach leads to a polynomial-time algorithm for computing minimum cardinality generators of finitely generated cones, improving upon existing methods that only compute conically independent generators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01451v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthias Georg Mayer, Fabian von der Warth</dc:creator>
    </item>
    <item>
      <title>Differential estimates for fast first-order multilevel nonconvex optimisation</title>
      <link>https://arxiv.org/abs/2412.01481</link>
      <description>arXiv:2412.01481v1 Announce Type: new 
Abstract: With a view on bilevel and PDE-constrained optimisation, we develop iterative estimates $\widetilde{F'}(x^k)$ of $F'(x^k)$ for compositions $F :=J \circ S$, where $S$ is the solution mapping of the inner optimisation problem or PDE. The idea is to form a single-loop method by interweaving updates of the iterate $x^k$ by an outer optimisation method, with updates of the estimate by single steps of standard optimisation methods and linear system solvers. When the inner methods satisfy simple tracking inequalities, the differential estimates can almost directly be employed in standard convergence proofs for general forward-backward type methods. We adapt those proofs to a general inexact setting in normed spaces, that, besides our differential estimates, also covers mismatched adjoints and unreachable optimality conditions in measure spaces. As a side product of these efforts, we provide improved convergence results for nonconvex Primal-Dual Proximal Splitting (PDPS).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01481v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neil Dizon, Tuomo Valkonen</dc:creator>
    </item>
    <item>
      <title>Total variations reduction for an exact control applied to a dynamical mechanical system</title>
      <link>https://arxiv.org/abs/2412.01533</link>
      <description>arXiv:2412.01533v1 Announce Type: new 
Abstract: In an optimal control strategy, an important point is to define the cost of the control. Usually it is added to the control criterion and multiplied by a small coefficient denoted by $\varepsilon$ which is known as the marginal cost of the control. The key idea of this paper, is to introduce a smoothing term in the control cost which aims at reducing the quantity of energy spent and reducing the oscillations of the control. Then using a so-called asymptotic control based on the smallness of $\varepsilon$, we construct an exact control which can be implemented in a close loop. The energy involved in the control depends mainly on the variation of the control. Therefore it seems natural to include this quantity (the total variations) in the criterion involved in the optimal control. This can be done approximately by introducing the $L^1$ norm of the first order derivative of the control. The control strategy that we develop in this paper can be applied to such linear models. One important and new point is that we focus on exact control strategies for a non-differentiable criterion because of the cost of the control. Following the ideas of Tykhonov regularization method, it is proved using the so-called asymptotic method based on the smallness of the marginal cost of the control, that the exact control suggested is the one which represents the minimum of the marginal cost among exact controls. Furthermore, and it is the main technical point, it can reduce the variations of the control with an adequate tuning of the various parameters of the control loop. We test the method on three examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01533v1</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philippe Destuynder, Erwan Liberge</dc:creator>
    </item>
    <item>
      <title>A homotopy theorem for incremental stability</title>
      <link>https://arxiv.org/abs/2412.01580</link>
      <description>arXiv:2412.01580v1 Announce Type: new 
Abstract: A theorem is proved to verify incremental stability of a feedback system via a homotopy from a known incrementally stable system. A first corollary of that result is that incremental stability may be verified by separation of Scaled Relative Graphs, correcting two assumptions in [1, Theorem 2]. A second corollary provides an incremental version of the classical IQC stability theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01580v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thomas Chaffey, Andrey Kharitenko, Fulvio Forni, Rodolphe Sepulchre</dc:creator>
    </item>
    <item>
      <title>Kernel-Based Optimal Control: An Infinitesimal Generator Approach</title>
      <link>https://arxiv.org/abs/2412.01591</link>
      <description>arXiv:2412.01591v1 Announce Type: new 
Abstract: This paper presents a novel approach for optimal control of nonlinear stochastic systems using infinitesimal generator learning within infinite-dimensional reproducing kernel Hilbert spaces. Our learning framework leverages data samples of system dynamics and stage cost functions, with only control penalties and constraints provided. The proposed method directly learns the diffusion operator of a controlled Fokker-Planck-Kolmogorov equation in an infinite-dimensional hypothesis space. This operator models the continuous-time evolution of the probability measure of the control system's state. We demonstrate that this approach seamlessly integrates with modern convex operator-theoretic Hamilton-Jacobi-Bellman recursions, enabling a data-driven solution to the optimal control problem. Furthermore, our statistical learning framework includes nonparametric estimators for uncontrolled forward infinitesimal generators as a special case. Numerical experiments, ranging from synthetic differential equations to simulated robotic systems, showcase the advantages of our approach compared to both modern data-driven and classical nonlinear programming methods for optimal control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01591v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Petar Bevanda, Nicolas Hosichen, Tobias Wittmann, Jan Br\"udigam, Sandra Hirche, Boris Houska</dc:creator>
    </item>
    <item>
      <title>Average-Cost MDPs with Infinite State and Action Sets: New Sufficient Conditions for Optimality Inequalities and Equations</title>
      <link>https://arxiv.org/abs/2412.01594</link>
      <description>arXiv:2412.01594v1 Announce Type: new 
Abstract: This paper studies discrete-time average-cost infinite-horizon Markov decision processes (MDPs) with Borel state and action sets. It introduces new sufficient conditions for validity of optimality inequalities and optimality equations for MDPs with weakly and setwise continuous transition probabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01594v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eugene A. Feinberg, Pavlo O. Kasyanov, Liliia S. Paliichuk</dc:creator>
    </item>
    <item>
      <title>A Booby Trap Game</title>
      <link>https://arxiv.org/abs/2412.01688</link>
      <description>arXiv:2412.01688v1 Announce Type: new 
Abstract: This paper presents a booby trap game played between a defender and an attacker on a search space, which may be a compact subset of Euclidean space or a network. The defender has several booby traps and chooses where to plant them. The attacker, aware of the presence of these booby traps but not their locations, chooses a subset of the space and collects a reward equal to the measure of the subset. If the attacker does not encounter any booby traps, then the attacker keeps the reward; otherwise, the attacker gets nothing. The attacker's objective is to maximize the expected reward, while the defender's objective is to minimize it. We solve this game in the case that the search space is a compact subset of Euclidean space, and then turn our attention to the case where the search space is a network in which the attacker must choose a connected subset of the network. We solve the game when the network is a circle or a line. For the case of one booby trap, we solve the game for 2-connected networks, and when the network is a tree we present an upper bound and a lower bound for the value of the game whose ratio is at most 27/25. We also present an optimal solution for each player in a few cases where the tree is a star network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01688v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Lidbetter, Kyle Lin</dc:creator>
    </item>
    <item>
      <title>A slot-based energy storage decision-making approach for optimal Off-Grid telecommunication operator</title>
      <link>https://arxiv.org/abs/2412.01731</link>
      <description>arXiv:2412.01731v1 Announce Type: new 
Abstract: This paper proposes a slot-based energy storage approach for decision-making in the context of an Off-Grid telecommunication operator. We consider network systems powered by solar panels, where harvest energy is stored in a battery that can also be sold when fully charged. To reflect real-world conditions, we account for non-stationary energy arrivals and service demands that depend on the time of day, as well as the failure states of PV panel. The network operator we model faces two conflicting objectives: maintaining the operation of its infrastructure and selling (or supplying to other networks) surplus energy from fully charged batteries. To address these challenges, we developed a slot-based Markov Decision Process (MDP) model that incorporates positive rewards for energy sales, as well as penalties for energy loss and battery depletion. This slot-based MDP follows a specific structure we have previously proven to be efficient in terms of computational performance and accuracy. From this model, we derive the optimal policy that balances these conflicting objectives and maximizes the average reward function. Additionally, we present results comparing different cities and months, which the operator can consider when deploying its infrastructure to maximize rewards based on location-specific energy availability and seasonal variations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01731v1</guid>
      <category>math.OC</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Youssef Ait El Mahjoub, Jean-Michel Fourneau</dc:creator>
    </item>
    <item>
      <title>The Data-Driven Censored Newsvendor Problem</title>
      <link>https://arxiv.org/abs/2412.01763</link>
      <description>arXiv:2412.01763v1 Announce Type: new 
Abstract: We study a censored variant of the data-driven newsvendor problem, where the decision-maker must select an ordering quantity that minimizes expected overage and underage costs based only on censored sales data, rather than historical demand realizations. To isolate the impact of demand censoring on this problem, we adopt a distributionally robust optimization framework, evaluating policies according to their worst-case regret over an ambiguity set of distributions. This set is defined by the largest historical order quantity (the observable boundary of the dataset), and contains all distributions matching the true demand distribution up to this boundary, while allowing them to be arbitrary afterwards. We demonstrate a spectrum of achievability under demand censoring by deriving a natural necessary and sufficient condition under which vanishing regret is an achievable goal. In regimes in which it is not, we exactly characterize the information loss due to censoring: an insurmountable lower bound on the performance of any policy, even when the decision-maker has access to infinitely many demand samples. We then leverage these sharp characterizations to propose a natural robust algorithm that adapts to the historical level of demand censoring. We derive finite-sample guarantees for this algorithm across all possible censoring regimes, and show its near-optimality with matching lower bounds (up to polylogarithmic factors). We moreover demonstrate its robust performance via extensive numerical experiments on both synthetic and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01763v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chamsi Hssaine, Sean R. Sinclair</dc:creator>
    </item>
    <item>
      <title>Automatic discovery of optimal meta-solvers via multi-objective optimization</title>
      <link>https://arxiv.org/abs/2412.00063</link>
      <description>arXiv:2412.00063v1 Announce Type: cross 
Abstract: We design two classes of ultra-fast meta-solvers for linear systems arising after discretizing PDEs by combining neural operators with either simple iterative solvers, e.g., Jacobi and Gauss-Seidel, or with Krylov methods, e.g., GMRES and BiCGStab, using the trunk basis of DeepONet as a coarse preconditioner. The idea is to leverage the spectral bias of neural networks to account for the lower part of the spectrum in the error distribution while the upper part is handled easily and inexpensively using relaxation methods or fine-scale preconditioners. We create a pareto front of optimal meta-solvers using a plurarilty of metrics, and we introduce a preference function to select the best solver most suitable for a specific scenario. This automation for finding optimal solvers can be extended to nonlinear systems and other setups, e.g. finding the best meta-solver for space-time in time-dependent PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00063v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youngkyu Lee, Shanqing Liu, Jerome Darbon, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>Dissipative iFIR filters for data-driven design</title>
      <link>https://arxiv.org/abs/2412.00211</link>
      <description>arXiv:2412.00211v1 Announce Type: cross 
Abstract: We tackle the problem of providing closed-loop stability guarantees with a scalable data-driven design. We combine virtual reference feedback tuning with dissipativity constraints on the controller for closed-loop stability. The constraints are formulated as a set of linear inequalities in the frequency domain. This leads to a convex problem that is scalable with respect to the length of the data and the complexity of the controller. An extension of virtual reference feedback tuning to include disturbance dynamics is also discussed. The proposed data-driven control design is illustrated by a soft gripper impedance control example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00211v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixing Wang Yi Zhang, Fulvio Forni</dc:creator>
    </item>
    <item>
      <title>Personal Sound Zones and Shielded Localized Communication through Active Acoustic Control</title>
      <link>https://arxiv.org/abs/2412.00456</link>
      <description>arXiv:2412.00456v1 Announce Type: cross 
Abstract: In this paper, we present a time domain extension of our strategy on manipulating radiated scalar Helmholtz fields and discuss two important applied scenarios, namely (1) creating personal sound zones inside a bounded domain and (2) shielded localized communication. Our strategy is based on the authors' previous works establishing the possibility and stability of controlling acoustic fields using an array of almost non-radiating coupling sources and presents a detailed Fourier synthesis approach towards a time-domain effect. We require that the array of acoustic sources creates the desired fields on the control regions while maintaining a zero field beyond a larger circumscribed sphere. This paper recalls the main theoretical results then presents the underlying Fourier synthesis paradigm and show, through relevant simulations, the performance of our strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00456v1</guid>
      <category>cs.SD</category>
      <category>cs.NA</category>
      <category>eess.AS</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Neil Jerome A. Egarguin, Daniel Onofrei</dc:creator>
    </item>
    <item>
      <title>Stability of long run functionals with respect to stationary Markov controls</title>
      <link>https://arxiv.org/abs/2412.00587</link>
      <description>arXiv:2412.00587v1 Announce Type: cross 
Abstract: In the paper we study dependence of long run functionals and limit characteristics assuming that Borel measurable Markov controls converge pointwise. We consider two kinds of functionals: average cost per unit time and long run risk sensitive. We impose uniform ergodicity assumption, which is later is relaxed and suitable convergence of controlled transition probabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00587v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukasz Stettner</dc:creator>
    </item>
    <item>
      <title>Mean-Field Sampling for Cooperative Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2412.00661</link>
      <description>arXiv:2412.00661v1 Announce Type: cross 
Abstract: Designing efficient algorithms for multi-agent reinforcement learning (MARL) is fundamentally challenging due to the fact that the size of the joint state and action spaces are exponentially large in the number of agents. These difficulties are exacerbated when balancing sequential global decision-making with local agent interactions. In this work, we propose a new algorithm \texttt{SUBSAMPLE-MFQ} (\textbf{Subsample}-\textbf{M}ean-\textbf{F}ield-\textbf{Q}-learning) and a decentralized randomized policy for a system with $n$ agents. For $k\leq n$, our algorithm system learns a policy for the system in time polynomial in $k$. We show that this learned policy converges to the optimal policy in the order of $\tilde{O}(1/\sqrt{k})$ as the number of subsampled agents $k$ increases. We validate our method empirically on Gaussian squeeze and global exploration settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00661v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emile Anand, Ishani Karmarkar, Guannan Qu</dc:creator>
    </item>
    <item>
      <title>Bringing Quantum Systems under Control: A Tutorial Invitation to Quantum Computing and Its Relation to Bilinear Control Systems</title>
      <link>https://arxiv.org/abs/2412.00736</link>
      <description>arXiv:2412.00736v1 Announce Type: cross 
Abstract: Quantum computing comes with the potential to push computational boundaries in various domains including, e.g., cryptography, simulation, optimization, and machine learning. Exploiting the principles of quantum mechanics, new algorithms can be developed with capabilities that are unprecedented by classical computers. However, the experimental realization of quantum devices is an active field of research with enormous open challenges, including robustness against noise and scalability. While systems and control theory plays a crucial role in tackling these challenges, the principles of quantum physics lead to a (perceived) high entry barrier for entering the field of quantum computing. This tutorial paper aims at lowering the barrier by introducing basic concepts required to understand and solve research problems in quantum systems. First, we introduce fundamentals of quantum algorithms, ranging from basic ingredients such as qubits and quantum logic gates to prominent examples and more advanced concepts, e.g., variational quantum algorithms. Next, we formalize some engineering questions for building quantum devices in the real world, which requires the careful manipulation of microscopic quantities obeying quantum effects. To this end for N-level systems, we introduce basic concepts of (bilinear) quantum systems and control theory including controllability, observability, and optimal control in a unified frame. Finally, we address the problem of noise in real-world quantum systems via robust quantum control, which relies on a set-membership uncertainty description frequently employed in control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00736v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julian Berberich, Robert L. Kosut, Thomas Schulte-Herbr\"uggen</dc:creator>
    </item>
    <item>
      <title>Explicit and data-Efficient Encoding via Gradient Flow</title>
      <link>https://arxiv.org/abs/2412.00864</link>
      <description>arXiv:2412.00864v1 Announce Type: cross 
Abstract: The autoencoder model typically uses an encoder to map data to a lower dimensional latent space and a decoder to reconstruct it. However, relying on an encoder for inversion can lead to suboptimal representations, particularly limiting in physical sciences where precision is key. We introduce a decoder-only method using gradient flow to directly encode data into the latent space, defined by ordinary differential equations (ODEs). This approach eliminates the need for approximate encoder inversion. We train the decoder via the adjoint method and show that costly integrals can be avoided with minimal accuracy loss. Additionally, we propose a $2^{nd}$ order ODE variant, approximating Nesterov's accelerated gradient descent for faster convergence. To handle stiff ODEs, we use an adaptive solver that prioritizes loss minimization, improving robustness. Compared to traditional autoencoders, our method demonstrates explicit encoding and superior data efficiency, which is crucial for data-scarce scenarios in the physical sciences. Furthermore, this work paves the way for integrating machine learning into scientific workflows, where precise and efficient encoding is critical. \footnote{The code for this work is available at \url{https://github.com/k-flouris/gfe}.}</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00864v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kyriakos Flouris, Anna Volokitin, Gustav Bredell, Ender Konukoglu</dc:creator>
    </item>
    <item>
      <title>Online convex optimization for constrained control of nonlinear systems</title>
      <link>https://arxiv.org/abs/2412.00922</link>
      <description>arXiv:2412.00922v1 Announce Type: cross 
Abstract: This paper investigates the problem of controlling nonlinear dynamical systems subject to state and input constraints while minimizing time-varying and a priori unknown cost functions. We propose a modular approach that combines the online convex optimization framework and reference governors to solve this problem. Our method is general in the sense that we do not limit our analysis to a specific choice of online convex optimization algorithm or reference governor. We show that the dynamic regret of the proposed framework is bounded linearly in both the dynamic regret and the path length of the chosen online convex optimization algorithm, even though the online convex optimization algorithm does not account for the underlying dynamics. We prove that a linear bound with respect to the online convex optimization algorithm's dynamic regret is optimal, i.e., cannot be improved upon. Furthermore, for a standard class of online convex optimization algorithms, our proposed framework attains a bound on its dynamic regret that is linear only in the variation of the cost functions, which is known to be an optimal bound. Finally, we demonstrate implementation and flexibility of the proposed framework by comparing different combinations of online convex optimization algorithms and reference governors to control a nonlinear chemical reactor in a numerical experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00922v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marko Nonhoff, Johannes K\"ohler, Matthias A. M\"uller</dc:creator>
    </item>
    <item>
      <title>A model of strategic sustainable investment</title>
      <link>https://arxiv.org/abs/2412.00986</link>
      <description>arXiv:2412.00986v1 Announce Type: cross 
Abstract: We study a problem of optimal irreversible investment and emission reduction formulated as a nonzero-sum dynamic game between an investor with environmental preferences and a firm. The game is set in continuous time on an infinite-time horizon. The firm generates profits with a stochastic dynamics and may spend part of its revenues towards emission reduction (e.g., renovating the infrastructure). The firm's objective is to maximize the discounted expectation of a function of its profits. The investor participates in the profits and may decide to invest to support the firm's production capacity. The investor uses a profit function which accounts for both financial and environmental factors. Nash equilibria of the game are obtained via a system of variational inequalities. We formulate a general verification theorem for this system in a diffusive setup and construct an explicit solution in the zero-noise limit. Our explicit results and numerical approximations show that both the investor's and the firm's optimal actions are triggered by moving boundaries that increase with the total amount of emission abatement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00986v1</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tiziano De Angelis, Caio C\'esar Graciani Rodrigues, Peter Tankov</dc:creator>
    </item>
    <item>
      <title>A Hybrid Evolutionary Approach for Multi Robot Coordinated Planning at Intersections</title>
      <link>https://arxiv.org/abs/2412.01082</link>
      <description>arXiv:2412.01082v1 Announce Type: cross 
Abstract: Coordinated multi-robot motion planning at intersections is key for safe mobility in roads, factories and warehouses. The rapidly exploring random tree (RRT) algorithms are popular in multi-robot motion planning. However, generating the graph configuration space and searching in the composite tensor configuration space is computationally expensive for large number of sample points. In this paper, we propose a new evolutionary-based algorithm using a parametric lattice-based configuration and the discrete-based RRT for collision-free multi-robot planning at intersections. Our computational experiments using complex planning intersection scenarios have shown the feasibility and the superiority of the proposed algorithm compared to seven other related approaches. Our results offer new sampling and representation mechanisms to render optimization-based approaches for multi-robot navigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01082v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Victor Parque</dc:creator>
    </item>
    <item>
      <title>A Hierarchical Heuristic for Clustered Steiner Trees in the Plane with Obstacles</title>
      <link>https://arxiv.org/abs/2412.01094</link>
      <description>arXiv:2412.01094v1 Announce Type: cross 
Abstract: Euclidean Steiner trees are relevant to model minimal networks in real-world applications ubiquitously. In this paper, we study the feasibility of a hierarchical approach embedded with bundling operations to compute multiple and mutually disjoint Euclidean Steiner trees that avoid clutter and overlapping with obstacles in the plane, which is significant to model the decentralized and the multipoint coordination of agents in constrained 2D domains. Our computational experiments using arbitrary obstacle configuration with convex and non-convex geometries show the feasibility and the attractive performance when computing multiple obstacle-avoiding Steiner trees in the plane. Our results offer the mechanisms to elucidate new operators for obstacle-avoiding Steiner trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01094v1</guid>
      <category>cs.AI</category>
      <category>cs.CG</category>
      <category>cs.NE</category>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Victor Parque</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Power Policies for Wireless Systems under Power Fluctuation Risk</title>
      <link>https://arxiv.org/abs/2412.01187</link>
      <description>arXiv:2412.01187v1 Announce Type: cross 
Abstract: Modern wireless communication systems necessitate the development of cost-effective resource allocation strategies, while ensuring maximal system performance. While commonly realizable via efficient waterfilling schemes, ergodic-optimal policies often exhibit instantaneous resource constraint fluctuations as a result of fading variability, violating prescribed specifications possibly within unacceptable margins, inducing further operational challenges and/or costs. On the other extent, short-term-optimal policies -- commonly based on deterministic waterfilling-- while strictly maintaining operational specifications, are not only impractical and computationally demanding, but also suboptimal in a long-term sense. To address these challenges, we introduce a novel distributionally robust version of a classical point-to-point interference-free multi-terminal constrained stochastic resource allocation problem, by leveraging the Conditional Value-at-Risk (CVaR) as a coherent measure of power policy fluctuation risk. We derive closed-form dual-parameterized expressions for the CVaR-optimal resource policy, along with corresponding optimal CVaR quantile levels by capitalizing on (sampling) the underlying fading distribution. We subsequently develop two dual-domain schemes -- one model-based and one model-free -- to iteratively determine a globally-optimal resource policy. Our numerical simulations confirm the remarkable effectiveness of the proposed approach, also revealing an almost-constant character of the CVaR-optimal policy and at rather minimal ergodic rate optimality loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01187v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gokberk Yaylali, Dionysios S. Kalogerias</dc:creator>
    </item>
    <item>
      <title>Towards Robust Interpretable Surrogates for Optimization</title>
      <link>https://arxiv.org/abs/2412.01264</link>
      <description>arXiv:2412.01264v1 Announce Type: cross 
Abstract: An important factor in the practical implementation of optimization models is the acceptance by the intended users. This is influenced among other factors by the interpretability of the solution process. Decision rules that meet this requirement can be generated using the framework for inherently interpretable optimization models. In practice, there is often uncertainty about the parameters of an optimization problem. An established way to deal with this challenge is the concept of robust optimization. The goal of our work is to combine both concepts: to create decision trees as surrogates for the optimization process that are more robust to perturbations and still inherently interpretable. For this purpose we present suitable models based on different variants to model uncertainty, and solution methods. Furthermore, the applicability of heuristic methods to perform this task is evaluated. Both approaches are compared with the existing framework for inherently interpretable optimization models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01264v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Goerigk, Michael Hartisch, Sebastian Merten</dc:creator>
    </item>
    <item>
      <title>A multi-criteria decision support system to evaluate the effectiveness of training courses on citizens' employability</title>
      <link>https://arxiv.org/abs/2412.01351</link>
      <description>arXiv:2412.01351v1 Announce Type: cross 
Abstract: This study examines the impact of lifelong learning on the professional lives of employed and unemployed individuals. Lifelong learning is a crucial factor in securing employment or enhancing one's existing career prospects. To achieve this objective, this study proposes the implementation of a multi-criteria decision support system for the evaluation of training courses in accordance with their capacity to enhance the employability of the students. The methodology is delineated in four stages. Firstly, a `working life curve' was defined to provide a quantitative description of an individual's working life. Secondly, an analysis based on K-medoids clustering defined a control group for each individual for comparison. Thirdly, the performance of a course according to each of the four predefined criteria was calculated using a t-test to determine the mean performance value of those who took the course. Ultimately, the unweighted TOPSIS method was used to evaluate the efficacy of the various training courses in relation to the four criteria. This approach effectively addresses the challenge of using extensive datasets within a system while facilitating the application of a multi-criteria unweighted TOPSIS method. The results of the multi-criteria TOPSIS method indicated that training courses related to the professional fields of administration and management, hostel and tourism and community and sociocultural services have positive impact on employability and improving the working conditions of citizens. However, courses that demonstrate the greatest effectiveness in ranking are the least demanded by citizens. The results will help policymakers evaluate the effectiveness of each training course offered by the regional government.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01351v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10489-024-05967-0</arxiv:DOI>
      <arxiv:journal_reference>Applied Intelligence, 55 (2025), 57</arxiv:journal_reference>
      <dc:creator>Maria C. Bas, Vicente J. Bolos, Alvaro E. Prieto, Roberto Rodriguez-Echeverria, Fernando Sanchez-Figueroa</dc:creator>
    </item>
    <item>
      <title>Refined Analysis of Federated Averaging's Bias and Federated Richardson-Romberg Extrapolation</title>
      <link>https://arxiv.org/abs/2412.01389</link>
      <description>arXiv:2412.01389v1 Announce Type: cross 
Abstract: In this paper, we present a novel analysis of FedAvg with constant step size, relying on the Markov property of the underlying process. We demonstrate that the global iterates of the algorithm converge to a stationary distribution and analyze its resulting bias and variance relative to the problem's solution. We provide a first-order expansion of the bias in both homogeneous and heterogeneous settings. Interestingly, this bias decomposes into two distinct components: one that depends solely on stochastic gradient noise and another on client heterogeneity. Finally, we introduce a new algorithm based on the Richardson-Romberg extrapolation technique to mitigate this bias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01389v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Mangold, Alain Durmus, Aymeric Dieuleveut, Sergey Samsonov, Eric Moulines</dc:creator>
    </item>
    <item>
      <title>On the Computational Complexity of Multi-Objective Ordinal Unconstrained Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2412.01465</link>
      <description>arXiv:2412.01465v1 Announce Type: cross 
Abstract: Multi-objective unconstrained combinatorial optimization problems (MUCO) are in general hard to solve, i.e., the corresponding decision problem is NP-hard and the outcome set is intractable. In this paper we explore special cases of MUCO problems that are actually easy, i.e., solvable in polynomial time. More precisely, we show that MUCO problems with up to two ordinal objective functions plus one real-valued objective function are tractable, and that their complete nondominated set can be computed in polynomial time. For MUCO problems with one ordinal and a second ordinal or real-valued objective function we present an even more efficient algorithm that applies a greedy strategy multiple times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01465v1</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jos\'e Rui Figueira, Kathrin Klamroth, Michael Stiglmayr, Julia Sudhoff Santos</dc:creator>
    </item>
    <item>
      <title>Differential Flatness-based Fast Trajectory Planning for Fixed-wing Unmanned Aerial Vehicles</title>
      <link>https://arxiv.org/abs/2412.01468</link>
      <description>arXiv:2412.01468v1 Announce Type: cross 
Abstract: Due to the strong nonlinearity and nonholonomic dynamics, despite that various general trajectory optimization methods have been presented, few of them can guarantee efficient compu-tation and physical feasibility for relatively complicated fixed-wing UAV dynamics. Aiming at this issue, this paper investigates a differential flatness-based trajectory optimization method for fixed-wing UAVs (DFTO-FW), which transcribes the trajectory optimization into a lightweight, unconstrained, gradient-analytical optimization with linear time complexity in each itera-tion to achieve fast trajectory generation. Through differential flat characteristics analysis and polynomial parameterization, the customized trajectory representation is presented, which implies the equality constraints to avoid the heavy computational burdens of solving complex dynamics. Through the design of integral performance costs and deduction of analytical gradients, the original trajectory optimization is transcribed into an uncon-strained, gradient-analytical optimization with linear time com-plexity to further improve efficiency. The simulation experi-ments illustrate the superior efficiency of the DFTO-FW, which takes sub-second CPU time against other competitors by orders of magnitude to generate fixed-wing UAV trajectories in ran-domly generated obstacle environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01468v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junzhi Li, Jingliang Sun, Teng Long, Zhenlin Zhou</dc:creator>
    </item>
    <item>
      <title>Opinion Dynamic Under Malicious Agent Influence in Multi-Agent Systems: From the Perspective of Opinion Evolution Cost</title>
      <link>https://arxiv.org/abs/2412.01524</link>
      <description>arXiv:2412.01524v1 Announce Type: cross 
Abstract: In human social systems, debates are often seen as a means to resolve differences of opinion. However, in reality, debates frequently incur significant communication costs, especially when dealing with stubborn opponents. Inspired by this phenomenon, this paper examines the impact of malicious agents on the evolution of normal agents' opinions from the perspective of opinion evolution cost, and proposes corresponding solutions for the scenario in which malicious agents hold different opinions in multi-agent systems(MASs). First, the paper analyzes the negative impact of malicious agents on the opinion evolution process, revealing the evolutionary cost they bring, which provides the theoretical foundation for the proposed solution. Next, based on the process of opinion evolution, a strategy is introduced where agents dynamically adjust trust values during the opinion evolution process, gradually isolating malicious agents and achieving this even when malicious agents are in the majority. Additionally, an evolution rate adjustment mechanism is introduced, allowing the system to flexibly regulate the evolution process in complex situations, effectively achieving the trade-off between opinion evolution rate and cost. Extensive numerical simulations demonstrate that the algorithm can effectively isolate the negative influence of malicious agents and achieve a balance between opinion evolution costs and convergence speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01524v1</guid>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhan Suo, Runqi Chai, Senchun Chai, Ishrak MD Farhan, Xudong Zhao, Yuanqing Xia</dc:creator>
    </item>
    <item>
      <title>Multi-objective Deep Learning: Taxonomy and Survey of the State of the Art</title>
      <link>https://arxiv.org/abs/2412.01566</link>
      <description>arXiv:2412.01566v1 Announce Type: cross 
Abstract: Simultaneously considering multiple objectives in machine learning has been a popular approach for several decades, with various benefits for multi-task learning, the consideration of secondary goals such as sparsity, or multicriteria hyperparameter tuning. However - as multi-objective optimization is significantly more costly than single-objective optimization - the recent focus on deep learning architectures poses considerable additional challenges due to the very large number of parameters, strong nonlinearities and stochasticity. This survey covers recent advancements in the area of multi-objective deep learning. We introduce a taxonomy of existing methods - based on the type of training algorithm as well as the decision maker's needs - before listing recent advancements, and also successful applications. All three main learning paradigms supervised learning, reinforcement learning and unsupervised learning are covered, and we also address the recently very popular area of generative modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01566v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Peitz, Sedjro Salomon Hotegni</dc:creator>
    </item>
    <item>
      <title>Amplitude response and square wave describing functions</title>
      <link>https://arxiv.org/abs/2412.01579</link>
      <description>arXiv:2412.01579v1 Announce Type: cross 
Abstract: An analogue of the describing function method is developed using square waves rather than sinusoids. Static nonlinearities map square waves to square waves, and their behavior is characterized by their response to square waves of varying amplitude - their amplitude response. The output of an LTI system to a square wave input is approximated by a square wave, to give an analogue of the describing function. The classical describing function method for predicting oscillations in feedback interconnections is generalized to this square wave setting, and gives accurate predictions when oscillations are approximately square.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01579v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thomas Chaffey, Fulvio Forni</dc:creator>
    </item>
    <item>
      <title>FairML: A Julia Package for Fair Classification</title>
      <link>https://arxiv.org/abs/2412.01585</link>
      <description>arXiv:2412.01585v1 Announce Type: cross 
Abstract: In this paper, we propose FairML.jl, a Julia package providing a framework for fair classification in machine learning. In this framework, the fair learning process is divided into three stages. Each stage aims to reduce unfairness, such as disparate impact and disparate mistreatment, in the final prediction. For the preprocessing stage, we present a resampling method that addresses unfairness coming from data imbalances. The in-processing phase consist of a classification method. This can be either one coming from the MLJ.jl package, or a user defined one. For this phase, we incorporate fair ML methods that can handle unfairness to a certain degree through their optimization process. In the post-processing, we discuss the choice of the cut-off value for fair prediction. With simulations, we show the performance of the single phases and their combinations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01585v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Pablo Burgard, Jo\~ao Vitor Pamplona</dc:creator>
    </item>
    <item>
      <title>Representation and Regression Problems in Neural Networks: Relaxation, Generalization, and Numerics</title>
      <link>https://arxiv.org/abs/2412.01619</link>
      <description>arXiv:2412.01619v1 Announce Type: cross 
Abstract: In this work, we address three non-convex optimization problems associated with the training of shallow neural networks (NNs) for exact and approximate representation, as well as for regression tasks. Through a mean-field approach, we convexify these problems and, applying a representer theorem, prove the absence of relaxation gaps. We establish generalization bounds for the resulting NN solutions, assessing their predictive performance on test datasets and, analyzing the impact of key hyperparameters on these bounds, propose optimal choices.
  On the computational side, we examine the discretization of the convexified problems and derive convergence rates. For low-dimensional datasets, these discretized problems are efficiently solvable using the simplex method. For high-dimensional datasets, we propose a sparsification algorithm that, combined with gradient descent for over-parameterized shallow NNs, yields effective solutions to the primal problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01619v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kang Liu, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>Stochastic subgradient for composite optimization with functional constraints</title>
      <link>https://arxiv.org/abs/2204.08204</link>
      <description>arXiv:2204.08204v3 Announce Type: replace 
Abstract: In this paper we consider convex optimization problems with stochastic composite objective function subject to (possibly) infinite intersection of constraints. The objective function is expressed in terms of expectation operator over a sum of two terms satisfying a stochastic bounded gradient condition, with or without strong convexity type properties. In contrast to the classical approach, where the constraints are usually represented as intersection of simple sets, in this paper we consider that each constraint set is given as the level set of a convex but not necessarily differentiable function. Based on the flexibility offered by our general optimization model we consider a stochastic subgradient method with random feasibility updates. At each iteration, our algorithm takes a stochastic proximal (sub)gradient step aimed at minimizing the objective function and then a subsequent subgradient step minimizing the feasibility violation of the observed random constraint. We analyze the convergence behavior of the proposed algorithm for diminishing stepsizes and for the case when the objective function is convex or strongly convex, unifying the nonsmooth and smooth cases. We prove sublinear convergence rates for this stochastic subgradient algorithm, which are known to be optimal for subgradient methods on this class of problems. When the objective function has a linear least-square form and the constraints are polyhedral, it is shown that the algorithm converges linearly. Numerical evidence supports the effectiveness of our method in real problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.08204v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Journal of Machine Learning Research, 2022</arxiv:journal_reference>
      <dc:creator>Ion Necoara, Nitesh Kumar Singh</dc:creator>
    </item>
    <item>
      <title>A Block Coordinate Descent Method for Nonsmooth Composite Optimization under Orthogonality Constraints</title>
      <link>https://arxiv.org/abs/2304.03641</link>
      <description>arXiv:2304.03641v3 Announce Type: replace 
Abstract: Nonsmooth composite optimization with orthogonality constraints has a wide range of applications in statistical learning and data science. However, this problem is challenging due to its nonsmooth objective and computationally expensive, non-convex constraints. In this paper, we propose a new approach called \textbf{OBCD}, which leverages Block Coordinate Descent to address these challenges. \textbf{OBCD} is a feasible method with a small computational footprint. In each iteration, it updates $k$ rows of the solution matrix, where $k \geq 2$, by globally solving a small nonsmooth optimization problem under orthogonality constraints. We prove that the limiting points of \textbf{OBCD}, referred to as (global) block-$k$ stationary points, offer stronger optimality than standard critical points. Furthermore, we show that \textbf{OBCD} converges to $\epsilon$-block-$k$ stationary points with an ergodic convergence rate of $\mathcal{O}(1/\epsilon)$. Additionally, under the Kurdyka-Lojasiewicz (KL) inequality, we establish the non-ergodic convergence rate of \textbf{OBCD}. We also extend \textbf{OBCD} by incorporating breakpoint searching methods for subproblem solving and greedy strategies for working set selection. Comprehensive experiments demonstrate the superior performance of our approach across various tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.03641v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganzhao Yuan</dc:creator>
    </item>
    <item>
      <title>A minimal face constant rank constraint qualification for reducible conic programming</title>
      <link>https://arxiv.org/abs/2304.13881</link>
      <description>arXiv:2304.13881v2 Announce Type: replace 
Abstract: In a previous paper [R. Andreani, G. Haeser, L. M. Mito, H. Ram\'irez, T. P. Silveira. First- and second-order optimality conditions for second-order cone and semidefinite programming under a constant rank condition. Mathematical Programming, 2023. DOI: 10.1007/s10107-023-01942-8] we introduced a constant rank constraint qualification for nonlinear semidefinite and second-order cone programming by considering all faces of the underlying cone. This condition is independent of Robinson's condition and it implies a strong second-order necessary optimality condition which depends on a single Lagrange multiplier instead of the full set of Lagrange multipliers. In this paper we expand on this result in several directions, namely, we consider the larger class of $\mathcal{C}^2-$cone reducible constraints and we show that it is not necessary to consider all faces of the cone; instead a single specific face should be considered (which turns out to be weaker than Robinson's condition) in order for the first order necessary optimality condition to hold. This gives rise to a notion of facial reduction for nonlinear conic programming, that allows locally redefining the original problem only in terms of this specific face instead of the whole cone, providing a more robust formulation of the problem in which Robinson's condition holds. We were also able to prove the strong second-order necessary optimality condition in this context by considering only the subfaces of this particular face, which is a new result even in nonlinear programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.13881v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Andreani, Gabriel Haeser, Leonardo M. Mito, H\'ector Ram\'irez</dc:creator>
    </item>
    <item>
      <title>Effects of Geopolitical Strain on Global Pharmaceutical Supply Chain Design and Drug Shortages</title>
      <link>https://arxiv.org/abs/2308.07434</link>
      <description>arXiv:2308.07434v3 Announce Type: replace 
Abstract: Emerging geopolitical risks have begun to threaten global supply chains, including those that produce life-saving drugs. Export bans may prevent a company from shipping products internationally, and it is unclear how these new dynamics may affect company plans and persistent, worldwide drug shortages. To address these questions, we present a global pharmaceutical supply chain design model that considers the risk of export bans that are induced by supplier capacity disruptions and corresponding price increases. The model takes the company's perspective as a decision-maker looking to locate plants and distribute drugs globally. It is a two-stage stochastic program that includes uncertainty in capacity, ability-to-export, and demand. The model is solved by integrating the Sample Average Approximation and L-shaped methods. We present conditions related to when demand will be met and a case study of a generic oncology drug. We find that preparing for geopolitical strain may increase resilience and profits as well as reduce shortages in the short term. At baseline, expected global shortages are high (17.2%) with disparities across country income levels (0.3%, 0.8%, 87.2%, and 87.6% for high, upper-middle, lower-middle, and low income countries, respectively). Pricing policies may improve drug access overall, back-shoring may slightly improve access for the country where it is implemented, and bilateral alliances may not be effective at improving access.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07434v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Martha L. Sabogal De La Pava (Industrial Engineering Department, Clemson University, Clemson, United States), Emily L. Tucker (Industrial Engineering Department, Clemson University, Clemson, United States, School of Health Research, Clemson University, Clemson, United States)</dc:creator>
    </item>
    <item>
      <title>Beyond Nonconvexity: A Universal Trust-Region Method with New Analyses</title>
      <link>https://arxiv.org/abs/2311.11489</link>
      <description>arXiv:2311.11489v3 Announce Type: replace 
Abstract: The trust-region (TR) method is renowned historically for its robustness in nonconvex problems and extraordinary numerical performance, but the study of its performance in convex optimization is somehow limited. This paper complements the existing literature by presenting a universal trust-region method that simultaneously incorporates the quadratic regularization and ball constraint. In particular, we introduce a novel descent property tailored for trust-region-type algorithms, enabling us to unify and streamline the analysis for both convex and nonconvex optimization. Our method exhibits an iteration complexity of $\tilde O(\epsilon^{-3/2})$ to find an $\epsilon$-approximate second-order stationary point for nonconvex optimization. Meanwhile, the analysis reveals that the universal method attains an $O(\epsilon^{-1/2})$ complexity bound for convex optimization. Finally, we develop an adaptive universal method to address practical implementations. The numerical results show the effectiveness of our method in both nonconvex and convex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.11489v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuntian Jiang, Chang He, Chuwen Zhang, Dongdong Ge, Bo Jiang, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>One to beat them all: "RYU" -- a unifying framework for the construction of safe balls</title>
      <link>https://arxiv.org/abs/2312.00640</link>
      <description>arXiv:2312.00640v2 Announce Type: replace 
Abstract: In this paper, we present a new framework, called "RYU" for constructing "safe" regions -- specifically, bounded sets that are guaranteed to contain the dual solution of a target optimization problem. Our framework applies to the standard case where the objective function is composed of two components: a closed, proper, convex function with Lipschitz-smooth gradient and another closed, proper, convex function. We show that the RYU framework not only encompasses but also improves upon the state-of-the-art methods proposed over the past decade for this class of optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00640v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thu-Le Tran, Cl\'ement Elvira, Hong-Phuong Dang, C\'edric Herzet</dc:creator>
    </item>
    <item>
      <title>Mini-batch stochastic subgradient for functional constrained optimization</title>
      <link>https://arxiv.org/abs/2401.10616</link>
      <description>arXiv:2401.10616v2 Announce Type: replace 
Abstract: In this paper we consider finite sum composite convex optimization problems with many functional constraints. The objective function is expressed as a finite sum of two terms, one of which admits easy computation of (sub)gradients while the other is amenable to proximal evaluations. We assume a generalized bounded gradient condition on the objective which allows us to simultaneously tackle both smooth and nonsmooth problems. We also consider the cases of both with and without a strong convexity property. Further, we assume that each constraint set is given as the level set of a convex but not necessarily differentiable function. We reformulate the constrained finite sum problem into a stochastic optimization problem for which the stochastic subgradient projection method from [17] specializes to a collection of mini-batch variants, with different mini-batch sizes for the objective function and functional constraints, respectively. More specifically, at each iteration, our algorithm takes a mini-batch stochastic proximal subgradient step aimed at minimizing the objective function and then a subsequent mini-batch subgradient projection step minimizing the feasibility violation. By specializing different mini-batching strategies, we derive exact expressions for the stepsizes as a function of the mini-batch size and in some cases we also derive insightful stepsize-switching rules which describe when one should switch from a constant to a decreasing stepsize regime. We also prove sublinear convergence rates for the mini-batch subgradient projection algorithm which depend explicitly on the mini-batch sizes and on the properties of the objective function. Numerical results also show a better performance of our mini-batch scheme over its single-batch counterpart.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10616v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/02331934.2023.2189015</arxiv:DOI>
      <arxiv:journal_reference>Optimization, 73(7), 2159-2185, 2023</arxiv:journal_reference>
      <dc:creator>Nitesh Kumar Singh, Ion Necoara, Vyacheslav Kungurtsev</dc:creator>
    </item>
    <item>
      <title>A stochastic moving ball approximation method for smooth convex constrained minimization</title>
      <link>https://arxiv.org/abs/2402.15016</link>
      <description>arXiv:2402.15016v2 Announce Type: replace 
Abstract: In this paper, we consider constrained optimization problems with convex, smooth objective and constraints. We propose a new stochastic gradient algorithm, called the Stochastic Moving Ball Approximation (SMBA) method, to solve this class of problems, where at each iteration we first take a gradient step for the objective function and then perform a projection step onto one ball approximation of a randomly chosen constraint. The computational simplicity of SMBA, which uses first-order information and considers only one constraint at a time, makes it suitable for large-scale problems with many functional constraints. We provide a convergence analysis for the SMBA algorithm using basic assumptions on the problem, that yields new convergence rates in both optimality and feasibility criteria evaluated at some average point. Our convergence proofs are novel since we need to deal properly with infeasible iterates and with quadratic upper approximations of constraints that may yield empty balls. We derive convergence rates of order $\mathcal{O} (k^{-1/2})$ when the objective function is convex, and $\mathcal{O} (k^{-1})$ when the objective function is strongly convex. Preliminary numerical experiments on quadratically constrained quadratic problems demonstrate the viability and performance of our method when compared to some existing state-of-the-art optimization methods and software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15016v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10589-024-00612-5</arxiv:DOI>
      <arxiv:journal_reference>Computational Optimization and Applications, 89, 659-689, 2024</arxiv:journal_reference>
      <dc:creator>Nitesh Kumar Singh, Ion Necoara</dc:creator>
    </item>
    <item>
      <title>An Analysis of Constraint-Relaxation in PDE-Based Inverse Problems</title>
      <link>https://arxiv.org/abs/2403.15292</link>
      <description>arXiv:2403.15292v2 Announce Type: replace 
Abstract: Inverse problems are ubiquitous in science and engineering. Many of these are naturally formulated as a PDE-constrained optimization problem. These non-linear, large-scale, constrained optimization problems know many challenges, of which the inherent non-linearity of the problem is an important one. In this paper, we focus on a relaxed formulation of the PDE-constrained optimization problem and provide an in-depth analysis of it. Starting from an infinite-dimensional formulation of the inverse problem with discrete data, we propose a general framework for the analysis and discretisation of such problems. The relaxed formulation of the PDE-constrained optimization problem is shown to reduce to a weighted non-linear least-squares problem. The weight matrix turns out to be the Gram matrix of solutions of the PDE and, in some cases, can be estimated directly from the measurements. The latter observation points to a potential way to unify recently proposed data-driven reduced-order models for inverse problems with PDE-constrained optimization. We provide a number of representative case studies and numerical examples to illustrate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15292v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tristan van Leeuwen, Yunan Yang</dc:creator>
    </item>
    <item>
      <title>Bike network planning in limited urban space</title>
      <link>https://arxiv.org/abs/2405.01770</link>
      <description>arXiv:2405.01770v2 Announce Type: replace 
Abstract: The lack of cycling infrastructure in urban environments hinders the adoption of cycling as a viable mode for commuting, despite the evident benefits of (e-)bikes as sustainable, efficient, and health-promoting transportation modes. Bike network planning is a tedious process, relying on heuristic computational methods that frequently overlook the broader implications of introducing new cycling infrastructure, in particular the necessity to repurpose car lanes. In this work, we call for optimizing the trade-off between bike and car networks, effectively pushing for Pareto optimality. This shift in perspective gives rise to a novel linear programming formulation towards optimal bike network allocation. Our experiments, conducted using both real-world and synthetic data, testify the effectiveness and superiority of this optimization approach compared to heuristic methods. In particular, the framework provides stakeholders with a range of lane reallocation scenarios, illustrating potential bike network enhancements and their implications for car infrastructure. Crucially, our approach is adaptable to various bikeability and car accessibility evaluation criteria, making our tool a highly flexible and scalable resource for urban planning. This paper presents an advanced decision-support framework that can significantly aid urban planners in making informed decisions on cycling infrastructure development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01770v2</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nina Wiedemann, Christian N\"obel, Lukas Ballo, Henry Martin, Martin Raubal</dc:creator>
    </item>
    <item>
      <title>Greedy Learning to Optimize with Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2406.00260</link>
      <description>arXiv:2406.00260v4 Announce Type: replace 
Abstract: Learning to optimize is an approach that leverages training data to accelerate the solution of optimization problems. Many approaches use unrolling to parametrize the update step and learn optimal parameters. Although L2O has shown empirical advantages over classical optimization algorithms, memory restrictions often greatly limit the unroll length and learned algorithms usually do not provide convergence guarantees. In contrast, we introduce a novel method employing a greedy strategy that learns iteration-specific parameters by minimizing the function value at the next iteration. This enables training over significantly more iterations while maintaining constant GPU memory usage. We parameterize the update such that parameter learning corresponds to solving a convex optimization problem at each iteration. In particular, we explore preconditioned gradient descent with multiple parametrizations including a novel convolutional preconditioner. With our learned algorithm, convergence in the training set is proved even when the preconditioner is neither symmetric nor positive definite. Convergence on a class of unseen functions is also obtained, ensuring robust performance and generalization beyond the training data. We test our learned algorithms on two inverse problems, image deblurring and Computed Tomography, on which learned convolutional preconditioners demonstrate improved empirical performance over classical optimization algorithms such as Nesterov's Accelerated Gradient Method and the quasi-Newton method L-BFGS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00260v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Fahy, Mohammad Golbabaee, Matthias J. Ehrhardt</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Semilinear Elliptic Partial Differential Equations with Non-Lipschitzian Nonlinearities</title>
      <link>https://arxiv.org/abs/2406.03110</link>
      <description>arXiv:2406.03110v2 Announce Type: replace 
Abstract: We study optimal control problems that are governed by semilinear elliptic partial differential equations that involve non-Lipschitzian nonlinearities. It is shown that, for a certain class of such PDEs, the solution map is Fr\'{e}chet differentiable even though the differential operator contains a nondifferentiable term. We exploit this effect to establish first-order necessary optimality conditions for minimizers of the considered control problems. The resulting KKT-conditions take the form of coupled PDE-systems that are posed in non-Muckenhoupt weighted Sobolev spaces and raise interesting questions regarding the regularity of optimal controls, the derivation of second-order optimality conditions, and the analysis of finite element discretizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03110v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Constantin Christof</dc:creator>
    </item>
    <item>
      <title>Prevailing against Adversarial Noncentral Disturbances: Exact Recovery of Linear Systems with the $l_1$-norm Estimator</title>
      <link>https://arxiv.org/abs/2410.03218</link>
      <description>arXiv:2410.03218v3 Announce Type: replace 
Abstract: This paper studies the linear system identification problem in the general case where the disturbance is sub-Gaussian, correlated, and possibly adversarial. First, we consider the case with noncentral (nonzero-mean) disturbances for which the ordinary least-squares (OLS) method fails to correctly identify the system. We prove that the $l_1$-norm estimator accurately identifies the system under the condition that each disturbance has equal probabilities of being positive or negative. This condition restricts the sign of each disturbance but allows its magnitude to be arbitrary. Second, we consider the case where each disturbance is adversarial with the model that the attack times happen occasionally but the distributions of the attack values are arbitrary. We show that when the probability of having an attack at a given time is less than 0.5 and each attack spans the entire space in expectation, the $l_1$-norm estimator prevails against any adversarial noncentral disturbances and the exact recovery is achieved within a finite time. These results pave the way to effectively defend against arbitrarily large noncentral attacks in safety-critical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03218v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jihun Kim, Javad Lavaei</dc:creator>
    </item>
    <item>
      <title>Barrier Function for Bilevel Optimization with Coupled Lower-Level Constraints: Formulation, Approximation and Algorithms</title>
      <link>https://arxiv.org/abs/2410.10670</link>
      <description>arXiv:2410.10670v2 Announce Type: replace 
Abstract: In this paper, we consider bilevel optimization problem where the lower-level has coupled constraints, i.e. the constraints depend both on the upper- and lower-level variables. In particular, we consider two settings for the lower-level problem. The first is when the objective is strongly convex and the constraints are convex with respect to the lower-level variable; The second is when the lower-level is a linear program. We propose to utilize a barrier function reformulation to translate the problem into an unconstrained problem. By developing a series of new techniques, we proved that both the hyperfunction value and hypergradient of the barrier reformulated problem (uniformly) converge to those of the original problem under minimal assumptions. Further, to overcome the non-Lipschitz smoothness of hyperfunction and lower-level problem for barrier reformulated problems, we design an adaptive algorithm that ensures a non-asymptotic convergence guarantee. We also design an algorithm that converges to the stationary point of the original problem asymptotically under certain assumptions. The proposed algorithms require minimal assumptions, and to our knowledge, they are the first with convergence guarantees when the lower-level problem is a linear program.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10670v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaotian Jiang, Jiaxiang Li, Mingyi Hong, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>An exact column generation algorithm for load balancing in capacity sharing networks</title>
      <link>https://arxiv.org/abs/2411.00555</link>
      <description>arXiv:2411.00555v2 Announce Type: replace 
Abstract: Capacity sharing networks are typical heterogeneous communication networks widely applied in information and communications technology (ICT) field. In such networks, resources like bandwidth, spectrum, computation and storage are shared among various communication services. Meanwhile, the issue of network congestion is always a prominent challenge. To handle network congestion essentially needs to solve the load balancing of networks. In this paper, for capacity sharing networks, we formulate their load balancing problem as a maximum multi-commodity flow problem. For such a problem, always a large-scale linear programming, the column generation algorithm is a commonly used and crucial method to solve it. In each iteration, this algorithm involves solving a linear programming subproblem and determining whether to terminate or generate a new column for inclusion in the subproblem. This iterative procedure of solving and checking continues throughout the algorithm. Nevertheless, since the checking subproblem is NP-hard, its solution significantly impacts the overall efficiency of the algorithm. In this paper, we innovatively convert the checking subproblem into a single-constrained shortest path (SCSP) subproblem. By exactly solving the SCSP subproblem, we can obtain the optimal solution to the checking subproblem with same or less computing time. Experimental results demonstrate that our algorithm achieves computational efficiency comparable to heuristic algorithms while outperforming other state-of-the-art algorithms by at least an order of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00555v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaixiang Hu, Feilong Huang, Caixia Kou</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Discrete-Time Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2411.01484</link>
      <description>arXiv:2411.01484v2 Announce Type: replace 
Abstract: This paper focuses on optimal control problem for a class of discrete-time nonlinear systems. In practical applications, computation time is a crucial consideration when solving nonlinear optimal control problems, especially under real-time constraints. While linearization methods are computationally efficient, their inherent low accuracy can compromise control precision and overall performance. To address this challenge, this study proposes a novel approach based on the optimal control method. Firstly, the original optimal control problem is transformed into an equivalent optimization problem, which is resolved using the Pontryagin's maximum principle, and a superlinear convergence algorithm is presented. Furthermore, to improve computation efficiency, explicit formulas for computing both the gradient and hessian matrix of the cost function are proposed. Finally, the effectiveness of the proposed algorithm is validated through simulations and experiments on a linear quadratic regulator problem and an automatic guided vehicle trajectory tracking problem, demonstrating its ability for real-time online precise control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01484v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuanzhi Lv, Xunmin Yin, Hongdan Li, Huanshui Zhang</dc:creator>
    </item>
    <item>
      <title>Trade-off Invariance Principle for minimizers of regularized functionals</title>
      <link>https://arxiv.org/abs/2411.11639</link>
      <description>arXiv:2411.11639v2 Announce Type: replace 
Abstract: In this paper, we consider functionals of the form $H_\alpha(u)=F(u)+\alpha G(u)$ with $\alpha\in[0,+\infty)$, where $u$ varies in a set $U\neq\emptyset$ (without further structure). We first show that, excluding at most countably many values of $\alpha$, we have that $\inf_{H_\alpha^\star}G= \sup_{H_\alpha^\star}G$, where $H_\alpha^\star := \arg \min_U H_\alpha$, which is assumed to be non-empty. We further prove a stronger result that concerns the {invariance of the} limiting value of the functional $G$ along minimizing sequences for $H_\alpha$. This fact in turn implies an unexpected consequence for functionals regularized with uniformly convex norms: excluding again at most countably many values of $\alpha$, it turns out that for a minimizing sequence, convergence to a minimizer in the weak or strong sense is equivalent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11639v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Massimo Fornasier, Jona Klemenc, Alessandro Scagliotti</dc:creator>
    </item>
    <item>
      <title>A Simple Introduction to the SiMPL Method for Density-Based Topology Optimization</title>
      <link>https://arxiv.org/abs/2411.19421</link>
      <description>arXiv:2411.19421v2 Announce Type: replace 
Abstract: We introduce a novel method for solving density-based topology optimization problems: Sigmoidal Mirror descent with a Projected Latent variable (SiMPL). The SiMPL method (pronounced as "the simple method") optimizes a design using only first-order derivative information of the objective function. The bound constraints on the density field are enforced with the help of the (negative) Fermi--Dirac entropy, which is also used to define a non-symmetric distance function called a Bregman divergence on the set of admissible designs. This Bregman divergence leads to a simple update rule that is further simplified with the help of a so-called latent variable. Because the SiMPL method involves discretizing the latent variable, it produces a sequence of pointwise-feasible iterates, even when high-order finite elements are used in the discretization. Numerical experiments demonstrate that the method outperforms other popular first-order optimization algorithms. To outline the general applicability of the technique, we include examples with (self-load) compliance minimization and compliant mechanism optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19421v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dohyun Kim, Boyan Stefanov Lazarov, Thomas M. Surowiec, Brendan Keith</dc:creator>
    </item>
    <item>
      <title>Exact Moment Representation in Polynomial Optimization</title>
      <link>https://arxiv.org/abs/2012.14652</link>
      <description>arXiv:2012.14652v5 Announce Type: replace-cross 
Abstract: We investigate the problem of representing moment sequences by measures in the context ofPolynomial Optimization Problems, that consist in finding the infimum of a real polynomial ona real semialgebraic set defined by polynomial inequalities. We analyze the exactness of MomentMatrix (MoM) hierarchies, dual to the Sum of Squares (SoS) hierarchies, which are sequences ofconvex cones introduced by Lasserre to approximate measures and positive polynomials. Weinvestigate in particular flat truncation properties, which allow testing effectively when MoMexactness holds and recovering the minimizers.We show that the dual of the MoM hierarchy coincides with the SoS hierarchy extendedwith the real radical of the support of the defining quadratic module Q. We deduce thatflat truncation happens if and only if the support of the quadratic module associated withthe minimizers is of dimension zero. We also bound the order of the hierarchy at which flattruncation holds.As corollaries, we show that flat truncation and MoM exactness hold when regularityconditions, known as Boundary Hessian Conditions, hold (and thus that MoM exactness holdsgenerically); and when the support of the quadratic module Q is zero-dimensional. Effectivenumerical computations illustrate these flat truncation properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.14652v5</guid>
      <category>math.AC</category>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jsc.2024.102403</arxiv:DOI>
      <dc:creator>Lorenzo Baldi (AROMATH), Bernard Mourrain (AROMATH)</dc:creator>
    </item>
    <item>
      <title>Geometric insights into robust portfolio construction</title>
      <link>https://arxiv.org/abs/2107.06194</link>
      <description>arXiv:2107.06194v5 Announce Type: replace-cross 
Abstract: We investigate and extend the result that an alpha-weight angle from unconstrained quadratic portfolio optimisations has an upper bound dependent on the condition number of the covariance matrix. This is known to imply that better conditioned covariance matrices produce weights from unconstrained mean-variance optimisations that are better aligned with each assets expected return. Here we relate the inequality between the alpha-weight angle and the condition number to extend the result to include portfolio optimisations with gearing constraints to provide an extended family of robust optimisations. We use this to argue that in general the equally weighted portfolio is not preferable to the mean-variance portfolio even with poor forecast ability and a badly conditioned covariance matrix. We confirm the distribution free theoretical arguments with a simple Gaussian simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.06194v5</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <category>q-fin.GN</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1142/S0219024924500249</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Theoretical and Applied Finance, 2024</arxiv:journal_reference>
      <dc:creator>Lara Dalmeyer, Tim Gebbie</dc:creator>
    </item>
    <item>
      <title>A framework for bilevel optimization that enables stochastic and global variance reduction algorithms</title>
      <link>https://arxiv.org/abs/2201.13409</link>
      <description>arXiv:2201.13409v4 Announce Type: replace-cross 
Abstract: Bilevel optimization, the problem of minimizing a value function which involves the arg-minimum of another function, appears in many areas of machine learning. In a large scale empirical risk minimization setting where the number of samples is huge, it is crucial to develop stochastic methods, which only use a few samples at a time to progress. However, computing the gradient of the value function involves solving a linear system, which makes it difficult to derive unbiased stochastic estimates. To overcome this problem we introduce a novel framework, in which the solution of the inner problem, the solution of the linear system, and the main variable evolve at the same time. These directions are written as a sum, making it straightforward to derive unbiased estimates. The simplicity of our approach allows us to develop global variance reduction algorithms, where the dynamics of all variables is subject to variance reduction. We demonstrate that SABA, an adaptation of the celebrated SAGA algorithm in our framework, has $O(\frac1T)$ convergence rate, and that it achieves linear convergence under Polyak-Lojasciewicz assumption. This is the first stochastic algorithm for bilevel optimization that verifies either of these properties. Numerical experiments validate the usefulness of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.13409v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathieu Dagr\'eou, Pierre Ablin, Samuel Vaiter, Thomas Moreau</dc:creator>
    </item>
    <item>
      <title>A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization</title>
      <link>https://arxiv.org/abs/2302.08766</link>
      <description>arXiv:2302.08766v5 Announce Type: replace-cross 
Abstract: Bilevel optimization problems, which are problems where two optimization problems are nested, have more and more applications in machine learning. In many practical cases, the upper and the lower objectives correspond to empirical risk minimization problems and therefore have a sum structure. In this context, we propose a bilevel extension of the celebrated SARAH algorithm. We demonstrate that the algorithm requires $\mathcal{O}((n+m)^{\frac12}\varepsilon^{-1})$ oracle calls to achieve $\varepsilon$-stationarity with $n+m$ the total number of samples, which improves over all previous bilevel algorithms. Moreover, we provide a lower bound on the number of oracle calls required to get an approximate stationary point of the objective function of the bilevel problem. This lower bound is attained by our algorithm, making it optimal in terms of sample complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.08766v5</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathieu Dagr\'eou, Thomas Moreau, Samuel Vaiter, Pierre Ablin</dc:creator>
    </item>
    <item>
      <title>Global Well-Posedness of Displacement Monotone Degenerate Mean Field Games Master Equations</title>
      <link>https://arxiv.org/abs/2308.16167</link>
      <description>arXiv:2308.16167v2 Announce Type: replace-cross 
Abstract: In this paper we construct global in time classical solutions to mean field games master equations in the lack of idiosyncratic noise in the individual agents' dynamics. These include both deterministic models and dynamics driven solely by a Brownian common noise. We consider a general class of non-separable Hamiltonians and final data functions that are supposed to be displacement monotone. Our main results unify and generalize in particular some of the well-posedness results on displacement monotone master equations obtained recently by Gangbo--M\'esz\'aros and Gangbo--M\'esz\'aros--Mou--Zhang.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.16167v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohit Bansil, Alp\'ar R. M\'esz\'aros, Chenchen Mou</dc:creator>
    </item>
    <item>
      <title>On the minimal algebraic complexity of the rank-one approximation problem for general inner products</title>
      <link>https://arxiv.org/abs/2309.15105</link>
      <description>arXiv:2309.15105v2 Announce Type: replace-cross 
Abstract: We study the algebraic complexity of Euclidean distance minimization from a generic tensor to a variety of rank-one tensors. The Euclidean Distance (ED) degree of the Segre-Veronese variety counts the number of complex critical points of this optimization problem. We regard this invariant as a function of inner products. We prove that Frobenius inner product is a local minimum of the ED degree, and conjecture that it is a global minimum. We prove our conjecture in the case of matrices and symmetric binary and $3\times 3\times 3$ tensors. We discuss the above optimization problem for other algebraic varieties, classifying all possible values of the ED degree. Our approach combines tools from Singularity Theory, Morse Theory, and Algebraic Geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15105v2</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Khazhgali Kozhasov, Alan Muniz, Yang Qi, Luca Sodomaco</dc:creator>
    </item>
    <item>
      <title>Asynchronous Message-Passing and Zeroth-Order Optimization Based Distributed Learning with a Use-Case in Resource Allocation in Communication Networks</title>
      <link>https://arxiv.org/abs/2311.04604</link>
      <description>arXiv:2311.04604v3 Announce Type: replace-cross 
Abstract: Distributed learning and adaptation have received significant interest and found wide-ranging applications in machine learning and signal processing. While various approaches, such as shared-memory optimization, multi-task learning, and consensus-based learning (e.g., federated learning and learning over graphs), focus on optimizing either local costs or a global cost, there remains a need for further exploration of their interconnections. This paper specifically focuses on a scenario where agents collaborate towards a common task (i.e., optimizing a global cost equal to aggregated local costs) while effectively having distinct individual tasks (i.e., optimizing individual local parameters in a local cost). Each agent's actions can potentially impact other agents' performance through interactions. Notably, each agent has access to only its local zeroth-order oracle (i.e., cost function value) and shares scalar values, rather than gradient vectors, with other agents, leading to communication bandwidth efficiency and agent privacy. Agents employ zeroth-order optimization to update their parameters, and the asynchronous message-passing between them is subject to bounded but possibly random communication delays. This paper presents theoretical convergence analyses and establishes a convergence rate for nonconvex problems. Furthermore, it addresses the relevant use-case of deep learning-based resource allocation in communication networks and conducts numerical experiments in which agents, acting as transmitters, collaboratively train their individual policies to maximize a global reward, e.g., a sum of data rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04604v3</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TSIPN.2024.3487421</arxiv:DOI>
      <dc:creator>Pourya Behmandpoor, Marc Moonen, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Feasible Space Monitoring for Multiple Control Barrier Functions with application to Large Scale Indoor Navigation</title>
      <link>https://arxiv.org/abs/2312.07803</link>
      <description>arXiv:2312.07803v2 Announce Type: replace-cross 
Abstract: Quadratic programs (QP) subject to multiple time-dependent control barrier function (CBF) based constraints have been used to design safety-critical controllers. However, ensuring the existence of a solution at all times to the QP subject to multiple CBF constraints (hereby called compatibility) is non-trivial. We quantify the feasible control input space defined by multiple CBFs at a state in terms of its volume. We then introduce a novel feasible space (FS) CBF that prevents this volume from going to zero. FS-CBF is shown to be a sufficient condition for the compatibility of multiple CBFs. For high-dimensional systems though, finding a valid FS-CBF may be difficult due to the limitations of existing computational hardware or theoretical approaches. In such cases, we show empirically that imposing the feasible space volume as a candidate FS-CBF not only enhances feasibility but also exhibits reduced sensitivity to changes in the user-chosen parameters such as gains of the nominal controller. Finally, paired with a global planner, we evaluate our controller for navigation among other dynamically moving agents in the AWS Hospital gazebo environment. The proposed controller is demonstrated to outperform the standard CBF-QP controller in maintaining feasibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07803v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hardik Parwana, Mitchell Black, Bardh Hoxha, Hideki Okamoto, Georgios Fainekos, Danil Prokhorov, Dimitra Panagou</dc:creator>
    </item>
    <item>
      <title>Stochastic Hessian Fittings with Lie Groups</title>
      <link>https://arxiv.org/abs/2402.11858</link>
      <description>arXiv:2402.11858v4 Announce Type: replace-cross 
Abstract: This report studies the fitting of Hessian or its inverse for stochastic optimizations using a Hessian fitting criterion from the preconditioned stochastic gradient descent (PSGD) method, which is intimately related to many commonly used second-order and adaptive gradient optimizers, e.g., BFGS, Gaussian-Newton algorithm, natural gradient descent, AdaGrad, etc. Our analyses reveal the efficiency and reliability differences among a wide range of preconditioner fitting methods, from closed-form to iterative solutions, using Hessian-vector products or stochastic gradients only, with Hessian fittings in the Euclidean space, the manifold of symmetric positive definite (SPL) matrices, to a variety of Lie groups. The most intriguing discovery is that the Hessian fitting itself as an optimization problem is strongly convex under mild conditions in certain general Lie groups. This discovery turns Hessian fitting into a well-behaved Lie group optimization problem and facilitates the designs of highly efficient and elegant Lie group sparse preconditioner fitting methods for large-scale stochastic optimizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11858v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xi-Lin Li</dc:creator>
    </item>
    <item>
      <title>A Conditional Upper Bound for the Moving Sofa Problem</title>
      <link>https://arxiv.org/abs/2406.10725</link>
      <description>arXiv:2406.10725v2 Announce Type: replace-cross 
Abstract: The moving sofa problem asks for the connected shape with the largest area $\mu_{\text{max}}$ that can move around the right-angled corner of a hallway $L$ with unit width. The best bounds currently known on $\mu_{\max}$ are summarized as $2.2195\ldots \leq \mu_{\max} \leq 2.37$. The lower bound $2.2195\ldots \leq \mu_{\max}$ comes from Gerver's sofa $S_G$ of area $\mu_G := 2.2195\ldots$. The upper bound $\mu_{\max} \leq 2.37$ was proved by Kallus and Romik using extensive computer assistance. It is conjectured that the equality $\mu_{\max} = \mu_G$ holds at the lower bound.
  We develop a new approach to the moving sofa problem by approximating it as an infinite-dimensional convex quadratic optimization problem. The problem is then explicitly solved using a calculus of variation based on the Brunn-Minkowski theory. Consequently, we prove that any moving sofa satisfying a property named the injectivity condition has an area of at most $1 + \pi^2/8 = 2.2337\dots$. The new conditional bound does not rely on any computer assistance, yet it is much closer to the lower bound $2.2195\ldots$ of Gerver than the computer-assisted upper bound $2.37$ of Kallus and Romik. Gerver's sofa $S_G$, the conjectured optimum, satisfies the injectivity condition in particular.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10725v2</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jineon Baek</dc:creator>
    </item>
    <item>
      <title>Enhancing supply chain security with automated machine learning</title>
      <link>https://arxiv.org/abs/2406.13166</link>
      <description>arXiv:2406.13166v2 Announce Type: replace-cross 
Abstract: The increasing scale and complexity of global supply chains have led to new challenges spanning various fields, such as supply chain disruptions due to long waiting lines at the ports, material shortages, and inflation. Coupled with the size of supply chains and the availability of vast amounts of data, efforts towards tackling such challenges have led to an increasing interest in applying machine learning methods in many aspects of supply chains. Unlike other solutions, ML techniques, including Random Forest, XGBoost, LightGBM, and Neural Networks, make predictions and approximate optimal solutions faster. This paper presents an automated ML framework to enhance supply chain security by detecting fraudulent activities, predicting maintenance needs, and forecasting material backorders. Using datasets of varying sizes, results show that fraud detection achieves an 88% accuracy rate using sampling methods, machine failure prediction reaches 93.4% accuracy, and material backorder prediction achieves 89.3% accuracy. Hyperparameter tuning significantly improved the performance of these models, with certain supervised techniques like XGBoost and LightGBM reaching up to 100% precision. This research contributes to supply chain security by streamlining data preprocessing, feature selection, model optimization, and inference deployment, addressing critical challenges and boosting operational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13166v2</guid>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haibo Wang, Lutfu S. Sua, Bahram Alidaee</dc:creator>
    </item>
    <item>
      <title>Strongly-polynomial time and validation analysis of policy gradient methods</title>
      <link>https://arxiv.org/abs/2409.19437</link>
      <description>arXiv:2409.19437v3 Announce Type: replace-cross 
Abstract: This paper proposes a novel termination criterion, termed the advantage gap function, for finite state and action Markov decision processes (MDP) and reinforcement learning (RL). By incorporating this advantage gap function into the design of step size rules and deriving a new linear rate of convergence that is independent of the stationary state distribution of the optimal policy, we demonstrate that policy gradient methods can solve MDPs in strongly-polynomial time. To the best of our knowledge, this is the first time that such strong convergence properties have been established for policy gradient methods. Moreover, in the stochastic setting, where only stochastic estimates of policy gradients are available, we show that the advantage gap function provides close approximations of the optimality gap for each individual state and exhibits a sublinear rate of convergence at every state. The advantage gap function can be easily estimated in the stochastic case, and when coupled with easily computable upper bounds on policy values, they provide a convenient way to validate the solutions generated by policy gradient methods. Therefore, our developments offer a principled and computable measure of optimality for RL, whereas current practice tends to rely on algorithm-to-algorithm or baselines comparisons with no certificate of optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19437v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caleb Ju, Guanghui Lan</dc:creator>
    </item>
    <item>
      <title>Spectral estimates on hyperbolic surfaces and a necessary condition for observability of the heat semigroup on manifolds</title>
      <link>https://arxiv.org/abs/2410.01323</link>
      <description>arXiv:2410.01323v3 Announce Type: replace-cross 
Abstract: This article is a continuation of arXiv:2401.14977. We study the concentration properties of spectral projectors on manifolds, in connection with the uncertainty principle. In arXiv:2401.14977, the second author proved an optimal uncertainty principle for the spectral projector of the Laplacian on the hyperbolic half-plane. The aim of the present work is to generalize this condition to surfaces with hyperbolic ends. In particular, we tackle the case of cusps, in which the volume of balls of fixed radius is not bounded from below. We establish that spectral estimates hold from sets satisfying a thickness condition, with a proof based on propagation of smallness estimates of Carleman and Logunov--Malinnikova type. We also prove the converse, namely the necessary character of the thickness condition, on any smooth manifold with Ricci curvature bounded from below.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01323v3</guid>
      <category>math.AP</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alix Deleporte, Marc Rouveyrol</dc:creator>
    </item>
    <item>
      <title>Provable Acceleration of Nesterov's Accelerated Gradient for Rectangular Matrix Factorization and Linear Neural Networks</title>
      <link>https://arxiv.org/abs/2410.09640</link>
      <description>arXiv:2410.09640v3 Announce Type: replace-cross 
Abstract: We study the convergence rate of first-order methods for rectangular matrix factorization, which is a canonical nonconvex optimization problem. Specifically, given a rank-$r$ matrix $\mathbf{A}\in\mathbb{R}^{m\times n}$, we prove that gradient descent (GD) can find a pair of $\epsilon$-optimal solutions $\mathbf{X}_T\in\mathbb{R}^{m\times d}$ and $\mathbf{Y}_T\in\mathbb{R}^{n\times d}$, where $d\geq r$, satisfying $\lVert\mathbf{X}_T\mathbf{Y}_T^\top-\mathbf{A}\rVert_\mathrm{F}\leq\epsilon\lVert\mathbf{A}\rVert_\mathrm{F}$ in $T=O(\kappa^2\log\frac{1}{\epsilon})$ iterations with high probability, where $\kappa$ denotes the condition number of $\mathbf{A}$. Furthermore, we prove that Nesterov's accelerated gradient (NAG) attains an iteration complexity of $O(\kappa\log\frac{1}{\epsilon})$, which is the best-known bound of first-order methods for rectangular matrix factorization. Different from small balanced random initialization in the existing literature, we adopt an unbalanced initialization, where $\mathbf{X}_0$ is large and $\mathbf{Y}_0$ is $0$. Moreover, our initialization and analysis can be further extended to linear neural networks, where we prove that NAG can also attain an accelerated linear convergence rate. In particular, we only require the width of the network to be greater than or equal to the rank of the output label matrix. In contrast, previous results achieving the same rate require excessive widths that additionally depend on the condition number and the rank of the input data matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09640v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenghao Xu, Yuqing Wang, Tuo Zhao, Rachel Ward, Molei Tao</dc:creator>
    </item>
    <item>
      <title>Dynamic Estimation of Learning Rates Using a Non-Linear Autoregressive Model</title>
      <link>https://arxiv.org/abs/2410.09943</link>
      <description>arXiv:2410.09943v2 Announce Type: replace-cross 
Abstract: We introduce a new class of adaptive non-linear autoregressive (Nlar) models incorporating the concept of momentum, which dynamically estimate both the learning rates and momentum as the number of iterations increases. In our method, the growth of the gradients is controlled using a scaling (clipping) function, leading to stable convergence. Within this framework, we propose three distinct estimators for learning rates and provide theoretical proof of their convergence. We further demonstrate how these estimators underpin the development of effective Nlar optimizers. The performance of the proposed estimators and optimizers is rigorously evaluated through extensive experiments across several datasets and a reinforcement learning environment. The results highlight two key features of the Nlar optimizers: robust convergence despite variations in underlying parameters, including large initial learning rates, and strong adaptability with rapid convergence during the initial epochs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09943v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ramin Okhrati</dc:creator>
    </item>
  </channel>
</rss>
