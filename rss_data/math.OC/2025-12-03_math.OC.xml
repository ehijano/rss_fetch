<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Dec 2025 02:35:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Distributed Time-Varying Coverage Control via Singular Perturbations</title>
      <link>https://arxiv.org/abs/2512.02163</link>
      <description>arXiv:2512.02163v1 Announce Type: new 
Abstract: This paper presents a novel dynamic coverage control algorithm allowing a group of robots to track an optimal-deployment configuration for arbitrary time-varying density functions. Building on singular perturbation theory, the proposed design employs a two-time scale separation approach, with a fast time scale corresponding to communication and a slow time scale corresponding to agent motion. The resulting algorithm is distributed over the 2-hop Delaunay graph and, for small enough values of the perturbation parameter, achieves the same performance as its centralized counterpart. We also introduce three discrete-time versions that rely only on 1-hop communication at the cost of having to use delayed information and formally establish their asymptotic convergence properties. Our technical approach combines computational geometry, singular perturbation theory, generating functions, and linear iterations with delayed updates. Various simulations illustrate the performance of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02163v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon Bao, Jorge Cortes, Sonia Martinez</dc:creator>
    </item>
    <item>
      <title>Parameter-Efficient Subspace Optimization for LLM Fine-Tuning</title>
      <link>https://arxiv.org/abs/2512.02216</link>
      <description>arXiv:2512.02216v1 Announce Type: new 
Abstract: This paper develops a new perspective on parameter-efficient fine-tuning for LLMs, inspired by the classical theory of subspace minimization. We introduce a unifying framework, Parameter-Efficient Subspace Optimization (PESO), which not only recovers many existing methods such as LoRA but also bridges them with the principled algorithmic and theoretical foundations of subspace optimization. This connection highlights a natural ``exploration--exploitation'' view of subspace methods, guiding the design of new algorithms that achieve strong convergence performance while still preserving memory efficiency. Importantly, our framework establishes the convergence in the full-parameter space, resolving a critical gap of LoRA variants where low-rank updates lack such guarantees. We further instantiate the framework into a practical algorithm named {PESO-LoRA}, based on LoRA-type parameterization. Our algorithm achieves notable improvements over existing methods on standard benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02216v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Lou, Zeqi Ye, Minshuo Chen</dc:creator>
    </item>
    <item>
      <title>An exact pricing algorithm for revenue maximization under the logit demand function</title>
      <link>https://arxiv.org/abs/2512.02247</link>
      <description>arXiv:2512.02247v1 Announce Type: new 
Abstract: Determining the optimal selling price is a challenge in revenue management, especially in markets characterized by nonlinear and price-sensitive demand. While traditional models, such as linear, power, and exponential demand functions, offer analytical convenience, they often fail to capture realistic purchase dynamics, leading to suboptimal pricing. The logit demand function addresses these limitations through its bounded, S-shaped curve, offering a more realistic representation of consumer behavior. Despite its advantages, most existing literature relies on heuristic approaches, such as pricing at the inflection point, which prioritizes maximum price sensitivity but does not guarantee maximum revenue. This study proposes a novel, exact pricing algorithm that analytically derives the revenue-maximizing price under the logit demand function using the Lambert W function. By providing a closed-form solution, the approach eliminates reliance on heuristic iterative methods and corrects the common practice of considering the inflection point price as market price. In fact, we demonstrate that the optimal price is consistently lower than the inflection-point price under reasonable assumptions, leading to lower prices for consumers and higher revenue for sellers. Numerical experiments illustrate the proposed algorithm and examine the changes in the optimality gap as demand function parameters vary. Results indicate that the optimal price is consistently lower than the inflection-point price, with an average 20% price reduction accompanied by a 15% increase in revenue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02247v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Moddassir Khan Nayeem, Omar Abbaas, Suzan Alaswad, Sinan Salman</dc:creator>
    </item>
    <item>
      <title>Neural networks for multi-horizon stochastic programming</title>
      <link>https://arxiv.org/abs/2512.02294</link>
      <description>arXiv:2512.02294v1 Announce Type: new 
Abstract: This paper proposes a machine-learning-based solution approach for solving multi-horizon stochastic programs. The approach embeds a deep learning neural network into a multi-horizon stochastic program to approximate the recourse operational objective function. The proposed approach is demonstrated on a UK power system planning problem with uncertainty at investment and operational timescales. The results show that (1) the surrogate neural network performs well across three different architectures, (2) the proposed approach is up to 34.72 times faster than the direct solution of the monolithic deterministic equivalent counterpart, (3) the surrogate-based solutions yield comparable in-sample stability and improved out-of-sample performance relative to the deterministic equivalent, indicating better generalisation to unseen scenarios. The main contributions of the paper are: (1) we propose a machine-learning-based framework for solving multi-horizon stochastic programs, (2) we introduce a neural network embedding formulation tailored to multi-horizon stochastic programs with continuous first-stage decisions and fixed scenario sets, extending existing surrogate modelling approaches from two-stage to multi-horizon settings, and (3) we provide an extensive computational study on a realistic UK power system planning problem, demonstrating the trade-off between approximation accuracy, computational efficiency, and solution robustness for different neural network architectures and scenario set sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02294v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hongyu Zhang, Gabriele Sormani, Enza Messina, Alan King, Francesca Maggioni</dc:creator>
    </item>
    <item>
      <title>Nonlinear MPC with PWM applied on a small satellite</title>
      <link>https://arxiv.org/abs/2512.02311</link>
      <description>arXiv:2512.02311v1 Announce Type: new 
Abstract: This paper employs Pulse Width Modulation (PWM) method to a Nonlinear Model Predictive Control (NMPC) for satellite attitude control and detumbling. Magnetic torquers have been used as actuators for the stabilization and attitude control of small satellites. NMPC generates the control input which is continuous and smooth. As a result, it is challenging for the on-board actuators to produce these continuous magnetic moments as a control input. Thus, PWM is applied to discretize the control input reducing the load on the actuators. Simulations are presented for detumbling and attitude control to illustrate the effectiveness and feasibility of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02311v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jinaykumar Patel</dc:creator>
    </item>
    <item>
      <title>Safeguarded Stochastic Polyak Step Sizes for Non-smooth Optimization: Robust Performance Without Small (Sub)Gradients</title>
      <link>https://arxiv.org/abs/2512.02342</link>
      <description>arXiv:2512.02342v1 Announce Type: new 
Abstract: The stochastic Polyak step size (SPS) has proven to be a promising choice for stochastic gradient descent (SGD), delivering competitive performance relative to state-of-the-art methods on smooth convex and non-convex optimization problems, including deep neural network training. However, extensions of this approach to non-smooth settings remain in their early stages, often relying on interpolation assumptions or requiring knowledge of the optimal solution. In this work, we propose a novel SPS variant, Safeguarded SPS (SPS$_{safe}$), for the stochastic subgradient method, and provide rigorous convergence guarantees for non-smooth convex optimization with no need for strong assumptions. We further incorporate momentum into the update rule, yielding equally tight theoretical results. Comprehensive experiments on convex benchmarks and deep neural networks corroborate our theory: the proposed step size accelerates convergence, reduces variance, and consistently outperforms existing adaptive baselines. Finally, in the context of deep neural network training, our method demonstrates robust performance by addressing the vanishing gradient problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02342v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitris Oikonomou, Nicolas Loizou</dc:creator>
    </item>
    <item>
      <title>Theory and Design of Extended PID Control for Stochastic Systems with Structural Uncertainties</title>
      <link>https://arxiv.org/abs/2512.02467</link>
      <description>arXiv:2512.02467v1 Announce Type: new 
Abstract: Since the classical proportional-integral-derivative (PID) controller has continued to be the most widely used feedback methods in engineering systems by far, it is crucial to investigate the working mechanism of PID in dealing with nonlinearity, uncertainty and random noises. Recently, Zhao and Guo (2022) has established the global stability of PID control for a class of uncertain nonlinear control systems with relative degree two without random perturbations. In this paper, we will consider a more general class of nonlinear stochastic systems with an arbitrary relative degree $n$, and discuss the stability and design of extended PID controller (a natural extension of PID). We demonstrate that, the closed-loop control systems will be globally stable in mean square with bounded tracking errors provided the extended PID parameters are selected from an $(n+1)$-dimensional unbounded set, even if both the system nonlinear drift and diffusion terms contain a wide range of structural uncertainties. Moreover, the steady-state tracking error is proved to be proportional to the noise intensity at the setpoint, which can also be made arbitrarily small by choosing the controller parameters suitably large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02467v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baoyou Qu, Cheng Zhao</dc:creator>
    </item>
    <item>
      <title>Parameter identification of lithium-ion batteries: a comparative study of various models and optimization techniques for battery modeling</title>
      <link>https://arxiv.org/abs/2512.02606</link>
      <description>arXiv:2512.02606v1 Announce Type: new 
Abstract: This work presents a comparative study of optimization techniques for parameter identification in equivalent electrical models of lithium-ion batteries. The 2RC model is applied to a set of twelve batteries using four publicly available datasets obtained from well-established research institutions. The methodology is structured in four stages: first, the 2RC model is selected due to its balance between physical interpretability and computational simplicity; second, experimental charge-discharge cycle data are collected; third, various optimization techniques are applied with the aim of minimizing the error between the experimental data and the response estimated by the model; and finally, accuracy is evaluated using the mean squared error, while computational efficiency is assessed through execution time. Traditional, metaheuristic, and bio-inspired optimization methods are considered, including least squares optimization, particle swarm optimization, simulated annealing, and several nature-inspired variants. It is demonstrated that bio-inspired techniques achieve greater accuracy than traditional methods, without a significant increase in computational cost. In particular, particle swarm optimization shows superior performance in terms of precision and robustness against local minima. It is concluded that the integration of advanced optimization strategies significantly enhances the fidelity of equivalent electrical models, which is essential for accurate estimation of internal states such as state of charge, aging, and service life in lithium-ion batteries used in electric vehicles and aerospace systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02606v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Ingenier{\'i}a e Innovaci{\'o}n, 2025, 13 (2)</arxiv:journal_reference>
      <dc:creator>Johan Sebastian Suarez Sep\'ulveda (UNAL), Edgar Hernando Sep\'ulveda-Oviedo (PROMES, UPVD), Bruno Jammes (LAAS-ISGE), Corinne Alonso (UT3, LAAS-ISGE)</dc:creator>
    </item>
    <item>
      <title>A new family of models with generalized orientation in data envelopment analysis</title>
      <link>https://arxiv.org/abs/2512.02630</link>
      <description>arXiv:2512.02630v1 Announce Type: new 
Abstract: In the framework of data envelopment analysis, we review directional models \citep{Chambers1996, Chambers1998, Briec1997} and show that they are inadequate when inputs and outputs are improved simultaneously under constant returns to scale. Conversely, we introduce a new family of quadratically constrained models with generalized orientation and demonstrate that these models overcome this limitation. Furthermore, we extend the Farrell measure of technical efficiency using these new models. Additionally, we prove that the family of generalized oriented models satisfies some desired monotonicity properties. Finally, we show that the new models, although being quadratically constrained, can be solved through linear programs in a fundamental particular case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02630v1</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1111/itor.70063</arxiv:DOI>
      <arxiv:journal_reference>International Transactions in Operational Research (2026, early access)</arxiv:journal_reference>
      <dc:creator>V. J. Bolos, R Benitez, V. Coll-Serrano</dc:creator>
    </item>
    <item>
      <title>A Communication-Efficient Distributed Optimization Algorithm with Coupled Constraints</title>
      <link>https://arxiv.org/abs/2512.02634</link>
      <description>arXiv:2512.02634v1 Announce Type: new 
Abstract: With the advancement of industrialization and Industry 4.0, the Industrial Internet of Things (IIoT) has emerged as a novel paradigm for information exchange in industrial production environments. To ensure the efficient operation of IIoT, it is imperative to develop communication-efficient methods for transmitting massive production data. This paper designs a communication-efficient distributed optimization algorithm for optimization problems subject to coupled equality constraints. While compressed communication is employed to enhance efficiency, it comes at the cost of introducing compression errors that may impair algorithm performance. To eliminate the influence of compression errors, differential compression techniques along with dynamic scaling factors are incorporated into the algorithm design. Linear convergence and constraint satisfaction of the algorithm are established under different types of compressors. Numerical results further demonstrate its effectiveness across three compression scenarios with specific quantizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02634v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuzhu Duan, Ziwen Yang, Xiaoming Duan, Shanying Zhu</dc:creator>
    </item>
    <item>
      <title>A Port-Hamiltonian Modeling Approach for Integrated Hydrogen Systems</title>
      <link>https://arxiv.org/abs/2512.02717</link>
      <description>arXiv:2512.02717v1 Announce Type: new 
Abstract: Hydrogen's growing role in the transition towards climate-neutral energy systems necessitates structured modeling frameworks. Existing gas network models, largely developed for natural gas, fail to capture hydrogen systems distinct properties, particularly the coupling of hydrogen pipes with electrolyzers, fuel cells, and electrically driven compressors. In this work, we present a unified systematic port-Hamiltonian (pH) framework for modeling hydrogen systems, which inherently provides a passive input-output map of the overall interconnected system and, thus, a promising foundation for structured analysis, control and optimization of this type of newly emerging energy systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02717v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdullah Shahin, Hannes Gernandt, Anton Plietzsch, Johannes Schiffer</dc:creator>
    </item>
    <item>
      <title>Sum of Squares Decompositions for Structured Biquadratic Forms</title>
      <link>https://arxiv.org/abs/2512.02734</link>
      <description>arXiv:2512.02734v1 Announce Type: new 
Abstract: This paper studies sum-of-squares (SOS) representations for structured biquadratic forms. We prove that diagonally dominated symmetric biquadratic tensors are always SOS. For the special case of symmetric biquadratic forms, we establish necessary and sufficient conditions for positive semi-definiteness of monic symmetric biquadratic forms, characterize the geometry of the corresponding psd cone, and prove that every such psd form is SOS. We also formulate conjectures regarding SOS representations for symmetric M-biquadratic tensors and symmetric B$_0$-biquadratic tensors, discussing their likelihood and potential proof strategies. Our results advance the understanding of when positive semi-definiteness implies sum-of-squares decompositions for structured biquadratic forms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02734v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Xu, Chunfeng Cui, Liqun Qi</dc:creator>
    </item>
    <item>
      <title>Reinforcement learning for irreversible reinsurance problems: the randomized singular control approach</title>
      <link>https://arxiv.org/abs/2512.02769</link>
      <description>arXiv:2512.02769v1 Announce Type: new 
Abstract: This paper studies the continuous-time reinforcement learning for stochastic singular control with the application to an infinite-horizon irreversible reinsurance problems. The singular control is equivalently characterized as a pair of regions of time and the augmented states, called the singular control law. To encourage the exploration in the learning procedure, we propose a randomization method for the singular control laws, new to the literature, by considering an auxiliary singular control and entropy regularization. The exploratory singular control problem is formulated as a two-stage optimal control problem, where the time-inconsistency issue arises in the outer problem. In the specific model setup with known model coefficients, we provide the full characterization of the time-consistent equilibrium singular controls for the two-stage problem. Taking advantage of the solution structure, we can consider the proper parameterization of the randomized equilibrium policy and the value function when the model is unknown and further devise the actor-critic reinforcement learning algorithms. In the numerical experiment, we present the superior convergence of parameter iterations towards the true values based on the randomized equilibrium policy and illustrate how the exploration may advance the learning performance in the context of singular controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02769v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zongxia Liang, Xiaodong Luo, Xiang Yu</dc:creator>
    </item>
    <item>
      <title>Asymptotic Analysis of Stochastic Splitting Methods for Multivariate Monotone Inclusions</title>
      <link>https://arxiv.org/abs/2512.03023</link>
      <description>arXiv:2512.03023v1 Announce Type: new 
Abstract: We propose an abstract framework to establish the convergence of the iterates of stochastic versions of a broad range of monotone operator splitting methods in Hilbert spaces. This framework allows for the introduction of stochasticity at several levels: approximation of operators, selection of coordinates and operators in block-iterative implementations, and relaxation parameters. The proposed analysis involves a reduced inclusion model with two operators. At each iteration, stochastic approximations to points in the graphs of these two operators are used to form the update. The results are applied to derive the almost sure and $L^2$ convergence of stochastic versions of the proximal point algorithm, as well as of randomized block-iterative projective splitting methods for solving systems of coupled inclusions involving a mix of set-valued, cocoercive, and Lipschitzian monotone operators combined via various monotonicity-preserving operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03023v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick L. Combettes, Javier I. Madariaga</dc:creator>
    </item>
    <item>
      <title>Verifying Closed-Loop Contractivity of Learning-Based Controllers via Partitioning</title>
      <link>https://arxiv.org/abs/2512.02262</link>
      <description>arXiv:2512.02262v1 Announce Type: cross 
Abstract: We address the problem of verifying closed-loop contraction in nonlinear control systems whose controller and contraction metric are both parameterized by neural networks. By leveraging interval analysis and interval bound propagation, we derive a tractable and scalable sufficient condition for closed-loop contractivity that reduces to checking that the dominant eigenvalue of a symmetric Metzler matrix is nonpositive. We combine this sufficient condition with a domain partitioning strategy to integrate this sufficient condition into training. The proposed approach is validated on an inverted pendulum system, demonstrating the ability to learn neural network controllers and contraction metrics that provably satisfy the contraction condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02262v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Davydov</dc:creator>
    </item>
    <item>
      <title>On Frequency-Weighted Extended Balanced Truncation</title>
      <link>https://arxiv.org/abs/2512.02298</link>
      <description>arXiv:2512.02298v1 Announce Type: cross 
Abstract: This paper addresses the problem of frequency-weighted extended balanced truncation for discrete and continuous-time linear time-invariant plants. We show that the frequency-weighted discrete-time plant admits block-diagonal solutions to both the Lyapunov inequality and its extended form. A recursive algorithm for extended balanced truncation is proposed, together with corresponding a-priori error bounds. Theoretical results are extended to continuous-time systems and validated through numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02298v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sribalaji C. Anand, Henrik Sandberg</dc:creator>
    </item>
    <item>
      <title>Risk-Sensitive Q-Learning in Continuous Time with Application to Dynamic Portfolio Selection</title>
      <link>https://arxiv.org/abs/2512.02386</link>
      <description>arXiv:2512.02386v1 Announce Type: cross 
Abstract: This paper studies the problem of risk-sensitive reinforcement learning (RSRL) in continuous time, where the environment is characterized by a controllable stochastic differential equation (SDE) and the objective is a potentially nonlinear functional of cumulative rewards. We prove that when the functional is an optimized certainty equivalent (OCE), the optimal policy is Markovian with respect to an augmented environment. We also propose \textit{CT-RS-q}, a risk-sensitive q-learning algorithm based on a novel martingale characterization approach. Finally, we run a simulation study on a dynamic portfolio selection problem and illustrate the effectiveness of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02386v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuhan Xie</dc:creator>
    </item>
    <item>
      <title>Necessary and Sufficient Conditions for PID Design of MIMO Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2512.02452</link>
      <description>arXiv:2512.02452v1 Announce Type: cross 
Abstract: As is well known, classical PID control is ubiquitous in industrial processes, yet a rigorous and explicit design theory for nonlinear uncertain MIMO second-order systems remains underdeveloped. In this paper we consider a class of such systems with both uncertain dynamics and an unknown but strictly positive input gain, where the nonlinear uncertainty is characterized by bounds on the Jacobian with respect to the state variables. We explicitly construct a three-dimensional region for the PID gains that is sufficient to guarantee global stability and asymptotic tracking of constant references for all nonlinearities satisfying these Jacobian bounds. We then derive a corresponding necessary region, thereby revealing the inherent conservatism required to cope with worst-case uncertainties. Moreover, under additional structural assumptions on the nonlinearities, these sufficient and necessary regions coincide, yielding a precise necessary-and-sufficient characterization of all globally stabilizing PID gains. All these regions are given in closed form and depend only on the prescribed Jacobian bounds and the known lower bound of the input gain, in contrast to many qualitative tuning methods in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02452v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyou Xiang, Cheng Zhao</dc:creator>
    </item>
    <item>
      <title>Monotone Near-Zero-Sum Games: A Generalization of Convex-Concave Minimax</title>
      <link>https://arxiv.org/abs/2512.02690</link>
      <description>arXiv:2512.02690v1 Announce Type: cross 
Abstract: Zero-sum and non-zero-sum (aka general-sum) games are relevant in a wide range of applications. While general non-zero-sum games are computationally hard, researchers focus on the special class of monotone games for gradient-based algorithms. However, there is a substantial gap between the gradient complexity of monotone zero-sum and monotone general-sum games. Moreover, in many practical scenarios of games the zero-sum assumption needs to be relaxed. To address these issues, we define a new intermediate class of monotone near-zero-sum games that contains monotone zero-sum games as a special case. Then, we present a novel algorithm that transforms the near-zero-sum games into a sequence of zero-sum subproblems, improving the gradient-based complexity for the class. Finally, we demonstrate the applicability of this new class to model practical scenarios of games motivated from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02690v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ruichen Luo, Sebastian U. Stich, Krishnendu Chatterjee</dc:creator>
    </item>
    <item>
      <title>Generative modeling using evolved quantum Boltzmann machines</title>
      <link>https://arxiv.org/abs/2512.02721</link>
      <description>arXiv:2512.02721v1 Announce Type: cross 
Abstract: Born-rule generative modeling, a central task in quantum machine learning, seeks to learn probability distributions that can be efficiently sampled by measuring complex quantum states. One hope is for quantum models to efficiently capture probability distributions that are difficult to learn and simulate by classical means alone. Quantum Boltzmann machines were proposed about one decade ago for this purpose, yet efficient training methods have remained elusive. In this paper, I overcome this obstacle by proposing a practical solution that trains quantum Boltzmann machines for Born-rule generative modeling. Two key ingredients in the proposal are the Donsker-Varadhan variational representation of the classical relative entropy and the quantum Boltzmann gradient estimator of [Patel et al., arXiv:2410.12935]. I present the main result for a more general ansatz known as an evolved quantum Boltzmann machine [Minervini et al., arXiv:2501.03367], which combines parameterized real- and imaginary-time evolution. I also show how to extend the findings to other distinguishability measures beyond relative entropy. Finally, I present four different hybrid quantum-classical algorithms for the minimax optimization underlying training, and I discuss their theoretical convergence guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02721v1</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark M. Wilde</dc:creator>
    </item>
    <item>
      <title>Tempering the Bayes Filter towards Improved Model-Based Estimation</title>
      <link>https://arxiv.org/abs/2512.02823</link>
      <description>arXiv:2512.02823v1 Announce Type: cross 
Abstract: Model-based filtering is often carried out while subject to an imperfect model, as learning partially-observable stochastic systems remains a challenge. Recent work on Bayesian inference found that tempering the likelihood or full posterior of an imperfect model can improve predictive accuracy, as measured by expected negative log likelihood. In this paper, we develop the tempered Bayes filter, improving estimation performance through both of the aforementioned, and one newly introduced, modalities. The result admits a recursive implementation with a computational complexity no higher than that of the original Bayes filter. Our analysis reveals that -- besides the well-known fact in the field of Bayesian inference that likelihood tempering affects the balance between prior and likelihood -- full-posterior tempering tunes the level of entropy in the final belief distribution. We further find that a region of the tempering space can be understood as interpolating between the Bayes- and MAP filters, recovering these as special cases. Analytical results further establish conditions under which a tempered Bayes filter achieves improved predictive performance. Specializing the results to the linear Gaussian case, we obtain the tempered Kalman filter. In this context, we interpret how the parameters affect the Kalman state estimate and covariance propagation. Empirical results confirm that our method consistently improves predictive accuracy over the Bayes filter baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02823v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Menno van Zutphen, Domagoj Herceg, Giannis Delimpaltadakis, Duarte J. Antunes</dc:creator>
    </item>
    <item>
      <title>Ergodic-risk Criterion for Stochastically Stabilizing Policy Optimization</title>
      <link>https://arxiv.org/abs/2409.10767</link>
      <description>arXiv:2409.10767v3 Announce Type: replace 
Abstract: This paper introduces ergodic-risk criteria, which capture long-term cumulative risks associated with controlled Markov chains through probabilistic limit theorems--in contrast to existing methods that require assumptions of either finite hitting time, finite state/action space, or exponentiation necessitating light-tailed distributions. Using tailored Functional Central Limit Theorems (FCLT), we demonstrate that the time-correlated terms in the ergodic-risk criteria converge under uniform ergodicity and establish conditions for the convergence of these criteria in non-stationary general-state Markov chains involving heavy-tailed distributions. For quadratic risk functionals on stochastic linear systems, in addition to internal stability, this requires the (possibly heavy-tailed) process noise to have only a finite fourth moment. After quantifying cumulative uncertainties in risk functionals that account for extreme deviations, these ergodic-risk criteria are then incorporated into policy optimizations, thereby extending the standard average optimal synthesis to a risk-sensitive framework. Finally, by establishing the strong duality of the constrained policy optimization, we propose a primal-dual algorithm that optimizes average performance while ensuring that certain risks associated with these ergodic-risk criteria are constrained. Our risk-sensitive framework offers a theoretically guaranteed policy iteration for the long-term risk-sensitive control of processes involving heavy-tailed noise, which is shown to be effective through several simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10767v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shahriar Talebi, Na Li</dc:creator>
    </item>
    <item>
      <title>Online Convex Optimization with Memory and Limited Predictions</title>
      <link>https://arxiv.org/abs/2410.23574</link>
      <description>arXiv:2410.23574v2 Announce Type: replace 
Abstract: This paper addresses an online convex optimization problem where the cost function at each step depends on a history of past decisions (i.e., memory), and the decision maker has access to limited predictions of future cost values within a finite window. The goal is to design an algorithm that minimizes the dynamic regret against the optimal sequence of decisions in hindsight. To this end, we propose a novel predictive algorithm and establish strong theoretical guarantees for its performance. We show that the algorithm's dynamic regret decays exponentially with the length of the prediction window. Our algorithm comprises two general subroutines of independent interest. The first subroutine solves online convex optimization with memory and bandit feedback, achieving a $\sqrt{TV_T}$-dynamic regret, where $V_T$ measures the variation of the optimal decision sequence. The second is a zeroth-order method that attains a linear convergence rate for general convex optimization, matching the best achievable rate of first-order methods. The key to our algorithm is a novel truncated Gaussian smoothing technique when querying the decision points to obtain the predictions. We validate our theoretical results with numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23574v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengmiao Wang, Zhi-Wei Liu, Ming Chi, Xiaoling Wang, Housheng Su, Lintao Ye</dc:creator>
    </item>
    <item>
      <title>Reducing Stochastic Games to Semidefinite Program Feasibility</title>
      <link>https://arxiv.org/abs/2411.09646</link>
      <description>arXiv:2411.09646v2 Announce Type: replace 
Abstract: We present a polynomial-time reduction from max-plus-average constraints to the feasibility problem for semidefinite programs. This shows that Condon's simple stochastic games, stochastic mean payoff games, and in particular mean payoff games and parity games can all be reduced to semidefinite programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09646v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Bodirsky, Georg Loho, Mateusz Skomra</dc:creator>
    </item>
    <item>
      <title>Decentralized Projection-free Online Upper-Linearizable Optimization with Applications to DR-Submodular Optimization</title>
      <link>https://arxiv.org/abs/2501.18183</link>
      <description>arXiv:2501.18183v2 Announce Type: replace 
Abstract: We introduce a novel framework for decentralized projection-free optimization, extending projection-free methods to a broader class of upper-linearizable functions. Our approach leverages decentralized optimization techniques with the flexibility of upper-linearizable function frameworks, effectively generalizing traditional DR-submodular function optimization. We obtain the regret of $O(T^{1-\theta/2})$ with communication complexity of $O(T^{\theta})$ and number of linear optimization oracle calls of $O(T^{2\theta})$ for decentralized upper-linearizable function optimization, for any $0\le \theta \le 1$. This approach allows for the first results for monotone up-concave optimization with general convex constraints and non-monotone up-concave optimization with general convex constraints. Further, the above results for first order feedback are extended to zeroth order, semi-bandit, and bandit feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18183v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiyang Lu, Mohammad Pedramfar, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Multiobjective Aerodynamic Design Optimization of the NASA Common Research Model</title>
      <link>https://arxiv.org/abs/2507.10488</link>
      <description>arXiv:2507.10488v2 Announce Type: replace 
Abstract: Aircraft aerodynamic design optimization must account for the varying operating conditions along the cruise segment as opposed to designing at one fixed operating condition, to arrive at more realistic designs. Conventional approaches address this by performing a ``multi-point'' optimization that assumes a weighted average of the objectives at a set of sub-segments along the cruise segment. We argue that since such multi-point approaches are, inevitably, biased by the specification of the weights, they can lead to sub-optimal designs. Instead, we propose to optimize the aircraft design at multiple sub-segments simultaneously -- that is, via multiobjective optimization that leads to a set of Pareto optimal solutions. However, existing work in multiobjective optimization suffers from (i) lack of sample efficiency (that is, keeping the number of function evaluations to convergence minimal), (ii) scalability {in the absence of derivative information}, and (iii) the ability to generate a batch of iterates for synchronous parallel evaluations. To overcome these limitations, we {apply} a novel multiobjective Bayesian optimization methodology {for aerodynamic design optimization} that demonstrates improved sample efficiency and accuracy compared to the state of the art. Inspired by Thompson sampling, our approach leverages Gaussian process surrogates and Bayesian decision theory to generate a sequence of iterates according to the probability that they are Pareto optimal. Our approach, named batch Pareto optimal Thompson sampling (\qpots)\footnote{Here, $q$ stands for selecting a batch of $q$ iterates at every step.}, demonstrates superior empirical performance on a variety of synthetic experiments as well as a $24$ dimensional two-objective aerodynamic design optimization of the NASA common research model. We also provide open-source software of our methodology {and experiments}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10488v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ast.2025.111120</arxiv:DOI>
      <dc:creator>Kade Carlson, Ashwin Renganathan</dc:creator>
    </item>
    <item>
      <title>Relaxed and inertial nonlinear Forward-Backward algorithm</title>
      <link>https://arxiv.org/abs/2507.18856</link>
      <description>arXiv:2507.18856v2 Announce Type: replace 
Abstract: The Nonlinear Forward-Backward (NFB) algorithm, also known as warped resolvent iterations, is a splitting method for finding zeros of sums of monotone operators. In particular cases, NFB reduces to well-known algorithms such as Forward-Backward, Forward-Backward-Forward, Chambolle--Pock, and Condat--V\~u. Therefore, NFB can be used to solve monotone inclusions involving sums of maximally monotone, cocoercive, monotone and Lipschitz operators as well as linear compositions terms. In this article, we study the weak and strong (linear) convergence of NFB with inertial and relaxation steps. Our results recover known convergence guarantees for the aforementioned methods when extended with inertial and relaxation terms. Additionally, we establish the convergence of inertial and relaxed variants of the Forward-Backward-Half-Forward and Forward-Primal--Dual-Half-Forward algorithms, which, to the best of our knowledge, are new contributions. We consider both nondecreasing and decreasing sequences of inertial parameters, the latter being a novel approach in the context of inertial algorithms. To evaluate the performance of these strategies, we present numerical experiments on optimization problems with affine constraints and on image restoration tasks. Our results show that decreasing inertial sequences can accelerate the numerical convergence of the algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18856v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Jos\'e Maul\'en, Fernando Rold\'an, Cristian Vega</dc:creator>
    </item>
    <item>
      <title>EV Charging in Smart Grids: Mean Field Equilibrium and Approximate Non-Cooperative and Cooperative Strategies</title>
      <link>https://arxiv.org/abs/2509.04963</link>
      <description>arXiv:2509.04963v2 Announce Type: replace 
Abstract: We study the optimal charging strategies for large-scale electric vehicles in smart grids within a finite-horizon mean field game framework. We first establish the existence and uniqueness of the solution to the consistency condition equation, which characterizes the optimal charging behavior in the mean field limit. Building on this result, we construct approximate optimal charging strategies for a finite population of vehicles in both non-cooperative and cooperative settings. Finally, we provide numerical analyses that illustrate and compare the approximate strategies in the non-cooperative and cooperative games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04963v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Fengcheng Liu, Shihua Wang</dc:creator>
    </item>
    <item>
      <title>Optimization in Theory and Practice</title>
      <link>https://arxiv.org/abs/2510.15734</link>
      <description>arXiv:2510.15734v2 Announce Type: replace 
Abstract: Algorithms for continuous optimization problems have a rich history of design and innovation over the past several decades, in which mathematical analysis of their convergence and complexity properties plays a central role. Besides their theoretical properties, optimization algorithms are interesting also for their practical usefulness as computational tools for solving real-world problems. There are often gaps between the practical performance of an algorithm and what can be proved about it. These two facets of the field -- the theoretical and the practical -- interact in fascinating ways, each driving innovation in the other. This work focuses on the development of algorithms in two areas -- linear programming and unconstrained minimization of smooth functions -- outlining major algorithm classes in each area along with their theoretical properties and practical performance, and highlighting how advances in theory and practice have influenced each other in these areas. In discussing theory, we focus mainly on non-asymptotic complexity, which are upper bounds on the amount of computation required by a given algorithm to find an approximate solution of problems in a given class.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15734v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stephen J. Wright</dc:creator>
    </item>
    <item>
      <title>The fastest way through a traffic light</title>
      <link>https://arxiv.org/abs/2511.09530</link>
      <description>arXiv:2511.09530v3 Announce Type: replace 
Abstract: We give a rigorous solution of an optimisation problem of minimizing the expected delay caused by encountering a red traffic light on a road journey. The problem incorporates simple constraints on maximum speed, acceleration and braking rates, and depends on the assumed distribution of the remaining time until the traffic light will turn green, after it is first noticed. We assume that this distribution has a bounded and non-increasing density, which is natural since this holds for the law of the excess time in any stationary renewal process. In two special cases, where this distribution is either Uniform or Exponential, we give a complete characterisation of all possible combinations of phases of maximum acceleration, maximum speed, maximum braking, following an Euler--Lagrange curve, and standing stationary at the traffic light, which can make up an optimal solution. The key technique is to write the problem in terms of a two-dimensional pressure integral, so that the problem becomes analogous to filling a tank with a given quantity of liquid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09530v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M\'arton Bal\'azs, Edward Crane, Alexander Tallis</dc:creator>
    </item>
    <item>
      <title>Quick Updates for the Perturbed Static Output Feedback Control Problem in Linear Systems with Applications to Power Systems</title>
      <link>https://arxiv.org/abs/2307.16178</link>
      <description>arXiv:2307.16178v5 Announce Type: replace-cross 
Abstract: This paper introduces a method for efficiently updating a nominal stabilizing static output feedback (SOF) controller in perturbed linear systems. As operating points and state-space matrices change in dynamic systems, accommodating updates to the SOF controller are necessary. Traditional methods address such changes by re-solving for the updated SOF gain, which is often (i) computationally expensive due to the NP-hard nature of the problem or (ii) infeasible due to the limitations of its semidefinite programming relaxations. To overcome this, we leverage the concept of minimum destabilizing real perturbation (MDRP) to formulate a norm minimization problem that yields fast, reliable controller updates. This approach accommodates a variety of known perturbations, including abrupt changes, model inaccuracies, and equilibrium-dependent linearizations. We remark that the application of our proposed approach is limited to the class of SOF controllers in perturbed linear systems. We also introduce geometric metrics to quantify the proximity to instability and rigorously define stability-guaranteed regions. Extensive numerical simulations validate the efficiency and robustness of the proposed method. Moreover, such extensive numerical simulations corroborate that although we utilize a heuristic optimization method to compute the MDRP, it performs quite well in practice compared to an existing approximation method in the literature, namely the hybrid expansion-contraction (HEC) method. We demonstrate the results on the SOF control of multi-machine power networks with changing operating points, and demonstrate that the computed quick updates produce comparable solutions to the traditional SOF ones, while requiring orders of magnitude less computational time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.16178v5</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>MirSaleh Bahavarnia, Ahmad F. Taha</dc:creator>
    </item>
    <item>
      <title>Feedback stabilization for a spatial-dependent Sterile Insect Technique model with Allee Effect</title>
      <link>https://arxiv.org/abs/2502.03898</link>
      <description>arXiv:2502.03898v2 Announce Type: replace-cross 
Abstract: This work focuses on feedback control strategies for applying the sterile insect technique (SIT) to eliminate pest populations. The presentation is centered on the case of mosquito populations, but most of the results can be extended to other species by adapting the model and selecting appropriate parameter values to describe the reproduction and movement dynamics of the species under consideration. In our study, we address the spatial distribution of the population in a two dimensional bounded domain by extending the temporal SIT model analyzed in [2], thereby obtaining a reaction-diffusion SIT model. After the analysis of the existence and the uniqueness of the solution of this problem, we construct a feedback law that globally asymptotically stabilizes the extinction equilibrium thus yielding a robust strategy to keep the pest population at very low levels in the long term.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03898v2</guid>
      <category>math.AP</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kala Agbo Bidi (LJLL), Lu\'is Almeida (SU, UPCit\'e, LPSM), Jean-Michel Coron (LJLL)</dc:creator>
    </item>
    <item>
      <title>Coordinated Decentralized Resource Optimization for Cell-Free ISAC Systems</title>
      <link>https://arxiv.org/abs/2508.01044</link>
      <description>arXiv:2508.01044v2 Announce Type: replace-cross 
Abstract: Integrated Sensing and Communication (ISAC) is emerging as a key enabler for 6G wireless networks, allowing the joint use of spectrum and infrastructure for both communication and sensing. While prior ISAC solutions have addressed resource optimization, including power allocation, beamforming, and waveform design, they often rely on centralized architectures with full network knowledge, limiting their scalability in distributed systems. In this paper, we propose two coordinated decentralized optimization algorithms for beamforming and power allocation tailored to cell-free ISAC networks. The first algorithm employs locally designed fixed beamformers at access points (APs), combined with a centralized power allocation scheme computed at a central server (CS). The second algorithm jointly optimizes beamforming and power control through a fully decentralized consensus ADMM framework. Both approaches rely on local information at APs and limited coordination with the CS. Simulation results obtained using our proposed Python-based simulation framework evaluate their fronthaul overhead and system-level performance, demonstrating their practicality for scalable ISAC deployment in decentralized, cell-free architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01044v2</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehdi Zafari, Rang Liu, A. Lee Swindlehurst</dc:creator>
    </item>
    <item>
      <title>Non-stationary and Varying-discounting Markov Decision Processes for Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2511.17598</link>
      <description>arXiv:2511.17598v2 Announce Type: replace-cross 
Abstract: Algorithms developed under stationary Markov Decision Processes (MDPs) often face challenges in non-stationary environments, and infinite-horizon formulations may not directly apply to finite-horizon tasks. To address these limitations, we introduce the Non-stationary and Varying-discounting MDP (NVMDP) framework, which naturally accommodates non-stationarity and allows discount rates to vary with time and transitions. Infinite-horizon, stationary MDPs emerge as special cases of NVMDPs for identifying an optimal policy, and finite-horizon MDPs are also subsumed within the NVMDP formulations. Moreover, NVMDPs provide a flexible mechanism to shape optimal policies, without altering the state space, action space, or the reward structure. We establish the theoretical foundations of NVMDPs, including assumptions, state- and action-value formulation and recursion, matrix representation, optimality conditions, and policy improvement under finite state and action spaces. Building on these results, we adapt dynamic programming and generalized Q-learning algorithms to NVMDPs, along with formal convergence proofs. For problems requiring function approximation, we extend the Policy Gradient Theorem and the policy improvement bound in Trust Region Policy Optimization (TRPO), offering proofs in both scalar and matrix forms. Empirical evaluations in a non-stationary gridworld environment demonstrate that NVMDP-based algorithms successfully recover optimal trajectories under multiple reward and discounting schemes, whereas original Q-learning fails. These results collectively show that NVMDPs provide a theoretically sound and practically effective framework for reinforcement learning, requiring only minor algorithmic modifications while enabling robust handling of non-stationarity and explicit optimal policy shaping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17598v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhizuo Chen, Theodore T. Allen</dc:creator>
    </item>
    <item>
      <title>Mean-Field Limits for Two-Layer Neural Networks Trained with Consensus-Based Optimization</title>
      <link>https://arxiv.org/abs/2511.21466</link>
      <description>arXiv:2511.21466v2 Announce Type: replace-cross 
Abstract: We study Consensus-Based Optimization (CBO) for two-layer neural network training. We compare the performance of CBO against Adam on two test cases and demonstrate how a hybrid approach, combining CBO with Adam, provides faster convergence than CBO. Additionally, in the context of multi-task learning, we recast CBO into a formulation that offers less memory overhead. The CBO method allows for a mean-field limit formulation, which we couple with the mean-field limit of the neural network. To this end, we first reformulate CBO within the optimal transport framework. In the limit of infinitely many particles, we define the corresponding dynamics on the Wasserstein-over-Wasserstein space and show that the variance decreases monotonically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21466v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William De Deyn, Michael Herty, Giovanni Samaey</dc:creator>
    </item>
  </channel>
</rss>
