<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Aug 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Distributional Robustness in Output Feedback Regret-Optimal Control</title>
      <link>https://arxiv.org/abs/2508.10150</link>
      <description>arXiv:2508.10150v1 Announce Type: new 
Abstract: This paper studies distributionally robust regret-optimal (DRRO) control with purified output feedback for linear systems subject to additive disturbances and measurement noise. These uncertainties (including the initial system state) are assumed to be stochastic and distributed according to an unknown joint probability distribution within a Wasserstein ambiguity set. We design affine controllers to minimise the worst-case expected regret over all distributions in this set. The expected regret is defined as the difference between an expected cost incurred by an affine causal controller and the expected cost incurred by the optimal noncausal controller with perfect knowledge of the disturbance trajectory at the outset. Leveraging the duality theory in distributionally robust optimisation, we derive strong duality results for worst-case expectation problems involving general quadratic objective functions, enabling exact reformulations of the DRRO control problem as semidefinite programs (SDPs). Focusing on one such reformulation, we eliminate certain decision variables. This technique also permits a further equivalent reformulation of the SDP as a distributed optimisation problem, with potential to enhance scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10150v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuhao Yan, Carsten W. Scherer</dc:creator>
    </item>
    <item>
      <title>Closed-loop strong equilibria for time-inconsistent control problems with higher-order moments</title>
      <link>https://arxiv.org/abs/2508.10181</link>
      <description>arXiv:2508.10181v1 Announce Type: new 
Abstract: In this paper, we study closed-loop strong equilibrium strategies for the time-inconsistent control problem with higher-order moments formulated by [Wang et al. SIAM J. Control. Optim., 63 (2025), 1560--1589]. Since time-inconsistency makes the dynamic programming principle inapplicable, the problem is treated as a game between the decision maker and her future selves. As a time-consistent solution, the previously proposed Nash equilibrium control is merely a stationary point and does not necessarily reach a maximum in the game-theoretical prospective. To address this issue, we consider the strong equilibrium strategy, from which any spike deviation will be worse off. We derive sufficient conditions for strong equilibrium strategies by expanding the objective function corresponding to the spike deviation with respect to the variational factor up to higher orders, and simplify the result by exploiting the partial differential equations that a Nash equilibrium control satisfies. Next, we examine whether the derived Nash equilibrium control is a strong equilibrium strategy. In particular, we provide a sufficient condition for the case with linear controlled equations. When the model parameters are constant, we find that the derived Nash equilibrium control for the mean-variance problem must be a strong equilibrium strategy, while that for the mean-variance-skewness-kurtosis problem is not necessarily a strong equilibrium strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10181v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yike Wang</dc:creator>
    </item>
    <item>
      <title>Improving Quasi-Newton Methods via Image and Projection Operators</title>
      <link>https://arxiv.org/abs/2508.10211</link>
      <description>arXiv:2508.10211v1 Announce Type: new 
Abstract: Designing efficient quasi-Newton methods is an important problem in nonlinear optimization and the solution of systems of nonlinear equations. From the perspective of the matrix approximation process, this paper presents a unified framework for establishing the quadratic termination property that covers the Broyden family, the generalized PSB family, and good Broyden method. Based on this framework, we employ operators to map the correction direction $s_k$ in the quasi-Newton equation to a specific subspace, which ensures quadratic termination for these three classes of methods without relying on exact line searches. We derive the corresponding image and projection operators, analyze their improved properties in matrix approximation, and design practical algorithms accordingly. Preliminary numerical results show that the proposed operator-based methods yield significant improvements in the performance of the Davidon-Fletcher-Powell (DFP), Broyden-Fletcher-Goldfarb-Shanno (BFGS), Powell-Symmetric-Broyden (PSB), limited-memory BFGS (L-BFGS) and Broyden's ``good'' methods (BGM).</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10211v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenyuan Ji</dc:creator>
    </item>
    <item>
      <title>Joint Planning and Operations of Wind Power under Decision-dependent Uncertainty</title>
      <link>https://arxiv.org/abs/2508.10437</link>
      <description>arXiv:2508.10437v1 Announce Type: new 
Abstract: We study a joint wind farm planning and operational scheduling problem under decision-dependent uncertainty. The objective is to determine the optimal number of wind turbines at each location to minimize total cost, including both investment and operational expenses. Due to the stochastic nature and geographical heterogeneity of wind power, fluctuations across dispersed wind farms can partially offset one another, thereby influencing the distribution of aggregated wind power generation-a phenomenon known as the smoothing effect. Effectively harnessing this effect requires strategic capacity allocation, which introduces decision-dependent uncertainty into the planning process. To address this challenge, we propose a two-stage distributionally robust optimization model with a decision-dependent Wasserstein ambiguity set, in which both the distribution and the radius are modeled as functions of the planning decisions, reflecting the statistical characteristics of wind power resources. Then, we reformulate the model as a mixed-integer second-order cone program, and the optimal objective value provides a probabilistic guarantee on the out-of-sample performance. To improve computational efficiency, we develop a constraint generation based solution framework that accelerates the solution procedure by hundreds of times. Numerical experiments using different datasets validate the effectiveness of the solution framework and demonstrate the superior performance of the proposed model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10437v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiqiang Chen, Caihua Chen, Jingshi Cui, Qian Hu, Wei Xu</dc:creator>
    </item>
    <item>
      <title>Onboard Dual Quaternion Guidance for Rocket Landing</title>
      <link>https://arxiv.org/abs/2508.10439</link>
      <description>arXiv:2508.10439v1 Announce Type: new 
Abstract: The dual quaternion guidance (DQG) algorithm was selected as the candidate 6-DoF powered-descent guidance algorithm for NASA's Safe and Precise Landing -- Integrated Capabilities Evolution (SPLICE) project. DQG is capable of handling state-triggered constraints that are of utmost importance in terms of enabling technologies such as terrain relative navigation. In this work, we develop a custom solver for DQG to enable onboard implementation for future rocket landing missions. We describe the design and implementation of a real-time-capable optimization framework, called sequential conic optimization (SeCO), that blends together sequential convex programming and first-order conic optimization to solve difficult nonconvex trajectory optimization problems, such as DQG, in real-time. A key feature of SeCO is that it leverages a first-order primal-dual conic optimization solver, based on the proportional-integral projected gradient method (PIPG). We describe the implementation of this solver, develop customizable first-order methods, and leverage convergence-accelerating strategies such as warm-starting and extrapolation, to solve the nonconvex DQG optimal control problem in real-time. Finally, in preparation for an upcoming closed-loop flight test campaign, we test our custom solver onboard the NASA SPLICE Descent and Landing Computer in a hardware-in-the-loop setting. We observe that our algorithm is significantly faster than previously reported solve-times using the flight-tested interior point method-based subproblem solver, BSOCP. Furthermore, our custom solver meets (and exceeds) NASA's autonomous precision rocket-landing guidance update-rate requirements for the first time, thus demonstrating the viability of SeCO for real-time, mission-critical applications onboard computationally-constrained flight hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10439v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhinav G. Kamath, Javier A. Doll, Purnanand Elango, Taewan Kim, Skye Mceowen, Yue Yu, Taylor P. Reynolds, Gavin F. Mendeck, John M. Carson III, Mehran Mesbahi, Beh\c{c}et A\c{c}{\i}kme\c{s}e</dc:creator>
    </item>
    <item>
      <title>A Dual Quaternion Control Law for Formation Control of Multiple 3-D Rigid Bodies</title>
      <link>https://arxiv.org/abs/2508.10519</link>
      <description>arXiv:2508.10519v1 Announce Type: new 
Abstract: This paper studies the integrated position and attitude control problem for multi-agent systems of 3D rigid bodies. While the state-of-the-art method in [Olfati-Saber and Murray, 2004] established the theoretical foundation for rigid-body formation control, it requires all agents to asymptotically converge to identical positions and attitudes, limiting its applicability in scenarios where distinct desired relative configurations must be maintained. In this paper, we develop a novel dual-quaternion-based framework that generalizes this paradigm. By introducing a unit dual quaternion directed graph (UDQDG) representation, we derive a new control law through the corresponding Laplacian matrix, enabling simultaneous position and attitude coordination while naturally accommodating directed interaction topologies. Leveraging the recent advances in UDQDG spectral theory, we prove global asymptotic convergence to desired relative configurations modulo a right-multiplicative constant and establish an R-linear convergence rate determined by the second smallest eigenvalue of the UDQDG Laplacian. A projected iteration method is proposed to compute the iterative states. Finally, the proposed solution is verified by several numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10519v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunfeng Cui, Liqun Qi, Hao Chen, Xiangke Wang</dc:creator>
    </item>
    <item>
      <title>On the computation of the infinity Wasserstein distance and the Wasserstein Projection Problem</title>
      <link>https://arxiv.org/abs/2508.10589</link>
      <description>arXiv:2508.10589v1 Announce Type: new 
Abstract: Computing the infinity Wasserstein distance and retrieving projections of a probability measure onto a closed subset of probability measures are critical sub-problems in various applied fields. However, the practical applicability of these objects is limited by two factors: either the associated quantities are computationally prohibitive or there is a lack of available algorithms capable of calculating them. In this paper, we propose a novel class of Linear Programming problems and a routine that allows us to compute the infinity Wasserstein distance and to compute a projection of a probability measure over a generic subset of probability measures with respect to any $p$-Wasserstein distance with $p\in[1,\infty]$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10589v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gennaro Auricchio, Gabriele Loli, Marco Veneroni</dc:creator>
    </item>
    <item>
      <title>Computable Robustness Bounds to Transition and Measurement Kernel Perturbations and Approximations in Partially Observable Stochastic Control</title>
      <link>https://arxiv.org/abs/2508.10658</link>
      <description>arXiv:2508.10658v1 Announce Type: new 
Abstract: Studying the stability of partially observed Markov decision processes (POMDPs) with respect to perturbations in either transition or observation kernels is a mathematically and practically important problem. While asymptotic robustness/stability results showing that as approximate transition kernels and/or measurement kernels converge to the true ones in appropriate senses have been previously reported, explicit and uniform bounds on value differences and mismatch costs have not been studied to our knowledge. In this paper, we provide such explicit bounds under both discounted and average cost criteria. The bounds are given in terms of Wasserstein and total variation distances between the original and approximate transition kernels, and total variation distances between observation channels. In particular, we show that control policies optimized for approximate models yield performance guarantees when applied to the true model with explicit bounds. As a particular application, we consider the case where the state space and the measurement spaces are quantized to obtain finite models, and we obtain explicit error bounds which decay to zero as the approximations get finer. This provides explicit performance guarantees for model reduction in POMDPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10658v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunus Emre Demirci, Ali Devran Kara, Serdar Y\"uksel</dc:creator>
    </item>
    <item>
      <title>A trust-region method for optimal control of ODEs with continuous-or-off controls and TV regularization</title>
      <link>https://arxiv.org/abs/2508.10692</link>
      <description>arXiv:2508.10692v1 Announce Type: new 
Abstract: A solution algorithm for a special class of optimal control problems subject to an ordinary differential equation is proposed. The controls possess a continuous-or-off structure and are priced by a convex function. Additionally a total variation regularization is applied to penalize switches. Our solution method combines a trust-region method and a proximal gradient method. The subproblems are solved via Bellman's optimality principle. Convergence with respect to a criticality measure is proven. As a numerical example, we solve a simple optimal control problem involving an SIR model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10692v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Markus Friedemann, Gerd Wachsmuth</dc:creator>
    </item>
    <item>
      <title>Accelerating Stochastic Energy System Optimization Models: Temporally Split Benders Decomposition</title>
      <link>https://arxiv.org/abs/2508.10789</link>
      <description>arXiv:2508.10789v1 Announce Type: new 
Abstract: Stochastic programming can be applied to consider uncertainties in energy system optimization models for capacity expansion planning. However, these models become increasingly large and time-consuming to solve, even without considering uncertainties. For two-stage stochastic capacity expansion planning problems, Benders decomposition is often applied to ensure that the problem remains solvable. Since stochastic scenarios can be optimized independently within subproblems, their optimization can be parallelized. However, hourly-resolved capacity expansion planning problems typically have a larger temporal than scenario cardinality. Therefore, we present a temporally split Benders decomposition that further exploits the parallelization potential of stochastic expansion planning problems. A compact reformulation of the storage level constraint into linking variables ensures that long-term storage operation can still be optimized despite the temporal decomposition. We demonstrate this novel approach with model instances of the German power system with up to 87 million rows and columns. Our results show a reduction in computing times of up to 60% and reduced memory requirements. Additional enhancement strategies and the use of distributed memory on high-performance computers further improve the computing time by over 80%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10789v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shima Sasanpour, Manuel Wetzel, Karl-Ki\^en Cao, Hans Christian Gils, Andr\'es Ramos</dc:creator>
    </item>
    <item>
      <title>An inverse problem on a metric graph with cycle</title>
      <link>https://arxiv.org/abs/2508.10121</link>
      <description>arXiv:2508.10121v1 Announce Type: cross 
Abstract: Consider a quantum graph consisting of a ring with two attached edges, and assume Kirchhoff-Neumann conditions hold at the internal vertices. Associated to this graph is a Schr\"{o}dinger type operator $L=-\Delta +q(x)$ with Dirichlet boundary conditions at the two boundary nodes. Let $\{ \omega_n^2, \ \varphi_n(x)\}$ be the eigenvalues and associated normalized eigenfunctions. Let $v_1$ be a boundary vertex, and $v_2$ the adjacent internal vertex. Assume we know the following data: $\{ \omega_n^2,\partial_x \varphi_n(v_1),\partial_x\varphi_n(v_2)\}.$ Here $\partial_x\varphi_n(v_2)$ refers to an outward normal derivative at $v_2$ along one of the edges incident to the other internal vertex. From this data we determine the following unknown quantities: the lengths of edges and the potential functions on each edge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10121v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergei Avdonin, Julian Edward</dc:creator>
    </item>
    <item>
      <title>Incorporating Taxonomies of Cyber Incidents Into Detection Networks for Improved Detection Performance</title>
      <link>https://arxiv.org/abs/2508.10187</link>
      <description>arXiv:2508.10187v1 Announce Type: cross 
Abstract: Many taxonomies exist to organize cybercrime incidents into ontological categories. We examine some of the taxonomies introduced in the literature; providing a framework, and analysis, of how best to leverage different taxonomy structures to optimize performance of detections targeting various types of threat-actor behaviors under the umbrella of precision and recall. Networks of detections are studied, and results are outlined showing properties of networks of interconnected detections. Some illustrations are provided to show how the construction of sets of detections to prevent broader types of attacks is limited by trade-offs in precision and recall under constraints. An equilibrium result is proven and validated on simulations, illustrating the existence of an optimal detection design strategy in this framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10187v1</guid>
      <category>stat.ME</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ryan Warnick</dc:creator>
    </item>
    <item>
      <title>Systematic Constraint Formulation and Collision-Free Trajectory Planning Using Space-Time Graphs of Convex Sets</title>
      <link>https://arxiv.org/abs/2508.10203</link>
      <description>arXiv:2508.10203v1 Announce Type: cross 
Abstract: In this paper, we create optimal, collision-free, time-dependent trajectories through cluttered dynamic environments. The many spatial and temporal constraints make finding an initial guess for a numerical solver difficult. Graphs of Convex Sets (GCS) and the recently developed Space-Time Graphs of Convex Sets formulation (ST-GCS) enable us to generate optimal minimum distance collision-free trajectories without providing an initial guess to the solver. We also explore the derivation of general GCS-compatible constraints and document an intuitive strategy for adapting general constraints to the framework. We show that ST-GCS produces equivalent trajectories to the standard GCS formulation when the environment is static. We then show ST-GCS operating in dynamic environments to find minimum distance collision-free trajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10203v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew D. Osburn, Cameron K. Peterson, John L. Salmon</dc:creator>
    </item>
    <item>
      <title>Pinet: Optimizing hard-constrained neural networks with orthogonal projection layers</title>
      <link>https://arxiv.org/abs/2508.10480</link>
      <description>arXiv:2508.10480v1 Announce Type: cross 
Abstract: We introduce an output layer for neural networks that ensures satisfaction of convex constraints. Our approach, $\Pi$net, leverages operator splitting for rapid and reliable projections in the forward pass, and the implicit function theorem for backpropagation. We deploy $\Pi$net as a feasible-by-design optimization proxy for parametric constrained optimization problems and obtain modest-accuracy solutions faster than traditional solvers when solving a single problem, and significantly faster for a batch of problems. We surpass state-of-the-art learning approaches in terms of training time, solution quality, and robustness to hyperparameter tuning, while maintaining similar inference times. Finally, we tackle multi-vehicle motion planning with non-convex trajectory preferences and provide $\Pi$net as a GPU-ready package implemented in JAX with effective tuning heuristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10480v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Panagiotis D. Grontas, Antonio Terpin, Efe C. Balta, Raffaello D'Andrea, John Lygeros</dc:creator>
    </item>
    <item>
      <title>A Unified Framework from Boltzmann Transport to Proton Treatment Planning</title>
      <link>https://arxiv.org/abs/2508.10596</link>
      <description>arXiv:2508.10596v1 Announce Type: cross 
Abstract: This work develops a rigorous mathematical formulation of proton transport by integrating both deterministic and stochastic perspectives. The deterministic framework is based on the Boltzmann-Fokker-Planck equation, formulated as an operator equation in a suitable functional setting. The stochastic approach models proton evolution via a track-length parameterised diffusion process, whose infinitesimal generator provides an alternative description of transport.
  A key result is the duality between the stochastic and deterministic formulations, established through the adjoint relationship between the transport operator and the stochastic generator. We prove that the resolvent of the stochastic process corresponds to the Green's function of the deterministic equation, providing a natural link between fluence-based and particle-based transport descriptions. The theory is applied to dose computation, where we show that the classical relation: dose = (fluence * mass stopping power) arises consistently in both approaches.
  Building on this foundation, we formulate a hybrid optimisation framework for treatment planning, in which dose is computed using a stochastic model while optimisation proceeds via adjoint-based PDE methods. We prove existence and differentiability of the objective functional and derive the first-order optimality system. This framework bridges stochastic simulation with deterministic control theory and provides a foundation for future work in constrained, adaptive and uncertainty-aware optimisation in proton therapy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10596v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>physics.med-ph</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas E. Kyprianou, Aaron Pim, Tristan Pryer</dc:creator>
    </item>
    <item>
      <title>Variance Reduced Policy Gradient Method for Multi-Objective Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2508.10608</link>
      <description>arXiv:2508.10608v1 Announce Type: cross 
Abstract: Multi-Objective Reinforcement Learning (MORL) is a generalization of traditional Reinforcement Learning (RL) that aims to optimize multiple, often conflicting objectives simultaneously rather than focusing on a single reward. This approach is crucial in complex decision-making scenarios where agents must balance trade-offs between various goals, such as maximizing performance while minimizing costs. We consider the problem of MORL where the objectives are combined using a non-linear scalarization function. Just like in standard RL, policy gradient methods (PGMs) are amongst the most effective for handling large and continuous state-action spaces in MORL. However, existing PGMs for MORL suffer from high sample inefficiency, requiring large amounts of data to be effective. Previous attempts to solve this problem rely on overly strict assumptions, losing PGMs' benefits in scalability to large state-action spaces. In this work, we address the issue of sample efficiency by implementing variance-reduction techniques to reduce the sample complexity of policy gradients while maintaining general assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10608v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Guidobene, Lorenzo Benedetti, Diego Arapovic</dc:creator>
    </item>
    <item>
      <title>Two-Instrument Screening under Soft Budget Constraints</title>
      <link>https://arxiv.org/abs/2508.10724</link>
      <description>arXiv:2508.10724v1 Announce Type: cross 
Abstract: We study soft budget constraints in multi-tier public finance when an upper-tier government uses two instruments: an ex-ante grant schedule and an ex-post rescue. Under convex rescue costs and standard primitives, the three-stage leader-follower problem collapses to one dimensional screening with a single allocation index: the cap on realized rescue. A hazard-based characterization delivers a unified rule that nests (i) no rescue, (ii) a threshold-cap with commitment, and (iii) a threshold--linear--cap without commitment. The knife-edge for eliminating bailouts compares the marginal cost at the origin to the supremum of a virtual weight, and the comparative statics show how greater curvature tightens caps while discretion shifts transfers toward front loading by lowering the effective grant weight. The framework provides a portable benchmark for mechanism design and yields testable implications for policy and empirical work on intergovernmental finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10724v1</guid>
      <category>econ.TH</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinli Guo</dc:creator>
    </item>
    <item>
      <title>An Efficient Model-Driven Groupwise Approach for Atlas Construction</title>
      <link>https://arxiv.org/abs/2508.10743</link>
      <description>arXiv:2508.10743v1 Announce Type: cross 
Abstract: Atlas construction is fundamental to medical image analysis, offering a standardized spatial reference for tasks such as population-level anatomical modeling. While data-driven registration methods have recently shown promise in pairwise settings, their reliance on large training datasets, limited generalizability, and lack of true inference phases in groupwise contexts hinder their practical use. In contrast, model-driven methods offer training-free, theoretically grounded, and data-efficient alternatives, though they often face scalability and optimization challenges when applied to large 3D datasets. In this work, we introduce DARC (Diffeomorphic Atlas Registration via Coordinate descent), a novel model-driven groupwise registration framework for atlas construction. DARC supports a broad range of image dissimilarity metrics and efficiently handles arbitrary numbers of 3D images without incurring GPU memory issues. Through a coordinate descent strategy and a centrality-enforcing activation function, DARC produces unbiased, diffeomorphic atlases with high anatomical fidelity. Beyond atlas construction, we demonstrate two key applications: (1) One-shot segmentation, where labels annotated only on the atlas are propagated to subjects via inverse deformations, outperforming state-of-the-art few-shot methods; and (2) shape synthesis, where new anatomical variants are generated by warping the atlas mesh using synthesized diffeomorphic deformation fields. Overall, DARC offers a flexible, generalizable, and resource-efficient framework for atlas construction and applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10743v1</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziwei Zou, Bei Zou, Xiaoyan Kui, Wenqi Lu, Haoran Dou, Arezoo Zakeri, Timothy Cootes, Alejandro F Frangi, Jinming Duan</dc:creator>
    </item>
    <item>
      <title>Parity Cross-Resonance: A Multiqubit Gate</title>
      <link>https://arxiv.org/abs/2508.10807</link>
      <description>arXiv:2508.10807v1 Announce Type: cross 
Abstract: We present a native three-qubit entangling gate that exploits engineered interactions to realize control-control-target and control-target-target operations in a single coherent step. Unlike conventional decompositions into multiple two-qubit gates, our hybrid optimization approach selectively amplifies desired interactions while suppressing unwanted couplings, yielding robust performance across the computational subspace and beyond. The new gate can be classified as a cross-resonance gate. We show it can be utilized in several ways, for example, in GHZ triplet state preparation, Toffoli-class logic demonstrations with many-body interactions, and in implementing a controlled-ZZ gate. The latter maps the parity of two data qubits directly onto a measurement qubit, enabling faster and higher-fidelity stabilizer measurements in surface-code quantum error correction. In all these examples, we show that the three-qubit gate performance remains robust across Hilbert space sizes, as confirmed by testing under increasing total excitation numbers. This work lays the foundation for co-designing circuit architectures and control protocols that leverage native multiqubit interactions as core elements of next-generation superconducting quantum processors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10807v1</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuexin Xu, Siyu Wang, Radhika Joshi, Rihan Hai, Mohammad H. Ansari</dc:creator>
    </item>
    <item>
      <title>Sequential subspace methods on Stiefel manifold optimization</title>
      <link>https://arxiv.org/abs/2404.13301</link>
      <description>arXiv:2404.13301v2 Announce Type: replace 
Abstract: We investigate the minimization of a quadratic function over Stiefel manifolds (the set of all orthogonal $r$- frames in $\mathbf{R}^n$), which has applications in high-dimensional semi-supervised classification tasks. To reduce the computational complexity, we employ sequential subspace methods(SSM) to transform the high-dimensional problem to a series of low-dimensional ones. In this paper, our goal is to achieve an optimal solution of high quality, referred to as a ''qualified critical point". Qualified critical points are defined as those where the associated multiplier matrix meets specific upper-bound conditions. These points exhibit near-global optimality in quadratic optimization problems.
  In the context of a general quadratic, SSM generates a sequence of qualified critical points through low-dimensional surrogate regularized models. The convergence to a qualified critical point is guaranteed, when each SSM subspace is constructed from the following vectors: (i) a set of orthogonal unit vectors associated with the current iterate, (ii) a set of vectors representing the gradient of the objective, and (iii) a set of eigenvectors links to the smallest $r$ eigenvalues of the system matrix. Furthermore, incorporating Newton direction vectors into the subspaces can significantly accelerate the convergence of SSM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13301v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pengwen Chen, Chung-Kuan Cheng, Chester Holtz</dc:creator>
    </item>
    <item>
      <title>Condensed-space methods for nonlinear programming on GPUs</title>
      <link>https://arxiv.org/abs/2405.14236</link>
      <description>arXiv:2405.14236v2 Announce Type: replace 
Abstract: This paper explores two condensed-space interior-point methods to efficiently solve large-scale nonlinear programs on graphics processing units (GPUs). The interior-point method solves a sequence of symmetric indefinite linear systems, or Karush-Kuhn-Tucker (KKT) systems, which become increasingly ill-conditioned as we approach the solution. Solving a KKT system with traditional sparse factorization methods involve numerical pivoting, making parallelization difficult. A solution is to condense the KKT system into a symmetric positive-definite matrix and solve it with a Cholesky factorization, stable without pivoting. Although condensed KKT systems are more prone to ill-conditioning than the original ones, they exhibit structured ill-conditioning that mitigates the loss of accuracy. This paper compares the benefits of two recent condensed-space interior-point methods, HyKKT and LiftedKKT. We implement the two methods on GPUs using MadNLP.jl, an optimization solver interfaced with the NVIDIA sparse linear solver cuDSS and with the GPU-accelerated modeler ExaModels.jl. Our experiments on the PGLIB and the COPS benchmarks reveal that GPUs can attain up to a tenfold speed increase compared to CPUs when solving large-scale instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14236v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Pacaud, Sungho Shin, Alexis Montoison, Michel Schanen, Mihai Anitescu</dc:creator>
    </item>
    <item>
      <title>Bi-Sparse Unsupervised Feature Selection</title>
      <link>https://arxiv.org/abs/2412.16819</link>
      <description>arXiv:2412.16819v2 Announce Type: replace 
Abstract: To deal with high-dimensional unlabeled datasets in many areas, principal component analysis (PCA) has become a rising technique for unsupervised feature selection (UFS). However, most existing PCA-based methods only consider the structure of datasets by embedding a single sparse regularization or constraint on the transformation matrix. In this paper, we introduce a novel bi-sparse method called BSUFS to improve the performance of UFS. The core idea of BSUFS is to incorporate $\ell_{2,p}$-norm and $\ell_q$-norm into the classical PCA, which enables our method to select relevant features and filter out irrelevant noises, thereby obtaining discriminative features. Here, the parameters $p$ and $q$ are within the range of $[0, 1)$. Therefore, BSUFS not only constructs a unified framework for bi-sparse optimization, but also includes some existing works as special cases. To solve the resulting non-convex model, we propose an efficient proximal alternating minimization (PAM) algorithm using Stiefel manifold optimization and sparse optimization techniques. In addition, the computational complexity analysis is presented. Extensive numerical experiments on synthetic and real-world datasets demonstrate the effectiveness of our proposed BSUFS. The results reveal the advantages of bi-sparse optimization in feature selection and show its potential for other fields in image processing. Our code is available at https://github.com/xianchaoxiu/BSUFS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16819v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xianchao Xiu, Chenyi Huang, Pan Shang, Wanquan Liu</dc:creator>
    </item>
    <item>
      <title>Averaged Controllability of the Random Schr\"odinger Equation with Diffusivity Following Absolutely Continuous Distributions</title>
      <link>https://arxiv.org/abs/2503.04465</link>
      <description>arXiv:2503.04465v2 Announce Type: replace 
Abstract: This paper is devoted to the averaged controllability of the random Schr\"odinger equation, with diffusivity as a random variable drawn from a general probability distribution. First, we show that the solutions to these random Schr\"odinger equations are null averaged controllable with an open-loop control independent of randomness from any arbitrary subset of the domain with strictly positive measure and in any time. This is done for an interesting class of random variables, including certain stable distributions, specifically recovering the known result when the random diffusivity follows a normal or Cauchy distribution. Second, by the Riemann-Lebesgue lemma, we prove for any time the lack of averaged exact controllability in a $L^2$ setting for all absolutely continuous random variables. Notably, this implies that this property is not inherited from the exact controllability of the Schr\"odinger equation. Third, we show that simultaneous null controllability is not possible except for a finite number of scenarios. Finally, we perform numerical simulations that robustly validate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04465v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jon Asier B\'arcena-Petisco, Fouad Et-Tahri</dc:creator>
    </item>
    <item>
      <title>CGD: Modifying the Loss Landscape by Gradient Regularization</title>
      <link>https://arxiv.org/abs/2504.16182</link>
      <description>arXiv:2504.16182v3 Announce Type: replace 
Abstract: Line-search methods are commonly used to solve optimization problems. The simplest line search method is steepest descent where one always moves in the direction of the negative gradient. Newton's method on the other hand is a second-order method that uses the curvature information in the Hessian to pick the descent direction. In this work, we propose a new line-search method called Constrained Gradient Descent (CGD) that implicitly changes the landscape of the objective function for efficient optimization. CGD is formulated as a solution to the constrained version of the original problem where the constraint is on a function of the gradient. We optimize the corresponding Lagrangian function thereby favourably changing the landscape of the objective function. This results in a line search procedure where the Lagrangian penalty acts as a control over the descent direction and can therefore be used to iterate over points that have smaller gradient values, compared to iterates of vanilla steepest descent. We establish global linear convergence rates for CGD and provide numerical experiments on synthetic test functions to illustrate the performance of CGD. We also provide two practical variants of CGD, CGD-FD which is a Hessian free variant and CGD-QN, a quasi-Newton variant and demonstrate their effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16182v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shikhar Saxena, Tejas Bodas, Arti Yardi</dc:creator>
    </item>
    <item>
      <title>Sequential QCQP for Bilevel Optimization with Line Search</title>
      <link>https://arxiv.org/abs/2505.14647</link>
      <description>arXiv:2505.14647v2 Announce Type: replace 
Abstract: Bilevel optimization involves a hierarchical structure where one problem is nested within another, leading to complex interdependencies between levels. We propose a single-loop, tuning-free algorithm that guarantees anytime feasibility, i.e., approximate satisfaction of the lower-level optimality condition, while ensuring descent of the upper-level objective. At each iteration, a convex quadratically-constrained quadratic program (QCQP) with a closed-form solution yields the search direction, followed by a backtracking line search inspired by control barrier functions to ensure safe, uniformly positive step sizes. The resulting method is scalable, requires no hyperparameter tuning, and converges under mild local regularity assumptions. We establish an O(1/k) ergodic convergence rate in terms of a first-order stationary metric and demonstrate the algorithm's effectiveness on representative bilevel tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14647v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sina Sharifi, Erfan Yazdandoost Hamedani, Mahyar Fazlyab</dc:creator>
    </item>
    <item>
      <title>Optimization-Free Fast Optimal Control: Bang-Ride Property, Monotonicity, and Applications to Fast Battery Charging</title>
      <link>https://arxiv.org/abs/2508.09010</link>
      <description>arXiv:2508.09010v2 Announce Type: replace 
Abstract: Single-input fast optimal control problems, which aim to achieve the optimal objective as fast as possible, occur in various real-world applications. In the case of fast battery charging, the associated optimal control problem becomes computationally challenging when detailed battery models are used. A recent heuristic optimization-free algorithm can significantly reduce the computational cost and provide an approximate solution, consistent with many heuristic input profiles in practice. These heuristic solutions have several special properties: They follow a bang-ride pattern that always activates a constraint and applies the maximum feasible input. This work investigates when the above properties arise in the optimal input, and ultimately, when the heuristic input profiles satisfy necessary optimality conditions. By exploiting Pontryagin's maximum principle (PMP), we show that the optimal control is bang-ride under regularity conditions on constraint switching and local controllability of the system. Moreover, the special type of bang-ride behavior, i.e., applying the maximum feasible input, arises under the monotonicity of the system, objective function, and restricted sensitivity of the constraints. These results provide a theoretical justification for a class of charging heuristics and the fast optimization-free algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09010v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengling Shi, Jacob Sass, Jiaen Wu, Minsu Kim, Yingjie Ma, Sungho Shin, Richard D. Braatz</dc:creator>
    </item>
    <item>
      <title>Tightening the mixed integer linear formulation for the piecewise linear approximation in general dimensions</title>
      <link>https://arxiv.org/abs/2508.09395</link>
      <description>arXiv:2508.09395v2 Announce Type: replace 
Abstract: This paper addresses the problem of tightening the mixed-integer linear programming (MILP) formulation for continuous piecewise linear (CPWL) approximations of data sets in arbitrary dimensions. The MILP formulation leverages the difference-of-convex (DC) representation of CPWL functions. We introduce the concept of well-behaved CPWL interpolations and demonstrate that any CPWL interpolation of a data set has a well-behaved version. This result is critical to tighten the MILP problem. We present six different strategies to tighten the problem, which include fixing the values of some variables, introducing additional constraints, identifying small big-M parameter values and applying tighter variable bounds. These methods leverage key aspects of the DC representation and the inherent structure of well-behaved CPWL interpolations. Experimental results demonstrate that specific combinations of these tightening strategies lead to significant improvement in solution times, especially for tightening strategies that consider well-behaved CPWL solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09395v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quentin Ploussard, Xiang Li, Matija Pavi\v{c}evi\'c</dc:creator>
    </item>
    <item>
      <title>Learning to Schedule in Parallel-Server Queues with Stochastic Bilinear Rewards</title>
      <link>https://arxiv.org/abs/2112.06362</link>
      <description>arXiv:2112.06362v4 Announce Type: replace-cross 
Abstract: We consider the problem of scheduling in multi-class, parallel-server queuing systems with uncertain rewards from job-server assignments. In this scenario, jobs incur holding costs while awaiting completion, and job-server assignments yield observable stochastic rewards with unknown mean values. The mean rewards for job-server assignments are assumed to follow a bilinear model with respect to features that characterize jobs and servers. Our objective is to minimize regret by maximizing the cumulative reward of job-server assignments over a time horizon, while keeping the total job holding cost bounded to ensure the stability of the queueing system. This problem is motivated by applications requiring resource allocation in network systems. In this problem, it is essential to control the tradeoff between reward maximization and fair allocation for the stability of the underlying queuing system (i.e., maximizing network throughput). To address this problem, we propose a scheduling algorithm based on a weighted proportional fair criteria augmented with marginal costs for reward maximization, incorporating a bandit algorithm tailored for bilinear rewards. Our algorithm achieves a sub-linear regret bound and a sub-linear mean holding cost (and queue length bound) of $\tilde{O}(\sqrt{T})$, respectively, with respect to the time horizon $T$, thus guaranteeing queuing system stability. Additionally, we establish stability conditions for distributed iterative algorithms for computing allocations, which are relevant to large-scale system applications. Finally, we demonstrate the efficiency of our algorithm through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.06362v4</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jung-hun Kim, Milan Vojnovic</dc:creator>
    </item>
    <item>
      <title>A Geometric Unification of Distributionally Robust Covariance Estimators: Shrinking the Spectrum by Inflating the Ambiguity Set</title>
      <link>https://arxiv.org/abs/2405.20124</link>
      <description>arXiv:2405.20124v2 Announce Type: replace-cross 
Abstract: The state-of-the-art methods for estimating high-dimensional covariance matrices all shrink the eigenvalues of the sample covariance matrix towards a data-insensitive shrinkage target. The underlying shrinkage transformation is either chosen heuristically - without compelling theoretical justification - or optimally in view of restrictive distributional assumptions. In this paper, we propose a principled approach to construct covariance estimators without imposing restrictive assumptions. That is, we study distributionally robust covariance estimation problems that minimize the worst-case Frobenius error with respect to all data distributions close to a nominal distribution, where the proximity of distributions is measured via a divergence on the space of covariance matrices. We identify mild conditions on this divergence under which the resulting minimizers represent shrinkage estimators. We show that the corresponding shrinkage transformations are intimately related to the geometrical properties of the underlying divergence. We also prove that our robust estimators are efficiently computable and asymptotically consistent and that they enjoy finite-sample performance guarantees. We exemplify our general methodology by synthesizing explicit estimators induced by the Kullback-Leibler, Fisher-Rao, and Wasserstein divergences. Numerical experiments based on synthetic and real data show that our robust estimators are competitive with state-of-the-art estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20124v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Man-Chung Yue, Yves Rychener, Daniel Kuhn, Viet Anh Nguyen</dc:creator>
    </item>
    <item>
      <title>Clipping Improves Adam-Norm and AdaGrad-Norm when the Noise Is Heavy-Tailed</title>
      <link>https://arxiv.org/abs/2406.04443</link>
      <description>arXiv:2406.04443v3 Announce Type: replace-cross 
Abstract: Methods with adaptive stepsizes, such as AdaGrad and Adam, are essential for training modern Deep Learning models, especially Large Language Models. Typically, the noise in the stochastic gradients is heavy-tailed for the later ones. Gradient clipping provably helps to achieve good high-probability convergence for such noises. However, despite the similarity between AdaGrad/Adam and Clip-SGD, the current understanding of the high-probability convergence of AdaGrad/Adam-type methods is limited in this case. In this work, we prove that AdaGrad/Adam (and their delayed version) can have provably bad high-probability convergence if the noise is heavy-tailed. We also show that gradient clipping fixes this issue, i.e., we derive new high-probability convergence bounds with polylogarithmic dependence on the confidence level for AdaGrad-Norm and Adam-Norm with clipping and with/without delay for smooth convex/non-convex stochastic optimization with heavy-tailed noise. We extend our results to the case of AdaGrad/Adam with delayed stepsizes. Our empirical evaluations highlight the superiority of clipped versions of AdaGrad/Adam in handling the heavy-tailed noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04443v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Savelii Chezhegov, Yaroslav Klyukin, Andrei Semenov, Aleksandr Beznosikov, Alexander Gasnikov, Samuel Horv\'ath, Martin Tak\'a\v{c}, Eduard Gorbunov</dc:creator>
    </item>
    <item>
      <title>A Random-Key Optimizer for Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2411.04293</link>
      <description>arXiv:2411.04293v3 Announce Type: replace-cross 
Abstract: This paper introduces the Random-Key Optimizer (RKO), a versatile and efficient stochastic local search method tailored for combinatorial optimization problems. Using the random-key concept, RKO encodes solutions as vectors of random keys that are subsequently decoded into feasible solutions via problem-specific decoders. The RKO framework is able to combine a plethora of classic metaheuristics, each capable of operating independently or in parallel, with solution sharing facilitated through an elite solution pool. This modular approach allows for the adaptation of various metaheuristics, including simulated annealing, iterated local search, and greedy randomized adaptive search procedures, among others. The efficacy of the RKO framework, implemented in C++ and publicly available (Github public repository: github.com/RKO-solver), is demonstrated through its application to three NP-hard combinatorial optimization problems: the alpha-neighborhood p-median problem, the tree of hubs location problem, and the node-capacitated graph partitioning problem. The results highlight the framework's ability to produce high-quality solutions across diverse problem domains, underscoring its potential as a robust tool for combinatorial optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04293v3</guid>
      <category>cs.AI</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio A. Chaves, Mauricio G. C. Resende, Martin J. A. Schuetz, J. Kyle Brubaker, Helmut G. Katzgraber, Edilson F. de Arruda, Ricardo M. A. Silva</dc:creator>
    </item>
    <item>
      <title>Entropic Selection Principle for Monge's Optimal Transport</title>
      <link>https://arxiv.org/abs/2502.16370</link>
      <description>arXiv:2502.16370v2 Announce Type: replace-cross 
Abstract: We investigate the small regularization limit of entropic optimal transport when the cost function is the Euclidean distance in dimensions $d &gt; 1$, and the marginal measures are absolutely continuous with respect to the Lebesgue measure. Our results establish that the limiting optimal transport plan is supported on transport rays. Furthermore, within each transport ray, the limiting transport plan uniquely minimizes a relative entropy functional with respect to specific reference measures supported on the rays. This provides a complete and unique characterization of the limiting transport plan. While similar results have been obtained for $d = 1$ in \cite{Marino} and for discrete measures in \cite{peyr\'e2020computationaloptimaltransport}, this work resolves the previously open case in higher dimensions $d&gt;1.$</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16370v2</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shrey Aryan, Promit Ghosal</dc:creator>
    </item>
    <item>
      <title>Incompressible Optimal Transport and Applications in Fluid Mixing</title>
      <link>https://arxiv.org/abs/2504.01109</link>
      <description>arXiv:2504.01109v2 Announce Type: replace-cross 
Abstract: The problem of incompressible fluid mixing arises in numerous engineering applications and has been well-studied over the years, yet many open questions remain. This paper aims to address the question "what do efficient flow fields for mixing look like, and how do they behave?" We approach this question by developing a framework which is inspired by the dynamic and geometric approach to optimal mass transport. Specifically, we formulate the fluid mixing problem as an optimal control problem where the dynamics are given by the continuity equation together with an incompressibility constraint. We show that within this framework, the set of reachable fluid configurations can formally be endowed with the structure of an infinite-dimensional Riemannian manifold, with a metric which is induced by the control effort, and that flow fields which are maximally efficient at mixing correspond to geodesics in this Riemannian space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01109v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Emerick, Bassam Bamieh</dc:creator>
    </item>
    <item>
      <title>Responsible Machine Learning via Mixed-Integer Optimization</title>
      <link>https://arxiv.org/abs/2505.05857</link>
      <description>arXiv:2505.05857v2 Announce Type: replace-cross 
Abstract: In the last few decades, Machine Learning (ML) has achieved significant success across domains ranging from healthcare, sustainability, and the social sciences, to criminal justice and finance. But its deployment in increasingly sophisticated, critical, and sensitive areas affecting individuals, the groups they belong to, and society as a whole raises critical concerns around fairness, transparency and robustness, among others. As the complexity and scale of ML systems and of the settings in which they are deployed grow, so does the need for responsible ML methods that address these challenges while providing guaranteed performance in deployment.
  Mixed-integer optimization (MIO) offers a powerful framework for embedding responsible ML considerations directly into the learning process while maintaining performance. For example, it enables learning of inherently transparent models that can conveniently incorporate fairness or other domain specific constraints. This tutorial paper provides an accessible and comprehensive introduction to this topic discussing both theoretical and practical aspects. It outlines some of the core principles of responsible ML, their importance in applications, and the practical utility of MIO for building ML models that align with these principles. Through examples and mathematical formulations, it illustrates practical strategies and available tools for efficiently solving MIO problems for responsible ML. It concludes with a discussion on current limitations and open research questions, providing suggestions for future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05857v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan Justin, Qingshi Sun, Andr\'es G\'omez, Phebe Vayanos</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning with Random Time Horizons</title>
      <link>https://arxiv.org/abs/2506.00962</link>
      <description>arXiv:2506.00962v2 Announce Type: replace-cross 
Abstract: We extend the standard reinforcement learning framework to random time horizons. While the classical setting typically assumes finite and deterministic or infinite runtimes of trajectories, we argue that multiple real-world applications naturally exhibit random (potentially trajectory-dependent) stopping times. Since those stopping times typically depend on the policy, their randomness has an effect on policy gradient formulas, which we (mostly for the first time) derive rigorously in this work both for stochastic and deterministic policies. We present two complementary perspectives, trajectory or state-space based, and establish connections to optimal control theory. Our numerical experiments demonstrate that using the proposed formulas can significantly improve optimization convergence compared to traditional approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00962v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enric Ribera Borrell, Lorenz Richter, Christof Sch\"utte</dc:creator>
    </item>
    <item>
      <title>MAP Estimation with Denoisers: Convergence Rates and Guarantees</title>
      <link>https://arxiv.org/abs/2507.15397</link>
      <description>arXiv:2507.15397v2 Announce Type: replace-cross 
Abstract: Denoiser models have become powerful tools for inverse problems, enabling the use of pretrained networks to approximate the score of a smoothed prior distribution. These models are often used in heuristic iterative schemes aimed at solving Maximum a Posteriori (MAP) optimisation problems, where the proximal operator of the negative log-prior plays a central role. In practice, this operator is intractable, and practitioners plug in a pretrained denoiser as a surrogate-despite the lack of general theoretical justification for this substitution. In this work, we show that a simple algorithm, closely related to several used in practice, provably converges to the proximal operator under a log-concavity assumption on the prior $p$. We show that this algorithm can be interpreted as a gradient descent on smoothed proximal objectives. Our analysis thus provides a theoretical foundation for a class of empirically successful but previously heuristic methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15397v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Scott Pesme, Giacomo Meanti, Michael Arbel, Julien Mairal</dc:creator>
    </item>
    <item>
      <title>Decision Theory For Large Scale Outlier Detection Using Aleatoric Uncertainty: With a Note on Bayesian FDR</title>
      <link>https://arxiv.org/abs/2508.01988</link>
      <description>arXiv:2508.01988v3 Announce Type: replace-cross 
Abstract: Aleatoric and Epistemic uncertainty have achieved recent attention in the literature as different sources from which uncertainty can emerge in stochastic modeling. Epistemic being intrinsic or model based notions of uncertainty, and aleatoric being the uncertainty inherent in the data. We propose a novel decision theoretic framework for outlier detection in the context of aleatoric uncertainty; in the context of Bayesian modeling. The model incorporates bayesian false discovery rate control for multiplicty adjustment, and a new generalization of Bayesian FDR is introduced. The model is applied to simulations based on temporally fluctuating outlier detection where fixing thresholds often results in poor performance due to nonstationarity, and a case study is outlined on on a novel cybersecurity detection. Cyberthreat signals are highly nonstationary; giving a credible stress test of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01988v3</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ryan Warnick</dc:creator>
    </item>
    <item>
      <title>Canonical Frames for Bracket Generating Rank 2 Distributions which are not Goursat</title>
      <link>https://arxiv.org/abs/2508.09307</link>
      <description>arXiv:2508.09307v2 Announce Type: replace-cross 
Abstract: We complete a uniform construction of canonical absolute parallelism for bracket generating rank $2$ distributions with $5$-dimensional cube on $n$-dimensional manifold with $n\geq 5$ by showing that the condition of maximality of class that was assumed previously by Doubrov-Zelenko for such a construction holds automatically at generic points. This also gives analogous constructions in the case when the cube is not $5$-dimensional but the distribution is not Goursat through the procedure of iterative Cartan deprolongation. This together with the classical theory of Goursat distributions covers in principle the local geometry of all bracket generating rank 2 distributions in a neighborhood of generic points. As a byproduct, for any $n\geq 5$ we describe the maximally symmetric germs among bracket generating rank $2$ distributions with $5$-dimensional cube, as well as among those which reduce to such a distribution under a fixed number of Cartan deprolongations. Another consequence of our results on maximality of class is for optimal control problems with constraint given by a rank $2$ distribution with $5$-dimensional cube: it implies that for a generic point $q_0$ of $M$, there are plenty abnormal extremal trajectories of corank $1$ (which is the minimal possible corank) starting at $q_0$. The set of such points contains all points where the distribution is equiregular.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09307v2</guid>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicklas Day, Igor Zelenko</dc:creator>
    </item>
  </channel>
</rss>
