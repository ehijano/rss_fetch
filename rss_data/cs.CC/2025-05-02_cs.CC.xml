<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 May 2025 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Computational Complexity of UAP Reverse Engineering: A Formal Analysis of Automaton Identification and Data Complexity</title>
      <link>https://arxiv.org/abs/2505.00051</link>
      <description>arXiv:2505.00051v1 Announce Type: new 
Abstract: This white paper demonstrates that reverse engineering Unidentified Aerial Phenomena (UAP) is NP-complete under classical computational paradigms. By modeling UAP reconstruction as an automaton identification problem with a state characterization matrix M(D, T, E) and examining the inherent challenges in data gathering as well as unknown physics, we show that inferring internal mechanisms (such as Isotopically-Engineered-Materials or unconventional propulsion systems) from finite observational data is computationally intractable. Data D, comprising both operational non-reproducible observations and reproducible analysis data from purported crash retrievals, remains inherently fragmentary. Even if UAP observables were reproducible, the absence of a comprehensive theoretical framework ensures that reverse engineering remains NP-complete, and may escalate to PSPACE-hard or to an Entscheidungsproblem. This intractability challenges current UAP reverse engineering efforts and has profound implications for transparency on UAP technology and related venture investments. Hence, UAP are as analogous to modern smartphones in the hands of Neanderthals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00051v1</guid>
      <category>cs.CC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>J.Acad. (N.Y.) 2025, Vol. 14, 1:3-15</arxiv:journal_reference>
      <dc:creator>Karim Daghbouche</dc:creator>
    </item>
    <item>
      <title>One-way Communication Complexity of Minimum Vertex Cover in General Graphs</title>
      <link>https://arxiv.org/abs/2505.00164</link>
      <description>arXiv:2505.00164v1 Announce Type: new 
Abstract: We study the communication complexity of the Minimum Vertex Cover (MVC) problem on general graphs within the \(k\)-party one-way communication model. Edges of an arbitrary \(n\)-vertex graph are distributed among \(k\) parties. The objective is for the parties to collectively find a small vertex cover of the graph while adhering to a communication protocol where each party sequentially sends a message to the next until the last party outputs a valid vertex cover of the whole graph. We are particularly interested in the trade-off between the size of the messages sent and the approximation ratio of the output solution.
  It is straightforward to see that any constant approximation protocol for MVC requires communicating \(\Omega(n)\) bits. Additionally, there exists a trivial 2-approximation protocol where the parties collectively find a maximal matching of the graph greedily and return the subset of vertices matched. This raises a natural question: \textit{What is the best approximation ratio achievable using optimal communication of \(O(n)\)?} We design a protocol with an approximation ratio of \((2-2^{-k+1}+\epsilon)\) and \(O(n)\) communication for any desirably small constant \(\epsilon&gt;0\), which is strictly better than 2 for any constant number of parties. Moreover, we show that achieving an approximation ratio smaller than \(3/2\) for the two-party case requires \(n^{1 + \Omega(1/\lg\lg n)}\) communication, thereby establishing the tightness of our protocol for two parties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00164v1</guid>
      <category>cs.CC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahsa Derakhshan, Andisheh Ghasemi, Rajmohan Rajaraman</dc:creator>
    </item>
    <item>
      <title>On the Space Complexity of Online Convolution</title>
      <link>https://arxiv.org/abs/2505.00181</link>
      <description>arXiv:2505.00181v1 Announce Type: new 
Abstract: We study a discrete convolution streaming problem. An input arrives as a stream of numbers $z = (z_0,z_1,z_2,\ldots)$, and at time $t$ our goal is to output $(Tz)_t$ where $T$ is a lower-triangular Toeplitz matrix. We focus on space complexity; the algorithm can store a buffer of $\beta(t)$ numbers in order to achieve this goal.
  We characterize space complexity when algorithms perform algebraic operations. The matrix $T$ corresponds to a generating function $G(x)$. If $G(x)$ is rational of degree $d$, then it is known that the space complexity is at most $O(d)$. We prove a corresponding lower bound; the space complexity is at least $\Omega(d)$. In addition, for irrational $G(x)$, we prove that the space complexity is infinite. We also provide finite-time guarantees. For example, for the generating function $\frac{1}{\sqrt{1-x}}$ that was studied in various previous works in the context of differentially private continual counting, we prove a sharp lower bound on the space complexity; at time $t$, it is at least $\Omega(t)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00181v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joel Daniel Andersson, Amir Yehudayoff</dc:creator>
    </item>
    <item>
      <title>The Planted Orthogonal Vectors Problem</title>
      <link>https://arxiv.org/abs/2505.00206</link>
      <description>arXiv:2505.00206v1 Announce Type: new 
Abstract: In the $k$-Orthogonal Vectors ($k$-OV) problem we are given $k$ sets, each containing $n$ binary vectors of dimension $d=n^{o(1)}$, and our goal is to pick one vector from each set so that at each coordinate at least one vector has a zero. It is a central problem in fine-grained complexity, conjectured to require $n^{k-o(1)}$ time in the worst case.
  We propose a way to \emph{plant} a solution among vectors with i.i.d. $p$-biased entries, for appropriately chosen $p$, so that the planted solution is the unique one. Our conjecture is that the resulting $k$-OV instances still require time $n^{k-o(1)}$ to solve, \emph{on average}.
  Our planted distribution has the property that any subset of strictly less than $k$ vectors has the \emph{same} marginal distribution as in the model distribution, consisting of i.i.d. $p$-biased random vectors. We use this property to give average-case search-to-decision reductions for $k$-OV.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00206v1</guid>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David K\"uhnemann, Adam Polak, Alon Rosen</dc:creator>
    </item>
    <item>
      <title>The Complexity of Minimum-Envy House Allocation Over Graphs</title>
      <link>https://arxiv.org/abs/2505.00296</link>
      <description>arXiv:2505.00296v1 Announce Type: cross 
Abstract: In this paper, we study a generalization of the House Allocation problem. In our problem, agents are represented by vertices of a graph $\GG_{\mathcal{A}} = (\AA, E_\AA)$, and each agent $a \in \AA$ is associated with a set of preferred houses $\PP_a \subseteq \HH$, where $\AA$ is the set of agents and $\HH$ is the set of houses. A house allocation is an injective function $\phi: \AA \rightarrow \HH$, and an agent $a$ envies a neighbour $a' \in N_{\GG_\AA}(a)$ under $\phi$ if $\phi(a) \notin \PP_a$ and $\phi(a') \in \PP_a$. We study two natural objectives: the first problem called \ohaa, aims to compute an allocation that minimizes the number of envious agents; the second problem called \ohaah aims to maximize, among all minimum-envy allocations, the number of agents who are assigned a house they prefer. These two objectives capture complementary notions of fairness and individual satisfaction.
  We design polynomial time algorithms for both problems for the variant when each agent prefers exactly one house. On the other hand, when the list of preferred houses for each agent has size at most $2$ then we show that both problems are \NP-hard even when the agent graph $\GG_\AA$ is a complete bipartite graph. We also show that both problems are \NP-hard even when the number $|\mathcal H|$ of houses is equal to the number $|\mathcal A|$ of agents. This is in contrast to the classical {\sc House Allocation} problem, where the problem is polynomial time solvable when $|\mathcal H| = |\mathcal A|$. The two problems are also \NP-hard when the agent graph has a small vertex cover. On the positive side, we design exact algorithms that exploit certain structural properties of $\GG_{\AA}$ such as sparsity, existence of balanced separators or existence of small-sized vertex covers, and perform better than the naive brute-force algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00296v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Palash Dey, Anubhav Dhar, Ashlesha Hota, Sudeshna Kolay</dc:creator>
    </item>
    <item>
      <title>On estimating the quantum $\ell_{\alpha}$ distance</title>
      <link>https://arxiv.org/abs/2505.00457</link>
      <description>arXiv:2505.00457v1 Announce Type: cross 
Abstract: We study the computational complexity of estimating the quantum $\ell_{\alpha}$ distance ${\mathrm{T}_\alpha}(\rho_0,\rho_1)$, defined via the Schatten $\alpha$-norm $\|A\|_{\alpha} = \mathrm{tr}(|A|^{\alpha})^{1/\alpha}$, given $\operatorname{poly}(n)$-size state-preparation circuits of $n$-qubit quantum states $\rho_0$ and $\rho_1$. This quantity serves as a lower bound on the trace distance for $\alpha &gt; 1$. For any constant $\alpha &gt; 1$, we develop an efficient rank-independent quantum estimator for ${\mathrm{T}_\alpha}(\rho_0,\rho_1)$ with time complexity $\operatorname{poly}(n)$, achieving an exponential speedup over the prior best results of $\exp(n)$ due to Wang, Guan, Liu, Zhang, and Ying (TIT 2024). Our improvement leverages efficiently computable uniform polynomial approximations of signed positive power functions within quantum singular value transformation, thereby eliminating the dependence on the rank of the quantum states.
  Our quantum algorithm reveals a dichotomy in the computational complexity of the Quantum State Distinguishability Problem with Schatten $\alpha$-norm (QSD$_{\alpha}$), which involves deciding whether ${\mathrm{T}_\alpha}(\rho_0,\rho_1)$ is at least $2/5$ or at most $1/5$. This dichotomy arises between the cases of constant $\alpha &gt; 1$ and $\alpha=1$:
  - For any $1+\Omega(1) \leq \alpha \leq O(1)$, QSD$_{\alpha}$ is $\mathsf{BQP}$-complete.
  - For any $1 \leq \alpha \leq 1+\frac{1}{n}$, QSD$_{\alpha}$ is $\mathsf{QSZK}$-complete, implying that no efficient quantum estimator for $\mathrm{T}_\alpha(\rho_0,\rho_1)$ exists unless $\mathsf{BQP} = \mathsf{QSZK}$.
  The hardness results follow from reductions based on new rank-dependent inequalities for the quantum $\ell_{\alpha}$ distance with $1\leq \alpha \leq \infty$, which are of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00457v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yupan Liu, Qisheng Wang</dc:creator>
    </item>
    <item>
      <title>Orbit-blocking words in free groups</title>
      <link>https://arxiv.org/abs/2505.00477</link>
      <description>arXiv:2505.00477v1 Announce Type: cross 
Abstract: By strengthening known results about primitivity-blocking words in free groups, we prove that for any nontrivial element w of a free group of finite rank, there are words that cannot be subwords of any cyclically reduced automorphic image of w. This has implications for the average-case complexity of Whitehead's problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00477v1</guid>
      <category>math.GR</category>
      <category>cs.CC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucy Koch-Hyde, Siobhan O'Connor, Eamonn Olive, Vladimir Shpilrain</dc:creator>
    </item>
    <item>
      <title>Smoothed Analysis for Learning Concepts with Low Intrinsic Dimension</title>
      <link>https://arxiv.org/abs/2407.00966</link>
      <description>arXiv:2407.00966v2 Announce Type: replace-cross 
Abstract: In traditional models of supervised learning, the goal of a learner -- given examples from an arbitrary joint distribution on $\mathbb{R}^d \times \{\pm 1\}$ -- is to output a hypothesis that is competitive (to within $\epsilon$) of the best fitting concept from some class. In order to escape strong hardness results for learning even simple concept classes, we introduce a smoothed-analysis framework that requires a learner to compete only with the best classifier that is robust to small random Gaussian perturbation.
  This subtle change allows us to give a wide array of learning results for any concept that (1) depends on a low-dimensional subspace (aka multi-index model) and (2) has a bounded Gaussian surface area. This class includes functions of halfspaces and (low-dimensional) convex sets, cases that are only known to be learnable in non-smoothed settings with respect to highly structured distributions such as Gaussians.
  Surprisingly, our analysis also yields new results for traditional non-smoothed frameworks such as learning with margin. In particular, we obtain the first algorithm for agnostically learning intersections of $k$-halfspaces in time $k^{poly(\frac{\log k}{\epsilon \gamma}) }$ where $\gamma$ is the margin parameter. Before our work, the best-known runtime was exponential in $k$ (Arriaga and Vempala, 1999).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00966v2</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gautam Chandrasekaran, Adam Klivans, Vasilis Kontonis, Raghu Meka, Konstantinos Stavropoulos</dc:creator>
    </item>
  </channel>
</rss>
