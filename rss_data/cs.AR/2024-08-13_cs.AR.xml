<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.AR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.AR</link>
    <description>cs.AR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.AR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 Aug 2024 04:02:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 14 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Potamoi: Accelerating Neural Rendering via a Unified Streaming Architecture</title>
      <link>https://arxiv.org/abs/2408.06608</link>
      <description>arXiv:2408.06608v1 Announce Type: new 
Abstract: Neural Radiance Field (NeRF) has emerged as a promising alternative for photorealistic rendering. Despite recent algorithmic advancements, achieving real-time performance on today's resource-constrained devices remains challenging. In this paper, we identify the primary bottlenecks in current NeRF algorithms and introduce a unified algorithm-architecture co-design, Potamoi, designed to accommodate various NeRF algorithms. Specifically, we introduce a runtime system featuring a plug-and-play algorithm, SpaRW, which significantly reduces the per-frame computational workload and alleviates compute inefficiencies. Furthermore, our unified streaming pipeline coupled with customized hardware support effectively tames both SRAM and DRAM inefficiencies by minimizing repetitive DRAM access and completely eliminating SRAM bank conflicts. When evaluated against a baseline utilizing a dedicated DNN accelerator, our framework demonstrates a speed-up and energy reduction of 53.1$\times$ and 67.7$\times$, respectively, all while maintaining high visual quality with less than a 1.0 dB reduction in peak signal-to-noise ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06608v1</guid>
      <category>cs.AR</category>
      <category>cs.GR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Feng, Weikai Lin, Zihan Liu, Jingwen Leng, Minyi Guo, Han Zhao, Xiaofeng Hou, Jieru Zhao, Yuhao Zhu</dc:creator>
    </item>
    <item>
      <title>HLSPilot: LLM-based High-Level Synthesis</title>
      <link>https://arxiv.org/abs/2408.06810</link>
      <description>arXiv:2408.06810v1 Announce Type: new 
Abstract: Large language models (LLMs) have catalyzed an upsurge in automatic code generation, garnering significant attention for register transfer level (RTL) code generation. Despite the potential of RTL code generation with natural language, it remains error-prone and limited to relatively small modules because of the substantial semantic gap between natural language expressions and hardware design intent. In response to the limitations, we propose a methodology that reduces the semantic gaps by utilizing C/C++ for generating hardware designs via High-Level Synthesis (HLS) tools. Basically, we build a set of C-to-HLS optimization strategies catering to various code patterns, such as nested loops and local arrays. Then, we apply these strategies to sequential C/C++ code through in-context learning, which provides the LLMs with exemplary C/C++ to HLS prompts. With this approach, HLS designs can be generated effectively. Since LLMs still face problems in determining the optimized pragma parameters precisely, we have a design space exploration (DSE) tool integrated for pragma parameter tuning. Furthermore, we also employ profiling tools to pinpoint the performance bottlenecks within a program and selectively convert bottleneck components to HLS code for hardware acceleration. By combining the LLM-based profiling, C/C++ to HLS translation, and DSE, we have established HLSPilot, the first LLM-enabled high-level synthesis framework, which can fully automate the high-level application acceleration on hybrid CPU-FPGA architectures. According to our experiments on real-world application benchmarks, HLSPilot achieve comparable performance in general and can even outperform manually crafted counterparts, thereby underscoring the substantial promise of LLM-assisted hardware designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06810v1</guid>
      <category>cs.AR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chenwei Xiong, Cheng Liu, Huawei Li, Xiaowei Li</dc:creator>
    </item>
    <item>
      <title>UFO-MAC: A Unified Framework for Optimization of High-Performance Multipliers and Multiply-Accumulators</title>
      <link>https://arxiv.org/abs/2408.06935</link>
      <description>arXiv:2408.06935v1 Announce Type: new 
Abstract: Multipliers and multiply-accumulators (MACs) are critical arithmetic circuit components in the modern era. As essential components of AI accelerators, they significantly influence the area and performance of compute-intensive circuits. This paper presents UFO-MAC, a unified framework for the optimization of multipliers and MACs. Specifically, UFO-MAC employs an optimal compressor tree structure and utilizes integer linear programming (ILP) to refine the stage assignment and interconnection of the compressors. Additionally, it explicitly exploits the non-uniform arrival time profile of the carry propagate adder (CPA) within multipliers to achieve targeted optimization. Moreover, the framework also supports the optimization of fused MAC architectures. Experimental results demonstrate that multipliers and MACs optimized by UFO-MAC Pareto-dominate state-of-the-art baselines and commercial IP libraries. The performance gain of UFO-MAC is further validated through the implementation of multipliers and MACs within functional modules, underlining its efficacy in real scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06935v1</guid>
      <category>cs.AR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dongsheng Zuo, Jiadong Zhu, Chenglin Li, Yuzhe Ma</dc:creator>
    </item>
    <item>
      <title>Approximate ADCs for In-Memory Computing</title>
      <link>https://arxiv.org/abs/2408.06390</link>
      <description>arXiv:2408.06390v1 Announce Type: cross 
Abstract: In memory computing (IMC) architectures for deep learning (DL) accelerators leverage energy-efficient and highly parallel matrix vector multiplication (MVM) operations, implemented directly in memory arrays. Such IMC designs have been explored based on CMOS as well as emerging non-volatile memory (NVM) technologies like RRAM. IMC architectures generally involve a large number of cores consisting of memory arrays, storing the trained weights of the DL model. Peripheral units like DACs and ADCs are also used for applying inputs and reading out the output values. Recently reported designs reveal that the ADCs required for reading out the MVM results, consume more than 85% of the total compute power and also dominate the area, thereby eschewing the benefits of the IMC scheme. Mitigation of imperfections in the ADCs, namely, non-linearity and variations, incur significant design overheads, due to dedicated calibration units. In this work we present peripheral aware design of IMC cores, to mitigate such overheads. It involves incorporating the non-idealities of ADCs in the training of the DL models, along with that of the memory units. The proposed approach applies equally well to both current mode as well as charge mode MVM operations demonstrated in recent years., and can significantly simplify the design of mixed-signal IMC units.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06390v1</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Arkapravo Ghosh, Hemkar Reddy Sadana, Mukut Debnath, Panthadip Maji, Shubham Negi, Sumeet Gupta, Mrigank Sharad, Kaushik Roy</dc:creator>
    </item>
    <item>
      <title>Analytical Heterogeneous Die-to-Die 3D Placement with Macros</title>
      <link>https://arxiv.org/abs/2403.09070</link>
      <description>arXiv:2403.09070v2 Announce Type: replace 
Abstract: This paper presents an innovative approach to 3D mixed-size placement in heterogeneous face-to-face (F2F) bonded 3D ICs. We propose an analytical framework that utilizes a dedicated density model and a bistratal wirelength model, effectively handling macros and standard cells in a 3D solution space. A novel 3D preconditioner is developed to resolve the topological and physical gap between macros and standard cells. Additionally, we propose a mixed-integer linear programming (MILP) formulation for macro rotation to optimize wirelength. Our framework is implemented with full-scale GPU acceleration, leveraging an adaptive 3D density accumulation algorithm and an incremental wirelength gradient algorithm. Experimental results on ICCAD 2023 contest benchmarks demonstrate that our framework can achieve 5.9% quality score improvement compared to the first-place winner with 4.0x runtime speedup. Additional experiments on modern RISC-V designs further validate the generalizability and superiority of our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09070v2</guid>
      <category>cs.AR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuxuan Zhao, Peiyu Liao, Siting Liu, Jiaxi Jiang, Yibo Lin, Bei Yu</dc:creator>
    </item>
    <item>
      <title>Mixed-precision Neural Networks on RISC-V Cores: ISA extensions for Multi-Pumped Soft SIMD Operations</title>
      <link>https://arxiv.org/abs/2407.14274</link>
      <description>arXiv:2407.14274v2 Announce Type: replace 
Abstract: Recent advancements in quantization and mixed-precision approaches offers substantial opportunities to improve the speed and energy efficiency of Neural Networks (NN). Research has shown that individual parameters with varying low precision, can attain accuracies comparable to full-precision counterparts. However, modern embedded microprocessors provide very limited support for mixed-precision NNs regarding both Instruction Set Architecture (ISA) extensions and their hardware design for efficient execution of mixed-precision operations, i.e., introducing several performance bottlenecks due to numerous instructions for data packing and unpacking, arithmetic unit under-utilizations etc. In this work, we bring together, for the first time, ISA extensions tailored to mixed-precision hardware optimizations, targeting energy-efficient DNN inference on leading RISC-V CPU architectures. To this end, we introduce a hardware-software co-design framework that enables cooperative hardware design, mixed-precision quantization, ISA extensions and inference in cycle-accurate emulations. At hardware level, we firstly expand the ALU unit within our proof-of-concept micro-architecture to support configurable fine grained mixed-precision arithmetic operations. Subsequently, we implement multi-pumping to minimize execution latency, with an additional soft SIMD optimization applied for 2-bit operations. At the ISA level, three distinct MAC instructions are encoded extending the RISC-V ISA, and exposed up to the compiler level, each corresponding to a different mixed-precision operational mode. Our extensive experimental evaluation over widely used DNNs and datasets, such as CIFAR10 and ImageNet, demonstrates that our framework can achieve, on average, 15x energy reduction for less than 1% accuracy loss and outperforms the ISA-agnostic state-of-the-art RISC-V cores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14274v2</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3676536.3676840</arxiv:DOI>
      <dc:creator>Giorgos Armeniakos, Alexis Maras, Sotirios Xydis, Dimitrios Soudris</dc:creator>
    </item>
    <item>
      <title>Uncontrolled learning: co-design of neuromorphic hardware topology for neuromorphic algorithms</title>
      <link>https://arxiv.org/abs/2408.05183</link>
      <description>arXiv:2408.05183v2 Announce Type: replace-cross 
Abstract: Hardware-based neuromorphic computing remains an elusive goal with the potential to profoundly impact future technologies and deepen our understanding of emergent intelligence. The learning-from-mistakes algorithm is one of the few training algorithms inspired by the brain's simple learning rules, utilizing inhibition and pruning to demonstrate self-organized learning. Here we implement this algorithm in purely neuromorphic memristive hardware through a co-design process. This implementation requires evaluating hardware trade-offs and constraints. It has been shown that learning-from-mistakes successfully trains small networks to function as binary classifiers and perceptrons. However, without tailoring the hardware to the algorithm, performance decreases exponentially as the network size increases. When implementing neuromorphic algorithms on neuromorphic hardware, we investigate the trade-offs between depth, controllability, and capacity, the latter being the number of learnable patterns. We emphasize the significance of topology and the use of governing equations, demonstrating theoretical tools to aid in the co-design of neuromorphic hardware and algorithms. We provide quantitative techniques to evaluate the computational capacity of a neuromorphic device based on the measurements performed and the underlying circuit structure. This approach shows that breaking the symmetry of a neural network can increase both the controllability and average network capacity. By pruning the circuit, neuromorphic algorithms in all-memristive device circuits leverage stochastic resources to drive local contrast in network weights. Our combined experimental and simulation efforts explore the parameters that make a network suited for displaying emergent intelligence from simple rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05183v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frank Barrows, Jonathan Lin, Francesco Caravelli, Dante R. Chialvo</dc:creator>
    </item>
    <item>
      <title>Sustainable Quantum Computing: Opportunities and Challenges of Benchmarking Carbon in the Quantum Computing Lifecycle</title>
      <link>https://arxiv.org/abs/2408.05679</link>
      <description>arXiv:2408.05679v2 Announce Type: replace-cross 
Abstract: While researchers in both industry and academia are racing to build Quantum Computing (QC) platforms with viable performance and functionality, the environmental impacts of this endeavor, such as its carbon footprint, e-waste generation, mineral use, and water and energy consumption, remain largely unknown. A similar oversight occurred during the semiconductor revolution and continues to have disastrous consequences for the health of our planet. As we build the quantum computing stack from the ground up, it is crucial to comprehensively assess it through an environmental sustainability lens for its entire life-cycle: production, use, and disposal. In this paper, we highlight the need and challenges in establishing a QC sustainability benchmark that enables researchers to make informed architectural design decisions and celebrate the potential quantum environmental advantage. We propose a carbon-aware quantum computing (CQC) framework that provides the foundational methodology and open research questions for calculating the total life-cycle carbon footprint of a QC platform. Our call to action to the research community is the establishment of a new research direction known as, sustainable quantum computing that promotes both quantum computing for sustainability-oriented applications and the sustainability of quantum computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05679v2</guid>
      <category>quant-ph</category>
      <category>cs.AR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nivedita Arora, Prem Kumar</dc:creator>
    </item>
  </channel>
</rss>
