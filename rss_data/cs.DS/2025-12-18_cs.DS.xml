<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Dec 2025 02:42:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Label-consistent clustering for evolving data</title>
      <link>https://arxiv.org/abs/2512.15210</link>
      <description>arXiv:2512.15210v1 Announce Type: new 
Abstract: Data analysis often involves an iterative process, where solutions must be continuously refined in response to new data. Typically, as new data becomes available, an existing solution must be updated to incorporate the latest information. In addition to seeking a high-quality solution for the task at hand, it is also crucial to ensure consistency by minimizing drastic changes from previous solutions. Applying this approach across many iterations, ensures that the solution evolves gradually and smoothly.
  In this paper, we study the above problem in the context of clustering, specifically focusing on the $k$-center problem. More precisely, we study the following problem: Given a set of points $X$, parameters $k$ and $b$, and a prior clustering solution $H$ for $X$, our goal is to compute a new solution $C$ for $X$, consisting of $k$ centers, which minimizes the clustering cost while introducing at most $b$ changes from $H$. We refer to this problem as label-consistent $k$-center, and we propose two constant-factor approximation algorithms for it. We complement our theoretical findings with an experimental evaluation demonstrating the effectiveness of our methods on real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15210v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ameet Gadekar, Aristides Gionis, Thibault Marette</dc:creator>
    </item>
    <item>
      <title>A Constant-Factor Approximation for Directed Latency</title>
      <link>https://arxiv.org/abs/2512.15473</link>
      <description>arXiv:2512.15473v1 Announce Type: new 
Abstract: In the Directed Latency problem, we are given an asymmetric metric on a set of vertices (or clients), and a given depot $s$. We seek a path $P$ starting at $s$ and visiting all the clients so as to minimize the sum of client waiting times (also known as latency) before being visited on the path.
  In contrast to the symmetric version of this problem (also known as the Deliveryperson problem and the Repairperson problem in the literature), there are significant gaps in our understanding of Directed Latency. The best approximation factor has remained at $O(\log n)$, where $n$ is the number of clients, for more than a decade [Friggstad, Salavatipour, and Svitkina, '13]. Only recently, [Friggstad and Swamy, '22] presented a constant-factor approximation but in quasi-polynomial time. Both results follow similar ideas: they consider buckets with geometrically-increasing distances, build paths in each bucket, and then stitch together all these paths to get a feasible solution. [Friggstad and Swamy, '22] showed if we guess a vertex from each bucket and augment a standard LP relaxation with these guesses, then one can reduce the stitching cost. Unfortunately, there are logarithmically many buckets so the running time of their algorithm is quasi-polynomial.
  In this paper, we present the first constant-factor approximation for Directed Latency in polynomial time by introducing a completely new way of bucketing which helps us strengthen a standard LP relaxation with less aggressive guessing. Although the resulting LP is no longer a relaxation of Directed Latency, it still admits a good solution. We present a rounding algorithm for fractional solutions of our LP, crucially exploiting the way we restricted the feasibility region of the LP formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15473v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jannis Blauth, Ramin Mousavi</dc:creator>
    </item>
    <item>
      <title>A Maximum Linear Arrangement Problem on Directed Graphs</title>
      <link>https://arxiv.org/abs/1810.12277</link>
      <description>arXiv:1810.12277v3 Announce Type: replace 
Abstract: We propose a new arrangement problem on directed graphs, Maximum Directed Linear Arrangement (MaxDLA). This is a directed variant of a similar problem for undirected graphs, in which however one seeks maximum and not minimum; this problem known as the Minimum Linear Arrangement Problem (MinLA) has been much studied in the literature. We establish a number of theorems illustrating the behavior and complexity of MaxDLA. First, we relate MaxDLA to Maximum Directed Cut (MaxDiCut) by proving that every simple digraph $D$ on $n$ vertices satisfies $\frac{n}{2}$$maxDiCut(D) \leq MaxDLA(D) \leq (n-1)MaxDiCut(D)$. Next, we prove that MaxDiCut is NP-Hard for planar digraphs (even with the added restriction of maximum degree 15); it follows from the above bounds that MaxDLA is also NP-Hard for planar digraphs. In contrast, Hadlock (1975) and Dorfman and Orlova (1972) showed that the undirected Maximum Cut problem is solvable in polynomial time on planar graphs.
  On the positive side, we present a polynomial-time algorithm for solving MaxDLA on orientations of trees with degree bounded by a constant, which translates to a polynomial-time algorithm for solving MinLA on the complements of those trees. This pairs with results by Goldberg and Klipker (1976), Shiloach (1979) and Chung (1984) solving MinLA in polynomial time on trees. Finally, analogues of Harper's famous isoperimetric inequality for the hypercube, in the setting of MaxDLA, are shown for tournaments, orientations of graphs with degree at most two, and transitive acyclic digraphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:1810.12277v3</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matt DeVos, Kathryn Nurse</dc:creator>
    </item>
    <item>
      <title>Forcing a unique minimum spanning tree and a unique shortest path</title>
      <link>https://arxiv.org/abs/2509.24309</link>
      <description>arXiv:2509.24309v2 Announce Type: replace 
Abstract: A forcing set $S$ in a combinatorial problem is a set of elements such that there is a unique solution that contains all the elements in $S$. An anti-forcing set is the symmetric concept: a set $S$ of elements is called an anti-forcing set if there is a unique solution disjoint from $S$. There are extensive studies on the computational complexity of finding a minimum forcing set in various combinatorial problems, and the known results indicate that many problems would be harder than their classical counterparts: the decision version of finding a minimum forcing set for perfect matchings is NP-complete [Adams et al., Discret. Math. 2004] and that of finding a minimum forcing set for satisfying assignments for 3CNF formulas is $\Sigma_2^{\mathrm{P}}$-complete [Hatami-Maserrat, DAM 2005]. In this paper, we investigate the complexity of the problems of finding minimum forcing and anti-forcing sets for the shortest $s$-$t$ path problem and the minimum weight spanning tree problem. We show that, unlike the aforementioned results, these problems are tractable, with the exception of the decision version of finding a minimum anti-forcing set for shortest $s$-$t$ paths, which is NP-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24309v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tatsuya Gima, Yasuaki Kobayashi, Yota Otachi, Takumi Sato</dc:creator>
    </item>
    <item>
      <title>Approximating Directed Minimum Cut and Arborescence Packing via Directed Expander Hierarchies</title>
      <link>https://arxiv.org/abs/2512.05300</link>
      <description>arXiv:2512.05300v2 Announce Type: replace 
Abstract: We give almost-linear-time algorithms for approximating rooted minimum cut and maximum arborescence packing in directed graphs, two problems that are dual to each other [Edm73]. More specifically, for an $n$-vertex, $m$-edge directed graph $G$ whose $s$-rooted minimum cut value is $k$, our first algorithm computes an $s$-rooted cut of size at most $O(k\log^{5} n)$ in $m^{1+o(1)}$ time, and our second algorithm packs $k$ $s$-rooted arborescences with $n^{o(1)}$ congestion in $m^{1+o(1)}$ time, certifying that the $s$-rooted minimum cut is at least $k / n^{o(1)}$. Our first algorithm also works for weighted graphs.
  Prior to our work, the fastest algorithms for computing the $s$-rooted minimum cut were exact but had super-linear running time: either $\tilde{O}(mk)$ [Gab91] or $\tilde{O}(m^{1+o(1)}\min\{\sqrt{n},n/m^{1/3}\})$ [CLN+22]. The fastest known algorithms for packing $s$-rooted arborescences had no congestion, but required $\tilde{O}(m \cdot \mathrm{poly}(k))$ time [BHKP08].</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05300v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yonggang Jiang, Yaowei Long, Thatchaphol Saranurak, Benyu Wang</dc:creator>
    </item>
    <item>
      <title>Robust and optimal loading of general classical data into quantum computers</title>
      <link>https://arxiv.org/abs/2411.02782</link>
      <description>arXiv:2411.02782v3 Announce Type: replace-cross 
Abstract: As standard data loading processes, quantum state preparation and block-encoding are critical and necessary processes for quantum computing applications, including quantum machine learning, Hamiltonian simulation, and many others. Yet, existing protocols suffer from poor robustness under device imperfection, thus limiting their practicality for real-world applications. Here, this limitation is overcome based on a fanin process designed in a tree-like bucket-brigade architecture. It suppresses the error propagation between different branches, thus exponentially improving the robustness compared to existing depth-optimal methods. Moreover, the approach here simultaneously achieves the state-of-the-art fault-tolerant circuit depth, gate count, and STA. As an example of application, we show that for quantum simulation of geometrically local Hamiltonian, the code distance of each logic qubit can potentially be reduced exponentially using our technique. We believe that our technique can significantly enhance the power of quantum computing in the near-term and fault-tolerant regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02782v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCAD.2025.3600368</arxiv:DOI>
      <dc:creator>Xiao-Ming Zhang</dc:creator>
    </item>
    <item>
      <title>Digital Quantum Simulations of the Non-Resonant Open Tavis-Cummings Model</title>
      <link>https://arxiv.org/abs/2501.18522</link>
      <description>arXiv:2501.18522v2 Announce Type: replace-cross 
Abstract: The open Tavis--Cummings model consists of $N$ quantum emitters interacting with a common cavity mode, accounts for losses and decoherence, and is frequently explored for quantum information processing and designing quantum devices. As $N$ increases, it becomes harder to simulate the open Tavis--Cummings model using traditional methods. To address this problem, we implement two quantum algorithms for simulating the dynamics of this model in the inhomogeneous, non-resonant regime, with up to three excitations in the cavity. We show that the implemented algorithms have gate complexities that scale polynomially, as $O(N^2)$ and $O(N^3)$, while the number of qubits used by these algorithms (space complexity) scales linearly as $O(N)$. One of these algorithms is the sampling-based wave matrix Lindbladization algorithm, for which we propose two protocols to implement its system-independent fixed interaction, resolving key open questions of [Patel and Wilde, Open Sys. &amp; Info. Dyn., 30:2350014 (2023)]. We benchmark our results against a classical differential equation solver in a variety of scenarios and demonstrate that our algorithms accurately reproduce the expected dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18522v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>physics.comp-ph</category>
      <category>physics.optics</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/yflv-3s7t</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Research 7, 043302 (2025)</arxiv:journal_reference>
      <dc:creator>Aidan N. Sims, Dhrumil Patel, Aby Philip, Alex H. Rubin, Rahul Bandyopadhyay, Marina Radulaski, Mark M. Wilde</dc:creator>
    </item>
    <item>
      <title>Sample-Efficient Optimization over Generative Priors via Coarse Learnability</title>
      <link>https://arxiv.org/abs/2503.06917</link>
      <description>arXiv:2503.06917v3 Announce Type: replace-cross 
Abstract: In zeroth-order optimization, we seek to minimize a function $d(\cdot)$, which may encode combinatorial feasibility, using only function evaluations. We focus on the setting where solutions must also satisfy qualitative constraints or conform to a complex prior distribution. To address this, we introduce a new framework in which such constraints are represented by an initial generative prior $\L(\cdot)$, for example, a Large Language Model (LLM). The objective is to find solutions $s$ that minimize $d(s)$ while having high probability under $\L(s)$, effectively sampling from a target distribution proportional to $\L(s) \cdot e^{-T \cdot d(s)}$ for a temperature parameter $T$.
  While this framework aligns with classical Model-Based Optimization (e.g., the Cross-Entropy method), existing theory is ill-suited for deriving sample complexity bounds in black-box deep generative models. We therefore propose a novel learning assumption, which we term \emph{coarse learnability}, where an agent with access to a polynomial number of samples can learn a model whose point-wise density approximates the target within a polynomial factor. Leveraging this assumption, we design an iterative algorithm that employs a Metropolis-Hastings correction to provably approximate the target distribution using a polynomial number of samples. To the best of our knowledge, this is one of the first works to establish such sample-complexity guarantees for model-based optimization with deep generative priors.
  We provide two lines of evidence supporting the coarse learnability assumption. Theoretically, we show that maximum likelihood estimation naturally induces the required coverage properties, holding for both standard exponential families and for misspecified models. Empirically, we demonstrate that LLMs can adapt their learned distributions to zeroth-order feedback to solve combinatorial optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06917v3</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pranjal Awasthi, Sreenivas Gollapudi, Ravi Kumar, Kamesh Munagala</dc:creator>
    </item>
  </channel>
</rss>
