<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 03 Feb 2026 05:00:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Early warning prediction: Onsager-Machlup vs Schr\"{o}dinger</title>
      <link>https://arxiv.org/abs/2602.00143</link>
      <description>arXiv:2602.00143v1 Announce Type: new 
Abstract: Predicting critical transitions in complex systems, such as epileptic seizures in the brain, represents a major challenge in scientific research. The high-dimensional characteristics and hidden critical signals further complicate early-warning tasks. This study proposes a novel early-warning framework that integrates manifold learning with stochastic dynamical system modeling. Through systematic comparison, six methods including diffusion maps (DM) are selected to construct low-dimensional representations. Based on these, a data-driven stochastic differential equation model is established to robustly estimate the probability evolution scoring function of the system. Building on this, a new Score Function (SF) indicator is defined by incorporating Schr\"{o}dinger bridge theory to quantify the likelihood of significant state transitions in the system. Experiments demonstrate that this indicator exhibits higher sensitivity and robustness in epilepsy prediction, enables earlier identification of critical points, and clearly captures dynamic features across various stages before and after seizure onset. This work provides a systematic theoretical framework and practical methodology for extracting early-warning signals from high-dimensional data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00143v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoai Xu, Yixuan Zhou, Xiang Zhou, Jingqiao Duan, Ting Gao</dc:creator>
    </item>
    <item>
      <title>ProDCARL: Reinforcement Learning-Aligned Diffusion Models for De Novo Antimicrobial Peptide Design</title>
      <link>https://arxiv.org/abs/2602.00157</link>
      <description>arXiv:2602.00157v1 Announce Type: new 
Abstract: Antimicrobial resistance threatens healthcare sustainability and motivates low-cost computational discovery of antimicrobial peptides (AMPs). De novo peptide generation must optimize antimicrobial activity and safety through low predicted toxicity, but likelihood-trained generators do not enforce these goals explicitly. We introduce ProDCARL, a reinforcement-learning alignment framework that couples a diffusion-based protein generator (EvoDiff OA-DM 38M) with sequence property predictors for AMP activity and peptide toxicity. We fine-tune the diffusion prior on AMP sequences to obtain a domain-aware generator. Top-k policy-gradient updates use classifier-derived rewards plus entropy regularization and early stopping to preserve diversity and reduce reward hacking. In silico experiments show ProDCARL increases the mean predicted AMP score from 0.081 after fine-tuning to 0.178. The joint high-quality hit rate reaches 6.3\% with pAMP $&gt;$0.7 and pTox $&lt;$0.3. ProDCARL maintains high diversity, with $1-$mean pairwise identity equal to 0.929. Qualitative analyses with AlphaFold3 and ProtBERT embeddings suggest candidates show plausible AMP-like structural and semantic characteristics. ProDCARL serves as a candidate generator that narrows experimental search space, and experimental validation remains future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00157v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fang Sheng, Mohammad Noaeen, Zahra Shakeri</dc:creator>
    </item>
    <item>
      <title>Rank-and-Reason: Multi-Agent Collaboration Accelerates Zero-Shot Protein Mutation Prediction</title>
      <link>https://arxiv.org/abs/2602.00197</link>
      <description>arXiv:2602.00197v1 Announce Type: new 
Abstract: Zero-shot mutation prediction is vital for low-resource protein engineering, yet existing protein language models (PLMs) often yield statistically confident results that ignore fundamental biophysical constraints. Currently, selecting candidates for wet-lab validation relies on manual expert auditing of PLM outputs, a process that is inefficient, subjective, and highly dependent on domain expertise. To address this, we propose Rank-and-Reason (VenusRAR), a two-stage agentic framework to automate this workflow and maximize expected wet-lab fitness. In the Rank-Stage, a Computational Expert and Virtual Biologist aggregate a context-aware multi-modal ensemble, establishing a new Spearman correlation record of 0.551 (vs. 0.518) on ProteinGym. In the Reason-Stage, an agentic Expert Panel employs chain-of-thought reasoning to audit candidates against geometric and structural constraints, improving the Top-5 Hit Rate by up to 367% on ProteinGym-DMS99. The wet-lab validation on Cas12i3 nuclease further confirms the framework's efficacy, achieving a 46.7% positive rate and identifying two novel mutants with 4.23-fold and 5.05-fold activity improvements. Code and datasets are released on GitHub (https://github.com/ai4protein/VenusRAR/).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00197v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yang Tan, Yuyuan Xi, Can Wu, Bozitao Zhong, Mingchen Li, Guisheng Fan, Jiankang Zhu, Yafeng Liang, Nanqing Dong, Liang Hong</dc:creator>
    </item>
    <item>
      <title>A 30-item Test for Assessing Chinese Character Amnesia in Child Handwriters</title>
      <link>https://arxiv.org/abs/2602.00464</link>
      <description>arXiv:2602.00464v1 Announce Type: new 
Abstract: Handwriting literacy is an important skill for learning and communication in school-age children. In the digital age, handwriting has been largely replaced by typing, leading to a decline in handwriting proficiency, particularly in non-alphabetic writing systems. Among children learning Chinese, a growing number have reported experiencing character amnesia: difficulty in correctly handwriting a character despite being able to recognize it. Given that there is currently no standardized diagnostic tool for assessing character amnesia in children, we developed an assessment to measure Chinese character amnesia in Mandarin-speaking school-age population. We utilised a large-scale handwriting dataset in which 40 children handwrote 800 characters from dictation prompts. Character amnesia and correct handwriting responses were analysed using a two-parameter Item Response Theory model. Four item-selection schemes were compared: random baseline, maximum discrimination, diverse difficulty, and an upper-and-lower-thirds discrimination score. Candidate item subsets were evaluated using out-of-sample prediction. Among these selection schemes, the upper-and-lower-thirds discrimination procedure yields a compact 30-item test that preserves individual-difference structure and generalizes to unseen test-takers (cross-validated mean r =.74 with full 800-item-test; within-sample r =.93). This short-form test provides a reliable and efficient tool of assessing Chinese character amnesia in children and can be used to identify early handwriting and orthographic learning difficulties, contributing to the early detection of developmental dysgraphia and related literacy challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00464v1</guid>
      <category>q-bio.QM</category>
      <category>cs.CV</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zebo Xu, Steven Langsford, Zhuang Qiu, Zhenguang Cai</dc:creator>
    </item>
    <item>
      <title>INDIGENA: inductive prediction of disease-gene associations using phenotype ontologies</title>
      <link>https://arxiv.org/abs/2602.01088</link>
      <description>arXiv:2602.01088v1 Announce Type: new 
Abstract: Motivation: Predicting gene-disease associations (GDAs) is the problem to determine which gene is associated with a disease. GDA prediction can be framed as a ranking problem where genes are ranked for a query disease, based on features such as phenotypic similarity. By describing phenotypes using phenotype ontologies, ontology-based semantic similarity measures can be used. However, traditional semantic similarity measures use only the ontology taxonomy. Recent methods based on ontology embeddings compare phenotypes in latent space; these methods can use all ontology axioms as well as a supervised signal, but are inherently transductive, i.e., query entities must already be known at the time of learning embeddings, and therefore these methods do not generalize to novel diseases (sets of phenotypes) at inference time.
  Results: We developed INDIGENA, an inductive disease-gene association method for ranking genes based on a set of phenotypes. Our method first uses a graph projection to map axioms from phenotype ontologies to a graph structure, and then uses graph embeddings to create latent representations of phenotypes. We use an explicit aggregation strategy to combine phenotype embeddings into representations of genes or diseases, allowing us to generalize to novel sets of phenotypes. We also develop a method to make the phenotype embeddings and the similarity measure task-specific by including a supervised signal from known gene-disease associations. We apply our method to mouse models of human disease and demonstrate that we can significantly improve over the inductive semantic similarity baseline measures, and reach a performance similar to transductive methods for predicting gene-disease associations while being more general.
  Availability and Implementation: https://github.com/bio-ontology-research-group/indigena</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01088v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernando Zhapa-Camacho, Robert Hoehndorf</dc:creator>
    </item>
    <item>
      <title>Is Normalized Biomass Really Abundance? Pitfalls, Artifacts, and Misconceptions in the Field of Size Spectra Analysis -- A Case for Back-Transformed Spectra</title>
      <link>https://arxiv.org/abs/2602.01496</link>
      <description>arXiv:2602.01496v1 Announce Type: new 
Abstract: The NBSS (normalized biomass size spectrum) is a common, intuitive approach for the study of natural ecosystems. However, very few studies have been dedicated to verifying possible bias, flaws, and paradoxes in this widely used method. An evident issue of this method, that best exemplifies its discrepancies and paradoxes, is the use of intriguing non-biomass units (such as abundance, biomass flux, or pseudo-abundance units) on NBSS plots, that are intended to visualize biomass spectra. The main objectives of this study were to verify, test and analyze the procedures involved in transformations that lead to the popular NBSS plot, and to check for the correctness of currently used units, while testing the hypothesis that NBSS indeed represents biomass, not abundance or biomass flux (dB/dM), while developing i.) a new conceptual framework, ii.) new terminology, iii.) a novel back-transformation method, iv.) a simple, new calculation method, that yields the best (i.e., least biased) representation of the original biomass vs body mass distribution shape, numerical values, dimensions, and units. Extensive tests with in-situ and synthetic (simulated) data were used to verify the procedures involved in transformations that lead to the popular NBSS plots, and to compare the original biomass distribution data with the binned outputs. Original biomass units and dimensions are retained in the novel backtransformed normalized biomass spectrum (bNBS), proposed and described herein. The proposed bNBS constitutes a new, improved approach of robust size spectra science, that allows for quantitative inter-comparisons of biomass spectra across regions and time periods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01496v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ralf Schwamborn</dc:creator>
    </item>
    <item>
      <title>MGKAN: Predicting Asymmetric Drug-Drug Interactions via a Multimodal Graph Kolmogorov-Arnold Network</title>
      <link>https://arxiv.org/abs/2602.01751</link>
      <description>arXiv:2602.01751v1 Announce Type: cross 
Abstract: Predicting drug-drug interactions (DDIs) is essential for safe pharmacological treatments. Previous graph neural network (GNN) models leverage molecular structures and interaction networks but mostly rely on linear aggregation and symmetric assumptions, limiting their ability to capture nonlinear and heterogeneous patterns. We propose MGKAN, a Graph Kolmogorov-Arnold Network that introduces learnable basis functions into asymmetric DDI prediction. MGKAN replaces conventional MLP transformations with KAN-driven basis functions, enabling more expressive and nonlinear modeling of drug relationships. To capture pharmacological dependencies, MGKAN integrates three network views-an asymmetric DDI network, a co-interaction network, and a biochemical similarity network-with role-specific embeddings to preserve directional semantics. A fusion module combines linear attention and nonlinear transformation to enhance representational capacity. On two benchmark datasets, MGKAN outperforms seven state-of-the-art baselines. Ablation studies and case studies confirm its predictive accuracy and effectiveness in modeling directional drug effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01751v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kunyi Fan, Mengjie Chen, Longlong Li, Cunquan Qu</dc:creator>
    </item>
    <item>
      <title>DIA-CLIP: a universal representation learning framework for zero-shot DIA proteomics</title>
      <link>https://arxiv.org/abs/2602.01772</link>
      <description>arXiv:2602.01772v1 Announce Type: cross 
Abstract: Data-independent acquisition mass spectrometry (DIA-MS) has established itself as a cornerstone of proteomic profiling and large-scale systems biology, offering unparalleled depth and reproducibility. Current DIA analysis frameworks, however, require semi-supervised training within each run for peptide-spectrum match (PSM) re-scoring. This approach is prone to overfitting and lacks generalizability across diverse species and experimental conditions. Here, we present DIA-CLIP, a pre-trained model shifting the DIA analysis paradigm from semi-supervised training to universal cross-modal representation learning. By integrating dual-encoder contrastive learning framework with encoder-decoder architecture, DIA-CLIP establishes a unified cross-modal representation for peptides and corresponding spectral features, achieving high-precision, zero-shot PSM inference. Extensive evaluations across diverse benchmarks demonstrate that DIA-CLIP consistently outperforms state-of-the-art tools, yielding up to a 45% increase in protein identification while achieving a 12% reduction in entrapment identifications. Moreover, DIA-CLIP holds immense potential for diverse practical applications, such as single-cell and spatial proteomics, where its enhanced identification depth facilitates the discovery of novel biomarkers and the elucidates of intricate cellular mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01772v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yucheng Liao, Han Wen, Weinan E, Weijie Zhang</dc:creator>
    </item>
    <item>
      <title>No Generation without Representation: Efficient Causal Protein Language Models Enable Zero-Shot Fitness Estimation</title>
      <link>https://arxiv.org/abs/2602.01845</link>
      <description>arXiv:2602.01845v1 Announce Type: cross 
Abstract: Protein language models (PLMs) face a fundamental divide: masked language models (MLMs) excel at fitness prediction while causal models enable generation, forcing practitioners to maintain separate architectures. We introduce \textbf{Proust}, a 309M-parameter causal PLM that bridges this gap through architectural innovations adapted from recent LLM research, including grouped-query attention with shared K/V projections, cross-layer value residuals, and depthwise causal convolutions. Trained on 33B tokens in 40 B200 GPU-hours, Proust achieves Spearman $\rho = 0.390$ on ProteinGym substitutions, competitive with MLMs requiring 50--200$\times$ the compute. On indels, Proust sets a new state-of-the-art, outperforming models up to 20$\times$ larger. On EVEREST viral fitness benchmarks, it approaches structure-aware methods using sequence alone. These powerful representations position Proust in a sweet spot as it also retains native generative capabilities that MLMs lack by design. Interpretability analysis reveals that per-position entropy variance predicts, to an extent, when retrieval augmentation helps and hurts. Such insights can grow in both quantity and quality at scale and inform capabilities such as test-time scaling. Code and weights are available at https://github.com/Furkan9015/proust-inference</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01845v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Furkan Eris</dc:creator>
    </item>
    <item>
      <title>Scalable Spatio-Temporal SE(3) Diffusion for Long-Horizon Protein Dynamics</title>
      <link>https://arxiv.org/abs/2602.02128</link>
      <description>arXiv:2602.02128v1 Announce Type: cross 
Abstract: Molecular dynamics (MD) simulations remain the gold standard for studying protein dynamics, but their computational cost limits access to biologically relevant timescales. Recent generative models have shown promise in accelerating simulations, yet they struggle with long-horizon generation due to architectural constraints, error accumulation, and inadequate modeling of spatio-temporal dynamics. We present STAR-MD (Spatio-Temporal Autoregressive Rollout for Molecular Dynamics), a scalable SE(3)-equivariant diffusion model that generates physically plausible protein trajectories over microsecond timescales. Our key innovation is a causal diffusion transformer with joint spatio-temporal attention that efficiently captures complex space-time dependencies while avoiding the memory bottlenecks of existing methods. On the standard ATLAS benchmark, STAR-MD achieves state-of-the-art performance across all metrics--substantially improving conformational coverage, structural validity, and dynamic fidelity compared to previous methods. STAR-MD successfully extrapolates to generate stable microsecond-scale trajectories where baseline methods fail catastrophically, maintaining high structural quality throughout the extended rollout. Our comprehensive evaluation reveals severe limitations in current models for long-horizon generation, while demonstrating that STAR-MD's joint spatio-temporal modeling enables robust dynamics simulation at biologically relevant timescales, paving the way for accelerated exploration of protein function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02128v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.bio-ph</category>
      <category>q-bio.BM</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nima Shoghi, Yuxuan Liu, Yuning Shen, Rob Brekelmans, Pan Li, Quanquan Gu</dc:creator>
    </item>
    <item>
      <title>Repurposing Protein Language Models for Latent Flow-Based Fitness Optimization</title>
      <link>https://arxiv.org/abs/2602.02425</link>
      <description>arXiv:2602.02425v1 Announce Type: cross 
Abstract: Protein fitness optimization is challenged by a vast combinatorial landscape where high-fitness variants are extremely sparse. Many current methods either underperform or require computationally expensive gradient-based sampling. We present CHASE, a framework that repurposes the evolutionary knowledge of pretrained protein language models by compressing their embeddings into a compact latent space. By training a conditional flow-matching model with classifier-free guidance, we enable the direct generation of high-fitness variants without predictor-based guidance during the ODE sampling steps. CHASE achieves state-of-the-art performance on AAV and GFP protein design benchmarks. Finally, we show that bootstrapping with synthetic data can further enhance performance in data-constrained settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02425v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amaru Caceres Arroyo, Lea Bogensperger, Ahmed Allam, Michael Krauthammer, Konrad Schindler, Dominik Narnhofer</dc:creator>
    </item>
    <item>
      <title>UniZyme: A Unified Protein Cleavage Site Predictor Enhanced with Enzyme Active-Site Knowledge</title>
      <link>https://arxiv.org/abs/2502.06914</link>
      <description>arXiv:2502.06914v3 Announce Type: replace 
Abstract: Enzyme-catalyzed protein cleavage is essential for many biological functions. Accurate prediction of cleavage sites can facilitate various applications such as drug development, enzyme design, and a deeper understanding of biological mechanisms. However, most existing models are restricted to an individual enzyme, which neglects shared knowledge of enzymes and fails to generalize to novel enzymes. Thus, we introduce a unified protein cleavage site predictor named UniZyme, which can generalize across diverse enzymes. To enhance the enzyme encoding for the protein cleavage site prediction, UniZyme employs a novel biochemically-informed model architecture along with active-site knowledge of proteolytic enzymes. Extensive experiments demonstrate that UniZyme achieves high accuracy in predicting cleavage sites across a range of proteolytic enzymes, including unseen enzymes. The code is available in https://github.com/Ao-LiChen/UniZyme</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06914v3</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chenao Li, Shuo Yan, Enyan Dai</dc:creator>
    </item>
    <item>
      <title>Evaluation of machine-learning models to measure individualized treatment effects from randomized clinical trial data with time-to-event outcomes</title>
      <link>https://arxiv.org/abs/2506.12277</link>
      <description>arXiv:2506.12277v2 Announce Type: replace 
Abstract: Objective: In randomized clinical trials, prediction models can be used to explore the relationships between patients' variables (e.g., clinical, pathological, or lifestyle variables, and also biomarker or genomic data) and treatment effect magnitude. Our aim was to evaluate flexible machine learning models capable of incorporating interactions and nonlinear effects from high-dimensional data to estimate individualized treatment recommendations in trials with time-to-event outcomes.
  Methods: We compared survival models based on neural networks (CoxCC and CoxTime) and random survival forests (Interaction Forests) against a Cox proportional hazards model with an adaptive LASSO (ALASSO) penalty as a benchmark. For individualized treatment recommendations in the survival setting, we adapted metrics originally designed for binary outcomes to accommodate time-to-event data with censoring. These adapted metrics included the C-for-Benefit, the E50-for-Benefit, and the root mean squared error for treatment benefit. An extensive simulation study was conducted using two different data generation processes incorporating nonlinearity and interactions. The models were applied to gene expression and clinical data from three cancer clinical trial data sets.
  Results: In the first data generation process, neural networks outperformed ALASSO in terms of calibration while the Interaction Forests showed superior C-for-benefit performance. In the second data generation process, both machine learning methods outperformed the benchmark linear ALASSO method across discrimination, calibration, and RMSE metrics. In the cancer trial data sets, the machine learning methods often performed better than ALASSO, particularly IF in terms of C-for-benefit, and either a neural network or IF for calibration measures addressing treatment benefit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12277v2</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elvire Roblin, Paul-Henry Courn\`ede, Stefan Michiels</dc:creator>
    </item>
    <item>
      <title>Comparing Bayesian and Frequentist Inference in Biological Models: A Comparative Analysis of Accuracy, Uncertainty, and Identifiability</title>
      <link>https://arxiv.org/abs/2511.15839</link>
      <description>arXiv:2511.15839v2 Announce Type: replace 
Abstract: Mathematical models support inference and forecasting in ecology and epidemiology, but results depend on the estimation framework. We compare Bayesian and Frequentist approaches across three biological models using four datasets: Lotka-Volterra predator-prey dynamics (Hudson Bay), a generalized logistic model (lung injury and 2022 U.S. mpox), and an SEIUR epidemic model (COVID-19 in Spain). Both approaches use a normal error structure to ensure a fair comparison.
  We first assessed structural identifiability to determine which parameters can theoretically be recovered from the data. We then evaluated practical identifiability and forecasting performance using four metrics: mean absolute error (MAE), mean squared error (MSE), 95 percent prediction interval (PI) coverage, and weighted interval score (WIS). For the Lotka-Volterra model with both prey and predator data, we analyzed three scenarios: prey only, predator only, and both.
  The Frequentist workflow used QuantDiffForecast (QDF) in MATLAB, which fits ODE models via nonlinear least squares and quantifies uncertainty through parametric bootstrap. The Bayesian workflow used BayesianFitForecast (BFF), which employs Hamiltonian Monte Carlo sampling via Stan to generate posterior distributions and diagnostics such as the Gelman-Rubin R-hat statistic.
  Results show that Frequentist inference performs best when data are rich and fully observed, while Bayesian inference excels when latent-state uncertainty is high and data are sparse, as in the SEIUR COVID-19 model. Structural identifiability clarifies these patterns: full observability benefits both frameworks, while limited observability constrains parameter recovery. This comparison provides guidance for choosing inference frameworks based on data richness, observability, and uncertainty needs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15839v2</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammed A. Y. Mohammed, Hamed Karami, Gerardo Chowell</dc:creator>
    </item>
    <item>
      <title>GPCR-Filter: a deep learning framework for efficient and precise GPCR modulator discovery</title>
      <link>https://arxiv.org/abs/2601.19149</link>
      <description>arXiv:2601.19149v2 Announce Type: replace-cross 
Abstract: G protein-coupled receptors (GPCRs) govern diverse physiological processes and are central to modern pharmacology. Yet discovering GPCR modulators remains challenging because receptor activation often arises from complex allosteric effects rather than direct binding affinity, and conventional assays are slow, costly, and not optimized for capturing these dynamics. Here we present GPCR-Filter, a deep learning framework specifically developed for GPCR modulator discovery. We assembled a high-quality dataset of over 90,000 experimentally validated GPCR-ligand pairs, providing a robust foundation for training and evaluation. GPCR-Filter integrates the ESM-3 protein language model for high-fidelity GPCR sequence representations with graph neural networks that encode ligand structures, coupled through an attention-based fusion mechanism that learns receptor-ligand functional relationships. Across multiple evaluation settings, GPCR-Filter consistently outperforms state-of-the-art compound-protein interaction models and exhibits strong generalization to unseen receptors and ligands. Notably, the model successfully identified micromolar-level agonists of the 5-HT\textsubscript{1A} receptor with distinct chemical frameworks. These results establish GPCR-Filter as a scalable and effective computational approach for GPCR modulator discovery, advancing AI-assisted drug development for complex signaling systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19149v2</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingjie Ning, Xiangzhen Shen, Li Hou, Shiyi Shen, Jiahao Yang, Junrui Li, Hong Shan, Sanan Wu, Sihan Gao, H. Eric Xu, Xinheng He</dc:creator>
    </item>
  </channel>
</rss>
