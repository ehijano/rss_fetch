<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Feb 2026 05:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>interwhen: A Generalizable Framework for Verifiable Reasoning with Test-time Monitors</title>
      <link>https://arxiv.org/abs/2602.11202</link>
      <description>arXiv:2602.11202v1 Announce Type: new 
Abstract: We present a test-time verification framework, interwhen, that ensures that the output of a reasoning model is valid wrt. a given set of verifiers. Verified reasoning is an important goal in high-stakes scenarios such as deploying agents in the physical world or in domains such as law and finance. However, current techniques either rely on the generate-test paradigm that verifies only after the final answer is produced, or verify partial output through a step-extraction paradigm where the task execution is externally broken down into structured steps. The former is inefficient while the latter artificially restricts a model's problem solving strategies. Instead, we propose to verify a model's reasoning trace as-is, taking full advantage of a model's reasoning capabilities while verifying and steering the model's output only when needed. The key idea is meta-prompting, identifying the verifiable properties that any partial solution should satisfy and then prompting the model to follow a custom format in its trace such that partial outputs can be easily parsed and checked. We consider both self-verification and external verification and find that interwhen provides a useful abstraction to provide feedback and steer reasoning models in each case. Using self-verification, interwhen obtains state-of-the-art results on early stopping reasoning models, without any loss in accuracy. Using external verifiers, interwhen obtains 10 p.p. improvement in accuracy over test-time scaling methods, while ensuring 100% soundness and being 4x more efficient. The code for interwhen is available at https://github.com/microsoft/interwhen</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11202v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vishak K Bhat, Prateek Chanda, Ashmit Khandelwal, Maitreyi Swaroop, Vineeth N. Balasubramanian, Subbarao Kambhampati, Nagarajan Natarajan, Amit Sharma</dc:creator>
    </item>
    <item>
      <title>Compositionality of Systems and Partially Ordered Runs</title>
      <link>https://arxiv.org/abs/2602.11203</link>
      <description>arXiv:2602.11203v1 Announce Type: new 
Abstract: In the late 1970s, C.A. Petri introduced partially ordered event occurrences (runs), then called \emph{processes}, as the appropriate model to describe the individual evolutions of distributed systems. Here, we present a unified framework for handling Petri nets and their runs, specifically to compose and decompose them. It is shown that, for nets $M$ and $N$, the set of runs of the composed net $M \bullet N$ equals the composition of the runs of $M$ and $N$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11203v1</guid>
      <category>cs.LO</category>
      <category>cs.SE</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Fettke, Wolfgang Reisig</dc:creator>
    </item>
    <item>
      <title>A Unified Treatment of Substitution for Presheaves, Nominal Sets, Renaming Sets, and so on</title>
      <link>https://arxiv.org/abs/2602.11907</link>
      <description>arXiv:2602.11907v1 Announce Type: new 
Abstract: Presheaves and nominal sets provide alternative abstract models of sets of syntactic objects with free and bound variables, such as lambda-terms. One distinguishing feature of the presheaf-based perspective is its elegant syntax-free characterization of substitution using a closed monoidal structure. In this paper, we introduce a corresponding closed monoidal structure on nominal sets, modeling substitution in the spirit of Fiore et al.'s substitution tensor for presheaves over finite sets. To this end, we present a general method to derive a closed monoidal structure on a category from a given action of a monoidal category on that category. We demonstrate that this method not only uniformly recovers known substitution tensors for various kinds of presheaf categories, but also yields novel notions of substitution tensor for nominal sets and their relatives, such as renaming sets. In doing so, we shed new light on different incarnations of nominal sets and (pre-)sheaf categories and establish a number of novel correspondences between them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11907v1</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Lenke, Stefan Milius, Henning Urbat</dc:creator>
    </item>
    <item>
      <title>Unravelling Abstract Cyclic Proofs into Proofs by Induction</title>
      <link>https://arxiv.org/abs/2602.12054</link>
      <description>arXiv:2602.12054v1 Announce Type: new 
Abstract: Cyclic proof theory breaks tradition by allowing certain infinite proofs: those that can be represented by a finite graph, while satisfying a soundness condition. We reconcile cyclic proofs with traditional finite proofs: we extend abstract cyclic proof systems with a well-founded induction principle, and transform any cyclic proof into a finite proof in the extended system. Moreover, this transformation preserves the structure of the cyclic proof.
  Our results leverage an annotated representation of cyclic proofs, which allows us to extract induction hypotheses and to determine their introduction order. The representation is essentially a reset proof with one key modification: names must be covered in a uniform way before a reset. This innovation allows us to handle cyclic proofs where the underlying inductive sort is non-linear.
  Our framework is general enough to cover recursive functions satisfying the size-change termination principle, which are viewed as cyclic proofs under the Curry-Howard correspondence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12054v1</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lide Grotenhuis, Dani\"el Otten</dc:creator>
    </item>
    <item>
      <title>Computing Distinguishing Formulae for Threshold-Based Behavioural Distances</title>
      <link>https://arxiv.org/abs/2602.12084</link>
      <description>arXiv:2602.12084v1 Announce Type: new 
Abstract: Behavioural distances generally offer more fine-grained means of comparing quantitative systems than two-valued behavioural equivalences. They often relate to quantitative modalities, which generate quantitative modal logics that characterize a given behavioural distance in terms of the induced logical distance. We develop a unified framework for behavioural distances and logics induced by a special type of modalities that lift two-valued predicates to quantitative predicates. A typical example is the probability operator, which maps a two-valued predicate $A$ to a quantitative predicate on probability distributions assigning to each distribution the respective probability of $A$. Correspondingly, the prototypical example of our framework is $\epsilon$-bisimulation distance of Markov chains, which has recently been shown to coincide with the behavioural distance induced by the popular L\'evy-Prokhorov distance on distributions. Other examples include behavioural distance on metric transition systems and Hausdorff behavioural distance on fuzzy transition systems. Our main generic results concern the polynomial-time extraction of distinguishing formulae in two characteristic modal logics: A two-valued logic with a notion of satisfaction up to $\epsilon$, and a quantitative modal logic. These results instantiate to new results in many of the mentioned examples. Notably, we obtain polynomial-time extraction of distinguishing formulae for $\epsilon$-bisimulation distance of Markov chains in a quantitative logic featuring a `generally' modality used in probabilistic knowledge representation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12084v1</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Forster, Lutz Schr\"oder, Paul Wild, Barbara K\"onig, Pedro Nora</dc:creator>
    </item>
    <item>
      <title>Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication</title>
      <link>https://arxiv.org/abs/2602.12083</link>
      <description>arXiv:2602.12083v1 Announce Type: cross 
Abstract: As multi-agent AI systems evolve from simple chatbots to autonomous swarms, debugging semantic failures requires reasoning about knowledge, belief, causality, and obligation, precisely what modal logic was designed to formalize. However, traditional modal logic requires manual specification of relationship structures that are unknown or dynamic in real systems. This tutorial demonstrates differentiable modal logic (DML), implemented via Modal Logical Neural Networks (MLNNs), enabling systems to learn trust networks, causal chains, and regulatory boundaries from behavioral data alone.
  We present a unified neurosymbolic debugging framework through four modalities: epistemic (who to trust), temporal (when events cause failures), deontic (what actions are permitted), and doxastic (how to interpret agent confidence). Each modality is demonstrated on concrete multi-agent scenarios, from discovering deceptive alliances in diplomacy games to detecting LLM hallucinations, with complete implementations showing how logical contradictions become learnable optimization objectives. Key contributions for the neurosymbolic community: (1) interpretable learned structures where trust and causality are explicit parameters, not opaque embeddings; (2) knowledge injection via differentiable axioms that guide learning with sparse data (3) compositional multi-modal reasoning that combines epistemic, temporal, and deontic constraints; and (4) practical deployment patterns for monitoring, active control and communication of multi-agent systems. All code provided as executable Jupyter notebooks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12083v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonin Sulc</dc:creator>
    </item>
    <item>
      <title>Compiling High-Level Neural Network Specifications into VNN-LIB Queries</title>
      <link>https://arxiv.org/abs/2402.01353</link>
      <description>arXiv:2402.01353v2 Announce Type: replace 
Abstract: The formal verification of traditional software has been revolutionised by verification-orientated languages such as Dafny and F* which enable developers to write high-level specifications that are automatically compiled down to low-level SMT-LIB queries. In contrast, neural network verification currently lacks such infrastructure, often requiring users to express requirements in formats close to the low-level VNN-LIB query format. This gap persists because targeting VNN-LIB presents unique algorithmic challenges when compared to targeting SMT-LIB: VNN-LIB is restricted to a fixed finite set of variables representing the input and outputs of the network, and even toy neural network specifications have an extremely large number of variables.
  In this paper, we present the first algorithm for compiling high-level neural network specifications into optimised VNN-LIB queries. Our algorithm is numerically sound and supports a far rich logical fragment than existing tools, including transformations of variables, first-class quantifiers, and specifications involving multiple networks or multiple applications of the same network. We implement this algorithm within the Vehicle framework and demonstrate that its performance is asymptotically optimal for benchmark specifications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01353v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew L. Daggitt, Wen Kokke, Robert Atkey</dc:creator>
    </item>
    <item>
      <title>Non-Expansive Fuzzy Coalgebraic Logic</title>
      <link>https://arxiv.org/abs/2510.11080</link>
      <description>arXiv:2510.11080v2 Announce Type: replace 
Abstract: Fuzzy logic extends the classical truth values "true" and "false" with additional truth degrees in between. More specifically, fuzzy modal logics in this sense are given by a choice of fuzzy modalities and a fuzzy propositional base. It has been noted that fuzzy modal logics over the Zadeh base, which interprets disjunction as maximum, are often computationally tractable but on the other hand add little in the way of expressivity to their classical counterparts. Contrastingly, fuzzy modal logics over the more expressive Lukasiewicz base have attractive logical properties but are often computationally less tractable or even undecidable. In the basic case of the modal logic of fuzzy relations, sometimes termed fuzzy ALC, it has recently been shown that an intermediate non-expansive propositional base, known from characteristic logics for behavioural distances of quantitative systems, strikes a balance between these poles: It provides increased expressiveness over the Zadeh base while avoiding the computational problems of the Lukasiewicz base, in fact allowing for reasoning in PSpace. Modal logics, in particular fuzzy modal logics, generally vary widely in terms of syntax and semantics, involving, for instance, probabilistic, preferential, or weighted structures. Coalgebraic modal logic provides a unifying framework for wide ranges of semantically different modal logics, both two-valued and fuzzy. In the present work, we focus on non-expansive coalgebraic fuzzy modal logics, providing a criterion for decidability in PSpace. Using this criterion, we recover the mentioned complexity result for non-expansive fuzzy ALC and moreover obtain new PSpace upper bounds for various quantitative modal logics over probabilistic and metric transition systems. Notably, we show that the logic of generally, which has recently been shown to characterize e-distance on Markov chains, is decidable in PSpace.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11080v2</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Gebhart, Lutz Schr\"oder, Paul Wild</dc:creator>
    </item>
    <item>
      <title>Modal Logical Neural Networks</title>
      <link>https://arxiv.org/abs/2512.03491</link>
      <description>arXiv:2512.03491v2 Announce Type: replace-cross 
Abstract: We propose Modal Logical Neural Networks (MLNNs), a neurosymbolic framework that integrates deep learning with the formal semantics of modal logic, enabling reasoning about necessity and possibility. Drawing on Kripke semantics, we introduce specialized neurons for the modal operators $\Box$ and $\Diamond$ that operate over a set of possible worlds, enabling the framework to act as a differentiable ``logical guardrail.'' The architecture is highly flexible: the accessibility relation between worlds can either be fixed by the user to enforce known rules or, as an inductive feature, be parameterized by a neural network. This allows the model to optionally learn the relational structure of a logical system from data while simultaneously performing deductive reasoning within that structure.
  This versatile construction is designed for flexibility. The entire framework is differentiable from end to end, with learning driven by minimizing a logical contradiction loss. This not only makes the system resilient to inconsistent knowledge but also enables it to learn nonlinear relationships that can help define the logic of a problem space. We illustrate MLNNs on four case studies: grammatical guardrailing, multi-agent epistemic trust, detecting constructive deception in natural language negotiation, and combinatorial constraint satisfaction in Sudoku. These experiments demonstrate how enforcing or learning accessibility can increase logical consistency and interpretability without changing the underlying task architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03491v2</guid>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonin Sulc</dc:creator>
    </item>
  </channel>
</rss>
