<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Jul 2024 01:37:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Physics of Learning: From Autoencoders to Truly Autonomous Learning Machines</title>
      <link>https://arxiv.org/abs/2407.04700</link>
      <description>arXiv:2407.04700v1 Announce Type: new 
Abstract: The fact that accurately predicted information can serve as an energy source paves the way for new approaches to autonomous learning. The energy derived from a sequence of successful predictions can be recycled as an immediate incentive and resource, driving the enhancement of predictive capabilities in AI agents. We propose that, through a series of straightforward meta-architectural adjustments, any unsupervised learning apparatus could achieve complete independence from external energy sources, evolving into a self-sustaining physical system with a strong intrinsic 'drive' for continual learning. This concept, while still purely theoretical, is exemplified through the autoencoder, a quintessential model for unsupervised efficient coding. We use this model to demonstrate how progressive paradigm shifts can profoundly alter our comprehension of learning and intelligence. By reconceptualizing learning as an energy-seeking process, we highlight the potential for achieving true autonomy in learning systems, thereby bridging the gap between algorithmic concepts and physical models of intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04700v1</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>physics.class-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex Ushveridze</dc:creator>
    </item>
    <item>
      <title>Quantum Ranging Enhanced TDoA Localization</title>
      <link>https://arxiv.org/abs/2407.04703</link>
      <description>arXiv:2407.04703v1 Announce Type: new 
Abstract: Localization is critical to numerous applications. The performance of classical localization protocols is limited by the specific form of distance information and suffer from considerable ranging errors. This paper foresees a new opportunity by utilizing the exceptional property of entangled quantum states to measure a linear combination of target-anchor distances. Specifically, we consider localization with quantum-based TDoA measurements. Classical TDoA ranging takes the difference of two separate measurements. Instead, quantum ranging allows TDoA estimation within a single measurement, thereby reducing the ranging errors. Numerical simulations demonstrate that the new quantum-based localization significantly outperforms conventional algorithms based on classical ranging, with over 50% gains on average.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04703v1</guid>
      <category>cs.ET</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ICASSP48485.2024.10446684</arxiv:DOI>
      <arxiv:journal_reference>ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</arxiv:journal_reference>
      <dc:creator>Entong He, Yuxiang Yang, Chenshu Wu</dc:creator>
    </item>
    <item>
      <title>16-channel Photonic Solver for Optimization Problems on a Silicon Chip</title>
      <link>https://arxiv.org/abs/2407.04713</link>
      <description>arXiv:2407.04713v1 Announce Type: new 
Abstract: In this article, we proposed a programmable 16-channel photonic solver for quadratic unconstrained binary optimization (QUBO) problems. The solver is based on a hybrid optoelectronic scheme including a photonic chip and the corresponding electronic driving circuit. The photonic chip is fabricated on silicon on insulator (SOI) substrate and integrates high-speed electro-optic modulators, thermo-optic phase shifters and photodetectors to conduct the 16-dimensional optical vector-matrix multiplication (OVMM). Due to the parallel and low latency propagation of lightwave, the calculation of the QUBO cost function can be accelerated. Besides, the electronic processor is employed to run the heuristic algorithm to search the optimal solution. In the experiment, two 16-dimensional randomly generated QUBO problems are solved with high successful probabilities. To our knowledge, it is the largest scale of programmable and on-chip photonic solver ever reported. Moreover, the computing speed of the OVMM on photonic chip is ~2 TFLOP/s. It shows the potential of fast solving such optimization problems with integrated photonic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04713v1</guid>
      <category>cs.ET</category>
      <category>physics.optics</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiayi Ouyang, Shengping Liu, Ziyue Yang, Wei Wang, Xue Feng, Yongzhuo Li, Yidong Huang</dc:creator>
    </item>
    <item>
      <title>$i$Trust: Trust-Region Optimisation with Ising Machines</title>
      <link>https://arxiv.org/abs/2407.04715</link>
      <description>arXiv:2407.04715v1 Announce Type: new 
Abstract: In this work, we present a heretofore unseen application of Ising machines to perform trust region-based optimisation with box constraints. This is done by considering a specific form of opto-electronic oscillator-based coherent Ising machines with clipped transfer functions, and proposing appropriate modifications to facilitate trust-region optimisation. The enhancements include the inclusion of non-symmetric coupling and linear terms, modulation of noise, and compatibility with convex-projections to improve its convergence. The convergence of the modified Ising machine has been shown under the reasonable assumptions of convexity or invexity. The mathematical structures of the modified Ising machine and trust-region methods have been exploited to design a new trust-region method to effectively solve unconstrained optimisation problems in many scenarios, such as machine learning and optimisation of parameters in variational quantum algorithms. Hence, the proposition is useful for both classical and quantum-classical hybrid scenarios. Finally, the convergence of the Ising machine-based trust-region method, has also been proven analytically, establishing the feasibility of the technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04715v1</guid>
      <category>cs.ET</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sayantan Pramanik, Kaumudibikash Goswami, Sourav Chatterjee, M Girish Chandra</dc:creator>
    </item>
    <item>
      <title>Classical and Quantum Physical Reservoir Computing for Onboard Artificial Intelligence Systems: A Perspective</title>
      <link>https://arxiv.org/abs/2407.04717</link>
      <description>arXiv:2407.04717v1 Announce Type: new 
Abstract: Artificial intelligence (AI) systems of autonomous systems such as drones, robots and self-driving cars may consume up to 50% of total power available onboard, thereby limiting the vehicle's range of functions and considerably reducing the distance the vehicle can travel on a single charge. Next-generation onboard AI systems need an even higher power since they collect and process even larger amounts of data in real time. This problem cannot be solved using the traditional computing devices since they become more and more power-consuming. In this review article, we discuss the perspectives of development of onboard neuromorphic computers that mimic the operation of a biological brain using nonlinear-dynamical properties of natural physical environments surrounding autonomous vehicles. Previous research also demonstrated that quantum neuromorphic processors (QNPs) can conduct computations with the efficiency of a standard computer while consuming less than 1% of the onboard battery power. Since QNPs is a semi-classical technology, their technical simplicity and low, compared with quantum computers, cost make them ideally suitable for application in autonomous AI system. Providing a perspective view on the future progress in unconventional physical reservoir computing and surveying the outcomes of more than 200 interdisciplinary research works, this article will be of interest to a broad readership, including both students and experts in the fields of physics, engineering, quantum technologies and computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04717v1</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>cs.RO</category>
      <category>nlin.CD</category>
      <category>physics.flu-dyn</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. H. Abbas, Hend Abdel-Ghani, Ivan S. Maksymov</dc:creator>
    </item>
    <item>
      <title>Event-Based Simulation of Stochastic Memristive Devices for Neuromorphic Computing</title>
      <link>https://arxiv.org/abs/2407.04718</link>
      <description>arXiv:2407.04718v1 Announce Type: new 
Abstract: In this paper, we build a general model of memristors suitable for the simulation of event-based systems, such as hardware spiking neural networks, and more generally, neuromorphic computing systems. We extend an existing general model of memristors - the Generalised Metastable Switch Model - to an event-driven setting, eliminating errors associated discrete time approximation, as well as offering potential improvements in terms of computational efficiency for simulation. We introduce the notion of a volatility state variable, to allow for the modelling of memory-dependent and dynamic switching behaviour, succinctly capturing and unifying a variety of volatile phenomena present in memristive devices, including state relaxation, structural disruption, Joule heating, and drift acceleration phenomena. We supply a drift dataset for titanium dioxide memristors and introduce a linear conductance model to simulate the drift characteristics, motivated by a proposed physical model of filament growth. We then demonstrate an approach for fitting the parameters of the event-based model to the drift model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04718v1</guid>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <category>physics.app-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Waleed El-Geresy, Christos Papavassiliou, Deniz G\"und\"uz</dc:creator>
    </item>
    <item>
      <title>A 103-TOPS/mm$^2$ Integrated Photonic Computing Engine Enabling Next-Generation Reservoir Computing</title>
      <link>https://arxiv.org/abs/2407.05840</link>
      <description>arXiv:2407.05840v1 Announce Type: new 
Abstract: Reservoir computing (RC) is a leading machine learning algorithm for information processing due to its rich expressiveness. A new RC paradigm has recently emerged, showcasing superior performance and delivering more interpretable results with shorter training data sets and training times, representing the next generation of RC computing. This work presents the first realization of a high-speed next-generation RC system on an integrated photonic chip. Our experimental results demonstrate state-of-the-art forecasting and classification performances under various machine learning tasks and achieve the fastest speeds of 60 Gbaud and a computing density of 103 tera operations/second/mm$^2$ (TOPS/mm$^2$). The passive system, composed of a simple star coupler with on-chip delay lines, offers several advantages over traditional RC systems, including no speed limitations, compact footprint, extremely high fabrication error tolerance, fewer metaparameters, and greater interpretability. This work lays the foundation for ultrafast on-chip photonic RC, representing significant progress toward developing next-generation high-speed photonic computing and signal processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05840v1</guid>
      <category>cs.ET</category>
      <category>physics.optics</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongliang Wang, Yikun Nie, Gaolei Hu, Hon Ki Tsang, Chaoran Huang</dc:creator>
    </item>
    <item>
      <title>AgriLLM: Harnessing Transformers for Farmer Queries</title>
      <link>https://arxiv.org/abs/2407.04721</link>
      <description>arXiv:2407.04721v1 Announce Type: cross 
Abstract: Agriculture, vital for global sustenance, necessitates innovative solutions due to a lack of organized domain experts, particularly in developing countries where many farmers are impoverished and cannot afford expert consulting. Initiatives like Farmers Helpline play a crucial role in such countries, yet challenges such as high operational costs persist. Automating query resolution can alleviate the burden on traditional call centers, providing farmers with immediate and contextually relevant information. The integration of Agriculture and Artificial Intelligence (AI) offers a transformative opportunity to empower farmers and bridge information gaps. Language models like transformers, the rising stars of AI, possess remarkable language understanding capabilities, making them ideal for addressing information gaps in agriculture. This work explores and demonstrates the transformative potential of Large Language Models (LLMs) in automating query resolution for agricultural farmers, leveraging their expertise in deciphering natural language and understanding context. Using a subset of a vast dataset of real-world farmer queries collected in India, our study focuses on approximately 4 million queries from the state of Tamil Nadu, spanning various sectors, seasonal crops, and query types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04721v1</guid>
      <category>cs.CL</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krish Didwania, Pratinav Seth, Aditya Kasliwal, Amit Agarwal</dc:creator>
    </item>
    <item>
      <title>Accurate Passive Radar via an Uncertainty-Aware Fusion of Wi-Fi Sensing Data</title>
      <link>https://arxiv.org/abs/2407.04733</link>
      <description>arXiv:2407.04733v1 Announce Type: cross 
Abstract: Wi-Fi devices can effectively be used as passive radar systems that sense what happens in the surroundings and can even discern human activity. We propose, for the first time, a principled architecture which employs Variational Auto-Encoders for estimating a latent distribution responsible for generating the data, and Evidential Deep Learning for its ability to sense out-of-distribution activities. We verify that the fused data processed by different antennas of the same Wi-Fi receiver results in increased accuracy of human activity recognition compared with the most recent benchmarks, while still being informative when facing out-of-distribution samples and enabling semantic interpretation of latent variables in terms of physical phenomena. The results of this paper are a first contribution toward the ultimate goal of providing a flexible, semantic characterisation of black-swan events, i.e., events for which we have limited to no training data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04733v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.23919/FUSION52260.2023.10224098</arxiv:DOI>
      <dc:creator>Marco Cominelli, Francesco Gringoli, Lance M. Kaplan, Mani B. Srivastava, Federico Cerutti</dc:creator>
    </item>
    <item>
      <title>Neuro-Symbolic Fusion of Wi-Fi Sensing Data for Passive Radar with Inter-Modal Knowledge Transfer</title>
      <link>https://arxiv.org/abs/2407.04734</link>
      <description>arXiv:2407.04734v1 Announce Type: cross 
Abstract: Wi-Fi devices, akin to passive radars, can discern human activities within indoor settings due to the human body's interaction with electromagnetic signals. Current Wi-Fi sensing applications predominantly employ data-driven learning techniques to associate the fluctuations in the physical properties of the communication channel with the human activity causing them. However, these techniques often lack the desired flexibility and transparency. This paper introduces DeepProbHAR, a neuro-symbolic architecture for Wi-Fi sensing, providing initial evidence that Wi-Fi signals can differentiate between simple movements, such as leg or arm movements, which are integral to human activities like running or walking. The neuro-symbolic approach affords gathering such evidence without needing additional specialised data collection or labelling. The training of DeepProbHAR is facilitated by declarative domain knowledge obtained from a camera feed and by fusing signals from various antennas of the Wi-Fi receivers. DeepProbHAR achieves results comparable to the state-of-the-art in human activity recognition. Moreover, as a by-product of the learning process, DeepProbHAR generates specialised classifiers for simple movements that match the accuracy of models trained on finely labelled datasets, which would be particularly costly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04734v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Cominelli, Francesco Gringoli, Lance M. Kaplan, Mani B. Srivastava, Trevor Bihl, Erik P. Blasch, Nandini Iyer, Federico Cerutti</dc:creator>
    </item>
    <item>
      <title>Multi-strategy Based Quantum Cost Reduction of Quantum Boolean Circuits</title>
      <link>https://arxiv.org/abs/2407.04826</link>
      <description>arXiv:2407.04826v1 Announce Type: cross 
Abstract: The construction of quantum computers is based on the synthesis of low-cost quantum circuits. The quantum circuit of any Boolean function expressed in a Positive Polarity Reed-Muller $PPRM$ expansion can be synthesized using Multiple-Control Toffoli ($MCT$) gates. This paper proposes two algorithms to construct a quantum circuit for any Boolean function expressed in a Positive Polarity Reed-Muller $PPRM$ expansion. The Boolean function can be expressed with various algebraic forms, so there are different quantum circuits can be synthesized for the Boolean function based on its algebraic form. The proposed algorithms aim to map the $MCT$ gates into the $NCV$ gates for any quantum circuit by generating a simple algebraic form for the Boolean function. The first algorithm generates a special algebraic form for any Boolean function by rearrangement of terms of the Boolean function according to a predefined degree of term $d_{term}$, then synthesizes the corresponding quantum circuit. The second algorithm applies the decomposition methods to decompose $MCT$ circuit into its elementary gates followed by applying a set of simplification rules to simplify and optimize the synthesized quantum circuit. The proposed algorithms achieve a reduction in the quantum cost of synthesized quantum circuits when compared with relevant work in literature. The proposed algorithms synthesize quantum circuits that can applied on IBM quantum computer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04826v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taghreed Ahmed, Ahmed Younes, and Islam Elkabani</dc:creator>
    </item>
    <item>
      <title>Late Breaking Results: Fortifying Neural Networks: Safeguarding Against Adversarial Attacks with Stochastic Computing</title>
      <link>https://arxiv.org/abs/2407.04861</link>
      <description>arXiv:2407.04861v1 Announce Type: cross 
Abstract: In neural network (NN) security, safeguarding model integrity and resilience against adversarial attacks has become paramount. This study investigates the application of stochastic computing (SC) as a novel mechanism to fortify NN models. The primary objective is to assess the efficacy of SC to mitigate the deleterious impact of attacks on NN results. Through a series of rigorous experiments and evaluations, we explore the resilience of NNs employing SC when subjected to adversarial attacks. Our findings reveal that SC introduces a robust layer of defense, significantly reducing the susceptibility of networks to attack-induced alterations in their outcomes. This research contributes novel insights into the development of more secure and reliable NN systems, essential for applications in sensitive domains where data integrity is of utmost concern.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04861v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faeze S. Banitaba, Sercan Aygun, M. Hassan Najafi</dc:creator>
    </item>
    <item>
      <title>Low-depth Quantum Circuit Decomposition of Multi-controlled Gates</title>
      <link>https://arxiv.org/abs/2407.05162</link>
      <description>arXiv:2407.05162v1 Announce Type: cross 
Abstract: Multi-controlled gates are fundamental components in the design of quantum algorithms, where efficient decompositions of these operators can enhance algorithm performance. The best asymptotic decomposition of an n-controlled X gate with one borrowed ancilla into single qubit and CNOT gates produces circuits with degree 3 polylogarithmic depth and employs a divide-and-conquer strategy. In this paper, we reduce the number of recursive calls in the divide-and-conquer algorithm and decrease the depth of n-controlled X gate decomposition to a degree of 2.799 polylogarithmic depth. With this optimized decomposition, we also reduce the depth of n-controlled SU(2) gates and approximate n-controlled U(2) gates. Decompositions described in this work achieve the lowest asymptotic depth reported in the literature. We also perform an optimization in the base of the recursive approach. Starting at 52 control qubits, the proposed n-controlled X gate with one borrowed ancilla has the shortest circuit depth in the literature. One can reproduce all the results with the freely available open-source code provided in a public repository.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05162v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thiago Melo D. Azevedo, Jefferson D. S. Silva, Adenilton J. da Silva</dc:creator>
    </item>
    <item>
      <title>On the Limitations of Compute Thresholds as a Governance Strategy</title>
      <link>https://arxiv.org/abs/2407.05694</link>
      <description>arXiv:2407.05694v1 Announce Type: cross 
Abstract: At face value, this essay is about understanding a fairly esoteric governance tool called compute thresholds. However, in order to grapple with whether these thresholds will achieve anything, we must first understand how they came to be. This requires engaging with a decades-old debate at the heart of computer science progress, namely, is bigger always better? Hence, this essay may be of interest not only to policymakers and the wider public but also to computer scientists interested in understanding the role of compute in unlocking breakthroughs. Does a certain inflection point of compute result in changes to the risk profile of a model? This discussion is increasingly urgent given the wide adoption of governance approaches that suggest greater compute equates with higher propensity for harm. Several leading frontier AI companies have released responsible scaling policies. Both the White House Executive Orders on AI Safety (EO) and the EU AI Act encode the use of FLOP or floating-point operations as a way to identify more powerful systems. What is striking about the choice of compute thresholds to-date is that no models currently deployed in the wild fulfill the current criteria set by the EO. This implies that the emphasis is often not on auditing the risks and harms incurred by currently deployed models - but rather is based upon the belief that future levels of compute will introduce unforeseen new risks. A key conclusion of this essay is that compute thresholds as currently implemented are shortsighted and likely to fail to mitigate risk. Governance that is overly reliant on compute fails to understand that the relationship between compute and risk is highly uncertain and rapidly changing. It also overestimates our ability to predict what abilities emerge at different scales. This essay ends with recommendations for a better way forward.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05694v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sara Hooker</dc:creator>
    </item>
    <item>
      <title>Minimum-regret hydrogen supply chain strategies to foster the energy transition of European hard-to-abate industries</title>
      <link>https://arxiv.org/abs/2407.05988</link>
      <description>arXiv:2407.05988v1 Announce Type: cross 
Abstract: Low-carbon hydrogen (H2) is envisioned to play a central role in decarbonizing European hard-to-abate industries, such as refineries, ammonia, methanol, steel, and cement. To enable its widespread use, H2 supply chain (HSC) infrastructure is required. Mature and economically viable low-carbon H2 production pathways include steam methane reforming (SMR) of natural gas coupled with carbon dioxide capture and storage (CCS), water-electrolysis from renewable electricity, biomethane reforming, and biomass gasification. However, uncertainties surrounding demand and feedstock availabilities hamper their proliferation. Here, we investigate the impact of uncertainty in H2 demand and biomass availability on the optimal HSC design. The HSC is modeled as a network of H2 production and consumption sites that are interconnected with H2 and biomass transport technologies. A CCS supply chain is modeled alongside the HSC. The cost-optimal HSC design is determined based on a linear optimization problem that considers a regional resolution and a multi-year time horizon (2022-2050). We adopt a scenario-based uncertainty quantification approach and define discrete H2 demand and biomass availability scenarios. Applying a minimum-regret strategy, we show that sufficiently large low-carbon H2 production capacities (about 9.6 Mt/a by 2030) are essential to flexibly scale up HSCs and accommodate H2 demands of up to 35 Mt/a by 2050. While biomass-based H2 production emerges as the most cost-efficient low-carbon H2 production pathway, investments are not recommended unless the availability of biomass feedstocks is guaranteed. Instead, investments in SMR-CCS and electrolysis often offer greater flexibility. In addition, we highlight the importance of CCS infrastructure, which is required across scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05988v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alissa Ganter, Paolo Gabrielli, Hanne Goericke, Giovanni Sansavini</dc:creator>
    </item>
    <item>
      <title>Scaling Analog Photonic Accelerators for Byte-Size, Integer General Matrix Multiply (GEMM) Kernels</title>
      <link>https://arxiv.org/abs/2407.06134</link>
      <description>arXiv:2407.06134v1 Announce Type: cross 
Abstract: Deep Neural Networks (DNNs) predominantly rely on General Matrix Multiply (GEMM) kernels, which are often accelerated using specialized hardware architectures. Recently, analog photonic GEMM accelerators have emerged as a promising alternative, offering vastly superior speed and energy efficiency compared to traditional electronic accelerators. However, these photonic cannot support wider than 4-bit integer operands due to their inherent trade-offs between analog dynamic range and parallelism. This is often inadequate for DNN training as at least 8-bit wide operands are deemed necessary to prevent significant accuracy drops. To address these limitations, we introduce a scalable photonic GEMM accelerator named SPOGA. SPOGA utilizes enhanced features such as analog summation of homodyne optical signals and in-transduction positional weighting of operands. By employing an extended optical-analog dataflow that minimizes overheads associated with bit-sliced integer arithmetic, SPOGA supports byte-size integer GEMM kernels, achieving significant improvements in throughput, latency, and energy efficiency. Specifically, SPOGA demonstrates up to 14.4$\times$, 2$\times$, and 28.5$\times$ improvements in frames-per-second (FPS), FPS/Watt, and FPS/Watt/mm$^2$ respectively, compared to existing state-of-the-art photonic solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06134v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <category>cs.PF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ISVLSI61997.2024.00080</arxiv:DOI>
      <dc:creator>Oluwaseun Adewunmi Alo, Sairam Sri Vatsavai, Ishan Thakkar</dc:creator>
    </item>
    <item>
      <title>Benchmarking Quantum Computer Simulation Software Packages: State Vector Simulators</title>
      <link>https://arxiv.org/abs/2401.09076</link>
      <description>arXiv:2401.09076v2 Announce Type: replace-cross 
Abstract: Rapid advances in quantum computing technology lead to an increasing need for software simulators that enable both algorithm design and the validation of results obtained from quantum hardware. This includes calculations that aim at probing regimes of quantum advantage, where a quantum computer outperforms a classical computer in the same task. High performance computing (HPC) platforms play a crucial role as today's quantum devices already reach beyond the limits of what powerful workstations can model, but a systematic evaluation of the individual performance of the many offered simulation packages is lacking so far. In this Technical Review, we benchmark several software packages capable of simulating quantum dynamics with a special focus on HPC capabilities. We develop a containerized toolchain for benchmarking a large set of simulation packages on a local HPC cluster using different parallelisation capabilities, and compare the performance and system size-scaling for three paradigmatic quantum computing tasks. Our results can help finding the right package for a given simulation task and lay the foundation for a systematic community effort to benchmark and validate upcoming versions of existing and also newly developed simulation packages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09076v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amit Jamadagni, Andreas M. L\"auchli, Cornelius Hempel</dc:creator>
    </item>
  </channel>
</rss>
