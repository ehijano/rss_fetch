<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Nov 2025 02:41:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Sigmoid-FTRL: Design-Based Adaptive Neyman Allocation for AIPW Estimators</title>
      <link>https://arxiv.org/abs/2511.19905</link>
      <description>arXiv:2511.19905v1 Announce Type: new 
Abstract: We consider the problem of Adaptive Neyman Allocation for the class of AIPW estimators in a design-based setting, where potential outcomes and covariates are deterministic. As each subject arrives, an adaptive procedure must select both a treatment assignment probability and a linear predictor to be used in the AIPW estimator. Our goal is to construct an adaptive procedure that minimizes the Neyman Regret, which is the difference between the variance of the adaptive procedure and an oracle variance which uses the optimal non-adaptive choice of assignment probability and linear predictors. While previous work has drawn insightful connections between Neyman Regret and online convex optimization for the Horvitz--Thompson estimator, one of the central challenges for AIPW estimator is that the underlying optimization is non-convex. In this paper, we propose Sigmoid-FTRL, an adaptive experimental design which addresses the non-convexity via simultaneous minimization of two convex regrets. We prove that under standard regularity conditions, the Neyman Regret of Sigmoid-FTRL converges at a $T^{-1/2} R^2$ rate, where $T$ is the number of subjects in the experiment and $R$ is the maximum norm of covariate vectors. Moreover, we show that no adaptive design can improve upon the $T^{-1/2}$ rate under our regularity conditions. Finally, we establish a central limit theorem and a consistently conservative variance estimator which facilitate the construction of asymptotically valid Wald-type confidence intervals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19905v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fangyi Chen, Shu Ge, Jian Qian, Christopher Harshaw</dc:creator>
    </item>
    <item>
      <title>On the Square Root of Wishart Matrices: Exact Distributions and Asymptotic Gaussian Behavior</title>
      <link>https://arxiv.org/abs/2511.19989</link>
      <description>arXiv:2511.19989v1 Announce Type: new 
Abstract: Random matrix theory has become a cornerstone in modern statistics and data science, providing fundamental tools for understanding high-dimensional covariance structures. Within this framework, the Wishart matrix plays a central role in multivariate analysis and related applications. This paper investigates both the exact and asymptotic distributions of the square root of a standard Wishart matrix. We first derive the exact distribution of the square root matrix. Then, by leveraging the Bartlett decomposition, we establish the joint asymptotic normality of the upper-triangular entries of the square root matrix. The resulting limiting distribution resembles that of a scaled Gaussian Wigner ensemble. Additionally, we quantify the rate of convergence using the 1-Wasserstein distance. To validate our theoretical findings, we conduct extensive Monte Carlo simulations, which demonstrate rapid convergence even with relatively low degrees of freedom. These results offer refined insights into the asymptotic behavior of random matrix functionals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19989v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fengcheng Liu</dc:creator>
    </item>
    <item>
      <title>An Efficient Adaptive Sequential Procedure for Simple Hypotheses with Expression for Finite Number of Applications of Less Effective Treatment</title>
      <link>https://arxiv.org/abs/2511.20061</link>
      <description>arXiv:2511.20061v1 Announce Type: new 
Abstract: We propose an adaptive sequential framework for testing two simple hypotheses that analytically ensures finite exposure to the less effective treatment. Our proposed procedure employs a likelihood ratio-driven adaptive allocation rule, dynamically concentrating sampling effort on the superior population while preserving asymptotic efficiency (in terms of average sample number) comparable to the Sequential Probability Ratio Test (SPRT). The foremost contribution of this work is the derivation of an explicit closed-form expression for the expected number of applications to the inferior treatment. This approach achieves a balanced method between statistical precision and ethical responsibility, aligning inferential reliability with patient safety. Extensive simulation studies substantiate the theoretical results, confirming stability in allocation and consistently high probability of correct selection (PCS) across different settings. In addition, we demonstrate how the adaptive procedure markedly reduces inferior allocations compared with the classical SPRT, highlighting its practical advantage in ethically sensitive sequential testing scenarios. The proposed design thus offers an ethically efficient and computationally tractable framework for adaptive sequential decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20061v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sampurna Kundu, Jayant Jha, Subir Kumar Bhandari</dc:creator>
    </item>
    <item>
      <title>Variational bagging: a robust approach for Bayesian uncertainty quantification</title>
      <link>https://arxiv.org/abs/2511.20594</link>
      <description>arXiv:2511.20594v1 Announce Type: new 
Abstract: Variational Bayes methods are popular due to their computational efficiency and adaptability to diverse applications. In specifying the variational family, mean-field classes are commonly used, which enables efficient algorithms such as coordinate ascent variational inference (CAVI) but fails to capture parameter dependence and typically underestimates uncertainty. In this work, we introduce a variational bagging approach that integrates a bagging procedure with variational Bayes, resulting in a bagged variational posterior for improved inference. We establish strong theoretical guarantees, including posterior contraction rates for general models and a Bernstein-von Mises (BVM) type theorem that ensures valid uncertainty quantification. Notably, our results show that even when using a mean-field variational family, our approach can recover off-diagonal elements of the limiting covariance structure and provide proper uncertainty quantification. In addition, variational bagging is robust to model misspecification, with covariance structures matching those of the target covariance. We illustrate our variational bagging method in numerical studies through applications to parametric models, finite mixture models, deep neural networks, and variational autoencoders (VAEs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20594v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shitao Fan, Ilsang Ohn, David Dunson, Lizhen Lin</dc:creator>
    </item>
    <item>
      <title>Dependence-Aware False Discovery Rate Control in Two-Sided Gaussian Mean Testing</title>
      <link>https://arxiv.org/abs/2511.19960</link>
      <description>arXiv:2511.19960v1 Announce Type: cross 
Abstract: This paper develops a general framework for controlling the false discovery rate (FDR) in multiple testing of Gaussian means against two-sided alternatives. The widely used Benjamini-Hochberg (BH) procedure provides exact FDR control under independence or conservative control under specific one-sided dependence structures, but its validity for correlated two-sided tests has remained an open question. We introduce the notion of positive left-tail dependence under the null (PLTDN), extending classical dependence assumptions to two-sided settings, and show that it ensures valid FDR control for BH-type procedures. Building on this framework, we propose a family of generalized shifted BH (GSBH) methods that incorporate correlation information through simple p-value adjustments. Simulation results demonstrate reliable FDR control and improved power across a range of dependence structures, while an application to an HIV gene expression dataset illustrates the practical effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19960v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deepra Ghosh, Sanat K. Sarkar</dc:creator>
    </item>
    <item>
      <title>Tight Margin-Based Generalization Bounds for Voting Classifiers over Finite Hypothesis Sets</title>
      <link>https://arxiv.org/abs/2511.20407</link>
      <description>arXiv:2511.20407v1 Announce Type: cross 
Abstract: We prove the first margin-based generalization bound for voting classifiers, that is asymptotically tight in the tradeoff between the size of the hypothesis set, the margin, the fraction of training points with the given margin, the number of training samples and the failure probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20407v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kasper Green Larsen, Natascha Schalburg</dc:creator>
    </item>
    <item>
      <title>A Latent-Variable Formulation of the Poisson Canonical Polyadic Tensor Model: Maximum Likelihood Estimation and Fisher Information</title>
      <link>https://arxiv.org/abs/2511.05352</link>
      <description>arXiv:2511.05352v2 Announce Type: replace 
Abstract: We establish parameter inference for the Poisson canonical polyadic (PCP) model of tensor count data through a latent-variable formulation. Our approach exploits the property that any random tensor that follows the PCP model can be derived by marginalizing an unobservable random tensor of one dimension larger. The loglikelihood of this larger dimensional tensor, referred to as the "complete" loglikelihood, is comprised of multiple loglikelihoods corresponding to rank one PCP models. Using this methodology, we first demonstrate that several existing algorithms for fitting non-negative matrix and tensor factorizations are Expectation-Maximization algorithms. Next, we derive the observed and expected Fisher information matrices for the PCP model by leveraging its latent-variable formulation. The Fisher information provides us crucial insights into the well-posedness of the tensor model, such as the role that the rank of parameter tensor plays in identifiability and indeterminacy. For the special case of PCP models with rank one parameter tensors, we demonstrate that these results are greatly simplified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05352v2</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos Llosa-Vite, Daniel M. Dunlavy, Richard B. Lehoucq, Oscar L\'opez, Arvind Prasadan</dc:creator>
    </item>
    <item>
      <title>Multiple Randomization Designs: Estimation and Inference with Interference</title>
      <link>https://arxiv.org/abs/2112.13495</link>
      <description>arXiv:2112.13495v3 Announce Type: replace-cross 
Abstract: In this study we introduce a new class of experimental designs. In a classical randomized controlled trial (RCT), or A/B test, a randomly selected subset of a population of units (e.g., individuals, plots of land, or experiences) is assigned to a treatment (treatment A), and the remainder of the population is assigned to the control treatment (treatment B). The difference in average outcome by treatment group is an estimate of the average effect of the treatment. However, motivating our study, the setting for modern experiments is often different, with the outcomes and treatment assignments indexed by multiple populations. For example, outcomes may be indexed by buyers and sellers, by content creators and subscribers, by drivers and riders, or by travelers and airlines and travel agents, with treatments potentially varying across these indices. Spillovers or interference can arise from interactions between units across populations. For example, sellers' behavior may depend on buyers' treatment assignment, or vice versa. This can invalidate the simple comparison of means as an estimator for the average effect of the treatment in classical RCTs. We propose new experiment designs for settings in which multiple populations interact. We show how these designs allow us to study questions about interference that cannot be answered by classical randomized experiments. Finally, we develop new statistical methods for analyzing these Multiple Randomization Designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.13495v3</guid>
      <category>stat.ME</category>
      <category>cs.SI</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Masoero, Suhas Vijaykumar, Thomas Richardson, James McQueen, Ido Rosen, Brian Burdick, Pat Bajari, Guido Imbens</dc:creator>
    </item>
    <item>
      <title>PriME: Privacy-aware Membership profile Estimation in networks</title>
      <link>https://arxiv.org/abs/2406.02794</link>
      <description>arXiv:2406.02794v2 Announce Type: replace-cross 
Abstract: This paper presents a novel approach to estimating community membership probabilities for network vertices generated by the Degree Corrected Mixed Membership Stochastic Block Model while preserving individual edge privacy. Operating within the $\varepsilon$-edge local differential privacy framework, we introduce an optimal private algorithm based on a symmetric edge flip mechanism and spectral clustering for accurate estimation of vertex community memberships. We conduct a comprehensive analysis of the estimation risk and establish the optimality of our procedure by providing matching lower bounds to the minimax risk under privacy constraints. To validate our approach, we demonstrate its performance through numerical simulations and its practical application to real-world data. This work represents a significant step forward in balancing accurate community membership estimation with stringent privacy preservation in network data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02794v2</guid>
      <category>stat.ME</category>
      <category>cs.SI</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhinav Chakraborty, Sayak Chatterjee, Sagnik Nandy</dc:creator>
    </item>
    <item>
      <title>Spatial Proportional Hazards Model with Differential Regularization</title>
      <link>https://arxiv.org/abs/2410.13420</link>
      <description>arXiv:2410.13420v4 Announce Type: replace-cross 
Abstract: The Proportional Hazards (PH) model is one of the most common model used in survival analysis, which typically assumes a log-linear relationship between covariates and the hazard function. However, this assumption may not hold in practice. This paper introduces a nonparametric extension of the PH model, which generalizes the log-linear assumption by allowing for an unspecified, smooth function of covariates, enabling more flexible modeling. We focus on applications with spatial survival data, where the location of an event affects the risk. The proposed model captures this spatial variation using a nonparametric spatial effect. We estimate the spatial effect using finite element methods on a mesh constructed from a triangulation of the domain, which allows us to handle irregular shapes. The model remains within the classical partial likelihood framework, ensuring computational feasibility. To enforce the smoothness in the nonparametric spatial effect, we consider a differential penalization. We establish the asymptotic properties of the proposed estimator using sieve methods, demonstrating its consistency and the asymptotic normality of the parametric component. A simulation study is conducted to evaluate the model's performance, followed by two empirical applications that demonstrate its practical advantages over standard PH models, especially in settings with spatial dependence in survival data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13420v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Tedesco, Francesco Finazzi</dc:creator>
    </item>
    <item>
      <title>Transfer Learning for High-dimensional Quantile Regression with Distribution Shift</title>
      <link>https://arxiv.org/abs/2411.19933</link>
      <description>arXiv:2411.19933v2 Announce Type: replace-cross 
Abstract: Information from related source studies can often enhance the findings of a target study. However, the distribution shift between target and source studies can severely impact the efficiency of knowledge transfer. In the high-dimensional regression setting, existing transfer approaches mainly focus on the parameter shift. In this paper, we focus on the high-dimensional quantile regression with knowledge transfer under three types of distribution shift: parameter shift, covariate shift, and residual shift. We propose a novel transferable set and a new transfer framework to address the above three discrepancies. Non-asymptotic estimation error bounds and source detection consistency are established to validate the availability and superiority of our method in the presence of distribution shift. Additionally, an orthogonal debiased approach is proposed for statistical inference with knowledge transfer, leading to sharper asymptotic results. Extensive simulation results as well as real data applications further demonstrate the effectiveness of our proposed procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19933v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiqi Bai, Yijiao Zhang, Hanbo Yang, Zhongyi Zhu</dc:creator>
    </item>
    <item>
      <title>An Asymptotic Equation Linking WAIC and WBIC in Singular Models</title>
      <link>https://arxiv.org/abs/2505.13902</link>
      <description>arXiv:2505.13902v3 Announce Type: replace-cross 
Abstract: In statistical learning, models are classified as regular or singular depending on whether the mapping from parameters to probability distributions is injective. Most models with hierarchical structures or latent variables are singular, for which conventional criteria such as the Akaike Information Criterion and the Bayesian Information Criterion are inapplicable due to the breakdown of normal approximations for the likelihood and posterior. To address this, the Widely Applicable Information Criterion (WAIC) and the Widely Applicable Bayesian Information Criterion (WBIC) have been proposed. Since WAIC and WBIC are computed using posterior distributions at different temperature settings, separate posterior sampling is generally required. In this paper, we theoretically derive an asymptotic equation that links WAIC and WBIC, despite their dependence on different posteriors. This equation yields an asymptotically unbiased expression of WAIC in terms of the posterior distribution used for WBIC. The result clarifies the structural relationship between these criteria within the framework of singular learning theory, and deepens understanding of their asymptotic behavior. This theoretical contribution provides a foundation for future developments in the computational efficiency of model selection in singular models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13902v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-981-95-4367-0_35</arxiv:DOI>
      <arxiv:journal_reference>Neural Information Processing. ICONIP 2025. Lecture Notes in Computer Science, vol 16309</arxiv:journal_reference>
      <dc:creator>Naoki Hayashi, Takuro Kutsuna, Sawa Takamuku</dc:creator>
    </item>
    <item>
      <title>Explicit Universal Bounds for Cumulants via Moments</title>
      <link>https://arxiv.org/abs/2510.05739</link>
      <description>arXiv:2510.05739v2 Announce Type: replace-cross 
Abstract: We establish explicit, universal, and distribution-free bounds for the $n$-th cumulant, $\kappa_n(X)$, of a scalar random variable, controlled solely by an $n$-th order absolute moment functional $M_n(X)$. The bounds take the form $\lvert\kappa_n(X)\rvert \le C_n M_n(X)$. Our principal contribution is the derivation of coefficients satisfying $C_n \sim (n-1)!/\rho^{\,n}$, which offers an exponential improvement over classical bounds where the coefficients grow superexponentially (on the order of $n^n$).
  We present a hierarchy of refinements where the rate parameter $\rho$ increases as the functional $M_n(X)$ incorporates more structural information. The most general bound uses the raw moment $M_n(X)=\mathsf{E}[\lvert X\rvert^n]$ with rate $\rho=\ln 2 \approx 0.693$. Using the central moment $M_n(X)=\mathsf{E}[\lvert X-\mathsf{E}[X]\rvert^n]$ improves the rate to $\rho_{\mathrm{cen}} \approx 1.146$, while assuming symmetry yields even higher rates.
  The proof is elementary, combining the moment-cumulant partition formula with a uniform moment-product inequality. We further prove that while these bounds are strict (not attainable by non-degenerate distributions), they are asymptotically efficient given the limited information of a single moment. The utility of the bounds is demonstrated through applications to analyticity of CGFs and concentration inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05739v2</guid>
      <category>math.PR</category>
      <category>math.CO</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiechen Zhang</dc:creator>
    </item>
    <item>
      <title>Subspace Ordering for Maximum Response Preservation in Sufficient Dimension Reduction</title>
      <link>https://arxiv.org/abs/2510.27593</link>
      <description>arXiv:2510.27593v2 Announce Type: replace-cross 
Abstract: Sufficient dimension reduction (SDR) methods aim to identify a dimension reduction subspace (DRS) that preserves all the information about the conditional distribution of a response given its predictor. Traditional SDR methods determine the DRS by solving a method-specific generalized eigenvalue problem and selecting the eigenvectors corresponding to the largest eigenvalues. In this article, we argue against the long-standing convention of using eigenvalues as the measure of subspace importance and propose alternative ordering criteria that directly assess the predictive relevance of each subspace. For a binary response, we introduce a subspace ordering criterion based on the absolute value of the independent Student's T-statistic. Theoretically, our criterion identifies subspaces that achieve the local minimum Bayes' error rate and yields consistent ordering of directions under mild regularity conditions. Additionally, we employ an F-statistic to provide a framework that unifies categorical and continuous responses under a single subspace criterion. We evaluate our proposed criteria within multiple SDR methods through extensive simulation studies and applications to real data. Our empirical results demonstrate the efficacy of reordering subspaces using our proposed criteria, which generally improves classification accuracy and subspace estimation compared to ordering by eigenvalues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.27593v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Derik T. Boonstra, Rakheon Kim, Dean M. Young</dc:creator>
    </item>
    <item>
      <title>Differential privacy with dependent data</title>
      <link>https://arxiv.org/abs/2511.18583</link>
      <description>arXiv:2511.18583v2 Announce Type: replace-cross 
Abstract: Dependent data underlies many statistical studies in the social and health sciences, which often involve sensitive or private information. Differential privacy (DP) and in particular \textit{user-level} DP provide a natural formalization of privacy requirements for processing dependent data where each individual provides multiple observations to the dataset. However, dependence introduced, e.g., through repeated measurements challenges the existing statistical theory under DP-constraints. In \iid{} settings, noisy Winsorized mean estimators have been shown to be minimax optimal for standard (\textit{item-level}) and \textit{user-level} DP estimation of a mean $\mu \in \R^d$. Yet, their behavior on potentially dependent observations has not previously been studied. We fill this gap and show that Winsorized mean estimators can also be used under dependence for bounded and unbounded data, and can lead to asymptotic and finite sample guarantees that resemble their \iid{} counterparts under a weak notion of dependence. For this, we formalize dependence via log-Sobolev inequalities on the joint distribution of observations. This enables us to adapt the stable histogram by Karwa and Vadhan (2018) to a non-\iid{} setting, which we then use to estimate the private projection intervals of the Winsorized estimator. The resulting guarantees for our item-level mean estimator extend to \textit{user-level} mean estimation and transfer to the local model via a randomized response histogram. Using the mean estimators as building blocks, we provide extensions to random effects models, longitudinal linear regression and nonparametric regression. Therefore, our work constitutes a first step towards a systematic study of DP for dependent data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18583v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Valentin Roth, Marco Avella-Medina</dc:creator>
    </item>
  </channel>
</rss>
