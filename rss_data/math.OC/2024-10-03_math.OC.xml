<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Oct 2024 02:09:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Polynomial Convergence of an Observer for an Infinite-Dimensional Oscillating System</title>
      <link>https://arxiv.org/abs/2410.00989</link>
      <description>arXiv:2410.00989v1 Announce Type: new 
Abstract: This paper is devoted to analyzing the observer convergence rate for a class of linear control systems in a Hilbert space. To characterize the polynomial stability of the observer error system, we apply the spectral theory of linear operators and explicitly construct the resolvent of the corresponding infinitesimal generator. The asymptotic behavior of the resolvent on the imaginary axis is studied to describe the rate of decay of the observation error. The estimated decay rate is illustrated through an example of an oscillating flexible structure with one-dimensional output.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00989v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Zuyev, Julia Kalosha</dc:creator>
    </item>
    <item>
      <title>Parametrized Families of Resolvent Compositions</title>
      <link>https://arxiv.org/abs/2410.01090</link>
      <description>arXiv:2410.01090v1 Announce Type: new 
Abstract: This paper presents an in-depth analysis of a parametrized version of the resolvent composition, an operation that combines a set-valued operator and a linear operator. We provide new properties and examples, and show that resolvent compositions can be interpreted as parallel compositions of perturbed operators. Additionally, we establish new monotonicity results, even in cases when the initial operator is not monotone. Finally, we derive asymptotic results regarding operator convergence, specifically focusing on graph-convergence and the $\rho$-Hausdorff distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01090v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego J. Cornejo</dc:creator>
    </item>
    <item>
      <title>Three-Operator Splitting Method with Two-Step Inertial Extrapolation</title>
      <link>https://arxiv.org/abs/2410.01099</link>
      <description>arXiv:2410.01099v1 Announce Type: new 
Abstract: The aim of this paper is to study the weak convergence analysis of sequence of iterates generated by a three-operator splitting method of Davis and Yin incorporated with two-step inertial extrapolation for solving monotone inclusion problem involving the sum of two maximal monotone operators and a co-coercive operator in Hilbert spaces. Our results improve on the setbacks observed recently in the literature that one-step inertial Douglas-Rachford splitting method may fail to provide acceleration. Our convergence results also dispense with the summability conditions imposed on inertial parameters and the sequence of iterates assumed in recent results on multi-step inertial methods in the literature. Numerical illustrations from image restoration problem and Smoothly Clipped Absolute Deviation (SCAD) penalty problem are given to show the efficiency and advantage gained by incorporating two-step inertial extrapolation over one-step inertial extrapolation for three-operator splitting method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01099v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Olaniyi S. Iyiola, Lateef O. Jolaoso, Yekini Shehu</dc:creator>
    </item>
    <item>
      <title>Robust Quantum Gate Preparation in Open Environments</title>
      <link>https://arxiv.org/abs/2410.01161</link>
      <description>arXiv:2410.01161v1 Announce Type: new 
Abstract: We develop an optimal control algorithm for robust quantum gate preparation in open environments with the state of the quantum system represented using the Lindblad master equation. The algorithm is based on adaptive linearization and iterative quadratic programming to gradually shape the control into an optimal signal. Robustness is achieved by introducing uncertain parameters into the master equation and expanding the parameterized state over the basis of Legendre polynomials to enable exponential rates of convergence. We prove that the proposed control algorithm reduces to GRadient Ascent Pulse Engineering (GRAPE) when the robustness portion of the algorithm is bypassed and signal restrictions are relaxed. The control algorithm is applied to prepare Controlled NOT and SWAP gates with high precision. Using only second order Legendre polynomials, the examples showcase unprecedented robustness to 100% parameter uncertainty in the interaction strength between the qubits even in the presence of environmental interactions, while simultaneously compensating for 20% uncertainty in signal intensity. The results could enable new capabilities for robust implementation of quantum gates and circuits subject to harsh environments and hardware limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01161v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke S. Baker, Syed A. Shah, Anatoly Zlotnik, Andrei Piryatinski</dc:creator>
    </item>
    <item>
      <title>Newton Meets Marchenko-Pastur: Massively Parallel Second-Order Optimization with Hessian Sketching and Debiasing</title>
      <link>https://arxiv.org/abs/2410.01374</link>
      <description>arXiv:2410.01374v1 Announce Type: new 
Abstract: Motivated by recent advances in serverless cloud computing, in particular the "function as a service" (FaaS) model, we consider the problem of minimizing a convex function in a massively parallel fashion, where communication between workers is limited. Focusing on the case of a twice-differentiable objective subject to an L2 penalty, we propose a scheme where the central node (server) effectively runs a Newton method, offloading its high per-iteration cost -- stemming from the need to invert the Hessian -- to the workers. In our solution, workers produce independently coarse but low-bias estimates of the inverse Hessian, using an adaptive sketching scheme. The server then averages the descent directions produced by the workers, yielding a good approximation for the exact Newton step. The main component of our adaptive sketching scheme is a low-complexity procedure for selecting the sketching dimension, an issue that was left largely unaddressed in the existing literature on Hessian sketching for distributed optimization. Our solution is based on ideas from asymptotic random matrix theory, specifically the Marchenko-Pastur law. For Gaussian sketching matrices, we derive non asymptotic guarantees for our algorithm which are essentially dimension-free. Lastly, when the objective is self-concordant, we provide convergence guarantees for the approximate Newton's method with noisy Hessians, which may be of independent interest beyond the setting considered in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01374v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elad Romanov, Fangzhao Zhang, Mert Pilanci</dc:creator>
    </item>
    <item>
      <title>Analyzing the speed of convergence in nonsmooth optimization via the Goldstein subdifferential with application to descent methods</title>
      <link>https://arxiv.org/abs/2410.01382</link>
      <description>arXiv:2410.01382v1 Announce Type: new 
Abstract: The Goldstein $\varepsilon$-subdifferential is a relaxed version of the Clarke subdifferential which has recently appeared in several algorithms for nonsmooth optimization. With it comes the notion of $(\varepsilon,\delta)$-critical points, which are points in which the element with the smallest norm in the $\varepsilon$-subdifferential has norm at most $\delta$. To obtain points that are critical in the classical sense, $\varepsilon$ and $\delta$ must vanish. In this article, we analyze at which speed the distance of $(\varepsilon,\delta)$-critical points to the minimum vanishes with respect to $\varepsilon$ and $\delta$. Afterwards, we apply our results to gradient sampling methods and perform numerical experiments. Throughout the article, we put a special emphasis on supporting the theoretical results with simple examples that visualize them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01382v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bennet Gebken</dc:creator>
    </item>
    <item>
      <title>On the Convergence of FedProx with Extrapolation and Inexact Prox</title>
      <link>https://arxiv.org/abs/2410.01410</link>
      <description>arXiv:2410.01410v1 Announce Type: new 
Abstract: Enhancing the FedProx federated learning algorithm (Li et al., 2020) with server-side extrapolation, Li et al. (2024a) recently introduced the FedExProx method. Their theoretical analysis, however, relies on the assumption that each client computes a certain proximal operator exactly, which is impractical since this is virtually never possible to do in real settings. In this paper, we investigate the behavior of FedExProx without this exactness assumption in the smooth and globally strongly convex setting. We establish a general convergence result, showing that inexactness leads to convergence to a neighborhood of the solution. Additionally, we demonstrate that, with careful control, the adverse effects of this inexactness can be mitigated. By linking inexactness to biased compression (Beznosikov et al., 2023), we refine our analysis, highlighting robustness of extrapolation to inexact proximal updates. We also examine the local iteration complexity required by each client to achieved the required level of inexactness using various local optimizers. Our theoretical insights are validated through comprehensive numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01410v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanmin Li, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Convex regularization and subdifferential calculus</title>
      <link>https://arxiv.org/abs/2410.01436</link>
      <description>arXiv:2410.01436v1 Announce Type: new 
Abstract: This paper deals with the regularization of the sum of functions defined on a locally convex spaces through their closed-convex hulls in the bidual space. Different conditions guaranteeing that the closed-convex hull of the sum is the sum of the corresponding closed-convex hulls are provided. These conditions are expressed in terms of some epsilon-subdifferential calculus rules for the sum. The case of convex functions is also studied, and exact calculus rules are given under additional continuity/qualifications conditions. As an illustration, a variant of the proof of the classical Rockafellar theorem on convex integration is proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01436v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafael Correa, Abderrahim Hantoute, Marco A. L\'opez</dc:creator>
    </item>
    <item>
      <title>A Fast Optimization Approach For A Complex Real-Life 3D Multiple Bin Size Bin Packing Problem</title>
      <link>https://arxiv.org/abs/2410.01445</link>
      <description>arXiv:2410.01445v1 Announce Type: new 
Abstract: We investigate a real-life air cargo loading problem which is a variant of the three-dimensional Variable Size Bin Packing Problem with special bin forms of cuboid and non-cuboid unit load devices (ULDs). Packing is constrained by additional practical restrictions, such as load stability, (non-)stackable items, and weight distribution constraints. To solve the problem, we present an insertion heuristic embedded into a Randomized Greedy Search. The solution space is limited by only considering certain candidate points (so-called extreme points), which are promising positions to load an item. We extend the concept of extreme points proposed in the literature and allow moving extreme points for non-cuboid ULDs. A special sorting of the items is suggested, which combines a layered structure and free packing. Moreover, we propose dividing the space of each ULD into smaller cells to accelerate the collision, non-floating, and stackability check while loading items. In a computational study, we analyze individual algorithm components and show the effectiveness of our method on adapted real-life instances from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01445v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katrin He{\ss}ler, Timo Hintsch, Lukas Wienkamp</dc:creator>
    </item>
    <item>
      <title>A Mathematics-Inspired Learning-to-Optimize Framework for Decentralized Optimization</title>
      <link>https://arxiv.org/abs/2410.01700</link>
      <description>arXiv:2410.01700v1 Announce Type: new 
Abstract: Most decentralized optimization algorithms are handcrafted. While endowed with strong theoretical guarantees, these algorithms generally target a broad class of problems, thereby not being adaptive or customized to specific problem features. This paper studies data-driven decentralized algorithms trained to exploit problem features to boost convergence. Existing learning-to-optimize methods typically suffer from poor generalization or prohibitively vast search spaces. In addition, the vast search space of communicating choices and final goal to reach the global solution via limited neighboring communication cast more challenges in decentralized settings. To resolve these challenges, this paper first derives the necessary conditions that successful decentralized algorithmic rules need to satisfy to achieve both optimality and consensus. Based on these conditions, we propose a novel Mathematics-inspired Learning-to-optimize framework for Decentralized optimization (MiLoDo). Empirical results demonstrate that MiLoDo-trained algorithms outperform handcrafted algorithms and exhibit strong generalizations. Algorithms learned via MiLoDo in 100 iterations perform robustly when running 100,000 iterations during inferences. Moreover, MiLoDo-trained algorithms on synthetic datasets perform well on problems involving real data, higher dimensions, and different loss functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01700v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yutong He, Qiulin Shang, Xinmeng Huang, Jialin Liu, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>Discrete-Time LQ Stochastic Two-Person Nonzero-Sum Difference Games with Random Coefficients:~Open-Loop Nash Equilibrium</title>
      <link>https://arxiv.org/abs/2410.01741</link>
      <description>arXiv:2410.01741v1 Announce Type: new 
Abstract: This paper presents a pioneering investigation into discrete-time two-person nonzero-sum linear quadratic (LQ) stochastic games characterized by random coefficients. We derive necessary and sufficient conditions for the existence of open-loop Nash equilibria using convex variational calculus. To obtain explicit expressions for the Nash equilibria, we introduce fully coupled forward-backward stochastic difference equations (stochastic Hamiltonian systems), which provide a dual characterization of these Nash equilibria. Additionally, we develop non-symmetric stochastic Riccati equations that decouple the stochastic Hamiltonian system for each player, enabling the derivation of closed-loop feedback forms for open-loop Nash equilibrium strategies. A notable aspect of this research is the complete randomness of the coefficients, which results in the corresponding Riccati equations becoming fully nonlinear higher-order backward stochastic difference equations. It distinguishes our nonzero-sum difference game from the deterministic case, where the Riccati equations reduce to algebraic forms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01741v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yiwei Wu, Xun Li, Qingxin Meng</dc:creator>
    </item>
    <item>
      <title>Fully Coupled Nonlinear FBS$\Delta$Es: Solvability and LQ Control Insights</title>
      <link>https://arxiv.org/abs/2410.01749</link>
      <description>arXiv:2410.01749v1 Announce Type: new 
Abstract: This paper explores a class of fully coupled nonlinear forward-backward stochastic difference equations (FBS$\Delta$Es). Building on insights from linear quadratic optimal control problems, we introduce a more relaxed framework of domination-monotonicity conditions specifically designed for discrete systems. Utilizing these conditions, we apply the method of continuation to demonstrate the unique solvability of the fully coupled FBS$\Delta$Es and derive a set of solution estimates. Moreover, our results have considerable implications for various related linear quadratic (LQ) problems, particularly where stochastic Hamiltonian systems are aligned with the FBS$\Delta$Es meeting these introduced domination-monotonicity conditions. As a result, solving the associated stochastic Hamiltonian systems allows us to derive explicit expressions for the unique optimal controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01749v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zhipeng Niu, Qingxin Meng, Xun Li, Maoning Tang</dc:creator>
    </item>
    <item>
      <title>Tight Rates for Bandit Control Beyond Quadratics</title>
      <link>https://arxiv.org/abs/2410.00993</link>
      <description>arXiv:2410.00993v1 Announce Type: cross 
Abstract: Unlike classical control theory, such as Linear Quadratic Control (LQC), real-world control problems are highly complex. These problems often involve adversarial perturbations, bandit feedback models, and non-quadratic, adversarially chosen cost functions. A fundamental yet unresolved question is whether optimal regret can be achieved for these general control problems. The standard approach to addressing this problem involves a reduction to bandit convex optimization with memory. In the bandit setting, constructing a gradient estimator with low variance is challenging due to the memory structure and non-quadratic loss functions.
  In this paper, we provide an affirmative answer to this question. Our main contribution is an algorithm that achieves an $\tilde{O}(\sqrt{T})$ optimal regret for bandit non-stochastic control with strongly-convex and smooth cost functions in the presence of adversarial perturbations, improving the previously known $\tilde{O}(T^{2/3})$ regret bound from (Cassel and Koren, 2020. Our algorithm overcomes the memory issue by reducing the problem to Bandit Convex Optimization (BCO) without memory and addresses general strongly-convex costs using recent advancements in BCO from (Suggala et al., 2024). Along the way, we develop an improved algorithm for BCO with memory, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00993v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Y. Jennifer Sun, Zhou Lu</dc:creator>
    </item>
    <item>
      <title>Sparse Actuation for LPV Systems with Full-State Feedback in $\mathcal{H}_2/\mathcal{H}_\infty$ Framework</title>
      <link>https://arxiv.org/abs/2410.01118</link>
      <description>arXiv:2410.01118v1 Announce Type: cross 
Abstract: This paper addresses the sparse actuation problem for nonlinear systems represented in the Linear Parameter-Varying (LPV) form. We propose a convex optimization framework that concurrently determines actuator magnitude limits and the state-feedback law that guarantees a user-specified closed-loop performance in the $\mathcal{H}_2/\mathcal{H}_\infty$ sense. We also demonstrate that sparse actuation is achieved when the actuator magnitude-limits are minimized in the $l_1$ sense. This is the first paper that addresses this problem for LPV systems. The formulation is demonstrated in a vibration control problem for a flexible wing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01118v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tanay Kumar, Raktim Bhattacharya</dc:creator>
    </item>
    <item>
      <title>H-DES: a Quantum-Classical Hybrid Differential Equation Solver</title>
      <link>https://arxiv.org/abs/2410.01130</link>
      <description>arXiv:2410.01130v1 Announce Type: cross 
Abstract: In this article, we introduce an original hybrid quantum-classical algorithm based on a variational quantum algorithm for solving systems of differential equations. The algorithm relies on a spectral method, which involves encoding the solution functions in the amplitudes of the quantum states generated by different parametrized circuits and transforms the task of solving the differential equations into an optimization problem. We first describe the principle of the algorithm from a theoretical point of view. We provide a detailed pseudo-code of the algorithm, on which we conduct a complexity analysis to highlight its scaling properties. We apply it to a set of examples, showcasing its applicability across diverse sets of differential equations. We discuss the advantages of our method and potential avenues for further exploration and refinement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01130v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hamza Jaffali, Jonas Bastos de Araujo, Nadia Milazzo, Marta Reina, Henri de Boutray, Karla Baumann, Fr\'ed\'eric Holweck</dc:creator>
    </item>
    <item>
      <title>Stochastic Gradient Descent with Adaptive Data</title>
      <link>https://arxiv.org/abs/2410.01195</link>
      <description>arXiv:2410.01195v1 Announce Type: cross 
Abstract: Stochastic gradient descent (SGD) is a powerful optimization technique that is particularly useful in online learning scenarios. Its convergence analysis is relatively well understood under the assumption that the data samples are independent and identically distributed (iid). However, applying SGD to policy optimization problems in operations research involves a distinct challenge: the policy changes the environment and thereby affects the data used to update the policy. The adaptively generated data stream involves samples that are non-stationary, no longer independent from each other, and affected by previous decisions. The influence of previous decisions on the data generated introduces bias in the gradient estimate, which presents a potential source of instability for online learning not present in the iid case. In this paper, we introduce simple criteria for the adaptively generated data stream to guarantee the convergence of SGD. We show that the convergence speed of SGD with adaptive data is largely similar to the classical iid setting, as long as the mixing time of the policy-induced dynamics is factored in. Our Lyapunov-function analysis allows one to translate existing stability analysis of stochastic systems studied in operations research into convergence rates for SGD, and we demonstrate this for queueing and inventory management problems. We also showcase how our result can be applied to study the sample complexity of an actor-critic policy gradient algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01195v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ethan Che, Jing Dong, Xin T. Tong</dc:creator>
    </item>
    <item>
      <title>Spectral estimates on hyperbolic surfaces and a necessary condition for observability of the heat semigroup on manifolds</title>
      <link>https://arxiv.org/abs/2410.01323</link>
      <description>arXiv:2410.01323v1 Announce Type: cross 
Abstract: This article is a continuation of arXiv:2401.14977. We study the concentration properties of spectral projectors on manifolds, in connection with the uncertainty principle. In arXiv:2401.14977, the second author proved an optimal uncertainty principle for the spectral projector of the Laplacian on the hyperbolic half-plane. The aim of the present work is to generalize this condition to surfaces with hyperbolic ends. In particular, we tackle the case of cusps, in which the volume of balls of fixed radius is not bounded from below. We establish that spectral estimates hold from sets satisfying a thickness condition, with a proof based on propagation of smallness estimates of Carleman and Logunov--Malinnikova type. We also prove the converse, namely the necessary character of the thickness condition, on any smooth manifold with Ricci curvature bounded from below.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01323v1</guid>
      <category>math.AP</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alix Deleporte, Marc Rouveyrol</dc:creator>
    </item>
    <item>
      <title>Detection and suppression of epileptiform seizures via model-free control and derivatives in a noisy environment</title>
      <link>https://arxiv.org/abs/2410.01403</link>
      <description>arXiv:2410.01403v1 Announce Type: cross 
Abstract: Recent advances in control theory yield closed-loop neurostimulations for suppressing epileptiform seizures. These advances are illustrated by computer experiments which are easy to implement and to tune. The feedback synthesis is provided by an intelligent proportional-derivative (iPD) regulator associated to model-free control. This approach has already been successfully exploited in many concrete situations in engineering, since no precise computational modeling is needed. iPDs permit tracking a large variety of signals including high-amplitude epileptic activity. Those unpredictable pathological brain oscillations should be detected in order to avoid continuous stimulation, which might induce detrimental side effects. This is achieved by introducing a data mining method based on the maxima of the recorded signals. The real-time derivative estimation in a particularly noisy epileptiform environment is made possible due to a newly developed algebraic differentiator. The virtual patient is the Wendling model, i.e., a set of ordinary differential equations adapted from the Jansen-Rit neural mass model in order to generate epileptiform activity via appropriate values of excitation- and inhibition-related parameters. Several simulations, which lead to a large variety of possible scenarios, are discussed. They show the robustness of our control synthesis with respect to different virtual patients and external disturbances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01403v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C\'edric Join, D. Blair Jovellar, Emmanuel Delaleau, Michel Fliess</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Fractional Punishment in Optional Public Goods Game</title>
      <link>https://arxiv.org/abs/2410.01674</link>
      <description>arXiv:2410.01674v1 Announce Type: cross 
Abstract: Punishment is probably the most frequently used mechanism to increase cooperation in Public Goods Games (PGG); however, it is expensive. To address this problem, this paper introduces an optimal control problem that uses fractional punishment to promote cooperation. We present a series of computational experiments illustrating the effects of single and combined terms of the optimization cost function. In the findings, the optimal controller outperforms the use of constant fractional punishment and gives an insight into the period and size of the penalization to be implemented with respect to the defection in the game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01674v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>J. Grau, R. Botta, C. E. Schaerer</dc:creator>
    </item>
    <item>
      <title>Capacities, Measurable Selection and Dynamic Programming Part II: Application in Stochastic Control Problems</title>
      <link>https://arxiv.org/abs/1310.3364</link>
      <description>arXiv:1310.3364v3 Announce Type: replace 
Abstract: We provide an overview on how to use the measurable selection techniques to derive the dynamic programming principle for a general stochastic optimal control/stopping problem. By considering its martingale problem formulation on the canonical space of paths, one can check the required measurability conditions. This covers in particular the most classical controlled/stopped diffusion processes problems. Further, we study the approximation property of the optimal control problems by piecewise constant control problems. As a byproduct, we obtain an equivalence result of the strong, weak and relaxed formulations of the controlled/stopped diffusion processes problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:1310.3364v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicole El Karoui, Xiaolu Tan</dc:creator>
    </item>
    <item>
      <title>Fix and Bound: An efficient approach for solving large-scale quadratic programming problems with box constraints</title>
      <link>https://arxiv.org/abs/2211.08911</link>
      <description>arXiv:2211.08911v2 Announce Type: replace 
Abstract: In this paper, we propose a branch-and-bound algorithm for solving nonconvex quadratic programming problems with box constraints (BoxQP). Our approach combines existing tools, such as semidefinite programming (SDP) bounds strengthened through valid inequalities, with a new class of optimality-based linear cuts which leads to variable fixing. The most important effect of fixing the value of some variables is the size reduction along the branch-and-bound tree, allowing to compute bounds by solving SDPs of smaller dimension. Extensive computational experiments over large dimensional (up to $n=200$) test instances show that our method is the state-of-the-art solver on large-scale BoxQPs. Furthermore, we test the proposed approach on the class of binary QP problems, where it exhibits competitive performance with state-of-the-art solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.08911v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Locatelli, Veronica Piccialli, Antonio M. Sudoso</dc:creator>
    </item>
    <item>
      <title>A Tight Formulation for the Dial-a-Ride Problem</title>
      <link>https://arxiv.org/abs/2308.11285</link>
      <description>arXiv:2308.11285v2 Announce Type: replace 
Abstract: Ridepooling services play an increasingly important role in modern transportation systems. With soaring demand and growing fleet sizes, the underlying route planning problems become increasingly challenging. In this context, we consider the dial-a-ride problem (DARP): Given a set of transportation requests with pick-up and delivery locations, passenger numbers, time windows, and maximum ride times, an optimal routing for a fleet of vehicles, including an optimized passenger assignment, needs to be determined. We present tight mixed-integer linear programming (MILP) formulations for the DARP by combining two state-of-the-art models into novel location-augmented-event-based formulations. Strong valid inequalities and lower and upper bounding techniques are derived to further improve the formulations. We then demonstrate the theoretical and computational superiority of the new model: First, the formulation is tight in the sense that, if time windows shrink to a single point in time, the linear programming relaxation yields integer (and hence optimal) solutions. Second, extensive numerical experiments on benchmark instances show that computational times are on average reduced by 49.7% compared to state-of-the-art event-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.11285v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejor.2024.09.028</arxiv:DOI>
      <dc:creator>Daniela Gaul, Kathrin Klamroth, Christian Pfeiffer, Arne Schulz, Michael Stiglmayr</dc:creator>
    </item>
    <item>
      <title>Solving Nonlinear Absolute Value Equations</title>
      <link>https://arxiv.org/abs/2402.16439</link>
      <description>arXiv:2402.16439v2 Announce Type: replace 
Abstract: In this work we show that several problems naturally modeled as Nonlinear Absolute Value Equations (NAVE), can be restated as Nonlinear Complementarity Problems (NCP) and solved efficiently using smoothing regularizing techniques under mild assumptions. Applications include ridge optimization and resolution of nonlinear ordinary differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16439v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aris Daniilidis (VADOR), Mounir Haddou (IRMAR), Tri Minh Le (VADOR), Olivier Ley (IRMAR)</dc:creator>
    </item>
    <item>
      <title>Emerging Optimization Problems for Distribution in Same-day Delivery</title>
      <link>https://arxiv.org/abs/2405.05620</link>
      <description>arXiv:2405.05620v2 Announce Type: replace 
Abstract: Same-day deliveries (SDD) have become a new standard to satisfy the "instant gratification" of online customers. Despite the existing powerful technologies deployed in last-mile delivery, SDD services face new decision-making challenges related to the trade-off between delivery cost and time. In addition, new challenges related to environmental issues, customer satisfaction, or fairness arise. Researchers have explored various approaches to face these challenges in the context of SDD, where stochastic and dynamic data uncertainty plays a fundamental role. In this paper, we carefully review the emerging routing problems and solutions proposed in the existing literature for SDD services. We survey papers related to how to deal with dynamic arrival times of orders, how to allocate time slots to deliveries, how to select the right delivery options, how to design pickup and delivery routes, or how to partition the delivery areas and decide the composition of the fleet. We also formulate and compare models for representative problems elaborating on the pros and cons that might guide practitioners in choosing the most appropriate objectives and constraints. Finally, we sketch challenges and identify future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05620v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanyuan Li, Claudia Archetti, Ivana Ljubic</dc:creator>
    </item>
    <item>
      <title>Exploratory Optimal Stopping: A Singular Control Formulation</title>
      <link>https://arxiv.org/abs/2408.09335</link>
      <description>arXiv:2408.09335v2 Announce Type: replace 
Abstract: This paper explores continuous-time and state-space optimal stopping problems from a reinforcement learning perspective. We begin by formulating the stopping problem using randomized stopping times, where the decision maker's control is represented by the probability of stopping within a given time--specifically, a bounded, non-decreasing, c\`adl\`ag control process. To encourage exploration and facilitate learning, we introduce a regularized version of the problem by penalizing it with the cumulative residual entropy of the randomized stopping time. The regularized problem takes the form of an (n+1)-dimensional degenerate singular stochastic control with finite-fuel. We address this through the dynamic programming principle, which enables us to identify the unique optimal exploratory strategy. For the specific case of a real option problem, we derive a semi-explicit solution to the regularized problem, allowing us to assess the impact of entropy regularization and analyze the vanishing entropy limit. Finally, we propose a reinforcement learning algorithm based on policy iteration. We show both policy improvement and policy convergence results for our proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09335v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>q-fin.MF</category>
      <category>stat.ML</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jodi Dianetti, Giorgio Ferrari, Renyuan Xu</dc:creator>
    </item>
    <item>
      <title>Ca{\Sigma}oS: A nonlinear sum-of-squares optimization suite</title>
      <link>https://arxiv.org/abs/2409.18549</link>
      <description>arXiv:2409.18549v2 Announce Type: replace 
Abstract: We present Ca$\Sigma$oS, the first MATLAB software specifically designed for nonlinear sum-of-squares optimization. A symbolic polynomial algebra system allows to formulate parametrized sum-of-squares optimization problems and facilitates their fast, repeated evaluations. To that extent, we make use of CasADi's symbolic framework and realize concepts of monomial sparsity, linear operators (including duals), and functions between polynomials. Ca$\Sigma$oS currently provides interfaces to the conic solvers SeDuMi, Mosek, and SCS as well as methods to solve quasiconvex optimization problems (via bisection) and nonconvex optimization problems (via sequential convexification). Numerical examples for benchmark problems including region-of-attraction and reachable set estimation for nonlinear dynamic systems demonstrate significant improvements in computation time compared to existing toolboxes. Ca$\Sigma$oS is available open-source at https://github.com/ifr-acso/casos.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18549v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Torbj{\o}rn Cunis, Jan Olucak</dc:creator>
    </item>
    <item>
      <title>A Parallel-in-Time Newton's Method for Nonlinear Model Predictive Control</title>
      <link>https://arxiv.org/abs/2409.20027</link>
      <description>arXiv:2409.20027v2 Announce Type: replace 
Abstract: Model predictive control (MPC) is a powerful framework for optimal control of dynamical systems. However, MPC solvers suffer from a high computational burden that restricts their application to systems with low sampling frequency. This issue is further amplified in nonlinear and constrained systems that require nesting MPC solvers within iterative procedures. In this paper, we address these issues by developing parallel-in-time algorithms for constrained nonlinear optimization problems that take advantage of massively parallel hardware to achieve logarithmic computational time scaling over the planning horizon. We develop time-parallel second-order solvers based on interior point methods and the alternating direction method of multipliers, leveraging fast convergence and lower computational cost per iteration. The parallelization is based on a reformulation of the subproblems in terms of associative operations that can be parallelized using the associative scan algorithm. We validate our approach on numerical examples of nonlinear and constrained dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20027v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Casian Iacob, Hany Abdulsamad, Simo S\"arkk\"a</dc:creator>
    </item>
    <item>
      <title>On the Oracle Complexity of a Riemannian Inexact Augmented Lagrangian Method for Riemannian Nonsmooth Composite Problems</title>
      <link>https://arxiv.org/abs/2410.00482</link>
      <description>arXiv:2410.00482v2 Announce Type: replace 
Abstract: In this paper, we establish for the first time the oracle complexity of a Riemannian inexact augmented Lagrangian (RiAL) method with the classical dual update for solving a class of Riemannian nonsmooth composite problems. By using the Riemannian gradient descent method with a specified stopping criterion for solving the inner subproblem, we show that the RiAL method can find an $\varepsilon$-stationary point of the considered problem with $\mathcal{O}(\varepsilon^{-3})$ calls to the first-order oracle. This achieves the best oracle complexity known to date. Numerical results demonstrate that the use of the classical dual stepsize is crucial to the high efficiency of the RiAL method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00482v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meng Xu, Bo Jiang, Ya-Feng Liu, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>Logit-Q Dynamics for Efficient Learning in Stochastic Teams</title>
      <link>https://arxiv.org/abs/2302.09806</link>
      <description>arXiv:2302.09806v3 Announce Type: replace-cross 
Abstract: We present a new family of logit-Q dynamics for efficient learning in stochastic games by combining the log-linear learning (also known as logit dynamics) for the repeated play of normal-form games with Q-learning for unknown Markov decision processes within the auxiliary stage-game framework. In this framework, we view stochastic games as agents repeatedly playing some stage game associated with the current state of the underlying game while the agents' Q-functions determine the payoffs of these stage games. We show that the logit-Q dynamics presented reach (near) efficient equilibrium in stochastic teams with unknown dynamics and quantify the approximation error. We also show the rationality of the logit-Q dynamics against agents following pure stationary strategies and the convergence of the dynamics in stochastic games where the stage-payoffs induce potential games, yet only a single agent controls the state transitions beyond stochastic teams. The key idea is to approximate the dynamics with a fictional scenario where the Q-function estimates are stationary over epochs whose lengths grow at a sufficiently slow rate. We then couple the dynamics in the main and fictional scenarios to show that these two scenarios become more and more similar across epochs due to the vanishing step size and growing epoch lengths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.09806v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Said Donmez, Onur Unlu, Muhammed O. Sayin</dc:creator>
    </item>
    <item>
      <title>On Continuous Full-Order Integral-Terminal Sliding Mode Control with Unknown A Priori Bound on Uncertainty</title>
      <link>https://arxiv.org/abs/2304.02433</link>
      <description>arXiv:2304.02433v3 Announce Type: replace-cross 
Abstract: This study aims at providing a solution to the problem of designing a continuous and finite-time control for a class of nonlinear systems in the presence of matched uncertainty with an unknown apriori bound. First, we propose a Full-Order Integral-Terminal Sliding Manifold (FOITSM) with a conventional (discontinuous) sliding mode to show that it provides the combined attributes of the nonsingular terminal and integral sliding mode algorithms. Secondly, an Adaptive Disturbance Observer (ADO) has been designed to alleviate the effect of the uncertainty acting on the system. On application of the ADO-based Full-Order Integral-Terminal Sliding Mode Control (FOITSMC), the chattering phenomenon in control input has been reduced substantially in the presence of conditionally known matched disturbances. Moreover, the adaptive gains of ADO are updated non-monotonically without over-bounding the acting disturbance, yet sustain the global boundedness of state trajectories within a specific bound. %Finally, an application of the proposed algorithm for attitude stabilization of a rigid spacecraft has been successively shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.02433v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jit Koley, Dinesh Patra, Binoy Krishna Roy</dc:creator>
    </item>
    <item>
      <title>The Average Rate of Convergence of the Exact Line Search Gradient Descent Method</title>
      <link>https://arxiv.org/abs/2305.09140</link>
      <description>arXiv:2305.09140v2 Announce Type: replace-cross 
Abstract: It is very well-known that when the exact line search gradient descent method is applied to a convex quadratic objective, the worst case rate of convergence (among all seed vectors) deteriorates as the condition number of the Hessian of the objective grows. By an elegant analysis by H. Akaike, it is generally believed -- but not proved -- that in the ill-conditioned regime the ROC for almost all initial vectors, and hence also the average ROC, is close to the worst case ROC. We complete Akaike's analysis using the theorem of center and stable manifolds. Our analysis also makes apparent the effect of an intermediate eigenvalue in the Hessian by establishing the following somewhat amusing result: In the absence of an intermediate eigenvalue, the average ROC gets arbitrarily fast -- not slow -- as the Hessian gets increasingly ill-conditioned.
  We discuss in passing some contemporary applications of exact line search GD to polynomial optimization problems arising from imaging and data sciences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.09140v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Yu</dc:creator>
    </item>
    <item>
      <title>Collective rhythm design in coupled mixed-feedback systems through dominance and bifurcations</title>
      <link>https://arxiv.org/abs/2401.04324</link>
      <description>arXiv:2401.04324v2 Announce Type: replace-cross 
Abstract: The theory of mixed-feedback systems provides an effective framework for the design of robust and tunable oscillations in nonlinear systems characterized by interleaved fast positive and slow negative feedback loops. The goal of this paper is to extend the mixed-feedback oscillation design framework to networks. To this aim, we introduce a network model of coupled mixed-feedback systems, ask under which conditions it exhibits a collective oscillatory rhythm, and if, and how, this rhythm can be shaped by network design. In the proposed network model, node dynamics are nonlinear and defined by a tractable realization of the mixed-feedback structure. Coupling between nodes is also nonlinear and defined by a tractable abstraction of synaptic coupling between neurons. We derive constructive conditions under which the spectral properties of the network adjacency matrix fully and explicitly determine both the emergence of a stable network rhythm and its detailed rhythmic profile, i.e., the pattern of relative oscillation amplitudes and phase differences. Our theoretical developments are grounded on ideas from dominant systems and bifurcation theory. They provide a new framework for the analysis and design of nonlinear network rhythms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04324v2</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>nlin.AO</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omar Juarez-Alvarez, Alessio Franci</dc:creator>
    </item>
    <item>
      <title>Provable Preconditioned Plug-and-Play Approach for Compressed Sensing MRI Reconstruction</title>
      <link>https://arxiv.org/abs/2405.03854</link>
      <description>arXiv:2405.03854v2 Announce Type: replace-cross 
Abstract: Model-based methods play a key role in the reconstruction of compressed sensing (CS) MRI. Finding an effective prior to describe the statistical distribution of the image family of interest is crucial for model-based methods. Plug-and-play (PnP) is a general framework that uses denoising algorithms as the prior or regularizer. Recent work showed that PnP methods with denoisers based on pretrained convolutional neural networks outperform other classical regularizers in CS MRI reconstruction. However, the numerical solvers for PnP can be slow for CS MRI reconstruction. This paper proposes a preconditioned PnP (P^2nP) method to accelerate the convergence speed. Moreover, we provide proofs of the fixed-point convergence of the P^2nP iterates. Numerical experiments on CS MRI reconstruction with non-Cartesian sampling trajectories illustrate the effectiveness and efficiency of the P^2nP approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03854v2</guid>
      <category>eess.IV</category>
      <category>math.OC</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Hong, Xiaojian Xu, Jason Hu, Jeffrey A. Fessler</dc:creator>
    </item>
    <item>
      <title>Local convergence of simultaneous min-max algorithms to differential equilibrium on Riemannian manifold</title>
      <link>https://arxiv.org/abs/2405.13392</link>
      <description>arXiv:2405.13392v2 Announce Type: replace-cross 
Abstract: We study min-max algorithms to solve zero-sum differential games on Riemannian manifold. Based on the notions of differential Stackelberg equilibrium and differential Nash equilibrium on Riemannian manifold, we analyze the local convergence of two representative deterministic simultaneous algorithms $\tau$-GDA and $\tau$-SGA to such equilibrium. Sufficient conditions are obtained to establish their linear convergence rates by Ostrowski theorem on manifold and spectral analysis. The $\tau$-SGA algorithm is extended from the symplectic gradient-adjustment method in Euclidean space to avoid strong rotational dynamics in $\tau$-GDA. In some cases, we obtain a faster convergence rate of $\tau$-SGA through an asymptotic analysis which is valid when the learning rate ratio $\tau$ is big. We show numerically how the insights obtained from the convergence analysis may improve the training of orthogonal Wasserstein GANs using stochastic $\tau$-GDA and $\tau$-SGA on simple benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13392v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sixin Zhang</dc:creator>
    </item>
    <item>
      <title>Decentralized Optimization in Time-Varying Networks with Arbitrary Delays</title>
      <link>https://arxiv.org/abs/2405.19513</link>
      <description>arXiv:2405.19513v2 Announce Type: replace-cross 
Abstract: We consider a decentralized optimization problem for networks affected by communication delays. Examples of such networks include collaborative machine learning, sensor networks, and multi-agent systems. To mimic communication delays, we add virtual non-computing nodes to the network, resulting in directed graphs. This motivates investigating decentralized optimization solutions on directed graphs. Existing solutions assume nodes know their out-degrees, resulting in limited applicability. To overcome this limitation, we introduce a novel gossip-based algorithm, called DT-GO, that does not need to know the out-degrees. The algorithm is applicable in general directed networks, for example networks with delays or limited acknowledgment capabilities. We derive convergence rates for both convex and non-convex objectives, showing that our algorithm achieves the same complexity order as centralized Stochastic Gradient Descent. In other words, the effects of the graph topology and delays are confined to higher-order terms. Additionally, we extend our analysis to accommodate time-varying network topologies. Numerical simulations are provided to support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19513v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tomas Ortega, Hamid Jafarkhani</dc:creator>
    </item>
    <item>
      <title>Almost Sure Convergence of Average Reward Temporal Difference Learning</title>
      <link>https://arxiv.org/abs/2409.19546</link>
      <description>arXiv:2409.19546v3 Announce Type: replace-cross 
Abstract: Tabular average reward Temporal Difference (TD) learning is perhaps the simplest and the most fundamental policy evaluation algorithm in average reward reinforcement learning. After at least 25 years since its discovery, we are finally able to provide a long-awaited almost sure convergence analysis. Namely, we are the first to prove that, under very mild conditions, tabular average reward TD converges almost surely to a sample path dependent fixed point. Key to this success is a new general stochastic approximation result concerning nonexpansive mappings with Markovian and additive noise, built on recent advances in stochastic Krasnoselskii-Mann iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19546v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ethan Blaser, Shangtong Zhang</dc:creator>
    </item>
  </channel>
</rss>
