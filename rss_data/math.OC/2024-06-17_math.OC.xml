<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Jun 2024 02:49:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 17 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Gap-gradient methods for solving generalized mixed integer inverse optimization: an application to political gerrymandering</title>
      <link>https://arxiv.org/abs/2406.09457</link>
      <description>arXiv:2406.09457v1 Announce Type: new 
Abstract: Inverse optimization has received much attention in recent years, but little literature exists for solving generalized mixed integer inverse optimization. We propose a new approach for solving generalized mixed-integer inverse optimization problems based on sub-gradient methods. We characterize when a generalized inverse optimization problem can be solved using sub-gradient methods and we prove that modifications to classic sub-gradient algorithms can return exact solutions in finite time. Our best implementation improves solution time by up to 90% compared to the best performing method from the literature. We then develop custom heuristic methods for graph-based inverse problems using a combination of graph coarsening and ensemble methods. Our heuristics are able to further reduce solution time by up to 52%, while still producing near-optimal solutions. Finally, we propose a new application domain - quantitatively identifying gerrymandering - for generalized inverse integer optimization. We apply our overall solution approach to analyze the congressional districts of the State of Iowa using real-world data. We find that the accepted districting marginally improves population imbalance at the cost of a significant increase in partisan efficiency gap. We argue that our approach can produce a more nuanced data-driven argument that a proposed districting should be considered gerrymandered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09457v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ari J. Smith, Justin J. Boutilier</dc:creator>
    </item>
    <item>
      <title>The polarization hierarchy for polynomial optimization over convex bodies, with applications to nonnegative matrix rank</title>
      <link>https://arxiv.org/abs/2406.09506</link>
      <description>arXiv:2406.09506v1 Announce Type: new 
Abstract: We construct a convergent family of outer approximations for the problem of optimizing polynomial functions over convex bodies subject to polynomial constraints. This is achieved by generalizing the polarization hierarchy, which has previously been introduced for the study of polynomial optimization problems over state spaces of $C^*$-algebras, to convex cones in finite dimensions. If the convex bodies can be characterized by linear or semidefinite programs, then the same is true for our hierarchy. Convergence is proven by relating the problem to a certain de Finetti theorem for general probabilistic theories, which are studied as possible generalizations of quantum mechanics. We apply the method to the problem of nonnegative matrix factorization, and in particular to the nested rectangles problem. A numerical implementation of the third level of the hierarchy is shown to give rise to a very tight approximation for this problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09506v1</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Pl\'avala, Laurens T. Ligthart, David Gross</dc:creator>
    </item>
    <item>
      <title>Finite-Agent Stochastic Differential Games on Large Graphs: I. The Linear-Quadratic Case</title>
      <link>https://arxiv.org/abs/2406.09523</link>
      <description>arXiv:2406.09523v1 Announce Type: new 
Abstract: In this paper, we study finite-agent linear-quadratic games on graphs. Specifically, we propose a comprehensive framework that extends the existing literature by incorporating heterogeneous and interpretable player interactions. Compared to previous works, our model offers a more realistic depiction of strategic decision-making processes. For general graphs, we establish the convergence of fictitious play, a widely-used iterative solution method for determining the Nash equilibrium of our proposed game model. Notably, under appropriate conditions, this convergence holds true irrespective of the number of players involved. For vertex-transitive graphs, we develop a semi-explicit characterization of the Nash equilibrium. Through rigorous analysis, we demonstrate the well-posedness of this characterization under certain conditions. We present numerical experiments that validate our theoretical results and provide insights into the intricate relationship between various game dynamics and the underlying graph structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09523v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruimeng Hu, Jihao Long, Haosheng Zhou</dc:creator>
    </item>
    <item>
      <title>Brief research of traditional and AI-based models for IMD2 cancellation</title>
      <link>https://arxiv.org/abs/2406.09531</link>
      <description>arXiv:2406.09531v1 Announce Type: new 
Abstract: Due to the limited isolation of duplexer's stopband transceivers operating in frequency division duplex (FDD) encounter a leakage of the transmitted signal onto the receiving path. Leakage signal with the combination of the second-order nonlinearity of the low noise amplifier (LNA) and receiver down-conversion mixer may lead to second-order intermodulation distortion (IMD2) generation thus greatly reducing the receiver sensitivity. Cancellation of undesirable interferences based on adaptation of traditional models such as memoryless and memory polynomials, spline polynomial based Hammerstein and Wiener-Hammerstein models proved its efficiency in case of well-known nonlinearity nature. On the other hand, currently there is an intensive research in the field of nonlinearity detection by means of neural network (NN) structures. NN-based IMD cancellers are effective in the case of unknown interference content due to their high generalization ability. Therefore, NN approach can provide universal model, which is capable of IMD suppression even in case it is hard to separate intermodulation products generated by LNA, down-conversion mixer or even power amplifier in transmitter path. Nevertheless, such structures suffer from high complexity and can`t be implemented in hardware. Current paper presents low-complexity feed-forward NN-based model, which successfully competes with traditional architectures in terms of computational complexity. The testbench results demonstrate the acceptable performance of provided model, which can be equal to the polynomial nonlinear canceler's performance at a reduced computational cost. Current paper provides performance and required resources comparison of traditional memory polynomial-based scheme and NN-based model for IMD2 cancellation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09531v1</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. A. Degtyarev, N. V. Bakholdin, A. Y. Maslovskiy, S. A. Bakhurin</dc:creator>
    </item>
    <item>
      <title>Measure This, Not That: Optimizing the Cost and Model-Based Information Content of Measurements</title>
      <link>https://arxiv.org/abs/2406.09557</link>
      <description>arXiv:2406.09557v1 Announce Type: new 
Abstract: Model-based design of experiments (MBDoE) is a powerful framework for selecting and calibrating science-based mathematical models from data. This work extends popular MBDoE workflows by proposing a convex mixed integer (non)linear programming (MINLP) problem to optimize the selection of measurements. The solver MindtPy is modified to support calculating the D-optimality objective and its gradient via an external package, \texttt{SciPy}, using the grey-box module in Pyomo. The new approach is demonstrated in two case studies: estimating highly correlated kinetics from a batch reactor and estimating transport parameters in a large-scale rotary packed bed for CO$_2$ capture. Both case studies show how examining the Pareto-optimal trade-offs between information content measured by A- and D-optimality versus measurement budget offers practical guidance for selecting measurements for scientific experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09557v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jialu Wang, Zedong Peng, Ryan Hughes, Debangsu Bhattacharyya, David E. Bernal Neira, Alexander W. Dowling</dc:creator>
    </item>
    <item>
      <title>Shape optimization for maximizing ionic concentration constrained by steady-state Poisson-Nernst-Planck system</title>
      <link>https://arxiv.org/abs/2406.09616</link>
      <description>arXiv:2406.09616v1 Announce Type: new 
Abstract: We build a new mathematical model of shape optimization for maximizing ionic concentration governed by the multi-physical coupling steady-state Poisson-Nernst-Planck system. Shape sensitivity analysis is performed to obtain the Eulerian derivative of the cost functional. The Gummel fixed-point method with inverse harmonic averaging technique on exponential coefficient is used to solve efficiently the steady-state Poisson-Nernst-Planck system. Various numerical results using a shape gradient algorithm in 2d and 3d are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09616v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jiajie Li, Shenggao Zhou, Shengfeng Zhu</dc:creator>
    </item>
    <item>
      <title>Interior-Point-based H2 Controller Synthesis for Compartmental Systems</title>
      <link>https://arxiv.org/abs/2406.09753</link>
      <description>arXiv:2406.09753v1 Announce Type: new 
Abstract: This paper addresses the problem of the optimal $H_2$ controller design for compartmental systems. In other words, we aim to enhance system robustness while maintaining the law of mass conservation. We perform a novel problem transformation and establish that the original problem is equivalent to an new optimization problem with a closed polyhedron constraint. Existing works have developed various first-order methods to tackle inequality constraints. However, the performance of the first-order method is limited in terms of convergence speed and precision, restricting its potential in practical applications. Therefore, developing a novel algorithm with fast speed and high precision is critical. In this paper, we reformulate the problem using log-barrier functions and introduce two separate approaches to address the problem: the first-order interior point method (FIPM) and the second-order interior point method (SIPM). We show they converge to a stationary point of the new problem. In addition, we propose an initialization method to guarantee the interior property of initial values. Finally, we compare FIPM and SIPM through a room temperature control example and show their pros and cons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09753v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaohua Yang, Nachuan Yang, Pengyu Wang, Haishan Zhang, Xiayan Xu, Ling Shi</dc:creator>
    </item>
    <item>
      <title>Accelerated Over-Relaxation Heavy-Ball Methods with Provable Acceleration and Global Convergence</title>
      <link>https://arxiv.org/abs/2406.09772</link>
      <description>arXiv:2406.09772v1 Announce Type: new 
Abstract: The heavy-ball momentum method has gained widespread popularity for accelerating gradient descent by incorporating a momentum term. Recent studies have conclusively shown that the heavy-ball method cannot achieve an accelerated convergence rate for general smooth strongly convex optimization problems. This work introduces the Accelerated Over-Relaxation Heavy-Ball (AOR-HB) method, a novel approach that represents the first heavy-ball method to demonstrate provable global and accelerated convergence for smooth strongly convex optimization. The key innovation of the AOR-HB method lies in the application of an over-relaxation technique to the gradient term. This novel approach enables the method to be applied to min-max problems and meet optimal lower complexity bounds. This breakthrough addresses a long-standing theoretical gap in heavy-ball momentum methods and paves the way for developing accelerated methods that transcend the boundaries of convex optimization to non-convex optimization. Numerical experiments validate the effectiveness of the proposed algorithms, with their performance matching that of other leading first-order optimization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09772v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingrong Wei, Long Chen</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of a regularized Newton method with generalized regularization terms for convex optimization problems</title>
      <link>https://arxiv.org/abs/2406.09786</link>
      <description>arXiv:2406.09786v1 Announce Type: new 
Abstract: In this paper, we present a regularized Newton method (RNM) with generalized regularization terms for an unconstrained convex optimization problem. The generalized regularization includes the quadratic, cubic, and elastic net regularization as a special case. Therefore, the proposed method is a general framework that includes not only the classical and cubic RNMs but also a novel RNM with the elastic net. We show that the proposed RNM has the global $\mathcal{O}(k^{-2})$ and local superlinear convergence, which are the same as those of the cubic RNM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09786v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuya Yamakawa, Nobuo Yamashita</dc:creator>
    </item>
    <item>
      <title>A Zeroth-Order Proximal Algorithm for Consensus Optimization</title>
      <link>https://arxiv.org/abs/2406.09816</link>
      <description>arXiv:2406.09816v1 Announce Type: new 
Abstract: This paper considers a consensus optimization problem, where all the nodes in a network, with access to the zeroth-order information of its local objective function only, attempt to cooperatively achieve a common minimizer of the sum of their local objectives. To address this problem, we develop ZoPro, a zeroth-order proximal algorithm, which incorporates a zeroth-order oracle for approximating Hessian and gradient into a recently proposed, high-performance distributed second-order proximal algorithm. We show that the proposed ZoPro algorithm, equipped with a dynamic stepsize, converges linearly to a neighborhood of the optimum in expectation, provided that each local objective function is strongly convex and smooth. Extensive simulations demonstrate that ZoPro converges faster than several state-of-the-art distributed zeroth-order algorithms and outperforms a few distributed second-order algorithms in terms of running time for reaching given accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09816v1</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chengan Wang, Zichong Ou, Jie Lu</dc:creator>
    </item>
    <item>
      <title>A penalty barrier framework for nonconvex constrained optimization</title>
      <link>https://arxiv.org/abs/2406.09901</link>
      <description>arXiv:2406.09901v1 Announce Type: new 
Abstract: Focusing on minimization problems with structured objective function and smooth constraints, we present a flexible technique that combines the beneficial regularization effects of (exact) penalty and interior-point methods. Working in the fully nonconvex setting, a pure barrier approach requires careful steps when approaching the infeasible set, thus hindering convergence. We show how a tight integration with a penalty scheme overcomes such conservatism, does not require a strictly feasible starting point, and thus accommodates equality constraints. The crucial advancement that allows us to invoke generic (possibly accelerated) subsolvers is a marginalization step: amounting to a conjugacy operation, this step effectively merges (exact) penalty and barrier into a smooth, full domain functional object. When the penalty exactness takes effect, the generated subproblems do not suffer the ill-conditioning typical of penalty methods, nor do they exhibit the nonsmoothness of exact penalty terms. We provide a theoretical characterization of the algorithm and its asymptotic properties, deriving convergence results for fully nonconvex problems. Illustrative examples and numerical simulations demonstrate the wide range of problems our theory and algorithm are able to cover.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09901v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto De Marchi, Andreas Themelis</dc:creator>
    </item>
    <item>
      <title>Exact Sparse Representation Recovery in Signal Demixing and Group BLASSO</title>
      <link>https://arxiv.org/abs/2406.09922</link>
      <description>arXiv:2406.09922v1 Announce Type: new 
Abstract: In this short article we present the theory of sparse representations recovery in convex regularized optimization problems introduced in (Carioni and Del Grande, arXiv:2311.08072, 2023). We focus on the scenario where the unknowns belong to Banach spaces and measurements are taken in Hilbert spaces, exploring the properties of minimizers of optimization problems in such settings. Specifically, we analyze a Tikhonov-regularized convex optimization problem, where $y_0$ are the measured data, $w$ denotes the noise, and $\lambda$ is the regularization parameter. By introducing a Metric Non-Degenerate Source Condition (MNDSC) and considering sufficiently small $\lambda$ and $w$, we establish Exact Sparse Representation Recovery (ESRR) for our problems, meaning that the minimizer is unique and precisely recovers the sparse representation of the original data. We then emphasize the practical implications of this theoretical result through two novel applications: signal demixing and super-resolution with Group BLASSO. These applications underscore the broad applicability and significance of our result, showcasing its potential across different domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09922v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcello Carioni, Leonardo Del Grande</dc:creator>
    </item>
    <item>
      <title>An Extended Validity Domain for Constraint Learning</title>
      <link>https://arxiv.org/abs/2406.10065</link>
      <description>arXiv:2406.10065v1 Announce Type: new 
Abstract: We consider embedding a predictive machine-learning model within a prescriptive optimization problem. In this setting, called constraint learning, we study the concept of a validity domain, i.e., a constraint added to the feasible set, which keeps the optimization close to the training data, thus helping to ensure that the computed optimal solution exhibits less prediction error. In particular, we propose a new validity domain which uses a standard convex-hull idea but in an extended space. We investigate its properties and compare it empirically with existing validity domains on a set of test problems for which the ground truth is known. Results show that our extended convex hull routinely outperforms existing validity domains, especially in terms of the function value error, that is, it exhibits closer agreement between the true function value and the predicted function value at the computed optimal solution. We also consider our approach within two stylized optimization models, which show that our method reduces feasibility error, as well as a real-world pricing case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10065v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilin Zhu, Samuel Burer</dc:creator>
    </item>
    <item>
      <title>Technical Report: A Totally Asynchronous Nesterov's Accelerated Gradient Method for Convex Optimization</title>
      <link>https://arxiv.org/abs/2406.10124</link>
      <description>arXiv:2406.10124v1 Announce Type: new 
Abstract: We present a totally asynchronous algorithm for convex optimization that is based on a novel generalization of Nesterov's accelerated gradient method. This algorithm is developed for fast convergence under "total asynchrony," i.e., allowing arbitrarily long delays between agents' computations and communications without assuming any form of delay bound. These conditions may arise, for example, due to jamming by adversaries. Our framework is block-based, in the sense that each agent is only responsible for computing updates to (and communicating the values of) a small subset of the network-level decision variables. In our main result, we present bounds on the algorithm's parameters that guarantee linear convergence to an optimizer. Then, we quantify the relationship between (i) the total number of computations and communications executed by the agents and (ii) the agents' collective distance to an optimum. Numerical simulations show that this algorithm requires 28% fewer iterations than the heavy ball algorithm and 61% fewer iterations than gradient descent under total asynchrony.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10124v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ellie Pond, April Sebok, Zachary Bell, Matthew Hale</dc:creator>
    </item>
    <item>
      <title>A Primal-Dual-Assisted Penalty Approach to Bilevel Optimization with Coupled Constraints</title>
      <link>https://arxiv.org/abs/2406.10148</link>
      <description>arXiv:2406.10148v1 Announce Type: new 
Abstract: Interest in bilevel optimization has grown in recent years, partially due to its applications to tackle challenging machine-learning problems. Several exciting recent works have been centered around developing efficient gradient-based algorithms that can solve bilevel optimization problems with provable guarantees. However, the existing literature mainly focuses on bilevel problems either without constraints, or featuring only simple constraints that do not couple variables across the upper and lower levels, excluding a range of complex applications. Our paper studies this challenging but less explored scenario and develops a (fully) first-order algorithm, which we term BLOCC, to tackle BiLevel Optimization problems with Coupled Constraints. We establish rigorous convergence theory for the proposed algorithm and demonstrate its effectiveness on two well-known real-world applications - hyperparameter selection in support vector machine (SVM) and infrastructure planning in transportation networks using the real data from the city of Seville.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10148v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liuyuan Jiang, Quan Xiao, Victor M. Tenorio, Fernando Real-Rojas, Antonio Marques, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>New algorithms for sampling and diffusion models</title>
      <link>https://arxiv.org/abs/2406.09665</link>
      <description>arXiv:2406.09665v1 Announce Type: cross 
Abstract: Drawing from the theory of stochastic differential equations, we introduce a novel sampling method for known distributions and a new algorithm for diffusion generative models with unknown distributions. Our approach is inspired by the concept of the reverse diffusion process, widely adopted in diffusion generative models. Additionally, we derive the explicit convergence rate based on the smooth ODE flow. For diffusion generative models and sampling, we establish a {\it dimension-free} particle approximation convergence result. Numerical experiments demonstrate the effectiveness of our method. Notably, unlike the traditional Langevin method, our sampling method does not require any regularity assumptions about the density function of the target distribution. Furthermore, we also apply our method to optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09665v1</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Xicheng Zhang</dc:creator>
    </item>
    <item>
      <title>Computation of Robust Option Prices via Structured Multi-Marginal Martingale Optimal Transport</title>
      <link>https://arxiv.org/abs/2406.09959</link>
      <description>arXiv:2406.09959v1 Announce Type: cross 
Abstract: We introduce an efficient computational framework for solving a class of multi-marginal martingale optimal transport problems, which includes many robust pricing problems of large financial interest. Such problems are typically computationally challenging due to the martingale constraint, however, by extending the state space we can identify them with problems that exhibit a certain sequential martingale structure. Our method exploits such structures in combination with entropic regularisation, enabling fast computation of optimal solutions and allowing us to solve problems with a large number of marginals. We demonstrate the method by using it for computing robust price bounds for different options, such as lookback options and Asian options.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09959v1</guid>
      <category>q-fin.CP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linn Engstr\"om, Sigrid K\"allblad, Johan Karlsson</dc:creator>
    </item>
    <item>
      <title>The one-station bike repositioning problem</title>
      <link>https://arxiv.org/abs/2210.14002</link>
      <description>arXiv:2210.14002v3 Announce Type: replace 
Abstract: In bike sharing systems the quality of the service to the users strongly depends on the strategy adopted to reposition the bikes. The bike repositioning problem is in general very complex as it involves different interrelated decisions: the routing of the repositioning vehicles, the scheduling of their visits to the stations, the number of bikes to load or unload for each station and for each vehicle that visits the station. In this paper we study the problem of optimally loading/unloading vehicles that visit the same station at given time instants of a finite time horizon. The goal is to minimize the total lost demand of bikes and free stands in the station. We model the problem as a mixed integer linear programming problem and present an optimal algorithm that runs in linear time in the size of the time horizon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.14002v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>E. Angelelli, A. Mor, M. G. Speranza</dc:creator>
    </item>
    <item>
      <title>Neural Operators for PDE Backstepping Control of First-Order Hyperbolic PIDE with Recycle and Delay</title>
      <link>https://arxiv.org/abs/2307.11436</link>
      <description>arXiv:2307.11436v2 Announce Type: replace 
Abstract: The recently introduced DeepONet operator-learning framework for PDE control is extended from the results for basic hyperbolic and parabolic PDEs to an advanced hyperbolic class that involves delays on both the state and the system output or input. The PDE backstepping design produces gain functions that are outputs of a nonlinear operator, mapping functions on a spatial domain into functions on a spatial domain, and where this gain-generating operator's inputs are the PDE's coefficients. The operator is approximated with a DeepONet neural network to a degree of accuracy that is provably arbitrarily tight. Once we produce this approximation-theoretic result in infinite dimension, with it we establish stability in closed loop under feedback that employs approximate gains. In addition to supplying such results under full-state feedback, we also develop DeepONet-approximated observers and output-feedback laws and prove their own stabilizing properties under neural operator approximations. With numerical simulations we illustrate the theoretical results and quantify the numerical effort savings, which are of two orders of magnitude, thanks to replacing the numerical PDE solving with the DeepONet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.11436v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.sysconle.2024.105714</arxiv:DOI>
      <arxiv:journal_reference>Systems &amp; Control Letters, 2024</arxiv:journal_reference>
      <dc:creator>Jie Qi, Jing Zhang, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>Adaptive Preconditioned Gradient Descent with Energy</title>
      <link>https://arxiv.org/abs/2310.06733</link>
      <description>arXiv:2310.06733v2 Announce Type: replace 
Abstract: We propose an adaptive step size with an energy approach for a suitable class of preconditioned gradient descent methods. We focus on settings where the preconditioning is applied to address the constraints in optimization problems, such as the Hessian-Riemannian and natural gradient descent methods. More specifically, we incorporate these preconditioned gradient descent algorithms in the recently introduced Adaptive Energy Gradient Descent (AEGD) framework. In particular, we discuss theoretical results on the unconditional energy-stability and convergence rates across three classes of objective functions. Furthermore, our numerical results demonstrate excellent performance of the proposed method on several test bed optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06733v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hailiang Liu, Levon Nurbekyan, Xuping Tian, Yunan Yang</dc:creator>
    </item>
    <item>
      <title>Metric Entropy-Free Sample Complexity Bounds for Sample Average Approximation in Convex Stochastic Programming</title>
      <link>https://arxiv.org/abs/2401.00664</link>
      <description>arXiv:2401.00664v3 Announce Type: replace 
Abstract: This paper studies sample average approximation (SAA) in solving convex or strongly convex stochastic programming problems. Under some common regularity conditions, we show -- perhaps for the first time -- that SAA's sample complexity can be completely free from any quantification of metric entropy (such as the logarithm of the covering number), leading to a significantly more efficient rate with dimensionality $d$ than most existing results. From the newly established complexity bounds, an important revelation is that SAA and the canonical stochastic mirror descent (SMD) method, two mainstream solution approaches to SP, entail almost identical rates of sample efficiency, rectifying a persistent theoretical discrepancy of SAA from SMD by the order of $O(d)$. Furthermore, this paper explores non-Lipschitzian scenarios where SAA maintains provable efficacy but the corresponding results for SMD remain mostly unexplored, indicating the potential of SAA's better applicability in some irregular settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00664v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongcheng Liu, Jindong Tong</dc:creator>
    </item>
    <item>
      <title>An excursion onto Schr\"odinger's bridges: Stochastic flows with spatio-temporal marginals</title>
      <link>https://arxiv.org/abs/2404.07402</link>
      <description>arXiv:2404.07402v4 Announce Type: replace 
Abstract: The purpose of the present work is to expand substantially the type of control and estimation problems that can be addressed following the paradigm of Schr\"odinger bridges, by incorporating termination (killing) of stochastic flows. Specifically, in the context of estimation, we seek the most likely evolution realizing measured spatio-temporal marginals of killed particles. In the context of control, we seek a suitable control action directing the killed process toward spatio-temporal probabilistic constraints. To this end, we derive a new Schr\"odinger system of coupled, in space and time, partial differential equations to construct the solution of the proposed problem. Further, we show that a Fortet-Sinkhorn type of algorithm is available to attain the associated bridge. A key feature of our framework is that the obtained bridge retains the Markovian structure in the prior process, and thereby, the corresponding controller takes the form of state feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07402v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asmaa Eldesoukey, Olga Movilla Miangolarra, Tryphon T. Georgiou</dc:creator>
    </item>
    <item>
      <title>Asymptotic Stability and Strict Passivity of Port-Hamiltonian Descriptor Systems via State Feedback</title>
      <link>https://arxiv.org/abs/2406.08994</link>
      <description>arXiv:2406.08994v2 Announce Type: replace 
Abstract: While port-Hamiltonian descriptor systems are known to be stable and passive, they may not be asymptotically stable or strictly passive. Necessary and sufficient conditions are presented when these properties as well as the regularity and the index one property can be achieved via state feedback while preserving the port-Hamiltonian structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08994v2</guid>
      <category>math.OC</category>
      <category>math.CA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Delin Chu, Volker Mehrmann</dc:creator>
    </item>
    <item>
      <title>Sparse Graphical Linear Dynamical Systems</title>
      <link>https://arxiv.org/abs/2307.03210</link>
      <description>arXiv:2307.03210v2 Announce Type: replace-cross 
Abstract: Time-series datasets are central in machine learning with applications in numerous fields of science and engineering, such as biomedicine, Earth observation, and network analysis. Extensive research exists on state-space models (SSMs), which are powerful mathematical tools that allow for probabilistic and interpretable learning on time series. Learning the model parameters in SSMs is arguably one of the most complicated tasks, and the inclusion of prior knowledge is known to both ease the interpretation but also to complicate the inferential tasks. Very recent works have attempted to incorporate a graphical perspective on some of those model parameters, but they present notable limitations that this work addresses. More generally, existing graphical modeling tools are designed to incorporate either static information, focusing on statistical dependencies among independent random variables (e.g., graphical Lasso approach), or dynamic information, emphasizing causal relationships among time series samples (e.g., graphical Granger approaches). However, there are no joint approaches combining static and dynamic graphical modeling within the context of SSMs. This work proposes a novel approach to fill this gap by introducing a joint graphical modeling framework that bridges the graphical Lasso model and a causal-based graphical approach for the linear-Gaussian SSM. We present DGLASSO (Dynamic Graphical Lasso), a new inference method within this framework that implements an efficient block alternating majorization-minimization algorithm. The algorithm's convergence is established by departing from modern tools from nonlinear analysis. Experimental validation on various synthetic data showcases the effectiveness of the proposed model and inference algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03210v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emilie Chouzenoux, Victor Elvira</dc:creator>
    </item>
    <item>
      <title>Bayesian Optimization of Function Networks with Partial Evaluations</title>
      <link>https://arxiv.org/abs/2311.02146</link>
      <description>arXiv:2311.02146v2 Announce Type: replace-cross 
Abstract: Bayesian optimization is a powerful framework for optimizing functions that are expensive or time-consuming to evaluate. Recent work has considered Bayesian optimization of function networks (BOFN), where the objective function is given by a network of functions, each taking as input the output of previous nodes in the network as well as additional parameters. Leveraging this network structure has been shown to yield significant performance improvements. Existing BOFN algorithms for general-purpose networks evaluate the full network at each iteration. However, many real-world applications allow for evaluating nodes individually. To exploit this, we propose a novel knowledge gradient acquisition function that chooses which node and corresponding inputs to evaluate in a cost-aware manner, thereby reducing query costs by evaluating only on a part of the network at each step. We provide an efficient approach to optimizing our acquisition function and show that it outperforms existing BOFN methods and other benchmarks across several synthetic and real-world problems. Our acquisition function is the first to enable cost-aware optimization of a broad class of function networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02146v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Poompol Buathong, Jiayue Wan, Raul Astudillo, Samuel Daulton, Maximilian Balandat, Peter I. Frazier</dc:creator>
    </item>
    <item>
      <title>Score-Aware Policy-Gradient Methods and Performance Guarantees using Local Lyapunov Conditions: Applications to Product-Form Stochastic Networks and Queueing Systems</title>
      <link>https://arxiv.org/abs/2312.02804</link>
      <description>arXiv:2312.02804v2 Announce Type: replace-cross 
Abstract: In this paper, we introduce a policy-gradient method for model-based reinforcement learning (RL) that exploits a type of stationary distributions commonly obtained from Markov decision processes (MDPs) in stochastic networks, queueing systems, and statistical mechanics. Specifically, when the stationary distribution of the MDP belongs to an exponential family that is parametrized by policy parameters, we can improve existing policy gradient methods for average-reward RL. Our key identification is a family of gradient estimators, called score-aware gradient estimators (SAGEs), that enable policy gradient estimation without relying on value-function approximation in the aforementioned setting. This contrasts with other common policy-gradient algorithms such as actor-critic methods. We first show that policy-gradient with SAGE locally converges, including in cases when the objective function is nonconvex, presents multiple maximizers, and the state space of the MDP is not finite. Under appropriate assumptions such as starting sufficiently close to a maximizer, the policy under stochastic gradient ascent with SAGE has an overwhelming probability of converging to the associated optimal policy. Other key assumptions are that a local Lyapunov function exists, and a nondegeneracy property of the Hessian of the objective function holds locally around a maximizer. Furthermore, we conduct a numerical comparison between a SAGE-based policy-gradient method and an actor-critic method. We specifically focus on several examples inspired from stochastic networks, queueing systems, and models derived from statistical physics, where parametrizable exponential families are commonplace. Our results demonstrate that a SAGE-based method finds close-to-optimal policies faster than an actor-critic method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02804v2</guid>
      <category>cs.LG</category>
      <category>cs.PF</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C\'eline Comte, Matthieu Jonckheere, Jaron Sanders, Albert Senen-Cerda</dc:creator>
    </item>
    <item>
      <title>A Novel Noise-Aware Classical Optimizer for Variational Quantum Algorithms</title>
      <link>https://arxiv.org/abs/2401.10121</link>
      <description>arXiv:2401.10121v2 Announce Type: replace-cross 
Abstract: A key component of variational quantum algorithms (VQAs) is the choice of classical optimizer employed to update the parameterization of an ansatz. It is well recognized that quantum algorithms will, for the foreseeable future, necessarily be run on noisy devices with limited fidelities. Thus, the evaluation of an objective function (e.g., the guiding function in the quantum approximate optimization algorithm (QAOA) or the expectation of the electronic Hamiltonian in variational quantum eigensolver (VQE)) required by a classical optimizer is subject not only to stochastic error from estimating an expected value but also to error resulting from intermittent hardware noise. Model-based derivative-free optimization methods have emerged as popular choices of a classical optimizer in the noisy VQA setting, based on empirical studies. However, these optimization methods were not explicitly designed with the consideration of noise. In this work we adapt recent developments from the ``noise-aware numerical optimization'' literature to these commonly used derivative-free model-based methods. We introduce the key defining characteristics of these novel noise-aware derivative-free model-based methods that separate them from standard model-based methods. We study an implementation of such noise-aware derivative-free model-based methods and compare its performance on demonstrative VQA simulations to classical solvers packaged in \texttt{scikit-quant}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10121v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeffrey Larson, Matt Menickelly, Jiahao Shi</dc:creator>
    </item>
  </channel>
</rss>
