<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Feb 2026 02:34:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A hybridizable discontinuous Galerkin method for the Ostrovsky equation</title>
      <link>https://arxiv.org/abs/2602.13786</link>
      <description>arXiv:2602.13786v1 Announce Type: new 
Abstract: This paper develops the hybridizable discontinuous Galerkin (HDG) method for the Ostrovsky equation, a nonlinear dispersive wave equation featuring both third-order dispersion and a nonlocal antiderivative term with Coriolis effect. On a bounded interval, the nonlocal operator $\partial_x^{-1}$ is localized through an auxiliary variable $v$ satisfying $v_x=u$ together with an additional boundary constraint that ensures uniqueness. We employ a mixed first-order formulation to decompose the dispersive operator and to localize the nonlocal term, and we couple the resulting semi-discrete HDG scheme with a $\theta$-time stepping method for $\theta \in [1/2,1]$. We prove $L^2$-stability for suitable stabilization parameters and derive an {\it a priori} $L^2(\Omega)$ error estimate for smooth solutions that explicitly accounts for the nonlinear convective flux.
  Numerical examples illustrate the convergence properties and demonstrate the scheme's capability to handle smooth and non-smooth solutions, including solitary wave propagation and peaked solitary wave (peakon) propagation in the zero dispersive limit regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13786v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Mukul Dwivedi, Andreas Rupp</dc:creator>
    </item>
    <item>
      <title>A Monolithic hp Space-Time Multigrid Preconditioned Newton-Krylov Solver for Space-Time FEM applied to the Incompressible Navier-Stokes Equations</title>
      <link>https://arxiv.org/abs/2602.13841</link>
      <description>arXiv:2602.13841v1 Announce Type: new 
Abstract: We present a monolithic hp space-time multigrid method (hp-STMG) for tensor-product space-time finite element discretizations of the incompressible Navier-Stokes equations. We employ mapped inf-sup stable pairs $\mathbb Q_{r+1}/\mathbb P_{r}^{\mathrm{disc}}$ in space and a slabwise discontinuous Galerkin DG($k$) discretization in time. The resulting fully coupled nonlinear systems are solved by Newton-GMRES preconditioned with hp-STMG, combining geometric coarsening in space with polynomial coarsening in space and time. Our main contribution is an hp-robust and practically efficient extension of space-time multigrid to Navier-Stokes: matrix-free operator evaluation is retained via column-wise, state-dependent spatial kernels; the nonlinear convective term is handled by a reduced, order-preserving time quadrature. Robustness is ensured by an inexact space-time Vanka smoother based on patch models with single time point evaluation. The method is implemented in the matrix-free multigrid framework of deal.II and demonstrates h- and p-robust convergence with robust solver performance across a range of Reynolds numbers, as well as high throughput in large-scale MPI-parallel experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13841v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nils Margenberg, Markus Bause</dc:creator>
    </item>
    <item>
      <title>Anisotropic hp space-time adaptivity and goal-oriented error control for convection-dominated problems</title>
      <link>https://arxiv.org/abs/2602.13843</link>
      <description>arXiv:2602.13843v1 Announce Type: new 
Abstract: We present an anisotropic goal-oriented error estimator based on the Dual Weighted Residual (DWR) method for time-dependent convection-dominated problems. Using elementwise p-anisotropic finite element spaces, the estimator is elementwise separated with respect to the single directions in space and time. This naturally leads to adaptive, anisotropic hp-refinement (h-anisotropic refinement and elementwise anisotropic p-enrichment). We employ discontinuous elements in space and time, which are well suited for problems with high Peclet numbers. Efficiency and robustness of the underlying algorithm are demonstrated for different goal functionals. The directional error indicators quantify anisotropy of the solution with respect to the goal, and produce hp-refinements that efficiently capture sharp layers. Numerical examples in up to three spatial dimensions demonstrate the superior performance of the proposed method compared to isotropic h and hp adaptive refinement using established benchmarks for convection-dominated transport.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13843v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nils Margenberg, Marius Paul Bruchh\"auser, Bernhard Endtmayer</dc:creator>
    </item>
    <item>
      <title>A Higher Order Discretization for the Stochastic Navier--Stokes equations with additive Noise</title>
      <link>https://arxiv.org/abs/2602.14268</link>
      <description>arXiv:2602.14268v1 Announce Type: new 
Abstract: We propose a new higher-order time discretization scheme for the stochastic Navier--Stokes equations with additive noise, where its velocity and pressure approximates converge at strong rate $1.5$ in probability. The construction rests on its reformulation as a random PDE for the transform $y = u- \Phi W$, and different higher order numerical quadrature rules for the diffusion and the drift part. The theoretical findings are supported by numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14268v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L. Banas, D. Breit, A. Chaudhary, A. Prohl</dc:creator>
    </item>
    <item>
      <title>Nonconforming virtual element methods for fourth-order nonlinear reaction-diffusion systems: a unified framework and analysis</title>
      <link>https://arxiv.org/abs/2602.14309</link>
      <description>arXiv:2602.14309v1 Announce Type: new 
Abstract: We develop a unified framework for the design and analysis of high-order nonconforming virtual element methods for nonlinear fourth-order reaction--diffusion problems in two dimensions, with emphasis on clamped, Navier, and Cahn--Hilliard-type boundary conditions. Time discretization is performed using the backward Euler scheme, while the spatial approximation relies on nonconforming virtual element spaces of arbitrary order $k \ge 2$, encompassing both $C^0$-nonconforming and Morley-type methods. A key contribution of this work is the development of a novel and rigorous unified error analysis for these numerical schemes, applicable to domains that are not necessarily convex, differing from the existing literature. By introducing a class of Companion operators, we construct novel Ritz-type projections and derive a new error equation that enables us to obtain optimal error estimates for the scheme under a minimal spatial regularity assumption on the weak solution. Finally, we present numerical experiments on polygonal meshes as applications of the proposed framework, including the extended Fisher--Kolmogorov equation, and a fourth-order model with Cahn--Hilliard-type boundary conditions, which validate the theoretical results and illustrate the performance of the method for the three classes of boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14309v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dibyendu Adak, David Mora, Alberth Silgado</dc:creator>
    </item>
    <item>
      <title>Mixed precision and mixed accuracy explicit two-derivative Runge--Kutta methods</title>
      <link>https://arxiv.org/abs/2602.14369</link>
      <description>arXiv:2602.14369v1 Announce Type: new 
Abstract: Mixed precision Runge--Kutta methods have been recently developed and used for the time-evolution of partial differential equations. Two-derivative Runge--Kutta schemes may offer enhanced stability and accuracy properties compared to classical one-derivative methods, making them attractive in a wide variety of problems. However, their computational cost can be significant, motivating the use of a mixed-precision paradigm that employs different floating-point precisions for different function evaluations to balance efficiency and accuracy. To ensure that the perturbations introduced by the low precision computations do not destroy the accuracy of the solution, we need to understand how these perturbation errors propagate. We extend the numerical analysis mixed precision framework previously developed for Runge--Kutta methods to characterize the propagation of the perturbation errors arising from mixed precision computations in explicit and implicit two-derivative Runge--Kutta methods. We use this framework for analyzing the order of the perturbation errors, and for designing new methods that are less sensitive to the effect of the low precision computations. Numerical experiments on linear and nonlinear representative PDEs, demonstrate that appropriately designed mixed-precision two-derivative Runge--Kutta methods achieve the predicted accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14369v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sigal Gottlieb, Zachary J. Grant, Cesar Herrera</dc:creator>
    </item>
    <item>
      <title>Flux-Balanced Patankar-type Schemes for the Compressible Euler Equations</title>
      <link>https://arxiv.org/abs/2602.14392</link>
      <description>arXiv:2602.14392v2 Announce Type: new 
Abstract: Positivity preservation of key physical quantities in the context of fluid flows, such as density and internal energy, is an essential property of a numerical scheme as otherwise the solution lacks physical relevance and has a not well-defined equation of state. One time integration technique that is capable of preserving the positivity of quantities for every time step size is the Patankar-trick and its variants. However, in the context of the Euler equations of gas dynamics, we wonder whether the Patankar-trick should be applied to the density and total energy equations or only to one of them. In this work, we discuss one drawback of the schemes when blindly applied to every positive conserved variable and additionally point out how to overcome the issue by balancing the involved numerical fluxes correctly. To illustrate our findings, we investigate modified Patankar--Runge--Kutta (MPRK) schemes in the context of the compressible Euler equations with and without stiff source terms. We discover that it is beneficial to only apply the Patankar-trick in the density equation and to balance the remaining numerical fluxes consistently rather than applying the trick also to the energy equation. This leads also to the preservation of contact discontinuities. We perform numerical experiments to demonstrate that the accuracy of the methods is maintained while the performance of our approach is superior to the traditional application of MPRK schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14392v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Izgin, Andreas Meister, Chi-Wang Shu, Davide Torlo</dc:creator>
    </item>
    <item>
      <title>A convergent finite element method with minimal deformation rate for mean curvature flow</title>
      <link>https://arxiv.org/abs/2602.14405</link>
      <description>arXiv:2602.14405v1 Announce Type: new 
Abstract: We propose and analyze a fully discrete parametric finite element method with minimal deformation rate (MDR) for simulating the mean curvature flow of general closed surfaces in three dimensions. The method is formulated from a coupled system that enforces the mean curvature flow law for the normal velocity while introducing an artificial tangential velocity that minimizes the deformation-rate energy, thereby preserving mesh quality without requiring remeshing or reparametrization. An $L^{2}$-projected averaged normal vector is used in the scheme to facilitate a rigorous convergence analysis. Within the projected--distance framework, we establish the first complete convergence proof for a parametric finite element method that incorporates the MDR tangential motion without relying on evolution equations for the mean curvature or the normal vector, achieving optimal-order error estimates for finite elements of degree $k \ge 3$. Numerical experiments corroborate the theoretical results and demonstrate that the proposed MDR method maintains mesh quality comparable to the Barrett--Garcke--N\"urnberg method, for which convergence has not yet been established.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14405v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tiantian Huang, Buyang Li, Rong Tang</dc:creator>
    </item>
    <item>
      <title>On Two-Stage Householder Orthogonalization</title>
      <link>https://arxiv.org/abs/2602.14449</link>
      <description>arXiv:2602.14449v1 Announce Type: new 
Abstract: Two-stage orthogonalization is essential in numerical algorithms such as Krylov subspace methods. For this task we need to orthogonalize a matrix $A$ against another matrix $V$ with orthonormal columns. A common approach is to employ the block Gram--Schmidt algorithm. However, its stability largely depends on the condition number of $[V,A]$. While performing a Householder orthogonalization on $[V,A]$ is unconditionally stable, it does not utilize the knowledge that $V$ has orthonormal columns. To address these issues, we propose a two-stage Householder orthogonalization algorithm based on the generalized Householder transformation. Instead of explicitly orthogonalizing the entire $V$, our algorithm only needs to orthogonalizes a square submatrix of $V$. Theoretical analysis and numerical experiments demonstrate that our method is also unconditionally stable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14449v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuang-Ao He, Meiyue Shao</dc:creator>
    </item>
    <item>
      <title>Adaptive Finite Elements with Algebraic Stabilization for Convection-Dominated Transport</title>
      <link>https://arxiv.org/abs/2602.14504</link>
      <description>arXiv:2602.14504v1 Announce Type: new 
Abstract: We present a numerical investigation of residual-based a posteriori error estimation for finite element discretizations of convection--diffusion equations stabilized by algebraic flux correction and related algebraic stabilization techniques. In particular, we consider AFC schemes employing the BJK and Monolithic Convex (MC) limiters and algebraically stabilized methods including MUAS, SMUAS, and the BBK approach. The performance of the estimators and limiters are studied on adaptively refined meshes for several two-dimensional test problems, including boundary layers, interior layers, and a nonlinear convection problem with solution-dependent transport.
  The experiments assess accuracy, preservation of the discrete maximum principle, adaptive mesh behaviour, and computational efficiency. The results show that the interaction between stabilization and a posteriori error estimation depends strongly on mesh alignment and on the character of the convection field. In particular, for problems with moving or curved layers, the behaviour of the limiters differs significantly: strongly upwind-biased limiters provide the most accurate solutions, while smoother algebraic stabilizations lead to more efficient nonlinear iterations. The study also indicates that residual-based estimators remain reliable for both linear and nonlinear problems but may react to changes in limiter activation during adaptive refinement.
  Overall, the numerical results clarify the practical behaviour of several widely used stabilization techniques within an adaptive framework and highlight aspects that are not yet fully explained by the current theory, particularly for nonlinear transport problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14504v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naveed Ahmed, Abhinav Jha</dc:creator>
    </item>
    <item>
      <title>New a posteriori error estimates for full-space transmission problems</title>
      <link>https://arxiv.org/abs/2602.14588</link>
      <description>arXiv:2602.14588v1 Announce Type: new 
Abstract: In the present work, we derive functional upper bounds for the potential error arising from finite-element boundary-element coupling formulations for a nonlinear Poisson-type transmission problem. The proposed a posteriori error estimates are independent of the precise discretization scheme and provide guaranteed upper bounds for the potential error. The computation of these upper bounds is based on the solutions of local auxiliary finite element problems on patches in the interior domain and in a strip domain along the coupling boundary. Numerical experiments illustrate the performance of the proposed error estimation strategy for a related adaptive mesh-refinement strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14588v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Freiszlinger, Dirk Pauly, Dirk Praetorius, Michael Schomburg</dc:creator>
    </item>
    <item>
      <title>Advances on the recovery of (perturbed) Cauchy matrices</title>
      <link>https://arxiv.org/abs/2602.14609</link>
      <description>arXiv:2602.14609v1 Announce Type: new 
Abstract: Given a (possibly approximate) Cauchy matrix, how can we efficiently compute its generators? Expanding on previous work by Liesen and Luce [Linear Algebra Appl. 493 (2016) 261--280], we present a general family of algorithms for Cauchy parameter recovery, together with new error estimates. We also introduce a displacement-based approximation, which leads to a new algorithm for Cauchy parameter recovery. Numerical experiments show that the algorithm based on the displacement approximation is generally more accurate than the other algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14609v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paola Boito, Dario Fasino, Beatrice Meini</dc:creator>
    </item>
    <item>
      <title>Solving Inverse Parametrized Problems via Finite Elements and Extreme Learning Networks</title>
      <link>https://arxiv.org/abs/2602.14757</link>
      <description>arXiv:2602.14757v1 Announce Type: new 
Abstract: We develop an interpolation-based reduced-order modeling framework for parameter-dependent partial differential equations arising in control, inverse problems, and uncertainty quantification. The solution is discretized in the physical domain using finite element methods, while the dependence on a finite-dimensional parameter is approximated separately. We establish existence, uniqueness, and regularity of the parametric solution and derive rigorous error estimates that explicitly quantify the interplay between spatial discretization and parameter approximation.
  In low-dimensional parameter spaces, classical interpolation schemes yield algebraic convergence rates based on Sobolev regularity in the parameter variable. In higher-dimensional parameter spaces, we replace classical interpolation by extreme learning machine (ELM) surrogates and obtain error bounds under explicit approximation and stability assumptions. The proposed framework is applied to inverse problems in quantitative photoacoustic tomography, where we derive potential and parameter reconstruction error estimates and demonstrate substantial computational savings compared to standard approaches, without sacrificing accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14757v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Burman, Mats G. Larson, Karl Larsson, Jonatan Vallin</dc:creator>
    </item>
    <item>
      <title>New Randomized Global Generalized Minimum Residual (RGl-GMRES) method</title>
      <link>https://arxiv.org/abs/2602.14786</link>
      <description>arXiv:2602.14786v1 Announce Type: new 
Abstract: In this paper, we develop a new Randomized Global Generalized Minimum Residual (RGlGMRES) algorithm for efficiently computing solutions to large scale linear systems with multiple right hand sides.The proposed method builds on a recently developed randomized global Gram Schmidt process, in which sketched Frobenius inner products are employed to approximate the exact Frobenius inner products of high-dimensional matrices. We give some new convergence results of the randomized global GMRES method for multiple linear systems. In the case where the coefficient matrix A is diagonalizable, we derive new upper bounds for the randomized Frobenius norm of the residual. In this paper, we study how to introduce matrix sketching in this algorithm. It allows us to reduce the dimension of the problem in one of the main steps of the algorithm. To validate the effectiveness and practicality of this approach, we conduct several numerical experiments, which demonstrate that our RGl-GMRES method is competitive with the GlGMRES method for solving large scale problems with multiple right-hand sides.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14786v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Achraf Badahmane, Xian-Ming GU</dc:creator>
    </item>
    <item>
      <title>Domain decomposition dynamical low-rank for multi-dimensional radiative transfer equations</title>
      <link>https://arxiv.org/abs/2602.14854</link>
      <description>arXiv:2602.14854v1 Announce Type: new 
Abstract: In this paper, we propose a domain decomposition dynamical low-rank method to solve high-dimensional radiative transfer problems and similar kinetic equations. The algorithm uses a separate low-rank approximation on each spatial subdomain, which means that, for a given accuracy, we can often use a smaller overall rank compared to classic dynamical low-rank methods. In particular, we can solve problems with point sources efficiently, that for classic algorithms require almost full rank. Our algorithm only transfers boundary data between subdomains and is thus very attractive for distributed memory parallelization, where classic dynamical low-rank algorithms suffer from global data dependency. We demonstrate the efficiency of our algorithm by a number of challenging test examples that have both very optical thin and thick regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14854v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Brunner, Lukas Einkemmer, Terry Haut</dc:creator>
    </item>
    <item>
      <title>A posteriori error estimates for a modified Morley FEM</title>
      <link>https://arxiv.org/abs/2602.14912</link>
      <description>arXiv:2602.14912v1 Announce Type: new 
Abstract: Residual-based a~posteriori error estimators are derived for the modified Morley FEM, proposed by Wang, Xu, Hu [J. Comput. Math, 24(2), 2006], for the singularly perturbed biharmonic equation and the nonlinear von K\'arm\'an equations. The error estimators are proven to be reliable and efficient. Moreover, an adaptive algorithm driven by these error estimators is investigated in numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14912v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. K. Dond, D. Gallistl, S. Nayak, M. Schedensack</dc:creator>
    </item>
    <item>
      <title>Approximation classes for the anisotropic space-time finite element method. An almost characterization</title>
      <link>https://arxiv.org/abs/2602.14921</link>
      <description>arXiv:2602.14921v1 Announce Type: new 
Abstract: We study the approximation of $L_p$-functions, $p\in (0,\infty]$, on cylindrical space-time domains $\Omega_T:=[0,T]\times \Omega$, $0&lt;T&lt;\infty$, $\Omega\subset \R^d$ Lipschitz, $d\in \mathbb{N}$, with respect to continuous anisotropic space-time finite elements on prismatic meshes. In particular, we propose a suitable refinement technique which creates (locally refined) prismatic meshes with sufficient smoothness and the desired anisotropy, and prove complexity estimates. Furthermore, we define a (quasi-)interpolation operator on this type of meshes and use it to characterize the corresponding approximation classes by showing direct and inverse estimates in terms of anisotropic Besov norms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14921v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Morin, Cornelia Schneider, Nick Schneider</dc:creator>
    </item>
    <item>
      <title>The proximal Galerkin method for non-symmetric variational inequalities</title>
      <link>https://arxiv.org/abs/2602.14967</link>
      <description>arXiv:2602.14967v1 Announce Type: new 
Abstract: We introduce the proximal Galerkin (PG) method for non-symmetric variational inequalities. The proposed approach is asymptotically mesh-independent and yields constraint-preserving approximations. We present both a conforming PG formulation and a hybrid mixed first-order system variant (FOSPG). We establish optimal a priori error estimates for each variant, which are verified numerically. We conclude by applying the method to American option pricing, free boundary problems in porous media, advection-diffusion with a semipermeable boundary, and the enforcement of discrete maximum principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14967v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guosheng Fu, Brendan Keith, Dohyun Kim, Rami Masri, Will Pazner</dc:creator>
    </item>
    <item>
      <title>Non-uniqueness of smooth solutions of the Navier-Stokes equations from almost the same initial conditions</title>
      <link>https://arxiv.org/abs/2602.12666</link>
      <description>arXiv:2602.12666v1 Announce Type: cross 
Abstract: Using clean numerical simulation (CNS) which can give very accurate spatiotemporal trajectory of Navier-Stokes turbulence in a finite but long enough interval of time, we give some numerical evidences that the Navier-Stokes equations admit distinct global solutions from almost the same initial conditions whose difference is very small, i.e. even at the order $10^{-40}$ of magnitude. Hopefully these examples could provide some enlightenments for the uniqueness and existence of Navier-Stokes equations, which are related to one Millennium Prize Problem of Clay Institute.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12666v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>nlin.CD</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shijun Liao, Shijie Qin</dc:creator>
    </item>
    <item>
      <title>Why is Normalization Preferred? A Worst-Case Complexity Theory for Stochastically Preconditioned SGD under Heavy-Tailed Noise</title>
      <link>https://arxiv.org/abs/2602.13413</link>
      <description>arXiv:2602.13413v1 Announce Type: cross 
Abstract: We develop a worst-case complexity theory for stochastically preconditioned stochastic gradient descent (SPSGD) and its accelerated variants under heavy-tailed noise, a setting that encompasses widely used adaptive methods such as Adam, RMSProp, and Shampoo. We assume the stochastic gradient noise has a finite $p$-th moment for some $p \in (1,2]$, and measure convergence after $T$ iterations. While clipping and normalization are parallel tools for stabilizing training of SGD under heavy-tailed noise, there is a fundamental separation in their worst-case properties in stochastically preconditioned settings. We demonstrate that normalization guarantees convergence to a first-order stationary point at rate $\mathcal{O}(T^{-\frac{p-1}{3p-2}})$ when problem parameters are known, and $\mathcal{O}(T^{-\frac{p-1}{2p}})$ when problem parameters are unknown, matching the optimal rates for normalized SGD, respectively. In contrast, we prove that clipping may fail to converge in the worst case due to the statistical dependence between the stochastic preconditioner and the gradient estimates. To enable the analysis, we develop a novel vector-valued Burkholder-type inequality that may be of independent interest. These results provide a theoretical explanation for the empirical preference for normalization over clipping in large-scale model training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13413v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen Fang, James Demmel, Javad Lavaei</dc:creator>
    </item>
    <item>
      <title>Non-Uniform Quantum Fourier Transform</title>
      <link>https://arxiv.org/abs/2602.13472</link>
      <description>arXiv:2602.13472v1 Announce Type: cross 
Abstract: The Discrete Fourier Transform (DFT) is central to the analysis of uniformly sampled signals, yet many practical applications involve non-uniform sampling, requiring the Non-Uniform Discrete Fourier Transform (NUDFT). While quantum algorithms for the standard DFT are well established, a corresponding framework for the non-uniform case remains underdeveloped. This work introduces a quantum algorithm for the Non-Uniform Quantum Fourier Transform (NUQFT) based on a low-rank factorization of the NUDFT matrix. The factorization is translated into an explicit quantum construction using block encodings, Quantum Signal Processing, and the Linear Combination of Unitaries framework, yielding an $\epsilon$-accurate block encoding of the NUDFT matrix with controlled approximation error from both classical truncation and quantum implementation. Under standard oracle access assumptions for non-uniform sampling points, we derive explicit, non-asymptotic gate-level resource estimates. The resulting complexity scales polylogarithmically with target precision, quadratically with the number of qubits through the quantum Fourier transform, and logarithmically with a geometry-dependent conditioning parameter induced by the non-uniform grid. This establishes a concrete and resource-efficient quantum analogue of the NUDFT and provides a foundation for quantum algorithms on irregularly sampled data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13472v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junaid Aftab, Yuehaw Khoo, Haizhao Yang</dc:creator>
    </item>
    <item>
      <title>Learning Gradient Flow: Using Equation Discovery to Accelerate Engineering Optimization</title>
      <link>https://arxiv.org/abs/2602.13513</link>
      <description>arXiv:2602.13513v1 Announce Type: cross 
Abstract: In this work, we investigate the use of data-driven equation discovery for dynamical systems to model and forecast continuous-time dynamics of unconstrained optimization problems. To avoid expensive evaluations of the objective function and its gradient, we leverage trajectory data on the optimization variables to learn the continuous-time dynamics associated with gradient descent, Newton's method, and ADAM optimization. The discovered gradient flows are then solved as a surrogate for the original optimization problem. To this end, we introduce the Learned Gradient Flow (LGF) optimizer, which is equipped to build surrogate models of variable polynomial order in full- or reduced-dimensional spaces at user-defined intervals in the optimization process. We demonstrate the efficacy of this approach on several standard problems from engineering mechanics and scientific machine learning, including two inverse problems, structural topology optimization, and two forward solves with different discretizations. Our results suggest that the learned gradient flows can significantly expedite convergence by capturing critical features of the optimization trajectory while avoiding expensive evaluations of the objective and its gradient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13513v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Grant Norman, Conor Rowan, Kurt Maute, Alireza Doostan</dc:creator>
    </item>
    <item>
      <title>An Improved Milstein Method for the Numerical Solution of Multidimensional Stochastic Differential Equations</title>
      <link>https://arxiv.org/abs/2602.13565</link>
      <description>arXiv:2602.13565v1 Announce Type: cross 
Abstract: Stochastic differential equations (SDEs) offer powerful and accessible mathematical models for capturing both deterministic and probabilistic aspects of dynamic behavior across a wide range of physical, financial, and social systems. However, analytical solutions for many SDEs are often unavailable, necessitating the use of numerical approximation methods. The rate of convergence of such numerical methods is of great importance, as it directly influences both computational efficiency and accuracy. This paper presents a proposed theorem, along with its proof, that facilitates the numerical evaluation of the strong (and weak) order of convergence of a numerical scheme for an SDE when the analytical solution is unavailable. Additionally, we address the challenge of numerically computing the multiple stochastic integrals required by the Milstein method to achieve improved convergence rates for multidimensional SDEs. In this context, two newly proposed numerical techniques for computing these multiple stochastic integrals are introduced and compared with existing approaches in terms of efficiency and effectiveness. The methodologies are further illustrated through simulation studies and applications to widely used financial models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13565v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Paromita Banerjee, Anirban Mondal</dc:creator>
    </item>
    <item>
      <title>An adaptive framework for first-order gradient methods</title>
      <link>https://arxiv.org/abs/2602.13620</link>
      <description>arXiv:2602.13620v1 Announce Type: cross 
Abstract: Gradient methods are widely used in optimization problems. In practice, while the smoothness parameter can be estimated utilizing techniques such as backtracking, estimating the strong convexity parameter remains a challenge; moreover, even with the optimal parameter choice, convergence can be slow. In this work, we propose a framework for dynamically adapting the step size and momentum parameters in first-order gradient methods for the optimization problem, without prior knowledge of the strong convexity parameter. The main idea is to use the geometric average of the ratios of successive residual norms as an empirical estimate of the upper bound on the convergence rate, which in turn allows us to adaptively update the algorithm parameters. The resulting algorithms are simple to implement, yet efficient in practice, requiring only a few additional computations on existing information. The proposed adaptive gradient methods are shown to converge at least as fast as gradient descent for quadratic optimization problems. Numerical experiments on both quadratic and nonlinear problems validate the effectiveness of the proposed adaptive algorithms. The results show that the adaptive algorithms are comparable to their counterparts using optimal parameters, and in some cases, they capture local information and exhibit improved performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13620v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaozhe Hu, Sara Pollock, Zhongqin Xue, Yunrong Zhu</dc:creator>
    </item>
    <item>
      <title>Discrete Double-Bracket Flows for Isotropic-Noise Invariant Eigendecomposition</title>
      <link>https://arxiv.org/abs/2602.13759</link>
      <description>arXiv:2602.13759v1 Announce Type: cross 
Abstract: We study matrix-free eigendecomposition under a matrix-vector product (MVP) oracle, where each step observes a covariance operator $C_k = C_{sig} + \sigma_k^2 I + E_k$. Standard stochastic approximation methods either use fixed steps that couple stability to $\|C_k\|_2$, or adapt steps in ways that slow down due to vanishing updates. We introduce a discrete double-bracket flow whose generator is invariant to isotropic shifts, yielding pathwise invariance to $\sigma_k^2 I$ at the discrete-time level. The resulting trajectory and a maximal stable step size $\eta_{max} \propto 1/\|C_e\|_2^2$ depend only on the trace-free covariance $C_e$. We establish global convergence via strict-saddle geometry for the diagonalization objective and an input-to-state stability analysis, with sample complexity scaling as $O(\|C_e\|_2^2 / (\Delta^2 \epsilon))$ under trace-free perturbations. An explicit characterization of degenerate blocks yields an accelerated $O(\log(1/\zeta))$ saddle-escape rate and a high-probability finite-time convergence guarantee.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13759v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>ZhiMing Li, JiaHe Feng</dc:creator>
    </item>
    <item>
      <title>Mean-Square Convergence of a New Parameterized Leapfrog Scheme for Hamiltonian Systems Driven by Gaussian Process Potentials</title>
      <link>https://arxiv.org/abs/2602.14053</link>
      <description>arXiv:2602.14053v1 Announce Type: cross 
Abstract: This paper establishes the mean-square convergence of a new stochastic, parameterized leapfrog scheme introduced in our companion paper Mazumder et al. (2026) for Hamiltonian systems with Gaussian process potentials. We consider a one-step numerical integrator and provide a complete, rigorous analysis under minimal regularity assumptions on the Gaussian potential. The key technical contribution is identifying and exploiting the symplectic structure ingrained in our stochastic, parameterized leapfrog method. Combined with local truncation error analysis, this leads to a global error bound of O({\delta}t) in mean-square sense. Our results establish that although the spatio-temporal model of Mazumder et al. (2026) arises as the anticipated new stochastic leapfrog solution of a system of modified (parameterized) stochastic Hamiltonian equations, the new stochastic leapfrog actually solves the traditional stochastic Hamiltonian equations, driven by Gaussian process potential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14053v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sourabh Bhattacharya</dc:creator>
    </item>
    <item>
      <title>MPL-HMC: A Tunable Parameterized Leapfrog Framework for Robust Hamiltonian Monte Carlo</title>
      <link>https://arxiv.org/abs/2602.14061</link>
      <description>arXiv:2602.14061v1 Announce Type: cross 
Abstract: This article introduces the Modified Parameterized Leapfrog Hamiltonian Monte Carlo (MPL-HMC) method, a novel extension of HMC addressing key limitations through tunable integration parameters $\alpha(\delta t)$ and $\beta(\delta t)$, enabling controlled perturbations to Hamiltonian dynamics. Theoretical analysis demonstrates MPL-HMC maintains approximate detailed balance. Extensive empirical evaluation reveals systematic performance improvements. The damping variant ($\alpha_2=-0.1$, $\beta_2=-0.05$) achieves a 14-fold increase in effective sample size for Neal's funnel and 27\% better efficiency for pharmacokinetic models. The anti-damping variant ($\alpha_2=0.1$, $\beta_2=0.05$) achieves $\hat{R}=1.026$ for Bayesian neural networks versus $\hat{R}=1.981$ for standard HMC. We introduce aggressive MPL-HMC for multimodal distributions, employing extreme parameters ($\alpha_2=8.0$--$15.0$, $\beta_2=5.0$--$8.0$) with enhanced sampling to achieve full mode exploration where standard methods fail. All variants maintain computational efficiency identical to standard HMC while providing systematic control over damping, exploration, stability, and accuracy. The article provides rigorous mathematical foundations, implementation specifications, parameter tuning strategies, and comprehensive performance comparisons, extending HMC's applicability to previously challenging domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14061v1</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sourabh Bhattacharya</dc:creator>
    </item>
    <item>
      <title>Parallel Sparse and Data-Sparse Factorization-based Linear Solvers</title>
      <link>https://arxiv.org/abs/2602.14289</link>
      <description>arXiv:2602.14289v1 Announce Type: cross 
Abstract: Efficient solutions of large-scale, ill-conditioned and indefinite algebraic equations are ubiquitously needed in numerous computational fields, including multiphysics simulations, machine learning, and data science. Because of their robustness and accuracy, direct solvers are crucial components in building a scalable solver toolchain. In this article, we will review recent advances of sparse direct solvers along two axes: 1) reducing communication and latency costs in both task- and data-parallel settings, and 2) reducing computational complexity via low-rank and other compression techniques such as hierarchical matrix algebra. In addition to algorithmic principles, we also illustrate the key parallelization challenges and best practices to deliver high speed and reliability on modern heterogeneous parallel machines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14289v1</guid>
      <category>cs.MS</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoye Sherry Li, Yang Liu</dc:creator>
    </item>
    <item>
      <title>Complex Wavelet-Based Sinogram Segmentation for Metal Artifact Reduction in Cone-Beam CT</title>
      <link>https://arxiv.org/abs/2602.14315</link>
      <description>arXiv:2602.14315v1 Announce Type: cross 
Abstract: Metal objects pose a significant challenge in cone-beam computed tomography, as their strong and energy-dependent X-ray attenuation leads to inconsistent projections and severe streaking and shading artifacts in reconstructed images. These artifacts degrade image quality and limit the reliability of subsequent medical analysis. We propose a projection-domain metal artifact reduction method based on analytical metal segmentation in the three-dimensional sinogram using the three-dimensional Dual-Tree Complex Wavelet Transform, where directional wavelet coefficients are exploited to extract the wavefront set and singular support of metal structures. The resulting segmentation enables projection-domain inpainting and artifact-reduced reconstruction by combining metal-free and metal-only reconstructions. The proposed approach is evaluated on both simulated and clinical cone-beam computed tomography data and consistently reduces metal artifacts compared to conventional image-domain hard-thresholding methods. The results demonstrate improved visual quality and robustness in clinically realistic scenarios, highlighting the potential of analytically grounded, non-learned projection-domain segmentation for metal artifact reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14315v1</guid>
      <category>physics.med-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siiri Rautio, Alexander Meaney, Salla-Maaria Latva-\"Aij\"o, Harshit Agrawal, Mikael Brix, Dinidu Jayakody, Samuli Siltanen</dc:creator>
    </item>
    <item>
      <title>Mixed precision solvers with half-precision floating point numbers for Lattice QCD on A64FX processor</title>
      <link>https://arxiv.org/abs/2602.14450</link>
      <description>arXiv:2602.14450v1 Announce Type: cross 
Abstract: We investigate the use of half-precision floating-point numbers (FP16) in mixed-precision linear solvers for lattice QCD simulations. Since the emergence of GPUs for general-purpose, mixed-precision algorithms that combine single-precision (FP32) with double-precision (FP64) arithmetics have become widely used in this field and others. While FP32-based methods are now well established, we examine the practicality of using FP16. In this work, we introduce rescaling steps in both the outer iterative refinement step and the inner BiCGStab solver to avoid numerical instability. In our experiments with a simple Wilson kernel, the solver shows improved stability, and the additional iteration count compared to the FP64 version remains within 20\%, indicating that the FP16 version is practical for use. We believe that the proposed rescaling methods can also benefit other mixed precision preconditioners in avoiding underflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14450v1</guid>
      <category>hep-lat</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3784828.3785398</arxiv:DOI>
      <dc:creator>Issaku Kanamori, Hideo Matsufuru, Tatsumi Aoyama, Kazuyuki Kanaya, Yusuke Namekawa, Hidekatsu Nemura, Keigo Nitadori</dc:creator>
    </item>
    <item>
      <title>Conditional Expectation expression in mean-field SDEs and its applications</title>
      <link>https://arxiv.org/abs/2602.14479</link>
      <description>arXiv:2602.14479v1 Announce Type: cross 
Abstract: This study developed a novel formulation of conditional expectations within the framework of a jump-diffusion mean-field stochastic differential equation. We introduce an integrated approach that combines unconditioned expectations with rigorously defined weighting factors, employing Malliavin calculus on Poisson space and directional derivatives to enhance estimation accuracy. \noindent The proposed method is applied to the numerical pricing of American put options in a jump-diffusion mean-field setting, addressing the challenges proposed by early-exercise features. Comprehensive numerical experiments demonstrate substantial improvements in pricing accuracy compared with conventional techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14479v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samaneh Sojudi, Mahdieh Tahmasebi</dc:creator>
    </item>
    <item>
      <title>A Bayesian Approach to Low-Discrepancy Subset Selection</title>
      <link>https://arxiv.org/abs/2602.14607</link>
      <description>arXiv:2602.14607v1 Announce Type: cross 
Abstract: Low-discrepancy designs play a central role in quasi-Monte Carlo methods and are increasingly influential in other domains such as machine learning, robotics and computer graphics, to name a few. In recent years, one such low-discrepancy construction method called subset selection has received a lot of attention. Given a large population, one optimally selects a small low-discrepancy subset with respect to a discrepancy-based objective. Versions of this problem are known to be NP-hard. In this text, we establish, for the first time, that the subset selection problem with respect to kernel discrepancies is also NP-hard. Motivated by this intractability, we propose a Bayesian Optimization procedure for the subset selection problem utilizing the recent notion of deep embedding kernels. We demonstrate the performance of the BO algorithm to minimize discrepancy measures and note that the framework is broadly applicable any design criteria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14607v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan Kirk</dc:creator>
    </item>
    <item>
      <title>Pseudo-differential-enhanced physics-informed neural networks</title>
      <link>https://arxiv.org/abs/2602.14663</link>
      <description>arXiv:2602.14663v1 Announce Type: cross 
Abstract: We present pseudo-differential enhanced physics-informed neural networks (PINNs), an extension of gradient enhancement but in Fourier space. Gradient enhancement of PINNs dictates that the PDE residual is taken to a higher differential order than prescribed by the PDE, added to the objective as an augmented term in order to improve training and overall learning fidelity. We propose the same procedure after application via Fourier transforms, since differentiating in Fourier space is multiplication with the Fourier wavenumber under suitable decay. Our methods are fast and efficient. Our methods oftentimes achieve superior PINN versus numerical error in fewer training iterations, potentially pair well with few samples in collocation, and can on occasion break plateaus in low collocation settings. Moreover, our methods are suitable for fractional derivatives. We establish that our methods improve spectral eigenvalue decay of the neural tangent kernel (NTK), and so our methods contribute towards the learning of high frequencies in early training, mitigating the effects of frequency bias up to the polynomial order and possibly greater with smooth activations. Our methods accommodate advanced techniques in PINNs, such as Fourier feature embeddings. A pitfall of discrete Fourier transforms via the Fast Fourier Transform (FFT) is mesh subjugation, and so we demonstrate compatibility of our methods for greater mesh flexibility and invariance on alternative Euclidean and non-Euclidean domains via Monte Carlo methods and otherwise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14663v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Gracyk</dc:creator>
    </item>
    <item>
      <title>Joint Majorization-Minimization for Nonnegative CP and Tucker Decompositions under $\beta$-Divergences: Unfolding-Free Updates</title>
      <link>https://arxiv.org/abs/2602.14683</link>
      <description>arXiv:2602.14683v1 Announce Type: cross 
Abstract: We study majorization-minimization methods for nonnegative tensor decompositions under the $\beta$-divergence family, focusing on nonnegative CP and Tucker models. Our aim is to avoid explicit mode unfoldings and large auxiliary matrices by deriving separable surrogates whose multiplicative updates can be implemented using only tensor contractions (einsum-style operations). We present both classical block-MM updates in contraction-only form and a joint majorization strategy, inspired by joint MM for matrix $\beta$-NMF, that reuses cached reference quantities across inexpensive inner updates. We prove tightness of the proposed majorizers, establish monotonic decrease of the objective, and show convergence of the sequence of objective values; we also discuss how BSUM theory applies to the block-MM scheme for analyzing limit points. Finally, experiments on synthetic tensors and the Uber spatiotemporal count tensor demonstrate substantial speedups over unfolding-based baselines and a recent einsum-factorization framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14683v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valentin Leplat</dc:creator>
    </item>
    <item>
      <title>BEACONS: Bounded-Error, Algebraically-Composable Neural Solvers for Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2602.14853</link>
      <description>arXiv:2602.14853v1 Announce Type: cross 
Abstract: The traditional limitations of neural networks in reliably generalizing beyond the convex hulls of their training data present a significant problem for computational physics, in which one often wishes to solve PDEs in regimes far beyond anything which can be experimentally or analytically validated. In this paper, we show how it is possible to circumvent these limitations by constructing formally-verified neural network solvers for PDEs, with rigorous convergence, stability, and conservation properties, whose correctness can therefore be guaranteed even in extrapolatory regimes. By using the method of characteristics to predict the analytical properties of PDE solutions a priori (even in regions arbitrarily far from the training domain), we show how it is possible to construct rigorous extrapolatory bounds on the worst-case L^inf errors of shallow neural network approximations. Then, by decomposing PDE solutions into compositions of simpler functions, we show how it is possible to compose these shallow neural networks together to form deep architectures, based on ideas from compositional deep learning, in which the large L^inf errors in the approximations have been suppressed. The resulting framework, called BEACONS (Bounded-Error, Algebraically-COmposable Neural Solvers), comprises both an automatic code-generator for the neural solvers themselves, as well as a bespoke automated theorem-proving system for producing machine-checkable certificates of correctness. We apply the framework to a variety of linear and non-linear PDEs, including the linear advection and inviscid Burgers' equations, as well as the full compressible Euler equations, in both 1D and 2D, and illustrate how BEACONS architectures are able to extrapolate solutions far beyond the training data in a reliable and bounded way. Various advantages of the approach over the classical PINN approach are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14853v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Gorard, Ammar Hakim, James Juno</dc:creator>
    </item>
    <item>
      <title>A stochastic perturbation approach to nonlinear bifurcating problems</title>
      <link>https://arxiv.org/abs/2402.16803</link>
      <description>arXiv:2402.16803v4 Announce Type: replace 
Abstract: Incorporating probabilistic terms in mathematical models is crucial for capturing and quantifying uncertainties in real-world systems, especially when the solution is not unique or exhibits sudden qualitative changes as parameters vary. However, stochastic models typically require large computational resources to produce meaningful statistics. In this work, we leverage the Polynomial Chaos (PC) expansion to propose a systematic approach for bifurcation detection in parametric systems of equations. We show that the method, exploiting a perturbed version of the deterministic model, avoids repeated costly simulations across multiple parameter values and requires no prior information for initializing numerical solvers, while still providing accurate characterization of the bifurcation branches. We argue that the PC solutions of the perturbed model not only provide access to statistical information about the deterministic branches, but also approximate these branches in a meaningful sense. Finally, we validate our claims by means of numerical tests on the pitchfork bifurcation, examining both its normal form and a classical realization in fluid-dynamics PDEs, namely the Coanda effect.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16803v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Isabella Carla Gonnella, Moaad Khamlich, Federico Pichi, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>New Jacobi--Davidson type methods for the large SVD computations</title>
      <link>https://arxiv.org/abs/2404.12568</link>
      <description>arXiv:2404.12568v3 Announce Type: replace 
Abstract: In a Jacobi--Davidson (JD) type method for singular value decomposition (SVD) problems, called JDSVD, a large symmetric and generally indefinite correction equation is solved iteratively at each outer iteration, which constitutes the inner iterations and dominates the overall efficiency of JDSVD. In this paper, by fully exploiting useful information from current subspaces, a new effective correction equation is derived at each outer iteration, leading to a new variant of JDSVD, called JDSVD-V. It is proved that JDSVD-V retains the same convergence of the outer iterations as JDSVD. A substantial advantage of JDSVD-V over JDSVD is that the new correction equations in JDSVD-V are much easier to iteratively solve than the standard ones in JDSVD: the MINRES method for the new correction equations converges much faster when there is a cluster of singular values closest to a given target, a typical case in applications. A new thick-restart JDSVD-V algorithm with deflation and purgation is proposed that simultaneously accelerates the outer and inner convergence of the standard thick-restart JDSVD and computes several singular triplets. Numerical experiments justify the theory and illustrate the considerable superiority of JDSVD-V to JDSVD, and demonstrate that a similar two-stage JDSVD-V algorithm substantially outperforms the most advanced PRIMME\_SVDS software nowadays for computing the smallest singular triplets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12568v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinzhi Huang, Zhongxiao Jia</dc:creator>
    </item>
    <item>
      <title>The Landau--Lifshitz--Bloch equation on polytopal domains: Unique existence and finite element approximation</title>
      <link>https://arxiv.org/abs/2406.05808</link>
      <description>arXiv:2406.05808v3 Announce Type: replace 
Abstract: The Landau--Lifshitz--Bloch equation (LLBE) describes the evolution of the magnetic spin field in ferromagnets at high temperatures. In this paper, we study the numerical approximation of the LLBE on bounded polytopal domains in $\mathbb{R}^d$, where $d\le 3$. We first establish the existence and uniqueness of strong solutions to the LLBE and propose a linear, fully discrete, conforming finite element scheme for its approximation. While this scheme is shown to converge, the obtained rate is suboptimal. To address this shortcoming, we introduce a viscous (pseudo-parabolic) regularisation of the LLBE, which we call the $\epsilon$-LLBE. For this regularised problem, we prove the unique existence of strong solutions and establish a rate of convergence of the solution $\boldsymbol{u}^\epsilon$ of the $\epsilon$-LLBE to the solution $\boldsymbol{u}$ of the LLBE as $\epsilon\to 0^+$. Furthermore, we propose a linear, fully discrete, conforming finite element scheme to approximate the solution of the $\epsilon$-LLBE. Given sufficiently smooth initial data, error analysis is performed to show stability and uniform-in-time convergence of the scheme. Finally, several numerical simulations are presented to corroborate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05808v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1093/imanum/drag002</arxiv:DOI>
      <arxiv:journal_reference>IMA J. Numerical Analysis (2026)</arxiv:journal_reference>
      <dc:creator>Kim-Ngan Le, Agus L. Soenjaya, Thanh Tran</dc:creator>
    </item>
    <item>
      <title>Annealing-based approach to solving partial differential equations</title>
      <link>https://arxiv.org/abs/2406.17364</link>
      <description>arXiv:2406.17364v5 Announce Type: replace 
Abstract: Solving partial differential equations (PDEs) using an annealing-based approach involves solving generalized eigenvalue problems. Discretizing a PDE yields a system of linear equations (SLE). Solving an SLE can be formulated as a general eigenvalue problem, which can be transformed into an optimization problem with an objective function given by a generalized Rayleigh quotient. The proposed algorithm requires iterative computations. However, it enables efficient annealing-based computation of eigenvectors to arbitrary precision without increasing the number of variables. Investigations using simulated annealing demonstrate how the number of iterations scales with system size and annealing time. Computational performance depends on system size, annealing time, and problem characteristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17364v5</guid>
      <category>math.NA</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.NA</category>
      <category>quant-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kazue Kudo</dc:creator>
    </item>
    <item>
      <title>Stability of Least Squares Approximation under Random Sampling</title>
      <link>https://arxiv.org/abs/2407.10221</link>
      <description>arXiv:2407.10221v2 Announce Type: replace 
Abstract: This paper investigates the stability of the least squares approximation $P_m^n$ within the univariate polynomial space of degree $m$, denoted by ${\mathbb P}_m$. The approximation $P_m^n$ entails identifying a polynomial in ${\mathbb P}_m$ that approximates a function $f$ over a domain $X$ based on samples of $f$ taken at $n$ randomly selected points, according to a specified probability measure $\rho_X$. The primary goal is to determine the sampling rate necessary to ensure the stability of $P_m^n$. Assuming the sampling points are i.i.d. with respect to a Jacobi weight function, we present the sampling rate that guarantee the stability of $P_m^n$. Specifically, for uniform random sampling, we demonstrate that a sampling rate of $n \asymp m^2$ is required to maintain stability. By combining these findings with those of Cohen-Davenport-Leviatan, we conclude that, for uniform random sampling, the optimal sampling rate for guaranteeing the stability of $P_m^n$ is $n \asymp m^2$, up to a $\log n$ factor. Motivated by this result, we extend the impossibility theorem, previously applicable to equally spaced samples, to the case of random samples, illustrating the balance between accuracy and stability in recovering analytic functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10221v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiqiang Xu, Xinyue Zhang</dc:creator>
    </item>
    <item>
      <title>Quasi-interpolation using generalized Gaussian kernels</title>
      <link>https://arxiv.org/abs/2407.21283</link>
      <description>arXiv:2407.21283v2 Announce Type: replace 
Abstract: This paper focuses on developing a framework for constructing quasi-interpolation with the highest achievable approximation order from generalized Gaussian kernels with the help of kernel restriction trick and periodization technique. We first demonstrate that when we restrict generalized Gaussian kernels satisfying generalized Strang-Fix conditions of order s over a torus, the corresponding restricted kernels in tensor-product forms fulfill periodic Strang-Fix conditions of the same order s. Then, based on these restricted kernels, we construct a periodic quasi-interpolant in Schoenberg's form and derive its error estimates for periodic function approximation over a torus, which reveals that our quasiinterpolant attains the highest approximation order s. Finally, using the periodization technique, we extend the periodic quasi-interpolant to its nonperiodic counterpart with the highest approximation order s for approximating a general function defined over a cube via a torus-to-cube transformation. This result stands in stark contrast to classical quasi-interpolation counterparts, which often yield much lower approximation orders than those dictated by the generalized Strang-Fix conditions of generalized Gaussian kernels. Furthermore, we propose a sparse grid counterpart for high-dimensional function approximation to alleviate the curse of dimensionality. Numerical simulations confirm that our quasi-interpolation scheme is simple and computationally efficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21283v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenwu Gao, Le Hu, Zhengjie Sun, Changwei Wang</dc:creator>
    </item>
    <item>
      <title>Re-anchoring Quantum Monte Carlo with Tensor-Train Sketching</title>
      <link>https://arxiv.org/abs/2411.07194</link>
      <description>arXiv:2411.07194v5 Announce Type: replace 
Abstract: We propose a novel algorithm for calculating the ground-state energy of quantum many-body systems by combining auxiliary-field quantum Monte Carlo (AFQMC) with tensor-train sketching. In AFQMC, a good trial wavefunction to guide the random walk is crucial for improving the sampling efficiency and controlling the sign problem. Our proposed method iterates between determining a new trial wavefunction in the form of a tensor train, derived from the current walkers, and using this updated trial wavefunction to anchor the next phase of AFQMC. Numerical results demonstrate that the algorithm is highly accurate for large spin systems. The overlap between the estimated trial wavefunction and the ground-state wavefunction also achieves high fidelity. We additionally provide a convergence analysis, highlighting how an effective trial wavefunction can reduce the variance in the AFQMC energy estimation. From a complementary perspective, our algorithm also extends the reach of tensor-train methods for studying quantum many-body systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07194v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziang Yu, Shiwei Zhang, Yuehaw Khoo</dc:creator>
    </item>
    <item>
      <title>Nonlinear reduction strategies for data compression: a comprehensive comparison from diffusion to advection problems</title>
      <link>https://arxiv.org/abs/2501.12816</link>
      <description>arXiv:2501.12816v2 Announce Type: replace 
Abstract: This work presents an overview of several nonlinear reduction strategies for data compression from various research fields, and a comparison of their performance when applied to problems characterized by diffusion and/or advection terms. We aim to create a common framework by unifying the notation referring to a common two-stage pipeline. At the same time, we underline their main differences and objectives by highlighting the diverse choices made for each stage. We test the considered approaches on three test cases belonging to the family of Advection-Diffusion problems, also focusing on the pure Advection and pure Diffusion benchmarks, studying their reducibility while varying the latent dimension. Finally, we interpret the numerical results under the lens of the discussed theoretical considerations, offering a comprehensive landscape for nonlinear reduction methods for general Advection-Diffusion dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12816v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Isabella Carla Gonnella, Federico Pichi, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>Enriching continuous Lagrange finite element approximation spaces using neural networks</title>
      <link>https://arxiv.org/abs/2502.04947</link>
      <description>arXiv:2502.04947v5 Announce Type: replace 
Abstract: In this work, we present a study combining two approaches in the context of solving PDEs: the continuous finite element method (FEM) and more recent techniques based on neural networks. In recent years, physics-informed neural networks (PINNs) have become particularly interesting for rapidly solving PDEs, especially in high dimensions. However, their lack of accuracy can be a significant drawback in this context, hence the interest in combining them with FEM, for which error estimates are already known. The complete pipeline proposed here consists in modifying the classical FEM approximation spaces by taking information from a prior, chosen as the prediction of a neural network. On the one hand, this combination improves and certifies the prediction of neural networks, to obtain a fast and accurate solution. On the other hand, error estimates are proven, showing that such strategies outperform classical ones by a factor that depends only on the quality of the prior. We validate our approach with numerical results performed on parametric problems with 1D, 2D and 3D geometries. These experiments demonstrate that to achieve a given accuracy, a coarser mesh can be used with our enriched FEM compared to the standard FEM, leading to reduced computational time, particularly for parametric problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04947v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H\'el\`ene Barucq, Michel Duprez, Florian Faucher, Emmanuel Franck, Fr\'ed\'erique Lecourtier, Vanessa Lleras, Victor Michel-Dansac, Nicolas Victorion</dc:creator>
    </item>
    <item>
      <title>Multiharmonic algorithms for contrast-enhanced ultrasound</title>
      <link>https://arxiv.org/abs/2504.13335</link>
      <description>arXiv:2504.13335v2 Announce Type: replace 
Abstract: Harmonic generation plays a crucial role in contrast-enhanced ultrasound, both for imaging and therapeutic applications. However, accurately capturing these nonlinear effects is computationally very demanding when using traditional time-domain approaches. To address this issue, in this work, we develop algorithms based on a time discretization that uses a multiharmonic Ansatz applied to a model that couples the Westervelt equation for acoustic pressure with a volume-based approximation of the Rayleigh--Plesset equation for the dynamics of microbubble contrast agents. We first rigorously establish the existence of time-periodic solutions for this Westervelt-ODE system. We then derive a multiharmonic representation of the system under time-periodic excitation and develop iterative algorithms that rely on the successive computation of higher harmonics under the assumption of real-valued or complex solution fields. In the real-valued setting, we characterize the approximation error in terms of the number of harmonics and a contribution owing to the fixed-point iteration. Finally, we investigate these algorithms numerically and illustrate how the number of harmonics and presence of microbubbles influence the propagation of acoustic waves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13335v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vanja Nikoli\'c, Teresa Rauscher</dc:creator>
    </item>
    <item>
      <title>A mixed finite element method for a class of fourth-order stochastic evolution equations with multiplicative noise</title>
      <link>https://arxiv.org/abs/2505.04866</link>
      <description>arXiv:2505.04866v3 Announce Type: replace 
Abstract: We develop a fully discrete, semi-implicit mixed finite element method for approximating solutions to a class of fourth-order stochastic partial differential equations (SPDEs) with non-globally Lipschitz and non-monotone nonlinearities, perturbed by spatially smooth multiplicative Gaussian noise. The proposed scheme is applicable to a range of physically relevant nonlinear models, including the stochastic Landau--Lifshitz--Baryakhtar (sLLBar) equation, the stochastic convective Cahn--Hilliard equation with mass source, and the stochastic regularised Landau--Lifshitz--Bloch (sLLB) equation, among others. To overcome the difficulties posed by the interplay between the nonlinearities and the stochastic forcing, we adopt a `truncate-then-discretise' strategy: the nonlinear term is first truncated before discretising the resulting modified problem. We show that the strong solution to the truncated system converges in probability to that of the original problem. A fully discrete numerical scheme is then proposed for the truncated problem. Assuming initial data in $\mathbb{H}^2$, we utilise parabolic smoothing estimates and the temporal H\"older continuity of the solution to establish both convergence in probability and strong convergence (with quantitative rates) for the two fields used in the mixed formulation. Numerical simulations are provided to support the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04866v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1051/m2an/2026018</arxiv:DOI>
      <arxiv:journal_reference>ESAIM: Mathematical Modelling and Numerical Analysis (2026)</arxiv:journal_reference>
      <dc:creator>Beniamin Goldys, Agus L. Soenjaya, Thanh Tran</dc:creator>
    </item>
    <item>
      <title>Dominant H-Eigenvectors of Tensor Kronecker Products Do Not Decouple</title>
      <link>https://arxiv.org/abs/2508.19902</link>
      <description>arXiv:2508.19902v2 Announce Type: replace 
Abstract: We illustrate a counterexample to an open question related to the dominant H-eigenvector of a Kronecker product of tensors. For matrices and Z-eigenvectors of tensors, the dominant eigenvector of a Kronecker product decouples into a product of eigenvectors of the tensors underlying the Kronecker product. This does not occur for H-eigenvectors and indeed, the largest H-eigenvalue can exceed the product of the H-eigenvalues of the component tensors. Beyond this general counterexample, we show this decoupling does hold in the case of diagonal tensors as well as nonnegative tensors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19902v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ayush Kulkarni, Charles Colley, David F. Gleich</dc:creator>
    </item>
    <item>
      <title>An element-based convex limiting framework for continuous Galerkin methods with nonlinear stabilization</title>
      <link>https://arxiv.org/abs/2509.04673</link>
      <description>arXiv:2509.04673v2 Announce Type: replace 
Abstract: We equip a high-order continuous Galerkin discretization of a general hyperbolic problem with a nonlinear stabilization term and introduce a new methodology for enforcing preservation of invariant domains. The amount of shock-capturing artificial viscosity is determined by a smoothness sensor that measures deviations from a weighted essentially nonoscillatory (WENO) reconstruction. Since this kind of dissipative stabilization does not guarantee that the nodal states of the finite element approximation stay in a convex admissible set, we adaptively constrain deviations of these states from intermediate cell averages. The representation of our scheme in terms of such cell averages makes it possible to apply convex limiting techniques originally designed for positivity-preserving discontinuous Galerkin (DG) methods. Adapting these techniques to the continuous Galerkin setting and using Bernstein polynomials as local basis functions, we prove the invariant domain preservation property under a time step restriction that can be significantly weakened by using a flux limiter for the auxiliary cell averages. The close relationship to DG-WENO schemes is exploited and discussed. All algorithmic steps can be implemented in a matrix-free and hardware-aware manner. The effectiveness of the new element-based limiting strategy is illustrated by numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04673v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitri Kuzmin, Hennes Hajduk, Joshua Vedral</dc:creator>
    </item>
    <item>
      <title>Efficient Tensor Completion Algorithms for Highly Oscillatory Operators</title>
      <link>https://arxiv.org/abs/2510.17734</link>
      <description>arXiv:2510.17734v3 Announce Type: replace 
Abstract: This paper presents low-complexity tensor completion algorithms and their efficient implementation to reconstruct highly oscillatory operators discretized as $n\times n$ matrices. The underlying tensor decomposition is based on the reshaping of the input matrix and its butterfly decomposition into an order $O (\log n)$ tensor. The reshaping of the input matrix into a tensor allows for representation of the butterfly decomposition as a tensor decomposition with dense tensors. This leads to efficient utilization of the existing software infrastructure for dense and sparse tensor computations. We propose two tensor completion algorithms in the butterfly format, using alternating least squares and gradient-based optimization, as well as a novel strategy that uses low-rank matrix completion to efficiently generate an initial guess for the proposed algorithms. To demonstrate the efficiency and applicability of our proposed algorithms, we perform three numerical experiments using simulated oscillatory operators in seismic applications. In these experiments, we use $O (n \log n)$ observed entries in the input matrix and demonstrate an $O(n\log^3 n)$ computational cost of the proposed algorithms, leading to a speedup of orders of magnitudes per iteration for large matrices compared to the low-rank matrix and quantized tensor-train completion. Moreover, the proposed butterfly completion algorithms, equipped with the novel initial guess generation strategy, achieve reconstruction errors that are smaller by an order of magnitude, enabling accurate recovery of the underlying structure compared to the state-of-the-art completion algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17734v3</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Navjot Singh, Edgar Solomonik, Xiaoye Sherry Li, Yang Liu</dc:creator>
    </item>
    <item>
      <title>Iterative Contact-resolving Hybrid Methods for Multiscale Contact Mechanics</title>
      <link>https://arxiv.org/abs/2512.04411</link>
      <description>arXiv:2512.04411v2 Announce Type: replace 
Abstract: Modeling contact mechanics with high contrast coefficients presents significant mathematical and computational challenges, especially in achieving strongly symmetric stress approximations for mixed formulations. Due to the inherent nonlinearity of contact problems, conventional methods that treat the entire domain as a monolithic system often lead to high global complexity. To address this, we develop an iterative contact-resolving hybrid method by localizing nonlinear contact constraints within a smaller subdomain, while the larger subdomain is governed by a linear system. Our system employs variational inequality theory, minimization principles, and penalty methods. More importantly, we propose four discretization types within the two-subdomain framework, ranging from applying standard/mixed FEM across the entire domain to combining standard/mixed multiscale methods in the larger subdomain with standard/mixed FEM in the smaller one. % The standard finite element method and standard constraint energy minimizing generalized multiscale finite element method are simple and easy to demonstrate. By employing a multiscale reduction technique, the method avoids excessive degrees of freedom inherent in conventional methods in the larger domain, while the mixed formulation enables direct stress computation, ensures local momentum conservation, and resists locking in nearly incompressible materials. Convergence analysis and the corresponding algorithms are provided for all cases. Extensive numerical experiments are presented to validate the effectiveness of the approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04411v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric T. Chung, Hyea Hyun Kim, Xiang Zhong</dc:creator>
    </item>
    <item>
      <title>On the Numerical Treatment of an Abstract Nonlinear System of Coupled Hyperbolic Equations Associated with the Timoshenko Model</title>
      <link>https://arxiv.org/abs/2602.02068</link>
      <description>arXiv:2602.02068v2 Announce Type: replace 
Abstract: The present work addresses the Cauchy problem for an abstract nonlinear system of coupled hyperbolic equations associated with the Timoshenko model in a real Hilbert space. Our purpose is to develop and delve into a temporal discretization scheme for approximating a solution to this problem. To this end, we propose a symmetric three-layer semi-discrete time-stepping scheme in which the nonlinear term is evaluated at the temporal midpoint. As a result, at each time step, this approach reduces the original nonlinear problem to a linear one and enables parallel computation of its solution. Convergence is proved, and second-order accuracy with respect to the time-step size is established on a local temporal interval. The proposed scheme is then applied to a spatially one-dimensional nonlinear dynamic Timoshenko beam system, and the results obtained for the abstract nonlinear system are extended to this setting. A Legendre-Galerkin spectral approximation is employed for the spatial discretization. By taking differences of Legendre polynomials within the Galerkin framework, the resulting linear system is sparse and can be efficiently decoupled. The convergence of the method is also investigated. Finally, several numerical experiments on carefully chosen benchmark problems are conducted to validate the proposed approach and to confirm the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02068v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.AP</category>
      <category>math.MP</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jemal Rogava, Zurab Vashakidze</dc:creator>
    </item>
    <item>
      <title>Convex limiting for finite elements and its relationship to residual distribution</title>
      <link>https://arxiv.org/abs/2602.02095</link>
      <description>arXiv:2602.02095v3 Announce Type: replace 
Abstract: We review some recent advances in the field of element-based algebraic stabilization for continuous finite element discretizations of nonlinear hyperbolic problems. The main focus is on multidimensional convex limiting techniques designed to constrain antidiffusive element contributions rather than fluxes. We show that the resulting schemes can be interpreted as residual distribution methods. Two kinds of convex limiting can be used to enforce the validity of generalized discrete maximum principles in this context. The first approach has the structure of a localized flux-corrected transport (FCT) algorithm, in which the computation of a low-order predictor is followed by an antidiffusive correction stage. The second option is the use of a monolithic convex limiting (MCL) procedure at the level of spatial semi-discretization. In both cases, inequality constraints are imposed on scalar functions of intermediate states that are required to stay in convex invariant sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02095v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitri Kuzmin</dc:creator>
    </item>
    <item>
      <title>Comparison of Trefftz-Based PINNs and Standard PINNs Focusing on Structure Preservation</title>
      <link>https://arxiv.org/abs/2602.02779</link>
      <description>arXiv:2602.02779v2 Announce Type: replace 
Abstract: In this study, we investigate the capability of physics-informed neural networks (PINNs) to preserve global physical structures by comparing standard PINNs with a Trefftz-based PINN (Trefftz-PINN). The target problem is the reproduction of mag-netic field-line structures in a helical fusion reactor configuration. Using identical training data sampled from exact solutions, we perform comparisons under matched mean squared error (MSE) levels. Visualization of magnetic field lines reveals that standard PINNs may exhibit structural collapse across magnetic surfaces even when the MSE is sufficiently small, whereas Trefftz-PINNs successfully preserve the global topology of magnetic field lines. Furthermore, the proposed framework is extended to computational fluid dynamics (CFD) problems, where streamline structures of veloc-ity fields are analyzed. Similar tendencies are observed, demonstrating that Trefftz-PINNs provide superior structure preservation compared to standard PINNs. These results indicate that minimizing numerical error alone does not guarantee physical consistency, and that constraining the solution space prior to learning is an effective strategy for physics-consistent surrogate modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02779v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koji Koyamada</dc:creator>
    </item>
    <item>
      <title>Learning nonnegative matrix factorizations from compressed data</title>
      <link>https://arxiv.org/abs/2409.04994</link>
      <description>arXiv:2409.04994v2 Announce Type: replace-cross 
Abstract: We propose a flexible and theoretically supported framework for scalable nonnegative matrix factorization. The goal is to find nonnegative low-rank components directly from compressed measurements, accessing the original data only once or twice. We consider compression through randomized sketching methods that can be adapted to the data, or can be oblivious. We formulate optimization problems that only depend on the compressed data, but which can recover a nonnegative factorization which closely approximates the original matrix. The defined problems can be approached with a variety of algorithms, and in particular, we discuss variations of the popular multiplicative updates method for these compressed problems. We demonstrate the success of our approaches empirically and validate their performance in real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04994v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abraar Chaudhry, Elizaveta Rebrova</dc:creator>
    </item>
    <item>
      <title>Denoising diffusion probabilistic models are optimally adaptive to unknown low dimensionality</title>
      <link>https://arxiv.org/abs/2410.18784</link>
      <description>arXiv:2410.18784v3 Announce Type: replace-cross 
Abstract: The denoising diffusion probabilistic model (DDPM) has emerged as a mainstream generative model in generative AI. While sharp convergence guarantees have been established for the DDPM, the iteration complexity is, in general, proportional to the ambient data dimension, resulting in overly conservative theory that fails to explain its practical efficiency. This has motivated the recent work Li and Yan (2024a) to investigate how the DDPM can achieve sampling speed-ups through automatic exploitation of intrinsic low dimensionality of data. We strengthen this line of work by demonstrating, in some sense, optimal adaptivity to unknown low dimensionality. For a broad class of data distributions with intrinsic dimension $k$, we prove that the iteration complexity of the DDPM scales nearly linearly with $k$, which is optimal when using KL divergence to measure distributional discrepancy. Notably, our work is closely aligned with the independent concurrent work Potaptchik et al. (2024) -- posted two weeks prior to ours -- in establishing nearly linear-$k$ convergence guarantees for the DDPM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18784v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhihan Huang, Yuting Wei, Yuxin Chen</dc:creator>
    </item>
    <item>
      <title>Solving Monge problem by Hilbert space embeddings of probability measures</title>
      <link>https://arxiv.org/abs/2412.03478</link>
      <description>arXiv:2412.03478v5 Announce Type: replace-cross 
Abstract: We propose deep learning methods for classical Monge's optimal mass transportation problems, where where the distribution constraint is treated as penalty terms defined by the maximum mean discrepancy in the theory of Hilbert space embeddings of probability measures. We prove that the transport maps given by the proposed methods converge to optimal transport maps in the problem with $L^2$ cost. Several numerical experiments validate our methods. In particular, we show that our methods are applicable to large-scale Monge problems. This is a corrected version of the ICORES 2025 proceedings paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03478v5</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takafumi Saito, Yumiharu Nakano</dc:creator>
    </item>
    <item>
      <title>A SIMPLE-Based Preconditioned Solver for the Direct-Forcing Immersed Boundary Method</title>
      <link>https://arxiv.org/abs/2501.15314</link>
      <description>arXiv:2501.15314v3 Announce Type: replace-cross 
Abstract: We present a robust and scalable solver for direct-forcing immersed boundary simulations, based on a preconditioned SIMPLE algorithm. The method applies block elimination to the pressure-force coupled system, and utilizes the discrete Laplacian operator as an efficient preconditioner for the resulting Schur complement. We rigorously demonstrate the spectral equivalence between the Schur complement and the discrete Laplacian, ensuring convergence behavior that is independent of grid resolution and physical parameters. This enables accurate, stable, and efficient two-way coupled fluid-structure interaction (FSI) simulations with moving boundaries and significant added-mass effects. These simulations are all executable on standard computing platforms. Extensive validation and verification - including simulations of oscillating, sedimenting, and buoyant spheres, as well as configurations involving multiple immersed bodies - confirm the solver's accuracy and efficiency across a broad range of FSI scenarios. The proposed approach introduces a novel and accessible framework for immersed boundary simulations requiring strong pressure-force coupling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15314v3</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rachel Yovel, Eran Treister, Yuri Feldman</dc:creator>
    </item>
    <item>
      <title>Variable aggregation for nonlinear optimization problems</title>
      <link>https://arxiv.org/abs/2502.13869</link>
      <description>arXiv:2502.13869v3 Announce Type: replace-cross 
Abstract: Variable aggregation has been largely studied as an important pre-solve algorithm for optimization of linear and mixed-integer programs. Although some nonlinear solvers and algebraic modeling languages implement variable aggregation as a pre-solve, the impact it can have on constrained nonlinear programs is unexplored. In this work, we formalize variable aggregation as a pre-solve algorithm to develop reduced-space formulations of nonlinear programs. A novel approximate maximum variable aggregation strategy is developed to aggregate as many variables as possible. Furthermore, aggregation strategies that preserve the problem structure are compared against approximate maximum aggregation. Our results show that variable aggregation can generally help to improve the convergence reliability of nonlinear programs. It can also help in reducing total solve time. However, Hessian evaluation can become a bottleneck if aggregation significantly increases the number of variables appearing nonlinearly in many constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13869v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sakshi Naik, Lorenz Biegler, Russell Bent, Robert Parker</dc:creator>
    </item>
    <item>
      <title>Epsilon-Neighborhood Decision-Boundary Governed Estimation (EDGE) of 2D Black Box Classifier Functions</title>
      <link>https://arxiv.org/abs/2504.09733</link>
      <description>arXiv:2504.09733v3 Announce Type: replace-cross 
Abstract: Accurately estimating decision boundaries in black box systems is critical when ensuring safety, quality, and feasibility in real-world applications. However, existing methods iteratively refine boundary estimates by sampling in regions of uncertainty, without providing guarantees on the closeness to the decision boundary and also result in unnecessary exploration that is especially disadvantageous when evaluations are costly. This paper presents $\varepsilon$-Neighborhood Decision-Boundary Governed Estimation (EDGE), a sample efficient and function-agnostic algorithm that leverages the intermediate value theorem to estimate the location of the decision boundary of a black box binary classifier within a user-specified $\varepsilon$-neighborhood. To demonstrate applicability, a case study is presented of an electric grid stability problem with uncertain renewable power injection. Evaluations are conducted on three test functions, where it is seen that the EDGE algorithm demonstrates superior sample efficiency and better boundary approximation than adaptive sampling techniques and grid-based searches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09733v3</guid>
      <category>cs.CG</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ifacol.2025.12.274</arxiv:DOI>
      <dc:creator>Mithun Goutham, Riccardo DalferroNucci, Stephanie Stockar, Meghna Menon, Sneha Nayak, Harshad Zade, Chetan Patel, Mario Santillo</dc:creator>
    </item>
    <item>
      <title>Boundary-velocity error and stability of the accelerated multi-direct-forcing immersed boundary method</title>
      <link>https://arxiv.org/abs/2507.04986</link>
      <description>arXiv:2507.04986v3 Announce Type: replace-cross 
Abstract: The multi-direct-forcing immersed boundary method allows for a small velocity error of the no-slip condition in moving-particle problems but suffers from numerical instability if simulation parameters are not carefully chosen. This study investigates the boundary-velocity error and numerical stability of the accelerated multi-direct-forcing immersed boundary method. An analysis of the discretized equations of body motion in moving boundary problems identifies a critical parameter that solely determines the numerical stability for the body motion. Additionally, numerical simulations reveal the optimal acceleration parameter that minimizes the velocity error of the no-slip condition and is independent of details of the boundary discretisation, the boundary shape, and spatial dimensionality. This study provides a guideline for establishing numerically stable simulations of moving boundary problems at optimal boundary-velocity error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04986v3</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kosuke Suzuki, Emmanouil Falagkaris, Timm Kr\"uger, Takaji Inamuro</dc:creator>
    </item>
    <item>
      <title>Optimal Frames for Phase Retrieval from Edge Vectors of Optimal Polygons</title>
      <link>https://arxiv.org/abs/2510.04099</link>
      <description>arXiv:2510.04099v3 Announce Type: replace-cross 
Abstract: This paper aims to characterize the optimal frame for phase retrieval, defined as the frame whose condition number for phase retrieval attains its minimal value. In the context of the two-dimensional real case, we reveal the connection between optimal frames for phase retrieval and the perimeter-maximizing isodiametric problem, originally proposed by Reinhardt in 1922. Our work establishes that every optimal solution to the perimeter-maximizing isodiametric problem inherently leads to an optimal frame in ${\mathbb R}^2$. By recasting the optimal polygons problem as one concerning the discrepancy of roots of unity, we characterize all optimal polygons. Building upon this connection, we then characterize all optimal frames with $m$ vectors in ${\mathbb R}^2$ for phase retrieval when $m \geq 3$ has an odd factor. As a key corollary, we show that the harmonic frame $E_m \subset {\mathbb R}^2$ is {\em not} optimal for any even integer $m \geq 4$. This finding disproves a conjecture proposed by Xia, Xu, and Xu [{\em Math. Comp.}, 94 (2025), pp.~2931--2960]. Previous work has established that $E_m$ is indeed optimal when $m$ is an odd integer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04099v3</guid>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.IT</category>
      <category>math.MG</category>
      <category>math.NA</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiqiang Xu, Zili Xu, Xinyue Zhang</dc:creator>
    </item>
    <item>
      <title>Interpolative separable density fitting on adaptive real space grids</title>
      <link>https://arxiv.org/abs/2510.20826</link>
      <description>arXiv:2510.20826v2 Announce Type: replace-cross 
Abstract: We generalize the interpolative separable density fitting (ISDF) method, used for compressing the four-index electron repulsion integral (ERI) tensor, to incorporate adaptive real space grids for potentially highly localized single-particle basis functions. To do so, we employ a fast adaptive algorithm, the recently-introduced dual-space multilevel kernel-splitting method, to solve the Poisson equation for the ISDF auxiliary basis functions. The adaptive grids are generated using a high-order accurate, black-box procedure that satisfies a user-specified error tolerance. Our algorithm relies on the observation, which we prove, that an adaptive grid resolving the pair densities appearing in the ERI tensor can be straightforwardly constructed from one that resolves the single-particle basis functions, with the number of required grid points differing only by a constant factor. We find that the ISDF compression efficiency for the ERI tensor with highly localized basis sets is comparable to that for smoother basis sets compatible with uniform grids. To demonstrate the performance of our procedure, we consider several molecular systems with all-electron basis sets which are intractable using uniform grid-based methods. Our work establishes a pathway for scalable many-body electronic structure simulations with arbitrary smooth basis functions, making simulations of phenomena like core-level excitations feasible on a large scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20826v2</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>quant-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hai Zhu, Chia-Nan Yeh, Miguel A. Morales, Leslie Greengard, Shidong Jiang, Jason Kaye</dc:creator>
    </item>
  </channel>
</rss>
