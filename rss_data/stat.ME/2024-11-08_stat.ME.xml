<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Nov 2024 05:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Kernel density estimation with polyspherical data and its applications</title>
      <link>https://arxiv.org/abs/2411.04166</link>
      <description>arXiv:2411.04166v1 Announce Type: new 
Abstract: A kernel density estimator for data on the polysphere $\mathbb{S}^{d_1}\times\cdots\times\mathbb{S}^{d_r}$, with $r,d_1,\ldots,d_r\geq 1$, is presented in this paper. We derive the main asymptotic properties of the estimator, including mean square error, normality, and optimal bandwidths. We address the kernel theory of the estimator beyond the von Mises-Fisher kernel, introducing new kernels that are more efficient and investigating normalizing constants, moments, and sampling methods thereof. Plug-in and cross-validated bandwidth selectors are also obtained. As a spin-off of the kernel density estimator, we propose a nonparametric $k$-sample test based on the Jensen-Shannon divergence. Numerical experiments illuminate the asymptotic theory of the kernel density estimator and demonstrate the superior performance of the $k$-sample test with respect to parametric alternatives in certain scenarios. Our smoothing methodology is applied to the analysis of the morphology of a sample of hippocampi of infants embedded on the high-dimensional polysphere $(\mathbb{S}^2)^{168}$ via skeletal representations ($s$-reps).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04166v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Eduardo Garc\'ia-Portugu\'es, Andrea Meil\'an-Vila</dc:creator>
    </item>
    <item>
      <title>dsld: A Socially Relevant Tool for Teaching Statistics</title>
      <link>https://arxiv.org/abs/2411.04228</link>
      <description>arXiv:2411.04228v1 Announce Type: new 
Abstract: The growing power of data science can play a crucial role in addressing social discrimination, necessitating nuanced understanding and effective mitigation strategies of potential biases. Data Science Looks At Discrimination (dsld) is an R and Python package designed to provide users with a comprehensive toolkit of statistical and graphical methods for assessing possible discrimination related to protected groups, such as race, gender, and age. Our software offers techniques for discrimination analysis by identifying and mitigating confounding variables, along with methods for reducing bias in predictive models.
  In educational settings, dsld offers instructors powerful tools to teach important statistical principles through motivating real world examples of discrimination analysis. The inclusion of an 80-page Quarto book further supports users, from statistics educators to legal professionals, in effectively applying these analytical tools to real world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04228v1</guid>
      <category>stat.ME</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taha Abdullah, Arjun Ashok, Brandon Estrada, Norman Matloff, Aditya Mittal</dc:creator>
    </item>
    <item>
      <title>Detecting State Changes in Functional Neuronal Connectivity using Factorial Switching Linear Dynamical Systems</title>
      <link>https://arxiv.org/abs/2411.04229</link>
      <description>arXiv:2411.04229v1 Announce Type: new 
Abstract: A key question in brain sciences is how to identify time-evolving functional connectivity, such as that obtained from recordings of neuronal activity over time. We wish to explain the observed phenomena in terms of latent states which, in the case of neuronal activity, might correspond to subnetworks of neurons within a brain or organoid. Many existing approaches assume that only one latent state can be active at a time, in contrast to our domain knowledge. We propose a switching dynamical system based on the factorial hidden Markov model. Unlike existing approaches, our model acknowledges that neuronal activity can be caused by multiple subnetworks, which may be activated either jointly or independently. A change in one part of the network does not mean that the entire connectivity pattern will change. We pair our model with scalable variational inference algorithm, using a concrete relaxation of the underlying factorial hidden Markov model, to effectively infer the latent states and model parameters. We show that our algorithm can recover ground-truth structure and yield insights about the maturation of neuronal activity in microelectrode array recordings from in vitro neuronal cultures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04229v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiwei Gong, Susanna B. Mierau, Sinead A. Williamson</dc:creator>
    </item>
    <item>
      <title>Mediation analysis of community context effects on heart failure using the survival R2D2 prior</title>
      <link>https://arxiv.org/abs/2411.04310</link>
      <description>arXiv:2411.04310v1 Announce Type: new 
Abstract: Congestive heart failure (CHF) is a leading cause of morbidity, mortality and healthcare costs, impacting $&gt;$23 million individuals worldwide. Large electronic health records data provide an opportunity to improve clinical management of diseases, but statistical inference on large amounts of relevant personal data is still a challenge. Thus, accurately identifying influential risk factors is pivotal to reducing the dimensionality of information. Bayesian variable selection in survival regression is a common approach towards solving this problem. In this paper, we propose placing a beta prior directly on the model coefficient of determination (Bayesian $R^2$), which induces a prior on the global variance of the predictors and provides shrinkage. Through reparameterization using an auxiliary variable, we are able to update a majority of the parameters with Gibbs sampling, simplifying computation and quickening convergence. Performance gains over competing variable selection methods are showcased through an extensive simulation study. Finally, the method is applied in a mediation analysis to identify community context attributes impacting time to first congestive heart failure diagnosis of patients enrolled in University of North Carolina Cardiovascular Device Surveillance Registry. The model has high predictive performance with a C-index of over 0.7 and we find that factors associated with higher socioeconomic inequality and air pollution increase risk of heart failure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04310v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brandon R. Feng, Eric Yanchenko, K. Lloyd Hill, Lindsey A. Rosman, Brian J. Reich, Ana G. Rappold</dc:creator>
    </item>
    <item>
      <title>Parsimoniously Fitting Large Multivariate Random Effects in glmmTMB</title>
      <link>https://arxiv.org/abs/2411.04411</link>
      <description>arXiv:2411.04411v1 Announce Type: new 
Abstract: Multivariate random effects with unstructured variance-covariance matrices of large dimensions, $q$, can be a major challenge to estimate. In this paper, we introduce a new implementation of a reduced-rank approach to fit large dimensional multivariate random effects by writing them as a linear combination of $d &lt; q$ latent variables. By adding reduced-rank functionality to the package glmmTMB, we enhance the mixed models available to include random effects of dimensions that were previously not possible. We apply the reduced-rank random effect to two examples, estimating a generalized latent variable model for multivariate abundance data and a random-slopes model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04411v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maeve McGillycuddy, Gordana Popovic, Benjamin M. Bolker, David I. Warton</dc:creator>
    </item>
    <item>
      <title>A Structured Estimator for large Covariance Matrices in the Presence of Pairwise and Spatial Covariates</title>
      <link>https://arxiv.org/abs/2411.04520</link>
      <description>arXiv:2411.04520v1 Announce Type: new 
Abstract: We consider the problem of estimating a high-dimensional covariance matrix from a small number of observations when covariates on pairs of variables are available and the variables can have spatial structure. This is motivated by the problem arising in demography of estimating the covariance matrix of the total fertility rate (TFR) of 195 different countries when only 11 observations are available. We construct an estimator for high-dimensional covariance matrices by exploiting information about pairwise covariates, such as whether pairs of variables belong to the same cluster, or spatial structure of the variables, and interactions between the covariates. We reformulate the problem in terms of a mixed effects model. This requires the estimation of only a small number of parameters, which are easy to interpret and which can be selected using standard procedures. The estimator is consistent under general conditions, and asymptotically normal. It works if the mean and variance structure of the data is already specified or if some of the data are missing. We assess its performance under our model assumptions, as well as under model misspecification, using simulations. We find that it outperforms several popular alternatives. We apply it to the TFR dataset and draw some conclusions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04520v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Metodiev, Marie Perrot-Dock\`es, Sarah Ouadah, Bailey K. Fosdick, St\'ephane Robin, Pierre Latouche, Adrian E. Raftery</dc:creator>
    </item>
    <item>
      <title>Doubly robust inference with censoring unbiased transformations</title>
      <link>https://arxiv.org/abs/2411.04909</link>
      <description>arXiv:2411.04909v1 Announce Type: new 
Abstract: This paper extends doubly robust censoring unbiased transformations to a broad class of censored data structures under the assumption of coarsening at random and positivity. This includes the classic survival and competing risks setting, but also encompasses multiple events. A doubly robust representation for the conditional bias of the transformed data is derived. This leads to rate double robustness and oracle efficiency properties for estimating conditional expectations when combined with cross-fitting and linear smoothers. Simulation studies demonstrate favourable performance of the proposed method relative to existing approaches. An application of the methods to a regression discontinuity design with censored data illustrates its practical utility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04909v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oliver Lunding Sandqvist</dc:creator>
    </item>
    <item>
      <title>Differentially Private Finite Population Estimation via Survey Weight Regularization</title>
      <link>https://arxiv.org/abs/2411.04236</link>
      <description>arXiv:2411.04236v1 Announce Type: cross 
Abstract: In general, it is challenging to release differentially private versions of survey-weighted statistics with low error for acceptable privacy loss. This is because weighted statistics from complex sample survey data can be more sensitive to individual survey response and weight values than unweighted statistics, resulting in differentially private mechanisms that can add substantial noise to the unbiased estimate of the finite population quantity. On the other hand, simply disregarding the survey weights adds noise to a biased estimator, which also can result in an inaccurate estimate. Thus, the problem of releasing an accurate survey-weighted estimate essentially involves a trade-off among bias, precision, and privacy. We leverage this trade-off to develop a differentially private method for estimating finite population quantities. The key step is to privately estimate a hyperparameter that determines how much to regularize or shrink survey weights as a function of privacy loss. We illustrate the differentially private finite population estimation using the Panel Study of Income Dynamics. We show that optimal strategies for releasing DP survey-weighted mean income estimates require orders-of-magnitude less noise than naively using the original survey weights without modification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04236v1</guid>
      <category>cs.CR</category>
      <category>stat.ME</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy Seeman, Yajuan Si, Jerome P Reiter</dc:creator>
    </item>
    <item>
      <title>Identification of Long-Term Treatment Effects via Temporal Links, Observational, and Experimental Data</title>
      <link>https://arxiv.org/abs/2411.04380</link>
      <description>arXiv:2411.04380v1 Announce Type: cross 
Abstract: Recent literature proposes combining short-term experimental and long-term observational data to provide credible alternatives to conventional observational studies for identification of long-term average treatment effects (LTEs). I show that experimental data have an auxiliary role in this context. They bring no identifying power without additional modeling assumptions. When modeling assumptions are imposed, experimental data serve to amplify their identifying power. If the assumptions fail, adding experimental data may only yield results that are farther from the truth. Motivated by this, I introduce two assumptions on treatment response that may be defensible based on economic theory or intuition. To utilize them, I develop a novel two-step identification approach that centers on bounding temporal link functions -- the relationship between short-term and mean long-term potential outcomes. The approach provides sharp bounds on LTEs for a general class of assumptions, and allows for imperfect experimental compliance -- extending existing results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04380v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filip Obradovi\'c</dc:creator>
    </item>
    <item>
      <title>Testing for changes in the error distribution in functional linear models</title>
      <link>https://arxiv.org/abs/2411.04522</link>
      <description>arXiv:2411.04522v1 Announce Type: cross 
Abstract: We consider linear models with scalar responses and covariates from a separable Hilbert space. The aim is to detect change points in the error distribution, based on sequential residual empirical distribution functions. Expansions for those estimated functions are more challenging in models with infinite-dimensional covariates than in regression models with scalar or vector-valued covariates due to a slower rate of convergence of the parameter estimators. Yet the suggested change point test is asymptotically distribution-free and consistent for one-change point alternatives. In the latter case we also show consistency of a change point estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04522v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Natalie Neumeyer, Leonie Selk</dc:creator>
    </item>
    <item>
      <title>Conjugate gradient methods for high-dimensional GLMMs</title>
      <link>https://arxiv.org/abs/2411.04729</link>
      <description>arXiv:2411.04729v1 Announce Type: cross 
Abstract: Generalized linear mixed models (GLMMs) are a widely used tool in statistical analysis. The main bottleneck of many computational approaches lies in the inversion of the high dimensional precision matrices associated with the random effects. Such matrices are typically sparse; however, the sparsity pattern resembles a multi partite random graph, which does not lend itself well to default sparse linear algebra techniques. Notably, we show that, for typical GLMMs, the Cholesky factor is dense even when the original precision is sparse. We thus turn to approximate iterative techniques, in particular to the conjugate gradient (CG) method. We combine a detailed analysis of the spectrum of said precision matrices with results from random graph theory to show that CG-based methods applied to high-dimensional GLMMs typically achieve a fixed approximation error with a total cost that scales linearly with the number of parameters and observations. Numerical illustrations with both real and simulated data confirm the theoretical findings, while at the same time illustrating situations, such as nested structures, where CG-based methods struggle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04729v1</guid>
      <category>stat.CO</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Pandolfi, Omiros Papaspiliopoulos, Giacomo Zanella</dc:creator>
    </item>
    <item>
      <title>Using negative controls to identify causal effects with invalid instrumental variables</title>
      <link>https://arxiv.org/abs/2204.04119</link>
      <description>arXiv:2204.04119v4 Announce Type: replace 
Abstract: Many proposals for the identification of causal effects require an instrumental variable that satisfies strong, untestable unconfoundedness and exclusion restriction assumptions. In this paper, we show how one can potentially identify causal effects under violations of these assumptions by harnessing a negative control population or outcome. This strategy allows one to leverage sup-populations for whom the exposure is degenerate, and requires that the instrument-outcome association satisfies a certain parallel trend condition. We develop the semiparametric efficiency theory for a general instrumental variable model, and obtain a multiply robust, locally efficient estimator of the average treatment effect in the treated. The utility of the estimators is demonstrated in simulation studies and an analysis of the Life Span Study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.04119v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oliver Dukes, David B. Richardson, Zachary Shahn, James M. Robins, Eric J. Tchetgen Tchetgen</dc:creator>
    </item>
    <item>
      <title>A review of statistical models used to characterize species-habitat associations with animal movement data</title>
      <link>https://arxiv.org/abs/2401.17389</link>
      <description>arXiv:2401.17389v2 Announce Type: replace 
Abstract: Understanding species-habitat associations is fundamental to ecological sciences and for species conservation. Consequently, various statistical approaches have been designed to infer species-habitat associations. Due to their conceptual and mathematical differences, these methods can yield contrasting results. In this paper, we describe and compare commonly used statistical models that relate animal movement data to environmental data. Specifically, we examined selection functions which include resource selection function (RSF) and step-selection function (SSF), as well as hidden Markov models (HMMs) and related methods such as state-space models. We demonstrate differences in assumptions of each method while highlighting advantages and limitations. Additionally, we provide guidance on selecting the most appropriate statistical method based on research objectives and intended inference. To demonstrate the varying ecological insights derived from each statistical model, we apply them to the movement track of a single ringed seal in a case study. For example, the RSF indicated selection of areas with high prey diversity, whereas the SSFs indicated no discernable relationship with prey diversity. Furthermore, the HMM reveals variable associations with prey diversity across different behaviors. Notably, the three models identified different important areas. This case study highlights the critical significance of selecting the appropriate model to identify species-habitat relationships and specific areas of importance. Our comprehensive review provides the foundational information required for making informed decisions when choosing the most suitable statistical methods to address specific questions, such as identifying expansive corridors or protected zones, understanding movement patterns, or studying behaviours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17389v2</guid>
      <category>stat.ME</category>
      <category>q-bio.PE</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Katie R. N. Florko, Ron R. Togunov, Rowenna Gryba, Evan Sidrow, Steven H. Ferguson, David J. Yurkowski, Marie Auger-M\'eth\'e</dc:creator>
    </item>
    <item>
      <title>Parameter identifiability, parameter estimation and model prediction for differential equation models</title>
      <link>https://arxiv.org/abs/2405.08177</link>
      <description>arXiv:2405.08177v3 Announce Type: replace 
Abstract: Interpreting data with mathematical models is an important aspect of real-world applied mathematical modeling. Very often we are interested to understand the extent to which a particular data set informs and constrains model parameters. This question is closely related to the concept of parameter identifiability, and in this article we present a series of computational exercises to introduce tools that can be used to assess parameter identifiability, estimate parameters and generate model predictions. Taking a likelihood-based approach, we show that very similar ideas and algorithms can be used to deal with a range of different mathematical modelling frameworks. The exercises and results presented in this article are supported by a suite of open access codes that can be accessed on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08177v3</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew J Simpson, Ruth E Baker</dc:creator>
    </item>
    <item>
      <title>A geometric approach to informed MCMC sampling</title>
      <link>https://arxiv.org/abs/2406.09010</link>
      <description>arXiv:2406.09010v2 Announce Type: replace 
Abstract: A Riemannian geometric framework for Markov chain Monte Carlo (MCMC) is developed where using the Fisher-Rao metric on the manifold of probability density functions (pdfs), informed proposal densities for Metropolis-Hastings (MH) algorithms are constructed. We exploit the square-root representation of pdfs under which the Fisher-Rao metric boils down to the standard $L^2$ metric on the positive orthant of the unit hypersphere. The square-root representation allows us to easily compute the geodesic distance between densities, resulting in a straightforward implementation of the proposed geometric MCMC methodology. Unlike the random walk MH that blindly proposes a candidate state using no information about the target, the geometric MH algorithms move an uninformed base density (e.g., a random walk proposal density) towards different global/local approximations of the target density, allowing effective exploration of the distribution simultaneously at different granular levels of the state space. We compare the proposed geometric MH algorithm with other MCMC algorithms for various Markov chain orderings, namely the covariance, efficiency, Peskun, and spectral gap orderings. The superior performance of the geometric algorithms over other MH algorithms like the random walk Metropolis, independent MH, and variants of Metropolis adjusted Langevin algorithms is demonstrated in the context of various multimodal, nonlinear, and high dimensional examples. In particular, we use extensive simulation and real data applications to compare these algorithms for analyzing mixture models, logistic regression models, spatial generalized linear mixed models and ultra-high dimensional Bayesian variable selection models. A publicly available R package accompanies the article.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09010v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vivekananda Roy</dc:creator>
    </item>
    <item>
      <title>Distributionally robust risk evaluation with an isotonic constraint</title>
      <link>https://arxiv.org/abs/2407.06867</link>
      <description>arXiv:2407.06867v3 Announce Type: replace 
Abstract: Statistical learning under distribution shift is challenging when neither prior knowledge nor fully accessible data from the target distribution is available. Distributionally robust learning (DRL) aims to control the worst-case statistical performance within an uncertainty set of candidate distributions, but how to properly specify the set remains challenging. To enable distributional robustness without being overly conservative, in this paper, we propose a shape-constrained approach to DRL, which incorporates prior information about the way in which the unknown target distribution differs from its estimate. More specifically, we assume the unknown density ratio between the target distribution and its estimate is isotonic with respect to some partial order. At the population level, we provide a solution to the shape-constrained optimization problem that does not involve the isotonic constraint. At the sample level, we provide consistency results for an empirical estimator of the target in a range of different settings. Empirical studies on both synthetic and real data examples demonstrate the improved accuracy of the proposed shape-constrained approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06867v3</guid>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Gui, Rina Foygel Barber, Cong Ma</dc:creator>
    </item>
    <item>
      <title>Improving the (approximate) sequential probability ratio test by avoiding overshoot</title>
      <link>https://arxiv.org/abs/2410.16076</link>
      <description>arXiv:2410.16076v2 Announce Type: replace 
Abstract: The sequential probability ratio test (SPRT) by Wald (1945) is a cornerstone of sequential analysis. Based on desired type-I, II error levels $\alpha, \beta \in (0,1)$, it stops when the likelihood ratio statistic crosses certain upper and lower thresholds, guaranteeing optimality of the expected sample size. However, these thresholds are not closed form and the test is often applied with approximate thresholds $(1-\beta)/\alpha$ and $\beta/(1-\alpha)$ (approximate SPRT). When $\beta &gt; 0$, this neither guarantees type I,II error control at $\alpha,\beta$ nor optimality. When $\beta=0$ (power-one SPRT), it guarantees type I error control at $\alpha$ that is in general conservative, and thus not optimal. The looseness in both cases is caused by overshoot: the test statistic overshoots the thresholds at the stopping time. One standard way to address this is to calculate the right thresholds numerically, but many papers and software packages do not do this. In this paper, we describe a different way to improve the approximate SPRT: we change the test statistic to avoid overshoot. Our technique uniformly improves power-one SPRTs $(\beta=0)$ for simple nulls and alternatives, or for one-sided nulls and alternatives in exponential families. When $\beta &gt; 0$, our techniques provide valid type I and type II error guarantees, while needing less samples than Wald's approximated thresholds in all considered simulations. These improved sequential tests can also be used for deriving tighter parametric confidence sequences, and can be extended to nontrivial settings like sampling without replacement and conformal martingales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16076v2</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lasse Fischer, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Finite-Sample and Distribution-Free Fair Classification: Optimal Trade-off Between Excess Risk and Fairness, and the Cost of Group-Blindness</title>
      <link>https://arxiv.org/abs/2410.16477</link>
      <description>arXiv:2410.16477v2 Announce Type: replace 
Abstract: Algorithmic fairness in machine learning has recently garnered significant attention. However, two pressing challenges remain: (1) The fairness guarantees of existing fair classification methods often rely on specific data distribution assumptions and large sample sizes, which can lead to fairness violations when the sample size is moderate-a common situation in practice. (2) Due to legal and societal considerations, using sensitive group attributes during decision-making (referred to as the group-blind setting) may not always be feasible.
  In this work, we quantify the impact of enforcing algorithmic fairness and group-blindness in binary classification under group fairness constraints. Specifically, we propose a unified framework for fair classification that provides distribution-free and finite-sample fairness guarantees with controlled excess risk. This framework is applicable to various group fairness notions in both group-aware and group-blind scenarios. Furthermore, we establish a minimax lower bound on the excess risk, showing the minimax optimality of our proposed algorithm up to logarithmic factors. Through extensive simulation studies and real data analysis, we further demonstrate the superior performance of our algorithm compared to existing methods, and provide empirical support for our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16477v2</guid>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaotian Hou, Linjun Zhang</dc:creator>
    </item>
    <item>
      <title>Comment on 'Sparse Bayesian Factor Analysis when the Number of Factors is Unknown' by S. Fr\"uhwirth-Schnatter, D. Hosszejni, and H. Freitas Lopes</title>
      <link>https://arxiv.org/abs/2411.02531</link>
      <description>arXiv:2411.02531v2 Announce Type: replace 
Abstract: The techniques suggested in Fr\"uhwirth-Schnatter et al. (2024) concern sparsity and factor selection and have enormous potential beyond standard factor analysis applications. We show how these techniques can be applied to Latent Space (LS) models for network data. These models suffer from well-known identification issues of the latent factors due to likelihood invariance to factor translation, reflection, and rotation (see Hoff et al., 2002). A set of observables can be instrumental in identifying the latent factors via auxiliary equations (see Liu et al., 2021). These, in turn, share many analogies with the equations used in factor modeling, and we argue that the factor loading restrictions may be beneficial for achieving identification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02531v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Casarin (Ca' Foscari University of Venice), Antonio Peruzzi (Ca' Foscari University of Venice)</dc:creator>
    </item>
    <item>
      <title>Bayesian Dynamic Quantile Model Averaging</title>
      <link>https://arxiv.org/abs/1602.00856</link>
      <description>arXiv:1602.00856v2 Announce Type: replace-cross 
Abstract: This article introduces a novel dynamic framework to Bayesian model averaging for time-varying parameter quantile regressions. By employing sequential Markov chain Monte Carlo, we combine empirical estimates derived from dynamically chosen quantile regressions, thereby facilitating a comprehensive understanding of the quantile model instabilities. The effectiveness of our methodology is initially validated through the examination of simulated datasets and, subsequently, by two applications to the US inflation rates and to the US real estate market. Our empirical findings suggest that a more intricate and nuanced analysis is needed when examining different sub-period regimes, since the determinants of inflation and real estate prices are clearly shown to be time-varying. In conclusion, we suggest that our proposed approach could offer valuable insights to aid decision making in a rapidly changing environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:1602.00856v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mauro Bernardi, Roberto Casarin, Bertrand Maillet, Lea Petrella</dc:creator>
    </item>
    <item>
      <title>Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance</title>
      <link>https://arxiv.org/abs/2310.03722</link>
      <description>arXiv:2310.03722v5 Announce Type: replace-cross 
Abstract: In 1976, Lai constructed a nontrivial confidence sequence for the mean $\mu$ of a Gaussian distribution with unknown variance $\sigma^2$. Curiously, he employed both an improper (right Haar) mixture over $\sigma$ and an improper (flat) mixture over $\mu$. Here, we elaborate carefully on the details of his construction, which use generalized nonintegrable martingales and an extended Ville's inequality. While this does yield a sequential t-test, it does not yield an "e-process" (due to the nonintegrability of his martingale). In this paper, we develop two new e-processes and confidence sequences for the same setting: one is a test martingale in a reduced filtration, while the other is an e-process in the canonical data filtration. These are respectively obtained by swapping Lai's flat mixture for a Gaussian mixture, and swapping the right Haar mixture over $\sigma$ with the maximum likelihood estimate under the null, as done in universal inference. We also analyze the width of resulting confidence sequences, which have a curious polynomial dependence on the error probability $\alpha$ that we prove to be not only unavoidable, but (for universal inference) even better than the classical fixed-sample t-test. Numerical experiments are provided along the way to compare and contrast the various approaches, including some recent suboptimal ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03722v5</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongjian Wang, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Differentially Private Range Queries with Correlated Input Perturbation</title>
      <link>https://arxiv.org/abs/2402.07066</link>
      <description>arXiv:2402.07066v2 Announce Type: replace-cross 
Abstract: This work proposes a class of differentially private mechanisms for linear queries, in particular range queries, that leverages correlated input perturbation to simultaneously achieve unbiasedness, consistency, statistical transparency, and control over utility requirements in terms of accuracy targets expressed either in certain query margins or as implied by the hierarchical database structure. The proposed Cascade Sampling algorithm instantiates the mechanism exactly and efficiently. Our theoretical and empirical analysis demonstrates that we achieve near-optimal utility, effectively compete with other methods, and retain all the favorable statistical properties discussed earlier.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07066v2</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prathamesh Dharangutte, Jie Gao, Ruobin Gong, Guanyang Wang</dc:creator>
    </item>
  </channel>
</rss>
