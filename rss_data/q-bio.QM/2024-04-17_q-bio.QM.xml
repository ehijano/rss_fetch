<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Apr 2024 04:00:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The theoretical basis of reservoir pressure in arteries</title>
      <link>https://arxiv.org/abs/2404.10806</link>
      <description>arXiv:2404.10806v1 Announce Type: new 
Abstract: The separation of measured arterial pressure into a reservoir pressure and an excess pressure was introduced nearly 20 years ago as an heuristic hypothesis. We demonstrate that a two-time asymptotic analysis of the 1-D conservation equations in each artery coupled with the separation of the smaller arteries into inviscid and resistance arteries, based on their resistance coefficients, results, for the first time, in a formal derivation of the reservoir pressure. The key to the two-time analysis is the existence of a fast time associated with the propagation of waves through the arteries and a slow time associated with the convective velocity of the blood. The ratio between these two time scales is given by the Mach number; the ratio of a characteristic convective velocity to a characteristic wave speed. If the Mach number is small, a formal asymptotic analysis can be carried out which is accurate to the order of the square of the Mach number. The slow-time conservation equations involve a resistance coefficient that models the effect of viscosity on the convective velocity. On the basis of this resistance coefficient, we separate the arteries into the larger inviscid arteries where the coefficient is negligible and the smaller resistance arteries where it it is not negligible. The slow time pressure in the inviscid arteries is shown to be spatially uniform but varying in time. We define this pressure as the reservoir pressure. Dynamic analysis using mass conservation in the inviscid arteries shows that the reservoir pressure accounts for the storage of potential energy by the distension of the elastic inviscid arteries during early systole and its release during late systole and diastole. This analysis thus provides a formal derivation of the reservoir pressure and its physical meaning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10806v1</guid>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kim H. Parker, Alun D. Hughes</dc:creator>
    </item>
    <item>
      <title>FrackyFrac: A Standalone UniFrac Calculator</title>
      <link>https://arxiv.org/abs/2404.11087</link>
      <description>arXiv:2404.11087v1 Announce Type: new 
Abstract: UniFrac is a family of distance metrics over microbial abundances, that take taxonomic relatedness into account. Current tools and libraries for calculating UniFrac have specific requirements regarding the user's technical expertise, operating system, and pre-installed software, which might exclude potential users. FrackyFrac is a native command-line tool that can run on any platform and has no requirements. It can also generate the phylogenetic trees required for the calculation. We show that FrackyFrac's performance is on par with currently existing implementations. FrackyFrac can make UniFrac accessible to researchers who may otherwise skip it due to the effort involved, and it can simplify analysis pipelines for those who already use it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11087v1</guid>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amit Lavon, Smadar Shilo, Ayya Keshet, Eran Segal</dc:creator>
    </item>
    <item>
      <title>UruDendro, a public dataset of cross-section images of Pinus taeda</title>
      <link>https://arxiv.org/abs/2404.10856</link>
      <description>arXiv:2404.10856v1 Announce Type: cross 
Abstract: The automatic detection of tree-ring boundaries and other anatomical features using image analysis has progressed substantially over the past decade with advances in machine learning and imagery technology, as well as increasing demands from the dendrochronology community. This paper presents a publicly available database of 64 scanned images of transverse sections of commercially grown Pinus taeda trees from northern Uruguay, ranging from 17 to 24 years old. The collection contains several challenging features for automatic ring detection, including illumination and surface preparation variation, fungal infection (blue stains), knot formation, missing cortex or interruptions in outer rings, and radial cracking. This dataset can be used to develop and test automatic tree ring detection algorithms. This paper presents to the dendrochronology community one such method, Cross-Section Tree-Ring Detection (CS-TRD), which identifies and marks complete annual rings in cross-sections for tree species presenting a clear definition between early and latewood. We compare the CS-TRD performance against the ground truth manual delineation of all rings over the UruDendro dataset. The CS-TRD software identified rings with an average F-score of 89% and RMSE error of 5.27px for the entire database in less than 20 seconds per image. Finally, we propose a robust measure of the ring growth using the \emph{equivalent radius} of a circle having the same area enclosed by the detected tree ring. Overall, this study contributes to the dendrochronologist's toolbox of fast and low-cost methods to automatically detect rings in conifer species, particularly for measuring diameter growth rates and stem transverse area using entire cross-sections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10856v1</guid>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Henry Marichal, Diego Passarella, Christine Lucas, Ludmila Profumo, Ver\'onica Casaravilla, Mar\'ia Noel Rocha Galli, Serrana Ambite, Gregory Randall</dc:creator>
    </item>
    <item>
      <title>Sparse model identification and prediction of microglial cells during ischemic stroke</title>
      <link>https://arxiv.org/abs/2404.10915</link>
      <description>arXiv:2404.10915v1 Announce Type: cross 
Abstract: Dynamics between key neuroinflammatory components, detrimental M1 and beneficial M2 microglial cells, are not fully understood post-ischemic stroke. To discover, model, and predict these dynamics, we use a method based on sparse identification of nonlinear dynamics (SINDy). The resulting data-driven dynamical system involves constant and linear terms but does not include nonlinear interactions between cells. Results show M2 microglial cell dominance of four days. Forward predictions capture potential long-term dynamics of microglial cells and suggest a persistent inflammatory response.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10915v1</guid>
      <category>q-bio.CB</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sara Amato, Andrea Arnold</dc:creator>
    </item>
    <item>
      <title>ScaleFold: Reducing AlphaFold Initial Training Time to 10 Hours</title>
      <link>https://arxiv.org/abs/2404.11068</link>
      <description>arXiv:2404.11068v1 Announce Type: cross 
Abstract: AlphaFold2 has been hailed as a breakthrough in protein folding. It can rapidly predict protein structures with lab-grade accuracy. However, its implementation does not include the necessary training code. OpenFold is the first trainable public reimplementation of AlphaFold. AlphaFold training procedure is prohibitively time-consuming, and gets diminishing benefits from scaling to more compute resources. In this work, we conducted a comprehensive analysis on the AlphaFold training procedure based on Openfold, identified that inefficient communications and overhead-dominated computations were the key factors that prevented the AlphaFold training from effective scaling. We introduced ScaleFold, a systematic training method that incorporated optimizations specifically for these factors. ScaleFold successfully scaled the AlphaFold training to 2080 NVIDIA H100 GPUs with high resource utilization. In the MLPerf HPC v3.0 benchmark, ScaleFold finished the OpenFold benchmark in 7.51 minutes, shown over $6\times$ speedup than the baseline. For training the AlphaFold model from scratch, ScaleFold completed the pretraining in 10 hours, a significant improvement over the seven days required by the original AlphaFold pretraining baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11068v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Feiwen Zhu, Arkadiusz Nowaczynski, Rundong Li, Jie Xin, Yifei Song, Michal Marcinkiewicz, Sukru Burc Eryilmaz, Jun Yang, Michael Andersch</dc:creator>
    </item>
    <item>
      <title>Reconstruction of the local contractility of the cardiac muscle from deficient apparent kinematics</title>
      <link>https://arxiv.org/abs/2404.11137</link>
      <description>arXiv:2404.11137v1 Announce Type: cross 
Abstract: Active solids are a large class of materials, including both living soft tissues and artificial matter, that share the ability to undergo strain even in absence of external loads. While in engineered materials the actuation is typically designed a priori, in natural materials it is an unknown of the problem. In such a framework, the identification of inactive regions in active materials is of particular interest. An example of paramount relevance is cardiac mechanics and the assessment of regions of the cardiac muscle with impaired contractility. The impossibility to measure the local active forces directly, suggests us to develop a novel methodology exploiting kinematic data from clinical images by a variational approach to reconstruct the local contractility in the cardiac muscle. Introducing a suitable cost functional and effective regularization methods, we minimize the discrepancy between observed and simulated displacement and we recover the contractility map of the muscle. Numerical experiments, including severe conditions with added noise to model uncertainties, and data knowledge limited to the boundary, demonstrate the effectiveness of our approach. Unlike other methods, we provide a spatially continuous recovery of the contractility map at a low computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11137v1</guid>
      <category>physics.med-ph</category>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giulia Pozzi, Davide Ambrosi, Simone Pezzuto</dc:creator>
    </item>
    <item>
      <title>VLST: Virtual Lung Screening Trial for Lung Cancer Detection Using Virtual Imaging Trial</title>
      <link>https://arxiv.org/abs/2404.11221</link>
      <description>arXiv:2404.11221v1 Announce Type: cross 
Abstract: Importance: The efficacy of lung cancer screening can be significantly impacted by the imaging modality used. This Virtual Lung Screening Trial (VLST) addresses the critical need for precision in lung cancer diagnostics and the potential for reducing unnecessary radiation exposure in clinical settings.
  Objectives: To establish a virtual imaging trial (VIT) platform that accurately simulates real-world lung screening trials (LSTs) to assess the diagnostic accuracy of CT and CXR modalities.
  Design, Setting, and Participants: Utilizing computational models and machine learning algorithms, we created a diverse virtual patient population. The cohort, designed to mirror real-world demographics, was assessed using virtual imaging techniques that reflect historical imaging technologies.
  Main Outcomes and Measures: The primary outcome was the difference in the Area Under the Curve (AUC) for CT and CXR modalities across lesion types and sizes.
  Results: The study analyzed 298 CT and 313 CXR simulated images from 313 virtual patients, with a lesion-level AUC of 0.81 (95% CI: 0.78-0.84) for CT and 0.55 (95% CI: 0.53-0.56) for CXR. At the patient level, CT demonstrated an AUC of 0.85 (95% CI: 0.80-0.89), compared to 0.53 (95% CI: 0.47-0.60) for CXR. Subgroup analyses indicated CT's superior performance in detecting homogeneous lesions (AUC of 0.97 for lesion-level) and heterogeneous lesions (AUC of 0.71 for lesion-level) as well as in identifying larger nodules (AUC of 0.98 for nodules &gt; 8 mm).
  Conclusion and Relevance: The VIT platform validated the superior diagnostic accuracy of CT over CXR, especially for smaller nodules, underscoring its potential to replicate real clinical imaging trials. These findings advocate for the integration of virtual trials in the evaluation and improvement of imaging-based diagnostic tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11221v1</guid>
      <category>eess.IV</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fakrul Islam Tushar, Liesbeth Vancoillie, Cindy McCabe, Amareswararao Kavuri, Lavsen Dahal, Brian Harrawood, Milo Fryling, Mojtaba Zarei, Saman Sotoudeh-Paima, Fong Chi Ho, Dhrubajyoti Ghosh, Sheng Luo, W. Paul Segars, Ehsan Abadi, Kyle J. Lafata, Ehsan Samei, Joseph Y. Lo</dc:creator>
    </item>
    <item>
      <title>Density estimation for ordinal biological sequences and its applications</title>
      <link>https://arxiv.org/abs/2404.11228</link>
      <description>arXiv:2404.11228v1 Announce Type: cross 
Abstract: Biological sequences do not come at random. Instead, they appear with particular frequencies that reflect properties of the associated system or phenomenon. Knowing how biological sequences are distributed in sequence space is thus a natural first step toward understanding the underlying mechanisms. Here we propose a new method for inferring the probability distribution from which a sample of biological sequences were drawn for the case where the sequences are composed of elements that admit a natural ordering. Our method is based on Bayesian field theory, a physics-based machine learning approach, and can be regarded as a nonparametric extension of the traditional maximum entropy estimate. As an example, we use it to analyze the aneuploidy data pertaining to gliomas from The Cancer Genome Atlas project. In addition, we demonstrate two follow-up analyses that can be performed with the resulting probability distribution. One of them is to investigate the associations among the sequence sites. This provides us a way to infer the governing biological grammar. The other is to study the global geometry of the probability landscape, which allows us to look at the problem from an evolutionary point of view. It can be seen that this methodology enables us to learn from a sample of sequences about how a biological system or phenomenon in the real world works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11228v1</guid>
      <category>physics.bio-ph</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei-Chia Chen, Juannan Zhou, David M. McCandlish</dc:creator>
    </item>
    <item>
      <title>CESPED: a new benchmark for supervised particle pose estimation in Cryo-EM</title>
      <link>https://arxiv.org/abs/2311.06194</link>
      <description>arXiv:2311.06194v4 Announce Type: replace 
Abstract: Cryo-EM is a powerful tool for understanding macromolecular structures, yet current methods for structure reconstruction are slow and computationally demanding. To accelerate research on pose estimation, we present CESPED, a new dataset specifically designed for Supervised Pose Estimation in Cryo-EM. Alongside CESPED, we provide a PyTorch package to simplify Cryo-EM data handling and model evaluation. We evaluated the performance of a baseline model, Image2Sphere, on CESPED, which showed promising results but also highlighted the need for further improvements. Additionally, we illustrate the potential of deep learning-based pose estimators to generalise across different samples, suggesting a promising path toward more efficient processing strategies. CESPED is available at https://github.com/oxpig/cesped.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06194v4</guid>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruben Sanchez-Garcia, Michael Saur, Javier Vargas, Carl Poelking, Charlotte M Deane</dc:creator>
    </item>
    <item>
      <title>Detecting local perturbations of networks in a latent hyperbolic space</title>
      <link>https://arxiv.org/abs/2401.13495</link>
      <description>arXiv:2401.13495v2 Announce Type: replace 
Abstract: Graph theoretical approaches have been proven to be effective in the characterization of connected systems, as well as in quantifying their dysfunction due to perturbation. In this paper, we show the advantage of a non-Euclidean (hyperbolic) representation of networks to identify local connectivity perturbations and to characterize the induced effects on a large scale. We propose two perturbation scores based on representations of the networks in a latent geometric space, obtained through an embedding onto the hyperbolic Poincar\'e disk. We numerically demonstrate that these methods are able to localize perturbations in networks with homogeneous or heterogeneous degree connectivity. We apply this framework to identify the most perturbed brain areas in epileptic patients following surgery. This study is conceived in the effort of developing more powerful tools to represent and analyze brain networks, and it is the first to apply geometric network embedding techniques to the case of epilepsy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13495v2</guid>
      <category>q-bio.QM</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alice Longhena, Martin Guillemaud, Mario Chavez</dc:creator>
    </item>
  </channel>
</rss>
