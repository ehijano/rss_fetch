<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Jun 2025 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Efficient Traffic Classification using HW-NAS: Advanced Analysis and Optimization for Cybersecurity on Resource-Constrained Devices</title>
      <link>https://arxiv.org/abs/2506.11319</link>
      <description>arXiv:2506.11319v1 Announce Type: new 
Abstract: This paper presents a hardware-efficient deep neural network (DNN), optimized through hardware-aware neural architecture search (HW-NAS); the DNN supports the classification of session-level encrypted traffic on resource-constrained Internet of Things (IoT) and edge devices. Thanks to HW-NAS, a 1D convolutional neural network (CNN) is tailored on the ISCX VPN-nonVPN dataset to meet strict memory and computational limits while achieving robust performance. The optimized model attains an accuracy of 96.59% with just 88.26K parameters, 10.08M FLOPs, and a maximum tensor size of 20.12K. Compared to state-of-the-art models, it achieves reductions of up to 444-fold, 312-fold, and 15.6-fold in these metrics, respectively, significantly minimizing memory footprint and runtime requirements. The model also demonstrates versatility in classification tasks, achieving accuracies of up to 99.64% in VPN differentiation, VPN-type classification, broader traffic categories, and application identification. In addition, an in-depth approach to header-level preprocessing strategies confirms that the optimized model can provide notable performances across a wide range of configurations, even in scenarios with stricter privacy considerations. Likewise, a reduction in the length of sessions of up to 75% yields significant improvements in efficiency, while maintaining high accuracy with only a negligible drop of 1-2%. However, the importance of careful preprocessing and session length selection in the classification of raw traffic data is still present, as improper settings or aggressive reductions can bring about a 7% reduction in overall accuracy. Those results highlight the method's effectiveness in enforcing cybersecurity for IoT networks, by providing scalable, efficient solutions for the real-time analysis of encrypted traffic within strict hardware limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11319v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Adel Chehade, Edoardo Ragusa, Paolo Gastaldo, Rodolfo Zunino</dc:creator>
    </item>
    <item>
      <title>Scheduling Agile Earth Observation Satellites with Onboard Processing and Real-Time Monitoring</title>
      <link>https://arxiv.org/abs/2506.11556</link>
      <description>arXiv:2506.11556v1 Announce Type: new 
Abstract: The emergence of Agile Earth Observation Satellites (AEOSs) has marked a significant turning point in the field of Earth Observation (EO), offering enhanced flexibility in data acquisition. Concurrently, advancements in onboard satellite computing and communication technologies have greatly enhanced data compression efficiency, reducing network latency and congestion while supporting near real-time information delivery. In this paper, we address the Agile Earth Observation Satellite Scheduling Problem (AEOSSP), which involves determining the optimal sequence of target observations to maximize overall observation profit. Our approach integrates onboard data processing for real-time remote monitoring into the multi-satellite optimization problem. To this end, we define a set of priority indicators and develop a constructive heuristic method, further enhanced with a Local Search (LS) strategy. The results show that the proposed algorithm provides high-quality information by increasing the resolution of the collected frames by up to 10% on average, while reducing the variance in the monitoring frequency of the targets within the instance by up to 83%, ensuring more up-to-date information across the entire set compared to a First-In First-Out (FIFO) method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11556v1</guid>
      <category>cs.NI</category>
      <category>cs.RO</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonio M. Mercado-Mart\'inez, Beatriz Soret, Antonio Jurado-Navas</dc:creator>
    </item>
    <item>
      <title>Generalised Rate Control Approach For Stream Processing Applications</title>
      <link>https://arxiv.org/abs/2506.11710</link>
      <description>arXiv:2506.11710v1 Announce Type: new 
Abstract: Distributed stream processing systems are widely deployed to process real-time data generated by various devices, such as sensors and software systems. A key challenge in the system is overloading, which leads to an unstable system status and consumes additional system resources. In this paper, we use a graph neural network-based deep reinforcement learning to collaboratively control the data emission rate at which the data is generated in the stream source to proactively avoid overloading scenarios. Instead of using a traditional multi-layer perceptron-styled network to control the rate, the graph neural network is used to process system metrics collected from the stream processing engine. Consequently, the learning agent (i) avoids storing past states where previous actions may affect the current state, (ii) is without waiting a long interval until the current action has been fully effective and reflected in the system's specific metrics, and more importantly, (iii) is able to adapt multiple stream applications in multiple scenarios. We deploy the rate control approach on three applications, and the experimental results demonstrate that the throughput and end-to-end latency are improved by up to 13.5% and 30%, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11710v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziren Xiao</dc:creator>
    </item>
    <item>
      <title>Adaptive determinantal scheduling with fairness in wireless networks</title>
      <link>https://arxiv.org/abs/2506.11738</link>
      <description>arXiv:2506.11738v1 Announce Type: new 
Abstract: We propose a novel framework for wireless network scheduling with fairness using determinantal (point) processes. Our approach incorporates the repulsive nature of determinantal processes, generalizing traditional Aloha protocols that schedule transmissions independently. We formulate the scheduling problem with an utility function representing fairness. We then recast this formulation as a convex optimization problem over a certain class of determinantal point processes called $L$-ensembles, which are particularly suited for statistical and numerical treatments. These determinantal processes, which have already proven valuable in subset learning, offer an attractive approach to network resource scheduling and allocating. We demonstrate the suitability of determinantal processes for network models based on the signal-to-interference-plus-noise ratio (SINR). Our results highlight the potential of determinantal scheduling coupled with fairness. This work bridges recent advances in machine learning with wireless communications, providing a mathematically elegant and computationally tractable approach to network scheduling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11738v1</guid>
      <category>cs.NI</category>
      <category>cs.DS</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H. P. Keeler, B. B{\l}aszczyszyn</dc:creator>
    </item>
    <item>
      <title>Enabling Next-Generation Cloud-Connected Bionic Limbs Through 5G Connectivity</title>
      <link>https://arxiv.org/abs/2506.11744</link>
      <description>arXiv:2506.11744v1 Announce Type: new 
Abstract: Despite the recent advancements in human-machine interfacing, contemporary assistive bionic limbs face critical challenges, including limited computational capabilities, high latency, and unintuitive control mechanisms, leading to suboptimal user experience and abandonment rates. Addressing these challenges requires a shift toward intelligent, interconnected solutions powered by advances in Internet of Things systems, particularly wireless connectivity and edge/cloud computing. This article presents a conceptual approach to transform bionic limbs by harnessing the pervasive connectivity of 5G and the significant computational power of cloud and edge servers, equipping them with capabilities not available hitherto. The system leverages a hierarchical distributed-computing architecture that integrates local, edge, and cloud computing layers. Time-critical tasks are handled by a local processing unit, while compute-intensive tasks are offloaded to edge and cloud servers, leveraging the high data rate, reliable and low latency capabilities of advanced cellular networks. We perform a proof-of-concept validation in a 5G testbed showing that such networks are capable of achieving data rates and fulfilling latency requirements for a natural prosthetic control, allowing for offloading of compute-intensive jobs to the edge/cloud servers. This is the first step towards the realization and real-world validation of cloud-connected bionic limb systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11744v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ozan Karaali, Hossam Farag, Strahinja Dosen, Cedomir Stefanovic</dc:creator>
    </item>
    <item>
      <title>The Throughput Gain of Hypercycle-level Resource Reservation for Time-Triggered Ethernet</title>
      <link>https://arxiv.org/abs/2506.11745</link>
      <description>arXiv:2506.11745v1 Announce Type: new 
Abstract: Time-Triggered Communication is a key technology for many safety-critical systems, with applications spanning the areas of aerospace and industrial control. Such communication relies on time-triggered flows, with each flow consisting of periodic packets originating from a source and destined for a destination node. Each packet needs to reach its destination before its deadline. Different flows can have different cycle lengths. To achieve assured transmission of time-triggered flows, existing efforts constrain the packets of a flow to be cyclically transmitted along the same path. Under such Fixed Cyclic Scheduling (FCS), reservation for flows with different cycle lengths can become incompatible over a shared link, limiting the total number of admissible flows. Considering the cycle lengths of different flows, a hyper-cycle has length equal to their least common multiple (LCM). It determines the time duration over which the scheduling compatibility of the different flows can be checked. In this work, we propose a more flexible schedule scheme called the Hypercycle-level Flexible Schedule (HFS) scheme, where a flow's resource reservation can change across cycles within a hypercycle. HFS can significantly increase the number of admitted flows by providing more scheduling options while remaining perfectly compatible with existing Time-Triggered Ethernet system. We show that, theoretically the possible capacity gain provided by HFS over FCS can be unbounded. We formulate the joint pathfinding and scheduling problem under HFS as an ILP problem which we prove to be NP-Hard. To solve HFS efficiently, we further propose a least-load-first heuristic (HFS-LLF), solving HFS as a sequence of shortest path problems. Extensive study shows that HFS admits up to 6 times the number of flows achieved by FCS. Moreover, our proposed HFS-LLF can run 104 times faster than solving HFS using a generic solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11745v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Wang, Suman Sourav, Binbin Chen, Hongyan Li, Feng Wang, Fan Zhang</dc:creator>
    </item>
    <item>
      <title>Distributed Learning for Reliable and Timely Communication in 6G Industrial Subnetworks</title>
      <link>https://arxiv.org/abs/2506.11749</link>
      <description>arXiv:2506.11749v1 Announce Type: new 
Abstract: Emerging 6G industrial networks envision autonomous in-X subnetworks to support efficient and cost-effective short range, localized connectivity for autonomous control operations. Supporting timely transmission of event-driven, critical control traffic is challenging in such networks is challenging due to limited radio resources, dynamic device activity, and high mobility. In this paper, we propose a distributed, learning-based random access protocol that establishes implicit inter-subnetwork coordination to minimize the collision probability and improves timely delivery. Each subnetwork independently learns and selects access configurations based on a contention signature signal broadcast by a central access point, enabling adaptive, collision-aware access under dynamic traffic and mobility conditions. The proposed approach features lightweight neural models and online training, making it suitable for deployment in constrained industrial subnetworks. Simulation results show that our method significantly improves the probability of timely packet delivery compared to baseline methods, particularly in dense and high-load scenarios. For instance, our proposed method achieves 21% gain in the probability of timely packet delivery compared to a classical Multi-Armed Bandit (MAB) for an industrial setting of 60 subnetworks and 5 radio channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11749v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samira Abdelrahman, Hossam Farag, Gilberto Berardinelli</dc:creator>
    </item>
    <item>
      <title>A Tale of Two Mobile Generations: 5G-Advanced and 6G in 3GPP Release 20</title>
      <link>https://arxiv.org/abs/2506.11828</link>
      <description>arXiv:2506.11828v1 Announce Type: new 
Abstract: As the telecommunications industry stands at the crossroads between the fifth generation (5G) and sixth generation (6G) of mobile communications, the 3rd generation partnership project (3GPP) Release 20 emerges as a pivotal point of transition. By striking a balance between enhancing 5G-Advanced capabilities and setting the stage for 6G, Release 20 provides the crucial foundation upon which future mobile communication standards and deployments will be built. This article examines these dual objectives, outlining the key enhancements, the motivations behind them, and their implications for the future of mobile communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11828v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingqin Lin</dc:creator>
    </item>
    <item>
      <title>Intractable Cookie Crumbs: Unveiling the Nexus of Stateful Banner Interaction and Tracking Cookies</title>
      <link>https://arxiv.org/abs/2506.11947</link>
      <description>arXiv:2506.11947v1 Announce Type: new 
Abstract: In response to the ePrivacy Directive and the consent requirements introduced by the GDPR, websites began deploying consent banners to obtain user permission for data collection and processing. However, due to shared third-party services and technical loopholes, non-consensual cross-site tracking can still occur. In fact, contrary to user expectations of seemingly isolated consent, a user's decision on one website may affect tracking behavior on others. In this study, we investigate the technical and behavioral mechanisms behind these discrepancies. Specifically, we disclose a persistent tracking mechanism exploiting web cookies. These cookies, which we refer to as intractable, are initially set on websites with accepted banners, persist in the browser, and are subsequently sent to trackers before the user provides explicit consent on other websites. To meticulously analyze this covert tracking behavior, we conduct an extensive measurement study performing stateful crawls on over 20k domains from the Tranco top list, strategically accepting banners in the first half of domains and measuring intractable cookies in the second half. Our findings reveal that around 50% of websites send at least one intractable cookie, with the majority set to expire after more than 10 days. In addition, enabling the Global Privacy Control (GPC) signal initially reduces the number of intractable cookies by 30% on average, with a further 32% reduction possible on subsequent visits by rejecting the banners. Moreover, websites with Consent Management Platform (CMP) banners, on average, send 6.9 times more intractable cookies compared to those with native banners. Our research further reveals that even if users reject all other banners, they still receive a large number of intractable cookies set by websites with cookie paywalls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11947v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 25th Privacy Enhancing Technologies Symposium (PETS 2025)</arxiv:journal_reference>
      <dc:creator>Ali Rasaii, Ha Dao, Anja Feldmann, Mohammadmadi Javid, Oliver Gasser, Devashish Gosain</dc:creator>
    </item>
    <item>
      <title>Minimum-hop Constellation Design for Low Earth Orbit Satellite Networks</title>
      <link>https://arxiv.org/abs/2506.11995</link>
      <description>arXiv:2506.11995v1 Announce Type: new 
Abstract: We consider a Low Earth Orbit (LEO) satellite network with each satellite capable of establishing inter-satellite link (ISL) connections for satellite-to-satellite communication. Since ISLs can be reoriented to change the topology, we optimize the topology to minimize the average shortest path length (ASPL). We characterize the optimal ASPL ISL topology in two families of topologies, 1) vertex-symmetric in which the ISL connections at a satellite node represent a motif that is repeated at all other satellite nodes, and 2) general regular topologies in which no such repeating pattern need exist. We establish ASPL lower bounds for both scenarios and show constructions for which they are achievable assuming each satellite makes 3 or 4 ISL connections. For the symmetric case, we show that the mesh grid is suboptimal in both ASPL and diameter. Additionally, we show there are constructions that maintain intra-orbital ISL connections while still achieving near-optimal ASPL performance. For the general case we show it is possible to construct networks with ASPL close to the general lower bound when the network is sufficiently dense. Simulation results show that for both scenarios, one can find topologies that are very close to the lower bounds as the network size scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11995v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chirag Rao, Eytan Modiano</dc:creator>
    </item>
    <item>
      <title>Upgrade or Switch: Do We Need a New Registry Architecture for the Internet of AI Agents?</title>
      <link>https://arxiv.org/abs/2506.12003</link>
      <description>arXiv:2506.12003v1 Announce Type: new 
Abstract: The emerging Internet of AI Agents challenges existing web infrastructure designed for human-scale, reactive interactions. Unlike traditional web resources, autonomous AI agents initiate actions, maintain persistent state, spawn sub-agents, and negotiate directly with peers: demanding millisecond-level discovery, instant credential revocation, and cryptographic behavioral proofs that exceed current DNS/PKI capabilities. This paper analyzes whether to upgrade existing infrastructure or implement purpose-built registry architectures for autonomous agents. We identify critical failure points: DNS propagation (24-48 hours vs. required milliseconds), certificate revocation unable to scale to trillions of entities, and IPv4/IPv6 addressing inadequate for agent-scale routing. We evaluate three approaches: (1) Upgrade paths, (2) Switch options, (3) Hybrid registries. Drawing parallels to dialup-to-broadband transitions, we find that agent requirements constitute qualitative, and not incremental, changes. While upgrades offer compatibility and faster deployment, clean-slate solutions provide better performance but require longer for adoption. Our analysis suggests hybrid approaches will emerge, with centralized registries for critical agents and federated meshes for specialized use cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12003v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ramesh Raskar, Pradyumna Chari, Jared James Grogan, Mahesh Lambe, Robert Lincourt, Raghu Bala, Abhishek Singh, Ayush Chopra, Rajesh Ranjan, Shailja Gupta, Dimitris Stripelis, Maria Gorskikh, Sichao Wang</dc:creator>
    </item>
    <item>
      <title>Decentralized Uplink Adaptive Compression for Cell-Free MIMO with Limited Fronthaul</title>
      <link>https://arxiv.org/abs/2506.11284</link>
      <description>arXiv:2506.11284v1 Announce Type: cross 
Abstract: We study the problem of uplink compression for cell-free multi-input multi-output networks with limited fronthaul capacity. In compress-forward mode, remote radio heads (RRHs) compress the received signal and forward it to a central unit for joint processing. While previous work has focused on a transform-based approach, which optimizes the transform matrix that reduces signals of high dimension to a static pre-determined lower dimension, we propose a rate-based approach that simultaneously finds both dimension and compression adaptively. Our approach accommodates for changes to network traffic and fronthaul limits. Using mutual information as the objective, we obtain the theoretical network capacity for adaptive compression and decouple the expression to enable decentralization. Furthermore, using channel statistics and user traffic density, we show different approaches to compute an efficient representation of side information that summarizes global channel state information and is shared with RRHs to assist compression. While keeping the information exchange overhead low, our decentralized implementation of adaptive compression shows competitive overall network performance compared to a centralized approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11284v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zehua Li, Jingjie Wei, Raviraj Adve</dc:creator>
    </item>
    <item>
      <title>Jelly: a fast and convenient RDF serialization format</title>
      <link>https://arxiv.org/abs/2506.11298</link>
      <description>arXiv:2506.11298v1 Announce Type: cross 
Abstract: Existing RDF serialization formats such as Turtle, N-Triples, and JSON-LD are widely used for communication and storage in knowledge graph and Semantic Web applications. However, they suffer from limitations in performance, compression ratio, and lack of native support for RDF streams. To address these shortcomings, we introduce Jelly, a fast and convenient binary serialization format for RDF data that supports both batch and streaming use cases. Jelly is designed to maximize serialization throughput, reduce file size with lightweight streaming compression, and minimize compute resource usage. Built on Protocol Buffers, Jelly is easy to integrate with modern programming languages and RDF libraries. To maximize reusability, Jelly has an open protocol specification, open-source implementations in Java and Python integrated with popular RDF libraries, and a versatile command-line tool. To illustrate its usefulness, we outline concrete use cases where Jelly can provide tangible benefits. By combining practical usability with state-of-the-art efficiency, Jelly is an important contribution to the Semantic Web tool stack.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11298v1</guid>
      <category>cs.DB</category>
      <category>cs.NI</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Piotr Sowinski, Karolina Bogacka, Anastasiya Danilenka, Nikita Kozlov</dc:creator>
    </item>
    <item>
      <title>Black-Box Edge AI Model Selection with Conformal Latency and Accuracy Guarantees</title>
      <link>https://arxiv.org/abs/2506.11391</link>
      <description>arXiv:2506.11391v1 Announce Type: cross 
Abstract: Edge artificial intelligence (AI) will be a central part of 6G, with powerful edge servers supporting devices in performing machine learning (ML) inference. However, it is challenging to deliver the latency and accuracy guarantees required by 6G applications, such as automated driving and robotics. This stems from the black-box nature of ML models, the complexities of the tasks, and the interplay between transmitted data quality, chosen inference model, and the random wireless channel. This paper proposes a novel black-box model selection framework for reliable real-time wireless edge AI designed to meet predefined requirements on both deadline violation probability and expected loss. Leveraging conformal risk control and non-parametric statistics, our framework intelligently selects the optimal model combination from a collection of black-box feature-extraction and inference models of varying complexities and computation times. We present both a fixed (relying on channel statistics) and a dynamic (channel-adaptive) model selection scheme. Numerical results validate the framework on a deadline-constrained image classification task while satisfying a maximum misclassification probability requirement. These results indicate that the proposed framework has the potential to provide reliable real-time edge AI services in 6G.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11391v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anders E. Kal{\o}r, Tomoaki Ohtsuki</dc:creator>
    </item>
    <item>
      <title>5G-Enabled Smart Prosthetic Hand: Connectivity Analysis and Assessment</title>
      <link>https://arxiv.org/abs/2506.11729</link>
      <description>arXiv:2506.11729v1 Announce Type: cross 
Abstract: In this paper, we demonstrate a proof-of-concept implementation of a framework for the development of edge-connected prosthetic systems. The framework is composed of a bionic hand equipped with a camera and connected to a Jetson device that establishes a wireless connection to the edge server, processing the received video stream and feeding back the inferred information about the environment. The hand-edge server connection is obtained either through a direct 5G link, where the edge server also functions as a 5G base station, or through a WiFi link. We evaluate the latency of closing the control loop in the system, showing that, in a realistic usage scenario, the connectivity and computation delays combined are well below 125 ms, which falls into the natural control range. To the best of our knowledge, this is the first analysis showcasing the feasibility of a 5G-enabled prosthetic system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11729v1</guid>
      <category>eess.SY</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ozan Karaali, Hossam Farag, Strahinja Dosen, Cedomir Stefanovic</dc:creator>
    </item>
    <item>
      <title>Teleoperated Driving: a New Challenge for 3D Object Detection in Compressed Point Clouds</title>
      <link>https://arxiv.org/abs/2506.11804</link>
      <description>arXiv:2506.11804v1 Announce Type: cross 
Abstract: In recent years, the development of interconnected devices has expanded in many fields, from infotainment to education and industrial applications. This trend has been accelerated by the increased number of sensors and accessibility to powerful hardware and software. One area that significantly benefits from these advancements is Teleoperated Driving (TD). In this scenario, a controller drives safely a vehicle from remote leveraging sensors data generated onboard the vehicle, and exchanged via Vehicle-to-Everything (V2X) communications. In this work, we tackle the problem of detecting the presence of cars and pedestrians from point cloud data to enable safe TD operations. More specifically, we exploit the SELMA dataset, a multimodal, open-source, synthetic dataset for autonomous driving, that we expanded by including the ground-truth bounding boxes of 3D objects to support object detection. We analyze the performance of state-of-the-art compression algorithms and object detectors under several metrics, including compression efficiency, (de)compression and inference time, and detection accuracy. Moreover, we measure the impact of compression and detection on the V2X network in terms of data rate and latency with respect to 3GPP requirements for TD applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11804v1</guid>
      <category>cs.CV</category>
      <category>cs.NI</category>
      <category>eess.IV</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Filippo Bragato, Michael Neri, Paolo Testolina, Marco Giordani, Federica Battisti</dc:creator>
    </item>
    <item>
      <title>EvalNet: A Practical Toolchain for Generation and Analysis of Extreme-Scale Interconnects</title>
      <link>https://arxiv.org/abs/2105.12663</link>
      <description>arXiv:2105.12663v2 Announce Type: replace 
Abstract: The diversity of communication paths in a network - especially non-minimal paths - is a key enabler of performance at extreme scales. We present EvalNet, a toolchain for scalable generation and analysis over 25 important network topologies, such as Slim Fly, PolarFly, and Orthogonal Fat Trees, with a strong focus on path diversity metrics. EvalNet provides an extensive and fine-grained analysis of shortest and non-shortest paths, including their multiplicities, lengths, and interference. It supports exact measurement and visualization of bandwidth and throughput between every router pair, enabling unprecedented insight into routing potential. EvalNet also includes detailed models for construction cost and power consumption, and interfaces seamlessly with established simulators, which we tune to support large-scale evaluations on low-cost hardware. Using EvalNet, we deliver the widest and most comprehensive path diversity study to date, demonstrating how path diversity underpins throughput and scalability, and facilitating progress towards new frontiers in extreme-scale network design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.12663v2</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maciej Besta, Patrick Iff, Marcel Schneider, Nils Blach, Alessandro Maissen, Salvatore Di Girolamo, Jens Domke, Jascha Krattenmacher, Ankit Singla, Kartik Lakhotia, Laura Monroe, Fabrizio Petrini, Robert Gerstenberger, Torsten Hoefler</dc:creator>
    </item>
    <item>
      <title>Graph-Based Floor Separation Using Node Embeddings and Clustering of WiFi Trajectories</title>
      <link>https://arxiv.org/abs/2505.08088</link>
      <description>arXiv:2505.08088v2 Announce Type: replace 
Abstract: Indoor positioning systems (IPSs) are increasingly vital for location-based services in complex multi-storey environments. This study proposes a novel graph-based approach for floor separation using Wi-Fi fingerprint trajectories, addressing the challenge of vertical localization in indoor settings. We construct a graph where nodes represent Wi-Fi fingerprints, and edges are weighted by signal similarity and contextual transitions. Node2Vec is employed to generate low-dimensional embeddings, which are subsequently clustered using K-means to identify distinct floors. Evaluated on the Huawei University Challenge 2021 dataset, our method outperforms traditional community detection algorithms, achieving an accuracy of 68.97\%, an F1-score of 61.99\%, and an Adjusted Rand Index of 57.19\%. By publicly releasing the preprocessed dataset and implementation code, this work contributes to advancing research in indoor positioning. The proposed approach demonstrates robustness to signal noise and architectural complexities, offering a scalable solution for floor-level localization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08088v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rabia Yasa Kostas, Kahraman Kostas</dc:creator>
    </item>
    <item>
      <title>Multi-Level Damage-Aware Graph Learning for Resilient UAV Swarm Networks</title>
      <link>https://arxiv.org/abs/2506.09703</link>
      <description>arXiv:2506.09703v2 Announce Type: replace 
Abstract: Unmanned aerial vehicle (UAV) swarm networks leverage resilient algorithms to address communication network split issues and restore connectivity. However, existing graph learning-based resilient algorithms face over-aggregation and non-convergence problems caused by uneven and sparse topology under massive damage scenarios. To alleviate these problems, we propose a novel Multi-Level Damage-Aware Graph Learning (ML-DAGL) algorithm, which generates recovery trajectories by mining information from destroyed UAVs. We first introduce a Multi-Branch Damage Attention (MBDA) module, which forms a sequence of multi-hop Damage Attentive Graphs (mDAG) with different ranges of receptive fields. Each mDAG links only remaining and damaged nodes to ensure a more even degree distribution for mitigating over-aggregation, and utilizes multi-hop dilation to establish more links for sparse topology enhancement. To resort to the mDAG, we propose a Dilated Graph Convolution Network (DGCN), which generates the optimal recovery trajectories with theoretically proven convergence under massive damage cases. Simulation results show that the proposed algorithm can guarantee the connectivity restoration under large swarm and damage scales, while significantly expediting the recovery time by 75.94% and improving the topology uniformity after recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09703v2</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huan Lin, Chenguang Zhu, Lianghui Ding, Feng Yang</dc:creator>
    </item>
  </channel>
</rss>
