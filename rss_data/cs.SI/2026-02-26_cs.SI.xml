<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Feb 2026 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Toward Effective Multi-Domain Rumor Detection in Social Networks Using Domain-Gated Mixture-of-Experts</title>
      <link>https://arxiv.org/abs/2602.21214</link>
      <description>arXiv:2602.21214v1 Announce Type: new 
Abstract: Social media platforms have become key channels for spreading and tracking rumors due to their widespread accessibility and ease of information sharing. Rumors can continuously emerge across diverse domains and topics, often with the intent to mislead society for personal or commercial gain. Therefore, developing methods that can accurately detect rumors at early stages is crucial to mitigating their negative impact. While existing approaches often specialize in single-domain detection, their performance degrades when applied to new domains due to shifts in data distribution, such as lexical patterns and propagation dynamics. To bridge this gap, this study introduces PerFact, a large-scale multi-domain rumor dataset comprising 8,034 annotated posts from the X platform, annotated into two primary categories: rumor (including true, false, and unverified rumors) and non-rumor. Annotator agreement, measured via Fleiss' Kappa ($\kappa = 0.74$), ensures high-quality labels.
  This research further proposes an effective multi-domain rumor detection model that employs a domain gate to dynamically aggregate multiple feature representations extracted through a Mixture-of-Experts method. Each expert combines CNN and BiLSTM networks to capture local syntactic features and long-range contextual dependencies. By leveraging both textual content and publisher information, the proposed model classifies posts into rumor and non-rumor categories with high accuracy. Evaluations demonstrate state-of-the-art performance, achieving an F1-score of 79.86\% and an accuracy of 79.98\% in multi-domain settings.
  Keywords: Rumor Detection, Multi-Domain, Natural Language Processing, Social Networks, Mixture-of-Experts Model</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21214v1</guid>
      <category>cs.SI</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohadeseh Sheikhqoraei, Zainabolhoda Heshmati, Zeinab Rajabi, Leila Rabiei</dc:creator>
    </item>
    <item>
      <title>@GrokSet: multi-party Human-LLM Interactions in Social Media</title>
      <link>https://arxiv.org/abs/2602.21236</link>
      <description>arXiv:2602.21236v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are increasingly deployed as active participants on public social media platforms, yet their behavior in these unconstrained social environments remains largely unstudied. Existing datasets, drawn primarily from private chat interfaces, lack the multi-party dynamics and public visibility crucial for understanding real-world performance. To address this gap, we introduce @GrokSet, a large-scale dataset of over 1 million tweets involving the @Grok LLM on X. Our analysis reveals a distinct functional shift: rather than serving as a general assistant, the LLM is frequently invoked as an authoritative arbiter in high-stakes, polarizing political debates. However, we observe a persistent engagement gap: despite this visibility, the model functions as a low-status utility, receiving significantly less social validation (likes, replies) than human peers. Finally, we find that this adversarial context exposes shallow alignment: users bypass safety filters not through complex jailbreaks, but through simple persona adoption and tone mirroring. We release @GrokSet as a critical resource for studying the intersection of AI agents and societal discourse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21236v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Migliarini, Berat Ercevik, Oluwagbemike Olowe, Saira Fatima, Sarah Zhao, Minh Anh Le, Vasu Sharma, Ashwinee Panda</dc:creator>
    </item>
    <item>
      <title>PPCR-IM: A System for Multi-layer DAG-based Public Policy Consequence Reasoning and Social Indicator Mapping</title>
      <link>https://arxiv.org/abs/2602.21650</link>
      <description>arXiv:2602.21650v1 Announce Type: new 
Abstract: Public policy decisions are typically justified using a narrow set of headline indicators, leaving many downstream social impacts unstructured and difficult to compare across policies. We propose PPCR-IM, a system for multi-layer DAG-based consequence reasoning and social indicator mapping that addresses this gap. Given a policy description and its context, PPCR-IM uses an LLM-driven, layer-wise generator to construct a directed acyclic graph of intermediate consequences, allowing child nodes to have multiple parents to capture joint influences. A mapping module then aligns these nodes to a fixed indicator set and assigns one of three qualitative impact directions: increase, decrease, or ambiguous change. For each policy episode, the system outputs a structured record containing the DAG, indicator mappings, and three evaluation measures: an expected-indicator coverage score, a discovery rate for overlooked but relevant indicators, and a relative focus ratio comparing the systems coverage to that of the government. PPCR-IM is available both as an online demo and as a configurable XLSX-to-JSON batch pipeline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21650v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zichen Song, Weijia Li</dc:creator>
    </item>
    <item>
      <title>RABot: Reinforcement-Guided Graph Augmentation for Imbalanced and Noisy Social Bot Detection</title>
      <link>https://arxiv.org/abs/2602.21749</link>
      <description>arXiv:2602.21749v1 Announce Type: new 
Abstract: Social bot detection is pivotal for safeguarding the integrity of online information ecosystems. Although recent graph neural network (GNN) solutions achieve strong results, they remain hindered by two practical challenges: (i) severe class imbalance arising from the high cost of generating bots, and (ii) topological noise introduced by bots that skillfully mimic human behavior and forge deceptive links. We propose the Reinforcement-guided graph Augmentation social Bot detector (RABot), a multi-granularity graph-augmentation framework that addresses both issues in a unified manner. RABot employs a neighborhood-aware oversampling strategy that linearly interpolates minority-class embeddings within local subgraphs, thereby stabilizing the decision boundary under low-resource regimes. Concurrently, a reinforcement-learning-driven edge-filtering module combines similarity-based edge features with adaptive threshold optimization to excise spurious interactions during message passing, yielding a cleaner topology. Extensive experiments on three real-world benchmarks and four GNN backbones demonstrate that RABot consistently surpasses state-of-the-art baselines. In addition, since its augmentation and filtering modules are orthogonal to the underlying architecture, RABot can be seamlessly integrated into existing GNN pipelines to boost performance with minimal overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21749v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Longlong Zhang, Xi Wang, Haotong Du, Yangyi Xu, Zhuo Liu, Yang Liu</dc:creator>
    </item>
    <item>
      <title>Embedding-aware Polarization Management in Signed Networks</title>
      <link>https://arxiv.org/abs/2602.21755</link>
      <description>arXiv:2602.21755v1 Announce Type: new 
Abstract: Signed network embeddings (SNE) are widely used to represent networks with positive and negative relations, but their repeated use in downstream analysis pipelines can inadvertently reinforce structural polarization. Existing polarization measures are largely designed for unsigned networks or rely on predefined opinion states, limiting their applicability to embedding-based analysis in signed settings. We propose EPM, a unified polarization management framework that jointly measures and mitigates polarization in the embedding space. EPM introduces an embedding-based polarization measure grounded in effective resistance and a structure-aware mitigation strategy via localized augmentation through structurally balanced intermediary nodes. Experiments on real-world signed networks demonstrate that EPM effectively mitigates polarization while preserving task-relevant network structure. The codebase of EPM is available at https://github.com/JeonghanSon/EPM-Embedding-aware-Polarization-Management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21755v1</guid>
      <category>cs.SI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeonghan Son, Kyungsik Han, Yeon-Chang Lee</dc:creator>
    </item>
    <item>
      <title>Bridging Through Absence: How Comeback Researchers Bridge Knowledge Gaps Through Structural Re-emergence</title>
      <link>https://arxiv.org/abs/2602.21926</link>
      <description>arXiv:2602.21926v1 Announce Type: new 
Abstract: Understanding the role of researchers who return to academia after prolonged inactivity, termed "comeback researchers", is crucial for developing inclusive models of scientific careers. This study investigates the structural and semantic behaviors of comeback researchers, focusing on their role in cross-disciplinary knowledge transfer and network reintegration. Using the AMiner citation dataset, we analyze 113,637 early-career researchers and identify 1,425 comeback cases based on a three-year-or-longer publication gap followed by renewed activity. We find that comeback researchers cite 126% more distinct communities and exhibit 7.6% higher bridging scores compared to dropouts. They also demonstrate 74% higher gap entropy, reflecting more irregular yet strategically impactful publication trajectories. Predictive models trained on these bridging- and entropy-based features achieve a 97% ROC-AUC, far outperforming the 54% ROC-AUC of baseline models using traditional metrics like publication count and h-index. Finally, we substantiate these results via a multi-lens validation. These findings highlight the unique contributions of comeback researchers and offer data-driven tools for their early identification and institutional support.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21926v1</guid>
      <category>cs.SI</category>
      <category>cs.DL</category>
      <category>cs.LG</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Somyajit Chakraborty, Angshuman Jana, Avijit Gayen</dc:creator>
    </item>
    <item>
      <title>The Headless Firm: How AI Reshapes Enterprise Boundaries</title>
      <link>https://arxiv.org/abs/2602.21401</link>
      <description>arXiv:2602.21401v1 Announce Type: cross 
Abstract: The boundary of the firm is determined by coordination cost. We argue that agentic AI induces a structural change in how coordination costs scale: in prior modular systems, integration cost grew with interaction topology (O(n^2) in the number of components); in protocol-mediated agentic systems, integration cost collapses to O(n) while verification scales with task throughput rather than interaction count. This shift selects for a specific organizational equilibrium -- the Headless Firm -- structured as an hourglass: a personalized generative interface at the top, a standardized protocol waist in the middle, and a competitive market of micro-specialized execution agents at the bottom. We formalize this claim as a coordination cost model with two falsifiable empirical predictions: (1) the marginal cost of adding an execution provider should be approximately constant in a mature hourglass ecosystem; (2) the ratio of total coordination cost to task throughput should remain stable as ecosystem size grows. We derive conditions for hourglass stability versus re-centralization and analyze implications for firm size distributions, labor markets, and software economics. The analysis predicts a domain-conditional Great Unbundling: in high knowledge-velocity domains, firm size distributions shift mass from large integrated incumbents toward micro-specialized agents and thin protocol orchestrators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.21401v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tassilo Klein, Sebastian Wieczorek</dc:creator>
    </item>
    <item>
      <title>EpidemIQs: Prompt-to-Paper LLM Agents for Epidemic Modeling and Analysis</title>
      <link>https://arxiv.org/abs/2510.00024</link>
      <description>arXiv:2510.00024v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) offer new opportunities to accelerate complex interdisciplinary research domains. Epidemic modeling, characterized by its complexity and reliance on network science, dynamical systems, epidemiology, and stochastic simulations, represents a prime candidate for leveraging LLM-driven automation. We introduce EpidemIQs, a novel multi-agent LLM framework that integrates user inputs and autonomously conducts literature review, analytical derivation, network modeling, mechanistic modeling, stochastic simulations, data visualization and analysis, and finally documentation of findings in a structured manuscript, through five predefined research phases. We introduce two types of agents: a scientist agent for planning, coordination, reflection, and generation of final results, and a task-expert agent to focus exclusively on one specific duty serving as a tool to the scientist agent. The framework consistently generated complete reports in scientific article format. Specifically, using GPT 4.1 and GPT 4.1 Mini as backbone LLMs for scientist and task-expert agents, respectively, the autonomous process completes with average total token usage 870K at a cost of about $1.57 per study, successfully executing all phases and final report. We evaluate EpidemIQs across several different epidemic scenarios, measuring computational cost, workflow reliability, task success rate, and LLM-as-Judge and human expert reviews to estimate the overall quality and technical correctness of the generated results. Through our experiments, the framework consistently addresses evaluation scenarios with an average task success rate of 79%. We compare EpidemIQs to an iterative single-agent LLM, benefiting from the same system prompts and tools, iteratively planning, invoking tools, and revising outputs until task completion. The comparisons suggest a consistently higher performance of EpidemIQs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00024v2</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Hossein Samaei, Faryad Darabi Sahneh, Lee W. Cohnstaedt, Caterina Scoglio</dc:creator>
    </item>
    <item>
      <title>Hyperactive Minority Alters the Stability of Community Notes</title>
      <link>https://arxiv.org/abs/2602.08970</link>
      <description>arXiv:2602.08970v2 Announce Type: replace 
Abstract: As platforms increasingly scale down professional fact-checking, community-based alternatives are promoted as more transparent and democratic. The main substitute being proposed is community-based contextualization, most notably Community Notes on X, where users write annotations and collectively rate their helpfulness under a consensus-oriented algorithm. This shift raises a basic empirical question: to what extent do users' social dynamics affect the emergence of Community Notes? We address this question by characterizing participation and political behavior, using the full public release of notes and ratings (between 2021 and 2025). We show that contribution activity is highly concentrated: a small minority of users accounts for a disproportionate share of ratings. Crucially, these high-activity contributors are not neutral volunteers: they are selective in the content they engage with and substantially more politically polarized than the overall contributor population. We replicate the notes' emergence process by integrating the open-source implementation of the Community Notes consensus algorithm used in production. This enables us to conduct counterfactual simulations that modify the display status of notes by varying the pool of raters. Our results reveal that the system is structurally unstable: the emergence and visibility of notes often depend on the behavior of a few dozen highly active users, and even minor perturbations in their participation can lead to markedly different outcomes. In sum, rather than decentralizing epistemic authority, community-based fact-checking on X reconfigures it, concentrating substantial power in the hands of a small, polarized group of highly active contributors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08970v2</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacopo Nudo, Eugenio Nerio Nemmi, Edoardo Loru, Alessandro Mei, Walter Quattrociocchi, Matteo Cinelli</dc:creator>
    </item>
    <item>
      <title>How segmented is my network?</title>
      <link>https://arxiv.org/abs/2602.10125</link>
      <description>arXiv:2602.10125v3 Announce Type: replace 
Abstract: Network segmentation is a popular security practice for limiting lateral movement, yet practitioners lack a metric to measure how segmented a network actually is. We introduce the first statistically principled metric for network segmentedness based on global edge density, enabling practitioners to quantify what has previously been assessed only qualitatively. Then, we derive a normalized estimator for segmentedness and evaluate its uncertainty using confidence intervals. For a 95\% confidence interval with a margin-of-error of $\pm 0.1$, we show that a minimum of $M=97$ sampled node pairs is sufficient. This result is independent of the total number of nodes in the network, provided that node pairs are sampled uniformly at random. We evaluate the estimator through Monte Carlo simulations on Erd\H{o}s--R\'enyi, stochastic block models, and real-world enterprise network datasets, demonstrating accurate estimation and well-behaved coverage. Finally, we discuss applications of the estimator, such as baseline tracking, zero trust assessment, and merger integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10125v3</guid>
      <category>cs.SI</category>
      <category>cs.NI</category>
      <category>stat.AP</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohit Dube</dc:creator>
    </item>
    <item>
      <title>A Comparative Analysis of Social Network Topology in Reddit and Moltbook</title>
      <link>https://arxiv.org/abs/2602.13920</link>
      <description>arXiv:2602.13920v3 Announce Type: replace 
Abstract: Recent advances in agent-mediated systems have enabled a new paradigm of social network simulation, where AI agents interact with human-like autonomy. This evolution has fostered the emergence of agent-driven social networks such as Moltbook, a Reddit-like platform populated entirely by AI agents. Despite these developments, empirical comparisons between agent-driven and human-driven social networks remain scarce, limiting our understanding of how their network topologies might diverge. This paper presents the first comparative analysis of network topology on Moltbook, utilizing a comment network comprising 33,577 nodes and 697,688 edges. To provide a benchmark, we curated a parallel dataset from Reddit consisting of 7.8 million nodes and 51.8 million edges. We examine key structural differences between agent-drive and human-drive networks, specifically focusing on topological patterns and the edge formation efficacy of their respective posts. Our findings provide a foundational profile of AI-driven social structures, serving as a preliminary step toward developing more robust and authentic agent-mediated social systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13920v3</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yiming Zhu, Gareth Tyson, Pan Hui</dc:creator>
    </item>
    <item>
      <title>On the Impact of Sample Size in Reconstructing Noisy Graph Signals: A Theoretical Characterisation</title>
      <link>https://arxiv.org/abs/2406.16816</link>
      <description>arXiv:2406.16816v3 Announce Type: replace-cross 
Abstract: Reconstructing a signal on a graph from noisy observations of a subset of the vertices is a fundamental problem in the field of graph signal processing. This paper investigates how sample size affects reconstruction error in the presence of noise via an in-depth theoretical analysis of the two most common reconstruction methods in the literature, least-squares reconstruction (LS) and graph-Laplacian regularised reconstruction (GLR). Our theorems show that at sufficiently low signal-to-noise ratios (SNRs), under these reconstruction methods we may simultaneously decrease sample size and decrease average reconstruction error. We further show that at sufficiently low SNRs, for LS reconstruction we have a $\Lambda$-shaped error curve and for GLR reconstruction, a sample size of $ O(\sqrt{N})$, where $N$ is the total number of vertices, results in lower reconstruction error than near full observation. We present thresholds on the SNRs, $\tau$ and $\tau_{GLR}$, below which the error is non-monotonic, and illustrate these theoretical results with experiments across multiple random graph models, sampling schemes and SNRs. These results demonstrate that any decision in sample-size choice has to be made in light of the noise levels in the data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16816v3</guid>
      <category>eess.SP</category>
      <category>cs.SI</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baskaran Sripathmanathan, Xiaowen Dong, Michael Bronstein</dc:creator>
    </item>
    <item>
      <title>Some Simple Economics of AGI</title>
      <link>https://arxiv.org/abs/2602.20946</link>
      <description>arXiv:2602.20946v2 Announce Type: replace-cross 
Abstract: For millennia, human cognition was the primary engine of progress on Earth. As AI decouples cognition from biology, the marginal cost of measurable execution falls to zero, absorbing any labor capturable by metrics--including creative, analytical, and innovative work. The binding constraint on growth is no longer intelligence but human verification bandwidth: the capacity to validate, audit, and underwrite responsibility when execution is abundant. We model the AGI transition as the collision of two racing cost curves: an exponentially decaying Cost to Automate and a biologically bottlenecked Cost to Verify. This structural asymmetry widens a Measurability Gap between what agents can execute and what humans can afford to verify. It also drives a shift from skill-biased to measurability-biased technical change. Rents migrate to verification-grade ground truth, cryptographic provenance, and liability underwriting--the ability to insure outcomes rather than merely generate them. The current human-in-the-loop equilibrium is unstable: eroded from below as apprenticeship collapses (Missing Junior Loop) and from within as experts codify their obsolescence (Codifier's Curse). Unverified deployment becomes privately rational--a Trojan Horse externality. Unmanaged, these forces pull toward a Hollow Economy. Yet by scaling verification alongside agentic capabilities, the forces that threaten collapse become the catalyst for unbounded discovery and experimentation--an Augmented Economy. We derive a practical playbook for individuals, companies, investors, and policymakers. Today's defining challenge is not the race to deploy the most autonomous systems; it is the race to secure the foundations of their oversight. Only by scaling our bandwidth for verification alongside our capacity for execution can we ensure that the intelligence we have summoned preserves the humanity that initiated it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20946v2</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 26 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Catalini, Xiang Hui, Jane Wu</dc:creator>
    </item>
  </channel>
</rss>
