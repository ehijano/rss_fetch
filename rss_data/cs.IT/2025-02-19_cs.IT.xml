<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Feb 2025 02:39:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Energy-Efficient Flat Precoding for MIMO Systems</title>
      <link>https://arxiv.org/abs/2502.12343</link>
      <description>arXiv:2502.12343v1 Announce Type: new 
Abstract: This paper addresses the suboptimal energy efficiency of conventional digital precoding schemes in multiple-input multiple-output (MIMO) systems. Through an analysis of the power amplifier (PA) output power distribution associated with conventional precoders, it is observed that these power distributions can be quite uneven, resulting in large PA backoff (thus low efficiency) and high power consumption. To tackle this issue, we propose a novel approach called flat precoding, which aims to control the flatness of the power distribution within a desired interval. In addition to reducing PA power consumption, flat precoding offers the advantage of requiring smaller saturation levels for PAs, which reduces the size of PAs and lowers the cost. To incorporate the concept of flat power distribution into precoding design, we introduce a new lower-bound per-antenna power constraint alongside the conventional sum power constraint and the upper-bound per-antenna power constraint. By adjusting the lower-bound and upper-bound values, we can effectively control the level of flatness in the power distribution. We then seek to find a flat precoder that satisfies these three sets of constraints while maximizing the weighted sum rate (WSR). In particular, we develop efficient algorithms to design weighted minimum mean squared error (WMMSE) and zero-forcing (ZF)-type precoders with controllable flatness features that maximize WSR. Numerical results demonstrate that complete flat precoding approaches, where the power distribution is a straight line, achieve the best trade-off between spectral efficiency and energy efficiency for existing PA technologies. We also show that the proposed ZF and WMMSE precoding methods can approach the performance of their conventional counterparts with only the sum power constraint, while significantly reducing PA size and power consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12343v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TSP.2025.3537960</arxiv:DOI>
      <dc:creator>Foad Sohrabi, Carl Nuzman, Jinfeng Du, Hong Yang, Harish Viswanathan</dc:creator>
    </item>
    <item>
      <title>On the Performance of Uplink Pinching Antenna Systems (PASS)</title>
      <link>https://arxiv.org/abs/2502.12365</link>
      <description>arXiv:2502.12365v1 Announce Type: new 
Abstract: Pinching antenna (PA) is a flexible antenna composed of a waveguide and multiple dielectric particles, which is capable of reconfiguring wireless channels intelligently in line-of-sight links. By leveraging the unique features of PAs, we exploit the uplink (UL) transmission in pinching antenna systems (PASS). To comprehensively evaluate the performance gains of PASS in UL transmissions, three scenarios, multiple PAs for a single user (MPSU), a single PA for a single user (SPSU), and a single PA for multiple users (SPMU) are considered. The positions of PAs are optimized to obtain the maximal channel gains in the considered scenarios. For the MPSU and SPSU scenarios, by applying the optimized position of PAs, closed-form expressions for analytical, asymptotic and approximated ergodic rate are derived. As the further advance, closed-form expressions of approximated ergodic rate is derived when a single PA is fixed in the SPMU scenario. Our results demonstrate the following key insights: i) The proposed PASS significantly outperforms conventional Multiple-input Single-output networks by exploiting the flexibility of PAs; ii) The PA distribution follows an asymmetric non-uniform distribution in the MPSU scenario; iii) Optimizing PA positions significantly enhances the ergodic sum rate performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12365v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianwei Hou, Yuanwei Liu, Arumugam Nallanathan</dc:creator>
    </item>
    <item>
      <title>Optimal and Almost Optimal Locally Repairable Codes from Hyperelliptic Curves</title>
      <link>https://arxiv.org/abs/2502.12493</link>
      <description>arXiv:2502.12493v1 Announce Type: new 
Abstract: Locally repairable codes are widely applicable in contemporary large-scale distributed cloud storage systems and various other areas. By making use of some algebraic structures of elliptic curves, Li et al. developed a series of $q$-ary optimal locally repairable codes with lengths that can extend to $q+2\sqrt{q}$. In this paper, we generalize their methods to hyperelliptic curves of genus $2$, resulting in the construction of several new families of $q$-ary optimal or almost optimal locally repairable codes. Our codes feature lengths that can approach $q+4\sqrt{q}$, and the locality can reach up to $239$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12493v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junjie Huang, Chang-An Zhao</dc:creator>
    </item>
    <item>
      <title>New Constant Dimension Codes From the Inserting Mixed Dimension Construction and Multilevel Construction</title>
      <link>https://arxiv.org/abs/2502.12518</link>
      <description>arXiv:2502.12518v1 Announce Type: new 
Abstract: Constant dimension codes (CDCs) are essential for error correction in random network coding. A fundamental problem of CDCs is to determine their maximal possible size for given parameters. Inserting construction and multilevel construction are two effective techniques for constructing CDCs. We first provide a sufficient condition for a subspace to be added to the code from the mixed dimension construction in Lao et al. (IEEE Trans. Inf. Theory 69(7): 4333-4344, 2023). By appropriately combining matrix blocks from small CDCs and rank-metric codes, we introduce three inserting constructions based on the mixed dimension construction. Furthermore, the mixed dimension construction and these inserting constructions are improved by the multilevel construction that is based on lifting rank-restricted Ferrers diagram rank-metric codes. Our constructions yield some new lower bounds for CDCs, which are superior to the previously best-known ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12518v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Li, Fang-Wei Fu</dc:creator>
    </item>
    <item>
      <title>Rate Maximization for Downlink Pinching-Antenna Systems</title>
      <link>https://arxiv.org/abs/2502.12629</link>
      <description>arXiv:2502.12629v1 Announce Type: new 
Abstract: In this letter, we consider a new type of flexible-antenna system, termed pinching-antenna, where multiple low-cost pinching antennas, realized by activating small dielectric particles on a dielectric waveguide, are jointly used to serve a single-antenna user. Our goal is to maximize the downlink transmission rate by optimizing the locations of the pinching antennas. However, these locations affect both the path losses and the phase shifts of the user's effective channel gain, making the problem challenging to solve. To address this challenge and solve the problem in a low complexity manner, a relaxed optimization problem is developed that minimizes the impact of path loss while ensuring that the received signals at the user are constructive. This approach leads to a two-stage algorithm: in the first stage, the locations of the pinching antennas are optimized to minimize the large-scale path loss; in the second stage, the antenna locations are refined to maximize the received signal strength. Simulation results show that pinching-antenna systems significantly outperform conventional fixed-location antenna systems, and the proposed algorithm achieves nearly the same performance as the highly complex exhaustive search-based benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12629v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yanqing Xu, Zhiguo Ding, George K. Karagiannidis</dc:creator>
    </item>
    <item>
      <title>Channel Estimation for Stacked Intelligent Metasurfaces in Rician Fading Channels</title>
      <link>https://arxiv.org/abs/2502.12692</link>
      <description>arXiv:2502.12692v1 Announce Type: new 
Abstract: The recent combination of the rising architectures, known as stacked intelligent metasurface (SIM) and holographic multiple-input multiple-output (HMIMO), drives toward breakthroughs for next-generation wireless communication systems. Given the fact that the number of elements per surface of the SIM is much larger than the base station (BS) antennas, the acquisition of the channel state information (CSI) in SIM-aided multi-user systems is challenging, especially when a line-of-sight (LoS) component is present. Thus, in this letter, we address the channel procedure under conditions of Rician fading by proposing a protocol in terms of a minimum mean square error (MMSE) estimator for wave-based design in a single phase. Moreover, we derive the normalized mean square error (NMSE) of the suggested estimator, and provide the optimal phase shifts minimising the NMSE. Numerical results illustrate the performance of the new channel estimation protocol.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12692v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anastasios Papazafeiropoulos, Pandelis Kourtessis, Dimitra I. Kaklamani, Iakovos S. Venieris</dc:creator>
    </item>
    <item>
      <title>On Zero Skip-Cost Generalized Fractional-Repetition Codes from Covering Designs</title>
      <link>https://arxiv.org/abs/2502.12897</link>
      <description>arXiv:2502.12897v1 Announce Type: new 
Abstract: We study generalized fractional repetition codes that have zero skip cost, and which are based on covering designs. We show that a zero skip cost is always attainable, perhaps at a price of an expansion factor compared with the optimal size of fractional repetition codes based on Steiner systems. We provide three constructions, as well as show non-constructively, that no expansion is needed for all codes based on sufficiently large covering systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12897v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjun Yu, Bo-Jun Yuan, Moshe Schwartz</dc:creator>
    </item>
    <item>
      <title>Symmetric Rank-One Quasi-Newton Methods for Deep Learning Using Cubic Regularization</title>
      <link>https://arxiv.org/abs/2502.12298</link>
      <description>arXiv:2502.12298v1 Announce Type: cross 
Abstract: Stochastic gradient descent and other first-order variants, such as Adam and AdaGrad, are commonly used in the field of deep learning due to their computational efficiency and low-storage memory requirements. However, these methods do not exploit curvature information. Consequently, iterates can converge to saddle points or poor local minima. On the other hand, Quasi-Newton methods compute Hessian approximations which exploit this information with a comparable computational budget. Quasi-Newton methods re-use previously computed iterates and gradients to compute a low-rank structured update. The most widely used quasi-Newton update is the L-BFGS, which guarantees a positive semi-definite Hessian approximation, making it suitable in a line search setting. However, the loss functions in DNNs are non-convex, where the Hessian is potentially non-positive definite. In this paper, we propose using a limited-memory symmetric rank-one quasi-Newton approach which allows for indefinite Hessian approximations, enabling directions of negative curvature to be exploited. Furthermore, we use a modified adaptive regularized cubics approach, which generates a sequence of cubic subproblems that have closed-form solutions with suitable regularization choices. We investigate the performance of our proposed method on autoencoders and feed-forward neural network models and compare our approach to state-of-the-art first-order adaptive stochastic methods as well as other quasi-Newton methods.x</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12298v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditya Ranganath, Mukesh Singhal, Roummel Marcia</dc:creator>
    </item>
    <item>
      <title>The Agafonov and Schnorr-Stimm theorems for probabilistic automata</title>
      <link>https://arxiv.org/abs/2502.12307</link>
      <description>arXiv:2502.12307v1 Announce Type: cross 
Abstract: For a fixed alphabet $A$, an infinite sequence $X$ is said to be normal if every word $w$ over $A$ appears in $X$ with the same frequency as any other word of the same length. A classical result of Agafonov (1966) relates normality to finite automata as follows: a sequence $X$ is normal if and only if any subsequence of $X$ selected by a finite automaton is itself normal. Another theorem of Schnorr and Stimm (1972) gives an alternative characterization: a sequence $X$ is normal if and only if no gambler can win large amounts of money by betting on the sequence $X$ using a strategy that can be described by a finite automaton. Both of these theorems are established in the setting of deterministic finite automata. This raises the question as to whether they can be extended to the setting of probabilistic finite automata. In the case of the Agafonov theorem, this question was positively answered by L\'echine et al.\ (2024) in a restricted case of probabilistic automata with rational transition probabilities.
  In this paper, we settle the full conjecture by proving that both the Agafonov and the Schnorr-Stimm theorems hold true for arbitrary probabilistic automata. Specifically, we show that a sequence $X$ is normal if and only if any probabilistic automaton selects a normal subsequence of $X$ with probability $1$. We also show that a sequence $X$ is normal if and only if a probabilistic finite-state gambler fails to win on $X$ with probability $1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12307v1</guid>
      <category>cs.FL</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laurent Bienvenu, Hugo Gimbert, Subin Pulari</dc:creator>
    </item>
    <item>
      <title>Dependence and Uncertainty: Information Measures using Tsallis Entropy</title>
      <link>https://arxiv.org/abs/2502.12779</link>
      <description>arXiv:2502.12779v1 Announce Type: cross 
Abstract: In multivariate analysis, uncertainty arises from two sources: the marginal distributions of the variables and their dependence structure. Quantifying the dependence structure is crucial, as it provides valuable insights into the relationships among components of a random vector. Copula functions effectively capture this dependence structure independent of marginals, making copula-based information measures highly significant. However, existing copula-based information measures, such as entropy, divergence, and mutual information, rely on copula densities, which may not exist in many scenarios, limiting their applicability. Recently, to address this issue, Arshad et al. (2024) introduced cumulative copula-based measures using Shannon entropy. In this paper, we extend this framework by using Tsallis entropy, a non-additive entropy that provides greater flexibility for quantifying uncertainties. We propose cumulative copula Tsallis entropy, derive its properties and bounds, and illustrate its utility through examples. We further develop a non-parametric version of the measure and validate it using coupled periodic and chaotic maps. Additionally, we extend Kerridge's inaccuracy measure and Kullback-Leibler (KL) divergence to the cumulative copula framework. Using the relationship between KL divergence and mutual information, we propose a new cumulative mutual information (CMI) measure, which outperform the limitations of density-based mutual information. Furthermore, we introduce a test procedure for testing the mutual independence among random variables using CMI measure. Finally, we illustrate the potential of the proposed CMI measure as an economic indicator through real bivariate financial time series data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12779v1</guid>
      <category>stat.ME</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Swaroop Georgy Zachariah, Mohd. Arshad, Ashok Kumar Pathak</dc:creator>
    </item>
    <item>
      <title>A Neural Difference-of-Entropies Estimator for Mutual Information</title>
      <link>https://arxiv.org/abs/2502.13085</link>
      <description>arXiv:2502.13085v1 Announce Type: cross 
Abstract: Estimating Mutual Information (MI), a key measure of dependence of random quantities without specific modelling assumptions, is a challenging problem in high dimensions. We propose a novel mutual information estimator based on parametrizing conditional densities using normalizing flows, a deep generative model that has gained popularity in recent years. This estimator leverages a block autoregressive structure to achieve improved bias-variance trade-offs on standard benchmark tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13085v1</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoran Ni, Martin Lotz</dc:creator>
    </item>
    <item>
      <title>A Unified Algorithmic Framework for Dynamic Compressive Sensing</title>
      <link>https://arxiv.org/abs/2310.07202</link>
      <description>arXiv:2310.07202v2 Announce Type: replace 
Abstract: We propose a unified dynamic tracking algorithmic framework (PLAY-CS) to reconstruct signal sequences with their intrinsic structured dynamic sparsity. By capitalizing on specific statistical assumptions concerning the dynamic filter of the signal sequences, the proposed framework exhibits versatility by encompassing various existing dynamic compressive sensing (DCS) algorithms. This is achieved through the incorporation of a newly proposed Partial-Laplacian filtering sparsity model, tailored to capture a more sophisticated dynamic sparsity. In practical scenarios such as dynamic channel tracking in wireless communications, the framework demonstrates enhanced performance compared to existing DCS algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07202v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.sigpro.2025.109926</arxiv:DOI>
      <dc:creator>Xiaozhi Liu, Yong Xia</dc:creator>
    </item>
    <item>
      <title>Performance Analysis of Near-Field Sensing in Wideband MIMO Systems</title>
      <link>https://arxiv.org/abs/2404.05076</link>
      <description>arXiv:2404.05076v3 Announce Type: replace 
Abstract: The performance of near-field sensing (NISE) in a legacy wideband multiple-input multiple-output (MIMO) orthogonal frequency-division multiplexing (OFDM) communication system is analyzed. The maximum likelihood estimates (MLE) for the target's distance and angle relative to the antenna array are derived. To evaluate the estimation error, closed-form analytical expressions of Cramer-Rao bounds (CRBs) are derived for both uniform linear arrays (ULAs) and uniform circular arrays (UCAs). The asymptotic CRBs are then analyzed to reveal the scaling laws of CRBs with respect to key system parameters, including array size, bandwidth, and target distance. Our results reveal that 1) the mean-squared error achieved by MLEs approaches CRBs in the high signal-to-noise ratio regime; 2) a larger array aperture does not necessarily improve NISE performance, especially with ultra-large bandwidth; 3) large bandwidth sets an estimation error ceiling for NISE as target distance increases; 4) array aperture and bandwidth, rather than the number of antennas and subcarriers, are the key factors affecting wideband NISE performance; and 5) UCAs offer superior, angle-independent wideband NISE performance compared to ULAs with the same aperture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05076v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaolin Wang, Xidong Mu, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>Continuous-Aperture Array (CAPA)-Based Wireless Communications: Capacity Characterization</title>
      <link>https://arxiv.org/abs/2406.15056</link>
      <description>arXiv:2406.15056v2 Announce Type: replace 
Abstract: The capacity limits of continuous-aperture array (CAPA)-based wireless communications are characterized. To this end, an analytically tractable transmission framework is established for both uplink and downlink CAPA systems. Based on this framework, closed-form expressions for the single-user channel capacity are derived. The results are further extended to a multiuser case by characterizing the capacity limits of a two-user channel and proposing the associated capacity-achieving decoding and encoding schemes. In the uplink case, the capacity-achieving detectors and sum-rate capacity are derived, and the capacity region is characterized. In the downlink case, the uplink-downlink duality is established by deriving the uplink-to-downlink and downlink-to-uplink transformations under the same power constraint, based on which the optimal source current distributions and the achieved sum-rate capacity and capacity region are characterized. For comparison, the uplink and downlink sum-rates achieved by the linear zero-forcing scheme are also analyzed. To gain further insights, several case studies are presented by specializing the derived results into various array structures, including the planar CAPA, linear CAPA, and planar spatially discrete array (SPDA). Numerical results are provided to reveal that the channel capacity achieved by CAPAs converges towards a finite upper bound as the aperture size increases; and CAPAs offer superior capacity over the conventional SPDAs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15056v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boqun Zhao, Chongjun Ouyang, Xingqi Zhang, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>Optimal Beamforming for Multi-User Continuous Aperture Array (CAPA) Systems</title>
      <link>https://arxiv.org/abs/2411.14919</link>
      <description>arXiv:2411.14919v3 Announce Type: replace 
Abstract: The optimal beamforming design for multi-user continuous aperture array (CAPA) systems is proposed. In contrast to conventional spatially discrete array (SPDA), the beamformer for CAPA is a continuous function rather than a discrete vector or matrix, rendering beamforming optimization a non-convex integral-based functional programming. To address this challenging issue, the closed-form optimal structure of the CAPA beamformer is first derived for maximizing generic system utility functions, by addressing the inversion of continuous functions and using the Lagrangian duality and the calculus of variations. The derived optimal structure is a linear combination of the continuous channel responses for CAPA, with the linear weights determined by the channel correlations. As a further advance, a monotonic optimization method is proposed for obtaining globally optimal CAPA beamforming based on the derived optimal structure. More particularly, a closed-form fixed-point iteration is proposed to obtain the globally optimal solution to the power minimization problem for CAPA beamforming. Furthermore, based on the optimal structure, the low-complexity maximum ratio transmission (MRT), zero-forcing (ZF), and minimum mean-squared error (MMSE) designs for CAPA beamforming are derived. It is theoretically proved that: 1) the MRT and ZF designs are asymptotically optimal in low and high signal-to-noise ratio (SNR) regimes, respectively, and 2) the MMSE design is optimal for signal-to-leakage-plus-noise ratio (SLNR) maximization. Our numerical results validate the effectiveness of the proposed designs and reveal that: i) CAPA achieves significant communication performance gain over SPDA, and ii) the MMSE design achieves nearly optimal performance in most cases, while the MRT and ZF designs achieve nearly optimal performance in specific cases</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14919v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaolin Wang, Chongjun Ouyang, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>CRC-Assisted Channel Codes for Integrated Passive Sensing and Communications</title>
      <link>https://arxiv.org/abs/2411.05531</link>
      <description>arXiv:2411.05531v2 Announce Type: replace-cross 
Abstract: We propose a novel coded integrated passive sensing and communication (CIPSAC) system with orthogonal frequency division multiplexing (OFDM), where a multi-antenna base station (BS) passively senses the parameters of the targets and decodes the information bit sequences transmitted by a user. The transmitted signal is comprised of pilot and data OFDM symbols where the data symbols adopt cyclic redundancy check (CRC)-assisted channel codes to facilitate both the decoding and sensing procedures. In the proposed scheme, CRC not only enhances the reliability of communication but also provides guidance to the parameter sensing procedure at the BS. In particular, a novel iterative parameter sensing and channel decoding (IPSCD) algorithm is proposed, where the correctly decoded codewords that pass CRC are utilized for sensing to improve the parameter estimation accuracy, and in return, more accurate parameter estimates lead to a larger number of correctly decoded data symbols. Conventional sensing algorithms rely only on the received pilot signals, while we utilize both the data and pilot signals for sensing. We provide a detailed analysis of the optimal strategy, in which the wrongly decoded data packets are replaced by zero codewords. To further improve the performance, we introduce learning-based near-orthogonal superposition (NOS) codes, which exhibit superior error correction capability especially in the short block length regime. NOS codes are trained using a weighted loss function, where a hyper parameter is introduced to balance the sensing and the communication losses. Simulation results show the effectiveness of the proposed CIPSAC system and the IPSCD algorithm, where both the sensing and decoding performances are significantly improved with a few iterations. We also carry out extensive ablation studies for a comprehensive understanding of the proposed scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05531v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Chenghong Bian, Kaitao Meng, Huihui Wu, Yumeng Zhang, Deniz Gunduz</dc:creator>
    </item>
    <item>
      <title>Structured Sampling for Robust Euclidean Distance Geometry</title>
      <link>https://arxiv.org/abs/2412.10664</link>
      <description>arXiv:2412.10664v2 Announce Type: replace-cross 
Abstract: This paper addresses the problem of estimating the positions of points from distance measurements corrupted by sparse outliers. Specifically, we consider a setting with two types of nodes: anchor nodes, for which exact distances to each other are known, and target nodes, for which complete but corrupted distance measurements to the anchors are available. To tackle this problem, we propose a novel algorithm powered by Nystr\"om method and robust principal component analysis. Our method is computationally efficient as it processes only a localized subset of the distance matrix and does not require distance measurements between target nodes. Empirical evaluations on synthetic datasets, designed to mimic sensor localization, and on molecular experiments, demonstrate that our algorithm achieves accurate recovery with a modest number of anchors, even in the presence of high levels of sparse outliers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10664v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chandra Kundu, Abiy Tasissa, HanQin Cai</dc:creator>
    </item>
    <item>
      <title>Algorithmic causal structure emerging through compression</title>
      <link>https://arxiv.org/abs/2502.04210</link>
      <description>arXiv:2502.04210v2 Announce Type: replace-cross 
Abstract: We explore the relationship between causality, symmetry, and compression. We build on and generalize the known connection between learning and compression to a setting where causal models are not identifiable. We propose a framework where causality emerges as a consequence of compressing data across multiple environments. We define algorithmic causality as an alternative definition of causality when traditional assumptions for causal identifiability do not hold. We demonstrate how algorithmic causal and symmetric structures can emerge from minimizing upper bounds on Kolmogorov complexity, without knowledge of intervention targets. We hypothesize that these insights may also provide a novel perspective on the emergence of causality in machine learning models, such as large language models, where causal relationships may not be explicitly identifiable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04210v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Wendong, Simon Buchholz, Bernhard Sch\"olkopf</dc:creator>
    </item>
    <item>
      <title>Interactive Inference: A Neuromorphic Theory of Human-Computer Interaction</title>
      <link>https://arxiv.org/abs/2502.05935</link>
      <description>arXiv:2502.05935v2 Announce Type: replace-cross 
Abstract: Neuromorphic HCI is a new theoretical approach to designing better UX inspired by the neurophysiology of the brain. Here, we apply the neuroscientific theory of Active Inference to HCI, postulating that users perform Bayesian inference on progress and goal distributions to predict their next action (Interactive Inference). We show how Bayesian surprise between goal and progress distributions follows a mean square error function of the signal-to-noise ratio (SNR) of the task. However, capacity to process Bayesian surprise follows the logarithm of SNR, and errors occur when average capacity is exceeded. Our model allows the quantitative analysis of performance and error in one framework with real-time estimation of mental load. We show through mathematical theorems how three basic laws of HCI, Hick's Law, Fitts' Law and the Power Law fit our model. We then test the validity of the general model by empirically measuring how well it predicts human performance in a car following task. Results suggest that driver processing capacity indeed is a logarithmic function of the SNR of the distance to a lead car. This positive result provides initial evidence that Interactive Interference can work as a new theoretical underpinning for HCI, deserving further exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05935v2</guid>
      <category>cs.HC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roel Vertegaal, Timothy Merritt, Saul Greenberg, Aneesh P. Tarun, Zhen Li, Zafeiros Fountas</dc:creator>
    </item>
    <item>
      <title>A Zero-Knowledge Proof for the Syndrome Decoding Problem in the Lee Metric</title>
      <link>https://arxiv.org/abs/2502.11641</link>
      <description>arXiv:2502.11641v2 Announce Type: replace-cross 
Abstract: The syndrome decoding problem is one of the NP-complete problems lying at the foundation of code-based cryptography. The variant thereof where the distance between vectors is measured with respect to the Lee metric, rather than the more commonly used Hamming metric, has been analyzed recently in several works due to its potential relevance for building more efficient code-based cryptosystems. The purpose of this article is to describe a zero-knowledge proof for this variant of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11641v2</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mladen Kova\v{c}evi\'c, Tatjana Grbi\'c, Darko \v{C}apko, Nemanja Nedi\'c, Srdjan Vukmirovi\'c</dc:creator>
    </item>
  </channel>
</rss>
