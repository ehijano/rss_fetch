<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Oct 2025 01:49:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On hypoellipticity of degenerate operators in testing and detection problems</title>
      <link>https://arxiv.org/abs/2510.22150</link>
      <description>arXiv:2510.22150v1 Announce Type: new 
Abstract: We study a class of degenerate diffusion generators that arise in sequential testing and quickest detection problems with partial information. The observation process is driven by $k$ independent Brownian motions, while the hidden state takes $n+1$ values with $k&lt;n$. By moving to the posterior likelihood coordinates, we analyze the H\"omander's condition of the operator both without state switching (testing) and with switching (detection). We characterize the cases where the operator is hypoelliptic for the former, give two different sufficient conditions for the latter, and discuss their consequences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22150v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Yuqiong Wang</dc:creator>
    </item>
    <item>
      <title>Design Stability in Adaptive Experiments: Implications for Treatment Effect Estimation</title>
      <link>https://arxiv.org/abs/2510.22351</link>
      <description>arXiv:2510.22351v1 Announce Type: new 
Abstract: We study the problem of estimating the average treatment effect (ATE) under sequentially adaptive treatment assignment mechanisms. In contrast to classical completely randomized designs, we consider a setting in which the probability of assigning treatment to each experimental unit may depend on prior assignments and observed outcomes. Within the potential outcomes framework, we propose and analyze two natural estimators for the ATE: the inverse propensity weighted (IPW) estimator and an augmented IPW (AIPW) estimator. The cornerstone of our analysis is the concept of design stability, which requires that as the number of units grows, either the assignment probabilities converge, or sample averages of the inverse propensity scores and of the inverse complement propensity scores converge in probability to fixed, non-random limits. Our main results establish central limit theorems for both the IPW and AIPW estimators under design stability and provide explicit expressions for their asymptotic variances. We further propose estimators for these variances, enabling the construction of asymptotically valid confidence intervals. Finally, we illustrate our theoretical results in the context of Wei's adaptive coin design and Efron's biased coin design, highlighting the applicability of the proposed methods to sequential experimentation with adaptive randomization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22351v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saikat Sengupta, Koulik Khamaru, Suvrojit Ghosh, Tirthankar Dasgupta</dc:creator>
    </item>
    <item>
      <title>Sequential monitoring for distributional changepoint using degenerate U-statistics</title>
      <link>https://arxiv.org/abs/2510.22368</link>
      <description>arXiv:2510.22368v1 Announce Type: new 
Abstract: We investigate the online detection of changepoints in the distribution of a sequence of observations using degenerate U-statistic-type processes. We study weighted versions of: an ordinary, CUSUM-type scheme, a Page-CUSUM-type scheme, and an entirely novel approach based on recycling past observations into the training sample. With an emphasis on completeness, we consider open-ended and closed-ended schemes, in the latter case considering both short- and long-running monitoring schemes. We study the asymptotics under the null in all cases, also proposing a consistent, Monte-Carlo based approximation of critical values; and we derive the limiting distribution of the detection delays under early and late occurring changes under the alternative, thus enabling to quantify the expected delay associated with each procedure. As a crucial technical contribution, we derive all our asymptotics under the assumption that the kernels associated with our U-statistics are square summable, instead of requiring the typical absolute summability, which makes our assumption naturally easier to check. Our simulations show that our procedures work well in all cases considered, having excellent power versus several types of distributional changes, and appearing to be particularly suited to the analysis of multivariate data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22368v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cooper Boniece, Lajos Horvath, Lorenzo Trapani</dc:creator>
    </item>
    <item>
      <title>Metric Entropy and Minimax Risk of Ellipsoids with an Application to Pinsker's Theorem</title>
      <link>https://arxiv.org/abs/2510.22441</link>
      <description>arXiv:2510.22441v1 Announce Type: new 
Abstract: We study how large an $\ell^2$ ellipsoid is by introducing type-$\tau$ integrals that capture the average decay of its semi-axes. These integrals turn out to be closely related to standard complexity measures: we show that the metric entropy of the ellipsoid is asymptotically equivalent to the type-1 integral, and that the minimax risk in non-parametric estimation is asymptotically determined by the type-2 and type-3 integrals. This allows us to retrieve and sharpen classical results about metric entropy and minimax risk of ellipsoids through a systematic analysis of the type-$\tau$ integrals, and yields an explicit formula linking the two. As an application, we improve on the best-known characterization of the metric entropy of the Sobolev ellipsoid, and extend Pinsker's Sobolev theorem in two ways: (i) to any bounded open domain in arbitrary finite dimension, and (ii) by providing the second-order term in the asymptotic expansion of the minimax risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22441v1</guid>
      <category>math.ST</category>
      <category>math.FA</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Allard</dc:creator>
    </item>
    <item>
      <title>Confidence Sets for Multidimensional Scaling</title>
      <link>https://arxiv.org/abs/2510.22452</link>
      <description>arXiv:2510.22452v1 Announce Type: new 
Abstract: We develop a formal statistical framework for classical multidimensional scaling (CMDS) applied to noisy dissimilarity data. We establish distributional convergence results for the embeddings produced by CMDS for various noise models, which enable the construction of \emph{bona~fide} uniform confidence sets for the latent configuration, up to rigid transformations. We further propose bootstrap procedures for constructing these confidence sets and provide theoretical guarantees for their validity. We find that the multiplier bootstrap adapts automatically to heteroscedastic noise such as multiplicative noise, while the empirical bootstrap seems to require homoscedasticity. Either form of bootstrap, when valid, is shown to substantially improve finite-sample accuracy. The empirical performance of the proposed methods is demonstrated through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22452v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddharth Vishwanath, Ery Arias-Castro</dc:creator>
    </item>
    <item>
      <title>Stopping Rules for Monte Carlo Methods of Martingale Difference Type</title>
      <link>https://arxiv.org/abs/2510.22690</link>
      <description>arXiv:2510.22690v1 Announce Type: new 
Abstract: We establish a practical and easy-to-implement sequential stopping rule for the martingale central limit theorem, focusing on Monte Carlo methods for estimating the mean of a non-iid sequence of martingale difference type. Starting with an impractical scheme based on the standard martingale central limit theorem, we progressively address its limitations from implementation perspectives in the non-asymptotic regime. Along the way, we compare the proposed schemes with their counterparts in the asymptotic regime. The developed framework has potential applications in various domains, including stochastic gradient descent methods. Numerical results are provided to demonstrate the effectiveness of the developed stopping rules in terms of reliability and complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22690v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiezhong Wu, Reiichiro Kawai</dc:creator>
    </item>
    <item>
      <title>Interpolation of functionals of stochastic sequences with stationary increments from observations with noise</title>
      <link>https://arxiv.org/abs/2510.22764</link>
      <description>arXiv:2510.22764v1 Announce Type: new 
Abstract: The problem of optimal estimation of linear functional ${{A}_{N}}\xi =\sum\limits_{k=0}^{N}{a(k)\xi (k)}\,$ depending on the unknown values of a stochastic sequence $\xi (m)$ with stationary $n$-th increments from observations of the sequence $\xi (k)$ at points $k=-1,-2,\ldots $ and of the sequence $\xi (k)+\eta (k)$ at points of time $k=N+1,N+2,\ldots $ is considered. Formulas for calculating the mean square error and the spectral characteristic of the optimal linear estimate of the functional are proposed under condition of spectral certainty, where spectral densities of the sequences $\xi (m)$ and $\eta (m)$ are exactly known. Minimax (robust) method of estimation is applied in the case where the spectral densities are not known exactly while some sets of admissible spectral densities are given. Formulas that determine the least favorable spectral densities and the minimax spectral characteristics are proposed for some specific sets of admissible densities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22764v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maksym Luz, Mykhailo Moklyachuk</dc:creator>
    </item>
    <item>
      <title>Minimax-robust interpolation problem for periodically correlated isotropic on a sphere random field</title>
      <link>https://arxiv.org/abs/2510.22766</link>
      <description>arXiv:2510.22766v1 Announce Type: new 
Abstract: The problem of optimal linear estimation of functionals depending on the unknown values of a spatial temporal isotropic random field $\zeta(j,x)$, which is periodically correlated
  with respect to discrete time argument $j\in\mathrm Z$ and mean-square continuous isotropic on the unit sphere ${S_n}$ with respect to spatial argument $x\in{S_n}$. Estimates are based on observations of the field $\zeta(j,x)+\theta(j,x)$ at points $(j,x):$ $j\in Z\backslash\{0, 1, .... , N\}$, $x\in S_{n}$,
  where $\theta(j,x)$ is an uncorrelated with $\zeta(t,x)$ spatial temporal isotropic random field, which is periodically correlated
  with respect to discrete time argument $j\in\mathrm Z$ and mean-square continuous isotropic on the sphere ${S_n}$ with respect to spatial argument $x\in{S_n}$. Formulas for calculating the mean square errors and the spectral characteristics of the optimal linear estimate of the functional are derived in the case where the spectral density matrices are exactly known. Formulas that determine the least favourable spectral density matrices and the minimax (robust) spectral characteristics are proposed in the case where the spectral density matrices are not exactly known but a class of admissible spectral density matrices is given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22766v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iryna Golichenko, Oleksandr Masyutka, Mykhailo Moklyachuk</dc:creator>
    </item>
    <item>
      <title>Composite goodness-of-fit test with the Kernel Stein Discrepancy and a bootstrap for degenerate U-statistics with estimated parameters</title>
      <link>https://arxiv.org/abs/2510.22792</link>
      <description>arXiv:2510.22792v1 Announce Type: new 
Abstract: This paper formally derives the asymptotic distribution of a goodness-of-fit test based on the Kernel Stein Discrepancy introduced in (Oscar Key et al., "Composite Goodness-of-fit Tests with Kernels", Journal of Machine Learning Research 26.51 (2025), pp. 1-60). The test enables the simultaneous estimation of the optimal parameter within a parametric family of candidate models. Its asymptotic distribution is shown to be a weighted sum of infinitely many $\chi^2$-distributed random variables plus an additional disturbance term, which is due to the parameter estimation. Further, we provide a general framework to bootstrap degenerate parameter-dependent $U$-statistics and use it to derive a new Kernel Stein Discrepancy composite goodness-of-fit test.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22792v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Florian Brueck, Veronika Reimoser, Fabian Baier</dc:creator>
    </item>
    <item>
      <title>Model-free filtering in high dimensions via projection and score-based diffusions</title>
      <link>https://arxiv.org/abs/2510.23197</link>
      <description>arXiv:2510.23197v1 Announce Type: new 
Abstract: We consider the problem of recovering a latent signal $X$ from its noisy observation $Y$. The unknown law $\mathbb{P}^X$ of $X$, and in particular its support $\mathscr{M}$, are accessible only through a large sample of i.i.d.\ observations. We further assume $\mathscr{M}$ to be a low-dimensional submanifold of a high-dimensional Euclidean space $\mathbb{R}^d$. As a filter or denoiser $\widehat X$, we suggest an estimator of the metric projection $\pi_{\mathscr{M}}(Y)$ of $Y$ onto the manifold $\mathscr{M}$. To compute this estimator, we study an auxiliary semiparametric model in which $Y$ is obtained by adding isotropic Laplace noise to $X$. Using score matching within a corresponding diffusion model, we obtain an estimator of the Bayesian posterior $\mathbb{P}^{X \mid Y}$ in this setup. Our main theoretical results show that, in the limit of high dimension $d$, this posterior $\mathbb{P}^{X\mid Y}$ is concentrated near the desired metric projection $\pi_{\mathscr{M}}(Y)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23197v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\"oren Christensen, Jan Kallsen, Claudia Strauch, Lukas Trottner</dc:creator>
    </item>
    <item>
      <title>Tests of independence for pairs of paths of non-stationary Gaussian processes</title>
      <link>https://arxiv.org/abs/2510.23563</link>
      <description>arXiv:2510.23563v1 Announce Type: new 
Abstract: In the current work, we provide theoretical results for testing (in)dependence between pairs of paths of most commonly studied non-stationary Gaussian processes - standard Brownian motion and fractional Brownian motion (fBm). Please see the PDF version of the paper for a full abstract.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23563v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philip A. Ernst, Frederi G. Viens, Shuo Yan</dc:creator>
    </item>
    <item>
      <title>Bridging Prediction and Attribution: Identifying Forward and Backward Causal Influence Ranges Using Assimilative Causal Inference</title>
      <link>https://arxiv.org/abs/2510.21889</link>
      <description>arXiv:2510.21889v1 Announce Type: cross 
Abstract: Causal inference identifies cause-and-effect relationships between variables. While traditional approaches rely on data to reveal causal links, a recently developed method, assimilative causal inference (ACI), integrates observations with dynamical models. It utilizes Bayesian data assimilation to trace causes back from observed effects by quantifying the reduction in uncertainty. ACI advances the detection of instantaneous causal relationships and the intermittent reversal of causal roles over time. Beyond identifying causal connections, an equally important challenge is determining the associated causal influence range (CIR), indicating when causal influences emerged and for how long they persist. In this paper, ACI is employed to develop mathematically rigorous formulations of both forward and backward CIRs at each time. The forward CIR quantifies the temporal impact of a cause, while the backward CIR traces the onset of triggers for an observed effect, thus characterizing causal predictability and attribution of outcomes at each transient phase, respectively. Objective and robust metrics for both CIRs are introduced, eliminating the need for empirical thresholds. Computationally efficient approximation algorithms to compute CIRs are developed, which facilitate the use of closed-form expressions for a broad class of nonlinear dynamical systems. Numerical simulations demonstrate how this forward and backward CIR framework provides new possibilities for probing complex dynamical systems. It advances the study of bifurcation-driven and noise-induced tipping points in Earth systems, investigates the impact from resolving the interfering variables when determining the influence ranges, and elucidates atmospheric blocking mechanisms in the equatorial region. These results have direct implications for science, policy, and decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21889v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>physics.data-an</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marios Andreou, Nan Chen</dc:creator>
    </item>
    <item>
      <title>Optimal Detection for Language Watermarks with Pseudorandom Collision</title>
      <link>https://arxiv.org/abs/2510.22007</link>
      <description>arXiv:2510.22007v1 Announce Type: cross 
Abstract: Text watermarking plays a crucial role in ensuring the traceability and accountability of large language model (LLM) outputs and mitigating misuse. While promising, most existing methods assume perfect pseudorandomness. In practice, repetition in generated text induces collisions that create structured dependence, compromising Type I error control and invalidating standard analyses.
  We introduce a statistical framework that captures this structure through a hierarchical two-layer partition. At its core is the concept of minimal units -- the smallest groups treatable as independent across units while permitting dependence within. Using minimal units, we define a non-asymptotic efficiency measure and cast watermark detection as a minimax hypothesis testing problem.
  Applied to Gumbel-max and inverse-transform watermarks, our framework produces closed-form optimal rules. It explains why discarding repeated statistics often improves performance and shows that within-unit dependence must be addressed unless degenerate. Both theory and experiments confirm improved detection power with rigorous Type I error control. These results provide the first principled foundation for watermark detection under imperfect pseudorandomness, offering both theoretical insight and practical guidance for reliable tracing of model outputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22007v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.CR</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>T. Tony Cai, Xiang Li, Qi Long, Weijie J. Su, Garrett G. Wen</dc:creator>
    </item>
    <item>
      <title>Frequentist Validity of Epistemic Uncertainty Estimators</title>
      <link>https://arxiv.org/abs/2510.22063</link>
      <description>arXiv:2510.22063v1 Announce Type: cross 
Abstract: Decomposing prediction uncertainty into its aleatoric (irreducible) and epistemic (reducible) components is critical for the development and deployment of machine learning systems. A popular, principled measure for epistemic uncertainty is the mutual information between the response variable and model parameters. However, evaluating this measure requires access to the posterior distribution of the model parameters, which is challenging to compute. In view of this, we introduce a frequentist measure of epistemic uncertainty based on the bootstrap. Our main theoretical contribution is a novel asymptotic expansion that reveals that our proposed (frequentist) measure and the (Bayesian) mutual information are asymptotically equivalent. This provides frequentist interpretations to mutual information and new computational strategies for approximating it. Moreover, we link our proposed approach to the widely-used heuristic approach of deep ensembles, giving added perspective on their practical success.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22063v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anchit Jain, Stephen Bates</dc:creator>
    </item>
    <item>
      <title>Stochastic Trace and Diagonal Estimator for Tensors</title>
      <link>https://arxiv.org/abs/2510.22157</link>
      <description>arXiv:2510.22157v1 Announce Type: cross 
Abstract: We consider the problem of estimating the trace and diagonal entries of an N-order tensor (where $N \geq 2$) under the framework where the tensor can only be accessed through tensor-vector multiplication. The aim is to estimate the tensor's diagonal entries and trace by minimizing the number of tensor-vector queries. The seminal work of Hutchinson and its extended version due to Bekas et al. give unbiased estimates of the trace and diagonal elements of a given matrix, respectively, using matrix-vector queries. However, to the best of our knowledge, no analogous results are known for estimating the trace and diagonal entries of higher-order tensors using tensor-vector queries. This paper addresses this gap and presents unbiased estimators for the trace and diagonal entries of a tensor under this model. Our proposed methods can be seen as generalizations of Hutchinson's and Bekas et al.'s estimators and reduce to their estimators when N = 2. We provide a rigorous theoretical analysis of our proposals and complement it with supporting simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22157v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bhisham Dev Verma, Rameshwar Pratap, Keegan Kang</dc:creator>
    </item>
    <item>
      <title>Robust Estimation for Dependent Binary Network Data</title>
      <link>https://arxiv.org/abs/2510.22177</link>
      <description>arXiv:2510.22177v1 Announce Type: cross 
Abstract: We consider the problem of learning the interaction strength between the nodes of a network based on dependent binary observations residing on these nodes, generated from a Markov Random Field (MRF). Since these observations can possibly be corrupted/noisy in larger networks in practice, it is important to robustly estimate the parameters of the underlying true MRF to account for such inherent contamination in observed data. However, it is well-known that classical likelihood and pseudolikelihood based approaches are highly sensitive to even a small amount of data contamination. So, in this paper, we propose a density power divergence (DPD) based robust generalization of the computationally efficient maximum pseudolikelihood (MPL) estimator of the interaction strength parameter, and derive its rate of consistency under the pure model. Moreover, we show that the gross error sensitivities of the proposed DPD based estimators are significantly smaller than that of the MPL estimator, thereby theoretically justifying the greater (local) robustness of the former under contaminated settings. We also demonstrate the superior (finite sample) performance of the DPD-based variants over the traditional MPL estimator in a number of synthetically generated contaminated network datasets. Finally, we apply our proposed DPD based estimators to learn the network interaction strength in several real datasets from diverse domains of social science, neurobiology and genomics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22177v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyu Liu, Somabha Mukherjee, Abhik Ghosh</dc:creator>
    </item>
    <item>
      <title>Optimal Spatial Anomaly Detection</title>
      <link>https://arxiv.org/abs/2510.22330</link>
      <description>arXiv:2510.22330v2 Announce Type: cross 
Abstract: There has been a growing interest in anomaly detection problems recently, whilst their focuses are mostly on anomalies taking place on the time index. In this work, we investigate a new anomaly-in-mean problem in multidimensional spatial lattice, that is, to detect the number and locations of anomaly ''spatial regions'' from the baseline. In addition to the classic minimisation over the cost function with a $L_0$ penalisation, we introduce an innovative penalty on the area of the minimum convex hull that covers the anomaly regions. We show that the proposed method yields a consistent estimation of the number of anomalies, and it achieves near optimal localisation error under the minimax framework. We also propose a dynamic programming algorithm to solve the double penalised cost minimisation approximately, and carry out large-scale Monte Carlo simulations to examine its numeric performance. The method has a wide range of applications in real-world problems. As an example, we apply it to detect the marine heatwaves using the sea surface temperature data from the European Space Agency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22330v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baiyu Wang, Chao Zheng</dc:creator>
    </item>
    <item>
      <title>Davis-Kahan Theorem under a moderate gap condition</title>
      <link>https://arxiv.org/abs/2510.22393</link>
      <description>arXiv:2510.22393v1 Announce Type: cross 
Abstract: The classical Davis-Kahan theorem provides an efficient bound on the perturbation of eigenspaces of a matrix under a large (eigenvalue) gap condition. In this paper, we consider the case when the gap is moderate. Using a bootstrapping argument, we obtain a new bound which is efficient when the perturbation matrix is uncorrelated to the ground matrix. We believe that this bound is sharp up to a logarithmic term.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22393v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.SP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1142/S021919972550035X</arxiv:DOI>
      <arxiv:journal_reference>Communications in Contemporary Mathematics 2025</arxiv:journal_reference>
      <dc:creator>Phuc Tran, Van Vu</dc:creator>
    </item>
    <item>
      <title>Derivative-Free Sequential Quadratic Programming for Equality-Constrained Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2510.22458</link>
      <description>arXiv:2510.22458v1 Announce Type: cross 
Abstract: We consider solving nonlinear optimization problems with a stochastic objective and deterministic equality constraints, assuming that only zero-order information is available for both the objective and constraints, and that the objective is also subject to random sampling noise. Under this setting, we propose a Derivative-Free Stochastic Sequential Quadratic Programming (DF-SSQP) method. Due to the lack of derivative information, we adopt a simultaneous perturbation stochastic approximation (SPSA) technique to randomly estimate the gradients and Hessians of both the objective and constraints. This approach requires only a dimension-independent number of zero-order evaluations -- as few as eight -- at each iteration step. A key distinction between our derivative-free and existing derivative-based SSQP methods lies in the intricate random bias introduced into the gradient and Hessian estimates of the objective and constraints, brought by stochastic zero-order approximations. To address this issue, we introduce an online debiasing technique based on momentum-style estimators that properly aggregate past gradient and Hessian estimates to reduce stochastic noise, while avoiding excessive memory costs via a moving averaging scheme. Under standard assumptions, we establish the global almost-sure convergence of the proposed DF-SSQP method. Notably, we further complement the global analysis with local convergence guarantees by demonstrating that the rescaled iterates exhibit asymptotic normality, with a limiting covariance matrix resembling the minimax optimal covariance achieved by derivative-based methods, albeit larger due to the absence of derivative information. Our local analysis enables online statistical inference of model parameters leveraging DF-SSQP. Numerical experiments on benchmark nonlinear problems demonstrate both the global and local behavior of DF-SSQP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22458v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sen Na</dc:creator>
    </item>
    <item>
      <title>Robust Spatial Confounding Adjustment via Basis Voting</title>
      <link>https://arxiv.org/abs/2510.22464</link>
      <description>arXiv:2510.22464v1 Announce Type: cross 
Abstract: Estimating causal effects of spatially structured exposures is complicated by unmeasured spatial confounders, which undermine identifiability in spatial linear regression models unless structural assumptions are imposed. We develop a general framework for causal effect estimation that relaxes the commonly assumed requirement that exposures contain higher-frequency variation than confounders. We propose basis voting, a plurality-rule estimator - novel in the spatial literature - that consistently identifies causal effects only under the assumption that, in a spatial basis expansion of the exposure and confounder, there exist several basis functions in the support of the exposure but not the confounder. This assumption generalizes existing assumptions of differential basis support used for identification of the causal effect under spatial confounding, and does not require prior knowledge of which basis functions satisfy this support condition. We also show that the standard projection-based estimator used in other methods relying on differential support is inefficient, and provide a more efficient novel estimator. Extensive simulations and a real-world application demonstrate that our approach reliably recovers unbiased causal estimates whenever exposure and confounder signals are separable on a plurality of basis functions. Importantly, by not relying on higher-frequency variation, our method remains applicable to settings where exposures are smooth spatial functions, such as distance to pollution sources or major roadways, common in environmental studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22464v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anik Burman, Elizabeth L. Ogburn, Abhirup Datta</dc:creator>
    </item>
    <item>
      <title>The Gravitational Aspect of Information: The Physical Reality of Asymmetric "Distance"</title>
      <link>https://arxiv.org/abs/2510.22664</link>
      <description>arXiv:2510.22664v1 Announce Type: cross 
Abstract: We demonstrate that when a Brownian bridge is physically constrained to be canonical, its time evolution becomes identical to an m-geodesic on the statistical manifold of Gaussian distributions. This finding provides strong evidence that, akin to general relativity where free particles follow geodesics, purely random processes also follow ``straight lines" defined by the geometry of information. This geometric principle is a direct consequence of the dually flat structure inherent to information geometry, originating from the asymmetry of informational ``distance" (divergence) leading to the violation of metric compatibility. Our results suggest a geometric foundation for randomness and open the door to an equivalence principle for information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22664v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>gr-qc</category>
      <category>hep-ph</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>quant-ph</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomoi Koide, Armin van de Venn</dc:creator>
    </item>
    <item>
      <title>Stopping Rules for Monte Carlo Methods: A Review</title>
      <link>https://arxiv.org/abs/2510.22688</link>
      <description>arXiv:2510.22688v1 Announce Type: cross 
Abstract: Sequential analysis encompasses simulation theories and methods where the sample size is determined dynamically based on accumulating data. Since the conceptual inception, numerous sequential stopping rules have been introduced, and many more are currently being refined and developed. Those studies often appear fragmented and complex, each relying on different assumptions and conditions. This article aims to deliver a comprehensive and up-to-date review of recent developments on sequential stopping rules, intentionally emphasizing standard and moderately generalized Monte Carlo methods, which have historically served, and likely will continue to serve, as fundamental bases for both theoretical and practical developments in stopping rules for general statistical inference, advanced Monte Carlo techniques and their modern applications. Building upon over a hundred references, we explore the essential aspects of these methods, such as core assumptions, numerical algorithms, convergence properties, and practical trade-offs to guide further developments, particularly at the intersection of sequential stopping rules and related areas of research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22688v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiezhong Wu, Reiichiro Kawai</dc:creator>
    </item>
    <item>
      <title>A Theory of the Mechanics of Information: Generalization Through Measurement of Uncertainty (Learning is Measuring)</title>
      <link>https://arxiv.org/abs/2510.22809</link>
      <description>arXiv:2510.22809v1 Announce Type: cross 
Abstract: Traditional machine learning relies on explicit models and domain assumptions, limiting flexibility and interpretability. We introduce a model-free framework using surprisal (information theoretic uncertainty) to directly analyze and perform inferences from raw data, eliminating distribution modeling, reducing bias, and enabling efficient updates including direct edits and deletion of training data. By quantifying relevance through uncertainty, the approach enables generalizable inference across tasks including generative inference, causal discovery, anomaly detection, and time series forecasting. It emphasizes traceability, interpretability, and data-driven decision making, offering a unified, human-understandable framework for machine learning, and achieves at or near state-of-the-art performance across most common machine learning tasks. The mathematical foundations create a ``physics'' of information, which enable these techniques to apply effectively to a wide variety of complex data types, including missing data. Empirical results indicate that this may be a viable alternative path to neural networks with regard to scalable machine learning and artificial intelligence that can maintain human understandability of the underlying mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22809v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Christopher J. Hazard, Michael Resnick, Jacob Beel, Jack Xia, Cade Mack, Dominic Glennie, Matthew Fulp, David Maze, Andrew Bassett, Martin Koistinen</dc:creator>
    </item>
    <item>
      <title>Unifying regression-based and design-based causal inference in time-series experiments</title>
      <link>https://arxiv.org/abs/2510.22864</link>
      <description>arXiv:2510.22864v1 Announce Type: cross 
Abstract: Time-series experiments, also called switchback experiments or N-of-1 trials, play increasingly important roles in modern applications in medical and industrial areas. Under the potential outcomes framework, recent research has studied time-series experiments from the design-based perspective, relying solely on the randomness in the design to drive the statistical inference. Focusing on simpler statistical methods, we examine the design-based properties of regression-based methods for estimating treatment effects in time-series experiments. We demonstrate that the treatment effects of interest can be consistently estimated using ordinary least squares with an appropriately specified working model and transformed regressors. Our analysis allows for estimating a diverging number of treatment effects simultaneously, and establishes the consistency and asymptotic normality of the regression-based estimators. Additionally, we show that asymptotically, the heteroskedasticity and autocorrelation consistent variance estimators provide conservative estimates of the true, design-based variances. Importantly, although our approach relies on regression, our design-based framework allows for misspecification of the regression model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22864v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhexiao Lin, Peng Ding</dc:creator>
    </item>
    <item>
      <title>Complexity Dependent Error Rates for Physics-informed Statistical Learning via the Small-ball Method</title>
      <link>https://arxiv.org/abs/2510.23149</link>
      <description>arXiv:2510.23149v1 Announce Type: cross 
Abstract: Physics-informed statistical learning (PISL) integrates empirical data with physical knowledge to enhance the statistical performance of estimators. While PISL methods are widely used in practice, a comprehensive theoretical understanding of how informed regularization affects statistical properties is still missing. Specifically, two fundamental questions have yet to be fully addressed: (1) what is the trade-off between considering soft penalties versus hard constraints, and (2) what is the statistical gain of incorporating physical knowledge compared to purely data-driven empirical error minimisation. In this paper, we address these questions for PISL in convex classes of functions under physical knowledge expressed as linear equations by developing appropriate complexity dependent error rates based on the small-ball method. We show that, under suitable assumptions, (1) the error rates of physics-informed estimators are comparable to those of hard constrained empirical error minimisers, differing only by constant terms, and that (2) informed penalization can effectively reduce model complexity, akin to dimensionality reduction, thereby improving learning performance. This work establishes a theoretical framework for evaluating the statistical properties of physics-informed estimators in convex classes of functions, contributing to closing the gap between statistical theory and practical PISL, with potential applications to cases not yet explored in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23149v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego Marcondes</dc:creator>
    </item>
    <item>
      <title>Provable test-time adaptivity and distributional robustness of in-context learning</title>
      <link>https://arxiv.org/abs/2510.23254</link>
      <description>arXiv:2510.23254v1 Announce Type: cross 
Abstract: We study in-context learning problems where a Transformer is pretrained on tasks drawn from a mixture distribution $\pi=\sum_{\alpha\in\mathcal{A}} \lambda_{\alpha} \pi_{\alpha}$, called the pretraining prior, in which each mixture component $\pi_{\alpha}$ is a distribution on tasks of a specific difficulty level indexed by $\alpha$. Our goal is to understand the performance of the pretrained Transformer when evaluated on a different test distribution $\mu$, consisting of tasks of fixed difficulty $\beta\in\mathcal{A}$, and with potential distribution shift relative to $\pi_\beta$, subject to the chi-squared divergence $\chi^2(\mu,\pi_{\beta})$ being at most $\kappa$. In particular, we consider nonparametric regression problems with random smoothness, and multi-index models with random smoothness as well as random effective dimension. We prove that a large Transformer pretrained on sufficient data achieves the optimal rate of convergence corresponding to the difficulty level $\beta$, uniformly over test distributions $\mu$ in the chi-squared divergence ball. Thus, the pretrained Transformer is able to achieve faster rates of convergence on easier tasks and is robust to distribution shift at test time. Finally, we prove that even if an estimator had access to the test distribution $\mu$, the convergence rate of its expected risk over $\mu$ could not be faster than that of our pretrained Transformers, thereby providing a more appropriate optimality guarantee than minimax lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23254v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianyi Ma, Tengyao Wang, Richard J. Samworth</dc:creator>
    </item>
    <item>
      <title>Choosing What to Learn: Experimental Design when Combining Experimental with Observational Evidence</title>
      <link>https://arxiv.org/abs/2510.23434</link>
      <description>arXiv:2510.23434v1 Announce Type: cross 
Abstract: Experiments deliver credible but often localized effects, tied to specific sites, populations, or mechanisms. When such estimates are insufficient to extrapolate effects for broader policy questions, such as external validity and general-equilibrium (GE) effects, researchers combine trials with external evidence from reduced-form or structural observational estimates, or prior experiments. We develop a unified framework for designing experiments in this setting: the researcher selects which parameters to identify experimentally from a feasible set (which treatment arms and/or individuals to include in the experiment), allocates sample size, and specifies how to weight experimental and observational estimators. Because observational inputs may be biased in ways unknown ex ante, we develop a minimax proportional regret objective that evaluates any candidate design relative to an oracle that knows the bias and jointly chooses the design and estimator. This yields a transparent bias-variance trade-off that requires no prespecified bias bound and depends only on information about the precision of the estimators and the estimand's sensitivity to the underlying parameters. We illustrate the framework by (i) designing small-scale cash transfer experiments aimed at estimating GE effects and (ii) optimizing site selection for microfinance interventions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23434v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Aristotelis Epanomeritakis, Davide Viviano</dc:creator>
    </item>
    <item>
      <title>Direct Debiased Machine Learning via Bregman Divergence Minimization</title>
      <link>https://arxiv.org/abs/2510.23534</link>
      <description>arXiv:2510.23534v1 Announce Type: cross 
Abstract: We develop a direct debiased machine learning framework comprising Neyman targeted estimation and generalized Riesz regression. Our framework unifies Riesz regression for automatic debiased machine learning, covariate balancing, targeted maximum likelihood estimation (TMLE), and density-ratio estimation. In many problems involving causal effects or structural models, the parameters of interest depend on regression functions. Plugging regression functions estimated by machine learning methods into the identifying equations can yield poor performance because of first-stage bias. To reduce such bias, debiased machine learning employs Neyman orthogonal estimating equations. Debiased machine learning typically requires estimation of the Riesz representer and the regression function. For this problem, we develop a direct debiased machine learning framework with an end-to-end algorithm. We formulate estimation of the nuisance parameters, the regression function and the Riesz representer, as minimizing the discrepancy between Neyman orthogonal scores computed with known and unknown nuisance parameters, which we refer to as Neyman targeted estimation. Neyman targeted estimation includes Riesz representer estimation, and we measure discrepancies using the Bregman divergence. The Bregman divergence encompasses various loss functions as special cases, where the squared loss yields Riesz regression and the Kullback-Leibler divergence yields entropy balancing. We refer to this Riesz representer estimation as generalized Riesz regression. Neyman targeted estimation also yields TMLE as a special case for regression function estimation. Furthermore, for specific pairs of models and Riesz representer estimation methods, we can automatically obtain the covariate balancing property without explicitly solving the covariate balancing objective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23534v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>Wasserstein Rate-Driven CLTs for Markov Chains with Weighted Lipschitz and Sobolev Extensions</title>
      <link>https://arxiv.org/abs/2002.09427</link>
      <description>arXiv:2002.09427v4 Announce Type: replace 
Abstract: Many tools are available to bound the convergence rate of Markov chains in total variation (TV) distance. Such results can be used to establish central limit theorems (CLT) that enable error evaluations of Monte Carlo estimates in practice. However, convergence analysis based on TV distance is often non-scalable to high-dimensional Markov chains (Qin and Hobert (2018); Rajaratnam and Sparks (2015)). Alternatively, robust bounds in Wasserstein distance are often easier to obtain, thanks to a coupling argument. Our work is concerned with the implication of such convergence results, in particular, do they lead to CLTs of the corresponding Markov chains? One indirect and typically non-trivial way is to first convert Wasserstein bounds into total variation bounds. Alternatively, we provide two CLTs that directly depend on (sub-geometric) convergence rates in Wasserstein distance. Our CLTs hold for Lipschitz functions under certain moment conditions. We also present two possible ways to lift obtained CLTs to a larger weighted Lipschitz class of functions. We further take an analytic route to obtain CLTs for a weighted Sobolev class based on $W_2$ convergence. Finally, we apply these CLTs to four sets of Markov chain examples including a class of nonlinear autoregressive processes, an exponential integrator version of the metropolis adjusted Langevin algorithm (EI-MALA), an unadjusted Langevin algorithm (ULA), and a special autoregressive model that generates reducible chains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2002.09427v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Jin, Aixin Tan</dc:creator>
    </item>
    <item>
      <title>R\'enyi entropy for multivariate controlled autoregressive moving average systems</title>
      <link>https://arxiv.org/abs/2103.07608</link>
      <description>arXiv:2103.07608v2 Announce Type: replace 
Abstract: R\'enyi entropy is an important measure in the context of information theory as a generalization of Shannon entropy. This information measure was often used for uncertainty quantification of dynamical behaviour of stochastic processes. In this paper, we study in detail this measure for multivariate controlled autoregressive moving average (MCARMA) systems. The characteristic function of output process is represented from the terms of its residual characteristic function. An explicit formula to compute the R\'enyi entropy for the output process of MCARMA system is derived. In addition, we investigate the covariance matrix to find the upper bound of R\'enyi entropy. We present three simulations that serve to illustrate the behavior of information in MCARMA system, where the control and noise follow the Gaussian, Cauchy and Laplace distributions. Finally, the behaviour of R\'enyi entropy is illustrated in two real-world applications: a paper-making process and an electric circuit system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.07608v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salah H. Abid, Uday J. Quaez, Javier E. Contreras-Reyescor</dc:creator>
    </item>
    <item>
      <title>Scale estimation and rate-unbiasedness for Gaussian processes under smoothness misspecification</title>
      <link>https://arxiv.org/abs/2110.02810</link>
      <description>arXiv:2110.02810v3 Announce Type: replace 
Abstract: Gaussian process regression is used throughout statistics and machine learning for prediction and uncertainty quantification. A Gaussian process is specified by its mean and covariance functions. Many covariance functions, including Mat\'erns, have a smoothness parameter that is notoriously difficult to specify correctly or estimate from the data. In practice, the smoothness parameter is often selected more or less arbitrarily. We introduce rate-unbiasedness, a relaxed notion of asymptotic optimality which requires that the expected ratio of the mean-square error presumed by a potentially misspecified model and the true, but unknown, mean-square error remain bounded away from zero and infinity as more data are obtained. A rate-unbiased model provides uncertainty quantification that is of correct order of magnitude. We then prove that scale estimation suffices for rate-unbiasedness in a variety of common settings. As estimation of the scale of a Gaussian process is routine and requires no optimisation, rate-unbiasedness can be achieved in many applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.02810v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toni Karvonen, Fran\c{c}ois Bachoc</dc:creator>
    </item>
    <item>
      <title>Weighted residual empirical processes, martingale transformations, and model specification tests for regressions with diverging number of parameters</title>
      <link>https://arxiv.org/abs/2201.12537</link>
      <description>arXiv:2201.12537v2 Announce Type: replace 
Abstract: This paper explores hypothesis testing for the parametric forms of the mean and variance functions in regression models under diverging-dimension settings. To mitigate the curse of dimensionality, we introduce weighted residual empirical process-based tests, both with and without martingale transformations. The asymptotic properties of these tests are derived from the behavior of weighted residual empirical processes and their martingale transformations under the null and alternative hypotheses. The proposed tests without martingale transformations achieve the fastest possible rate of detecting local alternatives, specifically of order $n^{-1/2}$, which is unaffected by dimensionality. However, these tests are not asymptotically distribution-free. To address this limitation, we propose a smooth residual bootstrap approximation and establish its validity in diverging-dimension settings. In contrast, tests incorporating martingale transformations are asymptotically distribution-free but exhibit an unexpected limitation: they can only detect local alternatives converging to the null at a much slower rate of order $n^{-1/4}$, which remains independent of dimensionality. This finding reveals a theoretical advantage in the power of tests based on weighted residual empirical process without martingale transformations over their martingale-transformed counterparts, challenging the conventional wisdom of existing asymptotically distribution-free tests based on martingale transformations. To validate our approach, we conduct simulation studies and apply the proposed tests to a real-world dataset, demonstrating their practical effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.12537v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jeconom.2025.106113</arxiv:DOI>
      <arxiv:journal_reference>Journal of Econometrics, 2025, 252: 106113</arxiv:journal_reference>
      <dc:creator>Falong Tan, Xu Guo, Lixing Zhu</dc:creator>
    </item>
    <item>
      <title>Graphical Finite Population Sampling</title>
      <link>https://arxiv.org/abs/2308.07715</link>
      <description>arXiv:2308.07715v3 Announce Type: replace 
Abstract: This paper introduces an innovative and intuitive finite population sampling method that has been developed using a unique graphical framework. In this approach, first-order inclusion probabilities are represented as bars on a two-dimensional graph. By manipulating the positions of these bars, researchers can create a wide range of different sampling designs. This graphical visualization of sampling designs facilitates the exploration of alternative designs and may simplify certain aspects of the implementation compared to traditional mathematical algorithms. This novel approach holds significant promise for tackling complex challenges in sampling, such as achieving an optimal design. By applying a version of the greedy best-first search algorithm to this graphical approach, the potential for integrating intelligent algorithms into finite population sampling is demonstrated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07715v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bardia Panahbehagh</dc:creator>
    </item>
    <item>
      <title>Thresholded Lasso for high dimensional variable selection</title>
      <link>https://arxiv.org/abs/2309.15355</link>
      <description>arXiv:2309.15355v3 Announce Type: replace 
Abstract: Given $n$ noisy samples with $p$ dimensions, where $n \ll p$, we show that the multi-step thresholding procedure based on the Lasso -- we call it the {\it Thresholded Lasso}, can accurately estimate a sparse vector $\beta \in {\mathbb R}^p$ in a linear model $Y = X \beta + \epsilon$, where $X_{n \times p}$ is a design matrix normalized to have column $\ell_2$-norm $\sqrt{n}$, and $\epsilon \sim N(0, \sigma^2 I_n)$. We show that under the restricted eigenvalue (RE) condition, it is possible to achieve the $\ell_2$ loss within a logarithmic factor of the ideal mean square error one would achieve with an $oracle$ while selecting a sufficiently sparse model -- hence achieving $sparse \ oracle \ inequalities$; the oracle would supply perfect information about which coordinates are non-zero and which are above the noise level. We also show for the Gauss-Dantzig selector (Cand\`{e}s-Tao 07), if $X$ obeys a uniform uncertainty principle, one will achieve the sparse oracle inequalities as above, while allowing at most $s_0$ irrelevant variables in the model in the worst case, where $s_0 \leq s$ is the smallest integer such that for $\lambda = \sqrt{2 \log p/n}$, $\sum_{i=1}^p \min(\beta_i^2, \lambda^2 \sigma^2) \leq s_0 \lambda^2 \sigma^2$. Our simulation results on the Thresholded Lasso match our theoretical analysis excellently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15355v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shuheng Zhou</dc:creator>
    </item>
    <item>
      <title>Higher criticism for rare and weak non-proportional hazard deviations in survival analysis</title>
      <link>https://arxiv.org/abs/2310.00554</link>
      <description>arXiv:2310.00554v2 Announce Type: replace 
Abstract: We propose a method for comparing survival data based on the higher criticism of p-values obtained from multiple exact hypergeometric tests. The method accommodates non-informative right-censorship and is sensitive to hazard differences in unknown and relatively rare time intervals. It attains much better power against such differences than the log-rank test and its variants. We demonstrate the usefulness of our method in detecting rare and weak non-proportional hazard differences compared to existing tests, using simulations and actual gene expression data. Additionally, we analyze the asymptotic power of our method and other tests under a theoretical framework describing two groups experiencing failure rates that are usually identical over time, except in a few unknown instances where one group's failure rate is higher. Our test's power undergoes a phase transition across the plane of rarity and intensity parameters that mirrors the phase transition of higher criticism in two-sample settings with rare and weak normal and Poisson means. The region of the plane in which our method has asymptotically full power is larger than the corresponding region for the log-rank test.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00554v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1093/biomet/asaf075</arxiv:DOI>
      <dc:creator>Alon Kipnis, Ben Galili, Zohar Yakhini</dc:creator>
    </item>
    <item>
      <title>Ask for More Than Bayes Optimal: A Theory of Indecisions for Classification</title>
      <link>https://arxiv.org/abs/2412.12807</link>
      <description>arXiv:2412.12807v3 Announce Type: replace 
Abstract: Selective classification is a powerful tool for automated decision-making in high-risk scenarios, allowing classifiers to act only when confident and abstain when uncertainty is high. Given a target accuracy, our goal is to minimize indecisions, observations we do not automate. For difficult problems, the target accuracy may be unattainable without abstention. By using indecisions, we can control the misclassification rate to any user-specified level, even below the Bayes optimal error rate, while minimizing overall indecision mass.
  We provide a complete characterization of the minimax risk in selective classification, establishing continuity and monotonicity properties that enable optimal indecision selection. We revisit selective inference via the Neyman-Pearson testing framework, where indecision enables control of type 2 error given fixed type 1 error probability. For both classification and testing, we propose a finite-sample calibration method with non-asymptotic guarantees, proving plug-in classifiers remain consistent and that accuracy-based calibration effectively controls indecision mass. In the binary Gaussian mixture model, we uncover the first sharp phase transition in selective inference, showing minimal indecision can yield near-optimal accuracy even under poor class separation. Experiments on Gaussian mixtures and real datasets confirm that small indecision proportions yield substantial accuracy gains, making indecision a principled tool for risk control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12807v3</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Ndaoud, Peter Radchenko, Bradley Rava</dc:creator>
    </item>
    <item>
      <title>On the Contractivity of Stochastic Interpolation Flow</title>
      <link>https://arxiv.org/abs/2504.10653</link>
      <description>arXiv:2504.10653v2 Announce Type: replace 
Abstract: We investigate stochastic interpolation, a recently introduced framework for high dimensional sampling which bears many similarities to diffusion modeling. Stochastic interpolation generates a data sample by first randomly initializing a particle drawn from a simple base distribution, then simulating deterministic or stochastic dynamics such that in finite time the particle's distribution converges to the target. We show that for a Gaussian base distribution and a strongly log-concave target distribution, the stochastic interpolation flow map is Lipschitz with a sharp constant which matches that of Caffarelli's theorem for optimal transport maps. We are further able to construct Lipschitz transport maps between non-Gaussian distributions, generalizing some recent constructions in the literature on transport methods for establishing functional inequalities. We discuss the practical implications of our theorem for the sampling and estimation problems required by stochastic interpolation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10653v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mara Daniels</dc:creator>
    </item>
    <item>
      <title>Uniform central limit theorems for non-stationary processes via relative weak convergence</title>
      <link>https://arxiv.org/abs/2505.02197</link>
      <description>arXiv:2505.02197v4 Announce Type: replace 
Abstract: Statistical inference for non-stationary data is hindered by the failure of classical central limit theorems (CLTs), not least because there is no fixed Gaussian limit to converge to. To resolve this, we introduce relative weak convergence, an extension of weak convergence that compares a statistic or process to a sequence of &lt;evolving processes. Relative weak convergence retains the essential consequences of classical weak convergence and coincides with it under stationarity. Crucially, it applies in general non-stationary settings where classical weak convergence fails. We establish concrete relative CLTs for random vectors and empirical processes, along with sequential, weighted, and bootstrap variants that parallel the state-of-the-art in stationary settings. Our framework and results offer simple, plug-in replacements for classical CLTs whenever stationarity is untenable, as illustrated by applications in nonparametric trend estimation and hypothesis testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02197v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolai Palm, Thomas Nagler</dc:creator>
    </item>
    <item>
      <title>Central Limit Theorems for Transition Probabilities of Controlled Markov Chains</title>
      <link>https://arxiv.org/abs/2508.01517</link>
      <description>arXiv:2508.01517v2 Announce Type: replace 
Abstract: We develop a central limit theorem (CLT) for the non-parametric estimator of the transition matrices in controlled Markov chains (CMCs) with finite state-action spaces. Our results establish precise conditions on the logging policy under which the estimator is asymptotically normal, and reveal settings in which no CLT can exist. We then build upon it to derive CLTs for the value, Q-, and advantage functions of any stationary stochastic policy, including the optimal policy recovered from the estimated model. Goodness-of-fit tests are derived as a corollary, which enable us to test whether the logged data is stochastic. These results provide new statistical tools for offline policy evaluation and optimal policy recovery, and enable hypothesis tests for transition probabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01517v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziwei Su, Imon Banerjee, Diego Klabjan</dc:creator>
    </item>
    <item>
      <title>Optimal Nuisance Function Tuning for Estimating a Doubly Robust Functional under Proportional Asymptotics</title>
      <link>https://arxiv.org/abs/2509.25536</link>
      <description>arXiv:2509.25536v2 Announce Type: replace 
Abstract: In this paper, we explore the asymptotically optimal tuning parameter choice in ridge regression for estimating nuisance functions of a statistical functional that has recently gained prominence in conditional independence testing and causal inference. Given a sample of size $n$, we study estimators of the Expected Conditional Covariance (ECC) between variables $Y$ and $A$ given a high-dimensional covariate $X \in \mathbb{R}^p$. Under linear regression models for $Y$ and $A$ on $X$ and the proportional asymptotic regime $p/n \to c \in (0, \infty)$, we evaluate three existing ECC estimators and two sample splitting strategies for estimating the required nuisance functions. Since no consistent estimator of the nuisance functions exists in the proportional asymptotic regime without imposing further structure on the problem, we first derive debiased versions of the ECC estimators that utilize the ridge regression nuisance function estimators. We show that our bias correction strategy yields $\sqrt{n}$-consistent estimators of the ECC across different sample splitting strategies and estimator choices. We then derive the asymptotic variances of these debiased estimators to illustrate the nuanced interplay between the sample splitting strategy, estimator choice, and tuning parameters of the nuisance function estimators for optimally estimating the ECC. Our analysis reveals that prediction-optimal tuning parameters (i.e., those that optimally estimate the nuisance functions) may not lead to the lowest asymptotic variance of the ECC estimator -- thereby demonstrating the need to be careful in selecting tuning parameters based on the final goal of inference. Finally, we verify our theoretical results through extensive numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25536v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sean McGrath, Debarghya Mukherjee, Rajarshi Mukherjee, Zixiao Jolene Wang</dc:creator>
    </item>
    <item>
      <title>Inference on common trends in functional time series</title>
      <link>https://arxiv.org/abs/2312.00590</link>
      <description>arXiv:2312.00590v5 Announce Type: replace-cross 
Abstract: We study statistical inference on unit roots and cointegration for time series in a Hilbert space. We develop statistical inference on the number of common stochastic trends embedded in the time series, i.e., the dimension of the nonstationary subspace. We also consider tests of hypotheses on the nonstationary and stationary subspaces themselves. The Hilbert space can be of an arbitrarily large dimension, and our methods remain asymptotically valid even when the time series of interest takes values in a subspace of possibly unknown dimension. This has wide applicability in practice; for example, to cointegrated vector time series that are either high-dimensional or of finite dimension, to high-dimensional factor models that include a finite number of nonstationary factors, to cointegrated curve-valued (or function-valued) time series, and to nonstationary dynamic functional factor models. We include two empirical illustrations to the term structure of interest rates and labor market indices, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00590v5</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Morten {\O}rregaard Nielsen, Won-Ki Seo, Dakyung Seong</dc:creator>
    </item>
    <item>
      <title>Local Identification in Instrumental Variable Multivariate Quantile Regression Models</title>
      <link>https://arxiv.org/abs/2401.11422</link>
      <description>arXiv:2401.11422v4 Announce Type: replace-cross 
Abstract: In the instrumental variable quantile regression (IVQR) model of Chernozhukov and Hansen (2005), a one-dimensional unobserved rank variable monotonically determines a single potential outcome. In practice, when researchers are interested in multiple outcomes, it is common to estimate separate IVQR models for each of them. This approach implicitly assumes that the rank variable in each regression affects only its associated outcome, without influencing others. In reality, however, outcomes are often jointly determined by multiple latent factors, inducing structural correlations across equations.
  To address this limitation, we propose a nonlinear instrumental variable model that accommodates multivariate unobserved heterogeneity, where each component of the latent vector acts as a rank variable corresponding to an observed outcome. When both the treatment and the instrument are discrete, we show that the structural function in our model is locally identified under a sufficiently strong positive correlation between the treatment and the instrument.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11422v4</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haruki Kono</dc:creator>
    </item>
    <item>
      <title>Provable Sample-Efficient Transfer Learning Conditional Diffusion Models via Representation Learning</title>
      <link>https://arxiv.org/abs/2502.04491</link>
      <description>arXiv:2502.04491v2 Announce Type: replace-cross 
Abstract: While conditional diffusion models have achieved remarkable success in various applications, they require abundant data to train from scratch, which is often infeasible in practice. To address this issue, transfer learning has emerged as an essential paradigm in small data regimes. Despite its empirical success, the theoretical underpinnings of transfer learning conditional diffusion models remain unexplored. In this paper, we take the first step towards understanding the sample efficiency of transfer learning conditional diffusion models through the lens of representation learning. Inspired by practical training procedures, we assume that there exists a low-dimensional representation of conditions shared across all tasks. Our analysis shows that with a well-learned representation from source tasks, the samplecomplexity of target tasks can be reduced substantially. In addition, we investigate the practical implications of our theoretical results in several real-world applications of conditional diffusion models. Numerical experiments are also conducted to verify our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04491v2</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziheng Cheng, Tianyu Xie, Shiyue Zhang, Cheng Zhang</dc:creator>
    </item>
    <item>
      <title>Dimension-free Score Matching and Time Bootstrapping for Diffusion Models</title>
      <link>https://arxiv.org/abs/2502.10354</link>
      <description>arXiv:2502.10354v2 Announce Type: replace-cross 
Abstract: Diffusion models generate samples by estimating the score function of the target distribution at various noise levels. The model is trained using samples drawn from the target distribution by progressively adding noise. Previous sample complexity bounds have polynomial dependence on the dimension $d$, apart from a $\log(|\mathcal{H}|)$ term, where $\mathcal{H}$ is the hypothesis class. In this work, we establish the first (nearly) dimension-free sample complexity bounds, modulo the $\log(|\mathcal{H}|)$ dependence, for learning these score functions, achieving a double exponential improvement in the dimension over prior results. A key aspect of our analysis is the use of a single function approximator to jointly estimate scores across noise levels, a practical feature that enables generalization across time steps. We introduce a martingale-based error decomposition and sharp variance bounds, enabling efficient learning from dependent data generated by Markov processes, which may be of independent interest. Building on these insights, we propose Bootstrapped Score Matching (BSM), a variance reduction technique that leverages previously learned scores to improve accuracy at higher noise levels. These results provide insights into the efficiency and effectiveness of diffusion models for generative modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10354v2</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Syamantak Kumar, Dheeraj Nagaraj, Purnamrita Sarkar</dc:creator>
    </item>
    <item>
      <title>Comparing regularisation paths of (conjugate) gradient estimators in ridge regression</title>
      <link>https://arxiv.org/abs/2503.05542</link>
      <description>arXiv:2503.05542v3 Announce Type: replace-cross 
Abstract: We consider standard gradient descent, gradient flow and conjugate gradients as iterative algorithms for minimising a penalised ridge criterion in linear regression. While it is well known that conjugate gradients exhibit fast numerical convergence, the statistical properties of their iterates are more difficult to assess due to inherent non-linearities and dependencies. On the other hand, standard gradient flow is a linear method with well-known regularising properties when stopped early. By an explicit non-standard error decomposition we are able to bound the prediction error for conjugate gradient iterates by a corresponding prediction error of gradient flow at transformed iteration indices. This way, the risk along the entire regularisation path of conjugate gradient iterations can be compared to that for regularisation paths of standard linear methods like gradient flow and ridge regression. In particular, the oracle conjugate gradient iterate shares the optimality properties of the gradient flow and ridge regression oracles up to a constant factor. Numerical examples show the similarity of the regularisation paths in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05542v3</guid>
      <category>stat.ML</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laura Hucker, Markus Rei{\ss}, Thomas Stark</dc:creator>
    </item>
    <item>
      <title>Statistical Inference under Performativity</title>
      <link>https://arxiv.org/abs/2505.18493</link>
      <description>arXiv:2505.18493v3 Announce Type: replace-cross 
Abstract: Performativity of predictions refers to the phenomenon where prediction-informed decisions influence the very targets they aim to predict -- a dynamic commonly observed in policy-making, social sciences, and economics. In this paper, we initiate an end-to-end framework of statistical inference under performativity. Our contributions are twofold. First, we establish a central limit theorem for estimation and inference in the performative setting, enabling standard inferential tasks such as constructing confidence intervals and conducting hypothesis tests in policy-making contexts. Second, we leverage this central limit theorem to study prediction-powered inference (PPI) under performativity. This approach yields more precise estimates and tighter confidence regions for the model parameters (i.e., policies) of interest in performative prediction. We validate the effectiveness of our framework through numerical experiments. To the best of our knowledge, this is the first work to establish a complete statistical inference under performativity, introducing new challenges and inference settings that we believe will provide substantial value to policy-making, statistics, and machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18493v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiang Li, Yunai Li, Huiying Zhong, Lihua Lei, Zhun Deng</dc:creator>
    </item>
    <item>
      <title>Berk-Nash Rationalizability</title>
      <link>https://arxiv.org/abs/2505.20708</link>
      <description>arXiv:2505.20708v3 Announce Type: replace-cross 
Abstract: We study learning in complete-information games, allowing the players' models of their environment to be misspecified. We introduce Berk--Nash rationalizability: the largest self-justified set of actions -- meaning each action in the set is optimal under some belief that is a best fit to outcomes generated by joint play within the set. We show that, in a model where players learn from past actions, every action played (or approached) infinitely often lies in this set. When players have a correct model of their environment, Berk--Nash rationalizability refines (correlated) rationalizability and coincides with it in two-player games. The concept delivers predictions on long-run behavior regardless of whether actions converge or not, thereby providing a practical alternative to proving convergence or solving complex stochastic learning dynamics. For example, if the rationalizable set is a singleton, actions converge almost surely.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20708v3</guid>
      <category>econ.TH</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ignacio Esponda, Demian Pouzo</dc:creator>
    </item>
    <item>
      <title>Causal Sufficiency and Necessity Improves Chain-of-Thought Reasoning</title>
      <link>https://arxiv.org/abs/2506.09853</link>
      <description>arXiv:2506.09853v3 Announce Type: replace-cross 
Abstract: Chain-of-Thought (CoT) prompting plays an indispensable role in endowing large language models (LLMs) with complex reasoning capabilities. However, CoT currently faces two fundamental challenges: (1) Sufficiency, which ensures that the generated intermediate inference steps comprehensively cover and substantiate the final conclusion; and (2) Necessity, which identifies the inference steps that are truly indispensable for the soundness of the resulting answer. We propose a causal framework that characterizes CoT reasoning through the dual lenses of sufficiency and necessity. Incorporating causal Probability of Sufficiency and Necessity allows us not only to determine which steps are logically sufficient or necessary to the prediction outcome, but also to quantify their actual influence on the final reasoning outcome under different intervention scenarios, thereby enabling the automated addition of missing steps and the pruning of redundant ones. Extensive experimental results on various mathematical and commonsense reasoning benchmarks confirm substantial improvements in reasoning efficiency and reduced token usage without sacrificing accuracy. Our work provides a promising direction for improving LLM reasoning performance and cost-effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09853v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangning Yu, Zhuohan Wang, Linyi Yang, Haoxuan Li, Anjie Liu, Xiao Xue, Jun Wang, Mengyue Yang</dc:creator>
    </item>
    <item>
      <title>Optimal Adjustment Sets for Nonparametric Estimation of Weighted Controlled Direct Effect</title>
      <link>https://arxiv.org/abs/2506.09871</link>
      <description>arXiv:2506.09871v3 Announce Type: replace-cross 
Abstract: The weighted controlled direct effect (WCDE) generalizes the standard controlled direct effect (CDE) by averaging over the mediator distribution, providing a robust estimate when treatment effects vary across mediator levels. This makes the WCDE especially relevant in fairness analysis, where it isolates the direct effect of an exposure on an outcome, independent of mediating pathways. This work establishes three fundamental advances for WCDE in observational studies: First, we establish necessary and sufficient conditions for the unique identifiability of the WCDE, clarifying when it diverges from the CDE. Next, we consider nonparametric estimation of the WCDE and derive its influence function, focusing on the class of regular and asymptotically linear estimators. Lastly, we characterize the optimal covariate adjustment set that minimizes the asymptotic variance, demonstrating how mediator-confounder interactions introduce distinct requirements compared to average treatment effect estimation. Our results offer a principled framework for efficient estimation of direct effects in complex causal systems, with practical applications in fairness and mediation analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09871v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ruiyang Lin (University of Science,Technology of China), Yongyi Guo (University of Wisconsin-Madison), Kyra Gan (Cornell Tech)</dc:creator>
    </item>
    <item>
      <title>Beyond the Average: Distributional Causal Inference under Imperfect Compliance</title>
      <link>https://arxiv.org/abs/2509.15594</link>
      <description>arXiv:2509.15594v2 Announce Type: replace-cross 
Abstract: We study the estimation of distributional treatment effects in randomized experiments with imperfect compliance. When participants do not adhere to their assigned treatments, we leverage treatment assignment as an instrumental variable to identify the local distributional treatment effect-the difference in outcome distributions between treatment and control groups for the subpopulation of compliers. We propose a regression-adjusted estimator based on a distribution regression framework with Neyman-orthogonal moment conditions, enabling robustness and flexibility with high-dimensional covariates. Our approach accommodates continuous, discrete, and mixed discrete-continuous outcomes, and applies under a broad class of covariate-adaptive randomization schemes, including stratified block designs and simple random sampling. We derive the estimator's asymptotic distribution and show that it achieves the semiparametric efficiency bound. Simulation results demonstrate favorable finite-sample performance, and we demonstrate the method's practical relevance in an application to the Oregon Health Insurance Experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15594v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Undral Byambadalai, Tomu Hirata, Tatsushi Oka, Shota Yasui</dc:creator>
    </item>
    <item>
      <title>Differentiable Structure Learning and Causal Discovery for General Binary Data</title>
      <link>https://arxiv.org/abs/2509.21658</link>
      <description>arXiv:2509.21658v2 Announce Type: replace-cross 
Abstract: Existing methods for differentiable structure learning in discrete data typically assume that the data are generated from specific structural equation models. However, these assumptions may not align with the true data-generating process, which limits the general applicability of such methods. Furthermore, current approaches often ignore the complex dependence structure inherent in discrete data and consider only linear effects. We propose a differentiable structure learning framework that is capable of capturing arbitrary dependencies among discrete variables. We show that although general discrete models are unidentifiable from purely observational data, it is possible to characterize the complete set of compatible parameters and structures. Additionally, we establish identifiability up to Markov equivalence under mild assumptions. We formulate the learning problem as a single differentiable optimization task in the most general form, thereby avoiding the unrealistic simplifications adopted by previous methods. Empirical results demonstrate that our approach effectively captures complex relationships in discrete data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21658v2</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chang Deng, Bryon Aragam</dc:creator>
    </item>
    <item>
      <title>Transfer Learning on Edge Connecting Probability Estimation under Graphon Model</title>
      <link>https://arxiv.org/abs/2510.05527</link>
      <description>arXiv:2510.05527v2 Announce Type: replace-cross 
Abstract: Graphon models provide a flexible nonparametric framework for estimating latent connectivity probabilities in networks, enabling a range of downstream applications such as link prediction and data augmentation. However, accurate graphon estimation typically requires a large graph, whereas in practice, one often only observes a small-sized network. One approach to addressing this issue is to adopt a transfer learning framework, which aims to improve estimation in a small target graph by leveraging structural information from a larger, related source graph. In this paper, we propose a novel method, namely GTRANS, a transfer learning framework that integrates neighborhood smoothing and Gromov-Wasserstein optimal transport to align and transfer structural patterns between graphs. To prevent negative transfer, GTRANS includes an adaptive debiasing mechanism that identifies and corrects for target-specific deviations via residual smoothing. We provide theoretical guarantees on the stability of the estimated alignment matrix and demonstrate the effectiveness of GTRANS in improving the accuracy of target graph estimation through extensive synthetic and real data experiments. These improvements translate directly to enhanced performance in downstream applications, such as the graph classification task and the link prediction task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05527v2</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuyao Wang, Yu-Hung Cheng, Debarghya Mukherjee, Huimin Cheng</dc:creator>
    </item>
    <item>
      <title>Change, dependence, and discovery: Celebrating the work of T.L. Lai</title>
      <link>https://arxiv.org/abs/2510.20023</link>
      <description>arXiv:2510.20023v2 Announce Type: replace-cross 
Abstract: Tze Leung Lai made seminal contributions to sequential analysis, particularly in sequential hypothesis testing, changepoint detection and nonlinear renewal theory. His work established fundamental optimality results for the sequential probability ratio test and its extensions, and provided a general framework for testing composite hypotheses. In changepoint detection, he introduced new optimality criteria and computationally efficient procedures that remain influential. He applied these and related tools to problems in biostatistics. In this article, we review these key results in the broader context of sequential analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20023v2</guid>
      <category>stat.OT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander G. Tartakovsky, Jay Bartroff, Cheng-Der Fuh, Haipeng Xing</dc:creator>
    </item>
    <item>
      <title>On Uncertainty Calibration for Equivariant Functions</title>
      <link>https://arxiv.org/abs/2510.21691</link>
      <description>arXiv:2510.21691v2 Announce Type: replace-cross 
Abstract: Data-sparse settings such as robotic manipulation, molecular physics, and galaxy morphology classification are some of the hardest domains for deep learning. For these problems, equivariant networks can help improve modeling across undersampled parts of the input space, and uncertainty estimation can guard against overconfidence. However, until now, the relationships between equivariance and model confidence, and more generally equivariance and model calibration, has yet to be studied. Since traditional classification and regression error terms show up in the definitions of calibration error, it is natural to suspect that previous work can be used to help understand the relationship between equivariance and calibration error. In this work, we present a theory relating equivariance to uncertainty estimation. By proving lower and upper bounds on uncertainty calibration errors (ECE and ENCE) under various equivariance conditions, we elucidate the generalization limits of equivariant models and illustrate how symmetry mismatch can result in miscalibration in both classification and regression. We complement our theoretical framework with numerical experiments that clarify the relationship between equivariance and uncertainty using a variety of real and simulated datasets, and we comment on trends with symmetry mismatch, group size, and aleatoric and epistemic uncertainties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21691v2</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 28 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edward Berman, Jacob Ginesin, Marco Pacini, Robin Walters</dc:creator>
    </item>
  </channel>
</rss>
