<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 13 May 2024 04:02:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 13 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The HLLC-2D method for the computation of two phase flow system ejecta transporting model</title>
      <link>https://arxiv.org/abs/2405.06046</link>
      <description>arXiv:2405.06046v1 Announce Type: new 
Abstract: This work presents a second-order arbitrary Lagrangian Eulerian (ALE) method for the compressible multiphase particle-flow system with the HLLC-2D Riemann solver. We focus on researching the precise equation to describe the interactions between partible phase and flow phase. The computation of equivalent relation of the momentum and energy between two phases is the key point during the procedure, which can be capable of maintaining the conservation of this system. In the case of particle terms, track their trajectories within the mesh and couple with the element based on the position in the space. Thereafter an ALE method instead of Lagrangian scheme is derived for the discretization of the equation to perform better with the complex motion of particles and flow. We apply the HLLC-2D Riemann solver to substitute the HLLC solver which relaxes the requirement for continuous fluxes along the edge. Meanwhile we propose a method for searching particles and provide a CFL-like condition based on this. Finally, we give some numerical tests to analysis the influence of particles on fluid and get a following effect between two phases. The model and method are validated through numerical tests to show its robustness and accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06046v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianqiao Zhang, Wei Yan, Xianggui Li</dc:creator>
    </item>
    <item>
      <title>Skewness of a randomized quasi-Monte Carlo estimate</title>
      <link>https://arxiv.org/abs/2405.06136</link>
      <description>arXiv:2405.06136v1 Announce Type: new 
Abstract: Some recent work on confidence intervals for randomized quasi-Monte Carlo (RQMC) sampling found a surprising result: ordinary Student $t$ 95\% confidence intervals based on a modest number of replicates were seen to be very effective and even more reliable than some bootstrap $t$ intervals that were expected to be best. One potential explanation is that those RQMC estimates have small skewness. In this paper we give conditions under which the skewness is $O(n^\epsilon)$ for any $\epsilon&gt;0$, so `almost $O(1)$'. Under a random generator matrix model, we can improve this rate to $O(n^{-1/2+\epsilon})$ with very high probability. We also improve some probabilistic bounds on the distribution of the quality parameter $t$ for a digital net in a prime base under random sampling of generator matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06136v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zexin Pan, Art B. Owen</dc:creator>
    </item>
    <item>
      <title>Learning PDEs from data on closed surfaces with sparse optimization</title>
      <link>https://arxiv.org/abs/2405.06199</link>
      <description>arXiv:2405.06199v1 Announce Type: new 
Abstract: The discovery of underlying surface partial differential equation (PDE) from observational data has significant implications across various fields, bridging the gap between theory and observation, enhancing our understanding of complex systems, and providing valuable tools and insights for applications. In this paper, we propose a novel approach, termed physical-informed sparse optimization (PIS), for learning surface PDEs. Our approach incorporates both $L_2$ physical-informed model loss and $L_1$ regularization penalty terms in the loss function, enabling the identification of specific physical terms within the surface PDEs. The unknown function and the differential operators on surfaces are approximated by some extrinsic meshless methods. We provide practical demonstrations of the algorithms including linear and nonlinear systems. The numerical experiments on spheres and various other surfaces demonstrate the effectiveness of the proposed approach in simultaneously achieving precise solution prediction and identification of unknown PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06199v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengjie Sun, Leevan Ling, Ran Zhang</dc:creator>
    </item>
    <item>
      <title>Refined localization spaces, Kondratiev spaces with fractional smoothness and extension operators</title>
      <link>https://arxiv.org/abs/2405.06316</link>
      <description>arXiv:2405.06316v1 Announce Type: new 
Abstract: In this paper, we introduce Kondratiev spaces of fractional smoothness based on their close relation to refined localization spaces. Moreover, we investigate relations to other approaches leading to extensions of the scale of Kondratiev spaces with integer order of smoothness, based on complex interpolation, and give further results for complex interpolation of those function spaces. As it turns out to be one of the main tools in studying these spaces on domains of polyhedral type, certain aspects of the analysis of Stein's extension operator are revisited. Finally, as an application, we study Sobolev-type embeddings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06316v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Markus Hansen, Cornelia Schneider</dc:creator>
    </item>
    <item>
      <title>Backward errors for multiple eigenpairs in structured and unstructured nonlinear eigenvalue problems</title>
      <link>https://arxiv.org/abs/2405.06327</link>
      <description>arXiv:2405.06327v1 Announce Type: new 
Abstract: Given a nonlinear matrix-valued function $F(\lambda)$ and approximate eigenpairs $(\lambda_i, v_i)$, we discuss how to determine the smallest perturbation $\delta F$ such that $[F + \delta F](\lambda_i) v_i = 0$; we call the distance between the $F$ and $F + \delta F$ the backward error for this set of approximate eigenpairs. We focus on the case where $F(\lambda)$ is given as a linear combination of scalar functions multiplying matrix coefficients $F_i$, and the perturbation is done on the matrix coefficients. We provide inexpensive upper bounds, and a way to accurately compute the backward error by means of direct computations or through Riemannian optimization. We also discuss how the backward error can be determined when the $F_i$ have particular structures (such as symmetry, sparsity, or low-rank), and the perturbations are required to preserve them. For special cases (such as for symmetric coefficients), explicit and inexpensive formulas to compute the $\delta F_i$ are also given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06327v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miryam Gnazzo, Leonardo Robol</dc:creator>
    </item>
    <item>
      <title>Random Batch Ewald Method for Dielectrically Confined Coulomb Systems</title>
      <link>https://arxiv.org/abs/2405.06333</link>
      <description>arXiv:2405.06333v1 Announce Type: new 
Abstract: Quasi two-dimensional Coulomb systems have drawn widespread interest. The reduced symmetry of these systems leads to complex collective behaviors, yet simultaneously poses significant challenges for particle-based simulations. In this paper, a novel method is presented for efficiently simulate a collection of charges confined in doubly-periodic slabs, with the extension to scenarios involving dielectric jumps at slab boundaries. Unlike existing methods, the method is insensitive to the aspect ratio of simulation box, and it achieves optimal O(N) complexity and strong scalability, thanks to the random batch Ewald (RBE) approach. Moreover, the additional cost for polarization contributions, represented as image reflection series, is reduced to a negligible cost via combining the RBE with an efficient structure factor coefficient re-calibration technique in k-space. Explicit formulas for optimal parameter choices of the algorithm are provided through error estimates, together with a rigorous proof. Finally, we demonstrate the accuracy, efficiency and scalability of our method, called RBE2D, via numerical tests across a variety of prototype systems. An excellent agreement between the RBE2D and the PPPM method is observed, with a significant reduction in the computational cost and strong scalability, demonstrating that it is a promising method for a broad range of charged systems under quasi-2D confinement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06333v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zecheng Gan, Xuanzhao Gao, Jiuyang Liang, Zhenli Xu</dc:creator>
    </item>
    <item>
      <title>Regularization with optimal space-time priors</title>
      <link>https://arxiv.org/abs/2405.06337</link>
      <description>arXiv:2405.06337v1 Announce Type: new 
Abstract: We propose a variational regularization approach based on cylindrical shearlets to deal with dynamic imaging problems, with dynamic tomography as guiding example. The idea is that the mismatch term essentially integrates a sequence of separable, static problems, while the regularization term sees the non-stationary target as a spatio-temporal object. We motivate this approach by showing that cylindrical shearlets provide optimally sparse approximations for the class of cartoon-like videos, i.e., a class of functions useful to model spatio-temporal image sequences and videos, which we introduce extending the classic notion of cartoon-like images. To formulate our regularization model, we define cylindrical shearlet smoothness spaces, which is pivotal to obtain suitable embeddings in functional spaces. To complete our analysis, we prove that the proposed regularization strategy is well-defined, the solution of the minimisation problem exists and is unique (for $ p &gt; 1$). Furthermore, we provide convergence rates (in terms of the symmetric Bregman distance) under deterministic and random noise conditions, and within the context of statistical inverse learning. We numerically validate our theoretical results using both simulated and measured dynamic tomography data, showing that our approach leads to a practical and robust reconstruction strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06337v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatiana A. Bubba, Tommi Heikkil\"a, Demetrio Labate, Luca Ratti</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of a nonconforming virtual element method for compressible miscible displacement problems in porous media</title>
      <link>https://arxiv.org/abs/2405.06352</link>
      <description>arXiv:2405.06352v1 Announce Type: new 
Abstract: This article presents a priori error estimates of the miscible displacement of one compressible fluid by another in a porous medium. The study utilizes the $H(\rm div)$ conforming virtual element method (VEM) for the approximation of the velocity, while a non-conforming virtual element approach is employed for the concentration. The pressure is discretised using the standard piecewise discontinuous polynomial functions. These spatial discretization techniques are combined with a backward Euler difference scheme for time discretization. Error estimates are established for velocity, pressure and concentration. The article also includes numerical results that validate the theoretical estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06352v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarvesh Kumar, Devika Shylaja</dc:creator>
    </item>
    <item>
      <title>Accuracy and Stability of CUR decompositions with Oversampling</title>
      <link>https://arxiv.org/abs/2405.06375</link>
      <description>arXiv:2405.06375v1 Announce Type: new 
Abstract: This work investigates the accuracy and numerical stability of CUR decompositions with oversampling. The CUR decomposition approximates a matrix using a subset of columns and rows of the matrix. When the number of columns and the rows are the same, the CUR decomposition can become unstable and less accurate due to the presence of the matrix inverse in the core matrix. Nevertheless, we demonstrate that the CUR decomposition can be implemented in a numerical stable manner and illustrate that oversampling, which increases either the number of columns or rows in the CUR decomposition, can enhance its accuracy and stability. Additionally, this work devises an algorithm for oversampling motivated by the theory of the CUR decomposition and the cosine-sine decomposition, whose competitiveness is illustrated through experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06375v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taejun Park, Yuji Nakatsukasa</dc:creator>
    </item>
    <item>
      <title>Recovery of transversely-isotropic elastic material parameters in induction motor rotors</title>
      <link>https://arxiv.org/abs/2405.06388</link>
      <description>arXiv:2405.06388v1 Announce Type: new 
Abstract: We propose numerical algorithms for recovering parameters in eigenvalue problems for linear elasticity of transversely isotropic materials. Specifically, the algorithms are used to recover the elastic constants of a rotor core. Numerical tests show that in the noiseless setup, two pairs of bending modes are sufficient for recovering one to four parameters accurately. To recover all five parameters that govern the elastic properties of electric engines accurately, we require three pairs of bending modes and one torsional mode. Moreover, we study the stability of the inversion method against multiplicative noise; for tests in which the data contained multiplicative noise of at most $1\%$, we find that all parameters can be recovered with an error less than $10\%$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06388v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanz Martin Cheng, Tapio Helin, Ville-Petteri Manninen, Timo Holopainen, Juha Jokinen, Samu Sorvari, Andreas Rupp</dc:creator>
    </item>
    <item>
      <title>A Review of Matrix Algebra for Power and Energy Applications</title>
      <link>https://arxiv.org/abs/2405.06452</link>
      <description>arXiv:2405.06452v1 Announce Type: new 
Abstract: This report presents a brief review of matrix algebra and its implementation in Julia for power and energy applications. First, we present basic examples of data visualization, followed by conventional operations with matrices and vectors. Then, we study quadratic forms and norms, two main concepts required in the convergence study of the power flow in power and energy applications. After that, we give good practices to create a neat code in Julia. There is an extensive set of examples available on the Internet related to these basic aspects, so we avoid repeating what is well documented. Hence, we show only basic examples to create our first scripts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06452v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alejandro Garces-Ruiz</dc:creator>
    </item>
    <item>
      <title>IETI-based Low-Rank method for PDE-constrained optimization</title>
      <link>https://arxiv.org/abs/2405.06458</link>
      <description>arXiv:2405.06458v1 Announce Type: new 
Abstract: Isogeometric Analysis (IgA) is a versatile method for the discretization of partial differential equations on complex domains, which arise in various applications of science and engineering. Some complex geometries can be better described as a computational domain by a multi-patch approach, where each patch is determined by a tensor product Non-Uniform Rational Basis Splines (NURBS) parameterization. This allows on the one hand to consider the problem of the complex assembly of mass or stiffness matrices (or tensors) over the whole geometry locally on the individual smaller patches, and on the other hand it is possible to perform local mesh refinements independently on each patch, allowing efficient local refinement in regions of high activity where higher accuracy is required, while coarser meshes can be used elsewhere. Furthermore, the information about differing material models or properties that are to apply in a subdomain of the geometry can be included in the patch in which this subdomain is located. For this it must be ensured that the approximate solution is continuous over the entire computational domain and therefore at the interfaces of two (or more) patches. The most promising approach for this problem, which transfers the idea of Finite Element Tearing and Interconnecting (FETI) methods into the isogeometric setup, was the IsogEometric Tearing and Interconnecting (IETI) method, where by introducing a constraints matrix and associated Lagrange multipliers and formulating it into a dual problem, depending only on the Lagrange multipliers, continuity at the interfaces was ensured in solving the resulting system. In this paper we illustrate that low-rank methods based on the tensor-train format can be generalised for a multi-patch IgA setup, which follows the IETI idea.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06458v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandra B\"unger, Tom-Christian Riemer, Martin Stoll</dc:creator>
    </item>
    <item>
      <title>Constructing Approximations to Bivariate Piecewise-Smooth Functions</title>
      <link>https://arxiv.org/abs/2405.06462</link>
      <description>arXiv:2405.06462v1 Announce Type: new 
Abstract: This paper demonstrates that the space of piecewise smooth functions can be well approximated by the space of functions defined by a set of simple (non-linear) operations on smooth uniform splines. The examples include bivariate functions with jump discontinuities or normal discontinuities across curves, and even across more involved geometries such as a 3-corner. The given data may be uniform or non-uniform, and noisy, and the approximation procedure involves non-linear least-squares minimization. Also included is a basic approximation theorem for functions with jump discontinuity across a smooth curve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06462v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>David Levin (Tel Aviv University)</dc:creator>
    </item>
    <item>
      <title>Single-seed generation of Brownian paths and integrals for adaptive and high order SDE solvers</title>
      <link>https://arxiv.org/abs/2405.06464</link>
      <description>arXiv:2405.06464v1 Announce Type: new 
Abstract: Despite the success of adaptive time-stepping in ODE simulation, it has so far seen few applications for Stochastic Differential Equations (SDEs). To simulate SDEs adaptively, methods such as the Virtual Brownian Tree (VBT) have been developed, which can generate Brownian motion (BM) non-chronologically. However, in most applications, knowing only the values of Brownian motion is not enough to achieve a high order of convergence; for that, we must compute time-integrals of BM such as $\int_s^t W_r \, dr$. With the aim of using high order SDE solvers adaptively, we extend the VBT to generate these integrals of BM in addition to the Brownian increments. A JAX-based implementation of our construction is included in the popular Diffrax library (https://github.com/patrick-kidger/diffrax).
  Since the entire Brownian path produced by VBT is uniquely determined by a single PRNG seed, previously generated samples need not be stored, which results in a constant memory footprint and enables experiment repeatability and strong error estimation. Based on binary search, the VBT's time complexity is logarithmic in the tolerance parameter $\varepsilon$. Unlike the original VBT algorithm, which was only precise at some dyadic times, we prove that our construction exactly matches the joint distribution of the Brownian motion and its time integrals at any query times, provided they are at least $\varepsilon$ apart.
  We present two applications of adaptive high order solvers enabled by our new VBT. Using adaptive solvers to simulate a high-volatility CIR model, we achieve more than twice the convergence order of constant stepping. We apply an adaptive third order underdamped or kinetic Langevin solver to an MCMC problem, where our approach outperforms the No U-Turn Sampler, while using only a tenth of its function evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06464v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andra\v{z} Jelin\v{c}i\v{c}, James Foster, Patrick Kidger</dc:creator>
    </item>
    <item>
      <title>Can Neural Networks learn Finite Elements?</title>
      <link>https://arxiv.org/abs/2405.06488</link>
      <description>arXiv:2405.06488v1 Announce Type: new 
Abstract: The aim of this note is to construct a neural network for which the linear finite element approximation of a simple one dimensional boundary value problem is a minimum of the cost function to find out if the neural network is able to reproduce the finite element approximation. The deepest goal is to shed some light on the problems one encounters when trying to use neural networks to approximate partial differential equations</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06488v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julia Novo, Eduardo Terr\'es</dc:creator>
    </item>
    <item>
      <title>A posteriori error estimates based on multilevel decompositions with large problems on the coarsest level</title>
      <link>https://arxiv.org/abs/2405.06532</link>
      <description>arXiv:2405.06532v1 Announce Type: new 
Abstract: Multilevel methods represent a powerful approach in numerical solution of partial differential equations. The multilevel structure can also be used to construct estimates for total and algebraic errors of computed approximations. This paper deals with residual-based error estimates that are based on properties of quasi-interpolation operators, stable-splittings, or frames. We focus on the settings where the system matrix on the coarsest level is still large and the associated terms in the estimates can only be approximated. We show that the way in which the error term associated with the coarsest level is approximated is substantial. It can significantly affect both the efficiency (accuracy) of the overall error estimates and their robustness with respect to the size of the coarsest problem. The newly proposed approximation of the coarsest-level term is based on using the conjugate gradient method with an appropriate stopping criterion. We prove that the resulting estimates are efficient and robust with respect to the size of the coarsest-level problem. Numerical experiments illustrate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06532v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Petr Vacek, Jan Pape\v{z}, Zden\v{e}k Strako\v{s}</dc:creator>
    </item>
    <item>
      <title>Gradient Flow Based Phase-Field Modeling Using Separable Neural Networks</title>
      <link>https://arxiv.org/abs/2405.06119</link>
      <description>arXiv:2405.06119v1 Announce Type: cross 
Abstract: The $L^2$ gradient flow of the Ginzburg-Landau free energy functional leads to the Allen Cahn equation that is widely used for modeling phase separation. Machine learning methods for solving the Allen-Cahn equation in its strong form suffer from inaccuracies in collocation techniques, errors in computing higher-order spatial derivatives through automatic differentiation, and the large system size required by the space-time approach. To overcome these limitations, we propose a separable neural network-based approximation of the phase field in a minimizing movement scheme to solve the aforementioned gradient flow problem. At each time step, the separable neural network is used to approximate the phase field in space through a low-rank tensor decomposition thereby accelerating the derivative calculations. The minimizing movement scheme naturally allows for the use of Gauss quadrature technique to compute the functional. A `$tanh$' transformation is applied on the neural network-predicted phase field to strictly bounds the solutions within the values of the two phases. For this transformation, a theoretical guarantee for energy stability of the minimizing movement scheme is established. Our results suggest that bounding the solution through this transformation is the key to effectively model sharp interfaces through separable neural network. The proposed method outperforms the state-of-the-art machine learning methods for phase separation problems and is an order of magnitude faster than the finite element method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06119v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Revanth Mattey, Susanta Ghosh</dc:creator>
    </item>
    <item>
      <title>A discontinuous Galerkin scheme for elliptic equations on extremely stretched grids</title>
      <link>https://arxiv.org/abs/2405.06120</link>
      <description>arXiv:2405.06120v1 Announce Type: cross 
Abstract: Discontinuous Galerkin (DG) methods for solving elliptic equations are gaining popularity in the computational physics community for their high-order spectral convergence and their potential for parallelization on computing clusters. However, problems in numerical relativity with extremely stretched grids, such as initial data problems for binary black holes that impose boundary conditions at large distances from the black holes, have proven challenging for DG methods. To alleviate this problem we have developed a primal DG scheme that is generically applicable to a large class of elliptic equations, including problems on curved and extremely stretched grids. The DG scheme accommodates two widely used initial data formulations in numerical relativity, namely the puncture formulation and the extended conformal thin-sandwich (XCTS) formulation. We find that our DG scheme is able to stretch the grid by a factor of $\sim 10^9$ and hence allows to impose boundary conditions at large distances. The scheme converges exponentially with resolution both for the smooth XCTS problem and for the non-smooth puncture problem. With this method we are able to generate high-quality initial data for binary black hole problems using a parallelizable DG scheme. The code is publicly available in the open-source SpECTRE numerical relativity code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06120v1</guid>
      <category>gr-qc</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nils L. Vu</dc:creator>
    </item>
    <item>
      <title>Open Source Implementations of Numerical Algorithms for Computing the Complete Elliptic Integral of the First Kind</title>
      <link>https://arxiv.org/abs/2212.05694</link>
      <description>arXiv:2212.05694v3 Announce Type: replace 
Abstract: The complete elliptic integral of the first kind (CEI-1) plays in a significant role in mathematics, physics and engineering. There is no simple formula for its computation, thus numerical algorithms are essential for coping with practical problems involved. The commercial implementations for the numerical solutions, such as the functions ellipticK and EllipticK provided by MATLAB and Mathematica respectively, are based on $K(m)$ instead of the usual form $K(k)$ such that $m = k^2$. It is necessary to develop open source implementations for the computation of the CEI-1 in order to avoid potential risks of using commercial software and possible limitations due to the unknown factors. In this paper, the infinite series method, arithmetic-geometric mean (AGM) method, Gauss-Chebyshev method and Gauss-Legendre methods are discussed in details with a top-down strategy. The four key algorithms for computing CEI-1 are designed, verified, validated and tested, which can be utilized in R\&amp; D and be reused properly. Numerical results show that our open source implementations based on $K(k)$ are equivalent to the commercial implementation based on $K(m)$. The general algorithms for computing orthogonal polynomials developed are significant byproducts in the sense of STEM education and scientific computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.05694v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hong-Yan Zhang, Wen-Juan Jiang</dc:creator>
    </item>
    <item>
      <title>The weak Galerkin finite element method for the Steklov eigenvalue problem</title>
      <link>https://arxiv.org/abs/2305.16036</link>
      <description>arXiv:2305.16036v2 Announce Type: replace 
Abstract: This paper introduces the application of the weak Galerkin (WG) finite element method to solve the Steklov eigenvalue problem, focusing on obtaining lower bounds of the eigenvalues. The noncomforming finite element space of the weak Galerkin finite element method is the key to obtain lower bounds of the eigenvalues. The arbitary high order lower bound estimates are given and the guaranteed lower bounds of the eigenvalues are also discussed. Numerical results demonstrate the accuracy and lower bound property of the numerical scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.16036v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shusheng Li, Hehu Xie, Qilong Zhai</dc:creator>
    </item>
    <item>
      <title>A sketch-and-select Arnoldi process</title>
      <link>https://arxiv.org/abs/2306.03592</link>
      <description>arXiv:2306.03592v3 Announce Type: replace 
Abstract: A sketch-and-select Arnoldi process to generate a well-conditioned basis of a Krylov space at low cost is proposed. At each iteration the procedure utilizes randomized sketching to select a limited number of previously computed basis vectors to project out of the current basis vector. The computational cost grows linearly with the dimension of the Krylov space. The subset selection problem for the projection step is approximately solved with a number of heuristic algorithms and greedy methods used in statistical learning and compressive sensing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03592v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Stefan G\"uttel, Igor Simunec</dc:creator>
    </item>
    <item>
      <title>Higher-Order Corrections to Optimisers based on Newton's Method</title>
      <link>https://arxiv.org/abs/2307.03820</link>
      <description>arXiv:2307.03820v2 Announce Type: replace 
Abstract: The Newton, Gauss--Newton and Levenberg--Marquardt methods all use the first derivative of a vector function (the Jacobian) to minimise its sum of squares. When the Jacobian matrix is ill-conditioned, the function varies much faster in some directions than others and the space of possible improvement in sum of squares becomes a long narrow ellipsoid in the linear model. This means that even a small amount of nonlinearity in the problem parameters can cause a proposed point far down the long axis of the ellipsoid to fall outside of the actual curved valley of improved values, even though it is quite nearby. This paper presents a differential equation that `follows' these valleys, based on the technique of geodesic acceleration, which itself provides a 2$^\mathrm{nd}$ order improvement to the Levenberg--Marquardt iteration step. Higher derivatives of this equation are computed that allow $n^\mathrm{th}$ order improvements to the optimisation methods to be derived. These higher-order accelerated methods up to 4$^\mathrm{th}$ order are tested numerically and shown to provide substantial reduction of both number of steps and computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03820v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Stephen Brooks</dc:creator>
    </item>
    <item>
      <title>Stability and regularization for ill-posed Cauchy problem of a stochastic parabolic differential equation</title>
      <link>https://arxiv.org/abs/2308.15741</link>
      <description>arXiv:2308.15741v2 Announce Type: replace 
Abstract: In this paper, we investigate an ill-posed Cauchy problem involving a stochastic parabolic equation. We first establish a Carleman estimate for this equation. Leveraging this estimate, we derive the conditional stability and convergence rate of the Tikhonov regularization method for the aforementioned ill-posed Cauchy problem. To complement our theoretical analysis, we employ kernel-based learning theory to implement the completed Tikhonov regularization method for several numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15741v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fangfang Dou, Peimin L\"u, Yu Wang</dc:creator>
    </item>
    <item>
      <title>Adaptive Finite Element Methods</title>
      <link>https://arxiv.org/abs/2402.07273</link>
      <description>arXiv:2402.07273v2 Announce Type: replace 
Abstract: This is a survey on the theory of adaptive finite element methods (AFEMs), which are fundamental in modern computational science and engineering but whose mathematical assessment is a formidable challenge. We present a self-contained and up-to-date discussion of AFEMs for linear second order elliptic PDEs and dimension d&gt;1, with emphasis on foundational issues. After a brief review of functional analysis and basic finite element theory, including piecewise polynomial approximation in graded meshes, we present the core material for coercive problems. We start with a novel a posteriori error analysis applicable to rough data, which delivers estimators fully equivalent to the solution error. They are used in the design and study of three AFEMs depending on the structure of data. We prove linear convergence of these algorithms and rate-optimality provided the solution and data belong to suitable approximation classes. We also address the relation between approximation and regularity classes. We finally extend this theory to discontinuous Galerkin methods as prototypes of non-conforming AFEMs and beyond coercive problems to inf-sup stable AFEMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07273v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrea Bonito, Claudio Canuto, Ricardo H. Nochetto, Andreas Veeser</dc:creator>
    </item>
    <item>
      <title>Parallelization of Software Systems Test Case Selection Algorithm Based on Singular Value Decomposition</title>
      <link>https://arxiv.org/abs/2206.05494</link>
      <description>arXiv:2206.05494v3 Announce Type: replace-cross 
Abstract: When developing a software system, a change in one part of the system may lead to unwanted changes in other parts of the system. These affected parts may interfere with system performance, so regression testing is used to deal with these disorders. This test seeks to re-measure these sections to prevent these abnormalities, but it is difficult to identify these sections for re-examination. We try to cluster the changes of our software system based on the system functions by singular value decomposition, to be able to use to identify these parts during a new change, to perform the test again. In order to increase speedup, our calculations were performed in parallel on shared memory systems so that by increasing the scale of software systems, an optimal answer could be obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.05494v3</guid>
      <category>cs.SE</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahdi Movahedian Moghaddam</dc:creator>
    </item>
    <item>
      <title>Rethink Decision Tree Traversal</title>
      <link>https://arxiv.org/abs/2209.04825</link>
      <description>arXiv:2209.04825v3 Announce Type: replace-cross 
Abstract: We will show how to implement binary decision tree traversal in the language of matrix computation. Our main contribution is to propose some equivalent algorithms of binary tree traversal based on a novel matrix representation of the hierarchical structure of the decision tree. Our key idea is to travel the binary decision tree by maximum inner product search. We not only implement decision tree methods without the recursive traverse but also delve into the partitioning nature of tree-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.04825v3</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jinxiong Zhang</dc:creator>
    </item>
    <item>
      <title>Network analysis using Krylov subspace trajectories</title>
      <link>https://arxiv.org/abs/2403.01269</link>
      <description>arXiv:2403.01269v2 Announce Type: replace-cross 
Abstract: We describe a set of network analysis methods based on the rows of the Krylov subspace matrix computed from a network adjacency matrix via power iteration using a non-random initial vector. We refer to these node-specific row vectors as Krylov subspace trajectories. While power iteration using a random initial starting vector is commonly applied to the network adjacency matrix to compute eigenvector centrality values, this application only uses the final vector generated after numerical convergence. Importantly, use of a random initial vector means that the intermediate results of power iteration are also random and lack a clear interpretation. To the best of our knowledge, use of intermediate power iteration results for network analysis has been limited to techniques that leverage just a single pre-convergence solution, e.g., Power Iteration Clustering. In this paper, we explore methods that apply power iteration with a non-random inital vector to the network adjacency matrix to generate Krylov subspace trajectories for each node. These non-random trajectories provide important information regarding network structure, node importance, and response to perturbations. We have created this short preprint in part to generate feedback from others in the network analysis community who might be aware of similar existing work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01269v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.NA</category>
      <category>cs.SI</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>H. Robert Frost</dc:creator>
    </item>
    <item>
      <title>Finite Sample Analysis and Bounds of Generalization Error of Gradient Descent in In-Context Linear Regression</title>
      <link>https://arxiv.org/abs/2405.02462</link>
      <description>arXiv:2405.02462v2 Announce Type: replace-cross 
Abstract: Recent studies show that transformer-based architectures emulate gradient descent during a forward pass, contributing to in-context learning capabilities - an ability where the model adapts to new tasks based on a sequence of prompt examples without being explicitly trained or fine tuned to do so. This work investigates the generalization properties of a single step of gradient descent in the context of linear regression with well-specified models. A random design setting is considered and analytical expressions are derived for the statistical properties and bounds of generalization error in a non-asymptotic (finite sample) setting. These expressions are notable for avoiding arbitrary constants, and thus offer robust quantitative information and scaling relationships. These results are contrasted with those from classical least squares regression (for which analogous finite sample bounds are also derived), shedding light on systematic and noise components, as well as optimal step sizes. Additionally, identities involving high-order products of Gaussian random matrices are presented as a byproduct of the analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02462v2</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthik Duraisamy</dc:creator>
    </item>
  </channel>
</rss>
