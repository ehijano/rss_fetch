<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Apr 2025 01:42:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Bounds in Wasserstein Distance for Locally Stationary Functional Time Series</title>
      <link>https://arxiv.org/abs/2504.06453</link>
      <description>arXiv:2504.06453v1 Announce Type: new 
Abstract: Functional time series (FTS) extend traditional methodologies to accommodate data observed as functions/curves. A significant challenge in FTS consists of accurately capturing the time-dependence structure, especially with the presence of time-varying covariates. When analyzing time series with time-varying statistical properties, locally stationary time series (LSTS) provide a robust framework that allows smooth changes in mean and variance over time. This work investigates Nadaraya-Watson (NW) estimation procedure for the conditional distribution of locally stationary functional time series (LSFTS), where the covariates reside in a semi-metric space endowed with a semi-metric. Under small ball probability and mixing condition, we establish convergence rates of NW estimator for LSFTS with respect to Wasserstein distance. The finite-sample performances of the model and the estimation method are illustrated through extensive numerical experiments both on functional simulated and real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06453v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Nino G. Tinio, Mokhtar Z. Alaya, Salim Bouzebda</dc:creator>
    </item>
    <item>
      <title>Estimation of rates in population-age-dependent processes by means of test functions</title>
      <link>https://arxiv.org/abs/2504.06516</link>
      <description>arXiv:2504.06516v1 Announce Type: new 
Abstract: This paper aims to develop practical applications of the model for the highly technical measure-valued populations developed by the authors in \cite{FanEtal20}. We consider the problem of estimation of parameters in the general age and population-dependent model, in which the individual birth and death rates depend not only on the age of the individual but also on the whole population composition. We derive new estimators of the rates based on the use of test functions in the functional Law of Large Numbers and Central Limit Theorem for populations with a large carrying capacity. We consider the rates to be simple functions, that take finitely many values both in age $x$ and measure $A$, which leads to systems of linear equations. The proposed method of using test functions for estimation is a radically new approach which can be applied to a wide range of models of dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06516v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>q-bio.PE</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Yen Fan, Kais Hamza, Fima C. Klebaner, Ziwen Zhong</dc:creator>
    </item>
    <item>
      <title>An Unbiased Variance Estimator with Denominator $N$</title>
      <link>https://arxiv.org/abs/2504.06569</link>
      <description>arXiv:2504.06569v1 Announce Type: new 
Abstract: Standard practice obtains an unbiased variance estimator by dividing by $N-1$ rather than $N$. Yet if only half the data are used to compute the mean, dividing by $N$ can still yield an unbiased estimator. We show that an alternative mean estimator $\hat{X} = \sum c_n X_n$ can produce such an unbiased variance estimator with denominator $N$. These average-adjusted unbiased variance (AAUV) permit infinitely many unbiased forms, though each has larger variance than the usual sample variance. Moreover, permuting and symmetrizing any AAUV recovers the classical formula with denominator $N-1$. We further demonstrate a continuum of unbiased variances by interpolating between the standard and AAUV-based means. Extending this average-adjusting method to higher-order moments remains a topic for future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06569v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dai Akita</dc:creator>
    </item>
    <item>
      <title>Weak Signals and Heavy Tails: Machine-learning meets Extreme Value Theory</title>
      <link>https://arxiv.org/abs/2504.06984</link>
      <description>arXiv:2504.06984v1 Announce Type: new 
Abstract: The masses of data now available have opened up the prospect of discovering weak signals using machine-learning algorithms, with a view to predictive or interpretation tasks. As this survey of recent results attempts to show, bringing multivariate extreme value theory and statistical learning theory together in a common, non-parametric and non-asymptotic framework makes it possible to design and analyze new methods for exploiting the scarce information located in distribution tails in these purposes. This article reviews recently proved theoretical tools for establishing guarantees for supervised or unsupervised algorithms learning from a fraction of extreme data. These are mainly exponential maximal deviation inequalities tailored to low-probability regions and concentration results for stochastic processes empirically describing the behavior of extreme observations, their dependence structure in particular. Under appropriate assumptions of regular variation, several illustrative applications are then examined: classification, regression, anomaly detection, model selection via cross-validation. For these, generalization results are established inspired by the classical bounds in statistical learning theory. In the same spirit, it is also shown how to adapt the popular high-dimensional lasso technique in the context of extreme values for the covariates with generalization guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06984v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Stephan Cl\'emen\c{c}on, Anne Sabourin</dc:creator>
    </item>
    <item>
      <title>Deep spatio-temporal point processes: Advances and new directions</title>
      <link>https://arxiv.org/abs/2504.06364</link>
      <description>arXiv:2504.06364v1 Announce Type: cross 
Abstract: Spatio-temporal point processes (STPPs) model discrete events distributed in time and space, with important applications in areas such as criminology, seismology, epidemiology, and social networks. Traditional models often rely on parametric kernels, limiting their ability to capture heterogeneous, nonstationary dynamics. Recent innovations integrate deep neural architectures -- either by modeling the conditional intensity function directly or by learning flexible, data-driven influence kernels, substantially broadening their expressive power. This article reviews the development of the deep influence kernel approach, which enjoys statistical explainability, since the influence kernel remains in the model to capture the spatiotemporal propagation of event influence and its impact on future events, while also possessing strong expressive power, thereby benefiting from both worlds. We explain the main components in developing deep kernel point processes, leveraging tools such as functional basis decomposition and graph neural networks to encode complex spatial or network structures, as well as estimation using both likelihood-based and likelihood-free methods, and address computational scalability for large-scale data. We also discuss the theoretical foundation of kernel identifiability. Simulated and real-data examples highlight applications to crime analysis, earthquake aftershock prediction, and sepsis prediction modeling, and we conclude by discussing promising directions for the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06364v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiuyuan Cheng, Zheng Dong, Yao Xie</dc:creator>
    </item>
    <item>
      <title>Sparsified-Learning for Heavy-Tailed Locally Stationary Processes</title>
      <link>https://arxiv.org/abs/2504.06477</link>
      <description>arXiv:2504.06477v1 Announce Type: cross 
Abstract: Sparsified Learning is ubiquitous in many machine learning tasks. It aims to regularize the objective function by adding a penalization term that considers the constraints made on the learned parameters. This paper considers the problem of learning heavy-tailed LSP. We develop a flexible and robust sparse learning framework capable of handling heavy-tailed data with locally stationary behavior and propose concentration inequalities. We further provide non-asymptotic oracle inequalities for different types of sparsity, including $\ell_1$-norm and total variation penalization for the least square loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06477v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingjie Wang, Mokhtar Z. Alaya, Salim Bouzebda, Xinsheng Liu</dc:creator>
    </item>
    <item>
      <title>Assessing dominance in survival functions: A test for right-censored data</title>
      <link>https://arxiv.org/abs/2504.07012</link>
      <description>arXiv:2504.07012v1 Announce Type: cross 
Abstract: This paper proposes a new statistical test to assess the dominance of survival functions in the presence of right-censored data. Traditional methods, such as the log-rank test, are inadequate for determining whether one survival function consistently dominates another, especially when survival curves cross. The proposed test is based on the supremum of the difference between Kaplan-Meier estimators and allows for distinguishing between dominance and crossing survival curves. The paper presents the test's asymptotic properties, along with simulations and applications to real datasets. The results demonstrate that the test has high sensitivity for detecting crossings and dominance compared to conventional methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07012v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>F\'elix Belzunce, Carolina Mart\'inez-Riquelme, Jaime Valenciano</dc:creator>
    </item>
    <item>
      <title>Normal approximations for the multivariate inverse Gaussian distribution and asymmetric kernel smoothing on $d$-dimensional half-spaces</title>
      <link>https://arxiv.org/abs/2209.04757</link>
      <description>arXiv:2209.04757v4 Announce Type: replace 
Abstract: This paper introduces a novel density estimator supported on $d$-dimensional half-spaces. It stands out as the first asymmetric kernel density estimator for half-spaces in the literature. Using the multivariate inverse Gaussian (MIG) density from Minami (2003) as the kernel and incorporating locally adaptive parameters, the estimator achieves desirable boundary properties. To analyze its mean integrated squared error (MISE) and asymptotic normality, a local limit theorem and probability metric bounds are established between the MIG and the corresponding multivariate Gaussian distribution with the same mean vector and covariance matrix, which may also be of independent interest. Additionally, a new algorithm for generating MIG random vectors is developed, proving to be faster and more accurate than Minami's algorithm based on a Brownian first-hitting location representation. This algorithm is then used to discuss and compare optimal MISE and likelihood cross-validation bandwidths for the estimator in a simulation study under various target distributions. As an application, the MIG asymmetric kernel is used to smooth the posterior distribution of a generalized Pareto model fitted to large electromagnetic storms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.04757v4</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'eo R. Belzile, Alain Desgagn\'e, Christian Genest, Fr\'ed\'eric Ouimet</dc:creator>
    </item>
    <item>
      <title>Sparse PCA: Phase Transitions in the Critical Regime</title>
      <link>https://arxiv.org/abs/2412.21038</link>
      <description>arXiv:2412.21038v2 Announce Type: replace 
Abstract: This work studies estimation of sparse principal components in high dimensions. Specifically, we consider a class of estimators based on kernel PCA, generalizing the covariance thresholding algorithm proposed by Krauthgamer et al. (2015). Focusing on Johnstone's spiked covariance model, we investigate the "critical" sparsity regime, where the sparsity level $m$, sample size $n$, and dimension $p$ each diverge and $m/\sqrt{n} \rightarrow \beta$, $p/n \rightarrow \gamma$.
  Within this framework, we develop a fine-grained understanding of signal detection and recovery. Our results establish a detectability phase transition, analogous to the Baik--Ben Arous--P\'ech\'e (BBP) transition: above a certain threshold -- depending on the kernel function, $\gamma$, and $\beta$ -- kernel PCA is informative. Conversely, below the threshold, kernel principal components are asymptotically orthogonal to the signal. Notably, above this detection threshold, we find that consistent support recovery is possible with high probability. Sparsity plays a key role in our analysis, and results in more nuanced phenomena than in related studies of kernel PCA with delocalized (dense) components. Finally, we identify optimal kernel functions for detection -- and consequently, support recovery -- and numerical calculations suggest that soft thresholding is nearly optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.21038v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael J. Feldman, Theodor Misiakiewicz, Elad Romanov</dc:creator>
    </item>
    <item>
      <title>Zero patterns in multi-way binary contingency tables with uniform margins</title>
      <link>https://arxiv.org/abs/2502.10143</link>
      <description>arXiv:2502.10143v2 Announce Type: replace 
Abstract: We study the problem of transforming a multi-way contingency table into an equivalent table with uniform margins and same dependence structure. This is an old question which relates to recent advances in copula modeling for discrete random vectors. In this work, we focus on multi-way binary tables and develop novel theory to show how the zero patterns affect the existence of the transformation as well as its statistical interpretability in terms of dependence structure. The implementation of the theory relies on combinatorial and linear programming techniques, which can also be applied to arbitrary multi-way tables. In addition, we investigate which odds ratios characterize the unique solution in relation to specific zero patterns. Several examples are described to illustrate the approach and point to interesting future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10143v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Fontana, Elisa Perrone, Fabio Rapallo</dc:creator>
    </item>
    <item>
      <title>Differentially Private Joint Independence Test</title>
      <link>https://arxiv.org/abs/2503.18721</link>
      <description>arXiv:2503.18721v2 Announce Type: replace 
Abstract: Identification of joint dependence among more than two random vectors plays an important role in many statistical applications, where the data may contain sensitive or confidential information. In this paper, we consider the the $d$-variable Hilbert-Schmidt independence criterion (dHSIC) in the context of differential privacy. Given the limiting distribution of the empirical estimate of dHSIC is complicated Gaussian chaos, constructing tests in the non-privacy regime is typically based on permutation and bootstrap. To detect joint dependence in privacy, we propose a dHSIC-based testing procedure by employing a differentially private permutation methodology. Our method enjoys privacy guarantee, valid level and pointwise consistency, while the bootstrap counterpart suffers inconsistent power. We further investigate the uniform power of the proposed test in dHSIC metric and $L_2$ metric, indicating that the proposed test attains the minimax optimal power across different privacy regimes. As a byproduct, our results also contain the pointwise and uniform power of the non-private permutation dHSIC, addressing an unsolved question remained in Pfister et al. (2018). Both numerical simulations and real data analysis on causal inference suggest our proposed test performs well empirically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18721v2</guid>
      <category>math.ST</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingwei Liu, Yuexin Chen, Wangli Xu</dc:creator>
    </item>
    <item>
      <title>Off-the-grid learning of mixtures from a continuous dictionary</title>
      <link>https://arxiv.org/abs/2207.00171</link>
      <description>arXiv:2207.00171v2 Announce Type: replace-cross 
Abstract: We consider a general non-linear model where the signal is a finite mixture of an unknown, possibly increasing, number of features issued from a continuous dictionary parameterized by a real non-linear parameter. The signal is observed with Gaussian (possibly correlated) noise in either a continuous or a discrete setup. We propose an off-the-grid optimization method, that is, a method which does not use any discretization scheme on the parameter space, to estimate both the non-linear parameters of the features and the linear parameters of the mixture. We use recent results on the geometry of off-the-grid methods to give minimal separation on the true underlying non-linear parameters such that interpolating certificate functions can be constructed. Using also tail bounds for suprema of Gaussian processes we bound the prediction error with high probability. Assuming that the certificate functions can be constructed, our prediction error bound is up to $\log$-factors similar to the rates attained by the Lasso predictor in the linear regression model. We also establish convergence rates that quantify with high probability the quality of estimation for both the linear and the non-linear parameters. We develop in full details our main results for two applications: the Gaussian spike deconvolution and the scaled exponential model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.00171v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cristina Butucea (CREST, FAIRPLAY), Jean-Fran\c{c}ois Delmas (CERMICS), Anne Dutfoy (EDF R\&amp;D), Cl\'ement Hardy (CERMICS, EDF R\&amp;D)</dc:creator>
    </item>
    <item>
      <title>Beyond Conditional Averages: Estimating The Individual Causal Effect Distribution</title>
      <link>https://arxiv.org/abs/2210.16563</link>
      <description>arXiv:2210.16563v2 Announce Type: replace-cross 
Abstract: In recent years, the field of causal inference from observational data has emerged rapidly. The literature has focused on (conditional) average causal effect estimation. When (remaining) variability of individual causal effects (ICEs) is considerable, average effects may be uninformative for an individual. The fundamental problem of causal inference precludes estimating the joint distribution of potential outcomes without making assumptions. In this work, we show that the ICE distribution is identifiable under (conditional) independence of the individual effect and the potential outcome under no exposure, in addition to the common assumptions of consistency, positivity, and conditional exchangeability. Moreover, we present a family of flexible latent variable models that can be used to study individual effect modification and estimate the ICE distribution from cross-sectional data. How such latent variable models can be applied and validated in practice is illustrated in a case study on the effect of Hepatic Steatosis on a clinical precursor to heart failure. Under the assumptions presented, we estimate that 20.6% (95% Bayesian credible interval: 8.9%, 33.6%) of the population has a harmful effect greater than twice the average causal effect.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.16563v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard Post, Edwin van den Heuvel</dc:creator>
    </item>
    <item>
      <title>Multilevel Metamodels: Enhancing Inference, Interpretability, and Generalizability in Monte Carlo Simulation Studies</title>
      <link>https://arxiv.org/abs/2401.07294</link>
      <description>arXiv:2401.07294v4 Announce Type: replace-cross 
Abstract: Metamodels, or the regression analysis of Monte Carlo simulation results, provide a powerful tool to summarize simulation findings. However, an underutilized approach is the multilevel metamodel (MLMM) that accounts for the dependent data structure that arises from fitting multiple models to the same simulated data set. In this study, we articulate the theoretical rationale for the MLMM and illustrate how it can improve the interpretability of simulation results, better account for complex simulation designs, and provide new insights into the generalizability of simulation findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07294v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Joshua Gilbert, Luke Miratrix</dc:creator>
    </item>
    <item>
      <title>Sampling from mixture distributions based on regime-switching diffusions</title>
      <link>https://arxiv.org/abs/2407.13389</link>
      <description>arXiv:2407.13389v3 Announce Type: replace-cross 
Abstract: It is proposed to use stochastic differential equations with state-dependent switching rates (SDEwS) for sampling from finite mixture distributions. An Euler scheme with constant time step for SDEwS is considered. It is shown that the scheme converges with order one in weak sense and also in the ergodic limit. Numerical experiments illustrate the use of SDEwS for sampling from mixture distributions and confirm the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13389v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. V. Tretyakov</dc:creator>
    </item>
    <item>
      <title>Low-Rank Thinning</title>
      <link>https://arxiv.org/abs/2502.12063</link>
      <description>arXiv:2502.12063v4 Announce Type: replace-cross 
Abstract: The goal in thinning is to summarize a dataset using a small set of representative points. Remarkably, sub-Gaussian thinning algorithms like Kernel Halving and Compress can match the quality of uniform subsampling while substantially reducing the number of summary points. However, existing guarantees cover only a restricted range of distributions and kernel-based quality measures and suffer from pessimistic dimension dependence. To address these deficiencies, we introduce a new low-rank analysis of sub-Gaussian thinning that applies to any distribution and any kernel, guaranteeing high-quality compression whenever the kernel or data matrix is approximately low-rank. To demonstrate the broad applicability of the techniques, we design practical sub-Gaussian thinning approaches that improve upon the best known guarantees for approximating attention in transformers, accelerating stochastic gradient training through reordering, and distinguishing distributions in near-linear time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12063v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Annabelle Michael Carrell, Albert Gong, Abhishek Shetty, Raaz Dwivedi, Lester Mackey</dc:creator>
    </item>
  </channel>
</rss>
