<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SE</link>
    <description>cs.SE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Apr 2025 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Predictive Process Monitoring: a comparison survey between different type of event logs</title>
      <link>https://arxiv.org/abs/2504.16933</link>
      <description>arXiv:2504.16933v1 Announce Type: new 
Abstract: The application of Predictive Process Monitoring (PPM) techniques is becoming increasingly widespread due to their capacity to provide organizations with accurate predictions regarding the future behavior of business processes, thereby facilitating more informed decision-making. A plethora of solutions have been proposed in the literature employing these techniques, yet they differ from one another due to a number of factors. However, in light of the growing recognition of the value of object-centric event logs, including in the context of PPM, this survey focuses on the differences among PPM techniques employed with different event logs, namely traditional event logs and object-centric event logs. In addition, the reviewed methods are classified according to the prediction task they address and the specific methodologies they employ.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16933v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Simona Fioretto, Elio Masciari</dc:creator>
    </item>
    <item>
      <title>Finding Important Stack Frames in Large Systems</title>
      <link>https://arxiv.org/abs/2504.16934</link>
      <description>arXiv:2504.16934v1 Announce Type: new 
Abstract: In this work, we developed, integrated, and tested a feature that automatically highlights potentially important frames in stack traces. The feature was implemented in the internal bug-processing tool at JetBrains that processes tens of millions of stack traces. We surveyed 18 developers at JetBrains who provided valuable feedback on the idea and the implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16934v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Khvorov, Yaroslav Golubev, Denis Sushentsev</dc:creator>
    </item>
    <item>
      <title>SCALAR: A Part-of-speech Tagger for Identifiers</title>
      <link>https://arxiv.org/abs/2504.17038</link>
      <description>arXiv:2504.17038v1 Announce Type: new 
Abstract: The paper presents the Source Code Analysis and Lexical Annotation Runtime (SCALAR), a tool specialized for mapping (annotating) source code identifier names to their corresponding part-of-speech tag sequence (grammar pattern). SCALAR's internal model is trained using scikit-learn's GradientBoostingClassifier in conjunction with a manually-curated oracle of identifier names and their grammar patterns. This specializes the tagger to recognize the unique structure of the natural language used by developers to create all types of identifiers (e.g., function names, variable names etc.). SCALAR's output is compared with a previous version of the tagger, as well as a modern off-the-shelf part-of-speech tagger to show how it improves upon other taggers' output for annotating identifiers. The code is available on Github</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17038v1</guid>
      <category>cs.SE</category>
      <category>cs.CL</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian D. Newman, Brandon Scholten, Sophia Testa, Joshua A. C. Behler, Syreen Banabilah, Michael L. Collard, Michael J. Decker, Mohamed Wiem Mkaouer, Marcos Zampieri, Eman Abdullah AlOmar, Reem Alsuhaibani, Anthony Peruma, Jonathan I. Maletic</dc:creator>
    </item>
    <item>
      <title>Exploring the Untapped: Student Perceptions and Participation in OSS</title>
      <link>https://arxiv.org/abs/2504.17051</link>
      <description>arXiv:2504.17051v1 Announce Type: new 
Abstract: Open Source Software (OSS) projects offer valuable opportunities to train the next generation of software engineers while benefiting projects and society as a whole. While research has extensively explored student participation in OSS and its use in software engineering education, student participation in OSS is still low, and the perspectives of students who have never contributed remain underexplored. This study aims to investigate the relationship between students' interest in contributing to OSS and their perceptions of barriers and motivational factors. We developed a theoretical model to understand the relationship between students' perceptions of OSS and their interest in contributing. We then surveyed students majoring in computer science and related fields (N=241). Using structural equation modeling techniques, we tested the model and found that intrinsic and internalized extrinsic motivations are positively associated with interest in contributing to OSS projects, while the impact of extrinsic motivation varies by gender. Comparatively, we found no significant relationship between barriers and interest in contributing. Students suggested several ways to make projects more attractive, including increasing awareness of the importance of OSS. Our findings can help communities better prepare to integrate students and encourage educators to enhance interest in OSS by linking participation to specific motivational factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17051v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Italo Santos, Katia Romero Felizardo, Bianca Trinkereinch, Daniel M. German, Igor Steinmacher, Marco A. Gerosa</dc:creator>
    </item>
    <item>
      <title>Automatically Generating Rules of Malicious Software Packages via Large Language Model</title>
      <link>https://arxiv.org/abs/2504.17198</link>
      <description>arXiv:2504.17198v1 Announce Type: new 
Abstract: Today's security tools predominantly rely on predefined rules crafted by experts, making them poorly adapted to the emergence of software supply chain attacks. To tackle this limitation, we propose a novel tool, RuleLLM, which leverages large language models (LLMs) to automate rule generation for OSS ecosystems. RuleLLM extracts metadata and code snippets from malware as its input, producing YARA and Semgrep rules that can be directly deployed in software development. Specifically, the rule generation task involves three subtasks: crafting rules, refining rules, and aligning rules. To validate RuleLLM's effectiveness, we implemented a prototype system and conducted experiments on the dataset of 1,633 malicious packages. The results are promising that RuleLLM generated 763 rules (452 YARA and 311 Semgrep) with a precision of 85.2\% and a recall of 91.8\%, outperforming state-of-the-art (SOTA) tools and scored-based approaches. We further analyzed generated rules and proposed a rule taxonomy: 11 categories and 38 subcategories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17198v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>the 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks(DSN), 2025</arxiv:journal_reference>
      <dc:creator>XiangRui Zhang, HaoYu Chen, Yongzhong He, Wenjia Niu, Qiang Li</dc:creator>
    </item>
    <item>
      <title>Combining Static and Dynamic Approaches for Mining and Testing Constraints for RESTful API Testing</title>
      <link>https://arxiv.org/abs/2504.17287</link>
      <description>arXiv:2504.17287v1 Announce Type: new 
Abstract: In API testing, deriving logical constraints on API response bodies is crucial in generating the test cases to cover various aspects of RESTful APIs. However, existing approaches are limited to dynamic analysis in which constraints are extracted from the execution of APIs as part of the system under test. The key limitation of such a dynamic approach is its under-estimation in which inputs in API executions are not sufficiently diverse to uncover actual constraints on API response bodies. In this paper, we propose to combine a novel static analysis approach (in which the constraints for API response bodies are mined from API specifications), with the dynamic approach (which relies on API execution data). We leverage large language models (LLMs) to comprehend the API specifications, mine constraints for response bodies, and generate test cases. To reduce LLMs' hallucination, we apply an Observation-Confirmation (OC) scheme which uses initial prompts to contextualize constraints. %, allowing subsequent prompts to more accurately confirm their presence. Our empirical results show that~LLMs with OC prompting achieve high precision in constraint mining with the average of 91.2%. When combining static and dynamic analysis, our tool, RBCTest , achieves a precision of 78.5%. RBCTest detects 107 constraints that the dynamic approach misses and 46 more precise constraints. We also use its generated test cases to detect 21 mismatches between the API specification and actual response data for 8 real-world APIs. Four of the mismatches were, in fact, reported in developers' forums.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17287v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hieu Huynh, Tri Le, Vu Nguyen, Tien N. Nguyen</dc:creator>
    </item>
    <item>
      <title>How Do Communities of ML-Enabled Systems Smell? A Cross-Sectional Study on the Prevalence of Community Smells</title>
      <link>https://arxiv.org/abs/2504.17419</link>
      <description>arXiv:2504.17419v1 Announce Type: new 
Abstract: Effective software development relies on managing both collaboration and technology, but sociotechnical challenges can harm team dynamics and increase technical debt. Although teams working on ML enabled systems are interdisciplinary, research has largely focused on technical issues, leaving their socio-technical dynamics underexplored. This study aims to address this gap by examining the prevalence, evolution, and interrelations of community smells, in open-source ML projects. We conducted an empirical study on 188 repositories from the NICHE dataset using the CADOCS tool to identify and analyze community smells. Our analysis focused on their prevalence, interrelations, and temporal variations. We found that certain smells, such as Prima Donna Effects and Sharing Villainy, are more prevalent and fluctuate over time compared to others like Radio Silence or Organizational Skirmish. These insights might provide valuable support for ML project managers in addressing socio-technical issues and improving team coordination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17419v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giusy Annunziata, Stefano Lambiase, Fabio Palomba, Gemma Catolino, Filomena Ferrucci</dc:creator>
    </item>
    <item>
      <title>Towards Leveraging Large Language Model Summaries for Topic Modeling in Source Code</title>
      <link>https://arxiv.org/abs/2504.17426</link>
      <description>arXiv:2504.17426v1 Announce Type: new 
Abstract: Understanding source code is a topic of great interest in the software engineering community, since it can help programmers in various tasks such as software maintenance and reuse. Recent advances in large language models (LLMs) have demonstrated remarkable program comprehension capabilities, while transformer-based topic modeling techniques offer effective ways to extract semantic information from text. This paper proposes and explores a novel approach that combines these strengths to automatically identify meaningful topics in a corpus of Python programs. Our method consists in applying topic modeling on the descriptions obtained by asking an LLM to summarize the code. To assess the internal consistency of the extracted topics, we compare them against topics inferred from function names alone, and those derived from existing docstrings. Experimental results suggest that leveraging LLM-generated summaries provides interpretable and semantically rich representation of code structure. The promising results suggest that our approach can be fruitfully applied in various software engineering tasks such as automatic documentation and tagging, code search, software reorganization and knowledge discovery in large repositories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17426v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michele Carissimi, Martina Saletta, Claudio Ferretti</dc:creator>
    </item>
    <item>
      <title>Detection, Classification and Prevalence of Self-Admitted Aging Debt</title>
      <link>https://arxiv.org/abs/2504.17428</link>
      <description>arXiv:2504.17428v1 Announce Type: new 
Abstract: Context: Previous research on software aging is limited with focus on dynamic runtime indicators like memory and performance, often neglecting evolutionary indicators like source code comments and narrowly examining legacy issues within the TD context. Objective: We introduce the concept of Aging Debt (AD), representing the increased maintenance efforts and costs needed to keep software updated. We study AD through Self-Admitted Aging Debt (SAAD) observed in source code comments left by software developers. Method: We employ a mixed-methods approach, combining qualitative and quantitative analyses to detect and measure AD in software. This includes framing SAAD patterns from the source code comments after analysing the source code context, then utilizing the SAAD patterns to detect SAAD comments. In the process, we develop a taxonomy for SAAD that reflects the temporal aging of software and its associated debt. Then we utilize the taxonomy to quantify the different types of AD prevalent in OSS repositories. Results: Our proposed taxonomy categorizes temporal software aging into Active and Dormant types. Our extensive analysis of over 9,000+ Open Source Software (OSS) repositories reveals that more than 21% repositories exhibit signs of SAAD as observed from our gold standard SAAD dataset. Notably, Dormant AD emerges as the predominant category, highlighting a critical but often overlooked aspect of software maintenance. Conclusion: As software volume grows annually, so do evolutionary aging and maintenance challenges; our proposed taxonomy can aid researchers in detailed software aging studies and help practitioners develop improved and proactive maintenance strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17428v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.GL</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Murali Sridharan, Mika M\"antyl\"a, Leevi Rantala</dc:creator>
    </item>
    <item>
      <title>Wolves in the Repository: A Software Engineering Analysis of the XZ Utils Supply Chain Attack</title>
      <link>https://arxiv.org/abs/2504.17473</link>
      <description>arXiv:2504.17473v1 Announce Type: new 
Abstract: The digital economy runs on Open Source Software (OSS), with an estimated 90\% of modern applications containing open-source components. While this widespread adoption has revolutionized software development, it has also created critical security vulnerabilities, particularly in essential but under-resourced projects. This paper examines a sophisticated attack on the XZ Utils project (CVE-2024-3094), where attackers exploited not just code, but the entire open-source development process to inject a backdoor into a fundamental Linux compression library. Our analysis reveals a new breed of supply chain attack that manipulates software engineering practices themselves -- from community management to CI/CD configurations -- to establish legitimacy and maintain long-term control. Through a comprehensive examination of GitHub events and development artifacts, we reconstruct the attack timeline, analyze the evolution of attacker tactics. Our findings demonstrate how attackers leveraged seemingly beneficial contributions to project infrastructure and maintenance to bypass traditional security measures. This work extends beyond traditional security analysis by examining how software engineering practices themselves can be weaponized, offering insights for protecting the open-source ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17473v1</guid>
      <category>cs.SE</category>
      <category>cs.CR</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Przymus (Nicolaus Copernicus University in Torun, Poland), Thomas Durieux (TU Delft &amp; Endor Labs, The Netherlands)</dc:creator>
    </item>
    <item>
      <title>Safe to Stay: Psychological Safety Sustains Participation in Pull-based Open Source Projects</title>
      <link>https://arxiv.org/abs/2504.17510</link>
      <description>arXiv:2504.17510v1 Announce Type: new 
Abstract: Psychological safety is the belief that team members can speak up or make mistakes without fear of negative consequences. While it is recognized as important in traditional software teams, its role in open-source development remains understudied. Yet, open-source contributors often collaborate without formal roles or structures, where interpersonal relationship can make or break participation. In this study, we examine whether team-level psychological safety, inferred from code review activities, is associated with contributors' continued participation in open-source projects. Code review is a central and collaborative activity in modern software development, which offers a rich context for observing team interactions. Based on 60,684 pull requests, we construct a psychological safety index using cues such as merge decisions, comment activity, interaction diversity, and mentions. We analyze its relationship with contributors' short-term (after 1 year) and long-term (after 4-5 years) sustained participation using three logistic regression models. Our findings show that contributors are more likely to remain active in repositories with higher levels of psychological safety. Psychological safety is positively associated with both short-term and future sustained participation. However, when prior participation is included, it becomes the stronger predictor of future sustained participation, while the effect of psychological safety becomes smaller. This study introduces a scalable approach to study psychological safety through pull request data and provides new evidence that it matters in open-source development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17510v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Emeralda Sesari, Federica Sarro, Ayushi Rastogi</dc:creator>
    </item>
    <item>
      <title>Large Language Model-Driven Concolic Execution for Highly Structured Test Input Generation</title>
      <link>https://arxiv.org/abs/2504.17542</link>
      <description>arXiv:2504.17542v1 Announce Type: new 
Abstract: How can we perform concolic execution to generate highly structured test inputs for systematically testing parsing programs? Existing concolic execution engines are significantly restricted by (1) input structure-agnostic path constraint selection, leading to the waste of testing effort or missing coverage; (2) limited constraint-solving capability, yielding many syntactically invalid test inputs; (3) reliance on manual acquisition of highly structured seed inputs, resulting in non-continuous testing.
  This paper proposes Cottontail, a new Large Language Model (LLM)-driven concolic execution engine, to mitigate the above limitations. A more complete program path representation, named Expressive Structural Coverage Tree (ESCT), is first constructed to select structure-aware path constraints. Later, an LLM-driven constraint solver based on a Solve-Complete paradigm is designed to solve the path constraints smartly to get test inputs that are not only satisfiable to the constraints but also valid to the input syntax. Finally, a history-guided seed acquisition is employed to obtain new highly structured test inputs either before testing starts or after testing is saturated.
  We implemented Cottontail on top of SymCC and evaluated eight extensively tested open-source libraries across four different formats (XML, SQL, JavaScript, and JSON). The experimental result is promising: it shows that Cottontail outperforms state-of-the-art approaches (SymCC and Marco) by 14.15% and 14.31% in terms of line coverage. Besides, Cottontail found 6 previously unknown vulnerabilities (six new CVEs have been assigned). We have reported these issues to developers, and 4 out of them have been fixed so far.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17542v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoxin Tu, Seongmin Lee, Yuxian Li, Peng Chen, Lingxiao Jiang, Marcel B\"ohme</dc:creator>
    </item>
    <item>
      <title>Modeling Communication Perception in Development Teams Using Monte Carlo Methods</title>
      <link>https://arxiv.org/abs/2504.17610</link>
      <description>arXiv:2504.17610v1 Announce Type: new 
Abstract: Software development is a collaborative task involving diverse development teams, where toxic communication can negatively impact team mood and project success. Mood surveys enable the early detection of underlying tensions or dissatisfaction within development teams, allowing communication issues to be addressed before they escalate, fostering a positive and productive work environment. The mood can be surveyed indirectly by analyzing the text-based communication of the team. However, emotional subjectivity leads to varying sentiment interpretations across team members; a statement perceived neutrally by one developer might be seen as problematic by another developer with a different conversational culture. Early identification of perception volatility can help prevent misunderstandings and enhance team morale while safeguarding the project. This paper analyzes the diversity of perceptions within arbitrary development teams and determines how many team members should report their sentiment to accurately reflect the team's mood. Through a Monte Carlo experiment involving 45 developers, we present a preliminary mathematical model to calculate the minimum agreement among a subset of developers based on the whole team's agreement. This model can guide leadership in mood assessment, demonstrating that omitting even a single member in an average-sized 7-member team can misrepresent the overall mood. Therefore, including all developers in mood surveying is recommended to ensure a reliable evaluation of the team's mood.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17610v1</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc Herrmann, Martin Obaidi, Jil Kl\"under</dc:creator>
    </item>
    <item>
      <title>Seamless Data Migration between Database Schemas with DAMI-Framework: An Empirical Study on Developer Experience</title>
      <link>https://arxiv.org/abs/2504.17662</link>
      <description>arXiv:2504.17662v1 Announce Type: new 
Abstract: Many businesses depend on legacy systems, which often use outdated technology that complicates maintenance and updates. Therefore, software modernization is essential, particularly data migration between different database schemas. Established methodologies, like model transformation and ETL tools, facilitate this migration; they require deep knowledge of database languages and both the source and target schemas. This necessity renders data migration an error-prone and cognitively demanding task. Our objective is to alleviate developers' workloads during schema evolution through our DAMI-Framework. This framework incorporates a domain-specific language (DSL) and a parser to facilitate data migration between database schemas. DAMI-DSL simplifies schema mapping while the parser automates SQL script generation. We assess developer experience in data migration by conducting an empirical evaluation with 21 developers to assess their experiences using our DSL versus traditional SQL. The study allows us to measure their perceptions of the DSL properties and user experience. The participants praised DAMI-DSL for its readability and ease of use. The findings indicate that our DSL reduces data migration efforts compared to SQL scripts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17662v1</guid>
      <category>cs.SE</category>
      <category>cs.DB</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Delfina Ramos-Vidal, Alejandro Corti\~nas, Miguel R. Luaces, Oscar Pedreira, \'Angeles Saavedra Places, Wesley K. G. Assun\c{c}\~ao</dc:creator>
    </item>
    <item>
      <title>Whence Is A Model Fair? Fixing Fairness Bugs via Propensity Score Matching</title>
      <link>https://arxiv.org/abs/2504.17066</link>
      <description>arXiv:2504.17066v1 Announce Type: cross 
Abstract: Fairness-aware learning aims to mitigate discrimination against specific protected social groups (e.g., those categorized by gender, ethnicity, age) while minimizing predictive performance loss. Despite efforts to improve fairness in machine learning, prior studies have shown that many models remain unfair when measured against various fairness metrics. In this paper, we examine whether the way training and testing data are sampled affects the reliability of reported fairness metrics. Since training and test sets are often randomly sampled from the same population, bias present in the training data may still exist in the test data, potentially skewing fairness assessments. To address this, we propose FairMatch, a post-processing method that applies propensity score matching to evaluate and mitigate bias. FairMatch identifies control and treatment pairs with similar propensity scores in the test set and adjusts decision thresholds for different subgroups accordingly. For samples that cannot be matched, we perform probabilistic calibration using fairness-aware loss functions. Experimental results demonstrate that our approach can (a) precisely locate subsets of the test data where the model is unbiased, and (b) significantly reduce bias on the remaining data. Overall, propensity score matching offers a principled way to improve both fairness evaluation and mitigation, without sacrificing predictive performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17066v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>cs.SE</category>
      <category>stat.ML</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kewen Peng, Yicheng Yang, Hao Zhuo, Tim Menzies</dc:creator>
    </item>
    <item>
      <title>Transactional Cloud Applications: Status Quo, Challenges, and Opportunities</title>
      <link>https://arxiv.org/abs/2504.17106</link>
      <description>arXiv:2504.17106v1 Announce Type: cross 
Abstract: Transactional cloud applications such as payment, booking, reservation systems, and complex business workflows are currently being rewritten for deployment in the cloud. This migration to the cloud is happening mainly for reasons of cost and scalability. Over the years, application developers have used different migration approaches, such as microservice frameworks, actors, and stateful dataflow systems.
  The migration to the cloud has brought back data management challenges traditionally handled by database management systems. Those challenges include ensuring state consistency, maintaining durability, and managing the application lifecycle. At the same time, the shift to a distributed computing infrastructure introduced new issues, such as message delivery, task scheduling, containerization, and (auto)scaling.
  Although the data management community has made progress in developing analytical and transactional database systems, transactional cloud applications have received little attention in database research. This tutorial aims to highlight recent trends in the area and discusses open research challenges for the data management community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17106v1</guid>
      <category>cs.DB</category>
      <category>cs.SE</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3722212.3725635</arxiv:DOI>
      <dc:creator>Rodrigo Laigner, George Christodoulou, Kyriakos Psarakis, Asterios Katsifodimos, Yongluan Zhou</dc:creator>
    </item>
    <item>
      <title>FLAG: Formal and LLM-assisted SVA Generation for Formal Specifications of On-Chip Communication Protocols</title>
      <link>https://arxiv.org/abs/2504.17226</link>
      <description>arXiv:2504.17226v1 Announce Type: cross 
Abstract: Formal specifications of on-chip communication protocols are crucial for system-on-chip (SoC) design and verification. However, manually constructing these formal specifications from informal documents remains a tedious and error-prone task. Although recent efforts have used Large Language Models (LLMs) to generate SystemVerilog Assertion (SVA) properties from design documents for Register-Transfer Level (RTL) design verification, in our experience these approaches have not shown promise in generating SVA properties for communication protocols. Since protocol specification documents are unstructured and ambiguous in nature, LLMs often fail to extract the necessary information and end up generating irrelevant or even incorrect properties. We propose FLAG, a two-stage framework to help construct formal protocol specifications from informal documents. In the first stage, a predefined template set is used to generate candidate SVA properties. To avoid missing necessary properties, we develop a grammar-based approach to generate comprehensive template sets that capture critical signal behaviors for various communication protocols. In the second stage, we utilize unambiguous timing diagrams in conjunction with textual descriptions from the specification documents to filter out incorrect properties. A formal approach is first implemented to check the candidate properties and filter out those inconsistent with the timing diagrams. An LLM is then consulted to further remove incorrect properties with respect to the textual description, obtaining the final property set. Experiments on various open-source communication protocols demonstrate the effectiveness of FLAG in generating SVA properties from informal documents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17226v1</guid>
      <category>cs.AR</category>
      <category>cs.SE</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu-An Shih, Annie Lin, Aarti Gupta, Sharad Malik</dc:creator>
    </item>
    <item>
      <title>Identity Control Plane: The Unifying Layer for Zero Trust Infrastructure</title>
      <link>https://arxiv.org/abs/2504.17759</link>
      <description>arXiv:2504.17759v1 Announce Type: cross 
Abstract: This paper introduces the Identity Control Plane (ICP), an architectural framework for enforcing identity-aware Zero Trust access across human users, workloads, and automation systems. The ICP model unifies SPIFFE-based workload identity, OIDC/SAML user identity, and scoped automation credentials via broker-issued transaction tokens. We propose a composable enforcement layer using ABAC policy engines (e.g., OPA, Cedar), aligned with IETF WIMSE drafts and OAuth transaction tokens. The paper includes architectural components, integration patterns, use cases, a comparative analysis with current models, and theorized performance metrics. A FedRAMP and SLSA compliance mapping is also presented. This is a theoretical infrastructure architecture paper intended for security researchers and platform architects. No prior version of this work has been published.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17759v1</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Surya Teja Avirneni</dc:creator>
    </item>
    <item>
      <title>Understanding Practitioners' Expectations on Clear Code Review Comments</title>
      <link>https://arxiv.org/abs/2410.06515</link>
      <description>arXiv:2410.06515v4 Announce Type: replace 
Abstract: The code review comment (CRC) is pivotal in the process of modern code review. It provides reviewers with the opportunity to identify potential bugs, offer constructive feedback, and suggest improvements. Clear and concise code review comments (CRCs) facilitate the communication between developers and are crucial to the correct understanding of the identified issues and proposed solutions. Despite the importance of CRCs' clarity, there is still a lack of guidelines on what constitutes a good clarity and how to evaluate it. In this paper, we conduct a comprehensive study on understanding and evaluating the clarity of CRCs. We first derive a set of attributes related to the clarity of CRCs, namely RIE attributes (i.e., Relevance, Informativeness, and Expression), as well as their corresponding evaluation criteria based on our literature review and survey with practitioners. We then investigate the clarity of CRCs in open-source projects written in nine programming languages and find that a large portion (i.e., 28.8%) of the CRCs lack the clarity in at least one of the attributes. Finally, we explore the potential of automatically evaluating the clarity of CRCs by proposing ClearCRC. Experimental results show that ClearCRC with pre-trained language models is promising for effective evaluation of the clarity of CRCs, achieving a balanced accuracy up to 73.04% and a F-1 score up to 94.61%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06515v4</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junkai Chen, Zhenhao Li, Qiheng Mao, Xing Hu, Kui Liu, Xin Xia</dc:creator>
    </item>
    <item>
      <title>AlphaTrans: A Neuro-Symbolic Compositional Approach for Repository-Level Code Translation and Validation</title>
      <link>https://arxiv.org/abs/2410.24117</link>
      <description>arXiv:2410.24117v4 Announce Type: replace 
Abstract: Code translation transforms programs from one programming language (PL) to another. Several rule-based transpilers have been designed to automate code translation between different pairs of PLs. However, the rules can become obsolete as the PLs evolve and cannot generalize to other PLs. Recent studies have explored the automation of code translation using Large Language Models (LLMs). One key observation is that such techniques may work well for crafted benchmarks but fail to generalize to the scale and complexity of real-world projects with dependencies, custom types, PL-specific features, etc. We propose AlphaTrans, a neuro-symbolic approach to automate repository-level code translation. AlphaTrans translates both source and test code, and employs multiple levels of validation to ensure the translation preserves the functionality of the source program. To break down the problem for LLMs, AlphaTrans leverages program analysis to decompose the program into fragments and translates them in the reverse call order. We leveraged AlphaTrans to translate ten real-world open-source projects consisting of &lt;836, 8575, 2719&gt; classes, methods, and tests. AlphaTrans breaks down these projects into 17874 fragments and translates the entire repository. 96.40% of the translated fragments are syntactically correct, and AlphaTrans validates the translations' runtime behavior and functional correctness for 27.03% and 25.14% of fragments. On average, the integrated translation and validation take 34 hours to translate a project, showing its scalability in practice. For the incorrect translations, AlphaTrans generates a report including existing translation, stack trace, test errors, or assertion failures. We provided these artifacts to two developers to fix the translation bugs in four projects. They were able to fix the issues in 20.1 hours on average and achieve all passing tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24117v4</guid>
      <category>cs.SE</category>
      <category>cs.LG</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3729379</arxiv:DOI>
      <dc:creator>Ali Reza Ibrahimzada, Kaiyao Ke, Mrigank Pawagi, Muhammad Salman Abid, Rangeet Pan, Saurabh Sinha, Reyhaneh Jabbarvand</dc:creator>
    </item>
    <item>
      <title>Less is More: Towards Green Code Large Language Models via Unified Structural Pruning</title>
      <link>https://arxiv.org/abs/2412.15921</link>
      <description>arXiv:2412.15921v2 Announce Type: replace 
Abstract: The extensive application of Large Language Models (LLMs) in generative coding tasks has raised concerns due to their high computational demands and energy consumption. Unlike previous structural pruning methods designed for classification models that deal with lowdimensional classification logits, generative Code LLMs produce high-dimensional token logit sequences, making traditional pruning objectives inherently limited. Moreover, existing single component pruning approaches further constrain the effectiveness when applied to generative Code LLMs. In response, we propose Flab-Pruner, an innovative unified structural pruning method that combines vocabulary, layer, and Feed-Forward Network (FFN) pruning. This approach effectively reduces model parameters while maintaining performance. Additionally, we introduce a customized code instruction data strategy for coding tasks to enhance the performance recovery efficiency of the pruned model. Through extensive evaluations on three state-of-the-art Code LLMs across multiple generative coding tasks, the results demonstrate that Flab-Pruner retains 97% of the original performance after pruning 22% of the parameters and achieves the same or even better performance after post-training. The pruned models exhibit significant improvements in storage, GPU usage, computational efficiency, and environmental impact, while maintaining well robustness. Our research provides a sustainable solution for green software engineering and promotes the efficient deployment of LLMs in real-world generative coding intelligence applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15921v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guang Yang, Yu Zhou, Xiangyu Zhang, Wei Cheng, Ke Liu, Xiang Chen, Terry Yue Zhuo, Taolue Chen</dc:creator>
    </item>
    <item>
      <title>CallNavi, A Challenge and Empirical Study on LLM Function Calling and Routing</title>
      <link>https://arxiv.org/abs/2501.05255</link>
      <description>arXiv:2501.05255v2 Announce Type: replace 
Abstract: API-driven chatbot systems are increasingly integral to software engineering applications, yet their effectiveness hinges on accurately generating and executing API calls. This is particularly challenging in scenarios requiring multi-step interactions with complex parameterization and nested API dependencies. Addressing these challenges, this work contributes to the evaluation and assessment of AI-based software development through three key advancements: (1) the introduction of a novel dataset specifically designed for benchmarking API function selection, parameter generation, and nested API execution; (2) an empirical evaluation of state-of-the-art language models, analyzing their performance across varying task complexities in API function generation and parameter accuracy; and (3) a hybrid approach to API routing, combining general-purpose large language models for API selection with fine-tuned models and prompt engineering for parameter generation. These innovations significantly improve API execution in chatbot systems, offering practical methodologies for enhancing software design, testing, and operational workflows in real-world software engineering contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05255v2</guid>
      <category>cs.SE</category>
      <category>cs.CL</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:journal_reference>The 29th International Conference on Evaluation and Assessment in Software Engineering (EASE 2025)</arxiv:journal_reference>
      <dc:creator>Yewei Song, Xunzhu Tang, Cedric Lothritz, Saad Ezzini, Jacques Klein, Tegawend\'e F. Bissyand\'e, Andrey Boytsov, Ulrick Ble, Anne Goujon</dc:creator>
    </item>
    <item>
      <title>SWE-PolyBench: A multi-language benchmark for repository level evaluation of coding agents</title>
      <link>https://arxiv.org/abs/2504.08703</link>
      <description>arXiv:2504.08703v3 Announce Type: replace 
Abstract: Coding agents powered by large language models have shown impressive capabilities in software engineering tasks, but evaluating their performance across diverse programming languages and real-world scenarios remains challenging. We introduce SWE-PolyBench, a new multi-language benchmark for repository-level, execution-based evaluation of coding agents. SWE-PolyBench contains 2110 instances from 21 repositories and includes tasks in Java (165), JavaScript (1017), TypeScript (729) and Python (199), covering bug fixes, feature additions, and code refactoring. We provide a task and repository-stratified subsample (SWE-PolyBench500) and release an evaluation harness allowing for fully automated evaluation. To enable a more comprehensive comparison of coding agents, this work also presents a novel set of metrics rooted in syntax tree analysis. We evaluate leading open source coding agents on SWE-PolyBench, revealing their strengths and limitations across languages, task types, and complexity classes. Our experiments show that current agents exhibit uneven performances across languages and struggle with complex problems while showing higher performance on simpler tasks. SWE-PolyBench aims to drive progress in developing more versatile and robust AI coding assistants for real-world software engineering. Our datasets and code are available at: https://github.com/amazon-science/SWE-PolyBench</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08703v3</guid>
      <category>cs.SE</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Muhammad Shihab Rashid, Christian Bock, Yuan Zhuang, Alexander Buchholz, Tim Esler, Simon Valentin, Luca Franceschi, Martin Wistuba, Prabhu Teja Sivaprasad, Woo Jung Kim, Anoop Deoras, Giovanni Zappella, Laurent Callot</dc:creator>
    </item>
    <item>
      <title>EditLord: Learning Code Transformation Rules for Code Editing</title>
      <link>https://arxiv.org/abs/2504.15284</link>
      <description>arXiv:2504.15284v2 Announce Type: replace 
Abstract: Code editing is a foundational task in software development, where its effectiveness depends on whether it introduces desired code property changes without changing the original code's intended functionality. Existing approaches often formulate code editing as an implicit end-to-end task, omitting the fact that code-editing procedures inherently consist of discrete and explicit steps. Thus, they suffer from suboptimal performance and lack of robustness and generalization. We introduce EditLord, a code editing framework that makes the code transformation steps explicit. Our key insight is to employ a language model (LM) as an inductive learner to extract code editing rules from the training code pairs as concise meta-rule sets. Such rule sets will be manifested for each training sample to augment them for finetuning or assist in prompting- and iterative-based code editing. EditLordoutperforms the state-of-the-art by an average of 22.7% in editing performance and 58.1% in robustness while achieving 20.2% higher functional correctness across critical software engineering and security applications, LM models, and editing modes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15284v2</guid>
      <category>cs.SE</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weichen Li, Albert Jan, Baishakhi Ray, Chengzhi Mao, Junfeng Yang, Kexin Pei</dc:creator>
    </item>
    <item>
      <title>A Study on Mixup-Inspired Augmentation Methods for Software Vulnerability Detection</title>
      <link>https://arxiv.org/abs/2504.15632</link>
      <description>arXiv:2504.15632v2 Announce Type: replace 
Abstract: Various deep learning (DL) methods have recently been utilized to detect software vulnerabilities. Real-world software vulnerability datasets are rare and hard to acquire, as there is no simple metric for classifying vulnerability. Such datasets are heavily imbalanced, and none of the current datasets are considered huge for DL models. To tackle these problems, a recent work has tried to augment the dataset using the source code and generate realistic single-statement vulnerabilities, which is not quite practical and requires manual checking of the generated vulnerabilities. In this paper, we aim to explore the augmentation of vulnerabilities at the representation level to help current models learn better, which has never been done before to the best of our knowledge. We implement and evaluate five augmentation techniques that augment the embedding of the data and have recently been used for code search, which is a completely different software engineering task. We also introduced a conditioned version of those augmentation methods, which ensures the augmentation does not change the vulnerable section of the vector representation. We show that such augmentation methods can be helpful and increase the F1-score by up to 9.67%, yet they cannot beat Random Oversampling when balancing datasets, which increases the F1-score by 10.82%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15632v2</guid>
      <category>cs.SE</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Seyed Shayan Daneshvar, Da Tan, Shaowei Wang, Carson Leung</dc:creator>
    </item>
  </channel>
</rss>
