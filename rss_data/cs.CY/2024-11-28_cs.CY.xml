<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 Nov 2024 05:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Exploring the Impact of Generative AI on Cross-Border E-Commerce Brand Building in Chinese Tianjin's Manufacturing Sector</title>
      <link>https://arxiv.org/abs/2411.17700</link>
      <description>arXiv:2411.17700v1 Announce Type: new 
Abstract: This study investigates the influence of generative artificial intelligence (AI) on the brand construction of cross-border e-commerce companies in the manufacturing industry in Tianjin, China. We examine the direct effects of generative AI on productivity, the mediating role of productivity in the relationship between generative AI and brand building, and the moderating influence of cross-border e-commerce strategies by developing and testing a comprehensive model. Based on data collected from 210 manufacturing firms in Chinese Tianjin, the results show that generative AI significantly increases productivity, which positively affects branding. Moreover, cross-border e-commerce strategies were found to moderate the impact of generative AI on branding, underscoring the importance of these strategies for using AI technologies to compete successfully in the global marketplace. This study provides valuable theory, empiricism and practical contributions to understanding the role AI plays in manufacturing and electronic commerce. Besides, this study tests several hypotheses to quantify these impacts using a structured model that consists of independent, dependent, mediating and moderating variables. Information is collected through a comprehensive survey of manufacturers in Chinese Tianjin and analyzed to test our proposed model. This study was analyzed and summarized using quantitative analysis, regression and structural equations (PLS-SEM).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17700v1</guid>
      <category>cs.CY</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jun Cui</dc:creator>
    </item>
    <item>
      <title>Basic Research, Lethal Effects: Military AI Research Funding as Enlistment</title>
      <link>https://arxiv.org/abs/2411.17840</link>
      <description>arXiv:2411.17840v1 Announce Type: new 
Abstract: In the context of unprecedented U.S. Department of Defense (DoD) budgets, this paper examines the recent history of DoD funding for academic research in algorithmically based warfighting. We draw from a corpus of DoD grant solicitations from 2007 to 2023, focusing on those addressed to researchers in the field of artificial intelligence (AI). Considering the implications of DoD funding for academic research, the paper proceeds through three analytic sections. In the first, we offer a critical examination of the distinction between basic and applied research, showing how funding calls framed as basic research nonetheless enlist researchers in a war fighting agenda. In the second, we offer a diachronic analysis of the corpus, showing how a 'one small problem' caveat, in which affirmation of progress in military technologies is qualified by acknowledgement of outstanding problems, becomes justification for additional investments in research. We close with an analysis of DoD aspirations based on a subset of Defense Advanced Research Projects Agency (DARPA) grant solicitations for the use of AI in battlefield applications. Taken together, we argue that grant solicitations work as a vehicle for the mutual enlistment of DoD funding agencies and the academic AI research community in setting research agendas. The trope of basic research in this context offers shelter from significant moral questions that military applications of one's research would raise, by obscuring the connections that implicate researchers in U.S. militarism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17840v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Gray Widder, Sireesh Gururaja, Lucy Suchman</dc:creator>
    </item>
    <item>
      <title>"Give me the code" -- Log Analysis of First-Year CS Students' Interactions With GPT</title>
      <link>https://arxiv.org/abs/2411.17855</link>
      <description>arXiv:2411.17855v1 Announce Type: new 
Abstract: The impact of Large Language Models (LLMs) like GPT-3, GPT-4, and Bard in computer science (CS) education is expected to be profound. Students now have the power to generate code solutions for a wide array of programming assignments. For first-year students, this may be particularly problematic since the foundational skills are still in development and an over-reliance on generative AI tools can hinder their ability to grasp essential programming concepts. This paper analyzes the prompts used by 69 freshmen undergraduate students to solve a certain programming problem within a project assignment, without giving them prior prompt training. We also present the rules of the exercise that motivated the prompts, designed to foster critical thinking skills during the interaction. Despite using unsophisticated prompting techniques, our findings suggest that the majority of students successfully leveraged GPT, incorporating the suggested solutions into their projects. Additionally, half of the students demonstrated the ability to exercise judgment in selecting from multiple GPT-generated solutions, showcasing the development of their critical thinking skills in evaluating AI-generated code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17855v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pedro Alves, Bruno Pereira Cipriano</dc:creator>
    </item>
    <item>
      <title>Howzat? Appealing to Expert Judgement for Evaluating Human and AI Next-Step Hints for Novice Programmers</title>
      <link>https://arxiv.org/abs/2411.18151</link>
      <description>arXiv:2411.18151v1 Announce Type: new 
Abstract: Motivation: Students learning to program often reach states where they are stuck and can make no forward progress. An automatically generated next-step hint can help them make forward progress and support their learning. It is important to know what makes a good hint or a bad hint, and how to generate good hints automatically in novice programming tools, for example using Large Language Models (LLMs).
  Method and participants: We recruited 44 Java educators from around the world to participate in an online study. We used a set of real student code states as hint-generation scenarios. Participants used a technique known as comparative judgement to rank a set of candidate next-step Java hints, which were generated by Large Language Models (LLMs) and by five human experienced educators. Participants ranked the hints without being told how they were generated.
  Findings: We found that LLMs had considerable variation in generating high quality next-step hints for programming novices, with GPT-4 outperforming other models tested. When used with a well-designed prompt, GPT-4 outperformed human experts in generating pedagogically valuable hints. A multi-stage prompt was the most effective LLM prompt. We found that the two most important factors of a good hint were length (80--160 words being best), and reading level (US grade 9 or below being best). Offering alternative approaches to solving the problem was considered bad, and we found no effect of sentiment.
  Conclusions: Automatic generation of these hints is immediately viable, given that LLMs outperformed humans -- even when the students' task is unknown. The fact that only the best prompts achieve this outcome suggests that students on their own are unlikely to be able to produce the same benefit. The prompting task, therefore, should be embedded in an expert-designed tool.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18151v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neil C. C. Brown, Pierre Weill-Tessier, Juho Leinonen, Paul Denny, Michael K\"olling</dc:creator>
    </item>
    <item>
      <title>Exploring the Impact of Rewards on Developers' Proactive AI Accountability Behavior</title>
      <link>https://arxiv.org/abs/2411.18393</link>
      <description>arXiv:2411.18393v1 Announce Type: new 
Abstract: The rapid integration of Artificial Intelligence (AI)-based systems offers benefits for various domains of the economy and society but simultaneously raises concerns due to emerging scandals. These scandals have led to the increasing importance of AI accountability to ensure that actors provide justification and victims receive compensation. However, AI accountability has a negative connotation due to its emphasis on penalizing sanctions, resulting in reactive approaches to emerging concerns. To counteract the prevalent negative view and offer a proactive approach to facilitate the AI accountability behavior of developers, we explore rewards as an alternative mechanism to sanctions. We develop a theoretical model grounded in Self-Determination Theory to uncover the potential impact of rewards and sanctions on AI developers. We further identify typical sanctions and bug bounties as potential reward mechanisms by surveying related research from various domains, including cybersecurity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18393v1</guid>
      <category>cs.CY</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.5445/IR/1000175289</arxiv:DOI>
      <dc:creator>L. H. Nguyen, S. Lins, G. Du, A. Sunyaev</dc:creator>
    </item>
    <item>
      <title>Enhancing Project Performance Forecasting using Machine Learning Techniques</title>
      <link>https://arxiv.org/abs/2411.17914</link>
      <description>arXiv:2411.17914v1 Announce Type: cross 
Abstract: Accurate forecasting of project performance metrics is crucial for successfully managing and delivering urban road reconstruction projects. Traditional methods often rely on static baseline plans and fail to consider the dynamic nature of project progress and external factors. This research proposes a machine learning-based approach to forecast project performance metrics, such as cost variance and earned value, for each Work Breakdown Structure (WBS) category in an urban road reconstruction project. The proposed model utilizes time series forecasting techniques, including Autoregressive Integrated Moving Average (ARIMA) and Long Short-Term Memory (LSTM) networks, to predict future performance based on historical data and project progress. The model also incorporates external factors, such as weather patterns and resource availability, as features to enhance the accuracy of forecasts. By applying the predictive power of machine learning, the performance forecasting model enables proactive identification of potential deviations from the baseline plan, which allows project managers to take timely corrective actions. The research aims to validate the effectiveness of the proposed approach using a case study of an urban road reconstruction project, comparing the model's forecasts with actual project performance data. The findings of this research contribute to the advancement of project management practices in the construction industry, offering a data-driven solution for improving project performance monitoring and control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17914v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soheila Sadeghi</dc:creator>
    </item>
    <item>
      <title>Combining Threat Intelligence with IoT Scanning to Predict Cyber Attack</title>
      <link>https://arxiv.org/abs/2411.17931</link>
      <description>arXiv:2411.17931v1 Announce Type: cross 
Abstract: While the Web has become a worldwide platform for communication, hackers and hacktivists share their ideology and communicate with members on the "Dark Web" - the reverse of the Web. Currently, the problems of information overload and difficulty to obtain a comprehensive picture of hackers and cyber-attackers hinder the effective analysis of predicting their activities on the Web. Also, there are currently more objects connected to the internet than there are people in the world and this gap will continue to grow as more and more objects gain ability to directly interface with the Internet. Many technical communities are vigorously pursuing research topics that contribute to the Internet of Things (IoT). In this paper we have proposed a novel methodology for collecting and analyzing the Dark Web information to identify websites of hackers from the Web sea, and how this information can help us in predicting IoT vulnerabilities. This methodology incorporates information collection, analysis, visualization techniques, and exploits some of the IoT devices. Through this research we want to contribute to the existing literature on cyber-security that could potentially guide in both policy-making and intelligence research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17931v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.NI</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jubin Abhishek Soni</dc:creator>
    </item>
    <item>
      <title>GPT as ghostwriter at the White House</title>
      <link>https://arxiv.org/abs/2411.18365</link>
      <description>arXiv:2411.18365v1 Announce Type: cross 
Abstract: Recently several large language models (LLMs) have demonstrated their capability to generate a message in response to a user request. Such scientific breakthroughs promote new perspectives but also some fears. The main focus of this study is to analyze the written style of one LLM called ChatGPT 3.5 by comparing its generated messages with those of the recent US presidents. To achieve this objective, we compare the State of the Union addresses written by Reagan to Obama with those automatically produced by ChatGPT. We found that ChatGPT tends to overuse the lemma "we" as well as nouns and commas. On the other hand, the generated speeches employ less verbs and include, in mean, longer sentences. Even when imposing a given style to ChatGPT, the resulting speech remains distinct from messages written by the target author. Moreover, ChatGPT opts for a neutral tone with mainly positive emotional expressions and symbolic terms (e.g., freedom, nation). Finally, we show that the GPT's style exposes distinct features compared to real presidential addresses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18365v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacques Savoy</dc:creator>
    </item>
    <item>
      <title>ChatGPT as speechwriter for the French presidents</title>
      <link>https://arxiv.org/abs/2411.18382</link>
      <description>arXiv:2411.18382v1 Announce Type: cross 
Abstract: Generative AI proposes several large language models (LLMs) to automatically generate a message in response to users' requests. Such scientific breakthroughs promote new writing assistants but with some fears. The main focus of this study is to analyze the written style of one LLM called ChatGPT by comparing its generated messages with those of the recent French presidents. To achieve this, we compare end-of-the-year addresses written by Chirac, Sarkozy, Hollande, and Macron with those automatically produced by ChatGPT. We found that ChatGPT tends to overuse nouns, possessive determiners, and numbers. On the other hand, the generated speeches employ less verbs, pronouns, and adverbs and include, in mean, too standardized sentences. Considering some words, one can observe that ChatGPT tends to overuse "to must" (devoir), "to continue" or the lemma "we" (nous). Moreover, GPT underuses the auxiliary verb "to be" (^etre), or the modal verbs "to will" (vouloir) or "to have to" (falloir). In addition, when a short text is provided as example to ChatGPT, the machine can generate a short message with a style closed to the original wording. Finally, we reveal that ChatGPT style exposes distinct features compared to real presidential speeches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18382v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dominique Labb\'e, Cyril Labb\'e, Jacques Savoy</dc:creator>
    </item>
    <item>
      <title>Politicians vs ChatGPT. A study of presuppositions in French and Italian political communication</title>
      <link>https://arxiv.org/abs/2411.18403</link>
      <description>arXiv:2411.18403v1 Announce Type: cross 
Abstract: This paper aims to provide a comparison between texts produced by French and Italian politicians on polarizing issues, such as immigration and the European Union, and their chatbot counterparts created with ChatGPT 3.5. In this study, we focus on implicit communication, in particular on presuppositions and their functions in discourse, which have been considered in the literature as a potential linguistic feature of manipulation. This study also aims to contribute to the emerging literature on the pragmatic competences of Large Language Models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18403v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.62408/ai-ling.v1i1</arxiv:DOI>
      <arxiv:journal_reference>Vol. 1 No. 1 (2024): AI-Linguistica</arxiv:journal_reference>
      <dc:creator>Davide Garassino, Vivana Masia, Nicola Brocca, Alice Delorme Benites</dc:creator>
    </item>
    <item>
      <title>Could ChatGPT get an Engineering Degree? Evaluating Higher Education Vulnerability to AI Assistants</title>
      <link>https://arxiv.org/abs/2408.11841</link>
      <description>arXiv:2408.11841v2 Announce Type: replace 
Abstract: AI assistants are being increasingly used by students enrolled in higher education institutions. While these tools provide opportunities for improved teaching and education, they also pose significant challenges for assessment and learning outcomes. We conceptualize these challenges through the lens of vulnerability, the potential for university assessments and learning outcomes to be impacted by student use of generative AI. We investigate the potential scale of this vulnerability by measuring the degree to which AI assistants can complete assessment questions in standard university-level STEM courses. Specifically, we compile a novel dataset of textual assessment questions from 50 courses at EPFL and evaluate whether two AI assistants, GPT-3.5 and GPT-4 can adequately answer these questions. We use eight prompting strategies to produce responses and find that GPT-4 answers an average of 65.8% of questions correctly, and can even produce the correct answer across at least one prompting strategy for 85.1% of questions. When grouping courses in our dataset by degree program, these systems already pass non-project assessments of large numbers of core courses in various degree programs, posing risks to higher education accreditation that will be amplified as these models improve. Our results call for revising program-level assessment design in higher education in light of advances in generative AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11841v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1073/pnas.2414955121</arxiv:DOI>
      <arxiv:journal_reference>PNAS (2024) Vol. 121 | No. 49</arxiv:journal_reference>
      <dc:creator>Beatriz Borges, Negar Foroutan, Deniz Bayazit, Anna Sotnikova, Syrielle Montariol, Tanya Nazaretzky, Mohammadreza Banaei, Alireza Sakhaeirad, Philippe Servant, Seyed Parsa Neshaei, Jibril Frej, Angelika Romanou, Gail Weiss, Sepideh Mamooler, Zeming Chen, Simin Fan, Silin Gao, Mete Ismayilzada, Debjit Paul, Alexandre Sch\"opfer, Andrej Janchevski, Anja Tiede, Clarence Linden, Emanuele Troiani, Francesco Salvi, Freya Behrens, Giacomo Orsi, Giovanni Piccioli, Hadrien Sevel, Louis Coulon, Manuela Pineros-Rodriguez, Marin Bonnassies, Pierre Hellich, Puck van Gerwen, Sankalp Gambhir, Solal Pirelli, Thomas Blanchard, Timoth\'ee Callens, Toni Abi Aoun, Yannick Calvino Alonso, Yuri Cho, Alberto Chiappa, Antonio Sclocchi, \'Etienne Bruno, Florian Hofhammer, Gabriel Pescia, Geovani Rizk, Leello Dadi, Lucas Stoffl, Manoel Horta Ribeiro, Matthieu Bovel, Yueyang Pan, Aleksandra Radenovic, Alexandre Alahi, Alexander Mathis, Anne-Florence Bitbol, Boi Faltings, C\'ecile H\'ebert, Devis Tuia, Fran\c{c}ois Mar\'echal, George Candea, Giuseppe Carleo, Jean-C\'edric Chappelier, Nicolas Flammarion, Jean-Marie F\"urbringer, Jean-Philippe Pellet, Karl Aberer, Lenka Zdeborov\'a, Marcel Salath\'e, Martin Jaggi, Martin Rajman, Mathias Payer, Matthieu Wyart, Michael Gastpar, Michele Ceriotti, Ola Svensson, Olivier L\'ev\^eque, Paolo Ienne, Rachid Guerraoui, Robert West, Sanidhya Kashyap, Valerio Piazza, Viesturs Simanis, Viktor Kuncak, Volkan Cevher, Philippe Schwaller, Sacha Friedli, Patrick Jermann, Tanja K\"aser, Antoine Bosselut</dc:creator>
    </item>
    <item>
      <title>The belief in Moore's Law is undermining ICT climate action</title>
      <link>https://arxiv.org/abs/2411.17391</link>
      <description>arXiv:2411.17391v2 Announce Type: replace 
Abstract: The growth of semiconductor technology is unprecedented, with profound transformational consequences for society. This includes feeding an over-reliance on digital solutions to systemic problems such as climate change ('techno-solutionism'). Such technologies come at a cost: environmental, social and material. We unpack topics arising from "The True Cost of ICT: From Materiality to Techno-Solutionism (TCICT)", a workshop held at the International ICT for Sustainability (ICT4S) conference 2024 in Stockholm, Sweden -- exploring, as a matter of global climate injustice, the drivers and material dependencies of these technologies. We point to the importance of addressing ICT's impacts as a system, rather than purely in terms of efficiency and energy use. We conclude by calling to build a community of like-minded and critical colleagues to address the intersectional climate impacts of the semiconductor industry and the techno-solutionism it embodies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17391v2</guid>
      <category>cs.CY</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrian Friday, Christina Bremer, Oliver Bates, Christian Remy, Srinjoy Mitra, Jan Tobias Muehlberg</dc:creator>
    </item>
    <item>
      <title>The Impact of School and Family Networks on COVID-19 Infections Among Dutch Students: A Study Using Population-Level Registry Data</title>
      <link>https://arxiv.org/abs/2404.08098</link>
      <description>arXiv:2404.08098v3 Announce Type: replace-cross 
Abstract: Understanding the impact of different social interactions is key to improving epidemic models. Here, we use extensive registry data -- including PCR test results and population-level networks -- to investigate the impact of school, family, and other social contacts on SARS-CoV-2 transmission in the Netherlands (June 2020--October 2021). We isolate and compare different contexts of potential SARS-CoV-2 transmission by matching pairs of students based on their attendance at the same or different primary school (in 2020) and secondary school (in 2021) and their geographic proximity. We then calculated the probability of temporally associated infections -- i.e. the probability of both students testing positive within a 14-day period.
  Our results highlight the relative importance of household and family transmission in the spread of SARS-CoV-2 compared to school settings. The probability of temporally associated infections for siblings and parent-child pairs living in the same household was 22.6--23.2\%, and 4.7--7.9\% for family members living in different household. In contrast, the probability of temporally associated infections was 0.52\% for pairs of students living nearby but not attending the same primary or secondary school, 0.66\% for pairs attending different secondary schools but having attended the same primary school, and 1.65\% for pairs attending the same secondary school. Finally, we used multilevel regression analyses to examine how individual, school, and geographic factors contribute to transmission risk. We found that the largest differences in transmission probabilities were due to unobserved individual (60\%) and school-level (35\%) factors. Only a small proportion (3\%) could be attributed to geographic proximity of students or to school size, denomination, or the median income of the school area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08098v3</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 28 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Javier Garcia-Bernardo, Christine Hedde-von Westernhagen, Tom Emery, Albert Jan van Hoek</dc:creator>
    </item>
  </channel>
</rss>
