<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Nov 2024 05:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Capacitated Collection-and-Delivery-Point Location Problem with Random Utility Maximizing Customers</title>
      <link>https://arxiv.org/abs/2411.04200</link>
      <description>arXiv:2411.04200v1 Announce Type: new 
Abstract: We consider a strategic decision-making problem where a logistics provider (LP) seeks to locate collection and delivery points (CDPs) with the objective to reduce total logistics costs. The customers maximize utility that depends on their perception of home delivery service as well as the characteristics of the CDPs, including their location. At the strategic planning level, the LP does not have complete information about customers' preferences and their exact location. We introduce a mixed integer non-linear formulation of the problem and propose two linear reformulations. The latter involve sample average approximations and closest assignment constraints, and in one of the formulations we use scenario aggregation to reduce its size. We solve the formulations with a general-purpose solver using a standard Benders decomposition method. Based on extensive computational results and a realistic case study, we find that the problem can be solved efficiently. However, the level of uncertainty in the instances determines which approach is the most efficient. We use an entropy measure to capture the level of uncertainty that can be computed prior to solving. Furthermore, the results highlight the value of accurate demand modeling, as customer preferences have an important impact on the solutions and associated costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04200v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David Pinzon Ulloa, Ammar Metnan, Emma Frejinger</dc:creator>
    </item>
    <item>
      <title>Chance-Constrained Set Multicover Problem</title>
      <link>https://arxiv.org/abs/2411.04237</link>
      <description>arXiv:2411.04237v1 Announce Type: new 
Abstract: We consider a variant of the set covering problem with uncertain parameters, which we refer to as the chance-constrained set multicover problem (CC-SMCP). In this problem, we assume that there is uncertainty regarding whether a selected set can cover an item, and the objective is to determine a minimum-cost combination of sets that covers each item $i$ at least $k_i$ times with a prescribed probability. To tackle CC-SMCP, we employ techniques of enumerative combinatorics, discrete probability distributions, and combinatorial optimization to derive exact equivalent deterministic reformulations that feature a hierarchy of bounds, and develop the corresponding outer-approximation (OA) algorithm. Additionally, we consider reducing the number of chance constraints via vector dominance relations and reformulate two special cases of CC-SMCP using the ``log-transformation" method and binomial distribution properties. Theoretical results on sampling-based methods, i.e., the sample average approximation (SAA) method and the importance sampling (IS) method, are also studied to approximate the true optimal value of CC-SMCP under a finite discrete probability space. Our numerical experiments demonstrate the effectiveness of the proposed OA method, particularly in scenarios with sparse probability matrices, outperforming sampling-based approaches in most cases and validating the practical applicability of our solution approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04237v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shunyu Yao, Neng Fan, Pavlo Krokhmal</dc:creator>
    </item>
    <item>
      <title>Sequential optimal contracting in continuous time</title>
      <link>https://arxiv.org/abs/2411.04262</link>
      <description>arXiv:2411.04262v1 Announce Type: new 
Abstract: In this paper we study a principal-agent problem in continuous time with multiple lump-sum payments (contracts) paid at different deterministic times. We reduce the non-zero sum Stackelberg game between the principal and agent to a standard stochastic optimal control problem. We apply our result to a benchmark model for which we investigate how different inputs (payment frequencies, payments' distribution, discounting factors, agent's reservation utility) affect the principal's value and agent's optimal compensations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04262v1</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <category>math.PR</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillermo Alonso Alvarez, Erhan Bayraktar, Ibrahim Ekren, Liwei Huang</dc:creator>
    </item>
    <item>
      <title>The one-shot problem: Solution to an open question of finite-fuel singular control with discretionary stopping</title>
      <link>https://arxiv.org/abs/2411.04301</link>
      <description>arXiv:2411.04301v1 Announce Type: new 
Abstract: We introduce a novel 'one-shot' solution technique resolving an open problem (Karatzas et al., Finite-fuel singular control with discretionary stopping, Stochastics 71:1-2 (2000)). Unexpectedly given the convexity of the latter problem, its waiting region is not necessarily connected. Along a typical sample path, the state process may even spend positive time in both of its connected components. The analysis reveals more generally that when fuel is limited, contrary to intuition, the solution without fuel is not necessarily indicative of the solution for small amounts of fuel. To resolve this, we recommend solving the `one-shot' problem, which is one of optimal stopping, prior to employing the usual `guess and verify' solution approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04301v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>John Moriarty, Neofytos Rodosthenous</dc:creator>
    </item>
    <item>
      <title>Correction to: A Lagrangian dual method for two-stage robust optimization with binary uncertainties</title>
      <link>https://arxiv.org/abs/2411.04307</link>
      <description>arXiv:2411.04307v1 Announce Type: new 
Abstract: We provide a correction to the sufficient conditions under which closed-form expressions for the optimal Lagrange multiplier are provided in arXiv:2112.13138 [math.OC]. We first present a simple counterexample where the original conditions are insufficient, highlight where the original proof fails, and then provide modified conditions along with a correct proof of their validity. Finally, although the original paper discusses modifications to their method for problems that may not satisfy any sufficient conditions, we substantiate that discussion along two directions. We first show that computing an optimal Lagrange multiplier can still be done in polynomial time. We then provide complete and correct versions of the corresponding Benders and column-and-constraint generation algorithms in which the original method is used. We also discuss the implications of our findings on computational performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04307v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henri Lefebvre, Anirudh Subramanyam</dc:creator>
    </item>
    <item>
      <title>Variational Analysis of a Nonconvex and Nonsmooth Optimization Problem: An Introduction</title>
      <link>https://arxiv.org/abs/2411.04317</link>
      <description>arXiv:2411.04317v1 Announce Type: new 
Abstract: Variational analysis provides the theoretical foundations and practical tools for constructing optimization algorithms without being restricted to smooth or convex problems. We survey the central concepts in the context of a concrete but broadly applicable problem class from composite optimization in finite dimensions. While prioritizing accessibility over mathematical details, we introduce subgradients of arbitrary functions and the resulting optimality conditions, describe approximations and the need for going pointwise and uniform convergence, and summarize proximal methods. We derive dual problems from parametrization of the actual problem and the resulting relaxations. The paper ends with an introduction to second-order theory and its role in stability analysis of optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04317v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes O. Royset</dc:creator>
    </item>
    <item>
      <title>Approximate Frank-Wolfe Algorithm over Graph-structured Support Set</title>
      <link>https://arxiv.org/abs/2411.04389</link>
      <description>arXiv:2411.04389v1 Announce Type: new 
Abstract: In this project, we reviewed a paper that deals graph-structured convex optimization (GSCO) problem with the approximate Frank-Wolfe (FW) algorithm. We analyzed and implemented the original algorithm and introduced some extensions based on that. Then we conducted experiments to compare the results and concluded that our backtracking line-search method effectively reduced the number of iterations, while our new DMO method (Top-g+ optimal visiting) did not make satisfying enough improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04389v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijian Pan</dc:creator>
    </item>
    <item>
      <title>Improved Approximation Bounds for Moore-Penrose Inverses of Banded Matrices with Applications to Continuous-Time Linear Quadratic Control</title>
      <link>https://arxiv.org/abs/2411.04400</link>
      <description>arXiv:2411.04400v1 Announce Type: new 
Abstract: We present improved approximation bounds for the Moore-Penrose inverses of banded matrices, where the bandedness is induced by an arbitrary metric space. We show that the pseudoinverse of a banded matrix can be approximated by another banded matrix, and the error of approximation is exponentially small in the bandwidth of the approximation. An intuitive corollary can be obtained: the off-diagonal blocks of the pseudoinverse decay exponentially with the distance between the node sets associated with row and column indices, on the given metric space. Our bounds are expressed in terms of the bound of singular values of the system. For saddle point systems, commonly encountered in optimization, we provide the bounds of singular values associated with standard regularity conditions (linear independence constraint qualifications and second-order sufficiency conditions). Our bounds improve previously reported ones (Demko,1984; Bickel, 2012; Shin, 2022). Remarkably, our bounds allow us to establish a perturbation bound for continuous-domain optimal control problems by analyzing the asymptotic limit of their finite difference discretization, which has been challenging with previously reported bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04400v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sungho Shin, Mihai Anitescu</dc:creator>
    </item>
    <item>
      <title>Butterfly factorization with error guarantees</title>
      <link>https://arxiv.org/abs/2411.04506</link>
      <description>arXiv:2411.04506v1 Announce Type: new 
Abstract: In this paper, we investigate the butterfly factorization problem, i.e., the problem of approximating a matrix by a product of sparse and structured factors. We propose a new formal mathematical description of such factors, that encompasses many different variations of butterfly factorization with different choices of the prescribed sparsity patterns. Among these supports, we identify those that ensure that the factorization problem admits an optimum, thanks to a new property called "chainability". For those supports we propose a new butterfly algorithm that yields an approximate solution to the butterfly factorization problem and that is supported by stronger theoretical guarantees than existing factorization methods. Specifically, we show that the ratio of the approximation error by the minimum value is bounded by a constant, independent of the target matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04506v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quoc-Tung Le (OCKHAM), R\'emi Gribonval (OCKHAM), Elisa Riccietti (OCKHAM), L\'eon Zheng (DANTE, LIP)</dc:creator>
    </item>
    <item>
      <title>Measure-to-measure interpolation using Transformers</title>
      <link>https://arxiv.org/abs/2411.04551</link>
      <description>arXiv:2411.04551v1 Announce Type: new 
Abstract: Transformers are deep neural network architectures that underpin the recent successes of large language models. Unlike more classical architectures that can be viewed as point-to-point maps, a Transformer acts as a measure-to-measure map implemented as specific interacting particle system on the unit sphere: the input is the empirical measure of tokens in a prompt and its evolution is governed by the continuity equation. In fact, Transformers are not limited to empirical measures and can in principle process any input measure. As the nature of data processed by Transformers is expanding rapidly, it is important to investigate their expressive power as maps from an arbitrary measure to another arbitrary measure. To that end, we provide an explicit choice of parameters that allows a single Transformer to match $N$ arbitrary input measures to $N$ arbitrary target measures, under the minimal assumption that every pair of input-target measures can be matched by some transport map.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04551v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Borjan Geshkovski, Philippe Rigollet, Dom\`enec Ruiz-Balet</dc:creator>
    </item>
    <item>
      <title>A Comparative Study of Distributed Feedback Optimizing Control Architectures</title>
      <link>https://arxiv.org/abs/2411.04676</link>
      <description>arXiv:2411.04676v1 Announce Type: new 
Abstract: This paper considers the problem of steady-state real-time optimization (RTO) of interconnected systems with a common constraint that couples several units, for example, a shared resource. Such problems are often studied under the context of distributed optimization, where decisions are made locally in each subsystem, and are coordinated to optimize the overall performance. Here, we use distributed feedback-optimizing control framework, where the local systems and the coordinator problems are converted into feedback control problems. This is a powerful scheme that allows us to design feedback control loops, and estimate parameters locally, as well as provide local fast response, allowing different closed-loop time constants for each local subsystem. This paper provides a comparative study of different distributed feedback optimizing control architectures using two case studies. The first case study considers the problem of demand response in a residential energy hub powered by a common renewable energy source, and compares the different feedback optimizing control approaches using simulations. The second case study experimentally validates and compares the different approaches using a lab-scale experimental rig that emulates a subsea oil production network, where the common resource is the gas lift that must be optimally allocated among the wells. %The pros and cons of the different approaches are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04676v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Risvan Dirza, Hari Prasad Varadarajan, Vegard Aas, Sigurd Skogestad, Dinesh Krishnamoorthy</dc:creator>
    </item>
    <item>
      <title>Minimax Linear Regulator Problems for Positive Systems</title>
      <link>https://arxiv.org/abs/2411.04809</link>
      <description>arXiv:2411.04809v1 Announce Type: new 
Abstract: Exceptional are the instances where explicit solutions to optimal control problems are obtainable. Of particular interest are the explicit solutions derived for minimax problems, which provide a framework for tackling challenges characterized by adversarial conditions and uncertainties. This work builds on recent discrete-time research, extending it to a multi-disturbance minimax linear framework for linear time-invariant systems in continuous time. Disturbances are considered to be bounded by elementwise linear constraints, along with unconstrained positive disturbances. Dynamic programming theory is applied to derive explicit solutions to the Hamilton-Jacobi-Bellman (HJB) equation for both finite and infinite horizons. For the infinite horizon a fixed-point method is proposed to compute the solution of the HJB equation. Moreover, the Linear Regulator (LR) problem is introduced, which, analogous to the Linear-Quadratic Regulator (LQR) problem, can be utilized for the stabilization of positive systems. A linear program formulation for the LR problem is proposed which computes the associated stabilizing controller, it it exists. Additionally necessary and sufficient conditions for minimizing the $l_1$-induced gain of the system are derived and characterized through the disturbance penalty of the cost function of the minimax problem class. We motivate the prospective scalability properties of our framework with a large-scale water management network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04809v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alba Gurpegui, Mark Jeeninga, Emma Tegling, Anders Rantzer</dc:creator>
    </item>
    <item>
      <title>Asymptotic regularity of a generalised stochastic Halpern scheme with applications</title>
      <link>https://arxiv.org/abs/2411.04845</link>
      <description>arXiv:2411.04845v1 Announce Type: new 
Abstract: We provide abstract, general and highly uniform rates of asymptotic regularity for a generalized stochastic Halpern-style iteration, which incorporates a second mapping in the style of a Krasnoselskii-Mann iteration. This iteration is general in two ways: First, it incorporates stochasticity in a completely abstract way rather than fixing a sampling method; secondly, it includes as special cases stochastic versions of various schemes from the optimization literature, including Halpern's iteration as well as a Krasnoselskii-Mann iteration with Tikhonov regularization terms in the sense of Bo\c{t}, Csetnek and Meier. For these particular cases, we in particular obtain linear rates of asymptotic regularity, matching (or improving) the currently best known rates for these iterations in stochastic optimization, and quadratic rates of asymptotic regularity are obtained in the context of inner product spaces for the general iteration. We utilize these rates to give bounds on the oracle complexity of such iterations under suitable variance assumptions and batching strategies, again presented in an abstract style. Finally, we sketch how the schemes presented here can be instantiated in the context of reinforcement learning to yield novel methods for Q-learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04845v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicholas Pischke, Thomas Powell</dc:creator>
    </item>
    <item>
      <title>Optimal vaccination strategies in the control of an infectious disease: a SEIRV model for administration of two vaccines</title>
      <link>https://arxiv.org/abs/2411.04910</link>
      <description>arXiv:2411.04910v1 Announce Type: new 
Abstract: In this paper, we study the optimal control for an SEIR model adapted to the vaccination strategy of susceptible individuals. There are factors associated with a vaccination campaign that make this strategy not only a public health issue but also an economic one. In this case, optimal control is important as it minimizes implementation costs. We consider the availability of two vaccines with different efficacy levels, and the control indicates when each vaccine should be used. The optimal strategy specifies in all cases how vaccine purchases should be distributed. For similar efficacy values, we perform a sensitivity analysis on parameters that depend on the intrinsic characteristics of the vaccines. Additionally, we investigate the behavior of the number of infections under the optimal vaccination strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04910v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nelson L. Santos Junior, Jo\~ao A. M. Gondim</dc:creator>
    </item>
    <item>
      <title>Optimal control under unknown intensity with Bayesian learning</title>
      <link>https://arxiv.org/abs/2411.04917</link>
      <description>arXiv:2411.04917v1 Announce Type: new 
Abstract: We consider an optimal control problem inspired by neuroscience, where the dynamics is driven by a Poisson process with a controlled stochastic intensity and an uncertain parameter. Given a prior distribution for the unknown parameter, we describe its evolution according to Bayes' rule. We reformulate the optimization problem using Girsanov's theorem and establish a dynamic programming principle. Finally, we characterize the value function as the unique viscosity solution to a finite-dimensional Hamilton-Jacobi-Bellman equation, which can be solved numerically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04917v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Baradel, Quentin Cormier</dc:creator>
    </item>
    <item>
      <title>SPGD: Steepest Perturbed Gradient Descent Optimization</title>
      <link>https://arxiv.org/abs/2411.04946</link>
      <description>arXiv:2411.04946v1 Announce Type: new 
Abstract: Optimization algorithms are pivotal in advancing various scientific and industrial fields but often encounter obstacles such as trapping in local minima, saddle points, and plateaus (flat regions), which makes the convergence to reasonable or near-optimal solutions particularly challenging. This paper presents the Steepest Perturbed Gradient Descent (SPGD), a novel algorithm that innovatively combines the principles of the gradient descent method with periodic uniform perturbation sampling to effectively circumvent these impediments and lead to better solutions whenever possible. SPGD is distinctively designed to generate a set of candidate solutions and select the one exhibiting the steepest loss difference relative to the current solution. It enhances the traditional gradient descent approach by integrating a strategic exploration mechanism that significantly increases the likelihood of escaping sub-optimal local minima and navigating complex optimization landscapes effectively. Our approach not only retains the directed efficiency of gradient descent but also leverages the exploratory benefits of stochastic perturbations, thus enabling a more comprehensive search for global optima across diverse problem spaces. We demonstrate the efficacy of SPGD in solving the 3D component packing problem, an NP-hard challenge. Preliminary results show a substantial improvement over four established methods, particularly on response surfaces with complex topographies and in multidimensional non-convex continuous optimization problems. Comparative analyses with established 2D benchmark functions highlight SPGD's superior performance, showcasing its ability to navigate complex optimization landscapes. These results emphasize SPGD's potential as a versatile tool for a wide range of optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04946v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amir M. Vahedi, Horea T. Ilies</dc:creator>
    </item>
    <item>
      <title>General monotonicity</title>
      <link>https://arxiv.org/abs/2411.04212</link>
      <description>arXiv:2411.04212v1 Announce Type: cross 
Abstract: This article employs techniques from convex analysis to present characterizations of (maximal) $n-$monotonicity, similar to the well-established characterizations of (maximal) monotonicity found in the existing literature. These characterizations are further illustrated through examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04212v1</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>M. D. Voisei</dc:creator>
    </item>
    <item>
      <title>Optimizing Multi-level Magic State Factories for Fault-Tolerant Quantum Architectures</title>
      <link>https://arxiv.org/abs/2411.04270</link>
      <description>arXiv:2411.04270v1 Announce Type: cross 
Abstract: We propose a novel technique for optimizing a modular fault-tolerant quantum computing architecture, taking into account any desired space-time trade--offs between the number of physical qubits and the fault-tolerant execution time of a quantum algorithm. We consider a concept architecture comprising a dedicated zone as a multi-level magic state factory and a core processor for efficient logical operations, forming a supply chain network for production and consumption of magic states. Using a heuristic algorithm, we solve the multi-objective optimization problem of minimizing space and time subject to a user-defined error budget for the success of the computation, taking the performance of various fault-tolerant protocols such as quantum memory, state preparation, magic state distillation, code growth, and logical operations into account. As an application, we show that physical quantum resource estimation reduces to a simple model involving a small number of key parameters, namely, the circuit volume, the error prefactors ($\mu$) and error suppression rates ($\Lambda$) of the fault-tolerant protocols, and an allowed slowdown factor ($\beta$). We show that, in the proposed architecture, $10^5$--$10^8$ physical qubits are required for quantum algorithms with $T$-counts in the range $10^6$--$10^{15}$ and logical qubit counts in the range $10^2$--$10^4$, when run on quantum computers with quantum memory $\Lambda$ in the range 3--10, for all slowdown factors $\beta \geq 0.2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04270v1</guid>
      <category>quant-ph</category>
      <category>cs.AR</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Allyson Silva, Artur Scherer, Zak Webb, Abdullah Khalid, Bohdan Kulchytskyy, Mia Kramer, Kevin Nguyen, Xiangzhou Kong, Gebremedhin A. Dagnew, Yumeng Wang, Huy Anh Nguyen, Katiemarie Olfert, Pooya Ronagh</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimization Using Ricci Flow</title>
      <link>https://arxiv.org/abs/2411.04292</link>
      <description>arXiv:2411.04292v1 Announce Type: cross 
Abstract: This paper proposes a theoretical framework for modeling and optimizing the bounded functions based on the Fourier series approximation and Ricci flow. Specifically, the initial manifold, $\mathcal{M}_0$ is approximated using Fourier series approximation in conjunction with the center and boundary sampling procedure introduced in the paper. The manifold is iteratively evolved using an algorithm that involves sampling along circles defined by the Riemannian metric tensor. Furthermore, the function is optimized by applying inverse Ricci flow i.e. instead of regularizing the manifold, flow allows for the high curvature regions to be accentuated. This allows for the singularities to occur at potential global optima assuming the deviation of the manifold at any point is smaller than the optimum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04292v1</guid>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Varsha Gupta</dc:creator>
    </item>
    <item>
      <title>Optimal Allocation of Pauli Measurements for Low-rank Quantum State Tomography</title>
      <link>https://arxiv.org/abs/2411.04452</link>
      <description>arXiv:2411.04452v1 Announce Type: cross 
Abstract: The process of reconstructing quantum states from experimental measurements, accomplished through quantum state tomography (QST), plays a crucial role in verifying and benchmarking quantum devices. A key challenge of QST is to find out how the accuracy of the reconstruction depends on the number of state copies used in the measurements. When multiple measurement settings are used, the total number of state copies is determined by multiplying the number of measurement settings with the number of repeated measurements for each setting. Due to statistical noise intrinsic to quantum measurements, a large number of repeated measurements is often used in practice. However, recent studies have shown that even with single-sample measurements--where only one measurement sample is obtained for each measurement setting--high accuracy QST can still be achieved with a sufficiently large number of different measurement settings. In this paper, we establish a theoretical understanding of the trade-off between the number of measurement settings and the number of repeated measurements per setting in QST. Our focus is primarily on low-rank density matrix recovery using Pauli measurements. We delve into the global landscape underlying the low-rank QST problem and demonstrate that the joint consideration of measurement settings and repeated measurements ensures a bounded recovery error for all second-order critical points, to which optimization algorithms tend to converge. This finding suggests the advantage of minimizing the number of repeated measurements per setting when the total number of state copies is held fixed. Additionally, we prove that the Wirtinger gradient descent algorithm can converge to the region of second-order critical points with a linear convergence rate. We have also performed numerical experiments to support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04452v1</guid>
      <category>quant-ph</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen Qin, Casey Jameson, Zhexuan Gong, Michael B. Wakin, Zhihui Zhu</dc:creator>
    </item>
    <item>
      <title>Dynamic Detection of Relevant Objectives and Adaptation to Preference Drifts in Interactive Evolutionary Multi-Objective Optimization</title>
      <link>https://arxiv.org/abs/2411.04547</link>
      <description>arXiv:2411.04547v1 Announce Type: cross 
Abstract: Evolutionary Multi-Objective Optimization Algorithms (EMOAs) are widely employed to tackle problems with multiple conflicting objectives. Recent research indicates that not all objectives are equally important to the decision-maker (DM). In the context of interactive EMOAs, preference information elicited from the DM during the optimization process can be leveraged to identify and discard irrelevant objectives, a crucial step when objective evaluations are computationally expensive. However, much of the existing literature fails to account for the dynamic nature of DM preferences, which can evolve throughout the decision-making process and affect the relevance of objectives. This study addresses this limitation by simulating dynamic shifts in DM preferences within a ranking-based interactive algorithm. Additionally, we propose methods to discard outdated or conflicting preferences when such shifts occur. Building on prior research, we also introduce a mechanism to safeguard relevant objectives that may become trapped in local or global optima due to the diminished correlation with the DM-provided rankings. Our experimental results demonstrate that the proposed methods effectively manage evolving preferences and significantly enhance the quality and desirability of the solutions produced by the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04547v1</guid>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seyed Mahdi Shavarani, Mahmoud Golabi, Richard Allmendinger, Lhassane Idoumghar</dc:creator>
    </item>
    <item>
      <title>Dynkin ghost games with asymmetry and consolation</title>
      <link>https://arxiv.org/abs/2411.04802</link>
      <description>arXiv:2411.04802v1 Announce Type: cross 
Abstract: We study a stopping game of preemption type between two players who both act under uncertain competition. In this framework we introduce, and study the effect of, (i) asymmetry of payoffs, allowing e.g. for different investment costs, and (ii) consolation, i.e. partial compensation to the forestalled stopper. In general, this setting does not offer an explicit equilibrium. Instead, we provide a general verification theorem, which we then use to explore various situations in which a solution can be constructed so that an equilibrium is obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04802v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Ekstr\"om, Yuqiong Wang</dc:creator>
    </item>
    <item>
      <title>Structure Matters: Dynamic Policy Gradient</title>
      <link>https://arxiv.org/abs/2411.04913</link>
      <description>arXiv:2411.04913v1 Announce Type: cross 
Abstract: In this work, we study $\gamma$-discounted infinite-horizon tabular Markov decision processes (MDPs) and introduce a framework called dynamic policy gradient (DynPG). The framework directly integrates dynamic programming with (any) policy gradient method, explicitly leveraging the Markovian property of the environment. DynPG dynamically adjusts the problem horizon during training, decomposing the original infinite-horizon MDP into a sequence of contextual bandit problems. By iteratively solving these contextual bandits, DynPG converges to the stationary optimal policy of the infinite-horizon MDP. To demonstrate the power of DynPG, we establish its non-asymptotic global convergence rate under the tabular softmax parametrization, focusing on the dependencies on salient but essential parameters of the MDP. By combining classical arguments from dynamic programming with more recent convergence arguments of policy gradient schemes, we prove that softmax DynPG scales polynomially in the effective horizon $(1-\gamma)^{-1}$. Our findings contrast recent exponential lower bound examples for vanilla policy gradient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04913v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sara Klein, Xiangyuan Zhang, Tamer Ba\c{s}ar, Simon Weissmann, Leif D\"oring</dc:creator>
    </item>
    <item>
      <title>Automated Tour Design in the Saturnian System</title>
      <link>https://arxiv.org/abs/2210.14996</link>
      <description>arXiv:2210.14996v3 Announce Type: replace 
Abstract: Future missions to Enceladus would benefit from multi-moon tours that leverage V-infinity on resonant orbits to progressively transfer between moons. Such "resonance family hopping" trajectories present a vast search space for global optimization due to the different combinations of available resonances and flyby speeds. The proposed multi-objective tour design algorithm optimizes entire moon tours from Titan to Enceladus via grid-based dynamic programming, in which the computation time is significantly reduced by utilizing a database of V-infinity-leveraging transfers. The result unveils a complete trade space of the moon tour design to Enceladus in a tractable computation time and global optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.14996v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10569-023-10179-8</arxiv:DOI>
      <dc:creator>Yuji Takubo, Damon Landau, Brian Anderson</dc:creator>
    </item>
    <item>
      <title>A stochastic use of the Kurdyka-Lojasiewicz property: Investigation of optimization algorithms behaviours in a non-convex differentiable framework</title>
      <link>https://arxiv.org/abs/2302.06447</link>
      <description>arXiv:2302.06447v5 Announce Type: replace 
Abstract: Stochastic differentiable approximation schemes are widely used for solving high dimensional problems. Most of existing methods satisfy some desirable properties, including conditional descent inequalities, and almost sure (a.s.) convergence guarantees on the objective function, or on the involved gradient. However, for non-convex objective functions, a.s. convergence of the iterates, i.e., the stochastic process, to a critical point is usually not guaranteed, and remains an important challenge. In this article, we develop a framework to bridge the gap between descent-type inequalities and a.s. convergence of the associated stochastic process. Leveraging a novel Kurdyka-Lojasiewicz property, we show convergence guarantees of stochastic processes under mild assumptions on the objective function. We also provide examples of stochastic algorithms benefiting from the proposed framework and derive a.s. convergence guarantees on the iterates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.06447v5</guid>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean-Baptiste Fest, Audrey Repetti, Emilie Chouzenoux</dc:creator>
    </item>
    <item>
      <title>Asynchronous Distributed Optimization with Delay-free Parameters</title>
      <link>https://arxiv.org/abs/2312.06508</link>
      <description>arXiv:2312.06508v2 Announce Type: replace 
Abstract: Existing asynchronous distributed optimization algorithms often use diminishing step-sizes that cause slow practical convergence, or use fixed step-sizes that depend on and decrease with an upper bound of the delays. Not only are such delay bounds hard to obtain in advance, but they also tend to be large and rarely attained, resulting in unnecessarily slow convergence. This paper develops asynchronous versions of two distributed algorithms, Prox-DGD and DGD-ATC, for solving consensus optimization problems over undirected networks. In contrast to alternatives, our algorithms can converge to the fixed point set of their synchronous counterparts using step-sizes that are independent of the delays. We establish convergence guarantees for convex and strongly convex problems under both partial and total asynchrony. We also show that the convergence speed of the two asynchronous methods adjusts to the actual level of asynchrony rather than being constrained by the worst-case. Numerical experiments demonstrate a strong practical performance of our asynchronous algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06508v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuyang Wu, Changxin Liu, Sindri Magnusson, Mikael Johansson</dc:creator>
    </item>
    <item>
      <title>On invariance of observability for BSDEs and its applications to stochastic control systems</title>
      <link>https://arxiv.org/abs/2410.21863</link>
      <description>arXiv:2410.21863v2 Announce Type: replace 
Abstract: In this paper, we establish the invariance of observability for the observed backward stochastic differential equations (BSDEs) with constant coefficients, relative to the filtered probability space. This signifies that the observability of these observed BSDEs with constant coefficients remains unaffected by the selection of the filtered probability space. As an illustrative application, we demonstrate that for stochastic control systems with constant coefficients, weak observability, approximate null controllability with cost, and stabilizability are equivalent across some or any filtered probability spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21863v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bao-Zhu Guo, Huaiqiang Yu, Meixuan Zhang</dc:creator>
    </item>
    <item>
      <title>Spatial Transformers for Radio Map Estimation</title>
      <link>https://arxiv.org/abs/2411.01211</link>
      <description>arXiv:2411.01211v2 Announce Type: replace 
Abstract: Radio map estimation (RME) involves spatial interpolation of radio measurements to predict metrics such as the received signal strength at locations where no measurements were collected. The most popular estimators nowadays project the measurement locations to a regular grid and complete the resulting measurement tensor with a convolutional deep neural network. Unfortunately, these approaches suffer from poor spatial resolution and require a great number of parameters. The first contribution of this paper addresses these limitations by means of an attention-based estimator named Spatial TransfOrmer for Radio Map estimation (STORM). This scheme not only outperforms the existing estimators, but also exhibits lower computational complexity, translation equivariance, rotation equivariance, and full spatial resolution. The second contribution is an extended transformer architecture that allows STORM to perform active sensing, by which the next measurement location is selected based on the previous measurements. This is particularly useful for minimization of drive tests (MDT) in cellular networks, where operators request user equipment to collect measurements. Finally, STORM is extensively validated by experiments with one ray-tracing and two real-measurement datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01211v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pham Q. Viet, Daniel Romero</dc:creator>
    </item>
    <item>
      <title>Preference Robust Optimization with Quasi-Concave Choice Functions in Multi-Attribute Decision-Making: Characterization and Computation</title>
      <link>https://arxiv.org/abs/2008.13309</link>
      <description>arXiv:2008.13309v5 Announce Type: replace-cross 
Abstract: In behavioural economics, a decision maker's (DM's) preferences are often expressed by a preference functional such as expected utility or a distortion risk measure, which assigns a numerical value to a risky prospect. Preference robust optimization (PRO) is about decision making where the DM's preference functional is ambiguous and the optimal decision is based on the worst-case preference functional from a set of plausible ones constructed from available partial information about the DM's true preferences. In this paper, we propose a choice function (a particular class of preference functionals) based PRO model where the DM's preferences over a prospect space satisfy Von Neumann-Morgenstern's (VNM's) axioms of completeness, monotonicity, and continuity. We concentrate on the class of choice functions which are monotonic, quasi-concave, and multi-attribute. The resulting PRO model is broader than the existing expected utility-based PRO models in that: (a) it captures a broader class of DM's preferences; and (b) it can be effectively applied to multi-attribute decision making problems where the DM's preferences over different attributes are related in a nonlinear manner. We propose a cutting plane-type method for evaluating the worst-case choice function and solve the resulting PRO problem by solving a sequence of convex optimization problems. We examine the behavior and scalability of the proposed model and computational schemes numerically on a multi-portfolio optimization problem and a capital allocation problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.13309v5</guid>
      <category>q-fin.RM</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian Wu, William B. Haskell, Wenjie Huang, Huifu Xu</dc:creator>
    </item>
    <item>
      <title>Symmetric Solutions to Symmetric Partial Difference Equations</title>
      <link>https://arxiv.org/abs/2310.00903</link>
      <description>arXiv:2310.00903v2 Announce Type: replace-cross 
Abstract: This paper studies systems of linear difference equations on the lattice $\Z^n$ that are invariant under a finite group of symmetries, and shows that there exist solutions to such systems that are also invariant under this group of symmetries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00903v2</guid>
      <category>math.CA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiva Shankar</dc:creator>
    </item>
    <item>
      <title>A Novel Variational Approach for Multiphoton Microscopy Image Restoration: from PSF Estimation to 3D Deconvolution</title>
      <link>https://arxiv.org/abs/2311.18386</link>
      <description>arXiv:2311.18386v2 Announce Type: replace-cross 
Abstract: In multi-photon microscopy (MPM), a recent in-vivo fluorescence microscopy system, the task of image restoration can be decomposed into two interlinked inverse problems: firstly, the characterization of the Point Spread Function (PSF) and subsequently, the deconvolution (i.e., deblurring) to remove the PSF effect, and reduce noise. The acquired MPM image quality is critically affected by PSF blurring and intense noise. The PSF in MPM is highly spread in 3D and is not well characterized, presenting high variability with respect to the observed objects. This makes the restoration of MPM images challenging. Common PSF estimation methods in fluorescence microscopy, including MPM, involve capturing images of sub-resolution beads, followed by quantifying the resulting ellipsoidal 3D spot. In this work, we revisit this approach, coping with its inherent limitations in terms of accuracy and practicality. We estimate the PSF from the observation of relatively large beads (approximately 1$\mu$m in diameter). This goes through the formulation and resolution of an original non-convex minimization problem, for which we propose a proximal alternating method along with convergence guarantees. Following the PSF estimation step, we then introduce an innovative strategy to deal with the high level multiplicative noise degrading the acquisitions. We rely on a heteroscedastic noise model for which we estimate the parameters. We then solve a constrained optimization problem to restore the image, accounting for the estimated PSF and noise, while allowing a minimal hyper-parameter tuning. Theoretical guarantees are given for the restoration algorithm. These algorithmic contributions lead to an end-to-end pipeline for 3D image restoration in MPM, that we share as a publicly available Python software. We demonstrate its effectiveness through several experiments on both simulated and real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18386v2</guid>
      <category>eess.IV</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1088/1361-6420/ad3c67</arxiv:DOI>
      <arxiv:journal_reference>Inverse Problems, 2024, 40 (6)</arxiv:journal_reference>
      <dc:creator>Julien Ajdenbaum (OPIS, CVN), Emilie Chouzenoux (OPIS, CVN), Claire Lefort (XLIM), S\'egol\`ene Martin (OPIS, CVN), Jean-Christophe Pesquet (OPIS, CVN)</dc:creator>
    </item>
    <item>
      <title>Parameter Symmetry and Noise Equilibrium of Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2402.07193</link>
      <description>arXiv:2402.07193v3 Announce Type: replace-cross 
Abstract: Symmetries are prevalent in deep learning and can significantly influence the learning dynamics of neural networks. In this paper, we examine how exponential symmetries -- a broad subclass of continuous symmetries present in the model architecture or loss function -- interplay with stochastic gradient descent (SGD). We first prove that gradient noise creates a systematic motion (a ``Noether flow") of the parameters $\theta$ along the degenerate direction to a unique initialization-independent fixed point $\theta^*$. These points are referred to as the {\it noise equilibria} because, at these points, noise contributions from different directions are balanced and aligned. Then, we show that the balance and alignment of gradient noise can serve as a novel alternative mechanism for explaining important phenomena such as progressive sharpening/flattening and representation formation within neural networks and have practical implications for understanding techniques like representation normalization and warmup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07193v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liu Ziyin, Mingze Wang, Hongchao Li, Lei Wu</dc:creator>
    </item>
    <item>
      <title>Closed-loop Performance Optimization of Model Predictive Control with Robustness Guarantees</title>
      <link>https://arxiv.org/abs/2403.04655</link>
      <description>arXiv:2403.04655v2 Announce Type: replace-cross 
Abstract: Model mismatch and process noise are two frequently occurring phenomena that can drastically affect the performance of model predictive control (MPC) in practical applications. We propose a principled way to tune the cost function and the constraints of linear MPC schemes to improve the closed-loop performance and robust constraint satisfaction on uncertain nonlinear dynamics with additive noise. The tuning is performed using a novel MPC tuning algorithm based on backpropagation developed in our earlier work. Using the scenario approach, we provide probabilistic bounds on the likelihood of closed-loop constraint violation over a finite horizon. We showcase the effectiveness of the proposed method on linear and nonlinear simulation examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04655v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Zuliani, Efe C. Balta, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Barely Random Algorithms and Collective Metrical Task Systems</title>
      <link>https://arxiv.org/abs/2403.11267</link>
      <description>arXiv:2403.11267v2 Announce Type: replace-cross 
Abstract: We consider metrical task systems on general metric spaces with $n$ points, and show that any fully randomized algorithm can be turned into a randomized algorithm that uses only $2\log n$ random bits, and achieves the same competitive ratio up to a factor $2$. This provides the first order-optimal barely random algorithms for metrical task systems, i.e., which use a number of random bits that does not depend on the number of requests addressed to the system. We discuss implications on various aspects of online decision-making such as: distributed systems, advice complexity, and transaction costs, suggesting broad applicability. We put forward an equivalent view that we call collective metrical task systems where $k$ agents in a metrical task system team up, and suffer the average cost paid by each agent. Our results imply that such a team can be $O(\log^2 n)$-competitive as soon as $k\geq n^2$. In comparison, a single agent is always $\Omega(n)$-competitive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11267v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Romain Cosson, Laurent Massouli\'e</dc:creator>
    </item>
    <item>
      <title>Topology Optimization for the Full-Cell Design of Porous Electrodes in Electrochemical Energy Storage Devices</title>
      <link>https://arxiv.org/abs/2403.18184</link>
      <description>arXiv:2403.18184v2 Announce Type: replace-cross 
Abstract: In this paper, we introduce a density-based topology optimization framework to design porous electrodes for maximum energy storage. We simulate the full cell with a model that incorporates electronic potential, ionic potential, and electrolyte concentration. The system consists of three materials, namely pure liquid electrolyte and the porous solids of the anode and cathode, for which we determine the optimal placement. We use separate electronic potentials to model each electrode, which allows interdigitated designs. As a result, a penalization is required to ensure that the anode and cathode do not touch, i.e., causing a short circuit. We compare multiple 2D designs generated for different fixed conditions, e.g. material properties. A 3D design with complex channel and interlocked structure is also created. All optimized designs are far superior to the traditional monolithic electrode design with respect to energy storage metrics. We observe up to a 750% increase in energy storage for cases with slow effective ionic diffusion within the porous electrode.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18184v2</guid>
      <category>physics.app-ph</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00158-024-03901-z</arxiv:DOI>
      <arxiv:journal_reference>Struct Multidisc Optim 67, 188 (2024)</arxiv:journal_reference>
      <dc:creator>Hanyu Li, Giovanna Bucci, Nicholas W. Brady, Nicholas R. Cross, Victoria M. Ehlinger, Tiras Y. Lin, Miguel Salazar de Troya, Daniel Tortorelli, Marcus A. Worsley, Thomas Roy</dc:creator>
    </item>
    <item>
      <title>Efficient Recovery of Sparse Graph Signals from Graph Filter Outputs</title>
      <link>https://arxiv.org/abs/2405.10649</link>
      <description>arXiv:2405.10649v2 Announce Type: replace-cross 
Abstract: This paper investigates the recovery of a node-domain sparse graph signal from the output of a graph filter. This problem, which is often referred to as the identification of the source of a diffused sparse graph signal, is seminal in the field of graph signal processing (GSP). Sparse graph signals can be used in the modeling of a variety of real-world applications in networks, such as social, biological, and power systems, and enable various GSP tasks, such as graph signal reconstruction, blind deconvolution, and sampling. In this paper, we assume double sparsity of both the graph signal and the graph topology, as well as a low-order graph filter. We propose three algorithms to reconstruct the support set of the input sparse graph signal from the graph filter output samples, leveraging these assumptions and the generalized information criterion (GIC). First, we describe the graph multiple GIC (GM-GIC) method, which is based on partitioning the dictionary elements (graph filter matrix columns) that capture information on the signal into smaller subsets. Then, the local GICs are computed for each subset and aggregated to make a global decision. Second, inspired by the well-known branch and bound (BNB) approach, we develop the graph-based branch and bound GIC (graph-BNB-GIC), and incorporate a new tractable heuristic bound tailored to the graph and graph filter characteristics. In addition, we propose the graph-based first order correction (GFOC) method, which improves existing sparse recovery methods by iteratively examining potential improvements to the GIC cost function by replacing elements from the estimated support set with elements from their one-hop neighborhood. In addition, we investigate the application of our graph-based sparse recovery methods in blind deconvolution scenarios where the graph filter is unknown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10649v2</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gal Morgenstern, Tirza Routtenberg</dc:creator>
    </item>
    <item>
      <title>Simplicity Bias of Two-Layer Networks beyond Linearly Separable Data</title>
      <link>https://arxiv.org/abs/2405.17299</link>
      <description>arXiv:2405.17299v2 Announce Type: replace-cross 
Abstract: Simplicity bias, the propensity of deep models to over-rely on simple features, has been identified as a potential reason for limited out-of-distribution generalization of neural networks (Shah et al., 2020). Despite the important implications, this phenomenon has been theoretically confirmed and characterized only under strong dataset assumptions, such as linear separability (Lyu et al., 2021). In this work, we characterize simplicity bias for general datasets in the context of two-layer neural networks initialized with small weights and trained with gradient flow. Specifically, we prove that in the early training phases, network features cluster around a few directions that do not depend on the size of the hidden layer. Furthermore, for datasets with an XOR-like pattern, we precisely identify the learned features and demonstrate that simplicity bias intensifies during later training stages. These results indicate that features learned in the middle stages of training may be more useful for OOD transfer. We support this hypothesis with experiments on image data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17299v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikita Tsoy, Nikola Konstantinov</dc:creator>
    </item>
    <item>
      <title>A Krasnoselskii-Mann Proximity Algorithm for Markowitz Portfolios with Adaptive Expected Return Level</title>
      <link>https://arxiv.org/abs/2409.13608</link>
      <description>arXiv:2409.13608v2 Announce Type: replace-cross 
Abstract: Markowitz's criterion aims to balance expected return and risk when optimizing the portfolio. The expected return level is usually fixed according to the risk appetite of an investor, then the risk is minimized at this fixed return level. However, the investor may not know which return level is suitable for her/him and the current financial circumstance. It motivates us to find a novel approach that adaptively optimizes this return level and the portfolio at the same time. It not only relieves the trouble of deciding the return level during an investment but also gets more adaptive to the ever-changing financial market than a subjective return level. In order to solve the new model, we propose an exact, convergent, and efficient Krasnoselskii-Mann Proximity Algorithm based on the proximity operator and Krasnoselskii-Mann momentum technique. Extensive experiments show that the proposed method achieves significant improvements over state-of-the-art methods in portfolio optimization. This finding may contribute a new perspective on the relationship between return and risk in portfolio optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13608v2</guid>
      <category>q-fin.PM</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizun Lin, Yongxin He, Zhao-Rong Lai</dc:creator>
    </item>
    <item>
      <title>Robustness to Model Approximation, Empirical Model Learning, and Sample Complexity in Wasserstein Regular MDPs</title>
      <link>https://arxiv.org/abs/2410.14116</link>
      <description>arXiv:2410.14116v2 Announce Type: replace-cross 
Abstract: The paper studies the robustness properties of discrete-time stochastic optimal control under Wasserstein model approximation for both discounted cost and average cost criteria. Specifically, we study the performance loss when applying an optimal policy designed for an approximate model to the true dynamics compared with the optimal cost for the true model under the sup-norm-induced metric, and relate it to the Wasserstein-1 distance between the approximate and true transition kernels. A primary motivation of this analysis is empirical model learning, as well as empirical noise distribution learning, where Wasserstein convergence holds under mild conditions but stronger convergence criteria, such as total variation, may not. We discuss applications of the results to the disturbance estimation problem, where sample complexity bounds are given, and also to a general empirical model learning approach, obtained under either Markov or i.i.d.~learning settings. Further applications regarding the continuity of invariant probability measures with respect to transition kernels are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14116v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yichen Zhou, Yanglei Song, Serdar Y\"uksel</dc:creator>
    </item>
    <item>
      <title>LDAdam: Adaptive Optimization from Low-Dimensional Gradient Statistics</title>
      <link>https://arxiv.org/abs/2410.16103</link>
      <description>arXiv:2410.16103v3 Announce Type: replace-cross 
Abstract: We introduce LDAdam, a memory-efficient optimizer for training large models, that performs adaptive optimization steps within lower dimensional subspaces, while consistently exploring the full parameter space during training. This strategy keeps the optimizer's memory footprint to a fraction of the model size. LDAdam relies on a new projection-aware update rule for the optimizer states that allows for transitioning between subspaces, i.e., estimation of the statistics of the projected gradients. To mitigate the errors due to low-rank projection, LDAdam integrates a new generalized error feedback mechanism, which explicitly accounts for both gradient and optimizer state compression. We prove the convergence of LDAdam under standard assumptions, and show that LDAdam allows for accurate and efficient fine-tuning and pre-training of language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16103v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Robert, Mher Safaryan, Ionut-Vlad Modoranu, Dan Alistarh</dc:creator>
    </item>
  </channel>
</rss>
