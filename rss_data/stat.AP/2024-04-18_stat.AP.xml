<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Apr 2024 04:01:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Periodicity in New York State COVID-19 Hospitalizations Leveraged from the Variable Bandpass Periodic Block Bootstrap</title>
      <link>https://arxiv.org/abs/2404.11006</link>
      <description>arXiv:2404.11006v1 Announce Type: new 
Abstract: The outbreak of the SARS-CoV-2 virus, which led to an unprecedented global pandemic, has underscored the critical importance of understanding seasonal patterns. This knowledge is fundamental for decision-making in healthcare and public health domains. Investigating the presence, intensity, and precise nature of seasonal trends, as well as these temporal patterns, is essential for forecasting future occurrences, planning interventions, and making informed decisions based on the evolution of events over time. This study employs the Variable Bandpass Periodic Block Bootstrap (VBPBB) to separate and analyze different periodic components by frequency in time series data, focusing on annually correlated (PC) principal components. Bootstrapping, a method used to estimate statistical sampling distributions through random sampling with replacement, is particularly useful in this context. Specifically, block bootstrapping, a model-independent resampling method suitable for time series data, is utilized. Its extensions are aimed at preserving the correlation structures inherent in PC processes. The VBPBB applies a bandpass filter to isolate the relevant PC frequency, thereby minimizing contamination from extraneous frequencies and noise. This approach significantly narrows the confidence intervals, enhancing the precision of estimated sampling distributions for the investigated periodic characteristics. Furthermore, we compared the outcomes of block bootstrapping for periodically correlated time series with VBPBB against those from more traditional bootstrapping methods. Our analysis shows VBPBB provides strong evidence of the existence of an annual seasonal PC pattern in hospitalization rates not detectible by other methods, providing timing and confidence intervals for their impact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11006v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Asmaa Ahmad, Edward Valachovic</dc:creator>
    </item>
    <item>
      <title>Deciphering seasonal depression variations and interplays between weather changes, physical activity, and depression severity in real-world settings: Learnings from RADAR-MDD longitudinal mobile health study</title>
      <link>https://arxiv.org/abs/2404.11212</link>
      <description>arXiv:2404.11212v1 Announce Type: new 
Abstract: Prior research has shown that changes in seasons and weather can have a significant impact on depression severity. However, findings are inconsistent across populations, and the interplay between weather, behavior, and depression has not been fully quantified. This study analyzed real-world data from 428 participants (a subset; 68.7% of the cohort) in the RADAR-MDD longitudinal mobile health study to investigate seasonal variations in depression (measured through a remote validated assessment - PHQ-8) and examine the potential interplay between dynamic weather changes, physical activity (monitored via wearables), and depression severity. The clustering of PHQ-8 scores identified four distinct seasonal variations in depression severity: one stable trend and three varying patterns where depression peaks in different seasons. Among these patterns, participants within the stable trend had the oldest average age (p=0.002) and the lowest baseline PHQ-8 score (p=0.003). Mediation analysis assessing the indirect effect of weather on physical activity and depression showed significant differences among participants with different affective responses to weather. These findings illustrate the heterogeneity in individuals' seasonal depression variations and responses to weather, underscoring the necessity for personalized approaches to help understand the impact of environmental factors on the real-world effectiveness of behavioral treatments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11212v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuezhou Zhang, Amos A. Folarin, Yatharth Ranjan, Nicholas Cummins, Zulqarnain Rashid, Pauline Conde, Callum Stewart, Shaoxiong Sun, Srinivasan Vairavan, Faith Matcham, Carolin Oetzmann, Sara Siddi, Femke Lamers, Sara Simblett, Til Wykes, David C. Mohr, Josep Maria Haro, Brenda W. J. H. Penninx, Vaibhav A. Narayan, Matthew Hotopf, Richard J. B. Dobson, Abhishek Pratap, RADAR-CNS consortium</dc:creator>
    </item>
    <item>
      <title>Pharmacokinetic Measurements in Dose Finding Model Guided by Escalation with Overdose Control</title>
      <link>https://arxiv.org/abs/2404.11406</link>
      <description>arXiv:2404.11406v1 Announce Type: new 
Abstract: Oncology drug development starts with a dose escalation phase to find the maximal tolerable dose (MTD). Dose limiting toxicity (DLT) is the primary endpoint for dose escalation phase. Traditionally, model-based dose escalation trial designs recommend a dose for escalation based on an assumed dose-DLT relationship. Pharmacokinetic (PK) data are often available but are currently only used by clinical teams in a subjective manner to aid decision making. Formal incorporation of PK data in dose-escalation models can make the decision process more efficient and lead to an increase in precision. In this talk we present a Bayesian joint modeling framework for incorporating PK data in Oncology dose escalation trials. This framework explores the dose-PK and PK-DLT relationships jointly for better model informed dose escalation decisions. Utility of the proposed model is demonstrated through a real-life case study along with simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11406v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnab Kumar Maity, Satrajit Roy Chowdhury, Ray Li, Lada Markovtsova, Roberto Bugarini</dc:creator>
    </item>
    <item>
      <title>Statistical methods to estimate the impact of gun policy on gun violence</title>
      <link>https://arxiv.org/abs/2404.11506</link>
      <description>arXiv:2404.11506v1 Announce Type: new 
Abstract: Gun violence is a critical public health and safety concern in the United States. There is considerable variability in policy proposals meant to curb gun violence, ranging from increasing gun availability to deter potential assailants (e.g., concealed carry laws or arming school teachers) to restricting access to firearms (e.g., universal background checks or banning assault weapons). Many studies use state-level variation in the enactment of these policies in order to quantify their effect on gun violence. In this paper, we discuss the policy trial emulation framework for evaluating the impact of these policies, and show how to apply this framework to estimating impacts via difference-in-differences and synthetic controls when there is staggered adoption of policies across jurisdictions, estimating the impacts of right-to-carry laws on violent crime as a case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11506v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eli Ben-Michael, Mitchell L. Doucette, Avi Feller, Alexander D. McCourt, Elizabeth A. Stuart</dc:creator>
    </item>
    <item>
      <title>A Bayesian level-set inversion method for simultaneous reconstruction of absorption and diffusion coefficients in diffuse optical tomography</title>
      <link>https://arxiv.org/abs/2404.11552</link>
      <description>arXiv:2404.11552v1 Announce Type: new 
Abstract: In this article, we propose a non-parametric Bayesian level-set method for simultaneous reconstruction of piecewise constant diffusion and absorption coefficients in diffuse optical tomography (DOT). We show that the Bayesian formulation of the corresponding inverse problem is well-posed and the posterior measure as a solution to the inverse problem satisfies a Lipschitz estimate with respect to the measured data in terms of Hellinger distance. We reduce the problem to a shape-reconstruction problem and use level-set priors for the parameters of interest. We demonstrate the efficacy of the proposed method using numerical simulations by performing reconstructions of the original phantom using two reconstruction methods. Posing the inverse problem in a Bayesian paradigm allows us to do statistical inference for the parameters of interest whereby we are able to quantify the uncertainty in the reconstructions for both the methods. This illustrates a key advantage of Bayesian methods over traditional algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11552v1</guid>
      <category>stat.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anuj Abhishek, Thilo Strauss, Taufiquar Khan</dc:creator>
    </item>
    <item>
      <title>Sparse model identification and prediction of microglial cells during ischemic stroke</title>
      <link>https://arxiv.org/abs/2404.10915</link>
      <description>arXiv:2404.10915v1 Announce Type: cross 
Abstract: Dynamics between key neuroinflammatory components, detrimental M1 and beneficial M2 microglial cells, are not fully understood post-ischemic stroke. To discover, model, and predict these dynamics, we use a method based on sparse identification of nonlinear dynamics (SINDy). The resulting data-driven dynamical system involves constant and linear terms but does not include nonlinear interactions between cells. Results show M2 microglial cell dominance of four days. Forward predictions capture potential long-term dynamics of microglial cells and suggest a persistent inflammatory response.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10915v1</guid>
      <category>q-bio.CB</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sara Amato, Andrea Arnold</dc:creator>
    </item>
    <item>
      <title>Partial Identification of Heteroskedastic Structural VARs: Theory and Bayesian Inference</title>
      <link>https://arxiv.org/abs/2404.11057</link>
      <description>arXiv:2404.11057v1 Announce Type: cross 
Abstract: We consider structural vector autoregressions identified through stochastic volatility. Our focus is on whether a particular structural shock is identified by heteroskedasticity without the need to impose any sign or exclusion restrictions. Three contributions emerge from our exercise: (i) a set of conditions under which the matrix containing structural parameters is partially or globally unique; (ii) a statistical procedure to assess the validity of the conditions mentioned above; and (iii) a shrinkage prior distribution for conditional variances centred on a hypothesis of homoskedasticity. Such a prior ensures that the evidence for identifying a structural shock comes only from the data and is not favoured by the prior. We illustrate our new methods using a U.S. fiscal structural model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11057v1</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Helmut L\"utkepohl (Freie Universit\"at Berlin and DIW Berlin), Fei Shang (South China University of Technology and Yuexiu Capital Holdings Group), Luis Uzeda (Bank of Canada), Tomasz Wo\'zniak (University of Melbourne)</dc:creator>
    </item>
    <item>
      <title>Additive Covariance Matrix Models: Modelling Regional Electricity Net-Demand in Great Britain</title>
      <link>https://arxiv.org/abs/2211.07451</link>
      <description>arXiv:2211.07451v3 Announce Type: replace 
Abstract: Forecasts of regional electricity net-demand, consumption minus embedded generation, are an essential input for reliable and economic power system operation, and energy trading. While such forecasts are typically performed region by region, operations such as managing power flows require spatially coherent joint forecasts, which account for cross-regional dependencies. Here, we forecast the joint distribution of net-demand across the 14 regions constituting Great Britain's electricity network. Joint modelling is complicated by the fact that the net-demand variability within each region, and the dependencies between regions, vary with temporal, socio-economical and weather-related factors. We accommodate for these characteristics by proposing a multivariate Gaussian model based on a modified Cholesky parametrisation, which allows us to model each unconstrained parameter via an additive model. Given that the number of model parameters and covariates is large, we adopt a semi-automated approach to model selection, based on gradient boosting. In addition to comparing the forecasting performance of several versions of the proposed model with that of two non-Gaussian copula-based models, we visually explore the model output to interpret how the covariates affect net-demand variability and dependencies.
  The code for reproducing the results in this paper is available at https://doi.org/10.5281/zenodo.7315105, while methods for building and fitting multivariate Gaussian additive models are provided by the SCM R package, available at https://github.com/VinGioia90/SCM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.07451v3</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V. Gioia, M. Fasiolo, J. Browell, R. Bellio</dc:creator>
    </item>
    <item>
      <title>Estimating Racial Disparities When Race is Not Observed</title>
      <link>https://arxiv.org/abs/2303.02580</link>
      <description>arXiv:2303.02580v2 Announce Type: replace 
Abstract: The estimation of racial disparities in various fields is often hampered by the lack of individual-level racial information. In many cases, the law prohibits the collection of such information to prevent direct racial discrimination. As a result, analysts have frequently adopted Bayesian Improved Surname Geocoding (BISG) and its variants, which combine individual names and addresses with Census data to predict race. Unfortunately, the residuals of BISG are often correlated with the outcomes of interest, generally attenuating estimates of racial disparities. To correct this bias, we propose an alternative identification strategy under the assumption that surname is conditionally independent of the outcome given (unobserved) race, residence location, and other observed characteristics. We introduce a new class of models, Bayesian Instrumental Regression for Disparity Estimation (BIRDiE), that take BISG probabilities as inputs and produce racial disparity estimates by using surnames as an instrumental variable for race. Our estimation method is scalable, making it possible to analyze large-scale administrative data. We also show how to address potential violations of the key identification assumptions. A validation study based on the North Carolina voter file shows that BISG+BIRDiE reduces error by up to 84% when estimating racial differences in party registration. Finally, we apply the proposed methodology to estimate racial differences in who benefits from the home mortgage interest deduction using individual-level tax data from the U.S. Internal Revenue Service. Open-source software is available which implements the proposed methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.02580v2</guid>
      <category>stat.AP</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cory McCartan, Robin Fisher, Jacob Goldin, Daniel E. Ho, Kosuke Imai</dc:creator>
    </item>
    <item>
      <title>Estimating Breakpoints between Climate States in Paleoclimate Data</title>
      <link>https://arxiv.org/abs/2404.08336</link>
      <description>arXiv:2404.08336v2 Announce Type: replace 
Abstract: This study presents a statistical approach for identifying transitions between climate states, referred to as breakpoints, using well-established econometric tools. We analyse a 67.1 million year record of the oxygen isotope ratio delta-O-18 derived from benthic foraminifera. The dataset is presented in Westerhold et al. (2020), where the authors use recurrence analysis to identify six climate states. We consider several model specifications. Fixing the number of breakpoints to five, the resulting breakpoint estimates closely align with those identified by Westerhold et al. (2020) across various data binning frequencies and model specifications. Treating the number of breakpoints as a parameter to be estimated results in statistical justification for more than five breakpoints in the time series. Our approach offers the advantage of constructing confidence intervals for the breakpoints, and it allows testing for the number of breakpoints present in the time series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08336v2</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mikkel Bennedsen, Eric Hillebrand, Siem Jan Koopman, Kathrine By Larsen</dc:creator>
    </item>
    <item>
      <title>JCGM 101-compliant uncertainty evaluation using virtual experiments</title>
      <link>https://arxiv.org/abs/2404.10530</link>
      <description>arXiv:2404.10530v2 Announce Type: replace 
Abstract: Virtual experiments (VEs), a modern tool in metrology, can be used to help perform an uncertainty evaluation for the measurand. Current guidelines in metrology do not cover the many possibilities to incorporate VEs into an uncertainty evaluation, and it is often difficult to assess if the intended use of a VE complies with said guidelines. In recent work, it was shown that a VE can be used in conjunction with real measurement data and a Monte Carlo procedure to produce equal results to a supplement of the Guide to the Expression of Uncertainty in Measurement. However, this was shown only for linear measurement models. In this work, we extend this Monte Carlo approach to a common class of non-linear measurement models and more complex VEs, providing a reference approach for suitable uncertainty evaluations involving VEs. Numerical examples are given to show that the theoretical derivations hold in a practical scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10530v2</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Finn Hughes, Manuel Marschall, Gerd W\"ubbeler, Gertjan Kok, Marcel van Dijk, Clemens Elster</dc:creator>
    </item>
    <item>
      <title>Local Projection Inference in High Dimensions</title>
      <link>https://arxiv.org/abs/2209.03218</link>
      <description>arXiv:2209.03218v3 Announce Type: replace-cross 
Abstract: In this paper, we estimate impulse responses by local projections in high-dimensional settings. We use the desparsified (de-biased) lasso to estimate the high-dimensional local projections, while leaving the impulse response parameter of interest unpenalized. We establish the uniform asymptotic normality of the proposed estimator under general conditions. Finally, we demonstrate small sample performance through a simulation study and consider two canonical applications in macroeconomic research on monetary policy and government spending.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.03218v3</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1093/ectj/utae012</arxiv:DOI>
      <dc:creator>Robert Adamek, Stephan Smeekes, Ines Wilms</dc:creator>
    </item>
    <item>
      <title>Subdata selection for big data regression: an improved approach</title>
      <link>https://arxiv.org/abs/2305.00218</link>
      <description>arXiv:2305.00218v2 Announce Type: replace-cross 
Abstract: In the big data era researchers face a series of problems. Even standard approaches/methodologies, like linear regression, can be difficult or problematic with huge volumes of data. Traditional approaches for regression in big datasets may suffer due to the large sample size, since they involve inverting huge data matrices or even because the data cannot fit to the memory. Proposed approaches are based on selecting representative subdata to run the regression. Existing approaches select the subdata using information criteria and/or properties from orthogonal arrays. In the present paper we improve existing algorithms providing a new algorithm that is based on D-optimality approach. We provide simulation evidence for its performance. Evidence about the parameters of the proposed algorithm is also provided in order to clarify the trade-offs between execution time and information gain. Real data applications are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00218v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vasilis Chasiotis, Dimitris Karlis</dc:creator>
    </item>
    <item>
      <title>Causal Inference for Genomic Data with Multiple Heterogeneous Outcomes</title>
      <link>https://arxiv.org/abs/2404.09119</link>
      <description>arXiv:2404.09119v2 Announce Type: replace-cross 
Abstract: With the evolution of single-cell RNA sequencing techniques into a standard approach in genomics, it has become possible to conduct cohort-level causal inferences based on single-cell-level measurements. However, the individual gene expression levels of interest are not directly observable; instead, only repeated proxy measurements from each individual's cells are available, providing a derived outcome to estimate the underlying outcome for each of many genes. In this paper, we propose a generic semiparametric inference framework for doubly robust estimation with multiple derived outcomes, which also encompasses the usual setting of multiple outcomes when the response of each unit is available. To reliably quantify the causal effects of heterogeneous outcomes, we specialize the analysis to standardized average treatment effects and quantile treatment effects. Through this, we demonstrate the use of the semiparametric inferential results for doubly robust estimators derived from both Von Mises expansions and estimating equations. A multiple testing procedure based on Gaussian multiplier bootstrap is tailored for doubly robust estimators to control the false discovery exceedance rate. Applications in single-cell CRISPR perturbation analysis and individual-level differential expression analysis demonstrate the utility of the proposed methods and offer insights into the usage of different estimands for causal inference in genomics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09119v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin-Hong Du, Zhenghao Zeng, Edward H. Kennedy, Larry Wasserman, Kathryn Roeder</dc:creator>
    </item>
  </channel>
</rss>
