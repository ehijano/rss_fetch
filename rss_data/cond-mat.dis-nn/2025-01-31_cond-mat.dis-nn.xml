<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cond-mat.dis-nn updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cond-mat.dis-nn</link>
    <description>cond-mat.dis-nn updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cond-mat.dis-nn" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Jan 2025 05:01:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Athermal creep deformation of ultrastable amorphous solids</title>
      <link>https://arxiv.org/abs/2501.17952</link>
      <description>arXiv:2501.17952v1 Announce Type: cross 
Abstract: We numerically investigate the athermal creep deformation of amorphous materials having a wide range of stability. The imposed shear stress serves as the control parameter, allowing us to examine the time-dependent transient response through both the macroscopic strain and microscopic observables. Least stable samples exhibit monotonicity in the transient strain rate versus time, while more stable samples display a pronounced non-monotonic S-shaped curve, corresponding to failure by sharp shear band formation. We identify a diverging timescale associated with the fluidization process and extract the corresponding critical exponents. Our results are compared with predictions from existing scaling theories relevant to soft matter systems. The numerical findings for stable, brittle-like materials represent a challenge for theoretical descriptions. We monitor the microscopic initiation of shear bands during creep responses. Our study encompasses creep deformation across a variety of materials ranging from ductile soft matter to brittle metallic and oxide glasses, all within the same numerical framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17952v1</guid>
      <category>cond-mat.soft</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pinaki Chaudhuri, Ludovic Berthier, Misaki Ozawa</dc:creator>
    </item>
    <item>
      <title>When less is more: evolving large neural networks from small ones</title>
      <link>https://arxiv.org/abs/2501.18012</link>
      <description>arXiv:2501.18012v1 Announce Type: cross 
Abstract: In contrast to conventional artificial neural networks, which are large and structurally static, we study feed-forward neural networks that are small and dynamic, whose nodes can be added (or subtracted) during training. A single neuronal weight in the network controls the network's size, while the weight itself is optimized by the same gradient-descent algorithm that optimizes the network's other weights and biases, but with a size-dependent objective or loss function. We train and evaluate such Nimble Neural Networks on nonlinear regression and classification tasks where they outperform the corresponding static networks. Growing networks to minimal, appropriate, or optimal sizes while training elucidates network dynamics and contrasts with pruning large networks after training but before deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18012v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anil Radhakrishnan, John F. Lindner, Scott T. Miller, Sudeshna Sinha, William L. Ditto</dc:creator>
    </item>
    <item>
      <title>Optimal generalisation and learning transition in extensive-width shallow neural networks near interpolation</title>
      <link>https://arxiv.org/abs/2501.18530</link>
      <description>arXiv:2501.18530v1 Announce Type: cross 
Abstract: We consider a teacher-student model of supervised learning with a fully-trained 2-layer neural network whose width $k$ and input dimension $d$ are large and proportional. We compute the Bayes-optimal generalisation error of the network for any activation function in the regime where the number of training data $n$ scales quadratically with the input dimension, i.e., around the interpolation threshold where the number of trainable parameters $kd+k$ and of data points $n$ are comparable. Our analysis tackles generic weight distributions. Focusing on binary weights, we uncover a discontinuous phase transition separating a "universal" phase from a "specialisation" phase. In the first, the generalisation error is independent of the weight distribution and decays slowly with the sampling rate $n/d^2$, with the student learning only some non-linear combinations of the teacher weights. In the latter, the error is weight distribution-dependent and decays faster due to the alignment of the student towards the teacher network. We thus unveil the existence of a highly predictive solution near interpolation, which is however potentially hard to find.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18530v1</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean Barbier, Francesco Camilli, Minh-Toan Nguyen, Mauro Pastore, Rudy Skerk</dc:creator>
    </item>
    <item>
      <title>Information dynamics of our brains in dynamically driven disordered superconducting loop networks</title>
      <link>https://arxiv.org/abs/2310.19279</link>
      <description>arXiv:2310.19279v4 Announce Type: replace 
Abstract: Complex systems of many interacting components exhibit patterns of recurrence and emergent behaviors in their time evolution that can be understood from a new perspective in physics of information dynamics modeled after one such system, our brains. A generic brain-like network model is derived from a system of disordered superconducting loops with Josephson junction oscillators to demonstrate these behaviors. The loops can trap multiples of fluxons that represent quantized information units in many distinct memory configurations populating a state space. The state can be updated by exciting the junctions to $fire$ or allow the movement of fluxons through the network as the current through them surpasses their thresholds. Simulations performed with a lumped circuit model of a 4-loop network show that information written through excitations is translated into stable states of trapped flux and their time evolution. Experimental implementation on the 4-loop network shows dynamically stable flux flow in each pathway characterized by the junction firing statistics. The network separates information from multiple excitations into state categories with large energy barriers observed in simulations that correspond to different flux (information) flow patterns observed across junctions in experiments. Strong evidence for associative and time-dependent (short-to-long-term) memories distributed across the network is observed, dependent on its intrinsic and geometrical properties as described by the model. Suitable network topologies can model various other systems leading to a universal description of the nature of information dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.19279v4</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.supr-con</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Uday S. Goteti</dc:creator>
    </item>
    <item>
      <title>How to escape atypical regions in the symmetric binary perceptron: a journey through connected-solutions states</title>
      <link>https://arxiv.org/abs/2408.04479</link>
      <description>arXiv:2408.04479v3 Announce Type: replace 
Abstract: We study the binary symmetric perceptron model, and in particular its atypical solutions. While the solution-space of this problem is dominated by isolated configurations, it is also solvable for a certain range of constraint density $\alpha$ and threshold $\kappa$. We provide in this paper a statistical measure probing sequences of solutions, where two consecutive elements shares a strong overlap. After simplifications, we test its predictions by comparing it to Monte-Carlo simulations. We obtain good agreement and show that connected states with a Markovian correlation profile can fully decorrelate from their initialization only for $\kappa&gt;\kappa_{\rm no-mem.\, state}$ ($\kappa_{\rm no-mem.\, state}\sim \sqrt{0.91\log(N)}$ for $\alpha=0.5$ and $N$ being the dimension of the problem). For $\kappa&lt;\kappa_{\rm no-mem.\, state}$, we show that decorrelated sequences still exist but have a non-trivial correlations profile. To study this regime we introduce an $Ansatz$ for the correlations that we label as the nested Markov chain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04479v3</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Damien Barbier</dc:creator>
    </item>
    <item>
      <title>Transfer Learning in $\ell_1$ Regularized Regression: Hyperparameter Selection Strategy based on Sharp Asymptotic Analysis</title>
      <link>https://arxiv.org/abs/2409.17704</link>
      <description>arXiv:2409.17704v2 Announce Type: replace-cross 
Abstract: Transfer learning techniques aim to leverage information from multiple related datasets to enhance prediction quality against a target dataset. Such methods have been adopted in the context of high-dimensional sparse regression, and some Lasso-based algorithms have been invented: Trans-Lasso and Pretraining Lasso are such examples. These algorithms require the statistician to select hyperparameters that control the extent and type of information transfer from related datasets. However, selection strategies for these hyperparameters, as well as the impact of these choices on the algorithm's performance, have been largely unexplored. To address this, we conduct a thorough, precise study of the algorithm in a high-dimensional setting via an asymptotic analysis using the replica method. Our approach reveals a surprisingly simple behavior of the algorithm: Ignoring one of the two types of information transferred to the fine-tuning stage has little effect on generalization performance, implying that efforts for hyperparameter selection can be significantly reduced. Our theoretical findings are also empirically supported by applications on real-world and semi-artificial datasets using the IMDb and MNIST datasets, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17704v2</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research (2025). &lt; https://openreview.net/forum?id=ccu0M3nmlF&gt;</arxiv:journal_reference>
      <dc:creator>Koki Okajima, Tomoyuki Obuchi</dc:creator>
    </item>
    <item>
      <title>Photonic Simulation of Localization Phenomena Using Boson Sampling</title>
      <link>https://arxiv.org/abs/2410.13938</link>
      <description>arXiv:2410.13938v2 Announce Type: replace-cross 
Abstract: Quantum simulation in its current state faces experimental overhead in terms of physical space and cooling. We propose boson sampling as an alternative compact synthetic platform performing at room temperature. Identifying the capability of estimating matrix permanents, we explore the applicability of boson sampling for tackling the dynamics of quantum systems without having access to information about the full state vector. By mapping the time-evolution unitary of a Hamiltonian onto an interferometer via continuous-variable gate decompositions, we present proof-of-principle results of localization characteristics of a single particle. We study the dynamics of one-dimensional tight-binding systems in the clean and quasiperiodic-disordered limits to observe Bloch oscillations and dynamical localization, and the delocalization-to-localization phase transition in the Aubry- Andre-Harper model respectively. Our computational results obtained using boson sampling are in complete agreement with the dynamical and static results of non-interacting tight-binding systems obtained using conventional numerical calculations. Additionally, our study highlights the role of number of sampling measurements or shots for simulation accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13938v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anuprita V. Kulkarni, Vatsana Tiwari, Auditya Sharma, Ankur Raina</dc:creator>
    </item>
    <item>
      <title>Theory of Irreversibility in Quantum Many-Body Systems</title>
      <link>https://arxiv.org/abs/2501.06183</link>
      <description>arXiv:2501.06183v2 Announce Type: replace-cross 
Abstract: We address the longstanding challenge in quantum many-body theory of reconciling unitary dynamics with irreversible relaxation. In classical chaos, the unitary evolution operator develops Ruelle-Pollicott (RP) resonances inside the unit circle in the continuum limit, leading to mixing. In the semiclassical limit, chaotic single-particle quantum systems relax with the same RP resonances. In contrast, the theory of quantum many-body RP resonances and their link to irreversibility remain underdeveloped. Here, we relate the spectral form factor to the sum of autocorrelation functions and, in generic many-body lattice systems without conservation laws, argue that all quantum many-body RP resonances converge inside the unit disk, highlighting the role of nonunitary and the thermodynamic limit. While we conjecture this picture to be general, we analytically prove the emergence of irreversibility in the random phase model (RPM), a paradigmatic Floquet quantum circuit model, in the limit of large local Hilbert space dimension. To this end, we couple it to local environments and compute the exact time evolution of autocorrelation functions, the dissipative form factor, and out-of-time-order correlation functions (OTOCs). Although valid for any dissipation strength, we then focus on weak dissipation to clarify the origin of irreversibility in unitary systems. When the dissipationless limit is taken after the thermodynamic limit, the unitary quantum map develops an infinite tower of decaying RP resonances -- chaotic systems display so-called anomalous relaxation. We also show that the OTOC in the RPM can undergo a two-stage relaxation and that during the second stage, the approach to the stationary value is again controlled by the leading RP resonance.
  [See the paper for the full abstract.]</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06183v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.str-el</category>
      <category>hep-th</category>
      <category>quant-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takato Yoshimura, Lucas S\'a</dc:creator>
    </item>
  </channel>
</rss>
