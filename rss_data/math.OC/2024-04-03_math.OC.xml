<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Apr 2024 04:00:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Proximal Oracles for Optimization and Sampling</title>
      <link>https://arxiv.org/abs/2404.02239</link>
      <description>arXiv:2404.02239v1 Announce Type: new 
Abstract: We consider convex optimization with non-smooth objective function and log-concave sampling with non-smooth potential (negative log density). In particular, we study two specific settings where the convex objective/potential function is either semi-smooth or in composite form as the finite sum of semi-smooth components. To overcome the challenges caused by non-smoothness, our algorithms employ two powerful proximal frameworks in optimization and sampling: the proximal point framework for optimization and the alternating sampling framework (ASF) that uses Gibbs sampling on an augmented distribution. A key component of both optimization and sampling algorithms is the efficient implementation of the proximal map by the regularized cutting-plane method. We establish the iteration-complexity of the proximal map in both semi-smooth and composite settings. We further propose an adaptive proximal bundle method for non-smooth optimization. The proposed method is universal since it does not need any problem parameters as input. Additionally, we develop a proximal sampling oracle that resembles the proximal map in optimization and establish its complexity using a novel technique (a modified Gaussian integral). Finally, we combine this proximal sampling oracle and ASF to obtain a Markov chain Monte Carlo method with non-asymptotic complexity bounds for sampling in semi-smooth and composite settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02239v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaming Liang, Yongxin Chen</dc:creator>
    </item>
    <item>
      <title>Output Feedback Periodic Event-triggered Control of Coupled $2\times 2$ Linear Hyperbolic PDEs</title>
      <link>https://arxiv.org/abs/2404.02298</link>
      <description>arXiv:2404.02298v1 Announce Type: new 
Abstract: This article introduces an observer-based periodic event-triggered control (PETC) strategy for boundary control of a system characterized by $2\times2$ linear hyperbolic partial differential equations (PDEs). An anti-collocated actuation and sensing configuration is considered, and an exponentially convergent observer for state estimation from boundary data is designed. Initially, a continuous-time dynamic event-triggering mechanism requiring constant monitoring of the triggering function is developed. This mechanism is subsequently adapted into a periodic event-triggering scheme, which necessitates only periodic monitoring to identify when the control input needs updating. The underlying control approach is the PDE backstepping boundary control, implemented in a zero-order hold manner between events. This result marks a substantial improvement over conventional observer-based continuous-time event-triggered control for linear coupled hyperbolic PDEs by removing the requirement for constant monitoring of the triggering function. With the triggering function evaluated periodically, the closed-loop system is inherently free from Zeno behavior. It is demonstrated that under the proposed PETC, the closed-loop system globally exponentially converges to zero in the spatial $L^2$ norm. A simulation study illustrating the theoretical results is presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02298v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eranda Somathilake, Bhathiya Rathnayake, Mamadou Diagne</dc:creator>
    </item>
    <item>
      <title>On Properties of Adjoint Systems for Evolutionary PDEs</title>
      <link>https://arxiv.org/abs/2404.02320</link>
      <description>arXiv:2404.02320v1 Announce Type: new 
Abstract: We investigate the geometric structure of adjoint systems associated with evolutionary partial differential equations at the fully continuous, semi-discrete, and fully discrete levels and the relations between these levels. We show that the adjoint system associated with an evolutionary partial differential equation has an infinite-dimensional Hamiltonian structure, which is useful for connecting the fully continuous, semi-discrete, and fully discrete levels. We subsequently address the question of discretize-then-optimize versus optimize-then-discrete for both semi-discretization and time integration, by characterizing the commutativity of discretize-then-optimize methods versus optimize-then-discretize methods uniquely in terms of an adjoint-variational quadratic conservation law. For Galerkin semi-discretizations and one-step time integration methods in particular, we explicitly construct these commuting methods by using structure-preserving discretization techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02320v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian K. Tran, Ben S. Southworth, Melvin Leok</dc:creator>
    </item>
    <item>
      <title>Bounds and Limiting Minimizers for a Family of Interaction Energies</title>
      <link>https://arxiv.org/abs/2404.02322</link>
      <description>arXiv:2404.02322v1 Announce Type: new 
Abstract: We study a two parameter family of energy minimization problems for interaction energies $\mathcal{E}_{\alpha,\beta}$ with attractive-repulsive potential $W_{\alpha,\beta}$. We develop a concavity principle, which allows us to provide a lower bound on $\mathcal{E}_{\alpha,\beta}$ if there exist $\beta_0&lt;\beta&lt;\beta_1$ with minimizers of $\mathcal{E}_{\alpha,\beta_0}$ and $\mathcal{E}_{\alpha,\beta_1}$ known. In addition to this, we also derive new conclusions about the limiting behaviour of $\mathcal{E}_{\alpha,\beta}$ for $\beta\approx 2.$ Finally, we describe a method to show that, for certain values of $(\alpha,\beta),$ $\mathcal{E}_{\alpha,\beta}$ cannot be minimized by the uniform distribution over a top-dimensional regular unit simplex. Our results are made possible by two key factors -- recent progress in identifying minimizers of $\mathcal{E}_{\alpha,\beta}$ for a range of $\alpha$ and $\beta$, and an analysis of $\inf\mathcal{E}_{\alpha,\beta}$ as a function on parameter space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02322v1</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.AP</category>
      <category>math.MP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cameron Davies</dc:creator>
    </item>
    <item>
      <title>Robust Constrained Consensus and Inequality-constrained Distributed Optimization with Guaranteed Differential Privacy and Accurate Convergence</title>
      <link>https://arxiv.org/abs/2404.02327</link>
      <description>arXiv:2404.02327v1 Announce Type: new 
Abstract: We address differential privacy for fully distributed optimization subject to a shared inequality constraint. By co-designing the distributed optimization mechanism and the differential-privacy noise injection mechanism, we propose the first distributed constrained optimization algorithm that can ensure both provable convergence to a global optimal solution and rigorous $\epsilon$-differential privacy, even when the number of iterations tends to infinity. Our approach does not require the Lagrangian function to be strictly convex/concave, and allows the global objective function to be non-separable. As a byproduct of the co-design, we also propose a new constrained consensus algorithm that can achieve rigorous $\epsilon$-differential privacy while maintaining accurate convergence, which, to our knowledge, has not been achieved before. Numerical simulation results on a demand response control problem in smart grid confirm the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02327v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yongqiang Wang, Angelia Nedic</dc:creator>
    </item>
    <item>
      <title>Faster Convergence of Stochastic Accelerated Gradient Descent under Interpolation</title>
      <link>https://arxiv.org/abs/2404.02378</link>
      <description>arXiv:2404.02378v1 Announce Type: new 
Abstract: We prove new convergence rates for a generalized version of stochastic Nesterov acceleration under interpolation conditions. Unlike previous analyses, our approach accelerates any stochastic gradient method which makes sufficient progress in expectation. The proof, which proceeds using the estimating sequences framework, applies to both convex and strongly convex functions and is easily specialized to accelerated SGD under the strong growth condition. In this special case, our analysis reduces the dependence on the strong growth constant from $\rho$ to $\sqrt{\rho}$ as compared to prior work. This improvement is comparable to a square-root of the condition number in the worst case and address criticism that guarantees for stochastic acceleration could be worse than those for SGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02378v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Mishkin, Mert Pilanci, Mark Schmidt</dc:creator>
    </item>
    <item>
      <title>Data-driven Optimization for Drone Delivery Service Planning with Online Demand</title>
      <link>https://arxiv.org/abs/2404.02442</link>
      <description>arXiv:2404.02442v1 Announce Type: new 
Abstract: In this study, we develop an innovative data-driven optimization approach to solve the drone delivery service planning problem with online demand. Drone-based logistics are expected to improve operations by enhancing flexibility and reducing congestion effects induced by last-mile deliveries. With rising digitalization and urbanization, however, logistics service providers are constantly grappling with the challenge of uncertain real-time demand. This study investigates the problem of planning drone delivery service through an urban air traffic network to fulfil online and stochastic demand. Customer requests, if accepted, generate profit and are serviced by individual drone flights as per request origins, destinations and time windows. We cast this stochastic optimization problem as a Markov decision process. We present a novel data-driven optimization approach which generates predictive prescriptions of parameters of a surrogate optimization formulation. Our solution method consists of synthesizing training data via lookahead simulations to train a supervised machine learning model for predicting relative link priority based on the state of the network. This knowledge is then leveraged to selectively create weighted reserve capacity in the network and via a surrogate objective function that controls the trade-off between reserve capacity and profit maximization to maximize the cumulative profit earned. Using numerical experiments based on benchmarking transportation networks, the resulting data-driven optimization policy is shown to outperform a myopic policy. Sensitivity analyses on learning parameters reveal insights into the design of efficient policies for drone delivery service planning with online demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02442v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditya Paul, Michael W. Levin, S. Travis Waller, David Rey</dc:creator>
    </item>
    <item>
      <title>Electric Vehicle Routing Problem for Emergency Power Supply: Towards Telecom Base Station Relief</title>
      <link>https://arxiv.org/abs/2404.02448</link>
      <description>arXiv:2404.02448v1 Announce Type: new 
Abstract: As a telecom provider, our company has a critical mission to maintain telecom services even during power outages. To accomplish the mission, it is essential to maintain the power of the telecom base stations. Here we consider a solution where electric vehicles (EVs) directly supply power to base stations by traveling to their locations. The goal is to find EV routes that minimize both the total travel distance of all EVs and the number of downed base stations. In this paper, we formulate this routing problem as a new variant of the Electric Vehicle Routing Problem (EVRP) and propose a solver that combines a rule-based vehicle selector and a reinforcement learning (RL)-based node selector. The rule of the vehicle selector ensures the exact environmental states when the selected EV starts to move. In addition, the node selection by the RL model enables fast route generation, which is critical in emergencies. We evaluate our solver on both synthetic datasets and real datasets. The results show that our solver outperforms baselines in terms of the objective value and computation time. Moreover, we analyze the generalization and scalability of our solver, demonstrating the capability toward unseen settings and large-scale problems. Check also our project page: https://ntt-dkiku.github.io/rl-evrpeps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02448v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daisuke Kikuta, Hiroki Ikeuchi, Kengo Tajiri, Yuta Toyama, Yuusuke Nakano</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Traveling Purchaser Problems</title>
      <link>https://arxiv.org/abs/2404.02476</link>
      <description>arXiv:2404.02476v1 Announce Type: new 
Abstract: The traveling purchaser problem (TPP) is an important combinatorial optimization problem with broad applications. Due to the coupling between routing and purchasing, existing works on TPPs commonly address route construction and purchase planning simultaneously, which, however, leads to exact methods with high computational cost and heuristics with sophisticated design but limited performance. In sharp contrast, we propose a novel approach based on deep reinforcement learning (DRL), which addresses route construction and purchase planning separately, while evaluating and optimizing the solution from a global perspective. The key components of our approach include a bipartite graph representation for TPPs to capture the market-product relations, and a policy network that extracts information from the bipartite graph and uses it to sequentially construct the route. One significant benefit of our framework is that we can efficiently construct the route using the policy network, and once the route is determined, the associated purchasing plan can be easily derived through linear programming, while, leveraging DRL, we can train the policy network to optimize the global solution objective. Furthermore, by introducing a meta-learning strategy, the policy network can be trained stably on large-sized TPP instances, and generalize well across instances of varying sizes and distributions, even to much larger instances that are never seen during training. Experiments on various synthetic TPP instances and the TPPLIB benchmark demonstrate that our DRL-based approach can significantly outperform well-established TPP heuristics, reducing the optimality gap by 40%-90%, and also showing an advantage in runtime, especially on large-sized instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02476v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haofeng Yuan, Rongping Zhu, Wanlu Yang, Shiji Song, Keyou You, Yuli Zhang</dc:creator>
    </item>
    <item>
      <title>Nonlinear integral extension of PID control with improved convergence of perturbed second-order dynamic systems</title>
      <link>https://arxiv.org/abs/2404.02502</link>
      <description>arXiv:2404.02502v1 Announce Type: new 
Abstract: Nonlinear extension of the integral part of PID feedback control is proposed for the perturbed second-order systems. For the matched constant perturbations, the global asymptotic stability is shown, and for Lipschitz perturbations an ultimately bounded output error is guaranteed. The second-order system plants can also be expanded by an additional (parasitic) actuator dynamics with low-pass characteristics. The proposed nonlinear control is proven to outperform its linear (PID) benchmarking counterpart during the settling phase, i.e. at convergence of the residual output error. An experimental case study of the second-order system with an additional actuator dynamics and considerable perturbation is demonstrated to confirm and benchmark the control performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02502v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Ruderman</dc:creator>
    </item>
    <item>
      <title>Stochastic Constrained Decentralized Optimization for Machine Learning with Fewer Data Oracles: a Gradient Sliding Approach</title>
      <link>https://arxiv.org/abs/2404.02511</link>
      <description>arXiv:2404.02511v1 Announce Type: new 
Abstract: In modern decentralized applications, ensuring communication efficiency and privacy for the users are the key challenges. In order to train machine-learning models, the algorithm has to communicate to the data center and sample data for its gradient computation, thus exposing the data and increasing the communication cost. This gives rise to the need for a decentralized optimization algorithm that is communication-efficient and minimizes the number of gradient computations. To this end, we propose the primal-dual sliding with conditional gradient sliding framework, which is communication-efficient and achieves an $\varepsilon$-approximate solution with the optimal gradient complexity of $O(1/\sqrt{\varepsilon}+\sigma^2/{\varepsilon^2})$ and $O(\log(1/\varepsilon)+\sigma^2/\varepsilon)$ for the convex and strongly convex setting respectively and an LO (Linear Optimization) complexity of $O(1/\varepsilon^2)$ for both settings given a stochastic gradient oracle with variance $\sigma^2$. Compared with the prior work \cite{wai-fw-2017}, our framework relaxes the assumption of the optimal solution being a strict interior point of the feasible set and enjoys wider applicability for large-scale training using a stochastic gradient oracle. We also demonstrate the efficiency of our algorithms with various numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02511v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hoang Huy Nguyen, Yan Li, Tuo Zhao</dc:creator>
    </item>
    <item>
      <title>Analysis and approximation to parabolic optimal control problems with measure-valued controls in time</title>
      <link>https://arxiv.org/abs/2404.02546</link>
      <description>arXiv:2404.02546v1 Announce Type: new 
Abstract: In this paper, we investigate an optimal control problem governed by parabolic equations with measure-valued controls over time. We establish the well-posedness of the optimal control problem and derive the first-order optimality condition using Clarke's subgradients, revealing a sparsity structure in time for the optimal control. Consequently, these optimal control problems represent a generalization of impulse control for evolution equations. To discretize the optimal control problem, we employ the space-time finite element method. Here, the state equation is approximated using piecewise linear and continuous finite elements in space, alongside a Petrov-Galerkin method utilizing piecewise constant trial functions and piecewise linear and continuous test functions in time. The control variable is discretized using the variational discretization concept. For error estimation, we initially derive a priori error estimates and stabilities for the finite element discretizations of the state and adjoint equations. Subsequently, we establish weak-* convergence for the control under the norm $\mathcal{M}(\bar I_c;L^2(\omega))$, with a convergence order of $O(h^\frac{1}{2}+\tau^\frac{1}{4})$ for the state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02546v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Wei Gong, Dongdong Liang</dc:creator>
    </item>
    <item>
      <title>A mixed-integer-programming-based Gauss-Seidel method for multi-leader-multi-follower games</title>
      <link>https://arxiv.org/abs/2404.02605</link>
      <description>arXiv:2404.02605v1 Announce Type: new 
Abstract: We design a computational approach to find equilibria in a class of Nash games possessing a hierarchical structure. By using tools from mixed-integer programming and the characterization of variational equilibria in terms of the Karush--Kuhn--Tucker conditions, we propose a mixed-integer game formulation for solving such a challenging instance. Besides providing an equivalent reformulation, we build upon our previous work and design a proximal Gauss--Seidel method with global convergence guarantees for the case in which the game enjoys a potential structure. In addition to proving the convergence of the resulting scheme, we show its performance on a numerical instance of a ride-hail market problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02605v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Filippo Fabiani, Barbara Franci, Martin Schmidt, Mathias Staudigl</dc:creator>
    </item>
    <item>
      <title>An Inexact Regularized Proximal Newton Method without Line Search</title>
      <link>https://arxiv.org/abs/2404.02635</link>
      <description>arXiv:2404.02635v1 Announce Type: new 
Abstract: In this paper, we introduce an inexact regularized proximal Newton method (IRPNM) that does not require any line search. The method is designed to minimize the sum of a twice continuously differentiable function $f$ and a convex (possibly non-smooth and extended-valued) function $\varphi$. Instead of controlling a step size by a line search procedure, we update the regularization parameter in a suitable way, based on the success of the previous iteration. The global convergence of the sequence of iterations and its superlinear convergence rate under a local H\"olderian error bound assumption are shown. Notably, these convergence results are obtained without requiring a global Lipschitz property for $ \nabla f $, which, to the best of the authors' knowledge, is a novel contribution for proximal Newton methods. To highlight the efficiency of our approach, we provide numerical comparisons with an IRPNM using a line search globalization and a modern FISTA-type method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02635v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simeon vom Dahl, Christian Kanzow</dc:creator>
    </item>
    <item>
      <title>A Dual Geometric Test for Forward-Flatness</title>
      <link>https://arxiv.org/abs/2404.02816</link>
      <description>arXiv:2404.02816v1 Announce Type: new 
Abstract: Forward-flatness is a generalization of static feedback linearizability and a special case of a more general flatness concept for discrete-time systems. Recently, it has been shown that this practically quite relevant property can be checked by computing a unique sequence of involutive distributions which generalizes the well-known static feedback linearization test. In this paper, a dual test for forward-flatness based on a unique sequence of integrable codistributions is derived. Since the main mathematical operations for determining this sequence are the intersection of codistributions and the calculation of Lie derivatives of 1-forms, it is computationally quite efficient. Furthermore, the formulation with codistributions also facilitates a comparison with the existing discrete-time literature regarding the closely related topic of dynamic feedback linearization, which is mostly formulated in terms of 1-forms rather than vector fields. The presented results are illustrated by two examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02816v1</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bernd Kolar, Johannes Schrotshamer, Markus Sch\"oberl</dc:creator>
    </item>
    <item>
      <title>Optimal distributed control with stability guarantees by training a network of neural closed-loop maps</title>
      <link>https://arxiv.org/abs/2404.02820</link>
      <description>arXiv:2404.02820v1 Announce Type: new 
Abstract: This paper proposes a novel approach to improve the performance of distributed nonlinear control systems while preserving stability by leveraging Deep Neural Networks (DNNs). We build upon the Neural System Level Synthesis (Neur-SLS) framework and introduce a method to parameterize stabilizing control policies that are distributed across a network topology. A distinctive feature is that we iteratively minimize an arbitrary control cost function through an unconstrained optimization algorithm, all while preserving the stability of the overall network architecture by design. This is achieved through two key steps. First, we establish a method to parameterize interconnected Recurrent Equilibrium Networks (RENs) that guarantees a bounded $\mathcal{L}_2$ gain at the network level. This ensures stability. Second, we demonstrate how the information flow within the network is preserved, enabling a fully distributed implementation where each subsystem only communicates with its neighbors. To showcase the effectiveness of our approach, we present a simulation of a distributed formation control problem for a fleet of vehicles. The simulation demonstrates how the proposed neural controller enables the vehicles to maintain a desired formation while navigating obstacles and avoiding collisions, all while guaranteeing network stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02820v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danilo Saccani, Leonardo Massai, Luca Furieri, Giancarlo Ferrari-Trecate</dc:creator>
    </item>
    <item>
      <title>Control of high-dimensional collective dynamics by deep neural feedback laws and kinetic modelling</title>
      <link>https://arxiv.org/abs/2404.02825</link>
      <description>arXiv:2404.02825v1 Announce Type: new 
Abstract: Modeling and control of agent-based models is twice cursed by the dimensionality of the problem, as both the number of agents and their state space dimension can be large. Even though the computational barrier posed by a large ensemble of agents can be overcome through a mean field formulation of the control problem, the feasibility of its solution is generally guaranteed only for agents operating in low-dimensional spaces. To circumvent the difficulty posed by the high dimensionality of the state space a kinetic model is proposed, requiring the sampling of high-dimensional, two-agent sub-problems, to evolve the agents' density using a Boltzmann type equation. Such density evolution requires a high-frequency sampling of two-agent optimal control problems, which is efficiently approximated by means of deep neural networks and supervised learning, enabling the fast simulation of high-dimensional, large-scale ensembles of controlled particles. Numerical experiments demonstrate the effectiveness of the proposed approach in the control of consensus and attraction-repulsion dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02825v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giacomo Albi, Sara Bicego, Dante Kalise</dc:creator>
    </item>
    <item>
      <title>A mean-field model of optimal investment</title>
      <link>https://arxiv.org/abs/2404.02871</link>
      <description>arXiv:2404.02871v1 Announce Type: new 
Abstract: We establish the existence and uniqueness of the equilibrium for a stochastic mean-field game of optimal investment. The analysis covers both finite and infinite time horizons, and the mean-field interaction of the representative company with a mass of identical and indistinguishable firms is modeled through the time-dependent price at which the produced good is sold. At equilibrium, this price is given in terms of a nonlinear function of the expected (optimally controlled) production capacity of the representative company at each time. The proof of the existence and uniqueness of the mean-field equilibrium relies on a priori estimates and the study of nonlinear integral equations, but employs different techniques for the finite and infinite horizon cases. Additionally, we investigate the deterministic counterpart of the mean-field game under study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02871v1</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Calvia, Salvatore Federico, Giorgio Ferrari, Fausto Gozzi</dc:creator>
    </item>
    <item>
      <title>Sensing Resource Allocation Against Data-Poisoning Attacks in Traffic Routing</title>
      <link>https://arxiv.org/abs/2404.02876</link>
      <description>arXiv:2404.02876v1 Announce Type: new 
Abstract: Data-poisoning attacks can disrupt the efficient operations of transportation systems by misdirecting traffic flows via falsified data. One challenge in countering these attacks is to reduce the uncertainties on the types of attacks, such as the distribution of their targets and intensities. We introduce a resource allocation method in transportation networks to detect and distinguish different types of attacks and facilitate efficient traffic routing. The idea is to first cluster different types of attacks based on the corresponding optimal routing strategies, then allocate sensing resources to a subset of network links to distinguish attacks from different clusters via lexicographical mixed-integer programming. We illustrate the application of the proposed method using the Anaheim network, a benchmark model in traffic routing that contains more than 400 nodes and 900 links.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02876v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Yu, Adam J. Thorpe, Jesse Milzman, David Fridovich-Keil, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>The Lavrentiev phenomenon</title>
      <link>https://arxiv.org/abs/2404.02901</link>
      <description>arXiv:2404.02901v1 Announce Type: new 
Abstract: The basic problem of the calculus of variations consists of finding a function that minimizes an energy, like finding the fastest trajectory between two points for a point mass in a gravity field moving without friction under the influence of gravity or finding the best shape of a wing. The existence of a solution may be established in quite abstract spaces, much larger than the space of smooth functions. An important practical problem is that of being able to approach the value of the infimum of the energy. However, numerical methods work with very concrete functions and sometimes they are unable to approximate the infimum: this is the surprising Lavrentiev phenomenon. The papers that ensure the non-occurrence of the phenomenon form a recent saga, and the most general result formulated in the early '90s was actually fully proved just recently, more than 30 years later. Our aim here is to introduce the reader to the calculus of variations, to illustrate the Lavrentiev phenomenon with the simplest known example, and to give an elementary proof of the non-occurrence of the phenomenon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02901v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rapha\"el Cerf, Carlo Mariconda</dc:creator>
    </item>
    <item>
      <title>Improved model-free bounds for multi-asset options using option-implied information and deep learning</title>
      <link>https://arxiv.org/abs/2404.02343</link>
      <description>arXiv:2404.02343v1 Announce Type: cross 
Abstract: We consider the computation of model-free bounds for multi-asset options in a setting that combines dependence uncertainty with additional information on the dependence structure. More specifically, we consider the setting where the marginal distributions are known and partial information, in the form of known prices for multi-asset options, is also available in the market. We provide a fundamental theorem of asset pricing in this setting, as well as a superhedging duality that allows to transform the maximization problem over probability measures in a more tractable minimization problem over trading strategies. The latter is solved using a penalization approach combined with a deep learning approximation using artificial neural networks. The numerical method is fast and the computational time scales linearly with respect to the number of traded assets. We finally examine the significance of various pieces of additional information. Empirical evidence suggests that "relevant" information, i.e. prices of derivatives with the same payoff structure as the target payoff, are more useful that other information, and should be prioritized in view of the trade-off between accuracy and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02343v1</guid>
      <category>q-fin.PR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evangelia Dragazi, Shuaiqiang Liu, Antonis Papapantoleon</dc:creator>
    </item>
    <item>
      <title>Network-Aware and Welfare-Maximizing Dynamic Pricing for Energy Sharing</title>
      <link>https://arxiv.org/abs/2404.02458</link>
      <description>arXiv:2404.02458v1 Announce Type: cross 
Abstract: The proliferation of behind-the-meter (BTM) distributed energy resources (DER) within the electrical distribution network presents significant supply and demand flexibilities, but also introduces operational challenges such as voltage spikes and reverse power flows. In response, this paper proposes a network-aware dynamic pricing framework tailored for energy-sharing coalitions that aggregate small, but ubiquitous, BTM DER downstream of a distribution system operator's (DSO) revenue meter that adopts a generic net energy metering (NEM) tariff. By formulating a Stackelberg game between the energy-sharing market leader and its prosumers, we show that the dynamic pricing policy induces the prosumers toward a network-safe operation and decentrally maximizes the energy-sharing social welfare. The dynamic pricing mechanism involves a combination of a locational {\em ex-ante} dynamic price and an {\em ex-post} allocation, both of which are functions of the energy sharing's BTM DER. The {\em ex-post} allocation is proportionate to the price differential between the DSO NEM price and the energy sharing locational price. Simulation results using real DER data and the IEEE 13-bus test systems illustrate the dynamic nature of network-aware pricing at each bus, and its impact on voltage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02458v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed S. Alahmed, Guido Cavraro, Andrey Bernstein, Lang Tong</dc:creator>
    </item>
    <item>
      <title>Degree Sequence Optimization and Extremal Degree Enumerators</title>
      <link>https://arxiv.org/abs/2404.02551</link>
      <description>arXiv:2404.02551v1 Announce Type: cross 
Abstract: The degree sequence optimization problem is to find a subgraph of a given graph which maximizes the sum of given functions evaluated at the subgraph degrees. Here we study this problem by replacing degree sequences, via suitable nonlinear transformations, by suitable degree enumerators, and we introduce suitable degree enumerator polytopes.
  We characterize their vertices, that is, the extremal degree enumerators, for complete graphs and some complete bipartite graphs, and use these characterizations to obtain simpler and faster algorithms for optimization over degree sequences for such graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02551v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shmuel Onn</dc:creator>
    </item>
    <item>
      <title>Effect of constraint relaxation on dynamic critical phenomena in minimum vertex cover problem</title>
      <link>https://arxiv.org/abs/2404.02564</link>
      <description>arXiv:2404.02564v1 Announce Type: cross 
Abstract: The effects of constraint relaxation on dynamic critical phenomena in the Minimum Vertex Cover (MVC) problem on Erd\H{o}s-R\'enyi random graphs are investigated using Markov chain Monte Carlo simulations. Following our previous work that revealed the reduction of the critical temperature by constraint relaxation based on the penalty function method, this study focuses on investigating the critical properties of the relaxation time along its phase boundary. It is found that the dynamical correlation function of MVC with respect to the problem size and the constraint strength follows a universal scaling function. The analysis shows that the relaxation time decreases as the constraints are relaxed. This decrease is more pronounced for the critical amplitude than for the critical exponent, and this result is interpreted in terms of the system's microscopic energy barriers due to the constraint relaxation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02564v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aki Dote, Koji Hukushima</dc:creator>
    </item>
    <item>
      <title>Self-similar intermediate asymptotics for first-order mean field games</title>
      <link>https://arxiv.org/abs/2404.02623</link>
      <description>arXiv:2404.02623v1 Announce Type: cross 
Abstract: We study the intermediate asymptotic behavior of solutions to the first-order mean field games system with a local coupling, when the initial density is a compactly supported function on the real line, and the coupling is of power type. Addressing a question that was left open in arXiv:2308.00314, we prove that the solutions converge to the self-similar profile. We proceed by analyzing a continuous rescaling of the solution, and identifying an appropriate Lyapunov functional. We identify a critical value for the parameter of the coupling, which determines the qualitative behavior of the functional, and the well-posedness of the infinite horizon system. Accordingly, we also establish, in the subcritical and critical cases, a second convergence result which characterizes the behavior of the full solution as the time horizon approaches infinity. We also prove the corresponding results for the mean field planning problem. A large part of our analysis and methodology apply just as well to arbitrary dimensions. As such, this work is a major step towards settling these questions in the higher-dimensional setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02623v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Munoz</dc:creator>
    </item>
    <item>
      <title>Towards a unifying framework for data-driven predictive control with quadratic regularization</title>
      <link>https://arxiv.org/abs/2404.02721</link>
      <description>arXiv:2404.02721v1 Announce Type: cross 
Abstract: Data-driven predictive control (DPC) has recently gained popularity as an alternative to model predictive control (MPC). Amidst the surge in proposed DPC frameworks, upon closer inspection, many of these frameworks are more closely related (or perhaps even equivalent) to each other than it may first appear. We argue for a more formal characterization of these relationships so that results can be freely transferred from one framework to another, rather than being uniquely attributed to a particular framework. We demonstrate this idea by examining the connection between $\gamma$-DDPC and the original DeePC formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02721v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Manuel Kl\"adtke, Moritz Schulze Darup</dc:creator>
    </item>
    <item>
      <title>Extending direct data-driven predictive control towards systems with finite control sets</title>
      <link>https://arxiv.org/abs/2404.02727</link>
      <description>arXiv:2404.02727v1 Announce Type: cross 
Abstract: Although classical model predictive control with finite control sets (FCS-MPC) is quite a popular control method, particularly in the realm of power electronics systems, its direct data-driven predictive control (FCS-DPC) counterpart has received relatively limited attention. In this paper, we introduce a novel reformulation of a commonly used DPC scheme that allows for the application of a modified sphere decoding algorithm, known for its efficiency and prominence in FCS-MPC applications. We test the reformulation on a popular electrical drive example and compare the computation times of sphere decoding FCS-DPC with an enumeration-based and a MIQP method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02727v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Manuel Kl\"adtke, Moritz Schulze Darup, Daniel E. Quevedo</dc:creator>
    </item>
    <item>
      <title>A camel with a less strict diet</title>
      <link>https://arxiv.org/abs/2404.02828</link>
      <description>arXiv:2404.02828v1 Announce Type: cross 
Abstract: A camel can carry $B$ bananas on its back. It can have $2$ bananas at a time in its stomach. For each mile the camel walks, the amount of bananas in its stomach decreases $1$. As soon as the amount of bananas in the camel's stomach is at most $1$, it can eat a new banana. When the camel's stomach is empty, the camel must eat a new banana (in order to be able to continue its itinerary).
  Let there be a stock of $N$ bananas at the border of the desert. How far can the camel penetrate into the desert, starting at this point? (Of course it can form new stocks with transported bananas.)
  The case $B=1$ is solved completely. The round trip variant is solved for $B=1$ as well. For $B=2$, the round trip variant is solved for $N$ which are a power of $2$ and $N \le 8$, and estimated up to $1/(N-1)$ miles for general $N$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02828v1</guid>
      <category>math.HO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michiel de Bondt</dc:creator>
    </item>
    <item>
      <title>Gaussian Process Regression with Soft Inequality and Monotonicity Constraints</title>
      <link>https://arxiv.org/abs/2404.02873</link>
      <description>arXiv:2404.02873v1 Announce Type: cross 
Abstract: Gaussian process (GP) regression is a non-parametric, Bayesian framework to approximate complex models. Standard GP regression can lead to an unbounded model in which some points can take infeasible values. We introduce a new GP method that enforces the physical constraints in a probabilistic manner. This GP model is trained by the quantum-inspired Hamiltonian Monte Carlo (QHMC). QHMC is an efficient way to sample from a broad class of distributions. Unlike the standard Hamiltonian Monte Carlo algorithm in which a particle has a fixed mass, QHMC allows a particle to have a random mass matrix with a probability distribution. Introducing the QHMC method to the inequality and monotonicity constrained GP regression in the probabilistic sense, our approach improves the accuracy and reduces the variance in the resulting GP model. According to our experiments on several datasets, the proposed approach serves as an efficient method as it accelerates the sampling process while maintaining the accuracy, and it is applicable to high dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02873v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Didem Kochan, Xiu Yang</dc:creator>
    </item>
    <item>
      <title>On computing approximate Lewis weights</title>
      <link>https://arxiv.org/abs/2404.02881</link>
      <description>arXiv:2404.02881v1 Announce Type: cross 
Abstract: In this note we provide and analyze a simple method that given an $n \times d$ matrix, outputs approximate $\ell_p$-Lewis weights, a natural measure of the importance of the rows with respect to the $\ell_p$ norm, for $p \geq 2$. More precisely, we provide a simple post-processing procedure that turns natural one-sided approximate $\ell_p$-Lewis weights into two-sided approximations. When combined with a simple one-sided approximation algorithm presented by Lee (PhD thesis, `16) this yields an algorithm for computing two-sided approximations of the $\ell_p$-Lewis weights of an $n \times d$-matrix using $\mathrm{poly}(d,p)$ approximate leverage score computations. While efficient high-accuracy algorithms for approximating $\ell_p$-Lewis had been established previously by Fazel, Lee, Padmanabhan and Sidford (SODA `22), the simple structure and approximation tolerance of our algorithm may make it of use for different applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02881v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Apers, Sander Gribling, Aaron Sidford</dc:creator>
    </item>
    <item>
      <title>A Riemannian Proximal Newton Method</title>
      <link>https://arxiv.org/abs/2304.04032</link>
      <description>arXiv:2304.04032v3 Announce Type: replace 
Abstract: In recent years, the proximal gradient method and its variants have been generalized to Riemannian manifolds for solving optimization problems with an additively separable structure, i.e., $f + h$, where $f$ is continuously differentiable, and $h$ may be nonsmooth but convex with computationally reasonable proximal mapping. In this paper, we generalize the proximal Newton method to embedded submanifolds for solving the type of problem with $h(x) = \mu \|x\|_1$. The generalization relies on the Weingarten and semismooth analysis. It is shown that the Riemannian proximal Newton method has a local quadratic convergence rate under certain reasonable assumptions. Moreover, a hybrid version is given by concatenating a Riemannian proximal gradient method and the Riemannian proximal Newton method. It is shown that if the switch parameter is chosen appropriately, then the hybrid method converges globally and also has a local quadratic convergence rate. Numerical experiments on random and synthetic data are used to demonstrate the performance of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.04032v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wutao Si, P. -A. Absil, Wen Huang, Rujun Jiang, Simon Vary</dc:creator>
    </item>
    <item>
      <title>On adaptive stochastic heavy ball momentum for solving linear systems</title>
      <link>https://arxiv.org/abs/2305.05482</link>
      <description>arXiv:2305.05482v3 Announce Type: replace 
Abstract: The stochastic heavy ball momentum (SHBM) method has gained considerable popularity as a scalable approach for solving large-scale optimization problems. However, one limitation of this method is its reliance on prior knowledge of certain problem parameters, such as singular values of a matrix. In this paper, we propose an adaptive variant of the SHBM method for solving stochastic problems that are reformulated from linear systems using user-defined distributions. Our adaptive SHBM (ASHBM) method utilizes iterative information to update the parameters, addressing an open problem in the literature regarding the adaptive learning of momentum parameters. We prove that our method converges linearly in expectation, with a better convergence bound compared to the basic method. Notably, we demonstrate that the deterministic version of our ASHBM algorithm can be reformulated as a variant of the conjugate gradient (CG) method, inheriting many of its appealing properties, such as finite-time convergence. Consequently, the ASHBM method can be further generalized to develop a brand-new framework of the stochastic CG (SCG) method for solving linear systems. Our theoretical results are supported by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.05482v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yun Zeng, Deren Han, Yansheng Su, Jiaxin Xie</dc:creator>
    </item>
    <item>
      <title>Online Optimization for Randomized Network Resource Allocation with Long-Term Constraints</title>
      <link>https://arxiv.org/abs/2305.15558</link>
      <description>arXiv:2305.15558v2 Announce Type: replace 
Abstract: In this paper, we study an optimal online resource reservation problem in a simple communication network. The network is composed of two compute nodes linked by a local communication link. The system operates in discrete time; at each time slot, the administrator reserves resources for servers before the actual job requests are known. A cost is incurred for the reservations made. Then, after the client requests are observed, jobs may be transferred from one server to the other to best accommodate the demands by incurring an additional transport cost. If certain job requests cannot be satisfied, there is a violation that engenders a cost to pay for each of the blocked jobs. The goal is to minimize the overall reservation cost over finite horizons while maintaining the cumulative violation and transport costs under a certain budget limit. To study this problem, we first formalize it as a repeated game against nature where the reservations are drawn randomly according to a sequence of probability distributions that are derived from an online optimization problem over the space of allowable reservations. We then propose an online saddle-point algorithm for which we present an upper bound for the associated K-benchmark regret together with an upper bound for the cumulative constraint violations. Finally, we present numerical experiments where we compare the performance of our algorithm with those of simple deterministic resource allocation policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.15558v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed Sid-Ali, Ioannis Lambadaris, Yiqiang Q. Zhao, Gennady Shaikhet, Shima Kheradmand</dc:creator>
    </item>
    <item>
      <title>A variable smoothing for Nonconvexly constrained nonsmooth optimization with application to sparse spectral clustering</title>
      <link>https://arxiv.org/abs/2309.11940</link>
      <description>arXiv:2309.11940v2 Announce Type: replace 
Abstract: We propose a variable smoothing algorithm for solving nonconvexly constrained nonsmooth optimization problems. The target problem has two issues that need to be addressed: (i) the nonconvex constraint and (ii) the nonsmooth term. To handle the nonconvex constraint, we translate the target problem into an unconstrained problem by parameterizing the nonconvex constraint in terms of a Euclidean space. We show that under a certain condition, these problems are equivalent in view of finding a stationary point. To find a stationary point of the parameterized problem, the proposed algorithm performs the gradient descent update for the smoothed version of the parameterized problem with replacement of the nonsmooth function by the Moreau envelope, inspired by a variable smoothing algorithm [B\"ohm-Wright, J. Optim. Theory Appl., 2021] specialized for unconstrained nonsmooth optimization. We also present a convergence analysis of the proposed algorithm as well as its application to a nonconvex reformulation of the sparse spectral clustering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.11940v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ICASSP48485.2024.10447693</arxiv:DOI>
      <arxiv:journal_reference>ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</arxiv:journal_reference>
      <dc:creator>Keita Kume, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>Polyak Minorant Method for Convex Optimization</title>
      <link>https://arxiv.org/abs/2310.07922</link>
      <description>arXiv:2310.07922v4 Announce Type: replace 
Abstract: In 1963 Boris Polyak suggested a particular step size for gradient descent methods, now known as the Polyak step size, that he later adapted to subgradient methods. The Polyak step size requires knowledge of the optimal value of the minimization problem, which is a strong assumption but one that holds for several important problems. In this paper we extend Polyak's method to handle constraints and, as a generalization of subgradients, general minorants, which are convex functions that tightly lower bound the objective and constraint functions. We refer to this algorithm as the Polyak Minorant Method (PMM). It is closely related to cutting-plane and bundle methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07922v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikhil Devanathan, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>A Corrected Inexact Proximal Augmented Lagrangian Method with a Relative Error Criterion for a Class of Group-quadratic Regularized Optimal Transport Problems</title>
      <link>https://arxiv.org/abs/2311.01976</link>
      <description>arXiv:2311.01976v2 Announce Type: replace 
Abstract: The optimal transport (OT) problem and its related problems have attracted significant attention and have been extensively studied in various applications. In this paper, we focus on a class of group-quadratic regularized OT problems which aim to find solutions with specialized structures that are advantageous in practical scenarios. To solve this class of problems, we propose a corrected inexact proximal augmented Lagrangian method (ciPALM), with the subproblems being solved by the semi-smooth Newton ({\sc Ssn}) method. We establish that the proposed method exhibits appealing convergence properties under mild conditions. Moreover, our ciPALM distinguishes itself from the recently developed semismooth Newton-based inexact proximal augmented Lagrangian ({\sc Snipal}) method for linear programming. Specifically, {\sc Snipal} uses an absolute error criterion for the approximate minimization of the subproblem for which a summable sequence of tolerance parameters needs to be pre-specified for practical implementations. In contrast, our ciPALM adopts a relative error criterion with a \textit{single} tolerance parameter, which would be more friendly to tune from computational and implementation perspectives. These favorable properties position our ciPALM as a promising candidate for tackling large-scale problems. Various numerical studies validate the effectiveness of employing a relative error criterion for the inexact proximal augmented Lagrangian method, and also demonstrate that our ciPALM is competitive for solving large-scale group-quadratic regularized OT problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.01976v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Yang, Ling Liang, Hong T. M. Chu, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Unbalanced L1 optimal transport for vector valued measures and application to Full Waveform Inversion</title>
      <link>https://arxiv.org/abs/2403.02764</link>
      <description>arXiv:2403.02764v2 Announce Type: replace 
Abstract: Optimal transport has recently started to be successfully employed to define misfit or loss functions in inverse problems. However, it is a problem intrinsically defined for positive (probability) measures and therefore strategies are needed for its applications in more general settings of interest. In this paper we introduce an unbalanced optimal transport problem for vector valued measures starting from the $L^1$ optimal transport. By lifting data in a self-dual cone of a higher dimensional vector space, we show that one can recover a meaningful transport problem. We show that the favorable computational complexity of the $L^1$ problem, an advantage compared to other formulations of optimal transport, is inherited by our vector extension. We consider both a one-homogeneous and a two-homogeneous penalization for the imbalance of mass, the latter being potentially relevant for applications to physics based problems. In particular, we demonstrate the potential of our strategy for full waveform inversion, an inverse problem for high resolution seismic imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02764v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriele Todeschi (LIGM), Ludovic M\'etivier (CNRS, ISTerre, LJK), Jean-Marie Mirebeau (CNRS, CB)</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Hospital Capacity Expansion Planning under Stochastic and Correlated Patient Demand</title>
      <link>https://arxiv.org/abs/2403.13234</link>
      <description>arXiv:2403.13234v2 Announce Type: replace 
Abstract: This paper investigates the optimal locations and capacities of hospital expansion facilities under uncertain future patient demands, considering both spatial and temporal correlations. We propose a novel two-stage distributionally robust optimization (DRO) model that integrates a Spatio-Temporal Neural Network (STNN). Specifically, we develop an STNN model that predicts future hospital occupancy levels considering spatial and temporal patterns in time-series datasets over a network of hospitals. The predictions of the STNN model are then used in the construction of the ambiguity set of the DRO model. To address computational challenges associated with two-stage DRO, we employ the linear-decision-rules technique to derive a tractable mixed-integer linear programming approximation. Extensive computational experiments conducted on real-world data demonstrate the superiority of the STNN model in minimizing forecast errors. Compared to neural network models built for each individual hospital, the proposed STNN model achieves a 53% improvement in average RMSE. Furthermore, the results demonstrate the value of incorporating spatiotemporal dependencies of demand uncertainty in the DRO model, as evidenced by out-of-sample analysis conducted with both ground truth data and under perfect information scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.13234v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aliaa Alnaggar, Faiza Farrukh</dc:creator>
    </item>
    <item>
      <title>Accelerated Objective Gap and Gradient Norm Convergence for Gradient Descent via Long Steps</title>
      <link>https://arxiv.org/abs/2403.14045</link>
      <description>arXiv:2403.14045v3 Announce Type: replace 
Abstract: This work considers gradient descent for L-smooth convex optimization with stepsizes larger than the classic regime where descent can be ensured. The stepsize schedules considered are similar to but differ slightly from the concurrently developed silver stepsizes of Altschuler and Parillo. For one of our stepsize sequences, we prove a $O\left(\frac{1}{N^{1.2716\dots}}\right)$ convergence rate in terms of objective gap decrease and for the other, we show the same rate of decrease for the squared-gradient-norm. This first result improves on the recent result of Altschuler and Parrilo by a constant factor, while the second results improve on the exponent of the prior best squared-gradient-norm convergence guarantee of $O(\frac{1}{N})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14045v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Grimmer, Kevin Shu, Alex L. Wang</dc:creator>
    </item>
    <item>
      <title>Horoballs and the subgradient method</title>
      <link>https://arxiv.org/abs/2403.15749</link>
      <description>arXiv:2403.15749v2 Announce Type: replace 
Abstract: To explore convex optimization on Hadamard spaces, we consider an iteration in the style of a subgradient algorithm. Traditionally, such methods assume that the underlying spaces are manifolds and that the objectives are geodesically convex: the methods are described using tangent spaces and exponential maps. By contrast, our iteration applies in a general Hadamard space, is framed in the underlying space itself, and relies instead on horospherical convexity of the objective level sets. For this restricted class of objectives, we prove a complexity result of the usual form. Notably, the complexity does not depend on a lower bound on the space curvature. We illustrate our subgradient algorithm on the minimal enclosing ball problem in Hadamard spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15749v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrian S. Lewis, Genaro Lopez-Acedo, Adriana Nicolae</dc:creator>
    </item>
    <item>
      <title>Sequential Decision-Making under Uncertainty: A Robust MDPs review</title>
      <link>https://arxiv.org/abs/2404.00940</link>
      <description>arXiv:2404.00940v3 Announce Type: replace 
Abstract: Fueled by both advances in robust optimization theory and applications of reinforcement learning, robust Markov Decision Processes (RMDPs) have gained increasing attention, due to their powerful capability for sequential decision-making under uncertainty. This review provides an in-depth overview of the evolution and advances in RMDPs formulations, particularly in ambiguity modeling, and classifies these methods for representing uncertainty into three principal approaches: parametric, moment-based, and discrepancy-based, elaborating the trade-offs among the alternative representations. Meanwhile, the review delves into the rectangular assumptions, which guarantee the tractability of RMDPs yet are noted for their conservatism. The review summarizes three popular rectangular conditions and develops a new proof to attest to the NP-hardness of non-rectangular RMDPs. Out of the traditional RMDPs scope, recent efforts without conventional rectangular assumptions and new fashions within the RMDPs community are also reviewed. These studies foster the development of more flexible and practical modeling frameworks and enhance the adaptability and performance of RMDPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00940v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenfan Ou, Sheng Bi</dc:creator>
    </item>
    <item>
      <title>Identification of High-dimensional ARMA Models with Binary-Valued Observations</title>
      <link>https://arxiv.org/abs/2404.01613</link>
      <description>arXiv:2404.01613v2 Announce Type: replace 
Abstract: This paper studies system identification of high-dimensional ARMA models with binary-valued observations. Compared with existing quantized identification of ARMA models, this problem is more challenging since the accessible information is much less. Different from the identification of FIR models with binary-valued observations, the prediction of original system output and the parameter both need to be estimated in ARMA models. We propose an online identification algorithm consisting of parameter estimation and prediction of original system output. The parameter estimation and the prediction of original output are strongly coupled but mutually reinforcing. By analyzing the two estimates at the same time instead of analyzing separately, we finally prove that the parameter estimate can converge to the true parameter with convergence rate $O(1/k)$ under certain conditions. Simulations are given to demonstrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01613v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Li, Ting Wang, Jin Guo, Yanlong Zhao</dc:creator>
    </item>
    <item>
      <title>Exploring Mount Neverest</title>
      <link>https://arxiv.org/abs/1009.2938</link>
      <description>arXiv:1009.2938v2 Announce Type: replace-cross 
Abstract: The problem `Exploring Mount Neverest' by Henry Ernest Dudeney is solved. Dudeney formulated the problem in the beginning of the 20th century and gave a non-optimal solution (without estimating the non-optimality).</description>
      <guid isPermaLink="false">oai:arXiv.org:1009.2938v2</guid>
      <category>math.HO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michiel de Bondt</dc:creator>
    </item>
    <item>
      <title>Solving non-Markovian Stochastic Control Problems driven by Wiener Functionals</title>
      <link>https://arxiv.org/abs/2003.06981</link>
      <description>arXiv:2003.06981v3 Announce Type: replace-cross 
Abstract: In this article, we present a general methodology for stochastic control problems driven by the Brownian motion filtration including non-Markovian and non-semimartingale state processes controlled by mutually singular measures. The main result of this paper is the development of a numerical scheme for computing near-optimal controls associated with controlled Wiener functionals via a finite-dimensional approximation procedure. The approach does not require functional differentiability assumptions on the value process and ellipticity conditions on the diffusion components. The general convergence of the method is established under rather weak conditions for distinct types of non-Markovian and non-semimartingale states. Explicit rates of convergence are provided in case the control acts only on the drift component of the controlled system. Near-closed/open-loop optimal controls are fully characterized by a dynamic programming algorithm and they are classified according to the strength of the possibly underlying non-Markovian memory. The theory is applied to stochastic control problems based on path-dependent SDEs and rough stochastic volatility models, where both drift and possibly degenerated diffusion components are controlled. Optimal control of drifts for nonlinear path-dependent SDEs driven by fractional Brownian motion with exponent $H\in (0,\frac{1}{2})$ is also discussed. Finally, we present a simple numerical example to illustrate the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2003.06981v3</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dorival Le\~ao, Alberto Ohashi, Francys Andrews de Souza</dc:creator>
    </item>
    <item>
      <title>An active learning method for solving competitive multi-agent decision-making and control problems</title>
      <link>https://arxiv.org/abs/2212.12561</link>
      <description>arXiv:2212.12561v3 Announce Type: replace-cross 
Abstract: To identify a stationary action profile for a population of competitive agents, each executing private strategies, we introduce a novel active-learning scheme where a centralized external observer (or entity) can probe the agents' reactions and recursively update simple local parametric estimates of the action-reaction mappings. Under very general working assumptions (not even assuming that a stationary profile exists), sufficient conditions are established to assess the asymptotic properties of the proposed active learning methodology so that, if the parameters characterizing the action-reaction mappings converge, a stationary action profile is achieved. Such conditions hence act also as certificates for the existence of such a profile. Extensive numerical simulations involving typical competitive multi-agent control and decision-making problems illustrate the practical effectiveness of the proposed learning-based approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.12561v3</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Fabiani, Alberto Bemporad</dc:creator>
    </item>
    <item>
      <title>Enhancing Multi-Objective Optimization through Machine Learning-Supported Multiphysics Simulation</title>
      <link>https://arxiv.org/abs/2309.13179</link>
      <description>arXiv:2309.13179v2 Announce Type: replace-cross 
Abstract: This paper presents a methodological framework for training, self-optimising, and self-organising surrogate models to approximate and speed up multiobjective optimisation of technical systems based on multiphysics simulations. At the hand of two real-world datasets, we illustrate that surrogate models can be trained on relatively small amounts of data to approximate the underlying simulations accurately. Including explainable AI techniques allow for highlighting feature relevancy or dependencies and supporting the possible extension of the used datasets. One of the datasets was created for this paper and is made publicly available for the broader scientific community. Extensive experiments combine four machine learning and deep learning algorithms with an evolutionary optimisation algorithm. The performance of the combined training and optimisation pipeline is evaluated by verifying the generated Pareto-optimal results using the ground truth simulations. The results from our pipeline and a comprehensive evaluation strategy show the potential for efficiently acquiring solution candidates in multiobjective optimisation tasks by reducing the number of simulations and conserving a higher prediction accuracy, i.e., with a MAPE score under 5% for one of the presented use cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.13179v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego Botache, Jens Decke, Winfried Ripken, Abhinay Dornipati, Franz G\"otz-Hahn, Mohamed Ayeb, Bernhard Sick</dc:creator>
    </item>
    <item>
      <title>Efficient Computation of the Quantum Rate-Distortion Function</title>
      <link>https://arxiv.org/abs/2309.15919</link>
      <description>arXiv:2309.15919v3 Announce Type: replace-cross 
Abstract: The quantum rate-distortion function plays a fundamental role in quantum information theory, however there is currently no practical algorithm which can efficiently compute this function to high accuracy for moderate channel dimensions. In this paper, we show how symmetry reduction can significantly simplify common instances of the entanglement-assisted quantum rate-distortion problems. This allows us to better understand the properties of the quantum channels which obtain the optimal rate-distortion trade-off, while also allowing for more efficient computation of the quantum rate-distortion function regardless of the numerical algorithm being used. Additionally, we propose an inexact variant of the mirror descent algorithm to compute the quantum rate-distortion function with provable sublinear convergence rates. We show how this mirror descent algorithm is related to Blahut-Arimoto and expectation-maximization methods previously used to solve similar problems in information theory. Using these techniques, we present the first numerical experiments to compute a multi-qubit quantum rate-distortion function, and show that our proposed algorithm solves faster and to higher accuracy when compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15919v3</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kerry He, James Saunderson, Hamza Fawzi</dc:creator>
    </item>
    <item>
      <title>Physics-Informed Graph Neural Network for Dynamic Reconfiguration of Power Systems</title>
      <link>https://arxiv.org/abs/2310.00728</link>
      <description>arXiv:2310.00728v2 Announce Type: replace-cross 
Abstract: To maintain a reliable grid we need fast decision-making algorithms for complex problems like Dynamic Reconfiguration (DyR). DyR optimizes distribution grid switch settings in real-time to minimize grid losses and dispatches resources to supply loads with available generation. DyR is a mixed-integer problem and can be computationally intractable to solve for large grids and at fast timescales. We propose GraPhyR, a Physics-Informed Graph Neural Network (GNNs) framework tailored for DyR. We incorporate essential operational and connectivity constraints directly within the GNN framework and train it end-to-end. Our results show that GraPhyR is able to learn to optimize the DyR task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00728v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jules Authier, Rabab Haider, Anuradha Annaswamy, Florian Dorfler</dc:creator>
    </item>
    <item>
      <title>Differentially Private Non-Convex Optimization under the KL Condition with Optimal Rates</title>
      <link>https://arxiv.org/abs/2311.13447</link>
      <description>arXiv:2311.13447v2 Announce Type: replace-cross 
Abstract: We study private empirical risk minimization (ERM) problem for losses satisfying the $(\gamma,\kappa)$-Kurdyka-{\L}ojasiewicz (KL) condition. The Polyak-{\L}ojasiewicz (PL) condition is a special case of this condition when $\kappa=2$. Specifically, we study this problem under the constraint of $\rho$ zero-concentrated differential privacy (zCDP). When $\kappa\in[1,2]$ and the loss function is Lipschitz and smooth over a sufficiently large region, we provide a new algorithm based on variance reduced gradient descent that achieves the rate $\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^\kappa\big)$ on the excess empirical risk, where $n$ is the dataset size and $d$ is the dimension. We further show that this rate is nearly optimal. When $\kappa \geq 2$ and the loss is instead Lipschitz and weakly convex, we show it is possible to achieve the rate $\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^\kappa\big)$ with a private implementation of the proximal point method. When the KL parameters are unknown, we provide a novel modification and analysis of the noisy gradient descent algorithm and show that this algorithm achieves a rate of $\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^{\frac{2\kappa}{4-\kappa}}\big)$ adaptively, which is nearly optimal when $\kappa = 2$. We further show that, without assuming the KL condition, the same gradient descent algorithm can achieve fast convergence to a stationary point when the gradient stays sufficiently large during the run of the algorithm. Specifically, we show that this algorithm can approximate stationary points of Lipschitz, smooth (and possibly nonconvex) objectives with rate as fast as $\tilde{O}\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)$ and never worse than $\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^{1/2}\big)$. The latter rate matches the best known rate for methods that do not rely on variance reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13447v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Menart, Enayat Ullah, Raman Arora, Raef Bassily, Crist\'obal Guzm\'an</dc:creator>
    </item>
    <item>
      <title>On Complexity of Stability Analysis in Higher-order Ecological Networks through Tensor Decompositions</title>
      <link>https://arxiv.org/abs/2401.02023</link>
      <description>arXiv:2401.02023v2 Announce Type: replace-cross 
Abstract: Complex ecological networks are often characterized by intricate interactions that extend beyond pairwise relationships. Understanding the stability of higher-order ecological networks is salient for species coexistence, biodiversity, and community persistence. In this article, we present complexity analyses for determining the linear stability of higher-order ecological networks through tensor decompositions. We are interested in the higher-order generalized Lotka-Volterra model, which captures high-order interactions using tensors of varying orders. To efficiently compute Jacobian matrices and thus determine stability in large ecological networks, we exploit various tensor decompositions, including higher-order singular value decomposition, Canonical Polyadic decomposition, and tensor train decomposition, accompanied by in-depth computational and memory complexity analyses. We demonstrate the effectiveness of our framework with numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.02023v2</guid>
      <category>eess.SY</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anqi Dong, Can Chen</dc:creator>
    </item>
    <item>
      <title>A Coupled Optimization Framework for Correlated Equilibria in Normal-Form Game</title>
      <link>https://arxiv.org/abs/2403.16223</link>
      <description>arXiv:2403.16223v2 Announce Type: replace-cross 
Abstract: In competitive multi-player interactions, simultaneous optimality is a key requirement for establishing strategic equilibria. This property is explicit when the game-theoretic equilibrium is the simultaneously optimal solution of coupled optimization problems. However, no such optimization problems exist for the correlated equilibrium, a strategic equilibrium where the players can correlate their actions. We address the lack of a coupled optimization framework for the correlated equilibrium by introducing an {unnormalized game} -- an extension of normal-form games in which the player strategies are lifted to unnormalized measures over the joint actions. We show that the set of fully mixed generalized Nash equilibria of this unnormalized game is a subset of the correlated equilibrium of the normal-form game. Furthermore, we introduce an entropy regularization to the unnormalized game and prove that the entropy-regularized generalized Nash equilibrium is a sub-optimal correlated equilibrium of the normal form game where the degree of sub-optimality depends on the magnitude of regularization. We prove that the entropy-regularized unnormalized game has a closed-form solution, and empirically verify its computational efficacy at approximating the correlated equilibrium of normal-form games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16223v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarah H. Q. Li, Yue Yu, Florian D\"orfler, John Lygeros</dc:creator>
    </item>
  </channel>
</rss>
