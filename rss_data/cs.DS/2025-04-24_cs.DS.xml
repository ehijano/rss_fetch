<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Apr 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Updating Lower and Upper Bounds for the Job-Shop Scheduling Problem Test Instances</title>
      <link>https://arxiv.org/abs/2504.16106</link>
      <description>arXiv:2504.16106v1 Announce Type: new 
Abstract: The Job-Shop Scheduling Problem (JSSP) and its variant, the Flexible Job-Shop Scheduling Problem (FJSSP), are combinatorial optimization problems studied thoroughly in the literature. Generally, the aim is to reduce the makespan of a scheduling solution corresponding to a problem instance. Thus, finding upper and lower bounds for an optimal makespan enables the assessment of performances for multiple approaches addressed so far. We use OR-Tools, a solver portfolio, to compute new bounds for some open benchmark instances, in order to reduce the gap between upper and lower bounds. We find new numerical lower bounds for multiple benchmark instances, up to closing the Taillard's ta33 instance. We also improve upper bounds for four instances, namely Taillard's ta26 &amp; ta45 and Dauzere's 05a &amp; 06a. Additionally we share an optimal solution for Taillard's ta45 as well as Hurink-edata's car5.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16106v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Marc-Emmanuel Coupvent des Graviers (Safran Electronics and Defense, France), Lotfi Kobrosly (Safran Electronics and Defense, France, LAMSADE, Universit\'e Paris Dauphine-PSL, Place du Mar\'echal de Lattre de Tassigny, Paris, France), Christophe Guettier (Safran Electronics and Defense, France), Tristan Cazenave (LAMSADE, Universit\'e Paris Dauphine-PSL, Place du Mar\'echal de Lattre de Tassigny, Paris, France)</dc:creator>
    </item>
    <item>
      <title>A Theory of Spectral CSP Sparsification</title>
      <link>https://arxiv.org/abs/2504.16206</link>
      <description>arXiv:2504.16206v1 Announce Type: new 
Abstract: We initiate the study of spectral sparsification for instances of Constraint Satisfaction Problems (CSPs). In particular, we introduce a notion of the \emph{spectral energy} of a fractional assignment for a Boolean CSP instance, and define a \emph{spectral sparsifier} as a weighted subset of constraints that approximately preserves this energy for all fractional assignments. Our definition not only strengthens the combinatorial notion of a CSP sparsifier but also extends well-studied concepts such as spectral sparsifiers for graphs and hypergraphs.
  Recent work by Khanna, Putterman, and Sudan [SODA 2024] demonstrated near-linear sized \emph{combinatorial sparsifiers} for a broad class of CSPs, which they term \emph{field-affine CSPs}. Our main result is a polynomial-time algorithm that constructs a spectral CSP sparsifier of near-quadratic size for all field-affine CSPs. This class of CSPs includes graph (and hypergraph) cuts, XORs, and more generally, any predicate which can be written as $P(x_1, \dots x_r) = \mathbf{1}[\sum a_i x_i \neq b \mod p]$.
  Based on our notion of the spectral energy of a fractional assignment, we also define an analog of the second eigenvalue of a CSP instance. We then show an extension of Cheeger's inequality for all even-arity XOR CSPs, showing that this second eigenvalue loosely captures the ``expansion'' of the underlying CSP. This extension specializes to the case of Cheeger's inequality when all constraints are even XORs and thus gives a new generalization of this powerful inequality which converts the combinatorial notion of expansion to an analytic property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16206v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sanjeev Khanna, Aaron Putterman, Madhu Sudan</dc:creator>
    </item>
    <item>
      <title>Fast, Space-Optimal Streaming Algorithms for Clustering and Subspace Embeddings</title>
      <link>https://arxiv.org/abs/2504.16229</link>
      <description>arXiv:2504.16229v1 Announce Type: new 
Abstract: We show that both clustering and subspace embeddings can be performed in the streaming model with the same asymptotic efficiency as in the central/offline setting.
  For $(k, z)$-clustering in the streaming model, we achieve a number of words of memory which is independent of the number $n$ of input points and the aspect ratio $\Delta$, yielding an optimal bound of $\tilde{\mathcal{O}}\left(\frac{dk}{\min(\varepsilon^4,\varepsilon^{z+2})}\right)$ words for accuracy parameter $\varepsilon$ on $d$-dimensional points. Additionally, we obtain amortized update time of $d\,\log(k)\cdot\text{polylog}(\log(n\Delta))$, which is an exponential improvement over the previous $d\,\text{poly}(k,\log(n\Delta))$. Our method also gives the fastest runtime for $(k,z)$-clustering even in the offline setting.
  For subspace embeddings in the streaming model, we achieve $\mathcal{O}(d)$ update time and space-optimal constructions, using $\tilde{\mathcal{O}}\left(\frac{d^2}{\varepsilon^2}\right)$ words for $p\le 2$ and $\tilde{\mathcal{O}}\left(\frac{d^{p/2+1}}{\varepsilon^2}\right)$ words for $p&gt;2$, showing that streaming algorithms can match offline algorithms in both space and time complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16229v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Cohen-Addad, Liudeng Wang, David P. Woodruff, Samson Zhou</dc:creator>
    </item>
    <item>
      <title>Linear Time Subsequence and Supersequence Regex Matching</title>
      <link>https://arxiv.org/abs/2504.16288</link>
      <description>arXiv:2504.16288v1 Announce Type: new 
Abstract: It is well-known that checking whether a given string $w$ matches a given regular expression $r$ can be done in quadratic time $O(|w|\cdot |r|)$ and that this cannot be improved to a truly subquadratic running time of $O((|w|\cdot |r|)^{1-\epsilon})$ assuming the strong exponential time hypothesis (SETH). We study a different matching paradigm where we ask instead whether $w$ has a subsequence that matches $r$, and show that regex matching in this sense can be solved in linear time $O(|w| + |r|)$. Further, the same holds if we ask for a supersequence. We show that the quantitative variants where we want to compute a longest or shortest subsequence or supersequence of $w$ that matches $r$ can be solved in $O(|w| \cdot |r|)$, i. e., asymptotically no worse than classical regex matching; and we show that $O(|w| + |r|)$ is conditionally not possible for these problems. We also investigate these questions with respect to other natural string relations like the infix, prefix, left-extension or extension relation instead of the subsequence and supersequence relation. We further study the complexity of the universal problem where we ask if all subsequences (or supersequences, infixes, prefixes, left-extensions or extensions) of an input string satisfy a given regular expression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16288v1</guid>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine Amarilli, Florin Manea, Tina Ringleb, Markus L. Schmid</dc:creator>
    </item>
    <item>
      <title>Near-optimal Hypergraph Sparsification in Insertion-only and Bounded-deletion Streams</title>
      <link>https://arxiv.org/abs/2504.16321</link>
      <description>arXiv:2504.16321v1 Announce Type: new 
Abstract: We study the problem of constructing hypergraph cut sparsifiers in the streaming model where a hypergraph on $n$ vertices is revealed either via an arbitrary sequence of hyperedge insertions alone ({\em insertion-only} streaming model) or via an arbitrary sequence of hyperedge insertions and deletions ({\em dynamic} streaming model). For any $\epsilon \in (0,1)$, a $(1 \pm \epsilon)$ hypergraph cut-sparsifier of a hypergraph $H$ is a reweighted subgraph $H'$ whose cut values approximate those of $H$ to within a $(1 \pm \epsilon)$ factor. Prior work shows that in the static setting, one can construct a $(1 \pm \epsilon)$ hypergraph cut-sparsifier using $\tilde{O}(nr/\epsilon^2)$ bits of space [Chen-Khanna-Nagda FOCS 2020], and in the setting of dynamic streams using $\tilde{O}(nr\log m/\epsilon^2)$ bits of space [Khanna-Putterman-Sudan FOCS 2024]; here the $\tilde{O}$ notation hides terms that are polylogarithmic in $n$, and we use $m$ to denote the total number of hyperedges in the hypergraph. Up until now, the best known space complexity for insertion-only streams has been the same as that for the dynamic streams. This naturally poses the question of understanding the complexity of hypergraph sparsification in insertion-only streams.
  Perhaps surprisingly, in this work we show that in \emph{insertion-only} streams, a $(1 \pm \epsilon)$ cut-sparsifier can be computed in $\tilde{O}(nr/\epsilon^2)$ bits of space, \emph{matching the complexity} of the static setting. As a consequence, this also establishes an $\Omega(\log m)$ factor separation between the space complexity of hypergraph cut sparsification in insertion-only streams and dynamic streams, as the latter is provably known to require $\Omega(nr \log m)$ bits of space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16321v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sanjeev Khanna, Aaron Putterman, Madhu Sudan</dc:creator>
    </item>
    <item>
      <title>Universal Online Contention Resolution with Preselected Order</title>
      <link>https://arxiv.org/abs/2504.16327</link>
      <description>arXiv:2504.16327v1 Announce Type: new 
Abstract: Online contention resolution scheme (OCRS) is a powerful technique for online decision making, which--in the case of matroids--given a matroid and a prior distribution of active elements, selects a subset of active elements that satisfies the matroid constraint in an online fashion. OCRS has been studied mostly for product distributions in the literature. Recently, universal OCRS, that works even for correlated distributions, has gained interest, because it naturally generalizes the classic notion, and its existence in the random-order arrival model turns out to be equivalent to the matroid secretary conjecture. However, currently very little is known about how to design universal OCRSs for any arrival model. In this work, we consider a natural and relatively flexible arrival model, where the OCRS is allowed to preselect (i.e., non-adaptively select) the arrival order of the elements, and within this model, we design simple and optimal universal OCRSs that are computationally efficient. In the course of deriving our OCRSs, we also discover an efficient reduction from universal online contention resolution to the matroid secretary problem for any arrival model, answering a question from Dughmi (2020).</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16327v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyao Zhao</dc:creator>
    </item>
    <item>
      <title>Fully Scalable MPC Algorithms for Euclidean k-Center</title>
      <link>https://arxiv.org/abs/2504.16382</link>
      <description>arXiv:2504.16382v1 Announce Type: new 
Abstract: The $k$-center problem is a fundamental optimization problem with numerous applications in machine learning, data analysis, data mining, and communication networks. The $k$-center problem has been extensively studied in the classical sequential setting for several decades, and more recently there have been some efforts in understanding the problem in parallel computing, on the Massively Parallel Computation (MPC) model. For now, we have a good understanding of $k$-center in the case where each local MPC machine has sufficient local memory to store some representatives from each cluster, that is, when one has $\Omega(k)$ local memory per machine. While this setting covers the case of small values of $k$, for a large number of clusters these algorithms require undesirably large local memory, making them poorly scalable. The case of large $k$ has been considered only recently for the fully scalable low-local-memory MPC model for the Euclidean instances of the $k$-center problem. However, the earlier works have been considering only the constant dimensional Euclidean space, required a super-constant number of rounds, and produced only $k(1+o(1))$ centers whose cost is a super-constant approximation of $k$-center.
  In this work, we significantly improve upon the earlier results for the $k$-center problem for the fully scalable low-local-memory MPC model. In the low dimensional Euclidean case in $\mathbb{R}^d$, we present the first constant-round fully scalable MPC algorithm for $(2+\varepsilon)$-approximation. We push the ratio further to $(1 + \varepsilon)$-approximation albeit using slightly more $(1 + \varepsilon)k$ centers. All these results naturally extends to slightly super-constant values of $d$. In the high-dimensional regime, we provide the first fully scalable MPC algorithm that in a constant number of rounds achieves an $O(\log n/ \log \log n)$-approximation for $k$-center.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16382v1</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Artur Czumaj, Guichen Gao, Mohsen Ghaffari, Shaofeng H. -C. Jiang</dc:creator>
    </item>
    <item>
      <title>An Explicit and Efficient $O(n^2)$-Time Algorithm for Sorting Sumsets</title>
      <link>https://arxiv.org/abs/2504.16393</link>
      <description>arXiv:2504.16393v1 Announce Type: new 
Abstract: We present the first explicit comparison-based algorithm that sorts the sumset $X + Y = \{x_i + y_j,\ \forall 0 \le i, j &lt; n\}$, where $X$ and $Y$ are sorted arrays of real numbers, in optimal $O(n^2)$ time and comparisons. While Fredman (1976) proved the theoretical existence of such an algorithm, a concrete construction has remained open for nearly five decades. Our algorithm exploits the structured monotonicity of the sumset matrix to perform amortized constant-comparisons and insertions, eliminating the $\log(n)$ overhead typical of comparison-based sorting. We prove correctness and optimality in the standard comparison model, extend the method to $k$-fold sumsets with $O(n^k)$ performance, and outline potential support for dynamic updates. Experimental benchmarks show significant speedups over classical algorithms such as MergeSort and QuickSort when applied to sumsets. These results resolve a longstanding open problem in sorting theory and contribute novel techniques for exploiting input structure in algorithm design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16393v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. Mundhra (Ohio Wesleyan University)</dc:creator>
    </item>
    <item>
      <title>Hardness of Median and Center in the Ulam Metric</title>
      <link>https://arxiv.org/abs/2504.16437</link>
      <description>arXiv:2504.16437v1 Announce Type: new 
Abstract: The classical rank aggregation problem seeks to combine a set X of n permutations into a single representative "consensus" permutation. In this paper, we investigate two fundamental rank aggregation tasks under the well-studied Ulam metric: computing a median permutation (which minimizes the sum of Ulam distances to X) and computing a center permutation (which minimizes the maximum Ulam distance to X) in two settings.
  $\bullet$ Continuous Setting: In the continuous setting, the median/center is allowed to be any permutation. It is known that computing a center in the Ulam metric is NP-hard and we add to this by showing that computing a median is NP-hard as well via a simple reduction from the Max-Cut problem. While this result may not be unexpected, it had remained elusive until now and confirms a speculation by Chakraborty, Das, and Krauthgamer [SODA '21].
  $\bullet$ Discrete Setting: In the discrete setting, the median/center must be a permutation from the input set. We fully resolve the fine-grained complexity of the discrete median and discrete center problems under the Ulam metric, proving that the naive $\widetilde{O}(n^2 L)$-time algorithm (where L is the length of the permutation) is conditionally optimal. This resolves an open problem raised by Abboud, Bateni, Cohen-Addad, Karthik C. S., and Seddighin [APPROX '23]. Our reductions are inspired by the known fine-grained lower bounds for similarity measures, but we face and overcome several new highly technical challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16437v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick Fischer, Elazar Goldenberg, Mursalin Habib, C. S. Karthik</dc:creator>
    </item>
    <item>
      <title>Multiplicative Spanners in Minor-Free Graphs</title>
      <link>https://arxiv.org/abs/2504.16463</link>
      <description>arXiv:2504.16463v1 Announce Type: new 
Abstract: In FOCS 2017, Borradaille, Le, and Wulff-Nilsen addressed a long-standing open problem by proving that minor-free graphs have light spanners. Specifically, they proved that every $K_h$-minor-free graph has a $(1+\epsilon)$-spanner of lightness $O_{\epsilon}(h \sqrt{\log h})$, hence constant when $h$ and $\epsilon$ are regarded as constants.
  We extend this result by showing that a more expressive size/stretch tradeoff is available. Specifically: for any positive integer $k$, every $n$-node, $K_h$-minor-free graph has a $(2k-1)$-spanner with sparsity \[O\left(h^{\frac{2}{k+1}} \cdot \text{polylog } h\right),\] and a $(1+\epsilon)(2k-1)$-spanner with lightness \[O_{\epsilon}\left(h^{\frac{2}{k+1}} \cdot \text{polylog } h \right).\] We further prove that this exponent $\frac{2}{k+1}$ is best possible, assuming the girth conjecture. At a technical level, our proofs leverage the recent improvements by Postle (2020) to the remarkable density increment theorem for minor-free graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16463v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Greg Bodwin, Gary Hoppenworth, Zihan Tan</dc:creator>
    </item>
    <item>
      <title>Improved Streaming Edge Coloring</title>
      <link>https://arxiv.org/abs/2504.16470</link>
      <description>arXiv:2504.16470v1 Announce Type: new 
Abstract: Given a graph, an edge coloring assigns colors to edges so that no pairs of adjacent edges share the same color. We are interested in edge coloring algorithms under the W-streaming model. In this model, the algorithm does not have enough memory to hold the entire graph, so the edges of the input graph are read from a data stream one by one in an unknown order, and the algorithm needs to print a valid edge coloring in an output stream. The performance of the algorithm is measured by the amount of space and the number of different colors it uses.
  This streaming edge coloring problem has been studied by several works in recent years. When the input graph contains $n$ vertices and has maximum vertex degree $\Delta$, it is known that in the W-streaming model, an $O(\Delta^2)$-edge coloring can be computed deterministically with $\tilde{O}(n)$ space [Ansari, Saneian, and Zarrabi-Zadeh, 2022], or an $O(\Delta^{1.5})$-edge coloring can be computed by a $\tilde{O}(n)$-space randomized algorithm [Behnezhad, Saneian, 2024] [Chechik, Mukhtar, Zhang, 2024].
  In this paper, we achieve polynomial improvement over previous results. Specifically, we show how to improve the number of colors to $\tilde{O}(\Delta^{4/3+\epsilon})$ using space $\tilde{O}(n)$ deterministically, for any constant $\epsilon &gt; 0$. This is the first deterministic result that bypasses the quadratic bound on the number of colors while using near-linear space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16470v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiri Chechik, Hongyi Chen, Tianyi Zhang</dc:creator>
    </item>
    <item>
      <title>Estimating Random-Walk Probabilities in Directed Graphs</title>
      <link>https://arxiv.org/abs/2504.16481</link>
      <description>arXiv:2504.16481v1 Announce Type: new 
Abstract: We study discounted random walks in a directed graph. In each vertex, the walk will either terminate with some probability $\alpha$, or continue to a random out-neighbor. We are interested in the probability $\pi(s,t)$ that such a random walk starting in $s$ ends in $t$. We wish to, with constant probability, estimate $\pi(s, t)$ within a constant relative error, unless $\pi(s, t) &lt; \delta$ for some given threshold $\delta$.
  The current status is as follows. Algorithms with worst-case running time $\tilde O(m)$ and $O(1/\delta)$ are known. A more complicated algorithm is known, which does not perform better in the worst case, but for the average running time over all $n$ possible targets $t$, it achieves an alternative bound of $O(\sqrt{d/\delta})$. All the above algorithms assume query access to the adjacency list of a node.
  On the lower bound side, the best-known lower bound for the worst case is $\Omega(n^{1/2}m^{1/4})$ with $\delta \leq 1/(n^{1/2}m^{1/4})$, and for the average case it is $\Omega(\sqrt{n})$ with $\delta \leq 1/n$. This leaves substantial polynomial gaps in both cases.
  In this paper, we show that the above upper bounds are tight across all parameters $n$, $m$ and $\delta$. We show that the right bound is $\tilde\Theta(\min\{m, 1/\delta\})$ for the worst case, and $\tilde\Theta(\min\{m, \sqrt{d/\delta}, 1/\delta\})$ for the average case.
  We also consider some additional graph queries from the literature. One allows checking whether there is an edge from $u$ to $v$ in constant time. Another allows access to the adjacency list of $u$ sorted by out-degree. We prove that none of these access queries help in the worst case, but if we have both of them, we get an average-case bound of $\tilde \Theta(\min\{m,\sqrt{d/\delta}, (1/\delta)^{2/3}\})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16481v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Bertram, Mads Vestergaard Jensen, Mikkel Thorup, Hanzhi Wang, Shuyi Yan</dc:creator>
    </item>
    <item>
      <title>Streaming algorithms for products of probabilities</title>
      <link>https://arxiv.org/abs/2504.16507</link>
      <description>arXiv:2504.16507v1 Announce Type: new 
Abstract: We consider streaming algorithms for approximating a product of input probabilities up to multiplicative error of $1-\epsilon$. It is shown that every randomized streaming algorithm for this problem needs space $\Omega(\log n + \log b - \log \epsilon) - \mathcal{O}(1)$, where $n$ is length of the input stream and $b$ is the bit length of the input numbers. This matches an upper bound from Alur et al.~up to a constant multiplicative factor. Moreover, we consider the threshold problem, where it is asked whether the product of the input probabilities is below a given threshold. It is shown that every randomized streaming algorithm for this problem needs space $\Omega(n \cdot b)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16507v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Markus Lohrey, Leon Rische, Louisa Seelbach Benkner, Julio Xochitemol</dc:creator>
    </item>
    <item>
      <title>Sorting as Gradient Flow on the Permutohedron</title>
      <link>https://arxiv.org/abs/2504.16706</link>
      <description>arXiv:2504.16706v1 Announce Type: new 
Abstract: We investigate how sorting algorithms efficiently overcome the exponential size of the permutation space. Our main contribution is a new continuous-time formulation of sorting as a gradient flow on the permutohedron, yielding an independent proof of the classical $\Omega(n \log n)$ lower bound for comparison-based sorting. This formulation reveals how exponential contraction of disorder occurs under simple geometric dynamics. In support of this analysis, we present algebraic, combinatorial, and geometric perspectives, including decision-tree arguments and linear constraints on the permutohedron. The idea that efficient sorting arises from structure-guided logarithmic reduction offers a unifying lens for how comparisons tame exponential spaces. These observations connect to broader questions in theoretical computer science, such as whether the existence of structure can explain why certain computational problems permit efficient solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16706v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Landers</dc:creator>
    </item>
    <item>
      <title>From Theory to Practice: Engineering Approximation Algorithms for Dynamic Orientation</title>
      <link>https://arxiv.org/abs/2504.16720</link>
      <description>arXiv:2504.16720v1 Announce Type: new 
Abstract: Dynamic graph algorithms have seen significant theoretical advancements, but practical evaluations often lag behind. This work bridges the gap between theory and practice by engineering and empirically evaluating recently developed approximation algorithms for dynamically maintaining graph orientations. We comprehensively describe the underlying data structures, including efficient bucketing techniques and round-robin updates. Our implementation has a natural parameter $\lambda$, which allows for a trade-off between algorithmic efficiency and the quality of the solution. In the extensive experimental evaluation, we demonstrate that our implementation offers a considerable speedup. Using different quality metrics, we show that our implementations are very competitive and can outperform previous methods. Overall, our approach solves more instances than other methods while being up to 112 times faster on instances that are solvable by all methods compared.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16720v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ernestine Gro{\ss}mann, Ivor van der Hoog, Henrik Reinst\"adtler, Eva Rotenberg, Christian Schulz, Juliette Vlieghe</dc:creator>
    </item>
    <item>
      <title>Traffic-Oblivious Multi-Commodity Flow Network Design</title>
      <link>https://arxiv.org/abs/2504.16744</link>
      <description>arXiv:2504.16744v1 Announce Type: new 
Abstract: We consider the Minimum Multi-Commodity Flow Subgraph (MMCFS) problem: given a directed graph $G$ with edge capacities $\mathit{cap}$ and a retention ratio $\alpha\in(0,1)$, find an edge-wise minimum subgraph $G' \subseteq G$ such that for all traffic matrices $T$ routable in $G$ using a multi-commodity flow, $\alpha\cdot T$ is routable in $G'$. This natural yet novel problem is motivated by recent research that investigates how the power consumption in backbone computer networks can be reduced by turning off connections during times of low demand without compromising the quality of service. Since the actual traffic demands are generally not known beforehand, our approach must be traffic-oblivious, i.e., work for all possible sets of simultaneously routable traffic demands in the original network.
  In this paper we present the problem, relate it to other known problems in literature, and show several structural results, including a reformulation, maximum possible deviations from the optimum, and NP-hardness (as well as a certain inapproximability) already on very restricted instances. The most significant contribution is a tight $\max(\frac{1}{\alpha}, 2)$-approximation based on an algorithmically surprisingly simple LP-rounding scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16744v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Markus Chimani, Max Ilsen</dc:creator>
    </item>
    <item>
      <title>Graph modification of bounded size to minor-closed classes as fast as vertex deletion</title>
      <link>https://arxiv.org/abs/2504.16803</link>
      <description>arXiv:2504.16803v1 Announce Type: new 
Abstract: A replacement action is a function $\mathcal{L}$ that maps each graph $H$ to a collection of graphs of size at most $|V(H)|$. Given a graph class $\mathcal{H}$, we consider a general family of graph modification problems, called $\mathcal{L}$-Replacement to $\mathcal{H}$, where the input is a graph $G$ and the question is whether it is possible to replace some induced subgraph $H_1$ of $G$ on at most $k$ vertices by a graph $H_2$ in $\mathcal{L}(H_1)$ so that the resulting graph belongs to $\mathcal{H}$. $\mathcal{L}$-Replacement to $\mathcal{H}$ can simulate many graph modification problems including vertex deletion, edge deletion/addition/edition/contraction, vertex identification, subgraph complementation, independent set deletion, (induced) matching deletion/contraction, etc. We present two algorithms. The first one solves $\mathcal{L}$-Replacement to $\mathcal{H}$ in time $2^{{\rm poly}(k)}\cdot |V(G)|^2$ for every minor-closed graph class $\mathcal{H}$, where {\rm poly} is a polynomial whose degree depends on $\mathcal{H}$, under a mild technical condition on $\mathcal{L}$. This generalizes the results of Morelle, Sau, Stamoulis, and Thilikos [ICALP 2020, ICALP 2023] for the particular case of Vertex Deletion to $\mathcal{H}$ within the same running time. Our second algorithm is an improvement of the first one when $\mathcal{H}$ is the class of graphs embeddable in a surface of Euler genus at most $g$ and runs in time $2^{\mathcal{O}(k^{9})}\cdot |V(G)|^2$, where the $\mathcal{O}(\cdot)$ notation depends on $g$. To the best of our knowledge, these are the first parameterized algorithms with a reasonable parametric dependence for such a general family of graph modification problems to minor-closed classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16803v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laure Morelle, Ignasi Sau, Dimitrios M. Thilikos</dc:creator>
    </item>
    <item>
      <title>Approximating Optimal Labelings for Temporal Connectivity</title>
      <link>https://arxiv.org/abs/2504.16837</link>
      <description>arXiv:2504.16837v1 Announce Type: new 
Abstract: In a temporal graph the edge set dynamically changes over time according to a set of time-labels associated with each edge that indicates at which time-steps the edge is available. Two vertices are connected if there is a path connecting them in which the edges are traversed in increasing order of their labels. We study the problem of scheduling the availability time of the edges of a temporal graph in such a way that all pairs of vertices are connected within a given maximum allowed time $a$ and the overall number of labels is minimized.
  The problem, known as \emph{Minimum Aged Labeling} (MAL), has several applications in logistics, distribution scheduling, and information spreading in social networks, where carefully choosing the time-labels can significantly reduce infrastructure costs, fuel consumption, or greenhouse gases.
  The problem MAL has previously been proved to be NP-complete on undirected graphs and \APX-hard on directed graphs. In this paper, we extend our knowledge on the complexity and approximability of MAL in several directions. We first show that the problem cannot be approximated within a factor better than $O(\log n)$ when $a\geq 2$, unless $\text{P} = \text{NP}$, and a factor better than $2^{\log ^{1-\epsilon} n}$ when $a\geq 3$, unless $\text{NP}\subseteq \text{DTIME}(2^{\text{polylog}(n)})$, where $n$ is the number of vertices in the graph. Then we give a set of approximation algorithms that, under some conditions, almost match these lower bounds. In particular, we show that the approximation depends on a relation between $a$ and the diameter of the input graph.
  We further establish a connection with a foundational optimization problem on static graphs called \emph{Diameter Constrained Spanning Subgraph} (DCSS) and show that our hardness results also apply to DCSS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16837v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniele Carnevale (Gran Sasso Science Institute), Gianlorenzo D'Angelo (Gran Sasso Science Institute), Martin Olsen (Aarhus University)</dc:creator>
    </item>
    <item>
      <title>Equivalences between Non-trivial Variants of 3LDT and Conv3LDT</title>
      <link>https://arxiv.org/abs/2001.01289</link>
      <description>arXiv:2001.01289v2 Announce Type: replace 
Abstract: The popular 3SUM conjecture states that there is no strongly subquadratic time algorithm for checking if a given set of integers contains three distinct elements $x_1, x_2, x_3$ such that $x_1+x_2=x_3$. A closely related problem is to check if a given set of integers contains distinct elements satisfying $x_1+x_2=2x_3$. This can be reduced to 3SUM in almost-linear time, but surprisingly a reverse reduction establishing 3SUM hardness was not known.
  We provide such a reduction, thus resolving an open question of Erickson. In fact, we consider a more general problem called 3LDT parameterized by integer parameters $\alpha_1, \alpha_2, \alpha_3$ and $t$. In this problem, we need to check if a given set of integers contains distinct elements $x_1, x_2, x_3$ such that $\alpha_1 x_1+\alpha_2 x_2 +\alpha_3 x_3 = t$. We prove that all non-trivial variants of 3LDT over the same universe $[-n^c,n^c]$ for some $c\geq2$ are equivalent under subquadratic reductions. The main technical tool used in our proof is an application of the famous Behrend's construction that partitions a given set of integers into few subsets that avoid a chosen linear equation.
  We extend our results to Conv3LDT and show that for all $c\geq2$, all non-trivial variants of 3LDT over the universe $[-n^c,n^c]$ and of Conv3LDT over the universe $[-n^{c-1},n^{c-1}]$ are subquadratic-equivalent, so in particular they are all equivalent to 3SUM under subquadratic reductions.
  Finally, we show how to apply the methods of Fischer et al. to show that we can reduce non-trivial variant of 3LDT (Conv3LDT) over an arbitrary universe to the same variant over cubic (quadratic) universe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2001.01289v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bart{\l}omiej Dudek, Pawe{\l} Gawrychowski, Tatiana Starikovskaya</dc:creator>
    </item>
    <item>
      <title>Finding Small Complete Subgraphs Efficiently</title>
      <link>https://arxiv.org/abs/2308.11146</link>
      <description>arXiv:2308.11146v3 Announce Type: replace 
Abstract: (I) We revisit the algorithmic problem of finding all triangles in a graph $G=(V,E)$ with $n$ vertices and $m$ edges. According to a result of Chiba and Nishizeki (1985), this task can be achieved by a combinatorial algorithm running in $O(m \alpha) = O(m^{3/2})$ time, where $\alpha= \alpha(G)$ is the graph arboricity. We provide a new very simple combinatorial algorithm for finding all triangles in a graph and show that is amenable to the same running time analysis. We derive these worst-case bounds from first principles and with very simple proofs that do not rely on classic results due to Nash-Williams from the 1960s. Our experimental results show that our simple algorithm for triangle listing is substantially faster in practice than that of Chiba and Nishizeki on all examples of real-world graphs we tried.
  (II) We extend our arguments to the problem of finding all small complete subgraphs of a given fixed size. We show that the dependency on $m$ and $\alpha$ in the running time $O(\alpha^{\ell-2} \cdot m)$ of the algorithm of Chiba and Nishizeki for listing all copies of $K_\ell$, where $\ell \geq 3$, is asymptotically tight.
  (III) We give improved arboricity-sensitive running times for counting and/or detection of copies of $K_\ell$, for small $\ell \geq 4$. A key ingredient in our algorithms is, once again, the algorithm of Chiba and Nishizeki. Our new algorithms are faster than all previous algorithms in certain high-range arboricity intervals for every $\ell \geq 7$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.11146v3</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ke Chen, Adrian Dumitrescu, Andrzej Lingas</dc:creator>
    </item>
    <item>
      <title>Fair and Efficient Ridesharing: A Dynamic Programming-based Relocation Approach</title>
      <link>https://arxiv.org/abs/2401.15363</link>
      <description>arXiv:2401.15363v2 Announce Type: replace 
Abstract: Recommending routes by their probability of having a rider has long been the goal of conventional route recommendation systems. While this maximizes the platform-specific criteria of efficiency, it results in sub-optimal outcomes with the disparity among the income of drivers who work for similar time frames. Pioneer studies on fairness in ridesharing platforms have focused on algorithms that match drivers and riders. However, these studies do not consider the time schedules of different riders sharing a ride in the ridesharing mode. To overcome this shortcoming, we present the first route recommendation system for ridesharing networks that explicitly considers fairness as an evaluation criterion. In particular, we design a routing mechanism that reduces the inequality among drivers and provides them with routes that have a similar probability of finding riders over a period of time. However, while optimizing fairness the efficiency of the platform should not be affected as both of these goals are important for the long-term sustainability of the system. In order to jointly optimize fairness and efficiency we consider repositioning drivers with low income to the areas that have a higher probability of finding riders in future. While applying driver repositioning, we design a future-aware policy and allocate the areas to the drivers considering the destination of requests in the corresponding area. Extensive simulations on real-world datasets of Washington DC and New York demonstrate superior performance by our proposed system in comparison to the existing baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15363v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3675403</arxiv:DOI>
      <arxiv:journal_reference>ACM Transactions on Intelligent Systems and Technology, Volume 15, Issue 5 Article No.: 105, Pages 1 - 30, Year 2024</arxiv:journal_reference>
      <dc:creator>Aqsa Ashraf Makhdomi, Iqra Altaf Gillani</dc:creator>
    </item>
    <item>
      <title>Group Fairness and Multi-criteria Optimization in School Assignment</title>
      <link>https://arxiv.org/abs/2403.15623</link>
      <description>arXiv:2403.15623v3 Announce Type: replace 
Abstract: We consider the problem of assigning students to schools, when students have different utilities for schools and schools have capacity. There are additional group fairness considerations over students that can be captured either by concave objectives, or additional constraints on the groups. We present approximation algorithms for this problem via convex program rounding that achieve various trade-offs between utility violation, capacity violation, and running time. We also show that our techniques easily extend to the setting where there are arbitrary covering constraints on the feasible assignment, capturing multi-criteria and ranking optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15623v3</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Santhini K. A., Kamesh Munagala, Meghana Nasre, Govind S. Sankar</dc:creator>
    </item>
    <item>
      <title>A Nearly Optimal Deterministic Algorithm for Online Transportation Problem</title>
      <link>https://arxiv.org/abs/2406.03778</link>
      <description>arXiv:2406.03778v3 Announce Type: replace 
Abstract: For the online transportation problem with $m$ server sites, it has long been known that the competitive ratio of any deterministic algorithm is at least $2m-1$. Kalyanasundaram and Pruhs conjectured in 1998 that a deterministic $(2m-1)$-competitive algorithm exists for this problem, a conjecture that has remained open for over two decades.
  In this paper, we propose a new deterministic algorithm named Subtree-Decomposition for the online transportation problem and show that it achieves a competitive ratio of at most $8m-5$. This is the first $O(m)$-competitive deterministic algorithm, coming close to the lower bound of $2m-1$ within a constant factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03778v3</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tsubasa Harada, Toshiya Itoh</dc:creator>
    </item>
    <item>
      <title>Parallel Contraction Hierarchies Can Be Efficient and Scalable</title>
      <link>https://arxiv.org/abs/2412.18008</link>
      <description>arXiv:2412.18008v3 Announce Type: replace 
Abstract: Contraction Hierarchies (CH) (Geisberger et al., 2008) is one of the most widely used algorithms for shortest-path queries on road networks. Compared to Dijkstra's algorithm, CH enables orders of magnitude faster query performance through a preprocessing phase, which iteratively categorizes vertices into hierarchies and adds shortcuts. However, constructing a CH is an expensive task. Existing solutions, including parallel ones, may suffer from long construction time. Especially, in our experiments, we observe that existing parallel solutions demonstrate unsatisfactory scalability, and have performance close to sequential algorithms.
  We present SPoCH (Scalable Parallelization of Contraction Hierarchies), an efficient and scalable CH construction algorithm in parallel. To address the challenges in previous work, our improvements focus on both redesigning the algorithm and leveraging parallel data structures. We compare SPoCH with the state-of-the-art sequential and parallel implementations on 16 graphs of various types. Our experiments show that SPoCH achieves speedups of 11 to 68 times over the best sequential baseline and 3.8 to 41 times over the best parallel baseline in CH construction, while maintaining competitive query performance and CH graph size. We have released our code and all datasets used in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18008v3</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3721145.3725744</arxiv:DOI>
      <dc:creator>Zijin Wan, Xiaojun Dong, Letong Wang, Enzuo Zhu, Yan Gu, Yihan Sun</dc:creator>
    </item>
    <item>
      <title>Multiplication of 0-1 matrices via clustering</title>
      <link>https://arxiv.org/abs/2503.19631</link>
      <description>arXiv:2503.19631v2 Announce Type: replace 
Abstract: We study applications of clustering (in particular the $k$-center
  clustering problem) in the design of efficient and practical
  deterministic algorithms for computing an approximate and the exact
  arithmetic matrix product of two 0-1 rectangular matrices $A$ and
  $B$ with clustered rows or columns, respectively. Let $\lambda_A$
  and $\lambda_B$ denote the minimum maximum radius of a cluster in an
  $\ell$-center clustering of the rows of $A$ and in a $k$-center
  clustering of the columns of $B,$ respectively. In particular,
  assuming that the matrices have size $n\times n$, we obtain the
  following results.
  A simple deterministic algorithm that approximates each entry of
  the arithmetic matrix product of $A$ and $B$ within the additive
  error of at most $2\lambda_A$ in $O(n^2\ell)$ time or at most
  $2\lambda_B$ in $O(n^2k)$ time.
  A simple deterministic preprocessing of the matrices $A$ and $B$
  in $O(n^2\ell)$ time or $O(n^2k)$ time such that a query asking
  for the exact value of an arbitrary entry of the arithmetic matrix
  product of $A$ and $B$ can be answered in $O(\lambda_A)$ time or
  $O(\lambda_B)$ time, respectively.
  A simple deterministic algorithm for the exact arithmetic matrix
  product of $A$ and $B$ running in time $O(n^2(\ell+k+\min\{\lambda_A,\lambda_B\}))$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19631v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jesper Jansson, Miroslaw Kowaluk, Andrzej Lingas, Mia Persson</dc:creator>
    </item>
    <item>
      <title>Distributed Maximum Flow in Planar Graphs</title>
      <link>https://arxiv.org/abs/2411.11718</link>
      <description>arXiv:2411.11718v2 Announce Type: replace-cross 
Abstract: The dual of a planar graph $G$ is a planar graph $G^*$ that has a vertex for each face of $G$ and an edge for each pair of adjacent faces of $G$. The profound relationship between a planar graph and its dual has been the algorithmic basis for solving numerous (centralized) classical problems on planar graphs. In the distributed setting however, the only use of planar duality is for finding a recursive decomposition of $G$ [DISC 2017, STOC 2019].
  We extend the distributed algorithmic toolkit to work on the dual graph $G^*$. These tools can then facilitate various algorithms on $G$ by solving a suitable dual problem on $G^*$.
  Given a directed planar graph $G$ with positive and negative edge-lengths and hop-diameter $D$, our key result is an $\tilde{O}(D^2)$-round algorithm for Single Source Shortest Paths on $G^*$, which then implies $\tilde{O}(D^2)$-round algorithms for Maximum $st$-Flow and Directed Global Min-Cut on $G$. Prior to our work, no $\tilde{O}(\text{poly}(D))$-round algorithm was known for those problems. We further obtain a $D\cdot n^{o(1)}$-rounds $(1-\epsilon)$-approximation algorithm for Maximum $st$-Flow on $G$ when $G$ is undirected and $st$-planar. Finally, we give a near optimal $\tilde O(D)$-round algorithm for computing the weighted girth of $G$. The main challenges in our work are that $G^*$ is not the communication graph (e.g., a vertex of $G$ is mapped to multiple vertices of $G^*$), and that the diameter of $G^*$ can be much larger than $D$ (i.e., possibly by a linear factor). We overcome these challenges by carefully defining and maintaining subgraphs of the dual graph $G^*$ while applying the recursive decomposition on the primal graph $G$. The main technical difficulty, is that along the recursive decomposition, a face of $G$ gets shattered into (disconnected) components yet we still need to treat it as a dual node.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11718v2</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yaseen Abd-Elhaleem (University of Haifa), Michal Dory (University of Haifa), Merav Parter (Weizmann Institute of Science), Oren Weimann (University of Haifa)</dc:creator>
    </item>
  </channel>
</rss>
