<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 16 Dec 2025 05:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Estimation of a Dynamic Tobit Model with a Unit Root</title>
      <link>https://arxiv.org/abs/2512.12110</link>
      <description>arXiv:2512.12110v1 Announce Type: new 
Abstract: This paper studies robust estimation in the dynamic Tobit model under local-to-unity (LUR) asymptotics. We show that both Gaussian maximum likelihood (ML) and censored least absolute deviations (CLAD) estimators are consistent, extending results from the stationary case where ordinary least squares (OLS) is inconsistent. The asymptotic distributions of MLE and CLAD are derived; for the short-run parameters they are shown to be Gaussian, yielding standard normal t-statistics. In contrast, although OLS remains consistent under LUR, its t-statistics are not standard normal. These results enable reliable model selection via sequential t-tests based on ML and CLAD, paralleling the linear autoregressive case. Applications to financial and epidemiological time series illustrate their practical relevance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12110v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Bykhovskaya, James A. Duffy</dc:creator>
    </item>
    <item>
      <title>Modeling the Happiness-Sustainability Nexus via Graphical Lasso and Quantile-on-Quantile Regression</title>
      <link>https://arxiv.org/abs/2512.12352</link>
      <description>arXiv:2512.12352v1 Announce Type: new 
Abstract: This paper investigates the nexus between subjective well-being and sustainability, proxied by the Sustainable Development Goals (SDG) Index, using cross-country data from 126 nations in 2022. While prior research has highlighted a positive association between happiness and sustainable development, existing approaches largely rely on linear regressions or correlation-based measures that mask distributional heterogeneity, multicollinearity, and potential nonlinear dependence. To address these limitations, we employ a two methodological framework combining Graphical Lasso, and Quantile-on-Quantile Regression (QQR). The Graphical Lasso identifies a direct conditional link between happiness and sustainability after controlling for governance, income, and life expectancy, with a partial correlation of about 0.21. On the other hand, QQR reveals heterogeneous effects across the joint distribution: sustainability gains are positively associated with happiness for low-happiness but high-sustainability countries, negatively associated in high-happiness but low-sustainability contexts, and essentially neutral elsewhere. These findings suggest that the happiness-sustainability link is modest, asymmetric, and context-dependent, underscoring the importance of moving beyond mean-based regressions. From a policy perspective, our results highlight that institutional quality, income, and demographic factors remain the dominant drivers of both happiness and sustainability, while the interplay between the two dimensions is most pronounced in distributional extremes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12352v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamed Chaouch, Thanasis Stengos</dc:creator>
    </item>
    <item>
      <title>Explainable Prediction of Economic Time Series Using IMFs and Neural Networks</title>
      <link>https://arxiv.org/abs/2512.12499</link>
      <description>arXiv:2512.12499v1 Announce Type: new 
Abstract: This study investigates the contribution of Intrinsic Mode Functions (IMFs) derived from economic time series to the predictive performance of neural network models, specifically Multilayer Perceptrons (MLP) and Long Short-Term Memory (LSTM) networks. To enhance interpretability, DeepSHAP is applied, which estimates the marginal contribution of each IMF while keeping the rest of the series intact. Results show that the last IMFs, representing long-term trends, are generally the most influential according to DeepSHAP, whereas high-frequency IMFs contribute less and may even introduce noise, as evidenced by improved metrics upon their removal. Differences between MLP and LSTM highlight the effect of model architecture on feature relevance distribution, with LSTM allocating importance more evenly across IMFs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12499v1</guid>
      <category>econ.EM</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pablo Hidalgo, Julio E. Sandubete, Agust\'in Garc\'ia-Garc\'ia</dc:creator>
    </item>
    <item>
      <title>Continuous Treatment Effects with Spatial and Network Spillovers</title>
      <link>https://arxiv.org/abs/2512.12653</link>
      <description>arXiv:2512.12653v1 Announce Type: new 
Abstract: This paper develops a continuous functional framework for treatment effects that propagate through geographic space and economic networks. We derive a master equation governing propagation from three economic foundations -- heterogeneous agent aggregation, market equilibrium, and cost minimization -- establishing that the framework rests on fundamental principles rather than ad hoc specifications. A key result shows that the spatial-network interaction coefficient equals the mutual information between geographic and market coordinates. The Feynman-Kac representation decomposes effects into inherited and accumulated components along stochastic paths representing economic linkages. The framework nests the no-spillover case as a testable restriction. Monte Carlo simulations demonstrate that conventional estimators -- two-way fixed effects, difference-in-differences, and generalized propensity score -- exhibit 25-38% bias and severe undercoverage when spillovers exist, while our estimator maintains correct inference regardless of whether spillovers are present. Applying the framework to U.S. minimum wage policy, we reject the no-spillover null and find total effects at state borders four times larger than direct effects -- conventional methods capture only one-quarter of policy impact. Structural estimates reveal spatial diffusion consistent with commuting-distance labor mobility, network diffusion consistent with quarterly supply chain adjustment, and significant spatial-network interaction reflecting geographic clustering of industries. Entropy-based fragility diagnostics outperform standard centrality measures by 56-76% in predicting labor market disruptions, identifying all high-risk state-industry pairs during 2020-2021 with six-month advance warning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12653v1</guid>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <category>stat.ME</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatsuru Kikuchi</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Treatment Effect</title>
      <link>https://arxiv.org/abs/2512.12781</link>
      <description>arXiv:2512.12781v1 Announce Type: new 
Abstract: Using only retrospective data, we propose an estimator for predicting the treatment effect for the same treatment/policy to be implemented in another location or time period, which requires no input from the target population. More specifically, we minimize the worst-case mean square error for the prediction of treatment effect within a class of distributions inside the Wasserstein ball centered on the source distribution. Since the joint distribution of potential outcomes is not identified, we pick the best and worst copulas of the marginal distributions of two potential outcomes as our optimistic and pessimistic optimization objects for partial identification. As a result, we can attain the upper and lower bounds of the minimax optimizer. The minimax solution differs depending on whether treatment effects are homogeneous or heterogeneous. We derive the consistency and asymptotic distribution of the bound estimators, provide a two-step inference procedure, and discuss the choice of the Wasserstein ball radius.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12781v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ruonan Xu, Xiye Yang</dc:creator>
    </item>
    <item>
      <title>Raking for estimation and inference in panel models with nonignorable attrition and refreshment</title>
      <link>https://arxiv.org/abs/2512.13270</link>
      <description>arXiv:2512.13270v1 Announce Type: new 
Abstract: In panel data subject to nonignorable attrition, auxiliary (refreshment) sampling may restore full identification under weak assumptions on the attrition process. Despite their generality, these identification strategies have seen limited empirical use, largely because the implied estimation procedure requires solving a functional minimization problem for the target density. We show that this problem can be solved using the iterative proportional fitting (raking) algorithm, which converges rapidly even with continuous and moderately high-dimensional data. This resulting density estimator is then used as input into a parametric moment condition. We establish consistency and convergence rates for both the raking-based density estimator and the resulting moment estimator when the distributions of the observed data are parametric. We also derive a simple recursive procedure for estimating the asymptotic variance. Finally, we demonstrate the satisfactory performance of our estimator in simulations and provide an empirical illustration using data from the Understanding America Study panel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13270v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Grigory Franguridi, Jinyong Hahn, Pierre Hoonhout, Arie Kapteyn, Geert Ridder</dc:creator>
    </item>
    <item>
      <title>Policy-Aligned Estimation of Conditional Average Treatment Effects</title>
      <link>https://arxiv.org/abs/2512.13400</link>
      <description>arXiv:2512.13400v1 Announce Type: new 
Abstract: Firms often develop targeting policies to personalize marketing actions and improve incremental profits. Effective targeting depends on accurately separating customers with positive versus negative treatment effects. We propose an approach to estimate the conditional average treatment effects (CATEs) of marketing actions that aligns their estimation with the firm's profit objective. The method recognizes that, for many customers, treatment effects are so extreme that additional accuracy is unlikely to change the recommended actions. However, accuracy matters near the decision boundary, as small errors can alter targeting decisions. By modifying the firm's objective function in the standard profit maximization problem, our method yields a near-optimal targeting policy while simultaneously estimating CATEs. This introduces a new perspective on CATE estimation, reframing it as a problem of profit optimization rather than prediction accuracy. We establish the theoretical properties of the proposed method and demonstrate its performance and trade-offs using synthetic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13400v1</guid>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Artem Timoshenko, Caio Waisman</dc:creator>
    </item>
    <item>
      <title>From Many Models, One: Macroeconomic Forecasting with Reservoir Ensembles</title>
      <link>https://arxiv.org/abs/2512.13642</link>
      <description>arXiv:2512.13642v1 Announce Type: new 
Abstract: Model combination is a powerful approach to achieve superior performance with a set of models than by just selecting any single one. We study both theoretically and empirically the effectiveness of ensembles of Multi-Frequency Echo State Networks (MFESNs), which have been shown to achieve state-of-the-art macroeconomic time series forecasting results (Ballarin et al., 2024a). Hedge and Follow-the-Leader schemes are discussed, and their online learning guarantees are extended to the case of dependent data. In applications, our proposed Ensemble Echo State Networks show significantly improved predictive performance compared to individual MFESN models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13642v1</guid>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giovanni Ballarin, Lyudmila Grigoryeva, Yui Ching Li</dc:creator>
    </item>
    <item>
      <title>Linear Regression in a Nonlinear World</title>
      <link>https://arxiv.org/abs/2512.13645</link>
      <description>arXiv:2512.13645v1 Announce Type: new 
Abstract: The interpretation of coefficients from multivariate linear regression relies on the assumption that the conditional expectation function is linear in the variables. However, in many cases the underlying data generating process is nonlinear. This paper examines how to interpret regression coefficients under nonlinearity. We show that if the relationships between the variable of interest and other covariates are linear, then the coefficient on the variable of interest represents a weighted average of the derivatives of the outcome conditional expectation function with respect to the variable of interest. If these relationships are nonlinear, the regression coefficient becomes biased relative to this weighted average. We show that this bias is interpretable, analogous to the biases from measurement error and omitted variable bias under the standard linear model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13645v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadav Kunievsky</dc:creator>
    </item>
    <item>
      <title>Information Based Inference in Models with Set-Valued Predictions and Misspecification</title>
      <link>https://arxiv.org/abs/2401.11046</link>
      <description>arXiv:2401.11046v2 Announce Type: replace 
Abstract: This paper proposes an information-based inference method for partially identified parameters in incomplete models that is valid both when the model is correctly specified and when it is misspecified. Key features of the method are: (i) it is based on minimizing a suitably defined Kullback-Leibler information criterion that accounts for incompleteness of the model and delivers a non-empty pseudo-true set; (ii) it is computationally tractable; (iii) its implementation is the same for both correctly and incorrectly specified models; (iv) it exploits all information provided by variation in discrete and continuous covariates; (v) it relies on Rao's score statistic, which is shown to be asymptotically pivotal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11046v2</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroaki Kaido, Francesca Molinari</dc:creator>
    </item>
    <item>
      <title>Testing identifying assumptions in Tobit Models</title>
      <link>https://arxiv.org/abs/2408.02573</link>
      <description>arXiv:2408.02573v3 Announce Type: replace 
Abstract: We develop sharp, testable implications for the identifying assumptions of Tobit and IV-Tobit models: linear index, (joint) normality of errors, treatment (instrument) exogeneity, and relevance. The new sharp testable equalities can detect all possible observable violations of the identifying conditions. The proposed test procedure for the model's validity uses existing inference methods for intersection bounds. Simulations suggest adequate test size and power in detecting exogeneity and error structure violations. We review and propose alternatives to partially identify the parameters of interest under less restrictive assumptions. We revisit a study of married women's labor supply in Lee (1995) to demonstrate the test's practical implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02573v3</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Santiago Acerenza, Ot\'avio Bartalotti, Federico Veneri</dc:creator>
    </item>
    <item>
      <title>Testing Shape Restrictions with Continuous Treatment: A Transformation Model Approach</title>
      <link>https://arxiv.org/abs/2506.08914</link>
      <description>arXiv:2506.08914v2 Announce Type: replace 
Abstract: We propose tests for the convexity/linearity/concavity of a transformation of the dependent variable in a semiparametric transformation model. These tests can be used to verify monotonicity of the treatment effect, or, equivalently, concavity/convexity of the outcome with respect to the treatment, in (quasi-)experimental settings. Our procedure does not require estimation of the transformation or the distribution of the error terms. The statistic takes the form of a U statistic or a localised U statistic, and we show that critical values can be obtained by bootstrapping. In our application we test the convexity of loan demand with respect to the interest rate using experimental data from South Africa.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08914v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Arkadiusz Szyd{\l}owski</dc:creator>
    </item>
    <item>
      <title>Uniform Quasi ML based inference for the panel AR(1) model</title>
      <link>https://arxiv.org/abs/2508.20855</link>
      <description>arXiv:2508.20855v4 Announce Type: replace 
Abstract: Maximum Likelihood (ML) offers attractive alternatives to Generalized Method of Moments (GMM) estimators for dynamic panel data models. However, to date no identification-robust inference methods exist that can be used in conjunction with the ML estimators for these models. In this paper we propose ML based inference methods for panel AR(1) models with arbitrary initial conditions and heteroskedasticity that are robust to the strength of identification. We show that (Quasi) Lagrange Multiplier (LM) tests and confidence sets (CSs) that use the expected Hessian rather than the observed Hessian of the log-likelihood function have correct asymptotic size and coverage probability in a uniform sense, respectively. Such Quasi LM tests and CSs are also robust to misspecification of the distribution of the data and to heterogeneity, including heteroskedasticity. We derive the power envelope of a Fixed Effects version of such an LM test for hypotheses involving the autoregressive parameter when the average information matrix is estimated by a centered OPG estimator and the model is only second-order identified, and show that it coincides with the maximal attainable power curve in the worst-case setting. We also study the empirical size and power properties of these (Quasi) LM tests and find that the hypothesis that the (Quasi) LM test has correct size cannot be rejected.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20855v4</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo Kruiniger</dc:creator>
    </item>
    <item>
      <title>Nonparametric Uniform Inference in Binary Classification and Policy Values</title>
      <link>https://arxiv.org/abs/2511.14700</link>
      <description>arXiv:2511.14700v2 Announce Type: replace 
Abstract: We develop methods for nonparametric uniform inference in cost-sensitive binary classification, a framework that encompasses maximum score estimation, predicting utility maximizing actions, and policy learning. These problems are well known for slow convergence rates and non-standard limiting behavior, even under point identified parametric frameworks. In nonparametric settings, they may further suffer from failures of identification. To address these challenges, we introduce a strictly convex surrogate loss that point-identifies a representative nonparametric policy function. We then estimate this representative policy function to conduct inference on both the optimal classification policy and the optimal policy value. This approach enables Gaussian inference, substantially simplifying empirical implementation relative to working directly with the original classification problem. In particular, we establish root-$n$ asymptotic normality for the optimal policy value and derive a Gaussian approximation for the optimal classification policy at the standard nonparametric rate. Extensive simulation studies corroborate the theoretical findings. We apply our method to the National JTPA Study to conduct inference on the optimal treatment assignment policy and its associated welfare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14700v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Nan Liu, Yanbo Liu, Yuya Sasaki, Yuanyuan Wan</dc:creator>
    </item>
    <item>
      <title>Market Sensitivities and Growth Differentials Across Australian Housing Markets</title>
      <link>https://arxiv.org/abs/2512.01139</link>
      <description>arXiv:2512.01139v3 Announce Type: replace 
Abstract: Australian house prices have risen strongly since the mid-1990s, but growth has been highly uneven across regions. Raw growth figures obscure whether these differences reflect persistent structural trends or cyclical fluctuations. We address this by estimating a three-factor model in levels for regional repeat-sales log price indexes over 1995-2024. The model decomposes each regional index into a national Market factor, two stationary spreads (Mining and Lifestyle) that capture mean-reverting geographic cycles, and a city-specific residual. The Mining spread, proxied by a Perth-Sydney index differential, reflects resource-driven oscillations in relative performance; the Lifestyle spread captures amenity-driven coastal and regional cycles. The Market loading isolates each region's fundamental sensitivity, beta, to national growth, so that a city's growth under an assumed national change is calculated from its beta once mean-reverting spreads are netted out. Comparing realised paths to these factor-implied trajectories indicates when a city is historically elevated or depressed, and attributes the gap to Mining or Lifestyle spreads.
  Expanding-window ARIMAX estimation reveals that Market betas are stable across major shocks (the mining boom, the Global Financial Crisis, and COVID-19), while Mining and Lifestyle behave as stationary spreads that widen forecast funnels without overturning the cross-sectional ranking implied by beta. Melbourne amplifies national growth, Sydney tracks the national trend closely, and regional areas dampen it. The framework thus provides a simple, factor-based tool for interpreting regional growth differentials and their persistence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01139v3</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Willem P Sijp</dc:creator>
    </item>
    <item>
      <title>Switchback Experiments under Geometric Mixing</title>
      <link>https://arxiv.org/abs/2209.00197</link>
      <description>arXiv:2209.00197v4 Announce Type: replace-cross 
Abstract: The switchback is an experimental design that measures treatment effects by repeatedly turning an intervention on and off for a whole system. Switchback experiments are a robust way to overcome cross-unit spillover effects; however, they are vulnerable to bias from temporal carryovers. In this paper, we consider properties of switchback experiments in Markovian systems that mix at a geometric rate. We find that, in this setting, standard switchback designs suffer considerably from carryover bias: Their estimation error decays as $T^{-1/3}$ in terms of the experiment horizon $T$, whereas in the absence of carryovers a faster rate of $T^{-1/2}$ would have been possible. We also show, however, that judicious use of burn-in periods can considerably improve the situation, and enables errors that decay as $\log(T)^{1/2}T^{-1/2}$. Our formal results are mirrored in an empirical evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.00197v4</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Hu, Stefan Wager</dc:creator>
    </item>
    <item>
      <title>Polynomial Log-Marginals and Tweedie's Formula : When Is Bayes Possible?</title>
      <link>https://arxiv.org/abs/2509.05823</link>
      <description>arXiv:2509.05823v2 Announce Type: replace-cross 
Abstract: Motivated by Tweedie's formula for the Compound Decision problem, we examine the theoretical foundations of empirical Bayes estimators that directly model the marginal density $m(y)$. Our main result shows that polynomial log-marginals of degree $k \ge 3 $ cannot arise from any valid prior distribution in exponential family models, while quadratic forms correspond exactly to Gaussian priors. This provides theoretical justification for why certain empirical Bayes decision rules, while practically useful, do not correspond to any formal Bayes procedures. We also strengthen the diagnostic by showing that a marginal is a Gaussian convolution only if it extends to a bounded solution of the heat equation in a neighborhood of the smoothing parameter, beyond the convexity of $c(y)=\tfrac12 y^2+\log m(y)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05823v2</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jyotishka Datta, Nicholas G. Polson</dc:creator>
    </item>
    <item>
      <title>Learning Time-Varying Correlation Networks with FDR Control via Time-Varying P-values</title>
      <link>https://arxiv.org/abs/2512.10467</link>
      <description>arXiv:2512.10467v2 Announce Type: replace-cross 
Abstract: This paper presents a systematic framework for controlling false discovery rate in learning time-varying correlation networks from high-dimensional, non-linear, non-Gaussian and non-stationary time series with an increasing number of potential abrupt change points in means. We propose a bootstrap-assisted approach to derive dependent and time-varying P-values from a robust estimate of time-varying correlation functions, which are not sensitive to change points. Our procedure is based on a new high-dimensional Gaussian approximation result for the uniform approximation of P-values across time and different coordinates. Moreover, we establish theoretically guaranteed Benjamini--Hochberg and Benjamini--Yekutieli procedures for the dependent and time-varying P-values, which can achieve uniform false discovery rate control. The proposed methods are supported by rigorous mathematical proofs and simulation studies. We also illustrate the real-world application of our framework using both brain electroencephalogram and financial time series data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10467v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bufan Li, Lujia Bai, Weichi Wu</dc:creator>
    </item>
  </channel>
</rss>
