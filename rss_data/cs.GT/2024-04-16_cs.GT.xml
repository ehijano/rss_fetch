<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Apr 2024 04:00:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>HSVI-based Online Minimax Strategies for Partially Observable Stochastic Games with Neural Perception Mechanisms</title>
      <link>https://arxiv.org/abs/2404.10679</link>
      <description>arXiv:2404.10679v1 Announce Type: new 
Abstract: We consider a variant of continuous-state partially-observable stochastic games with neural perception mechanisms and an asymmetric information structure. One agent has partial information, with the observation function implemented as a neural network, while the other agent is assumed to have full knowledge of the state. We present, for the first time, an efficient online method to compute an $\varepsilon$-minimax strategy profile, which requires only one linear program to be solved for each agent at every stage, instead of a complex estimation of opponent counterfactual values. For the partially-informed agent, we propose a continual resolving approach which uses lower bounds, pre-computed offline with heuristic search value iteration (HSVI), instead of opponent counterfactual values. This inherits the soundness of continual resolving at the cost of pre-computing the bound. For the fully-informed agent, we propose an inferred-belief strategy, where the agent maintains an inferred belief about the belief of the partially-informed agent based on (offline) upper bounds from HSVI, guaranteeing $\varepsilon$-distance to the value of the game at the initial belief known to both agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10679v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Yan, Gabriel Santos, Gethin Norman, David Parker, Marta Kwiatkowska</dc:creator>
    </item>
    <item>
      <title>Privacy Can Arise Endogenously in an Economic System with Learning Agents</title>
      <link>https://arxiv.org/abs/2404.10767</link>
      <description>arXiv:2404.10767v1 Announce Type: new 
Abstract: We study price-discrimination games between buyers and a seller where privacy arises endogenously--that is, utility maximization yields equilibrium strategies where privacy occurs naturally. In this game, buyers with a high valuation for a good have an incentive to keep their valuation private, lest the seller charge them a higher price. This yields an equilibrium where some buyers will send a signal that misrepresents their type with some probability; we refer to this as buyer-induced privacy. When the seller is able to publicly commit to providing a certain privacy level, we find that their equilibrium response is to commit to ignore buyers' signals with some positive probability; we refer to this as seller-induced privacy. We then turn our attention to a repeated interaction setting where the game parameters are unknown and the seller cannot credibly commit to a level of seller-induced privacy. In this setting, players must learn strategies based on information revealed in past rounds. We find that, even without commitment ability, seller-induced privacy arises as a result of reputation building. We characterize the resulting seller-induced privacy and seller's utility under no-regret and no-policy-regret learning algorithms and verify these results through simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10767v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nivasini Ananthakrishnan, Tiffany Ding, Mariel Werner, Sai Praneeth Karimireddy, Michael I. Jordan</dc:creator>
    </item>
    <item>
      <title>Social Choice for AI Alignment: Dealing with Diverse Human Feedback</title>
      <link>https://arxiv.org/abs/2404.10271</link>
      <description>arXiv:2404.10271v1 Announce Type: cross 
Abstract: Foundation models such as GPT-4 are fine-tuned to avoid unsafe or otherwise problematic behavior, so that, for example, they refuse to comply with requests for help with committing crimes or with producing racist text. One approach to fine-tuning, called reinforcement learning from human feedback, learns from humans' expressed preferences over multiple outputs. Another approach is constitutional AI, in which the input from humans is a list of high-level principles. But how do we deal with potentially diverging input from humans? How can we aggregate the input into consistent data about ''collective'' preferences or otherwise use it to make collective choices about model behavior? In this paper, we argue that the field of social choice is well positioned to address these questions, and we discuss ways forward for this agenda, drawing on discussions in a recent workshop on Social Choice for AI Ethics and Safety held in Berkeley, CA, USA in December 2023.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10271v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Conitzer, Rachel Freedman, Jobst Heitzig, Wesley H. Holliday, Bob M. Jacobs, Nathan Lambert, Milan Moss\'e, Eric Pacuit, Stuart Russell, Hailey Schoelkopf, Emanuel Tewolde, William S. Zwicker</dc:creator>
    </item>
    <item>
      <title>Principal-Agent Hypothesis Testing</title>
      <link>https://arxiv.org/abs/2205.06812</link>
      <description>arXiv:2205.06812v3 Announce Type: replace 
Abstract: Consider the relationship between a regulator (the principal) and an experimenter (the agent) such as a pharmaceutical company. The pharmaceutical company wishes to sell a drug for profit, whereas the regulator wishes to allow only efficacious drugs to be marketed. The efficacy of the drug is not known to the regulator, so the pharmaceutical company must run a costly trial to prove efficacy to the regulator. Critically, the statistical protocol used to establish efficacy affects the behavior of a strategic, self-interested agent; a lower standard of statistical evidence incentivizes the agent to run more trials that are less likely to be effective. The interaction between the statistical protocol and the incentives of the pharmaceutical company is crucial for understanding this system and designing protocols with high social utility. In this work, we discuss how the regulator can set up a protocol with payoffs based on statistical evidence. We show how to design protocols that are robust to an agent's strategic actions, and derive the optimal protocol in the presence of strategic entrants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.06812v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stephen Bates, Michael I. Jordan, Michael Sklar, Jake A. Soloff</dc:creator>
    </item>
    <item>
      <title>Optimal Parametrization of the Gale-Shapley Preallocation Method for Combinatorial Auction-based Channel Assignment</title>
      <link>https://arxiv.org/abs/2209.00331</link>
      <description>arXiv:2209.00331v2 Announce Type: replace 
Abstract: Algorithms based on combinatorial auctions show significant potential regarding their application for channel assignment problems in multi-connectivity ultra-reliable wireless networks. However the computational effort required by such algorithms grows fast with the number of users and resources. Therefore, preallocation-based combinatorial auction represents a promising approach for these setups. The aim of the preallocation is to constrain the number of bids submitted by participants in the combinatorial auction process, thus reducing computational demands and enabling numerical feasibility of the auction problem. Reduction of bid number is achieved via limiting the number of items (channels) considered by auction participants (tenants) in their bids. Thus the aim of preallocation is to non-exclusively assign channels to tenants. This assignment serves as a basis for the later bid generation in the auction procedure. In this paper we analyze the optimal parametrization of the many-to-many Gale-Shapley preallocation method and formulate recommendations for optimal performance. Numerical assessments illustrate that the appropriate preallocation has significant impact on the performance and computational demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.00331v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>D\'avid Csercsik, Eduard Jorswieck</dc:creator>
    </item>
    <item>
      <title>Bilateral Trade with Correlated Values</title>
      <link>https://arxiv.org/abs/2308.09964</link>
      <description>arXiv:2308.09964v2 Announce Type: replace 
Abstract: We study the bilateral trade problem where a seller owns a single indivisible item, and a potential buyer seeks to purchase it. Previous mechanisms for this problem only considered the case where the values of the buyer and the seller are drawn from independent distributions. In this paper, we study bilateral trade mechanisms when the values are drawn from a joint distribution.
  We prove that the buyer-offering mechanism guarantees an approximation ratio of $\frac e {e-1} \approx 1.582$ to the social welfare even if the values are drawn from a joint distribution. The buyer-offering mechanism is Bayesian incentive compatible, but the seller has a dominant strategy. We prove the buyer-offering mechanism is optimal in the sense that no Bayesian mechanism where one of the players has a dominant strategy can obtain an approximation ratio better than $\frac e {e-1}$. We also show that no mechanism in which both sides have a dominant strategy can provide any constant approximation to the social welfare when the values are drawn from a joint distribution.
  Finally, we prove some impossibility results on the power of general Bayesian incentive compatible mechanisms. In particular, we show that no deterministic Bayesian incentive-compatible mechanism can provide an approximation ratio better than $1+\frac {\ln 2} 2\approx 1.346$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.09964v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shahar Dobzinski, Ariel Shaulker</dc:creator>
    </item>
    <item>
      <title>The Critical Node Game</title>
      <link>https://arxiv.org/abs/2303.05961</link>
      <description>arXiv:2303.05961v2 Announce Type: replace-cross 
Abstract: In this work, we introduce a game-theoretic model that assesses the cyber-security risk of cloud networks and informs security experts on the optimal security strategies. Our approach combines game theory, combinatorial optimization, and cyber-security and aims to minimize the unexpected network disruptions caused by malicious cyber-attacks under uncertainty. Methodologically, we introduce the critical node game, a simultaneous and non-cooperative attacker-defender game where each player solves a combinatorial optimization problem parametrized in the variables of the other player. Each player simultaneously commits to a defensive (or attacking) strategy with limited knowledge about the choices of their adversary. We provide a realistic model for the critical node game and propose an algorithm to compute its stable solutions, i.e., its Nash equilibria. Practically, our approach enables security experts to assess the security posture of the cloud network and dynamically adapt the level of cyber-protection deployed on the network. We provide a detailed analysis of a real-world cloud network and demonstrate the efficacy of our approach through extensive computational tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.05961v2</guid>
      <category>math.OC</category>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>Journal of Combinatorial Optimization, 2024</arxiv:journal_reference>
      <dc:creator>Gabriele Dragotto, Amine Boukhtouta, Andrea Lodi, Mehdi Taobane</dc:creator>
    </item>
    <item>
      <title>Learning to Manipulate under Limited Information</title>
      <link>https://arxiv.org/abs/2401.16412</link>
      <description>arXiv:2401.16412v2 Announce Type: replace-cross 
Abstract: By classic results in social choice theory, any reasonable preferential voting method sometimes gives individuals an incentive to report an insincere preference. The extent to which different voting methods are more or less resistant to such strategic manipulation has become a key consideration for comparing voting methods. Here we measure resistance to manipulation by whether neural networks of varying sizes can learn to profitably manipulate a given voting method in expectation, given different types of limited information about how other voters will vote. We trained over 70,000 neural networks of 26 sizes to manipulate against 8 different voting methods, under 6 types of limited information, in committee-sized elections with 5-21 voters and 3-6 candidates. We find that some voting methods, such as Borda, are highly manipulable by networks with limited information, while others, such as Instant Runoff, are not, despite being quite profitably manipulated by an ideal manipulator with full information. For the two probability models for elections that we use, the overall least manipulable of the 8 methods we study are Condorcet methods, namely Minimax and Split Cycle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16412v2</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday, Alexander Kristoffersen, Eric Pacuit</dc:creator>
    </item>
  </channel>
</rss>
