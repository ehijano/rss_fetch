<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PF</link>
    <description>cs.PF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 Aug 2024 04:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>TINA: Acceleration of Non-NN Signal Processing Algorithms Using NN Accelerators</title>
      <link>https://arxiv.org/abs/2408.16551</link>
      <description>arXiv:2408.16551v1 Announce Type: new 
Abstract: This paper introduces TINA, a novel framework for implementing non Neural Network (NN) signal processing algorithms on NN accelerators such as GPUs, TPUs or FPGAs. The key to this approach is the concept of mapping mathematical and logic functions as a series of convolutional and fully connected layers. By mapping functions into such a small substack of NN layers, it becomes possible to execute non-NN algorithms on NN hardware (HW) accelerators efficiently, as well as to ensure the portability of TINA implementations to any platform that supports such NN accelerators. Results show that TINA is highly competitive compared to alternative frameworks, specifically for complex functions with iterations. For a Polyphase Filter Bank use case TINA shows GPU speedups of up to 80x vs a CPU baseline with NumPy compared to 8x speedup achieved by alternative frameworks. The framework is open source and publicly available at https://github.com/ChristiaanBoe/TINA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16551v1</guid>
      <category>cs.PF</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christiaan Boerkamp, Steven van der Vlugt, Zaid Al-Ars</dc:creator>
    </item>
    <item>
      <title>ppOpen-AT: A Directive-base Auto-tuning Language</title>
      <link>https://arxiv.org/abs/2408.16607</link>
      <description>arXiv:2408.16607v1 Announce Type: new 
Abstract: ppOpen-AT is a domain-specific language designed to ease the workload for developers creating libraries with auto-tuning (AT) capabilities. It consists of a set of directives that allow for the automatic generation of code necessary for AT by placing annotations in the source program. This approach significantly reduces the effort required by numerical library developers. This technical report details the implementation of the AT software and its extended functions, and provides an explanation of the internal specifications of ppOpen-AT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16607v1</guid>
      <category>cs.PF</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takahiro Katagiri</dc:creator>
    </item>
    <item>
      <title>Efficient $k$-NN Search in IoT Data: Overlap Optimization in Tree-Based Indexing Structures</title>
      <link>https://arxiv.org/abs/2408.16036</link>
      <description>arXiv:2408.16036v1 Announce Type: cross 
Abstract: The proliferation of interconnected devices in the Internet of Things (IoT) has led to an exponential increase in data, commonly known as Big IoT Data. Efficient retrieval of this heterogeneous data demands a robust indexing mechanism for effective organization. However, a significant challenge remains: the overlap in data space partitions during index construction. This overlap increases node access during search and retrieval, resulting in higher resource consumption, performance bottlenecks, and impedes system scalability. To address this issue, we propose three innovative heuristics designed to quantify and strategically reduce data space partition overlap. The volume-based method (VBM) offers a detailed assessment by calculating the intersection volume between partitions, providing deeper insights into spatial relationships. The distance-based method (DBM) enhances efficiency by using the distance between partition centers and radii to evaluate overlap, offering a streamlined yet accurate approach. Finally, the object-based method (OBM) provides a practical solution by counting objects across multiple partitions, delivering an intuitive understanding of data space dynamics. Experimental results demonstrate the effectiveness of these methods in reducing search time, underscoring their potential to improve data space partitioning and enhance overall system performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16036v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <category>cs.PF</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ala-Eddine Benrazek, Zineddine Kouahla, Brahim Farou, Hamid Seridi, Ibtissem Kemouguette</dc:creator>
    </item>
    <item>
      <title>Adversarial Network Optimization under Bandit Feedback: Maximizing Utility in Non-Stationary Multi-Hop Networks</title>
      <link>https://arxiv.org/abs/2408.16215</link>
      <description>arXiv:2408.16215v1 Announce Type: cross 
Abstract: Stochastic Network Optimization (SNO) concerns scheduling in stochastic queueing systems. It has been widely studied in network theory. Classical SNO algorithms require network conditions to be stationary with time, which fails to capture the non-stationary components in many real-world scenarios. Many existing algorithms also assume knowledge of network conditions before decision, which rules out applications where unpredictability presents.
  Motivated by these issues, we consider Adversarial Network Optimization (ANO) under bandit feedback. Specifically, we consider the task of *i)* maximizing some unknown and time-varying utility function associated to scheduler's actions, where *ii)* the underlying network is a non-stationary multi-hop one whose conditions change arbitrarily with time, and *iii)* only bandit feedback (effect of actually deployed actions) is revealed after decisions. Our proposed `UMO2` algorithm ensures network stability and also matches the utility maximization performance of any "mildly varying" reference policy up to a polynomially decaying gap. To our knowledge, no previous ANO algorithm handled multi-hop networks or achieved utility guarantees under bandit feedback, whereas ours can do both.
  Technically, our method builds upon a novel integration of online learning into Lyapunov analyses: To handle complex inter-dependencies among queues in multi-hop networks, we propose meticulous techniques to balance online learning and Lyapunov arguments. To tackle the learning obstacles due to potentially unbounded queue sizes, we design a new online linear optimization algorithm that automatically adapts to loss magnitudes. To maximize utility, we propose a bandit convex optimization algorithm with novel queue-dependent learning rate scheduling that suites drastically varying queue lengths. Our new insights in online learning can be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16215v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.PF</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Dai, Longbo Huang</dc:creator>
    </item>
  </channel>
</rss>
