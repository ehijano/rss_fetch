<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Aug 2025 04:01:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Numerical Uncertainty in Linear Registration: An Experimental Study</title>
      <link>https://arxiv.org/abs/2508.00781</link>
      <description>arXiv:2508.00781v1 Announce Type: new 
Abstract: While linear registration is a critical step in MRI preprocessing pipelines, its numerical uncertainty is understudied. Using Monte-Carlo Arithmetic (MCA) simulations, we assessed the most commonly used linear registration tools within major software packages (SPM, FSL, and ANTs) across multiple image similarity measures, two brain templates, and both healthy control (HC, n=50) and Parkinson's Disease (PD, n=50) cohorts. Our findings highlight the influence of linear registration tools and similarity measures on numerical stability. Among the evaluated tools and with default similarity measures, SPM exhibited the highest stability. FSL and ANTs showed greater and similar ranges of variability, with ANTs demonstrating particular sensitivity to numerical perturbations that occasionally led to registration failure. Furthermore, no significant differences were observed between healthy and PD cohorts, suggesting that numerical stability analyses obtained with healthy subjects may generalise to clinical populations. Finally, we also demonstrated how numerical uncertainty measures may support automated quality control (QC) of linear registration results. Overall, our experimental results characterize the numerical stability of linear registration experimentally and can serve as a basis for future uncertainty analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00781v1</guid>
      <category>q-bio.QM</category>
      <category>eess.IV</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niusha Mirhakimi, Yohan Chatelain, Jean-Baptiste Poline, Tristan Glatard</dc:creator>
    </item>
    <item>
      <title>On the Utility of Virtual Staining for Downstream Applications as it relates to Task Network Capacity</title>
      <link>https://arxiv.org/abs/2508.00164</link>
      <description>arXiv:2508.00164v1 Announce Type: cross 
Abstract: Virtual staining, or in-silico-labeling, has been proposed to computationally generate synthetic fluorescence images from label-free images by use of deep learning-based image-to-image translation networks. In most reported studies, virtually stained images have been assessed only using traditional image quality measures such as structural similarity or signal-to-noise ratio. However, in biomedical imaging, images are typically acquired to facilitate an image-based inference, which we refer to as a downstream biological or clinical task. This study systematically investigates the utility of virtual staining for facilitating clinically relevant downstream tasks (like segmentation or classification) with consideration of the capacity of the deep neural networks employed to perform the tasks. Comprehensive empirical evaluations were conducted using biological datasets, assessing task performance by use of label-free, virtually stained, and ground truth fluorescence images. The results demonstrated that the utility of virtual staining is largely dependent on the ability of the segmentation or classification task network to extract meaningful task-relevant information, which is related to the concept of network capacity. Examples are provided in which virtual staining does not improve, or even degrades, segmentation or classification performance when the capacity of the associated task network is sufficiently large. The results demonstrate that task network capacity should be considered when deciding whether to perform virtual staining.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00164v1</guid>
      <category>eess.IV</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sourya Sengupta, Jianquan Xu, Phuong Nguyen, Frank J. Brooks, Yang Liu, Mark A. Anastasio</dc:creator>
    </item>
    <item>
      <title>Comorbid anxiety predicts lower odds of MDD improvement in a trial of smartphone-delivered interventions</title>
      <link>https://arxiv.org/abs/2409.11183</link>
      <description>arXiv:2409.11183v3 Announce Type: replace 
Abstract: Comorbid anxiety disorders are common among patients with major depressive disorder (MDD), but their impact on outcomes of digital and smartphone-delivered interventions is not well understood. This study is a secondary analysis of a randomized controlled effectiveness trial (n=638) that assessed three smartphone-delivered interventions: Project EVO (a cognitive training app), iPST (a problem-solving therapy app), and Health Tips (an active control). We applied classical machine learning models (logistic regression, support vector machines, decision trees, random forests, and k-nearest-neighbors) to identify baseline predictors of MDD improvement at 4 weeks after trial enrollment. Our analysis produced a decision tree model indicating that a baseline GAD-7 questionnaire score of 11 or higher, a threshold consistent with at least moderate anxiety, strongly predicts lower odds of MDD improvement in this trial. Our exploratory findings suggest that depressed individuals with comorbid anxiety have reduced odds of substantial improvement in the context of smartphone-delivered interventions, as the association was observed across all three intervention groups. Our work highlights a methodology that can identify interpretable clinical thresholds, which, if validated, could predict symptom trajectories and inform treatment selection and intensity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11183v3</guid>
      <category>q-bio.QM</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Morgan B. Talbot, Jessica M. Lipschitz, Omar Costilla-Reyes</dc:creator>
    </item>
    <item>
      <title>A Large Sensor Foundation Model Pretrained on Continuous Glucose Monitor Data for Diabetes Management</title>
      <link>https://arxiv.org/abs/2412.09727</link>
      <description>arXiv:2412.09727v3 Announce Type: replace 
Abstract: Continuous glucose monitoring (CGM) combined with AI offers new opportunities for proactive diabetes management through real-time glucose forecasting. However, most existing models are task-specific and lack generalization across patient populations. Inspired by the autoregressive paradigm of large language models, we introduce CGM-LSM, a Transformer decoder-based Large Sensor Model (LSM) pretrained on 1.6 million CGM records from patients with different diabetes types, ages, and genders. We model patients as sequences of glucose time steps to learn latent knowledge embedded in CGM data and apply it to the prediction of glucose readings for a 2-hour horizon. Compared with prior methods, CGM-LSM significantly improves prediction accuracy and robustness: a 48.51% reduction in root mean square error in one-hour horizon forecasting and consistent zero-shot prediction performance across held-out patient groups. We analyze model performance variations across patient subgroups and prediction scenarios and outline key opportunities and challenges for advancing CGM foundation models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09727v3</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Junjie Luo, Abhimanyu Kumbara, Mansur Shomali, Rui Han, Anand Iyer, Ritu Agarwal, Gordon Gao</dc:creator>
    </item>
    <item>
      <title>Inverse 3D Microscopy Rendering for Cell Shape Inference with Active Mesh</title>
      <link>https://arxiv.org/abs/2303.10440</link>
      <description>arXiv:2303.10440v3 Announce Type: replace-cross 
Abstract: Traditional methods for biological shape inference, such as deep learning (DL) and active contour models, face important limitations in 3D. DL approaches require large annotated datasets, which are often impractical to obtain, while active contour methods depend on carefully tuned heuristics for intensity attraction and shape regularization. We introduce deltaMic, a novel differentiable 3D renderer for fluorescence microscopy that formulates shape inference as an inverse problem. By leveraging differentiable convolutions, deltaMic simulates the image formation process, integrating a parameterized point spread function (PSF) with a triangle mesh-based representation of biological structures. Unlike DL- or contour-based segmentation, deltaMic directly optimizes both shape and optical parameters to align synthetic and real microscopy images, removing the need for large datasets or sample-specific fine-tuning. To ensure scalability, we implement a GPU-accelerated Fourier transform for triangle meshes along with narrow-band spectral filtering. We show that deltaMic accurately reconstructs cell geometries from both synthetic and diverse experimental 3D microscopy data, while remaining robust to noise and initialization. This establishes a new physics-informed framework for biophysical image analysis and inverse modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.10440v3</guid>
      <category>physics.bio-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sacha Ichbiah, Anshuman Sinha, Fabrice Delbary, Herv\'e Turlier</dc:creator>
    </item>
    <item>
      <title>Climate benefits of afforestation and reforestation with varying species mixtures and densities in the north-western boreal lands</title>
      <link>https://arxiv.org/abs/2506.03300</link>
      <description>arXiv:2506.03300v2 Announce Type: replace-cross 
Abstract: The boreal forest plays a crucial role as a global carbon sink. This study uses two 250-year simulations of Canada's Taiga Plains, an area targeted by the 2 Billion Trees Program to evaluate afforestation and reforestation strategies that vary by species mix, planting density, and surface albedo. Medium density stands, 600 to 1400 trees per hectare, composed of mixed species with approximately 25 to 40 percent deciduous trees sequestered 15 to 30 percent more net ecosystem carbon than conifer monocultures. These benefits stem from a combination of rapid early growth, long-term carbon retention, and enhanced resilience to disturbance. Replanting understocked stands with such mixtures increased long-term carbon storage by 18 to 30 percent relative to prevailing scenarios. When surface albedo was considered, pure evergreen or deciduous stands showed a reduction in climate benefit by 6 to 20 percent, while mixed stands maintained net cooling and achieved the highest sequestration rates, approximately 4.6 to 4.7 tons of carbon dioxide equivalent per hectare per year. Scenarios involving partial harvesting followed by replanting sustained or improved ecosystem carbon stocks, about 300 to 340 tons of carbon per hectare, and productivity, roughly 1.6 to 2.0 tons of carbon per hectare per year, without increasing ecological risk. Overall, integrating fast-growing deciduous species with long-lived conifers at moderate planting densities enhances the climate mitigation potential of boreal afforestation and reforestation efforts and offers guidance for reforestation policy in similar high latitude ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03300v2</guid>
      <category>q-bio.PE</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Enoch Ofosu, Kevin Bradley Dsouza, Daniel Chukwuemeka Amaogu, Jerome Pigeon, Richard Boudreault, Juan Moreno-Cruz, Pooneh Maghoul, Yuri Leonenko</dc:creator>
    </item>
  </channel>
</rss>
