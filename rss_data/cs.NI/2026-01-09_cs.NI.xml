<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Jan 2026 05:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Mathematical Theory of Payment Channel Networks</title>
      <link>https://arxiv.org/abs/2601.04835</link>
      <description>arXiv:2601.04835v1 Announce Type: new 
Abstract: We introduce a geometric theory of payment channel networks that centers the polytope $W_G$ of feasible wealth distributions; liquidity states $L_G$ project onto $W_G$ via strict circulations. A payment is feasible iff the post-transfer wealth stays in $W_G$. This yields a simple throughput law: if $\zeta$ is on-chain settlement bandwidth and $\rho$ the expected fraction of infeasible payments, the sustainable off-chain bandwidth satisfies $S = \zeta / \rho$.
  Feasibility admits a cut-interval view: for any node set S, the wealth of S must lie in an interval whose width equals the cut capacity $C(\delta(S))$. Using this, we show how multi-party channels (coinpools / channel factories) expand $W_G$. Modeling a k-party channel as a k-uniform hyperedge widens every cut in expectation, so $W_G$ grows monotonically with k; for single nodes the expected accessible wealth scales linearly with $k/n$.
  We also analyze depletion. Under linear, asymmetric fees, cost-minimizing flow within a wealth fiber pushes cycles to the boundary, generically depleting channels except for a residual spanning forest. Three mitigation levers follow: (i) symmetric fees per direction, (ii) convex/tiered fees (effective flow control but at odds with source routing without liquidity disclosure), and (iii) coordinated replenishment (choose an optimal circulation within a fiber).
  Together, these results explain why two-party meshes struggle to scale and why multi-party primitives are more capital-efficient, yielding higher expected payment bandwidth. They also show how fee design and coordination keep operation inside the feasible region, improving reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04835v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rene Pickhardt</dc:creator>
    </item>
    <item>
      <title>Intelligent resource allocation in wireless networks via deep reinforcement learning</title>
      <link>https://arxiv.org/abs/2601.04842</link>
      <description>arXiv:2601.04842v1 Announce Type: new 
Abstract: This study addresses the challenge of optimal power allocation in stochastic wireless networks by employing a Deep Reinforcement Learning (DRL) framework. Specifically, we design a Deep Q-Network (DQN) agent capable of learning adaptive power control policies directly from channel state observations, effectively bypassing the need for explicit system models. We formulate the resource allocation problem as a Markov Decision Process (MDP) and benchmark the proposed approach against classical heuristics, including fixed allocation, random assignment, and the theoretical water-filling algorithm. Empirical results demonstrate that the DQN agent achieves a system throughput of 3.88 Mbps, effectively matching the upper limit of the water fill, while outperforming the random and fixed allocation strategies by approximately 73% and 27%, respectively. Moreover, the agent exhibits emergent fairness, maintaining a Jain's Index of 0.91, and successfully optimizes the trade-off between spectral efficiency and energy consumption. These findings substantiate the efficacy of model-free DRL as a robust and scalable solution for resource management in next-generation communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04842v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marie Diane Iradukunda, Chabi F. El\'egb\'ed\'e, Ya\'e Ulrich Gaba</dc:creator>
    </item>
    <item>
      <title>5G NR Non-Terrestrial Networks: From Early Results to the Road Ahead</title>
      <link>https://arxiv.org/abs/2601.04882</link>
      <description>arXiv:2601.04882v1 Announce Type: new 
Abstract: This paper overviews the 3GPP 5G NR-NTN standard, detailing the evolution from Rel. 18 to 19 and innovations for Rel. 20. Using realistic ns-3 simulations validated against 3GPP calibration data, we evaluate various satellite network configurations. The results highlight the potential of NTNs to extend wireless connectivity to remote areas, serve requests during emergency, and alleviate terrestrial network congestion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04882v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mattia Figaro, Francesco Rossato, Marco Giordani, Alessandro Traspadini, Takayuki Shimizu, Chinmay Mahabal, Sanjeewa Herath, Chunghan Lee, Dogan Kutay Pekcan, Michele Zorzi</dc:creator>
    </item>
    <item>
      <title>A DQN-based model for intelligent network selection in heterogeneous wireless systems</title>
      <link>https://arxiv.org/abs/2601.04978</link>
      <description>arXiv:2601.04978v1 Announce Type: new 
Abstract: Wireless communications have been at the center of the revolution in technology for the last few years. The 5G communication system is the pinnacle of these technologies; however 4G LTE, WiFi, and even satellite technologies are still employed worldwide. So, the aim of the next generation network is to take advantage of these technologies for the better of the end users. Our research analyzes this subject and reveals a new and intelligent method that allows users to select the suitable RAT at each time and, therefore, to switch to another RAT if necessary. The Deep Q Network DQN algorithm was utilized, which is a reinforcement learning algorithm that determines judgments based on antecedent actions (rewards and punishments). The approach exhibits a high accuracy, reaching 93 percent, especially after a given number of epochs (the exploration phase), compared to typical MADM methods where the accuracy does not exceed 75 percent</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04978v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fayssal Bendaoud, Asma Amraoui, karim Sehimi</dc:creator>
    </item>
    <item>
      <title>Cognitive Infrastructure: A Unified DCIM Framework for AI Data Centers</title>
      <link>https://arxiv.org/abs/2601.04750</link>
      <description>arXiv:2601.04750v1 Announce Type: cross 
Abstract: This work presents DCIM 3.0, a unified framework integrating semantic reasoning, predictive analytics, autonomous orchestration, and unified connectivity for next-generation AI data center management. The framework addresses critical challenges in infrastructure automation, sustainability, and digital-twin design through knowledge graph-based intelligence, thermal modeling, and the Unified Device Connectivity Protocol (UDCP).Keywords-Data Center Infrastructure Management, DCIM, AI Data Centers, Knowledge Graphs, Digital Twin, Thermal Management, Infrastructure Automation, Sustainability, GPU Computing, Data Center</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04750v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krishna Chaitanya Sunkara</dc:creator>
    </item>
    <item>
      <title>Experimental Study of Low-Latency Video Streaming in an ORAN Setup with Generative AI</title>
      <link>https://arxiv.org/abs/2412.12751</link>
      <description>arXiv:2412.12751v4 Announce Type: replace 
Abstract: Current Adaptive Bit Rate (ABR) methods react to network congestion after it occurs, causing application layer buffering and latency spikes in live video streaming. We introduce a proactive semantic control channel that enables coordination between Open Radio Access Network (ORAN) xApp, Mobile Edge computing (MEC), and User Equipment (UE) components for seamless live video streaming between mobile devices. When the transmitting UE experiences poor Uplink (UL) conditions, the MEC proactively instructs downscaling based on low-level RAN metrics, including channel SNR updated every millisecond, preventing buffering before it occurs. A Generative AI (GAI) module at the MEC reconstructs high-quality frames from downscaled video before forwarding to the receiving UE via the typically more robust Downlink (DL). Experimental validation on a live ORAN testbed with 50 video streams shows that our approach reduces latency tail behavior while achieving up to 4 dB improvement in PSNR and 15 points in VMAF compared to reactive ABR methods. The proactive control eliminates latency spikes exceeding 600 ms, demonstrating effective cross-layer coordination for latency-critical live video streaming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12751v4</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andreas Casparsen, Van-Phuc Bui, Shashi Raj Pandey, Jimmy Jessen Nielsen, Petar Popovski</dc:creator>
    </item>
    <item>
      <title>From Timestamps to Versions: Version AoI in Single- and Multi-Hop Networks</title>
      <link>https://arxiv.org/abs/2507.23433</link>
      <description>arXiv:2507.23433v2 Announce Type: replace 
Abstract: Timely and informative data dissemination in communication networks is essential for enhancing system performance and energy efficiency, as it reduces the transmission of outdated or redundant data. Timeliness metrics, such as Age of Information (AoI), effectively quantify data freshness; however, these metrics fail to account for the intrinsic informativeness of the content itself. To address this limitation, content-based metrics have been proposed that combine both timeliness and informativeness. Nevertheless, existing studies have predominantly focused on evaluating average metric values, leaving the complete distribution-particularly in multi-hop network scenarios-largely unexplored. In this paper, we provide a comprehensive analysis of the stationary distribution of the Version Age of Information (VAoI), a content-based metric, under various scheduling policies, including randomized stationary, uniform, and threshold-based policies, with transmission constraints in single-hop and multi-hop networks. We derive closed-form expressions for the stationary distribution and average VAoI under these scheduling approaches. Furthermore, for threshold-based scheduling, we analytically determine the optimal threshold value that minimizes VAoI and derive the corresponding optimal VAoI in closed form. Numerical evaluations verify our analytical findings, providing valuable insights into leveraging VAoI in the design of efficient communication networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23433v2</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erfan Delfani, Nikolaos Pappas</dc:creator>
    </item>
    <item>
      <title>A Novel Hierarchical Co-Optimization Framework for Coordinated Task Scheduling and Power Dispatch in Computing Power Networks</title>
      <link>https://arxiv.org/abs/2508.04015</link>
      <description>arXiv:2508.04015v2 Announce Type: replace 
Abstract: The proliferation of large-scale artificial intelligence and data-intensive applications has spurred the development of Computing Power Networks (CPNs), which promise to deliver ubiquitous and on-demand computational resources. However, the immense energy consumption of these networks poses a significant sustainability challenge. Simultaneously, power grids are grappling with the instability introduced by the high penetration of intermittent renewable energy sources (RES). This paper addresses these dual challenges through a novel Two-Stage Co-Optimization (TSCO) framework that synergistically manages power system dispatch and CPN task scheduling to achieve low-carbon operations. The framework decomposes the complex, large-scale problem into a day-ahead stochastic unit commitment (SUC) stage and a real-time operational stage. The former is solved using Benders decomposition for computational tractability, while in the latter, economic dispatch of generation assets is coupled with an adaptive CPN task scheduling managed by a Deep Reinforcement Learning (DRL) agent. This agent makes intelligent, carbon-aware decisions by responding to dynamic grid conditions, including real-time electricity prices and marginal carbon intensity. Through extensive simulations on an IEEE 30-bus system integrated with a CPN, the TSCO framework is shown to significantly outperform baseline approaches. Results demonstrate that the proposed framework reduces total carbon emissions and operational costs, while simultaneously decreasing RES curtailment by more than 60% and maintaining stringent Quality of Service (QoS) for computational tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04015v2</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Haoxiang Luo, Kun Yang, Qi Huang, Schahram Dustdar</dc:creator>
    </item>
    <item>
      <title>Timely Information Updating for Mobile Devices Without and With ML Advice</title>
      <link>https://arxiv.org/abs/2512.17381</link>
      <description>arXiv:2512.17381v2 Announce Type: replace 
Abstract: This paper investigates an information update system in which a mobile device monitors a physical process and sends status updates to an access point (AP). A fundamental trade-off arises between the timeliness of the information maintained at the AP and the update cost incurred at the device. To address this trade-off, we propose an online algorithm that determines when to transmit updates using only available observations. The proposed algorithm asymptotically achieves the optimal competitive ratio against an adversary that can simultaneously manipulate multiple sources of uncertainty, including the operation duration, information staleness, update cost, and update opportunities. Furthermore, by incorporating machine learning (ML) advice of unknown reliability into the design, we develop an ML-augmented algorithm that asymptotically attains the optimal consistency-robustness trade-off, even when the adversary can additionally corrupt the ML advice. The optimal competitive ratio scales linearly with the range of update costs, but is unaffected by other sources of uncertainty. Moreover, an optimal competitive online algorithm exhibits a threshold-like response to the ML advice: it either fully trusts or completely ignores the ML advice, as partially trusting the advice cannot improve the consistency without severely degrading the robustness. Extensive simulations in stochastic settings further validate the theoretical findings in the adversarial environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17381v2</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu-Pin Hsu, Yi-Hsuan Tseng</dc:creator>
    </item>
    <item>
      <title>Cells on Autopilot: Adaptive Cell (Re)Selection via Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2601.04083</link>
      <description>arXiv:2601.04083v2 Announce Type: replace 
Abstract: The widespread deployment of 5G networks, together with the coexistence of 4G/LTE networks, provides mobile devices a diverse set of candidate cells to connect to. However, associating mobile devices to cells to maximize overall network performance, a.k.a. cell (re)selection, remains a key challenge for mobile operators. Today, cell (re)selection parameters are typically configured manually based on operator experience and rarely adapted to dynamic network conditions. In this work, we ask: Can an agent automatically learn and adapt cell (re)selection parameters to consistently improve network performance? We present a reinforcement learning (RL)-based framework called CellPilot that adaptively tunes cell (re)selection parameters by learning spatiotemporal patterns of mobile network dynamics. Our study with real-world data demonstrates that even a lightweight RL agent can outperform conventional heuristic reconfigurations by up to 167%, while generalizing effectively across different network scenarios. These results indicate that data-driven approaches can significantly improve cell (re)selection configurations and enhance mobile network performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04083v2</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marvin Illian, Ramin Khalili, Antonio A. de A. Rocha, Lin Wang</dc:creator>
    </item>
    <item>
      <title>Entanglement-Based Artificial Topology: Neighboring Remote Network Nodes</title>
      <link>https://arxiv.org/abs/2404.16204</link>
      <description>arXiv:2404.16204v5 Announce Type: replace-cross 
Abstract: Entanglement is unanimously recognized as the key communication resource of the Quantum Internet. Yet, the possibility of implementing novel network functionalities by exploiting the marvels of entanglement has been poorly investigated so far, by mainly restricting the attention to bipartite entanglement. Conversely, in this paper, we aim at exploiting multipartite entanglement as inter-network resource. Specifically, we consider the interconnection of different Quantum Local Area Networks (QLANs), and we show that multipartite entanglement allows to dynamically generate an inter-QLAN artificial topology, by means of local operations only, that overcomes the limitations of the physical QLAN topologies. To this aim, we first design the multipartite entangled state to be distributed within each QLAN. Then, we show how such a state can be engineered to: i) interconnect nodes belonging to different QLANs, and ii) dynamically adapt to different inter-QLAN traffic patterns. Our contribution aims at providing the network engineering community with a hands-on guideline towards the concept of artificial topology and artificial neighborhood.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16204v5</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/OJCOMS.2025.3554052</arxiv:DOI>
      <arxiv:journal_reference>IEEE Open Journal of the Communications Society, April, 2025</arxiv:journal_reference>
      <dc:creator>Si-Yi Chen, Jessica Illiano, Angela Sara Cacciapuoti, Marcello Caleffi</dc:creator>
    </item>
    <item>
      <title>Quantum Data Centres: Why Entanglement Changes Everything</title>
      <link>https://arxiv.org/abs/2506.02920</link>
      <description>arXiv:2506.02920v3 Announce Type: replace-cross 
Abstract: The Quantum Internet is key for distributed quantum computing, by interconnecting multiple quantum processors into a virtual quantum computation system. This allows to scale the number of qubits, by overcoming the inherent limitations of noisy-intermediate-scale quantum (NISQ) devices. Thus, the Quantum Internet is the foundation for large-scale, fault-tolerant quantum computation. Among the distributed architectures, Quantum Data Centres emerge as the most viable in the medium-term, since they integrate multiple quantum processors within a localized network infrastructure, by allowing modular design of quantum networking. We analyze the physical and topological constraints of Quantum Data Centres, by emphasizing the role of entanglement orchestrators in dynamically reconfiguring network topologies through local operations. We examine the major hardware challenge of quantum transduction, essential for interfacing heterogeneous quantum systems. Furthermore, we explore how interconnecting multiple Quantum Data Centres could enable large-scale quantum networks. We discuss the topological constraints of such a scaling and identify open challenges, including entanglement routing and synchronization. The carried analysis positions Quantum Data Centres as both a practical implementation platform and strategic framework for the future Quantum Internet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02920v3</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <pubDate>Fri, 09 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1098/rsta.2024.0518</arxiv:DOI>
      <dc:creator>Angela Sara Cacciapuoti, Claudio Pellitteri, Jessica Illiano, Laura d'Avossa, Francesco Mazza, Siyi Chen, Marcello Caleffi</dc:creator>
    </item>
  </channel>
</rss>
