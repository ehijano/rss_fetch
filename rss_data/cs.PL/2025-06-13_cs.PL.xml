<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Jun 2025 04:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>From Tool Calling to Symbolic Thinking: LLMs in a Persistent Lisp Metaprogramming Loop</title>
      <link>https://arxiv.org/abs/2506.10021</link>
      <description>arXiv:2506.10021v1 Announce Type: new 
Abstract: We propose a novel architecture for integrating large language models (LLMs) with a persistent, interactive Lisp environment. This setup enables LLMs to define, invoke, and evolve their own tools through programmatic interaction with a live REPL. By embedding Lisp expressions within generation and intercepting them via a middleware layer, the system allows for stateful external memory, reflective programming, and dynamic tool creation. We present a design framework and architectural principles to guide future implementations of interactive AI systems that integrate symbolic programming with neural language generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10021v1</guid>
      <category>cs.PL</category>
      <category>cs.AI</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jordi de la Torre</dc:creator>
    </item>
    <item>
      <title>A Language-Agnostic Logical Relation for Message-Passing Protocols</title>
      <link>https://arxiv.org/abs/2506.10026</link>
      <description>arXiv:2506.10026v1 Announce Type: new 
Abstract: Today's computing landscape has been gradually shifting to applications targeting distributed and *heterogeneous* systems, such as cloud computing and Internet of Things (IoT) applications. These applications are predominantly *concurrent*, employ *message-passing*, and interface with *foreign objects*, ranging from externally implemented code to actual physical devices such as sensors. Verifying that the resulting systems adhere to the intended protocol of interaction is challenging -- the usual assumption of a common implementation language, let alone a type system, no longer applies, ruling out any verification method based on them. This paper develops a framework for certifying *protocol compliance* of heterogeneous message-passing systems. It contributes the first mechanization of a *language-agnostic logical relation*, asserting that its inhabitants comply with the protocol specified. This definition relies entirely on a labelled transition-based semantics, accommodating arbitrary inhabitants, typed and untyped alike, including foreign objects. As a case study, the paper considers two scenarios: (1) *per-instance verification* of a specific application or hardware device, and (2) *once-and-for-all verification* of well-typed applications for a given type system. The logical relation and both scenarios are mechanized in the Coq theorem prover.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10026v1</guid>
      <category>cs.PL</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tesla Zhang, Sonya Simkin, Rui Li, Yue Yao, Stephanie Balzer</dc:creator>
    </item>
    <item>
      <title>Hazel Deriver: A Live Editor for Constructing Rule-Based Derivations</title>
      <link>https://arxiv.org/abs/2506.10781</link>
      <description>arXiv:2506.10781v1 Announce Type: new 
Abstract: Students in programming languages and formal logic courses often struggle with constructing rule-based derivation trees due to the complexity of applying inference rules, the lack of immediate feedback, and the manual effort required for handwritten proofs. We present Hazel Deriver, a live, web-based editor designed to scaffold derivation construction through multiple layers of support. Built on the Hazel live programming environment, it provides a structured, interactive experience that encourages iterative exploration and real-time feedback. A preliminary user study with former students suggests that Hazel Deriver reduces the perceived difficulty of derivation tasks while improving conceptual understanding and engagement. We discuss the design of its layered scaffolding features and raise questions about balancing system guidance with learner autonomy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10781v1</guid>
      <category>cs.PL</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyao Zhong, Cyrus Omar</dc:creator>
    </item>
    <item>
      <title>Choreographic Quick Changes: First-Class Location (Set) Polymorphism</title>
      <link>https://arxiv.org/abs/2506.10913</link>
      <description>arXiv:2506.10913v1 Announce Type: new 
Abstract: Choreographic programming is a promising new paradigm for programming concurrent systems where a developer writes a single centralized program that compiles to individual programs for each node. Existing choreographic languages, however, lack critical features integral to modern systems, like the ability of one node to dynamically compute who should perform a computation and send that decision to others. This work addresses this gap with $\lambda_{QC}$, the first typed choreographic language with \emph{first class process names} and polymorphism over both types and (sets of) locations. $\lambda_{QC}$ also improves expressive power over previous work by supporting algebraic and recursive data types as well as multiply-located values. We formalize and mechanically verify our results in Rocq, including the standard choreographic guarantee of deadlock freedom.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10913v1</guid>
      <category>cs.PL</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashley Samuelson, Andrew K. Hirsch, Ethan Cecchetti</dc:creator>
    </item>
    <item>
      <title>Reward Models Enable Scalable Code Verification by Trading Accuracy for Throughput</title>
      <link>https://arxiv.org/abs/2506.10056</link>
      <description>arXiv:2506.10056v1 Announce Type: cross 
Abstract: The standard paradigm for solving coding tasks via large language models (LLMs) is to generate-then-rank programs, where the latter step uses a verifier in the ranking process. The growing consensus is that a comprehensive verifier (e.g., a full test suite) should be prioritized over an outcome reward model (ORM) whenever possible, with little consideration given to the trade-offs involved. We aim to challenge this assumption by systematically exploring the tradeoff between speed and accuracy. We find that ORMs play a crucial role in scaling verification through trading accuracy for speed, even when a comprehensive verifier is available. Their value becomes especially apparent when used in a generate-prune-then-rank approach, where a faster but less accurate verifier removes incorrect solutions prior to ranking -- leading to a system that is 11.65x faster while only being 8.33% less accurate than the full test suite. We analyze the generate-prune-then-rank approach and show that it works by filtering out incorrect but highly ranked solutions. These findings enable the design of scalable and accurate program ranking systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10056v1</guid>
      <category>cs.SE</category>
      <category>cs.PL</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Gabriel Orlanski, Nicholas Roberts, Aws Albarghouthi, Frederic Sala</dc:creator>
    </item>
    <item>
      <title>Solving Package Management via Hypergraph Dependency Resolution</title>
      <link>https://arxiv.org/abs/2506.10803</link>
      <description>arXiv:2506.10803v1 Announce Type: cross 
Abstract: Package managers are everywhere, with seemingly every language and operating system implementing their own solution. The lack of interoperability between these systems means that multi-lingual projects are unable to express precise dependencies across language ecosystems, and external system and hardware dependencies are typically implicit and unversioned. We define HyperRes, a formal system for describing versioned dependency resolution using a hypergraph that is expressive enough to model many ecosystems and solve dependency constraints across them. We define translations from dozens of existing package managers to HyperRes and comprehensively demonstrate that dependency resolution can work across ecosystems that are currently distinct. This does not require users to shift their choice of package managers; instead, HyperRes allows for the translation of packaging metadata between ecosystems, and for solving to be precisely specialised to a particular deployment environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10803v1</guid>
      <category>cs.SE</category>
      <category>cs.PL</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan Gibb, Patrick Ferris, David Allsopp, Michael Winston Dales, Mark Elvers, Thomas Gazagnaire, Sadiq Jaffer, Thomas Leonard, Jon Ludlam, Anil Madhavapeddy</dc:creator>
    </item>
    <item>
      <title>CompilerDream: Learning a Compiler World Model for General Code Optimization</title>
      <link>https://arxiv.org/abs/2404.16077</link>
      <description>arXiv:2404.16077v3 Announce Type: replace 
Abstract: Effective code optimization in compilers is crucial for computer and software engineering. The success of these optimizations primarily depends on the selection and ordering of the optimization passes applied to the code. While most compilers rely on a fixed sequence of optimization passes, current methods to find the optimal sequence either employ impractically slow search algorithms or learning methods that struggle to generalize to code unseen during training. We introduce CompilerDream, a model-based reinforcement learning approach to general code optimization. CompilerDream comprises a compiler world model that accurately simulates the intrinsic properties of optimization passes and an agent trained on this model to produce effective optimization strategies. By training on a large-scale program dataset, CompilerDream is equipped to serve as a general code optimizer across various application scenarios and source-code languages. Our extensive experiments first highlight CompilerDream's strong optimization capabilities for autotuning, where it leads the CompilerGym leaderboard. More importantly, the zero-shot generalization ability of large-scale trained compiler world model and agent, excels across diverse datasets, surpassing LLVM's built-in optimizations and other state-of-the-art methods in both settings of value prediction and end-to-end code optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16077v3</guid>
      <category>cs.PL</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaoyi Deng, Jialong Wu, Ningya Feng, Jianmin Wang, Mingsheng Long</dc:creator>
    </item>
    <item>
      <title>Weaver: A Retargetable Compiler Framework for FPQA Quantum Architectures</title>
      <link>https://arxiv.org/abs/2409.07870</link>
      <description>arXiv:2409.07870v2 Announce Type: replace-cross 
Abstract: While the prominent quantum computing architectures are based on superconducting technology, new quantum hardware technologies are emerging, such as Trapped Ions, Neutral Atoms (or FPQAs), Silicon Spin Qubits, etc. This diverse set of technologies presents fundamental trade-offs in terms of scalability, performance, manufacturing, and operating expenses. To manage these diverse quantum technologies, there is a growing need for a retargetable compiler that can efficiently adapt existing code to these emerging hardware platforms. Such a retargetable compiler must be extensible to support new and rapidly evolving technologies, performant with fast compilation times and high-fidelity execution, and verifiable through rigorous equivalence checking to ensure the functional equivalence of the retargeted code.
  To this end, we present $Weaver$, the first extensible, performant, and verifiable retargetable quantum compiler framework with a focus on FPQAs due to their unique, promising features. $Weaver$ introduces WQASM, the first formal extension of the standard OpenQASM quantum assembly with FPQA-specific instructions to support their distinct capabilities. Next, $Weaver$ implements the WOptimizer, an extensible set of FPQA-specific optimization passes to improve execution quality. Last, the WChecker automatically checks for equivalence between the original and the retargeted code. Our evaluation shows that $Weaver$ improves compilation times by $10^3\times$, execution times by $4.4\times$, and execution fidelity by $10\%$, on average, compared to superconducting and state-of-the-art (non-retargetable) FPQA compilers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07870v2</guid>
      <category>quant-ph</category>
      <category>cs.PL</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>O\u{g}uzcan K{\i}rmemi\c{s}, Francisco Rom\~ao, Emmanouil Giortamis, Pramod Bhatotia</dc:creator>
    </item>
  </channel>
</rss>
