<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 May 2025 01:54:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Stability of two-dimensional SISO LTI system with bounded feedback gain that has bounded derivative</title>
      <link>https://arxiv.org/abs/2505.20372</link>
      <description>arXiv:2505.20372v1 Announce Type: new 
Abstract: We consider a two-dimensional SISO LTI system closed by uncertain linear feedback. The feedback gain is time-varying, bounded, and has a bounded derivative (both bounds are known). We investigate the asymptotic stability of this system under all admissible behaviors of the gain. Note that the situation is similar to the classical absolute stability problem of Lurie--Aizerman with two differences: linearity and derivative constraint. Our method of analysis is therefore inspired by the variational ideas of Pyatnitskii, Barabanov, Margaliot, and others developed for the absolute stability problem. We derive the Hamilton--Jacobi--Bellman equation for a function describing the "most unstable" of the possible portraits of the closed-loop system. A numerical method is proposed for solving the equation. Based on the solution, sufficient conditions are formulated for the asymptotic stability and instability. The method is applied to an equation arising from the analysis of a power electronics synchronization circuit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20372v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anton Ponomarev, Lutz Gr\"oll</dc:creator>
    </item>
    <item>
      <title>Numerical estimation of the lock-in domain of a DC/AC inverter</title>
      <link>https://arxiv.org/abs/2505.20374</link>
      <description>arXiv:2505.20374v1 Announce Type: new 
Abstract: We estimate the lock-in domain of the origin of a current control system which is used in common DC/AC inverter designs. The system is a cascade connection of a 4-dimensional linear system (current controller, CC) followed by a two-dimensional nonlinear system (phase-locked loop, PLL). For the PLL, we construct a Lyapunov function via numerical approximation of its level curves. In combination with the quadratic Lyapunov function of the CC, it forms a vector Lyapunov function (VLF) for the overall system. A forward-invariant set of the VLF is found via numerical application of the comparison principle. By LaSalle's invariance principle, convergence to the origin is established.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20374v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anton Ponomarev, Lutz Gr\"oll, Veit Hagenmeyer</dc:creator>
    </item>
    <item>
      <title>An Unconstrained Optimization Approach to Moment Fitting with Phase Type Distributions</title>
      <link>https://arxiv.org/abs/2505.20379</link>
      <description>arXiv:2505.20379v1 Announce Type: new 
Abstract: Phase type (PH) distributions are widely used in modeling and simulation due to their generality and analytical properties. In such settings, it is often necessary to construct a PH distribution that aligns with real-world data by matching a set of prescribed moments. Existing approaches provide either exact closed-form solutions or iterative procedures that may yield exact or approximate results. However, these methods are limited to matching a small number of moments using PH distributions with a small number of phases, or are restricted to narrow subclasses within the PH family. We address the problem of approximately fitting a larger set of given moments using potentially large PH distributions. We introduce an optimization methodology that relies on a re-parametrization of the Markovian representation, formulated in a space that enables unconstrained optimization of the moment-matching objective. This reformulation allows us to scale to significantly larger PH distributions and capture higher moments. Results on a large and diverse set of moment targets show that the proposed method is, in the vast majority of cases, capable of fitting as many as 20 moments to PH distributions with as many as 100 phases, with small relative errors on the order of under 0.5% from each target. We further demonstrate an application of the optimization framework where we search for a PH distribution that conforms not only to a given set of moments but also to a given shape. Finally, we illustrate the practical utility of this approach through a queueing application, presenting a case study that examines the influence of the i^{th} moment of the inter-arrival and service time distributions on the steady-state probabilities of the GI/GI/1 queue length.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20379v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eliran Sherzer, Yehezkel Resheff, Miklos Telek</dc:creator>
    </item>
    <item>
      <title>Joint Optimization of Service Routing and Scheduling in Home Health Care</title>
      <link>https://arxiv.org/abs/2505.20474</link>
      <description>arXiv:2505.20474v1 Announce Type: new 
Abstract: The growing aging population has significantly increased demand for efficient home health care (HHC) services. This study introduces a Vehicle Routing and Appointment Scheduling Problem (VRASP) to simultaneously optimize caregiver routes and appointment times, minimizing costs while improving service quality. We first develop a deterministic VRASP model and then extend it to a stochastic version using sample average approximation to account for travel and service time uncertainty. A tailored Variable Neighborhood Search (VNS) heuristic is proposed, combining regret-based insertion and Tabu Search to efficiently solve both problem variants. Computational experiments show that the stochastic model outperforms the deterministic approach, while VNS achieves near-optimal solutions for small instances and demonstrates superior scalability for larger problems compared to CPLEX. This work provides HHC providers with a practical decision-making tool to enhance operational efficiency under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20474v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Zhang, Zhenzhen Zhang</dc:creator>
    </item>
    <item>
      <title>Asymptotic Convergence Analysis of High-Order Proximal-Point Methods Beyond Sublinear Rates</title>
      <link>https://arxiv.org/abs/2505.20484</link>
      <description>arXiv:2505.20484v1 Announce Type: new 
Abstract: This paper investigates the asymptotic convergence behavior of high-order proximal-point algorithms (HiPPA) toward global minimizers, extending the analysis beyond sublinear convergence rate results. Specifically, we consider the proximal operator of a lower semicontinuous function augmented with a $p$th-order regularization for $p&gt;1$, and establish the convergence of HiPPA to a global minimizer with a particular focus on its convergence rate. To this end, we focus on minimizing the class of uniformly quasiconvex functions, including strongly convex, uniformly convex, and strongly quasiconvex functions as special cases. Our analysis reveals the following convergence behaviors of HiPPA when the uniform quasiconvexity modulus admits a power function of degree $q$ as a lower bound on an interval $\mathcal{I}$: (i) for $q\in (1,2]$ and $\mathcal{I}=[0,1)$, HiPPA exhibits local linear rate for $p\in (1,2)$; (ii) for $q=2$ and $\mathcal{I}=[0,\infty)$, HiPPA converges linearly for $p=2$; (iii) for $p=q&gt;2$ and $\mathcal{I}=[0,\infty)$, HiPPA converges linearly; (iv) for $q\geq 2$ and $\mathcal{I}=[0,\infty)$, HiPPA achieves superlinear rate for $p&gt;q$. Notably, to our knowledge, some of these results are novel, even in the context of strongly or uniformly convex functions, offering new insights into optimizing generalized convex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20484v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masoud Ahookhosh, Alfredo Iusem, Alireza Kabgani, Felipe Lara</dc:creator>
    </item>
    <item>
      <title>Least Squares Model Reduction: A Two-Stage System-Theoretic Interpretation</title>
      <link>https://arxiv.org/abs/2505.20604</link>
      <description>arXiv:2505.20604v1 Announce Type: new 
Abstract: Model reduction simplifies complex dynamical systems while preserving essential properties. This paper revisits a recently proposed system-theoretic framework for least squares moment matching. It interprets least squares model reduction in terms of two steps process: constructing a surrogate model to satisfy interpolation constraints, then projecting it onto a reduced-order space. Using tools from output regulation theory and Krylov projections, this approach provides a new view on classical methods. For illustration, we reexamine the least-squares model reduction method by Lucas and Smith, offering new insights into its structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20604v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alberto Padoan</dc:creator>
    </item>
    <item>
      <title>Controllability of partial differential equations on graphs</title>
      <link>https://arxiv.org/abs/2505.20690</link>
      <description>arXiv:2505.20690v1 Announce Type: new 
Abstract: We study the boundary control problems for the wave, heat, and Schr\"odinger equations on a finite graph. We suppose that the graph is a tree (i.e., it does not contain cycles), and on each edge an equation is defined. The control is acting through the Dirichlet condition applied to all or all but one boundary vertices. The exact controllability in $L_2$-classes of controls is proved and sharp estimates of the time of controllability are obtained for the wave equation. The null controllability for the heat equation and exact controllability for the Schr\"odinger equation in arbitrary time interval are obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20690v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.SP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.4064/am35-4-1</arxiv:DOI>
      <dc:creator>S. A. Avdonin, V. S. Mikhaylov</dc:creator>
    </item>
    <item>
      <title>Convergence of Clipped-SGD for Convex $(L_0,L_1)$-Smooth Optimization with Heavy-Tailed Noise</title>
      <link>https://arxiv.org/abs/2505.20817</link>
      <description>arXiv:2505.20817v1 Announce Type: new 
Abstract: Gradient clipping is a widely used technique in Machine Learning and Deep Learning (DL), known for its effectiveness in mitigating the impact of heavy-tailed noise, which frequently arises in the training of large language models. Additionally, first-order methods with clipping, such as Clip-SGD, exhibit stronger convergence guarantees than SGD under the $(L_0,L_1)$-smoothness assumption, a property observed in many DL tasks. However, the high-probability convergence of Clip-SGD under both assumptions -- heavy-tailed noise and $(L_0,L_1)$-smoothness -- has not been fully addressed in the literature. In this paper, we bridge this critical gap by establishing the first high-probability convergence bounds for Clip-SGD applied to convex $(L_0,L_1)$-smooth optimization with heavy-tailed noise. Our analysis extends prior results by recovering known bounds for the deterministic case and the stochastic setting with $L_1 = 0$ as special cases. Notably, our rates avoid exponentially large factors and do not rely on restrictive sub-Gaussian noise assumptions, significantly broadening the applicability of gradient clipping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20817v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Savelii Chezhegov, Aleksandr Beznosikov, Samuel Horv\'ath, Eduard Gorbunov</dc:creator>
    </item>
    <item>
      <title>Optimal control of a two-dimensional elliptic equation with exponential nonlinearity and Dirac measure data</title>
      <link>https://arxiv.org/abs/2505.20852</link>
      <description>arXiv:2505.20852v1 Announce Type: new 
Abstract: This work addresses an optimal control problem for a semilinear elliptic equation in two-dimensional space, characterized by an exponential nonlinearity and a singular source term. The source is modeled as a finite linear combination of Dirac measures concentrated at a fixed set of distinct points. The control variable is a finite-dimensional vector whose components represent the masses assigned to these point sources. 
  Due to the interplay between the exponential nonlinearity and the singular measure data, the state equation is generally ill-posed and admits a unique very weak solution only when the largest component of the control vector does not surpass a certain critical threshold. Consequently, the control-to-state operator might be continuously differentiable only on an open subset of the control space. 
  To derive first-order optimality conditions for the original problem, we introduce a family of regularized problems by imposing box constraints on the control variables. These constraints are chosen such that the admissible control sets of the regularized problems lie entirely within the open subset where the control-to-state operator is smooth. By analyzing the optimality systems associated with the regularized problems and passing to the limit, we obtain necessary optimality conditions for the original, unregularized problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20852v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vu Huu Nhu</dc:creator>
    </item>
    <item>
      <title>Uncertainty Partitioning with Probabilistic Feasibility and Performance Guarantees for Chance-Constrained Optimization</title>
      <link>https://arxiv.org/abs/2505.20927</link>
      <description>arXiv:2505.20927v1 Announce Type: new 
Abstract: We propose a novel distribution-free scheme to solve optimization problems where the goal is to minimize the expected value of a cost function subject to probabilistic constraints. Unlike standard sampling-based methods, our idea consists of partitioning the uncertainty domain in a user-defined number of sets, enabling more flexibility in the trade-off between conservatism and computational complexity. We provide sufficient conditions to ensure that our approximated problem is feasible for the original stochastic program, in terms of chance constraint satisfaction. In addition, we perform a rigorous performance analysis, by quantifying the distance between the optimal values of the original and the approximated problem. We show that our approach is tractable for optimization problems that include model predictive control of piecewise affine systems, and we demonstrate the benefits of our approach, in terms of the trade-off between conservatism and computational complexity, on a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20927v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesco Cordiano, Matin Jafarian, Bart De Schutter</dc:creator>
    </item>
    <item>
      <title>An accelerated semi-proximal ADMM with applications to multi-block sparse optimization problems</title>
      <link>https://arxiv.org/abs/2505.20991</link>
      <description>arXiv:2505.20991v1 Announce Type: new 
Abstract: As an extension of the alternating direction method of multipliers (ADMM), the semi-proximal ADMM (sPADMM) has been widely used in various fields due to its flexibility and robustness. In this paper, we first show that the two-block sPADMM algorithm can achieve an $O(1/\sqrt{K})$ non-ergodic convergence rate. Then we propose an accelerated sPADMM (AsPADMM) algorithm by introducing extrapolation techniques and incrementing penalty parameters. The proposed AsPADMM algorithm is proven to converge globally to an optimal solution with a non-ergodic convergence rate of $O(1/K)$. Furthermore, the AsPADMM can be extended and combined with the symmetric Gauss-Seidel decomposition to achieve an accelerated ADMM for multi-block problems. Finally, we apply the proposed AsPADMM to solving the multi-block subproblems in difference-of-convex algorithms for robust low-rank tensor completion problems and mixed sparse optimization problems. The numerical results suggest that the acceleration techniques bring about a notable improvement in the convergence speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20991v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peng Liu, Liang Chen, Minru Bai</dc:creator>
    </item>
    <item>
      <title>Dual Hierarchical Least-Squares Programming with Equality Constraints</title>
      <link>https://arxiv.org/abs/2505.21071</link>
      <description>arXiv:2505.21071v1 Announce Type: new 
Abstract: Hierarchical least-squares programming (HLSP) is an important tool in optimization as it enables the stacking of any number of priority levels in order to reflect complex constraint relationships, for example in physical systems like robots. Existing solvers typically address the primal formulation of HLSP's, which is computationally efficient due to sequential treatment of the priority levels. This way, already identified active constraints can be eliminated after each priority level, leading to smaller problems as the solver progresses through the hierarchy. However, this sequential progression makes the solvers discontinuous and therefore not differentiable. This prevents the incorporation of HLSP's as neural network neurons, or solving HLSP's in a distributed fashion. In this work, an efficient solver based on the dual formulation of HLSP's with equality constraints (D-HLSP-E) is developed. D-HLSP-E is a convex and differentiable quadratically constrained least-squares program (QCLSP), which is solved by an Alternating Direction Method of Multipliers (ADMM). By introducing appropriate operator splitting, primal-dual variables, which link each priority level with all their respective higher priority levels, can be eliminated from the main computation step of computing a matrix factorization. The proposed solver D-HADM is about one magnitude faster than a comparable D-HLSP-E solver based on the interior-point method (D-HIPM), where the primal-dual variables enter the computational complexity in a cubic fashion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21071v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kai Pfeiffer</dc:creator>
    </item>
    <item>
      <title>Yet Another Distributional Bellman Equation</title>
      <link>https://arxiv.org/abs/2505.21098</link>
      <description>arXiv:2505.21098v1 Announce Type: new 
Abstract: We consider non-standard Markov Decision Processes (MDPs) where the target function is not only a simple expectation of the accumulated reward. Instead, we consider rather general functionals of the joint distribution of terminal state and accumulated reward which have to be optimized. For finite state and compact action space, we show how to solve these problems by defining a lifted MDP whose state space is the space of distributions over the true states of the process. We derive a Bellman equation in this setting, which can be considered as a distributional Bellman equation. Well-known cases like the standard MDP and quantile MDPs are shown to be special examples of our framework. We also apply our model to a variant of an optimal transport problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21098v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicole B\"auerle, Tamara G\"oll, Anna Ja\'skiewicz</dc:creator>
    </item>
    <item>
      <title>Solving a linear program via a single unconstrained minimization</title>
      <link>https://arxiv.org/abs/2505.21232</link>
      <description>arXiv:2505.21232v1 Announce Type: new 
Abstract: This paper proposes a novel approach for solving linear programs. We reformulate a primal-dual linear program as an unconstrained minimization of a convex and twice continuously differentiable merit function. When the optimal set of the primal-dual pair is nonempty, its optimal set is equal to the optimal set of the proposed merit function. Minimizing this merit function poses some challenges due to its Hessian being singular at some points in the domain, including the optimal solutions. We handle singular Hessians using the Newton method with Levenberg-Marquardt regularization. We show that the Newton method with Levenberg-Marquardt regularization yields global convergence to a solution of the primal-dual linear program in at most $O(\epsilon^{-3/2})$ iterations requiring only the assumption that the optimal set of the primal-dual linear program is bounded. Testing on random synthetic problems demonstrates convergence to optimal solutions to very high accuracy, significantly faster than the derived worst-case bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21232v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adilet Otemissov, Alina Abdikarimova</dc:creator>
    </item>
    <item>
      <title>Sample complexity of optimal transport barycenters with discrete support</title>
      <link>https://arxiv.org/abs/2505.21274</link>
      <description>arXiv:2505.21274v1 Announce Type: new 
Abstract: Computational implementation of optimal transport barycenters for a set of target probability measures requires a form of approximation, a widespread solution being empirical approximation of measures. We provide an $O(\sqrt{N/n})$ statistical generalization bounds for the empirical sparse optimal transport barycenters problem, where $N$ is the maximum cardinality of the barycenter (sparse support) and $n$ is the sample size of the target measures empirical approximation. Our analysis includes various optimal transport divergences including Wasserstein, Sinkhorn and Sliced-Wasserstein. We discuss the application of our result to specific settings including K-means, constrained K-means, free and fixed support Wasserstein barycenters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21274v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>L\'eo Portales, Edouard Pauwels, Elsa Cazelles</dc:creator>
    </item>
    <item>
      <title>Dual Averaging Converges for Nonconvex Smooth Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2505.21394</link>
      <description>arXiv:2505.21394v1 Announce Type: new 
Abstract: Dual averaging and gradient descent with their stochastic variants stand as the two canonical recipe books for first-order optimization: Every modern variant can be viewed as a descendant of one or the other. In the convex regime, these algorithms have been deeply studied, and we know that they are essentially equivalent in terms of theoretical guarantees. On the other hand, in the non-convex setting, the situation is drastically different: While we know that SGD can minimize the gradient of non-convex smooth functions, no finite-time complexity guarantee for Stochastic Dual Averaging (SDA) was known in the same setting. In this paper, we close this gap by a reduction that views SDA as SGD applied to a sequence of implicitly regularized objectives. We show that a tuned SDA exhibits a rate of convergence $\mathcal{O}(1 / T + \sigma \log T/ \sqrt{T})$, similar to that of SGD under the same assumptions. To our best knowledge, this is the first complete convergence theory for dual averaging on non-convex smooth stochastic problems without restrictive assumptions, closing a long-standing open problem in the field. Beyond the base algorithm, we also discuss ADA-DA, a variant that marries SDA with AdaGrad's auto-scaling, which achieves the same rate without requiring knowledge of the noise variance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21394v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tuo Liu, El Mehdi Saad, Wojciech Kot{\l}owski, Francesco Orabona</dc:creator>
    </item>
    <item>
      <title>Second domain variation for a product of domain functionals</title>
      <link>https://arxiv.org/abs/2505.20307</link>
      <description>arXiv:2505.20307v2 Announce Type: cross 
Abstract: The second domain variation of the $p$-capacity and the $q$ - torsional rigidity for compact sets in $R^d, d\geq3$ with $1&lt;p&lt;d$ is computed. Conditions on $p$ and $q&gt;1$ are given such that the ball is a local minimzer or maximizer of the product.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20307v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alfred Wagner</dc:creator>
    </item>
    <item>
      <title>Byzantine-Resilient Distributed P2P Energy Trading via Spatial-Temporal Anomaly Detection</title>
      <link>https://arxiv.org/abs/2505.20567</link>
      <description>arXiv:2505.20567v1 Announce Type: cross 
Abstract: Distributed peer-to-peer (P2P) energy trading mandates an escalating coupling between the physical power network and communication network, necessitating high-frequency sharing of real-time data among prosumers. However, this data-sharing scheme renders the system vulnerable to various malicious behaviors, as Byzantine agents can initiate cyberattacks by injecting sophisticated false data. To better investigate the impacts of malicious Byzantine faults, this paper develops a fully distributed P2P energy trading model by accounting for the high-fidelity physical network constraints. To further detect Byzantine faults and mitigate their impacts on distributed P2P energy trading problem, we propose an online spatial-temporal anomaly detection approach by leveraging the tensor learning method, which is informed by the domain knowledge to enable awesome detection performance. Moreover, to enhance its computational efficiency, we further develop closed-form solutions for the proposed detection approach. Subsequently, we derive theoretical conditions for guaranteeing optimality and convergence of the distributed P2P energy trading problem with anomaly detection mechanisms. Results from numerical simulations validate the effectiveness, optimality, and scalability of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20567v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TSG.2025.3569688</arxiv:DOI>
      <arxiv:journal_reference>Junhong Liu, Qinfei Long, Rong-Peng Liu, Wenjie Liu, and Yunhe Hou. "Byzantine-Resilient Distributed P2P Energy Trading via Spatial-Temporal Anomaly Detection." IEEE Transactions on Smart Grid (2025)</arxiv:journal_reference>
      <dc:creator>Junhong Liu, Qinfei Long, Rong-Peng Liu, Wenjie Liu, Yunhe Hou</dc:creator>
    </item>
    <item>
      <title>Privacy-Preserving Peer-to-Peer Energy Trading via Hybrid Secure Computations</title>
      <link>https://arxiv.org/abs/2505.20577</link>
      <description>arXiv:2505.20577v1 Announce Type: cross 
Abstract: The massive integration of uncertain distributed renewable energy resources into power systems raises power imbalance concerns. Peer-to-peer (P2P) energy trading provides a promising way to balance the prosumers' volatile energy power generation and demands locally. Particularly, to protect the privacy of prosumers, distributed P2P energy trading is broadly advocated. However, severe privacy leakage issues can emerge in the realistic fully distributed P2P energy trading paradigm. Meanwhile, in this paradigm, two-party and multi-party computations coexist, challenging the naive privacy-preserving techniques. To tackle privacy leakage issues arising from the fully distributed P2P energy trading, this paper proposes a privacy-preserving approach via hybrid secure computations. A secure multi-party computation mechanism consisting of offline and online phases is developed to ensure the security of shared data by leveraging the tailored secret sharing method. In addition, the Paillier encryption method based on the Chinese Remainder Theorem is proposed for both the secure two-party computation and the offline phase of the multi-party computation. The random encryption coefficient is designed to enhance the security of the two-party computation and simultaneously guarantee the convergence of the distributed optimization. The feasible range for the encryption coefficient is derived with a strict mathematical proof. Numerical simulations demonstrate the exactness, effectiveness, and scalability of the proposed privacy-preserving approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20577v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TSG.2023.3293549</arxiv:DOI>
      <arxiv:journal_reference>Junhong Liu, Qinfei Long, Rong-Peng Liu, Wenjie Liu, Xin Cui, and Yunhe Hou. "Privacy-preserving peer-to-peer energy trading via hybrid secure computations." IEEE Transactions on Smart Grid 15, no. 2 (2023): 1951-1964</arxiv:journal_reference>
      <dc:creator>Junhong Liu, Qinfei Long, Rong-Peng Liu, Wenjie Liu, Xin Cui, Yunhe Hou</dc:creator>
    </item>
    <item>
      <title>Position: Adopt Constraints Over Penalties in Deep Learning</title>
      <link>https://arxiv.org/abs/2505.20628</link>
      <description>arXiv:2505.20628v1 Announce Type: cross 
Abstract: Recent efforts toward developing trustworthy AI systems with accountability guarantees have led to a growing reliance on machine learning formulations that incorporate external requirements, or constraints. These requirements are often enforced through penalization--adding fixed-weight terms to the task loss. We argue that this approach is ill-suited, and that tailored constrained optimization methods should be adopted instead. In particular, no penalty coefficient may yield a solution that both satisfies the constraints and achieves good performance--i.e., one solving the constrained problem. Moreover, tuning these coefficients is costly, incurring significant time and computational overhead. In contrast, tailored constrained methods--such as the Lagrangian approach, which optimizes the penalization "coefficients" (the Lagrange multipliers) alongside the model--(i) truly solve the constrained problem and add accountability, (ii) eliminate the need for extensive penalty tuning, and (iii) integrate seamlessly with modern deep learning pipelines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20628v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Ramirez, Meraj Hashemizadeh, Simon Lacoste-Julien</dc:creator>
    </item>
    <item>
      <title>A reinforcement learning agent for maintenance of deteriorating systems with increasingly imperfect repairs</title>
      <link>https://arxiv.org/abs/2505.20725</link>
      <description>arXiv:2505.20725v1 Announce Type: cross 
Abstract: Efficient maintenance has always been essential for the successful application of engineering systems. However, the challenges to be overcome in the implementation of Industry 4.0 necessitate new paradigms of maintenance optimization. Machine learning techniques are becoming increasingly used in engineering and maintenance, with reinforcement learning being one of the most promising. In this paper, we propose a gamma degradation process together with a novel maintenance model in which repairs are increasingly imperfect, i.e., the beneficial effect of system repairs decreases as more repairs are performed, reflecting the degradational behavior of real-world systems. To generate maintenance policies for this system, we developed a reinforcement-learning-based agent using a Double Deep Q-Network architecture. This agent presents two important advantages: it works without a predefined preventive threshold, and it can operate in a continuous degradation state space. Our agent learns to behave in different scenarios, showing great flexibility. In addition, we performed an analysis of how changes in the main parameters of the environment affect the maintenance policy proposed by the agent. The proposed approach is demonstrated to be appropriate and to significatively improve long-run cost as compared with other common maintenance strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20725v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ress.2024.110466</arxiv:DOI>
      <arxiv:journal_reference>Reliability Engineering &amp; System Safety, published December 2024</arxiv:journal_reference>
      <dc:creator>Alberto Pliego Marug\'an, Jes\'us M. Pinar-P\'erez, Fausto Pedro Garc\'ia M\'arquez</dc:creator>
    </item>
    <item>
      <title>Some optimal control and shape optimisation problems for bulk-surface cooperative systems</title>
      <link>https://arxiv.org/abs/2505.20865</link>
      <description>arXiv:2505.20865v1 Announce Type: cross 
Abstract: The goal of this paper is to address some optimal control and shape optimisation problems arising from bulk-surface cooperative systems. The basic model under consideration is the following: letting $\Omega$ be a fixed domain, we assume that a population (with density $u$) lives inside $\Omega$ and can access some resources $f$, while a second population (with density $v$) lives on the boundary $\partial \Omega$ and can access other resources $g$. These two populations are coupled in a cooperative manner by a constant exchange rate at the boundary, leading to a non-standard PDE system that has already been studied in previous works by Bogosel, Giletti and Tellini, for its connection with road-field models. Building on the considerations of the aforementioned previous works, we have two main objectives here: first, investigate the question of optimal resources distribution inside the domain $\Omega$ and on the surface $\partial \Omega$, i.e. how to spread resources in order to guarantee an optimal survival of the two species. We establish rigid Talenti inequalities and comparison results when $\Omega$ is a ball, extending in particular the results of J. J. Langford on symmetrisation for Neumann and Robin problems. Second, when the resources distribution $f$ and $g$ are constant, we provide a partial analysis of the natural shape optimisation problem: which shape $\Omega$ maximises the survival rate of the two species? Namely, we show that in certain regimes there can be no optimal shape and, by computing second-order shape derivatives, we investigate the local optimality of the ball.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20865v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Gentile, Idriss Mazari-Fouquer, Rapha\"el Prunier</dc:creator>
    </item>
    <item>
      <title>Efficient Spectral Control of Partially Observed Linear Dynamical Systems</title>
      <link>https://arxiv.org/abs/2505.20943</link>
      <description>arXiv:2505.20943v1 Announce Type: cross 
Abstract: We propose a new method for the problem of controlling linear dynamical systems under partial observation and adversarial disturbances. Our new algorithm, Double Spectral Control (DSC), matches the best known regret guarantees while exponentially improving runtime complexity over previous approaches in its dependence on the system's stability margin. Our key innovation is a two-level spectral approximation strategy, leveraging double convolution with a universal basis of spectral filters, enabling efficient and accurate learning of the best linear dynamical controllers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20943v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anand Brahmbhatt, Gon Buzaglo, Sofiia Druchyna, Elad Hazan</dc:creator>
    </item>
    <item>
      <title>Federated Instrumental Variable Analysis via Federated Generalized Method of Moments</title>
      <link>https://arxiv.org/abs/2505.21012</link>
      <description>arXiv:2505.21012v1 Announce Type: cross 
Abstract: Instrumental variables (IV) analysis is an important applied tool for areas such as healthcare and consumer economics. For IV analysis in high-dimensional settings, the Generalized Method of Moments (GMM) using deep neural networks offers an efficient approach. With non-i.i.d. data sourced from scattered decentralized clients, federated learning is a popular paradigm for training the models while promising data privacy. However, to our knowledge, no federated algorithm for either GMM or IV analysis exists to date. In this work, we introduce federated instrumental variables analysis (FedIV) via federated generalized method of moments (FedGMM). We formulate FedGMM as a federated zero-sum game defined by a federated non-convex non-concave minimax optimization problem, which is solved using federated gradient descent ascent (FedGDA) algorithm. One key challenge arises in theoretically characterizing the federated local optimality. To address this, we present properties and existence results of clients' local equilibria via FedGDA limit points. Thereby, we show that the federated solution consistently estimates the local moment conditions of every participating client. The proposed algorithm is backed by extensive experiments to demonstrate the efficacy of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21012v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator> Geetika, Somya Tyagi, Bapi Chatterjee</dc:creator>
    </item>
    <item>
      <title>Collision Probability Estimation for Optimization-based Vehicular Motion Planning</title>
      <link>https://arxiv.org/abs/2505.21161</link>
      <description>arXiv:2505.21161v1 Announce Type: cross 
Abstract: Many motion planning algorithms for automated driving require estimating the probability of collision (POC) to account for uncertainties in the measurement and estimation of the motion of road users. Common POC estimation techniques often utilize sampling-based methods that suffer from computational inefficiency and a non-deterministic estimation, i.e., each estimation result for the same inputs is slightly different. In contrast, optimization-based motion planning algorithms require computationally efficient POC estimation, ideally using deterministic estimation, such that typical optimization algorithms for motion planning retain feasibility. Estimating the POC analytically, however, is challenging because it depends on understanding the collision conditions (e.g., vehicle's shape) and characterizing the uncertainty in motion prediction. In this paper, we propose an approach in which we estimate the POC between two vehicles by over-approximating their shapes by a multi-circular shape approximation. The position and heading of the predicted vehicle are modelled as random variables, contrasting with the literature, where the heading angle is often neglected. We guarantee that the provided POC is an over-approximation, which is essential in providing safety guarantees, and present a computationally efficient algorithm for computing the POC estimate for Gaussian uncertainty in the position and heading. This algorithm is then used in a path-following stochastic model predictive controller (SMPC) for motion planning. With the proposed algorithm, the SMPC generates reproducible trajectories while the controller retains its feasibility in the presented test cases and demonstrates the ability to handle varying levels of uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21161v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leon Tolksdorf, Arturo Tejada, Christian Birkner, Nathan van de Wouw</dc:creator>
    </item>
    <item>
      <title>Input Convex Kolmogorov Arnold Networks</title>
      <link>https://arxiv.org/abs/2505.21208</link>
      <description>arXiv:2505.21208v1 Announce Type: cross 
Abstract: This article presents an input convex neural network architecture using Kolmogorov-Arnold networks (ICKAN). Two specific networks are presented: the first is based on a low-order, linear-by-part, representation of functions, and a universal approximation theorem is provided. The second is based on cubic splines, for which only numerical results support convergence. We demonstrate on simple tests that these networks perform competitively with classical input convex neural networks (ICNNs). In a second part, we use the networks to solve some optimal transport problems needing a convex approximation of functions and demonstrate their effectiveness. Comparisons with ICNNs show that cubic ICKANs produce results similar to those of classical ICNNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21208v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Deschatre, Xavier Warin</dc:creator>
    </item>
    <item>
      <title>Output Regulation of Linear Systems with Non-periodic Non-smooth Exogenous Signals</title>
      <link>https://arxiv.org/abs/2505.21209</link>
      <description>arXiv:2505.21209v1 Announce Type: cross 
Abstract: We address the output regulation problem of linear systems with non-smooth and non-periodic exogenous signals. Specifically, we first formulate and solve the full-information problem by designing a state-feedback controller. We study the solvability of the regulator equations, providing a new non-resonance condition. We then focus on the error-feedback problem, for which we design a (non-robust) internal model leveraging the concept of canonical realisation and applying a high-gain method for the stabilisation of the closed-loop system under the minimum-phase assumption. Finally, we study the regulation problem involving model parameter uncertainties. Drawing ideas from both hybrid and time-varying (smooth) output regulation, we propose two methods to establish an internal model that is robust to uncertainties. The first method is an extension of the hybrid internal model, while the second relies on a new concept of immersion. In this non-smooth case, the immersion is established based on integrals rather than derivatives. The effectiveness of the proposed solutions is illustrated by a circuit regulation example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21209v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zirui Niu, Daniele Astolfi, Giordano Scarciotti</dc:creator>
    </item>
    <item>
      <title>LoFT: Low-Rank Adaptation That Behaves Like Full Fine-Tuning</title>
      <link>https://arxiv.org/abs/2505.21289</link>
      <description>arXiv:2505.21289v1 Announce Type: cross 
Abstract: Large pre-trained models are commonly adapted to downstream tasks using parameter-efficient fine-tuning methods such as Low-Rank Adaptation (LoRA), which injects small trainable low-rank matrices instead of updating all weights. While LoRA dramatically reduces trainable parameters with little overhead, it can still underperform full fine-tuning in accuracy and often converges more slowly. We introduce LoFT, a novel low-rank adaptation method that behaves like full fine-tuning by aligning the optimizer's internal dynamics with those of updating all model weights. LoFT not only learns weight updates in a low-rank subspace (like LoRA) but also properly projects the optimizer's first and second moments (Adam's momentum and variance) into the same subspace, mirroring full-model updates. By aligning the low-rank update itself with the full update, LoFT eliminates the need for tuning extra hyperparameters, e.g., LoRA scaling factor $\alpha$. Empirically, this approach substantially narrows the performance gap between adapter-based tuning and full fine-tuning and consistently outperforms standard LoRA-style methods, all without increasing inference cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21289v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nurbek Tastan, Stefanos Laskaridis, Martin Takac, Karthik Nandakumar, Samuel Horvath</dc:creator>
    </item>
    <item>
      <title>Joint Learning in the Gaussian Single Index Model</title>
      <link>https://arxiv.org/abs/2505.21336</link>
      <description>arXiv:2505.21336v1 Announce Type: cross 
Abstract: We consider the problem of jointly learning a one-dimensional projection and a univariate function in high-dimensional Gaussian models. Specifically, we study predictors of the form $f(x)=\varphi^\star(\langle w^\star, x \rangle)$, where both the direction $w^\star \in \mathcal{S}_{d-1}$, the sphere of $\mathbb{R}^d$, and the function $\varphi^\star: \mathbb{R} \to \mathbb{R}$ are learned from Gaussian data. This setting captures a fundamental non-convex problem at the intersection of representation learning and nonlinear regression. We analyze the gradient flow dynamics of a natural alternating scheme and prove convergence, with a rate controlled by the information exponent reflecting the \textit{Gaussian regularity} of the function $\varphi^\star$. Strikingly, our analysis shows that convergence still occurs even when the initial direction is negatively correlated with the target. On the practical side, we demonstrate that such joint learning can be effectively implemented using a Reproducing Kernel Hilbert Space (RKHS) adapted to the structure of the problem, enabling efficient and flexible estimation of the univariate function. Our results offer both theoretical insight and practical methodology for learning low-dimensional structure in high-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21336v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Loucas Pillaud-Vivien, Adrien Schertzer</dc:creator>
    </item>
    <item>
      <title>Distributed equilibrium seeking in aggregative games: linear convergence under singular perturbations lens</title>
      <link>https://arxiv.org/abs/2505.21386</link>
      <description>arXiv:2505.21386v1 Announce Type: cross 
Abstract: We present a fully-distributed algorithm for Nash equilibrium seeking in aggregative games over networks. The proposed scheme endows each agent with a gradient-based scheme equipped with a tracking mechanism to locally reconstruct the aggregative variable, which is not available to the agents. We show that our method falls into the framework of singularly perturbed systems, as it involves the interconnection between a fast subsystem - the global information reconstruction dynamics - with a slow one concerning the optimization of the local strategies. This perspective plays a key role in analyzing the scheme with a constant stepsize, and in proving its linear convergence to the Nash equilibrium in strongly monotone games with local constraints. By exploiting the flexibility of our aggregative variable definition (not necessarily the arithmetic average of the agents' strategy), we show the efficacy of our algorithm on a realistic voltage support case study for the smart grid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21386v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/CDC56724.2024.10886119</arxiv:DOI>
      <arxiv:journal_reference>2024 IEEE 63rd Conference on Decision and Control (CDC), Milan, Italy, 2024, pp. 3918-3923</arxiv:journal_reference>
      <dc:creator>Guido Carnevale, Filippo Fabiani, Filiberto Fele, Kostas Margellos, Giuseppe Notarstefano</dc:creator>
    </item>
    <item>
      <title>A generalized global Hartman-Grobman theorem for asymptotically stable semiflows</title>
      <link>https://arxiv.org/abs/2505.21401</link>
      <description>arXiv:2505.21401v1 Announce Type: cross 
Abstract: We extend the generalized global Hartman-Grobman theorem by Kvalheim and Sontag for flows to a case of asymptotically stable semiflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21401v1</guid>
      <category>math.DS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wouter Jongeneel</dc:creator>
    </item>
    <item>
      <title>Dual Natural Gradient Descent for Scalable Training of Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2505.21404</link>
      <description>arXiv:2505.21404v1 Announce Type: cross 
Abstract: Natural-gradient methods markedly accelerate the training of Physics-Informed Neural Networks (PINNs), yet their Gauss--Newton update must be solved in the parameter space, incurring a prohibitive $O(n^3)$ time complexity, where $n$ is the number of network trainable weights. We show that exactly the same step can instead be formulated in a generally smaller residual space of size $m = \sum_{\gamma} N_{\gamma} d_{\gamma}$, where each residual class $\gamma$ (e.g. PDE interior, boundary, initial data) contributes $N_{\gamma}$ collocation points of output dimension $d_{\gamma}$.
  Building on this insight, we introduce \textit{Dual Natural Gradient Descent} (D-NGD). D-NGD computes the Gauss--Newton step in residual space, augments it with a geodesic-acceleration correction at negligible extra cost, and provides both a dense direct solver for modest $m$ and a Nystrom-preconditioned conjugate-gradient solver for larger $m$.
  Experimentally, D-NGD scales second-order PINN optimization to networks with up to 12.8 million parameters, delivers one- to three-order-of-magnitude lower final error $L^2$ than first-order methods (Adam, SGD) and quasi-Newton methods, and -- crucially -- enables natural-gradient training of PINNs at this scale on a single GPU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21404v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anas Jnini, Flavio Vella</dc:creator>
    </item>
    <item>
      <title>Optimal Mixed Strategy for Zero-Sum Differential Games</title>
      <link>https://arxiv.org/abs/2308.01144</link>
      <description>arXiv:2308.01144v2 Announce Type: replace 
Abstract: Solving zero-sum differential games (ZSDGs) under mixed strategies has been challenging for decades. Existing research mainly focuses on characterizing the value function, while the problem of solving optimal mixed strategies remains open. To address this issue, we propose a novel weak-approximation-based method to solve ZSDGs under mixed strategies. The key idea is to design an SDG under pure strategies that closely approximates the original game under mixed strategies, ensuring that both the state distributions and cost expectations remain nearly identical over the entire time horizon. Based on the solution of this SDG, the value function under mixed strategies can be approximated with a certified approximation error. In addition, near-optimal mixed strategies can be designed with certified suboptimality gaps. We further apply this method to a class of ZSDGs with control-affine dynamics and quadratic costs, demonstrating that the value approximation error is of order $O(\bar{\pi})$ and the strategy suboptimality gap is of order $O(\bar{\pi})$ with respect to the maximum commitment delay $\bar{\pi}$. Numerical examples are provided to illustrate and validate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.01144v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tao Xu, Wang Xi, Jianping He</dc:creator>
    </item>
    <item>
      <title>The Global R-linear Convergence of Nesterov's Accelerated Gradient Method with Unknown Strongly Convex Parameter</title>
      <link>https://arxiv.org/abs/2308.14080</link>
      <description>arXiv:2308.14080v3 Announce Type: replace 
Abstract: The Nesterov accelerated gradient (NAG) method is an important extrapolation-based numerical algorithm that accelerates the convergence of the gradient descent method in convex optimization. When dealing with an objective function that is $\mu$-strongly convex, selecting extrapolation coefficients dependent on $\mu$ enables global R-linear convergence. In cases where $\mu$ is unknown, a commonly adopted approach is to set the extrapolation coefficient using the original NAG method. This choice allows for achieving the optimal iteration complexity among first-order methods for general convex problems. However, it remains unknown whether the NAG method with an unknown strongly convex parameter exhibits global R-linear convergence for strongly convex problems. In this work, we answer this question positively by establishing the Q-linear convergence of certain constructed Lyapunov sequences. Furthermore, we extend our result to the global R-linear convergence of the accelerated proximal gradient method, which is employed for solving strongly convex composite optimization problems. Interestingly, these results contradict the findings of the continuous counterpart of the NAG method in [Su, Boyd, and Cand\'es, J. Mach. Learn. Res., 2016, 17(153), 1-43], where the convergence rate by the suggested ordinary differential equation cannot exceed the $O(1/{\tt poly}(k))$ for strongly convex functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.14080v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenglong Bao, Liang Chen, Jiahong Li</dc:creator>
    </item>
    <item>
      <title>Distributionally robust optimization through the lens of submodularity</title>
      <link>https://arxiv.org/abs/2312.04890</link>
      <description>arXiv:2312.04890v2 Announce Type: replace 
Abstract: Distributionally robust optimization is used to tackle decision making problems under uncertainty where the distribution of the uncertain data is ambiguous. Many ambiguity sets have been proposed for continuous uncertainty that build on convexity and for which the resulting formulations scale polynomially in the number of random variables. However fewer ambiguity sets have been proposed for discrete uncertainty where the exact formulations scale polynomially in the number of random variables. Towards this, we define a submodular ambiguity set and showcase its expressive power in modeling both discrete and continuous uncertainty. With discrete uncertainty, we show that a class of distributionally robust optimization problems is solvable in polynomial time by viewing it through the lens of submodularity. With continuous uncertainty, we show that it is solvable approximately up to an additive error in pseudo-polynomial time. We then focus on a specific class of submodular ambiguity sets where univariate marginal information and bivariate dependence information on the random vector is specified and provide an exact reformulation as a polynomial sized linear program when the uncertainty is discrete and as a polynomial sized semidefinite program when the uncertainty is continuous. We provide numerical evidence of the modeling flexibility and expressive power of the submodular ambiguity set and demonstrate its applicability in two examples: project networks and multi-newsvendor problems. The paper highlights that the submodular ambiguity set is the natural discrete counterpart of the convex ambiguity set and supplements it for continuous uncertainty, both in modeling and computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.04890v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Karthik Natarajan, Divya Padmanabhan, Arjun Ramachandra</dc:creator>
    </item>
    <item>
      <title>An Inexact Halpern Iteration with Application to Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2402.06033</link>
      <description>arXiv:2402.06033v3 Announce Type: replace 
Abstract: The Halpern iteration for solving monotone inclusion problems has gained increasing interests in recent years due to its simple form and appealing convergence properties. In this paper, we investigate the inexact variants of the scheme in both deterministic and stochastic settings. We conduct extensive convergence analysis and show that by choosing the inexactness tolerances appropriately, the inexact schemes admit an $O(k^{-1})$ convergence rate in terms of the (expected) residue norm. Our results relax the state-of-the-art inexactness conditions employed in the literature while sharing the same competitive convergence properties. We then demonstrate how the proposed methods can be applied for solving two classes of data-driven Wasserstein distributionally robust optimization problems that admit convex-concave min-max optimization reformulations. We highlight its capability of performing inexact computations for distributionally robust learning with stochastic first-order methods and for general nonlinear convex-concave loss functions, which are competitive in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06033v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ling Liang, Zusen Xu, Kim-Chuan Toh, Jia-Jie Zhu</dc:creator>
    </item>
    <item>
      <title>On existence of solutions to non-convex minimization problems</title>
      <link>https://arxiv.org/abs/2405.04688</link>
      <description>arXiv:2405.04688v3 Announce Type: replace 
Abstract: We provide a unified framework for a systematic analysis of the existence of solutions to general nonconvex problems, relying on asymptotic and retractive cones for functions and sets. Using this framework we develop new necessary and sufficient conditions for the existence of solutions to a general problem of minimizing a proper closed function over a closed, possibly unbounded, set. Towards the result, we introduce cones of retractive directions for a set and a function, establishing some basic properties for them. We also investigate the relationships between the cone of retractive directions of a function and the cone of level sets of the function. Using the cones of retractive directions we provide necessary and sufficient conditions for the existence of solutions that require an asymptotically bounded decay of a function, and a relation between the cones of retractive directions of the constraint set and the asymptotic cone of the objective function. Finally we refine these conditions for more structured problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04688v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rohan Rele, Angelia Nedich</dc:creator>
    </item>
    <item>
      <title>Policy Iteration for Exploratory Hamilton--Jacobi--Bellman Equations</title>
      <link>https://arxiv.org/abs/2406.00612</link>
      <description>arXiv:2406.00612v4 Announce Type: replace 
Abstract: We study the policy iteration algorithm (PIA) for entropy-regularized stochastic control problems on an infinite time horizon with a large discount rate, focusing on two main scenarios. First, we analyze PIA with bounded coefficients where the controls applied to the diffusion term satisfy a smallness condition. We demonstrate the convergence of PIA based on a uniform $\mathcal{C}^{2,\alpha}$ estimate for the value sequence generated by PIA, and provide a quantitative convergence analysis for this scenario. Second, we investigate PIA with unbounded coefficients but no control over the diffusion term. In this scenario, we first provide the well-posedness of the exploratory Hamilton--Jacobi--Bellman equation with linear growth coefficients and polynomial growth reward function. By such a well-posedess result we achieve PIA's convergence by establishing a quantitative locally uniform $\mathcal{C}^{1,\alpha}$ estimates for the generated value sequence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00612v4</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hung Vinh Tran, Zhenhua Wang, Yuming Paul Zhang</dc:creator>
    </item>
    <item>
      <title>Convergence of machine learning methods for feedback control laws: averaged feedback learning scheme and data driven methods</title>
      <link>https://arxiv.org/abs/2407.18403</link>
      <description>arXiv:2407.18403v3 Announce Type: replace 
Abstract: This work addresses the synthesis of optimal feedback control laws via machine learning. In particular, the Averaged Feedback Learning Scheme (AFLS) and a data driven method are considered. Hypotheses for each method ensuring the convergence of the evaluation of the objective function of the underlying control problem at the obtained feedback-laws towards the optimal value function are provided. These hypotheses are connected to the regularity of the value function and the stability of the dynamics. In the case of AFLS these hypotheses only require H\"older continuity of the value function, whereas for the data driven method the value function must be at least $C^2$. It is demonstrated that these methods are connected via their optimality conditions. Additionally, numerical experiments are provided by applying both methods to a family control problems, parameterized by a positive real number which controls the regularity of the value function. For small parameters the value function is smooth and in contrast for large parameters it is non-differentiable, but semi-concave. The results of the experiments indicate that both methods have a similar performance for the case that the value function is smooth. On the other hand, if the value function is not differentiable, AFLS has a better performance which is consistent with the obtained convergence results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18403v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karl Kunisch, Donato V\'asquez-Varas</dc:creator>
    </item>
    <item>
      <title>Adaptive Backtracking Line Search</title>
      <link>https://arxiv.org/abs/2408.13150</link>
      <description>arXiv:2408.13150v2 Announce Type: replace 
Abstract: Backtracking line search is foundational in numerical optimization. The basic idea is to adjust the step-size of an algorithm by a constant factor until some chosen criterion (e.g. Armijo, Descent Lemma) is satisfied. We propose a novel way to adjust step-sizes, replacing the constant factor used in regular backtracking with one that takes into account the degree to which the chosen criterion is violated, with no additional computational burden. This light-weight adjustment leads to significantly faster optimization, which we confirm by performing a variety of experiments on over fifteen real world datasets. For convex problems, we prove adaptive backtracking requires no more adjustments to produce a feasible step-size than regular backtracking does. For nonconvex smooth problems, we prove adaptive backtracking enjoys the same guarantees of regular backtracking. Furthermore, we prove adaptive backtracking preserves the convergence rates of gradient descent and its accelerated variant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13150v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joao V. Cavalcanti, Laurent Lessard, Ashia C. Wilson</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2411.02549</link>
      <description>arXiv:2411.02549v3 Announce Type: replace 
Abstract: Distributionally robust optimization (DRO) studies decision problems under uncertainty where the probability distribution governing the uncertain problem parameters is itself uncertain. A key component of any DRO model is its ambiguity set, that is, a family of probability distributions consistent with any available structural or statistical information. DRO seeks decisions that perform best under the worst distribution in the ambiguity set. This worst case criterion is supported by findings in psychology and neuroscience, which indicate that many decision-makers have a low tolerance for distributional ambiguity. DRO is rooted in statistics, operations research and control theory, and recent research has uncovered its deep connections to regularization techniques and adversarial training in machine learning. This survey presents the key findings of the field in a unified and self-contained manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02549v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Kuhn, Soroosh Shafiee, Wolfram Wiesemann</dc:creator>
    </item>
    <item>
      <title>On the Almost Sure Convergence of the Stochastic Three Points Algorithm</title>
      <link>https://arxiv.org/abs/2501.13886</link>
      <description>arXiv:2501.13886v4 Announce Type: replace 
Abstract: The stochastic three points (STP) algorithm is a derivative-free optimization technique designed for unconstrained optimization problems in $\mathbb{R}^d$. In this paper, we analyze this algorithm for three classes of functions: smooth functions that may lack convexity, smooth convex functions, and smooth functions that are strongly convex. Our work provides the first almost sure convergence results of the STP algorithm, alongside some convergence results in expectation. For the class of smooth functions, we establish that the best gradient iterate of the STP algorithm converges almost surely to zero at a rate of $o(1/{T^{\frac{1}{2}-\epsilon}})$ for any $\epsilon\in (0,\frac{1}{2})$, where $T$ is the number of iterations. Furthermore, within the same class of functions, we establish both almost sure convergence and convergence in expectation of the final gradient iterate towards zero. For the class of smooth convex functions, we establish that $f(\theta^T)$ converges to $\inf_{\theta \in \mathbb{R}^d} f(\theta)$ almost surely at a rate of $o(1/{T^{1-\epsilon}})$ for any $\epsilon\in (0,1)$, and in expectation at a rate of $O(\frac{d}{T})$ where $d$ is the dimension of the space. Finally, for the class of smooth functions that are strongly convex, we establish that when step sizes are obtained by approximating the directional derivatives of the function, $f(\theta^T)$ converges to $\inf_{\theta \in \mathbb{R}^d} f(\theta)$ in expectation at a rate of $O((1-\frac{\mu}{2\pi dL})^T)$, and almost surely at a rate of $o((1-s\frac{\mu}{2\pi dL})^T)$ for any $s\in (0,1)$, where $\mu$ and $L$ are the strong convexity and smoothness parameters of the function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13886v4</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taha El Bakkali El Kadi, Omar Saadi</dc:creator>
    </item>
    <item>
      <title>A primal-dual interior point trust region method for second-order stationary points of Riemannian inequality-constrained optimization problems</title>
      <link>https://arxiv.org/abs/2501.15419</link>
      <description>arXiv:2501.15419v2 Announce Type: replace 
Abstract: We consider Riemannian inequality-constrained optimization problems. Such problems inherit the benefits of Riemannian approach developed in the unconstrained setting and naturally arise from applications in control, machine learning, and other fields. We propose a Riemannian primal-dual interior point trust region method (RIPTRM) for solving them. We prove its global convergence to an approximate Karush-Kuhn-Tucker point and a second-order stationary point. To the best of our knowledge, this is the first algorithm that incorporates the trust region strategy for constrained optimization on Riemannian manifolds, and has the second-order convergence property for optimization problems on Riemannian manifolds with nonlinear inequality constraints. We conduct numerical experiments in which we introduce a truncated conjugate gradient method and an eigenvalue-based subsolver for RIPTRM to approximately and exactly solve the trust region subproblems, respectively. Empirical results show that RIPTRMs find solutions with higher accuracy compared to an existing Riemannian interior point method and other algorithms. Additionally, we observe that RIPTRM with the exact search direction shows promising performance in an instance where the Hessian of the Lagrangian has a large negative eigenvalue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15419v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mitsuaki Obara, Takayuki Okuno, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Sign Operator for Coping with Heavy-Tailed Noise in Non-Convex Optimization: High Probability Bounds Under $(L_0, L_1)$-Smoothness</title>
      <link>https://arxiv.org/abs/2502.07923</link>
      <description>arXiv:2502.07923v2 Announce Type: replace 
Abstract: In recent years, non-convex optimization problems are more often described by generalized $(L_0, L_1)$-smoothness assumption rather than standard one. Meanwhile, severely corrupted data used in these problems has increased the demand for methods capable of handling heavy-tailed noises, i.e., noises with bounded $\kappa$-th moment. Motivated by these real-world trends and challenges, we explore sign-based methods in this setup and demonstrate their effectiveness in comparison with other popular solutions like clipping or normalization.
  In theory, we prove the first-known high probability convergence bounds under $(L_0, L_1)$-smoothness and heavy-tailed noises with mild parameter dependencies. In the case of standard smoothness, these bounds are novel for sign-based methods as well. In particular, SignSGD with batching achieves sample complexity $\tilde{O}\left(\left(\frac{\Delta L_0d}{\varepsilon^2} + \frac{\Delta L_1d^\frac{3}{2}}{\varepsilon}\right)\left[1 + \left(\frac{\sigma}{\varepsilon}\right)^\frac{\kappa}{\kappa-1}\right]\right), \kappa \in (1,2]$. Under the assumption of symmetric noises, SignSGD with Majority Voting can robustly work on the whole range of $\kappa \in (0,2]$ with complexity $\tilde{O}\left(\left(\frac{\Delta L_0d}{\varepsilon^2} + \frac{\Delta L_1d^\frac{3}{2}}{\varepsilon}\right)\left[\frac{1}{\kappa^2} + \frac{\sigma^2}{\varepsilon^2}\right]\right)$. We also obtain results for parameter-agnostic setups, Polyak-Lojasiewicz functions and momentum-based methods (in expectation). Our theoretical findings are supported by the superior performance of sign-based methods in training Large Language Models compared to clipping and normalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07923v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikita Kornilov, Philip Zmushko, Andrei Semenov, Mark Ikonnikov, Alexander Gasnikov, Alexander Beznosikov</dc:creator>
    </item>
    <item>
      <title>Hybrid Data-enabled Predictive Control: Incorporating model knowledge into the DeePC</title>
      <link>https://arxiv.org/abs/2502.12467</link>
      <description>arXiv:2502.12467v3 Announce Type: replace 
Abstract: Predictive control can either be data-based (e.g. data-enabled predictive control, or DeePC) or model-based (model predictive control). In this paper we aim to bridge the gap between the two by investigating the case where only a partial model is available, i.e. incorporating model knowledge into DeePC. This has potential advantages over a purely data-based approach in terms of noise and computational expense in some cases, as well as applications to certain linear time-varying and nonlinear systems. We formulate an approach to take advantage of partial model knowledge which we call hybrid data-enabled predictive control (HDeePC) and prove feasible set equivalence and equivalent closed-loop behavior in the noiseless, LTI case. Finally, two examples illustrate the potential of HDeePC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12467v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremy D. Watson</dc:creator>
    </item>
    <item>
      <title>On Optimal Control of Hybrid Dynamical Systems using Complementarity Constraints</title>
      <link>https://arxiv.org/abs/2503.03879</link>
      <description>arXiv:2503.03879v2 Announce Type: replace 
Abstract: Optimal control for switch-based dynamical systems is a challenging problem in the process control literature. In this study, we model these systems as hybrid dynamical systems with finite number of unknown switching points and reformulate them using non-smooth and non-convex complementarity constraints as a mathematical program with complementarity constraints (MPCC). We utilize a moving finite element based strategy to discretize the differential equation system to accurately locate the unknown switching points at the finite element boundary and achieve high-order accuracy at intermediate non-collocation points. We propose a globalization approach to solve the discretized MPCC problem using a mixed NLP/MILP-based strategy to converge to a non-spurious first-order optimal solution. The method is tested on three dynamic optimization examples, including a gas-liquid tank model and an optimal control problem with a sliding mode solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03879v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saif R. Kazi, Kexin Wang, Lorenz T. Biegler</dc:creator>
    </item>
    <item>
      <title>A Spectral Approach to Optimal Control of the Fokker-Planck Equation</title>
      <link>https://arxiv.org/abs/2503.15125</link>
      <description>arXiv:2503.15125v3 Announce Type: replace 
Abstract: In this paper, we present a spectral optimal control framework for Fokker-Planck equations based on the standard ground state transformation that maps the Fokker-Planck operator to a Schrodinger operator. Our primary objective is to accelerate convergence toward the (unique) steady state. To fulfill this objective, a gradient-based iterative algorithm with Pontryagin's maximum principle and the Barzilai-Borwein update is developed to compute time-dependent controls. Numerical experiments on two-dimensional ill-conditioned normal distributions and double-well potentials demonstrate that our approach effectively targets slow-decaying modes, thus increasing the spectral gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15125v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2025.3573604</arxiv:DOI>
      <dc:creator>Dante Kalise, Lucas M. Moschen, Grigorios A. Pavliotis, Urbain Vaes</dc:creator>
    </item>
    <item>
      <title>Extremum Seeking for Controlled Vibrational Stabilization of Second Order Mechanical Systems</title>
      <link>https://arxiv.org/abs/2504.04174</link>
      <description>arXiv:2504.04174v4 Announce Type: replace 
Abstract: This paper presents a novel extremum seeking control (ESC) approach for the vibrational stabilization of a class of mechanical systems (e.g., systems characterized by equations of motion resulting from Newton second law or Euler-Lagrange mechanics). Inspired by flapping insects mechanics, the proposed ESC approach is operable by only one perturbation signal and can admit generalized forces that are quadratic in velocities. We test our ESC, and compare it against approaches from literature, on some classical mechanical systems (e.g., mass-spring and an inverted pendulum systems). We also provide a novel, first-of-its-kind, application of the introduced ESC by achieving a 1D model-free source-seeking of a flapping system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04174v4</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed A. Elgohary, Sameh A. Eisa</dc:creator>
    </item>
    <item>
      <title>An Operator Splitting Method for Large-Scale CVaR-Constrained Quadratic Programs</title>
      <link>https://arxiv.org/abs/2504.10814</link>
      <description>arXiv:2504.10814v3 Announce Type: replace 
Abstract: We introduce a fast and scalable method for solving quadratic programs with conditional value-at-risk (CVaR) constraints. While these problems can be formulated as standard quadratic programs, the number of variables and constraints grows linearly with the number of scenarios, making general-purpose solvers impractical for large-scale problems. Our method combines operator splitting with a specialized $O(m\log m)$ algorithm for projecting onto CVaR constraints, where $m$ is the number of scenarios. The method alternates between solving a linear system and performing parallel projections: onto CVaR constraints using our specialized algorithm and onto box constraints with a closed-form solution. Numerical examples from several application domains demonstrate that our method outperforms general-purpose solvers by several orders of magnitude on problems with up to millions of scenarios. Our method is implemented in an open-source package called CVQP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10814v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Luxenberg, David P\'erez-Pi\~neiro, Steven Diamond, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>Computing Optimal Transport Plans via Min-Max Gradient Flows</title>
      <link>https://arxiv.org/abs/2504.16890</link>
      <description>arXiv:2504.16890v2 Announce Type: replace 
Abstract: We pose the Kantorovich optimal transport problem as a min-max problem with a Nash equilibrium that can be obtained dynamically via a two-player game, providing a framework for approximating optimal couplings. We prove convergence of the timescale-separated gradient descent dynamics to the optimal transport plan, and implement the gradient descent algorithm with a particle method, where the marginal constraints are enforced weakly using the KL divergence, automatically selecting a dynamical adaptation of the regularizer. The numerical results highlight the different advantages of using the standard Kullback-Leibler (KL) divergence versus the reverse KL divergence with this approach, opening the door for new methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16890v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lauren Conger, Franca Hoffmann, Ricardo Baptista, Eric Mazumdar</dc:creator>
    </item>
    <item>
      <title>Empathic network learning for multi-expert emergency decision-making under incomplete and inconsistent information</title>
      <link>https://arxiv.org/abs/2505.18009</link>
      <description>arXiv:2505.18009v2 Announce Type: replace 
Abstract: Challenges, such as a lack of information for emergency decision-making, time pressure, and limited knowledge of experts acting as decision-makers (DMs), can result in the generation of poor or inconsistent indirect information regarding DMs' preferences. Simultaneously, the empathic relationship represents a tangible social connection within the context of actual emergency decision-making, with the structure of the empathic network being a significant factor influencing the outcomes of the decision-making process. To deduce the empathic network underpinning the decision behaviors of DMs from incomplete and inconsistent preference information, we introduce an empathic network learning methodology rooted in the concept of robust ordinal regression via preference disaggregation. Firstly, we complete incomplete fuzzy judgment matrices including holistic preference information given in terms of decision examples on some reference alternatives, independently by each DM, and we calculate the intrinsic utilities of DMs. Secondly, we establish constraints for empathic network learning models based on empathic preference information and information about relations between some reference nodes. Then, the necessary and possible empathic relationships between any two DMs are calculated. Lastly, tailored to the specific requirements of different emergency scenarios, we design six target networks and construct models to derive the most representative empathic network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18009v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.inffus.2024.102844.</arxiv:DOI>
      <arxiv:journal_reference>Shen S, Gong Z, Zhou B, et al. Empathic network learning for multi-expert emergency decision-making under incomplete and inconsistent information[J]. Information Fusion, 2025, 117: 102844</arxiv:journal_reference>
      <dc:creator>Simin Shen, Zaiwu Gong, Bin Zhou, Roman S{\l}owi\'nski</dc:creator>
    </item>
    <item>
      <title>PDPO: Parametric Density Path Optimization</title>
      <link>https://arxiv.org/abs/2505.18473</link>
      <description>arXiv:2505.18473v2 Announce Type: replace 
Abstract: We introduce Parametric Density Path Optimization (PDPO), a novel method for computing action-minimizing paths between probability densities. The core idea is to represent the target probability path as the pushforward of a reference density through a parametric map, transforming the original infinite-dimensional optimization over densities to a finite-dimensional one over the parameters of the map. We derive a static formulation of the dynamic problem of action minimization and propose cubic spline interpolation of the path in parameter space to solve the static problem. Theoretically, we establish an error bound of the action under proper assumptions on the regularity of the parameter path. Empirically, we find that using 3-5 control points of the spline interpolation suffices to accurately resolve both multimodal and high-dimensional problems. We demonstrate that PDPO can flexibly accommodate a wide range of potential terms, including those modeling obstacles, mean-field interactions, stochastic control, and higher-order dynamics. Our method outperforms existing state-of-the-art approaches in benchmark tasks, demonstrating superior computational efficiency and solution quality. The source code will be publically available after the revision process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18473v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Gutierrez Hernandez, Peng Chen, Haomin Zhou</dc:creator>
    </item>
    <item>
      <title>Sequential Resource Trading Using Comparison-Based Gradient Estimation</title>
      <link>https://arxiv.org/abs/2408.11186</link>
      <description>arXiv:2408.11186v3 Announce Type: replace-cross 
Abstract: Autonomous agents interact with other autonomous agents and humans of unknown preferences to share resources in their environment. We explore sequential trading for resource allocation in a setting where two greedily rational agents sequentially trade resources from a finite set of categories. Each agent has a utility function that depends on the amount of resources it possesses in each category. The offering agent makes trade offers to improve its utility without knowing the responding agent's utility function, and the responding agent only accepts offers that improve its utility. To facilitate cooperation between an autonomous agent and another autonomous agent or a human, we present an algorithm for the offering agent to estimate the responding agent's gradient (preferences) and make offers based on previous acceptance or rejection responses. The algorithm's goal is to reach a Pareto-optimal resource allocation state while ensuring that the utilities of both agents improve after every accepted trade. The algorithm estimates the responding agent's gradient by leveraging the rejected offers and the greedy rationality assumption, to prune the space of potential gradients. We show that, after the algorithm makes a finite number of rejected offers, the algorithm either finds a mutually beneficial trade or certifies that the current state is epsilon-weakly Pareto optimal. We compare the proposed algorithm against various baselines in continuous and discrete trading scenarios and show that it improves the societal benefit with fewer offers. Additionally, we validate these findings in a user study with human participants, where the algorithm achieves high performance in scenarios with high resource conflict due to aligned agent goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11186v3</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Surya Murthy, Mustafa O. Karabag, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>Robustness to Model Approximation, Model Learning From Data, and Sample Complexity in Wasserstein Regular MDPs</title>
      <link>https://arxiv.org/abs/2410.14116</link>
      <description>arXiv:2410.14116v4 Announce Type: replace-cross 
Abstract: The paper studies the robustness properties of discrete-time stochastic optimal control under Wasserstein model approximation for both discounted cost and average cost criteria. Specifically, we study the performance loss when applying an optimal policy designed for an approximate model to the true dynamics compared with the optimal cost for the true model under the sup-norm-induced metric, and relate it to the Wasserstein-1 distance between the approximate and true transition kernels. A primary motivation of this analysis is empirical model learning, as well as empirical noise distribution learning, where Wasserstein convergence holds under mild conditions but stronger convergence criteria, such as total variation, may not. We discuss applications of the results to the disturbance estimation problem, where sample complexity bounds are given, and also to a general empirical model learning approach, obtained under either Markov or i.i.d. learning settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14116v4</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yichen Zhou, Yanglei Song, Serdar Y\"uksel</dc:creator>
    </item>
    <item>
      <title>Controlling Participation in Federated Learning with Feedback</title>
      <link>https://arxiv.org/abs/2411.19242</link>
      <description>arXiv:2411.19242v2 Announce Type: replace-cross 
Abstract: We address the problem of client participation in federated learning, where traditional methods typically rely on a random selection of a small subset of clients for each training round. In contrast, we propose FedBack, a deterministic approach that leverages control-theoretic principles to manage client participation in ADMM-based federated learning. FedBack models client participation as a discrete-time dynamical system and employs an integral feedback controller to adjust each client's participation rate individually, based on the client's optimization dynamics. We provide global convergence guarantees for our approach by building on the recent federated learning research. Numerical experiments on federated image classification demonstrate that FedBack achieves up to 50\% improvement in communication and computational efficiency over algorithms that rely on a random selection of clients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19242v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Michael Cummins, Guner Dilsad Er, Michael Muehlebach</dc:creator>
    </item>
  </channel>
</rss>
