<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.FL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.FL</link>
    <description>cs.FL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.FL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 May 2025 04:00:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A General Information Extraction Framework Based on Formal Languages</title>
      <link>https://arxiv.org/abs/2505.15605</link>
      <description>arXiv:2505.15605v1 Announce Type: new 
Abstract: For a terminal alphabet $\Sigma$ and an attribute alphabet $\Gamma$, a $(\Sigma, \Gamma)$-extractor is a function that maps every string over $\Sigma$ to a table with a column per attribute and with sets of positions of $w$ as cell entries. This rather general information extraction framework extends the well-known document spanner framework, which has intensively been investigated in the database theory community over the last decade. Moreover, our framework is based on formal language theory in a particularly clean and simple way. In addition to this conceptual contribution, we investigate closure properties, different representation formalisms and the complexity of natural decision problems for extractors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15605v1</guid>
      <category>cs.FL</category>
      <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Markus L. Schmid</dc:creator>
    </item>
    <item>
      <title>HybridProver: Augmenting Theorem Proving with LLM-Driven Proof Synthesis and Refinement</title>
      <link>https://arxiv.org/abs/2505.15740</link>
      <description>arXiv:2505.15740v1 Announce Type: new 
Abstract: Formal methods is pivotal for verifying the reliability of critical systems through rigorous mathematical proofs. However, its adoption is hindered by labor-intensive manual proofs and the expertise required to use theorem provers. Recent advancements in large language models (LLMs) offer new opportunities for automated theorem proving. Two promising approaches are generating tactics step by step and generating a whole proof directly with an LLM. However, existing work makes no attempt to combine the two approaches. In this work, we introduce HybridProver, a dual-model proof synthesis framework that combines tactic-based generation and whole-proof synthesis to harness the benefits of both approaches. HybridProver generates whole proof candidates for evaluation directly, then extracts proof sketches from those candidates. It then uses a tactic-based generation model that integrates automated tools to complete the sketches via stepwise refinement. We implement HybridProver for the Isabelle theorem prover and fine-tune LLMs on our optimized Isabelle datasets. Evaluation on the miniF2F dataset illustrates HybridProver's effectiveness. We achieve a 59.4% success rate on miniF2F, where the previous SOTA is 56.1%. Our ablation studies show that this SOTA result is attributable to combining whole-proof and tactic-based generation. Additionally, we show how the dataset quality, training parameters, and sampling diversity affect the final result during automated theorem proving with LLMs. All of our code, datasets, and LLMs are open source.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15740v1</guid>
      <category>cs.FL</category>
      <category>cs.AI</category>
      <category>cs.SE</category>
      <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jilin Hu, Jianyu Zhang, Yongwang Zhao, Talia Ringer</dc:creator>
    </item>
    <item>
      <title>Robust Probabilistic Bisimilarity for Labelled Markov Chains</title>
      <link>https://arxiv.org/abs/2505.15290</link>
      <description>arXiv:2505.15290v1 Announce Type: cross 
Abstract: Despite its prevalence, probabilistic bisimilarity suffers from a lack of robustness under minuscule perturbations of the transition probabilities. This can lead to discontinuities in the probabilistic bisimilarity distance function, undermining its reliability in practical applications where transition probabilities are often approximations derived from experimental data. Motivated by this limitation, we introduce the notion of robust probabilistic bisimilarity for labelled Markov chains, which ensures the continuity of the probabilistic bisimilarity distance function. We also propose an efficient algorithm for computing robust probabilistic bisimilarity and show that it performs well in practice, as evidenced by our experimental results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15290v1</guid>
      <category>cs.LO</category>
      <category>cs.FL</category>
      <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Syyeda Zainab Fatmi, Stefan Kiefer, David Parker, Franck van Breugel</dc:creator>
    </item>
    <item>
      <title>A cornering strategy for synchronizing a DFA</title>
      <link>https://arxiv.org/abs/2405.00826</link>
      <description>arXiv:2405.00826v2 Announce Type: replace 
Abstract: This paper considers the existence of short synchronizing words in deterministic finite automata (DFAs). In particular, we define a general strategy, which we call the cornering strategy, for generating short synchronizing words in well-structured DFAs. We show that a DFA is synchronizable if and only if this strategy can be applied.
  Using the cornering strategy, we prove that all DFAs consisting of $n$ points in $\mathbb{R}^d$ with bidirectional connected edge sets in which each edge $(\mathbf x, \mathbf y)$ with distinct endpoints is labeled $\mathbf y - \mathbf x$ are synchronizable. We also give sufficient conditions for such DFAs to have synchronizing words of length at most $(n-1)^2$ and thereby satisfy \v{C}ern\'y's conjecture. Using similar ideas, we improve upper bounds by Trahtman and Volkov on the length of shortest synchronizing words in aperiodic DFAs, in special cases where the DFAs in question have small diameter. Finally, we consider how the cornering strategy can be applied to the problem of simultaneously synchronizing a DFA $G$ to an initial state $u$ and a DFA $H$ to an initial state $v$. We do not assume that DFAs $G$ and $H$ or states $u$ and $v$ are related beyond sharing the same set of edge labels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00826v2</guid>
      <category>cs.FL</category>
      <category>math.CO</category>
      <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Bradshaw, Alexander Clow, Ladislav Stacho</dc:creator>
    </item>
    <item>
      <title>The rIC3 Hardware Model Checker</title>
      <link>https://arxiv.org/abs/2502.13605</link>
      <description>arXiv:2502.13605v2 Announce Type: replace 
Abstract: In this paper, we present rIC3, an efficient bit-level hardware model checker primarily based on the IC3 algorithm. It boasts a highly efficient implementation and integrates several recently proposed optimizations, such as the specifically optimized SAT solver, dynamically adjustment of generalization strategies, and the use of predicates with internal signals, among others. As a first-time participant in the Hardware Model Checking Competition, rIC3 was independently evaluated as the best-performing tool, not only in the bit-level track but also in the word-level bit-vector track through bit-blasting. Our experiments further demonstrate significant advancements in both efficiency and scalability. rIC3 can also serve as a backend for verifying industrial RTL designs using SymbiYosys. Additionally, the source code of rIC3 is highly modular, with the IC3 algorithm module being particularly concise, making it an academic platform that is easy to modify and extend.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13605v2</guid>
      <category>cs.FL</category>
      <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuheng Su, Qiusong Yang, Yiwei Ci, Tianjun Bu, Ziyu Huang</dc:creator>
    </item>
    <item>
      <title>Minimal History-Deterministic Co-Buchi Automata: Congruences and Passive Learning</title>
      <link>https://arxiv.org/abs/2505.14304</link>
      <description>arXiv:2505.14304v2 Announce Type: replace 
Abstract: Abu Radi and Kupferman (2019) demonstrated the efficient minimization of history-deterministic (transition-based) co-B\"uchi automata, building on the results of Kuperberg and Skrzypczak (2015). We give a congruence-based description of these minimal automata, and a self-contained proof of its correctness. We use this description based on congruences to create a passive learning algorithm that can learn minimal history-deterministic co-B\"uchi automata from a set of labeled example words. The algorithm runs in polynomial time on a given set of examples, and there is a characteristic set of examples of polynomial size for each minimal history-deterministic co-B\"uchi automaton.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14304v2</guid>
      <category>cs.FL</category>
      <pubDate>Thu, 22 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christof L\"oding, Igor Walukiewicz</dc:creator>
    </item>
  </channel>
</rss>
