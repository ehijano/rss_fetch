<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Jan 2026 05:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The cost of cyclic permutations and remainder sums in the Euclidean algorithm</title>
      <link>https://arxiv.org/abs/2601.00979</link>
      <description>arXiv:2601.00979v1 Announce Type: new 
Abstract: We discuss a modification to the Gries-Mills block swapping scheme for in-place rotation with average costs of 1.85 moves per element and worst case performance still at 3 moves per element. Analysis of the average case relies on the asymptotic behavior of the sum of remainders in the Euclidean algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00979v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valentin Blomer, Kai-Uwe Bux</dc:creator>
    </item>
    <item>
      <title>AGIS: Fast Approximate Graph Pattern Mining with Structure-Informed Sampling</title>
      <link>https://arxiv.org/abs/2601.01388</link>
      <description>arXiv:2601.01388v1 Announce Type: new 
Abstract: Approximate Graph Pattern Mining (AGPM) is essential for analyzing large-scale graphs where exact counting is computationally prohibitive. While there exist numerous sampling-based AGPM systems, they all rely on uniform sampling and overlook the underlying probability distribution. This limitation restricts their scalability to a broader range of patterns.
  In this paper, we introduce AGIS, an extremely fast AGPM system capable of counting arbitrary patterns from huge graphs. AGIS employs structure-informed neighbor sampling, a novel sampling technique that deviates from uniformness but allocates specific sampling probabilities based on the pattern structure. We first derive the ideal sampling distribution for AGPM and then present a practical method to approximate it. Furthermore, we develop a method that balances convergence speed and computational overhead, determining when to use the approximated distribution.
  Experimental results demonstrate that AGIS significantly outperforms the state-of-the-art AGPM system, achieving 28.5x geometric mean speedup and more than 100,000x speedup in specific cases. Furthermore, AGIS is the only AGPM system that scales to graphs with tens of billions of edges and robustly handles diverse patterns, successfully providing accurate estimates within seconds. We will open-source AGIS to encourage further research in this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01388v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Seoyong Lee, Jinho Lee</dc:creator>
    </item>
    <item>
      <title>Derandomizing Pseudopolynomial Algorithms for Subset Sum</title>
      <link>https://arxiv.org/abs/2601.01390</link>
      <description>arXiv:2601.01390v1 Announce Type: new 
Abstract: We reexamine the classical subset sum problem: given a set $X$ of $n$ positive integers and a number $t$, decide whether there exists a subset of $X$ that sums to $t$; or more generally, compute the set $\mbox{out}$ of all numbers $y\in\{0,\ldots,t\}$ for which there exists a subset of $X$ that sums to $y$. Standard dynamic programming solves the problem in $O(tn)$ time. In SODA'17, two papers appeared giving the current best deterministic and randomized algorithms, ignoring polylogarithmic factors: Koiliaris and Xu's deterministic algorithm runs in $\widetilde{O}(t\sqrt{n})$ time, while Bringmann's randomized algorithm runs in $\widetilde{O}(t)$ time. We present the first deterministic algorithm running in $\widetilde{O}(t)$ time.
  Our technique has a number of other applications: for example, we can also derandomize the more recent output-sensitive algorithms by Bringmann and Nakos [STOC'20] and Bringmann, Fischer, and Nakos [SODA'25] running in $\widetilde{O}(|\mbox{out}|^{4/3})$ and $\widetilde{O}(|\mbox{out}|\sqrt{n})$ time, and we can derandomize a previous fine-grained reduction from 0-1 knapsack to min-plus convolution by Cygan et al. [ICALP'17].</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01390v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timothy M. Chan</dc:creator>
    </item>
    <item>
      <title>Publishing Below-Threshold Triangle Counts under Local Weight Differential Privacy</title>
      <link>https://arxiv.org/abs/2601.01710</link>
      <description>arXiv:2601.01710v1 Announce Type: new 
Abstract: We propose an algorithm for counting below-threshold triangles in weighted graphs under local weight differential privacy. While prior work focused on unweighted graphs, many real-world networks naturally include edge weights. We study the setting where the graph topology is public known and the privacy of the influence of an individual on the edge weights is protected. This captures realistic scenarios such as road networks and telecommunication networks. Our approach consists of two rounds of communication. In the first round, each node publishes their incident weight information under local weight differential privacy while in the second round, the nodes locally count below-threshold triangles, for which we introduce a biased and unbiased variant. We further propose two different improvements. We present a pre-computation step that reduces the covariance and thereby lowers the expected error. Secondly, we develop an algorithm for computing the smooth-sensitivity, which significantly reduces the running time compared to a straightforward approach. Finally, we provide experimental results that demonstrate the differences between the biased and unbiased variants and the effectiveness of the proposed improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01710v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kevin Pfisterer, Quentin Hillebrand, Vorapong Suppakitpaisarn</dc:creator>
    </item>
    <item>
      <title>Improved Approximation Algorithms for the Multiple-Depot Split Delivery Vehicle Routing Problem</title>
      <link>https://arxiv.org/abs/2601.01841</link>
      <description>arXiv:2601.01841v1 Announce Type: new 
Abstract: The Multiple-Depot Split Delivery Vehicle Routing Problem (MD-SDVRP) is a challenging problem with broad applications in logistics. The goal is to serve customers' demand using a fleet of capacitated vehicles located in multiple depots, where each customer's demand can be served by more than one vehicle, while minimizing the total travel cost of all vehicles. We study approximation algorithms for this problem. Previously, the only known result was a $6$-approximation algorithm for a constant number of depots (INFORMS J. Comput. 2023), and whether this ratio could be improved was left as an open question. In this paper, we resolve it by proposing a $(6-2\cdot 10^{-36})$-approximation algorithm for this setting. Moreover, we develop constant-factor approximation algorithms that work beyond a constant number of depots, improved parameterized approximation algorithms related to the vehicle capacity and the number of depots, as well as bi-factor approximation algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01841v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingyang Zhao, Yonghang Su, Mingyu Xiao</dc:creator>
    </item>
    <item>
      <title>Exact Clique Number Manipulation via Edge Interdiction</title>
      <link>https://arxiv.org/abs/2601.01869</link>
      <description>arXiv:2601.01869v1 Announce Type: new 
Abstract: The Edge Interdiction Clique Problem (EICP) aims to remove at most $k$ edges from a graph so as to minimize the size of the largest clique in the remaining graph. This problem captures a fundamental question in graph manipulation: which edges are structurally critical for preserving large cliques? Such a problem is also motivated by practical applications including protein function maintenance and image matching. The EICP is computationally challenging and belongs to a complexity class beyond NP. Existing approaches rely on general mixed-integer bilevel programming solvers or reformulate the problem into a single-level mixed integer linear program. However, they are still not scalable when the graph size and interdiction budget $k$ grow. To overcome this, we investigate new mixed integer linear formulations, which recast the problem into a sequence of parameterized Edge Blocker Clique Problems (EBCP). This perspective decomposes the original problem into simpler subproblems and enables tighter modeling of clique-related inequalities. Furthermore, we propose a two-stage exact algorithm, \textsc{RLCM}, which first applies problem-specific reduction techniques to shrink the graph and then solves the reduced problem using a tailored branch-and-cut framework. Extensive computational experiments on maximum clique benchmark graphs, large real-world sparse networks, and random graphs demonstrate that \textsc{RLCM} consistently outperforms existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01869v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Zhou, Haoyu Jiang, Chenghao Zhu, Andr\'e Rossi</dc:creator>
    </item>
    <item>
      <title>Time-Dependent Hamiltonian Simulation in the Low-Energy Subspace</title>
      <link>https://arxiv.org/abs/2601.01550</link>
      <description>arXiv:2601.01550v1 Announce Type: cross 
Abstract: Hamiltonian simulations are key subroutines in adiabatic quantum computation, quantum control, and quantum many-body physics, where quantum dynamics often happen in the low-energy sector. In contrast to time-independent Hamiltonian simulations, a comprehensive understanding of quantum simulation algorithms for time-dependent Hamiltonians under the low-energy assumption remains limited hitherto. In this paper, we investigate how much we can improve upon the standard performance guarantee assuming the initial state is supported on a low-energy subspace. In particular, we compute the Trotter number of digital quantum simulation based on product formulas for time-dependent spin Hamiltonians under the low-energy assumption that the initial state is supported on a small number of low-energy eigenstates, and show improvements over the standard cost for simulating full unitary simulations. Technically, we derive the low-energy simulation error with commutator scaling for product formulas by leveraging adiabatic perturbation theory to analyze the time-variant energy spectrum of the underlying Hamiltonian. We further discuss the applications to simulations of non-equilibrium quantum many-body dynamics and adiabatic state preparation. Finally, we prove a lower bound of query complexity for generic time-dependent Hamiltonian simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01550v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuo Zhou, Zhaokai Pan, Weiyuan Gong, Tongyang Li</dc:creator>
    </item>
    <item>
      <title>Learning with Monotone Adversarial Corruptions</title>
      <link>https://arxiv.org/abs/2601.02193</link>
      <description>arXiv:2601.02193v1 Announce Type: cross 
Abstract: We study the extent to which standard machine learning algorithms rely on exchangeability and independence of data by introducing a monotone adversarial corruption model. In this model, an adversary, upon looking at a "clean" i.i.d. dataset, inserts additional "corrupted" points of their choice into the dataset. These added points are constrained to be monotone corruptions, in that they get labeled according to the ground-truth target function. Perhaps surprisingly, we demonstrate that in this setting, all known optimal learning algorithms for binary classification can be made to achieve suboptimal expected error on a new independent test point drawn from the same distribution as the clean dataset. On the other hand, we show that uniform convergence-based algorithms do not degrade in their guarantees. Our results showcase how optimal learning algorithms break down in the face of seemingly helpful monotone corruptions, exposing their overreliance on exchangeability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02193v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kasper Green Larsen, Chirag Pabbaraju, Abhishek Shetty</dc:creator>
    </item>
    <item>
      <title>Improved Accuracy for Private Continual Cardinality Estimation in Fully Dynamic Streams via Matrix Factorization</title>
      <link>https://arxiv.org/abs/2601.02257</link>
      <description>arXiv:2601.02257v1 Announce Type: cross 
Abstract: We study differentially-private statistics in the fully dynamic continual observation model, where many updates can arrive at each time step and updates to a stream can involve both insertions and deletions of an item. Earlier work (e.g., Jain et al., NeurIPS 2023 for counting distinct elements; Raskhodnikova &amp; Steiner, PODS 2025 for triangle counting with edge updates) reduced the respective cardinality estimation problem to continual counting on the difference stream associated with the true function values on the input stream. In such reductions, a change in the original stream can cause many changes in the difference stream, this poses a challenge for applying private continual counting algorithms to obtain optimal error bounds. We improve the accuracy of several such reductions by studying the associated $\ell_p$-sensitivity vectors of the resulting difference streams and isolating their properties.
  We demonstrate that our framework gives improved bounds for counting distinct elements, estimating degree histograms, and estimating triangle counts (under a slightly relaxed privacy model), thus offering a general approach to private continual cardinality estimation in streaming settings. Our improved accuracy stems from tight analysis of known factorization mechanisms for the counting matrix in this setting; the key technical challenge is arguing that one can use state-of-the-art factorizations for sensitivity vector sets with the properties we isolate. Empirically and analytically, we demonstrate that our improved error bounds offer a substantial improvement in accuracy for cardinality estimation problems over a large range of parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02257v1</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joel Daniel Andersson, Palak Jain, Satchit Sivakumar</dc:creator>
    </item>
    <item>
      <title>Solving Matrix Games with Even Fewer Matrix-Vector Products</title>
      <link>https://arxiv.org/abs/2601.02347</link>
      <description>arXiv:2601.02347v1 Announce Type: cross 
Abstract: We study the problem of computing an $\epsilon$-approximate Nash equilibrium of a two-player, bilinear, zero-sum game with a bounded payoff matrix $A \in \mathbb{R}^{m \times n}$, when the players' strategies are constrained to lie in simple sets. We provide algorithms which solve this problem in $\tilde{O}(\epsilon^{-2/3})$ matrix-vector multiplies (matvecs) in two well-studied cases: $\ell_1$-$\ell_1$ games, where the players' strategies are both in the probability simplex, and $\ell_2$-$\ell_1$ games, where the players' strategies are in the unit Euclidean ball and probability simplex respectively. These results improve upon the previous state-of-the-art complexities of $\tilde{O}(\epsilon^{-8/9})$ for $\ell_1$-$\ell_1$ and of $\tilde{O}(\epsilon^{-7/9})$ for $\ell_2$-$\ell_1$ due to [KOS '25]. In particular, our result for $\ell_2$-$\ell_1$, which corresponds to hard-margin support vector machines (SVMs), matches the lower bound of [KS '25] up to polylogarithmic factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02347v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ishani Karmarkar, Liam O'Carroll, Aaron Sidford</dc:creator>
    </item>
    <item>
      <title>A Tale of Santa Claus, Hypergraphs and Matroids</title>
      <link>https://arxiv.org/abs/1807.07189</link>
      <description>arXiv:1807.07189v4 Announce Type: replace 
Abstract: A well-known problem in scheduling and approximation algorithms is the Santa Claus problem. Suppose that Santa Claus has a set of gifts, and he wants to distribute them among a set of children so that the least happy child is made as happy as possible. Here, the value that a child $i$ has for a present $j$ is of the form $p_{ij} \in \{ 0,p_j\}$. A polynomial time algorithm by Annamalai et al. gives a $12.33$-approximation and is based on a modification of Haxell's hypergraph matching argument.
  In this paper, we introduce a matroid version of the Santa Claus problem. Our algorithm is also based on Haxell's augmenting tree, but with the introduction of the matroid structure we solve a more general problem with cleaner methods. Our result can then be used as a blackbox to obtain a $(6+\varepsilon)$-approximation for Santa Claus. This factor also compares against a natural, compact LP for Santa Claus.</description>
      <guid isPermaLink="false">oai:arXiv.org:1807.07189v4</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sami Davies, Thomas Rothvoss, Yihao Zhang</dc:creator>
    </item>
    <item>
      <title>Optimality of Non-Adaptive Algorithms in Online Submodular Welfare Maximization with Stochastic Outcomes</title>
      <link>https://arxiv.org/abs/2403.18059</link>
      <description>arXiv:2403.18059v5 Announce Type: replace 
Abstract: We generalize the problem of online submodular welfare maximization to incorporate various stochastic elements that have gained significant attention in recent years. We show that a non-adaptive Greedy algorithm, which is oblivious to the realization of these stochastic elements, achieves the best possible competitive ratio among all polynomial-time algorithms, including adaptive ones, unless NP$=$RP. This result holds even when the objective function is not submodular but instead satisfies the weaker submodular order property. Our results unify and strengthen existing competitive ratio bounds across well-studied settings and diverse arrival models, showing that, in general, adaptivity to stochastic elements offers no advantage in terms of competitive ratio.
  To establish these results, we introduce a technique that lifts known results from the deterministic setting to the generalized stochastic setting. The technique has broad applicability, enabling us to show that, in certain special cases, non-adaptive Greedy-like algorithms outperform the Greedy algorithm and achieve the optimal competitive ratio. We also apply the technique in reverse to derive new upper bounds on the performance of Greedy-like algorithms in deterministic settings by leveraging upper bounds on the performance of non-adaptive algorithms in stochastic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18059v5</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rajan Udwani</dc:creator>
    </item>
    <item>
      <title>On Efficient Approximate Aggregate Nearest Neighbor Queries over Learned Representations</title>
      <link>https://arxiv.org/abs/2502.18803</link>
      <description>arXiv:2502.18803v2 Announce Type: replace 
Abstract: We study Aggregation Queries over Nearest Neighbors (AQNN), which compute aggregates over the learned representations of the neighborhood of a designated query object. For example, a medical professional may be interested in the average heart rate of patients whose representations are similar to that of an insomnia patient. Answering AQNNs accurately and efficiently is challenging due to the high cost of generating high-quality representations (e.g., via a deep learning model trained on human expert annotations) and the different sensitivities of different aggregation functions to neighbor selection errors. We address these challenges by combining high-quality and low-cost representations to approximate the aggregate. We characterize value- and count-sensitive AQNNs and propose the Sampler with Precision-Recall in Target (SPRinT), a query answering framework that works in three steps: (1) sampling, (2) nearest neighbor selection, and (3) aggregation. We further establish theoretical bounds on sample sizes and aggregation errors. Extensive experiments on five datasets from three domains (medical, social media, and e-commerce) demonstrate that SPRinT achieves the lowest aggregation error with minimal computation cost in most cases compared to existing solutions. SPRinT's performance remains stable as dataset size grows, confirming its scalability for large-scale applications requiring both accuracy and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18803v2</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3786672</arxiv:DOI>
      <arxiv:journal_reference>Proc. ACM Manag. Data, Vol. 4, No. 1 (SIGMOD), Article 58. Publication date: February 2026</arxiv:journal_reference>
      <dc:creator>Carrie Wang, Sihem Amer-Yahia, Laks V. S. Lakshmanan, Reynold Cheng</dc:creator>
    </item>
    <item>
      <title>New Sorting Algorithm Wave Sort (W-Sort)</title>
      <link>https://arxiv.org/abs/2505.13552</link>
      <description>arXiv:2505.13552v3 Announce Type: replace 
Abstract: Modern comparison sorts like quicksort suffer from performance inconsistencies due to suboptimal pivot selection, leading to $(O(N^2))$ worst-case complexity, while in-place merge sort variants face challenges with data movement overhead. We introduce Wave Sort, a novel in-place sorting algorithm that addresses these limitations through a dynamic pivot selection strategy. Wave Sort iteratively expands a sorted region and selects pivots from this growing sorted portion to partition adjacent unsorted data. This approach ensures robust pivot selection irrespective of dataset size, guarantees a logarithmic recursion stack depth, and enables efficient in-place sorting. Our analysis shows a best comparison complexity of $(N-1)$, average comparison complexity close to $(\log_2(N)!)$, and worst-case comparison complexity bounded by $(O(N(\log(N))^2))$ with a small constant factor, which could be reduced to $(O(N\log(N)))$ with hybrid sorting. The algorithm can be easily expanded to be hybridized with other sorting algorithms. Experimental results demonstrate that Wave Sort requires significantly fewer comparisons than quicksort on average (approximately 24% less) and performs close to the theoretical minimum $(\log_2(N)!)$. Wave Sort offers a compelling alternative for applications demanding consistent, predictable, and in-place sorting performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13552v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jia Xu Wei</dc:creator>
    </item>
    <item>
      <title>Modern Minimal Perfect Hashing: A Survey</title>
      <link>https://arxiv.org/abs/2506.06536</link>
      <description>arXiv:2506.06536v2 Announce Type: replace 
Abstract: Given a set $S$ of $n$ keys, a perfect hash function for $S$ maps the keys in $S$ to the first $m \geq n$ integers without collisions. It may return an arbitrary result for any key not in $S$ and is called minimal if $m = n$. The most important parameters are its space consumption, construction time, and query time. Years of research now enable modern perfect hash functions to be extremely fast to query, very space-efficient, and scale to billions of keys. Different approaches give different trade-offs between these aspects. For example, the smallest constructions get within 0.1% of the space lower bound of $\log_2(e)$ bits per key. Others are particularly fast to query, requiring only one memory access. Perfect hashing has many applications, for example to avoid collision resolution in static hash tables, and is used in databases, bioinformatics, and stringology.
  Since the last comprehensive survey in 1997, significant progress has been made. This survey covers the latest developments and provides a starting point for getting familiar with the topic. Additionally, our extensive experimental evaluation can serve as a guide to select a perfect hash function for use in applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06536v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hans-Peter Lehmann, Thomas Mueller, Rasmus Pagh, Giulio Ermanno Pibiri, Peter Sanders, Sebastiano Vigna, Stefan Walzer</dc:creator>
    </item>
    <item>
      <title>PageRank Centrality in Directed Graphs with Bounded In-Degree</title>
      <link>https://arxiv.org/abs/2508.01257</link>
      <description>arXiv:2508.01257v2 Announce Type: replace 
Abstract: We study the computational complexity of locally estimating a node's PageRank centrality in a directed graph $G$. For any node $t$, its PageRank centrality $\pi(t)$ is defined as the probability that a random walk in $G$, starting from a uniformly chosen node, terminates at $t$, where each step terminates with a constant probability $\alpha\in(0,1)$.
  To obtain a multiplicative $\big(1\pm O(1)\big)$-approximation of $\pi(t)$ with probability $\Omega(1)$, the previously best upper bound is $O(n^{1/2}\min\{ \Delta_{in}^{1/2},\Delta_{out}^{1/2},m^{1/4}\})$ from [Wang, Wei, Wen, Yang, STOC '24], where $n$ and $m$ denote the number of nodes and edges in $G$, and $\Delta_{in}$ and $\Delta_{out}$ upper bound the in-degrees and out-degrees of $G$, respectively. Using a refinement of the proof in the same paper, we establish a lower bound of $\Omega(n^{1/2}\min\{\Delta_{in}^{1/2}/n^{\gamma},\Delta_{out}^{1/2}/n^{\gamma},m^{1/4}\})$, where $\gamma=\frac{1}{2}(2\max\{\log_{1/(1-\alpha)}\Delta_{in},1\}-1)^{-1}$. As $\gamma$ only depends on $\Delta_{in}$ and $n^{\gamma}=O(1)$ for $\Delta_{in}=\Omega\left(n^{\Omega(1)}\right)$, the known upper bound is tight if we only parameterize the complexity by $n$, $m$, and $\Delta_{out}$. However, there remains a gap of $\Omega(n^{\gamma})$ when considering $\Delta_{in}$, and this gap is large when $\Delta_{in}$ is small. In the extreme case where $\Delta_{in}\le1/(1-\alpha)$, we have $\gamma=1/2$, leading to a gap of $\Omega(n^{1/2})$ between the bounds $O(n^{1/2})$ and $\Omega(1)$.
  In this paper, we present a new algorithm that achieves the above lower bound (up to logarithmic factors). The algorithm assumes that $n$ and the bounds $\Delta_{in}$ and $\Delta_{out}$ are known in advance. Our key technique is a novel randomized backwards propagation process that only propagates selectively based on Monte Carlo estimated PageRank scores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01257v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikkel Thorup, Hanzhi Wang, Zhewei Wei, Mingji Yang</dc:creator>
    </item>
    <item>
      <title>Expected Cost Analysis of Online Facility Assignment on Regular Polygons (v2)</title>
      <link>https://arxiv.org/abs/2512.00506</link>
      <description>arXiv:2512.00506v2 Announce Type: replace 
Abstract: This paper analyzes the online facility assignment problem in a geometric setting where facilities with unit capacity are positioned at the vertices of a regular $n$-gon. Customers arrive sequentially at uniformly random positions along the edges. They must be assigned immediately to the nearest available facility, with ties broken by coin toss. The sequential nature and unknown future arrivals require a probabilistic analysis of the expected assignment cost. Our main contribution is a recursive characterization of the expected cost: for any occupancy state $S$, the expected remaining cost $V(S)$ equals the average over all edge positions of the immediate assignment cost plus the expected future cost after assignment. We prove that this integral equation can calculate a solution and provide the expected value for small $n$ ($n = 3, 4, 5, \dots$). For larger values of $n$ and expected cost, we develop efficient numerical methods, including a discretized dynamic programming approach and Monte Carlo simulation. The work establishes a fundamental probabilistic approach for online assignment in polygonal environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00506v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Rawha Siddiqi Riad, Md Manzurul Hasan</dc:creator>
    </item>
    <item>
      <title>Convergence of a L2 regularized Policy Gradient Algorithm for the Multi Armed Bandit</title>
      <link>https://arxiv.org/abs/2402.06388</link>
      <description>arXiv:2402.06388v4 Announce Type: replace-cross 
Abstract: Although Multi Armed Bandit (MAB) on one hand and the policy gradient approach on the other hand are among the most used frameworks of Reinforcement Learning, the theoretical properties of the policy gradient algorithm used for MAB have not been given enough attention. We investigate in this work the convergence of such a procedure for the situation when a $L2$ regularization term is present jointly with the 'softmax' parametrization. We prove convergence under appropriate technical hypotheses and test numerically the procedure including situations beyond the theoretical setting. The tests show that a time dependent regularized procedure can improve over the canonical approach especially when the initial guess is far from the solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06388v4</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-78395-1_27</arxiv:DOI>
      <arxiv:journal_reference>In: Antonacopoulos, A., et al. (eds) Pattern Recognition. ICPR 2024. Lecture Notes in Computer Science, vol 15326. Springer, Cham (2025)</arxiv:journal_reference>
      <dc:creator>Stefana Anita, Gabriel Turinici</dc:creator>
    </item>
    <item>
      <title>Attainability of Two-Point Testing Rates for Finite-Sample Location Estimation</title>
      <link>https://arxiv.org/abs/2502.05730</link>
      <description>arXiv:2502.05730v3 Announce Type: replace-cross 
Abstract: Le Cam's two-point testing method yields perhaps the simplest lower bound for estimating the mean of a distribution: roughly, if it is impossible to well-distinguish a distribution centered at $\mu$ from the same distribution centered at $\mu+\Delta$, then it is impossible to estimate the mean by better than $\Delta/2$. It is setting-dependent whether or not a nearly matching upper bound is attainable. We study the conditions under which the two-point testing lower bound can be attained for univariate mean estimation; both in the setting of location estimation (where the distribution is known up to translation) and adaptive location estimation (unknown distribution). Roughly, we will say an estimate nearly attains the two-point testing lower bound if it incurs error that is at most polylogarithmically larger than the Hellinger modulus of continuity for $\tilde{\Omega}(n)$ samples.
  Adaptive location estimation is particularly interesting as some distributions admit much better guarantees than sub-Gaussian rates (e.g. $\operatorname{Unif}(\mu-1,\mu+1)$ permits error $\Theta(\frac{1}{n})$, while the sub-Gaussian rate is $\Theta(\frac{1}{\sqrt{n}})$), yet it is not obvious whether these rates may be adaptively attained by one unified approach. Our main result designs an algorithm that nearly attains the two-point testing rate for mixtures of symmetric, log-concave distributions with a common mean. Moreover, this algorithm runs in near-linear time and is parameter-free. In contrast, we show the two-point testing rate is not nearly attainable even for symmetric, unimodal distributions.
  We complement this with results for location estimation, showing the two-point testing rate is nearly attainable for unimodal distributions, but unattainable for symmetric distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05730v3</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Spencer Compton, Gregory Valiant</dc:creator>
    </item>
    <item>
      <title>Verified Purely Functional Catenable Real-Time Deques</title>
      <link>https://arxiv.org/abs/2505.07681</link>
      <description>arXiv:2505.07681v2 Announce Type: replace-cross 
Abstract: We present OCaml and Rocq implementations of Kaplan and Tarjan's purely functional, real-time catenable deques. The correctness of our Rocq implementation is machine-checked.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07681v2</guid>
      <category>cs.PL</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jules Viennot, Arthur Wendling, Arma\"el Gu\'eneau, Fran\c{c}ois Pottier</dc:creator>
    </item>
    <item>
      <title>Approximate Message Passing for Quantum State Tomography</title>
      <link>https://arxiv.org/abs/2511.12857</link>
      <description>arXiv:2511.12857v2 Announce Type: replace-cross 
Abstract: Quantum state tomography (QST) is an indispensable tool for characterizing many-body quantum systems. However, due to the exponential scaling of the cost of the protocol with system size, many approaches have been developed for quantum states with specific structure, such as low-rank states. In this paper, we show how approximate message passing (AMP), an algorithmic framework for sparse signal recovery, can be used to perform low-rank QST. AMP provides asymptotically optimal performance guarantees for large sparse recovery problems, which suggests its utility for QST. We discuss the design challenges that come with applying AMP to QST, and show that by properly designing the AMP algorithm, we can reduce the reconstruction error by over an order of magnitude compared to existing approaches to low-rank QST. We also performed tomographic experiments on IBM Kingston and considered the effect of device noise on the reliability of the predicted fidelity of state preparation. Our work advances the state of low-rank QST and may be applicable to other quantum tomography protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12857v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 06 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noah Siekierski, Kausthubh Chandramouli, Christian K\"ummerle, Bojko N. Bakalov, Dror Baron</dc:creator>
    </item>
  </channel>
</rss>
