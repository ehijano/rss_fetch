<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Jan 2026 03:17:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Neural Brain Fields: A NeRF-Inspired Approach for Generating Nonexistent EEG Electrodes</title>
      <link>https://arxiv.org/abs/2601.00012</link>
      <description>arXiv:2601.00012v1 Announce Type: new 
Abstract: Electroencephalography (EEG) data present unique modeling challenges because recordings vary in length, exhibit very low signal to noise ratios, differ significantly across participants, drift over time within sessions, and are rarely available in large and clean datasets. Consequently, developing deep learning methods that can effectively process EEG signals remains an open and important research problem. To tackle this problem, this work presents a new method inspired by Neural Radiance Fields (NeRF). In computer vision, NeRF techniques train a neural network to memorize the appearance of a 3D scene and then uses its learned parameters to render and edit the scene from any viewpoint. We draw an analogy between the discrete images captured from different viewpoints used to learn a continuous 3D scene in NeRF, and EEG electrodes positioned at different locations on the scalp, which are used to infer the underlying representation of continuous neural activity. Building on this connection, we show that a neural network can be trained on a single EEG sample in a NeRF style manner to produce a fixed size and informative weight vector that encodes the entire signal. Moreover, via this representation we can render the EEG signal at previously unseen time steps and spatial electrode positions. We demonstrate that this approach enables continuous visualization of brain activity at any desired resolution, including ultra high resolution, and reconstruction of raw EEG signals. Finally, our empirical analysis shows that this method can effectively simulate nonexistent electrodes data in EEG recordings, allowing the reconstructed signal to be fed into standard EEG processing networks to improve performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00012v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.AS</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shahar Ain Kedem, Itamar Zimerman, Eliya Nachmani</dc:creator>
    </item>
    <item>
      <title>Modeling Day-Long ECG Signals to Predict Heart Failure Risk with Explainable AI</title>
      <link>https://arxiv.org/abs/2601.00014</link>
      <description>arXiv:2601.00014v1 Announce Type: new 
Abstract: Heart failure (HF) affects 11.8% of adults aged 65 and older, reducing quality of life and longevity. Preventing HF can reduce morbidity and mortality. We hypothesized that artificial intelligence (AI) applied to 24-hour single-lead electrocardiogram (ECG) data could predict the risk of HF within five years. To research this, the Technion-Leumit Holter ECG (TLHE) dataset, including 69,663 recordings from 47,729 patients, collected over 20 years was used. Our deep learning model, DeepHHF, trained on 24-hour ECG recordings, achieved an area under the receiver operating characteristic curve of 0.80 that outperformed a model using 30-second segments and a clinical score. High-risk individuals identified by DeepHHF had a two-fold chance of hospitalization or death incidents. Explainability analysis showed DeepHHF focused on arrhythmias and heart abnormalities, with key attention between 8 AM and 3 PM. This study highlights the feasibility of deep learning to model 24-hour continuous ECG data, capturing paroxysmal events and circadian variations essential for reliable risk prediction. Artificial intelligence applied to single-lead Holter ECG is non-invasive, inexpensive, and widely accessible, making it a promising tool for HF risk prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00014v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eran Zvuloni, Ronit Almog, Michael Glikson, Shany Brimer Biton, Ilan Green, Izhar Laufer, Offer Amir, Joachim A. Behar</dc:creator>
    </item>
    <item>
      <title>Adaptive Pinching Antenna Optimization via Meta-Learning for Physical-Layer Security in Dynamic Wireless Networks</title>
      <link>https://arxiv.org/abs/2601.00115</link>
      <description>arXiv:2601.00115v1 Announce Type: new 
Abstract: This paper develops a gradient-based meta-learning framework for real-time control of waveguided pinching-antenna systems under user-location uncertainty and physical-layer security (PLS) constraints. A probabilistic system model is introduced to capture the impact of imperfect localization on outage performance and secrecy. Based on this model, a joint antenna-positioning and transmit-power optimization problem is formulated to satisfy probabilistic reliability and secrecy requirements. To enable rapid adaptation in highly dynamic environments, the proposed approach employs model-agnostic meta-learning (MAML) to learn a transferable initialization across diverse mobility and channel conditions, allowing few-shot online adaptation using limited pilot feedback. Simulation results demonstrate that the proposed framework significantly outperforms Reptile-based meta-learning, non-meta reinforcement learning, conventional optimization, static antenna placement, and power-only control in terms of outage probability, secrecy performance, and convergence latency. These results establish meta-learning as an effective tool for secure and low-latency control of reconfigurable pinching-antenna systems in non-stationary wireless environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00115v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Khalid T. Musri, Akram Y. Sarhan, Osamah A. Abdullah, Hayder Al-Hraishawi</dc:creator>
    </item>
    <item>
      <title>AI-Driven Channel State Information (CSI) Extrapolation for 6G: Current Situations, Challenges and Future Research</title>
      <link>https://arxiv.org/abs/2601.00159</link>
      <description>arXiv:2601.00159v1 Announce Type: new 
Abstract: CSI extrapolation is an effective method for acquiring channel state information (CSI), essential for optimizing performance of sixth-generation (6G) communication systems. Traditional channel estimation methods face scalability challenges due to the surging overhead in emerging high-mobility, extremely large-scale multiple-input multiple-output (EL-MIMO), and multi-band systems. CSI extrapolation techniques mitigate these challenges by using partial CSI to infer complete CSI, significantly reducing overhead. Despite growing interest, a comprehensive review of state-of-the-art (SOTA) CSI extrapolation techniques is lacking. This paper addresses this gap by comprehensively reviewing the current status, challenges, and future directions of CSI extrapolation for the first time. Firstly, we analyze the performance metrics specific to CSI extrapolation in 6G, including extrapolation accuracy, adaption to dynamic scenarios and algorithm costs. We then review both model-driven and artificial intelligence (AI)-driven approaches for time, frequency, antenna, and multi-domain CSI extrapolation. Key insights and takeaways from these methods are summarized. Given the promise of AI-driven methods in meeting performance requirements, we also examine the open-source channel datasets and simulators that could be used to train high-performance AI-driven CSI extrapolation models. Finally, we discuss the critical challenges of the existing research and propose perspective research opportunities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00159v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Gao, Zichen Lu, Xinyi Wu, Wenjun Yu, Shengli Liu, Jianbo Du, Yanliang Jin, Shunqing Zhang, Xiaoli Chu, Shugong Xu</dc:creator>
    </item>
    <item>
      <title>Edge AI Inference in ISCC Networks: Sensing Accuracy Analysis and Precoding Design</title>
      <link>https://arxiv.org/abs/2601.00171</link>
      <description>arXiv:2601.00171v1 Announce Type: new 
Abstract: This work explores the relationship between sensing accuracy and precoding coefficients for edge artificial intelligence (AI) inference in integrated sensing, communication and computation (ISCC) networks. We start by constructing a system model of an over-the-air-empowered ISCC network for edge AI inference, involving distributed edge sensors for feature extraction and an edge server for classification. Based on this model, we introduce a discriminant gain (DG) to characterize sensing accuracy and novelly derive an explicit function of the DG about precoding coefficients, giving valuable insights into precoding design. Guided by this, we propose an effective precoding algorithm to solve a non-convex DG-maximization problem. Simulation results verify the effectiveness and feasibility of the proposed design for edge inference in ISCC networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00171v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lingyun Xu, Bowen Wang, Huiyong Li, Ziyang Cheng</dc:creator>
    </item>
    <item>
      <title>Time--to--Digital Converter (TDC)--Based Resonant Compute--in--Memory for INT8 CNNs with Layer--Optimized SRAM Mapping</title>
      <link>https://arxiv.org/abs/2601.00434</link>
      <description>arXiv:2601.00434v1 Announce Type: new 
Abstract: In recent years, Compute-in-memory (CiM) architectures have emerged as a promising solution for deep neural network (NN) accelerators. Multiply-accumulate~(MAC) is considered a {\textit de facto} unit operation in NNs. By leveraging the inherent parallel processing capabilities of CiM, NNs that require numerous MAC operations can be executed more efficiently. This is further facilitated by storing the weights in SRAM, reducing the need for extensive data movement and enhancing overall computational speed and efficiency. Traditional CiM architectures execute MAC operations in the analog domain, employing an Analog-to-Digital converter (ADC) to convert the analog MAC values into digital outputs. However, these ADCs introduce significant increase in area and power consumption, as well as introduce non-linearities. This work proposes a resonant time-domain compute-in-memory (TDC-CiM) architecture that eliminates the need for an ADC by using a time-to-digital converter (TDC) to digitize analog MAC results with lower power and area cost. A dedicated 8T SRAM cell enables reliable bitwise MAC operations, while the readout uses a 4-bit TDC with pulse-shrinking delay elements, achieving 1 GS/s sampling with a power consumption of only 1.25 mW. In addition, a weight stationary data mapping strategy combined with an automated SRAM macro selection algorithm enables scalable and energy-efficient deployment across CNN workloads. Evaluation across six CNN models shows that the algorithm reduces inference energy consumption by up to 8x when scaling SRAM size from 32~KB to 256~KB, while maintaining minimal accuracy loss after quantization. The feasibility of the proposed architecture is validated on an 8~KB SRAM memory array using TSMC 28~nm technology. The proposed TDC-CiM architecture demonstrates a throughput of 320~GOPS with an energy efficiency of 38.46~TOPS/W.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00434v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dhandeep Challagundla, Ignatius Bezzam, Riadul Islam</dc:creator>
    </item>
    <item>
      <title>MIMO-AFDM Outperforms MIMO-OFDM in the Face of Hardware Impairments</title>
      <link>https://arxiv.org/abs/2601.00502</link>
      <description>arXiv:2601.00502v1 Announce Type: new 
Abstract: The impact of both multiplicative and additive hardware impairments (HWIs) on multiple-input multiple-output affine frequency division multiplexing (MIMO-AFDM) systems is investigated. For small-scale MIMO-AFDM systems, a tight bit error rate (BER) upper bound associated with the maximum likelihood (ML) detector is derived. By contrast, for large-scale systems, a closed-form BER approximation associated with the linear minimum mean squared error (LMMSE) detector is presented, including realistic imperfect channel estimation scenarios. Our first key observation is that the full diversity order of a hardware-impaired AFDM system remains unaffected, which is a unique advantage. Furthermore, our analysis shows that 1) the BER results derived accurately predict the simulated ML performance in moderate-to-high signal-to-noise ratios (SNRs), while the theoretical BER curve of the LMMSE detector closely matches that of the Monte-Carlo based one. 2) MIMO-AFDM is more resilient to multiplicative distortions, such as phase noise and carrier frequency offset, compared to its orthogonal frequency division multiplexing (OFDM) counterparts. This is attributed to its inherent chirp signal characteristics; 3) MIMO-AFDM consistently achieves superior BER performance compared to conventional MIMO-OFDM systems under the same additive HWI conditions, as well as different velocity values. The latter is because MIMO-AFDM is also resilient to the additional inter-carrier interference (ICI) imposed by the nonlinear distortions of additive HWIs. In a nutshell, compared to OFDM, AFDM demonstrates stronger ICI resilience and achieves the maximum full diversity attainable gain even under HWIs, thanks to its intrinsic chirp signalling structure as well as to the beneficial spreading effect of the discrete affine Fourier transform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00502v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeping Sui, Zilong Liu, Leila Musavian, Yong Liang Guan, Lie-Liang Yang, Lajos Hanzo</dc:creator>
    </item>
    <item>
      <title>Parametrized Sharing for Multi-Agent Hybrid DRL for Multiple Multi-Functional RISs-Aided Downlink NOMA Networks</title>
      <link>https://arxiv.org/abs/2601.00538</link>
      <description>arXiv:2601.00538v1 Announce Type: new 
Abstract: Multi-functional reconfigurable intelligent surface (MF-RIS) is conceived to address the communication efficiency thanks to its extended signal coverage from its active RIS capability and self-sustainability from energy harvesting (EH). We investigate the architecture of multi-MF-RISs to assist non-orthogonal multiple access (NOMA) downlink networks. We formulate an energy efficiency (EE) maximization problem by optimizing power allocation, transmit beamforming and MF-RIS configurations of amplitudes, phase-shifts and EH ratios, as well as the position of MF-RISs, while satisfying constraints of available power, user rate requirements, and self-sustainability property. We design a parametrized sharing scheme for multi-agent hybrid deep reinforcement learning (PMHRL), where the multi-agent proximal policy optimization (PPO) and deep-Q network (DQN) handle continuous and discrete variables, respectively. The simulation results have demonstrated that proposed PMHRL has the highest EE compared to other benchmarks, including cases without parametrized sharing, pure PPO and DQN. Moreover, the proposed multi-MF-RISs-aided downlink NOMA achieves the highest EE compared to scenarios of no-EH/amplification, traditional RISs, and deployment without RISs/MF-RISs under different multiple access.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00538v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi-Te Kuo, Li-Hsiang Shen, Jyun-Jhe Huang</dc:creator>
    </item>
    <item>
      <title>Fractional Programming for Kullback-Leibler Divergence in Hypothesis Testing</title>
      <link>https://arxiv.org/abs/2601.00564</link>
      <description>arXiv:2601.00564v1 Announce Type: new 
Abstract: Maximizing the Kullback-Leibler divergence (KLD) is a fundamental problem in waveform design for active sensing and hypothesis testing, as it directly relates to the error exponent of detection probability. However, the associated optimization problem is highly nonconvex due to the intricate coupling of log-determinant and matrix trace terms. Existing solutions often suffer from high computational complexity, typically requiring matrix inversion at every iteration. In this paper, we propose a computationally efficient optimization framework based on fractional programming (FP). Our key idea is to reformulate the KLD maximization problem into a sequence of tractable quadratic subproblems using matrix FP. To further reduce complexity, we introduce a nonhomogeneous relaxation technique that replaces the costly linear system solver with a simple closed-form update, thereby reducing the per-iteration complexity to quadratic order. To compensate for the convergence speed trade-off caused by relaxation, we employ an acceleration method called STEM by interpreting the iterative scheme as a fixed-point mapping. The resulting algorithm achieves significantly faster convergence rates with low per-iteration cost. Numerical results demonstrate that our approach reduces the total runtime by orders of magnitude compared to a state-of-the-art benchmark. Finally, we apply the proposed framework to a multiple random access scenario and a joint integrated sensing and communication scenario, validating the efficacy of our framework in such applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00564v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jeongwoo Park, Seongkyu Jung, Kaiming Shen, Jeonghun Park</dc:creator>
    </item>
    <item>
      <title>WiFo-MUD: Wireless Foundation Model for Heterogeneous Multi-User Demodulator</title>
      <link>https://arxiv.org/abs/2601.00612</link>
      <description>arXiv:2601.00612v1 Announce Type: new 
Abstract: Multi-user signal demodulation is critical to wireless communications, directly impacting transmission reliability and efficiency. However, existing demodulators underperform in generic multi-user environments: classical demodulators struggle to balance accuracy and complexity, while deep learning-based methods lack adaptability under heterogeneous configurations. Although diffusion models have been introduced for demodulation, their flexibility remains limited for practical use. To address these issues, this work proposes WiFo-MUD, a universal diffusion-based foundation model for multi-user demodulation. The model aligns inter-user signal-to-noise ratio imbalance and performs conditional denoising via a customized backbone. Furthermore, a communication-aware consistency distillation method and a dynamic user-grouping strategy are devised to enhance inference. WiFo-MUD achieves state-of-the-art results on large-scale heterogeneous datasets, demonstrating efficient inference and strong generalization across varying system configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00612v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zonghui Yang, Shijian Gao, Xuesong Cai, Xiang Cheng, Liuqing Yang</dc:creator>
    </item>
    <item>
      <title>Splitting Precoding with Subspace Selection and Quantized Refinement for Massive MIMO</title>
      <link>https://arxiv.org/abs/2601.00616</link>
      <description>arXiv:2601.00616v1 Announce Type: new 
Abstract: Limited fronthaul capacity is a practical bottleneck in massive multiple-input multiple-output (MIMO) 5G architectures, where a base station (BS) consists of an advanced antenna system (AAS) connected to a baseband unit (BBU). Conventional downlink designs place the entire precoding computation at the BBU and transmit a high-dimensional precoding matrix over the fronthaul, resulting in substantial quantization losses and signaling overhead. This letter proposes a splitting precoding architecture that separates the design between the AAS and BBU. The AAS performs a local subspace selection to reduce the channel dimensionality, while the BBU computes an optimized quantized refinement precoding based on the resulting effective channel. The numerical results show that the proposed splitting precoding strategy achieves higher sum spectral efficiency than conventional one-stage precoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00616v1</guid>
      <category>eess.SP</category>
      <category>cs.AR</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasaman Khorsandmanesh, Emil Bjornson, Joakim Jalden</dc:creator>
    </item>
    <item>
      <title>Conformal Reconfigurable Intelligent Surfaces: A Cylindrical Geometry Perspective</title>
      <link>https://arxiv.org/abs/2601.00734</link>
      <description>arXiv:2601.00734v1 Announce Type: new 
Abstract: Curved reconfigurable intelligent surfaces (RISs) represent a promising frontier for next-generation wireless communication, enabling adaptive wavefront control on nonplanar platforms such as unmanned aerial vehicles and urban infrastructure. This work presents a systematic investigation of cylindrical RISs, progressing from idealized surface-impedance synthesis to practical implementations based on simple one-bit meta-atoms. Exact analytical and geometrical-optics-based models are first developed to explore fundamental design limits, followed by a semi-analytical formulation tailored to discrete, reconfigurable architectures. This model enables efficient beam synthesis using both evolutionary optimization and low-complexity strategies, including the minimum power distortionless response method, and is validated through full-wave simulations. Results confirm that one-bit RISs can achieve directive scattering with manageable sidelobe levels and minimal hardware complexity. These findings establish the viability of cylindrical RISs and open the door to their integration into dual-use wireless platforms for real-world communication scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00734v1</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Pepe, Ivan Iudice, Giuseppe Castaldi, Marco Di Renzo, Vincenzo Galdi</dc:creator>
    </item>
    <item>
      <title>Energy Efficiency Maximization of MIMO Systems through Reconfigurable Holographic Beamforming</title>
      <link>https://arxiv.org/abs/2601.00780</link>
      <description>arXiv:2601.00780v1 Announce Type: new 
Abstract: This study considers a point-to-point wireless link, in which both the transmitter and receiver are equipped with multiple antennas. In addition, two reconfigurable metasurfaces are deployed, one in the immediate vicinity of the transmit antenna array, and one in the immediate vicinity of the receive antenna array. The resulting architecture implements a holographic beamforming structure at both the transmitter and receiver. In this scenario, the system energy efficiency is optimized with respect to the transmit covariance matrix, and the reflection matrices of the two metasurfaces. A low-complexity algorithm is developed, which is guaranteed to converge to a first-order optimal point of the energy efficiency maximization problem. Moreover, closed-form expressions are derived for the metasurface matrices in the special case of single-antenna or single-stream transmission. The two metasurfaces are considered to be nearly-passive and subject to global reflection constraints. A numerical performance analysis is conducted to assess the performance of the proposed optimization methods, showing, in particular, that the use of holographic beamforming by metasurfaces can provide significant energy efficiency gains compared to fully digital beamforming architectures, even when the latter achieve substantial multiplexing gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00780v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Kuku Fotock, Alessio Zappone, Agbotiname Lucky Imoize, Marco Di Renzo</dc:creator>
    </item>
    <item>
      <title>Evolution of UE in Massive MIMO Systems for 6G: From Passive to Active</title>
      <link>https://arxiv.org/abs/2601.00251</link>
      <description>arXiv:2601.00251v1 Announce Type: cross 
Abstract: As wireless networks continue to evolve, stringent latency and reliability requirements and highly dynamic channels expose fundamental limitations of gNB-centric massive multiple-input multiple-output (mMIMO) architectures, motivating a rethinking of the user equipment (UE) role. In response, the UE is transitioning from a passive transceiver into an active entity that directly contributes to system-level performance. In this context, this article examines the evolving role of the UE in mMIMO systems during the transition from fifth-generation (5G) to sixth-generation (6G), bridging third generation partnership project (3GPP) standardization, device implementation, and architectural innovation. Through a chronological review of 3GPP Releases 15 to 19, we highlight the progression of UE functionalities from basic channel state information (CSI) reporting to artificial intelligence (AI) and machine learning (ML)-based CSI enhancement and UE-initiated beam management. We further examine key implementation challenges, including multi-panel UE (MPUE) architectures, on-device intelligent processing, and energy-efficient operation, and then discuss corresponding architectural innovations under practical constraints. Using digital-twin-based evaluations, we validate the impact of emerging UE-centric functionalities, illustrating that UE-initiated beam reporting improves throughput in realistic mobility scenarios, while a multi-panel architecture enhances link robustness compared with a single-panel UE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00251v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kwonyeol Park, Hyuckjin Choi, Geonho Han, Gyoseung Lee, Yeonjoon Choi, Sunwoo Park, Junil Choi</dc:creator>
    </item>
    <item>
      <title>Semantic Transmission Framework in Direct Satellite Communications</title>
      <link>https://arxiv.org/abs/2601.00381</link>
      <description>arXiv:2601.00381v1 Announce Type: cross 
Abstract: Insufficient link budget has become a bottleneck problem for direct access in current satellite communications. In this paper, we develop a semantic transmission framework for direct satellite communications as an effective and viable solution to tackle this problem. To measure the tradeoffs between communication, computation, and generation quality, we introduce a semantic efficiency metric with optimized weights. The optimization aims to maximize the average semantic efficiency metric by jointly optimizing transmission mode selection, satellite-user association, ISL task migration, denoising steps, and adaptive weights, which is a complex nonlinear integer programming problem. To maximize the average semantic efficiency metric, we propose a decision-assisted REINFORCE++ algorithm that utilizes feasibility-aware action space and a critic-free stabilized policy update. Numerical results show that the proposed algorithm achieves higher semantic efficiency than baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00381v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chong Huang, Xuyang Chen, Jingfu Li, Pei Xiao, Gaojie Chen, Rahim Tafazolli</dc:creator>
    </item>
    <item>
      <title>Detecting Spike Wave Discharges (SWD) using 1-dimensional Residual UNet</title>
      <link>https://arxiv.org/abs/2601.00459</link>
      <description>arXiv:2601.00459v1 Announce Type: cross 
Abstract: The manual labeling of events in electroencephalography (EEG) records is time-consuming. This is especially true when EEG recordings are taken continuously over weeks to months. Therefore, a method to automatically label pertinent EEG events reduces the manual workload. Spike wave discharges (SWD), which are the electrographic hallmark of absence seizures, are EEG events that are often labeled manually. While some previous studies have utilized machine learning to automatically segment and classify EEG signals like SWDs, they can be improved. Here we compare the performance of 14 machine learning classifiers on our own manually annotated dataset of 961 hours of EEG recordings from C3H/HeJ mice, including 22,637 labeled SWDs. We find that a 1D UNet performs best for labeling SWDs in this dataset. We also improve the 1D UNet by augmenting our training data and determine that scaling showed the greatest benefit of all augmentation procedures applied. We then compare the 1D UNet with data augmentation, AugUNet1D, against a recently published time- and frequency-based algorithmic approach called "Twin Peaks". AugUNet1D showed superior performance and detected events with more similar features to the SWDs labeled manually. AugUNet1D, pretrained on our manually annotated data or untrained, is made public for others users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00459v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Saurav Sengupta, Scott Kilianski, Suchetha Sharma, Sakina Lashkeri, Ashley McHugh, Mark Beenhakker, Donald E. Brown</dc:creator>
    </item>
    <item>
      <title>Real-Time Forecasting of Pathological Gait via IMU Navigation: A Few-Shot and Generative Learning Framework for Wearable Devices</title>
      <link>https://arxiv.org/abs/2405.09569</link>
      <description>arXiv:2405.09569v2 Announce Type: replace 
Abstract: Current gait analysis faces challenges in various aspects, including limited and poorly labeled data within existing wearable electronics databases, difficulties in collecting patient data due to privacy concerns, and the inadequacy of the Zero-Velocity Update Technique (ZUPT) in accurately analyzing pathological gait patterns. To address these limitations, we introduce GaitMotion, a novel machine-learning framework that employs few-shot learning on a multitask dataset collected via wearable IMU sensors for real-time pathological gait analysis. GaitMotion enhances data quality through detailed, ground-truth-labeled sequences and achieves accurate step and stride segmentation and stride length estimation, which are essential for diagnosing neurological disorders. We incorporate a generative augmentation component, which synthesizes rare or underrepresented pathological gait patterns. GaitMotion achieves a 65\% increase in stride length estimation accuracy compared to ZUPT. In addition, its application to real patient datasets via transfer learning confirms its robust predictive capability. By integrating generative AI into wearable gait analysis, GaitMotion not only refines the precision of pathological gait forecasting but also demonstrates a scalable framework for leveraging synthetic data in biomechanical pattern recognition, paving the way for more personalized and data-efficient digital health services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09569v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenwen Zhang, Hao Zhang, Zenan Jiang, Amir Servati, Peyman Servati</dc:creator>
    </item>
    <item>
      <title>Machine Learning based Radio Environment Map Estimation for Indoor Visible Light Communication</title>
      <link>https://arxiv.org/abs/2507.19149</link>
      <description>arXiv:2507.19149v2 Announce Type: replace 
Abstract: Novel radio map estimation in optical wireless communications is proposed based on ML prediction rather than simulation techniques. ML training is performed on simulation and experimentally generated synthetic data and in both cases, prediction is fast and of high accuracy. Among various models, Multi-Layer Perceptron (MLP) representation of indoor Visible Light Communication (VLC) systems outperforms the others with respect to RSS that is estimated for various indoor systems. The predicted RSS is very accurate and fast and requires a reduced set of training sample size with respect to other counterparts, making this solution very suitable for real time estimation of an indoor VLC system. It is shown that by tweaking MLP parameters, such as sample size, number of epochs and batch size, one can balance the desired level of inference accuracy with training time and optimize the model's performance to meet real-time requirements. Furthermore, experimental data from a PureLiFi system has been used in a proof-of-concept production of synthetic data radio map prediction based on MLP. Using SMOGN-generated synthetic data derived from fewer than 100 experimental measurements, our MLP model achieves strong regression performance on the experimental measurements, demonstrating successful synthetic-to-real generalization without direct training on the full experimental dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19149v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Helena Serpi (Tanya),  Christina (Tanya),  Politi</dc:creator>
    </item>
    <item>
      <title>Affine Frequency Division Multiplexing (AFDM) for 6G: Properties, Features, and Challenges</title>
      <link>https://arxiv.org/abs/2507.21704</link>
      <description>arXiv:2507.21704v4 Announce Type: replace 
Abstract: Affine frequency division multiplexing (AFDM) is an emerging waveform candidate for future sixth generation (6G) systems offering a range of promising features, such as enhanced robustness in heterogeneous and high-mobility environments, as well as inherent suitability for integrated sensing and communications (ISAC) applications. In addition, unlike other candidates such as orthogonal time-frequency space (OTFS) modulation, AFDM provides several unique advantages that strengthen its relevance to practical deployment and standardization in 6G. Notably, as a natural generalization of orthogonal frequency division multiplexing (OFDM), strong backward compatibility with existing conventional systems is guaranteed, while also offering novel possibilities in waveform design, for example to enable physical-layer security through its inherent chirp parametrization. In all, this article provides an overview of AFDM, emphasizing its suitability as a candidate waveform for 6G standardization. First, we provide a concise introduction to the fundamental properties and unique characteristics of AFDM, followed by highlights of its advantageous features, and finally a discussion of its potential and challenges in 6G standardization efforts and representative requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21704v4</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/MCOMSTD.2025.3643183</arxiv:DOI>
      <dc:creator>Hyeon Seok Rou, Kuranage Roche Rayan Ranasinghe, Vincent Savaux, Giuseppe Thadeu Freitas de Abreu, David Gonz\'alez G., Christos Masouros</dc:creator>
    </item>
    <item>
      <title>Quasi-Deterministic Modeling of Sub-THz Band Access Channels in Street Canyon Environments</title>
      <link>https://arxiv.org/abs/2509.10752</link>
      <description>arXiv:2509.10752v2 Announce Type: replace 
Abstract: Sub-terahertz (sub-THz) frequencies (100--300 GHz) are expected to play a key role in beyond-5G and 6G mobile networks. However, their quasi-optical propagation characteristics require new channel models beyond sub-100 GHz extrapolations. This paper presents an extensive double-directional (D-D) channel measurement campaign conducted in an outdoor street-canyon environment at 154 GHz and 300 GHz under both line-of-sight (LoS) and non-line-of-sight (NLoS) conditions using an in-house-developed multi-tone frequency-domain channel sounder. Based on these measurements, clustering with merged datasets across the two frequencies enables comparative analyses that identify both common and distinct multipath clusters, as well as the frequency dependence of cluster-level characteristics. A quasi-deterministic (Q-D) channel model is then proposed, combining deterministic components, such as LoS and single-bounce reflections from side walls, with random components. Large-scale parameters (path loss, delay spread, angular spread, and Rician $K$-factor) are also evaluated. These results provide valuable insights into sub-THz propagation in urban street canyons and contribute toward the development of accurate, channel models for future 6G systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10752v2</guid>
      <category>eess.SP</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minseok Kim, Masato Yomoda, Minghe Mao, Nobuaki Kuno, Koshiro Kitao, Satoshi Suyama</dc:creator>
    </item>
    <item>
      <title>RadarPLM: Adapting Pre-trained Language Models for Marine Radar Target Detection by Selective Fine-tuning</title>
      <link>https://arxiv.org/abs/2509.12089</link>
      <description>arXiv:2509.12089v4 Announce Type: replace 
Abstract: Recent advances in pre-trained language models (PLMs) have demonstrated their capabilities in capturing universal knowledge, making them promising for radar signal processing applications. Nevertheless, directly fine-tuning PLMs on radar signals is both computationally expensive and prone to overfitting, particularly in low signal-to-clutter ratio (SCR) environments. In this paper, we propose a novel fine-tuning framework for PLM-based marine radar target detection. First, we design a lightweight adaptation module, enabling computationally efficient fine-tuning while preserving the pre-trained model's general knowledge. Second, a novel preference-aware loss is developed to selectively optimize different feature patches based on their online-evaluated learning values, guiding the model to concentrate on those generalizable feature patterns during optimization. Finally, a binary classification head is retrained based on autoencoder network to further enhance detection performance. Experiments on real-world radar data show that the proposed RadarPLM framework yields at least a 6.35% improvement in detection performance over the existing networks under low SCR conditions. Especially, in small training samples cases,the proposed RadarPLM also achieves significant advantage over existing networks owing to the incorporation of the PLM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12089v4</guid>
      <category>eess.SP</category>
      <category>cs.CL</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiying Hu, Yaowen Li, Xueqian Wang, Linping Zhang, Junlong Ke, Gang Li, Yu Liu, You He</dc:creator>
    </item>
    <item>
      <title>Parameter Training Efficiency Aware Resource Allocation for AIGC in Space-Air-Ground Integrated Networks</title>
      <link>https://arxiv.org/abs/2406.13602</link>
      <description>arXiv:2406.13602v3 Announce Type: replace-cross 
Abstract: With the evolution of artificial intelligence-generated content (AIGC) techniques and the development of space-air-ground integrated networks (SAGIN), there will be a growing opportunity to enhance more users' mobile experience with customized AIGC applications. This is made possible through the use of parameter-efficient fine-tuning (PEFT) training alongside mobile edge computing. In this paper, we formulate the optimization problem of maximizing the parameter training efficiency of the SAGIN system over wireless networks under limited resource constraints. We propose the Parameter training efficiency Aware Resource Allocation (PARA) technique to jointly optimize user association, data offloading, and communication and computational resource allocation. Solid proofs are presented to solve this difficult sum of ratios problem based on quadratically constrained quadratic programming (QCQP), semidefinite programming (SDP), graph theory, and fractional programming (FP) techniques. Our proposed PARA technique is effective in finding a stationary point of this non-convex problem. The simulation results demonstrate that the proposed PARA method outperforms other baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13602v3</guid>
      <category>cs.ET</category>
      <category>eess.SP</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liangxin Qian, Peiyuan Si, Jun Zhao, Kwok-Yan Lam</dc:creator>
    </item>
    <item>
      <title>Dual-Scale Channel Estimation in Sensing-Assisted Communication Systems: Joint Time Allocation and Beamforming Design</title>
      <link>https://arxiv.org/abs/2411.05267</link>
      <description>arXiv:2411.05267v2 Announce Type: replace-cross 
Abstract: In this paper, we propose a novel integrated sensing and communication (ISAC)-enabled dual-scale channel estimation framework, where large-scale channel estimation benefits from sensing, and the temporal variation of small-scale channel state information is modeled via channel aging. By characterizing the impact of angular sensing error on the communication spatial correlation matrix, we derive a closed form expression for the achievable rate under dual-scale channel estimation errors. Considering the different characteristics in time scales, we design the sensing duration for slow-varying large-scale channel and determine the update timing and frequency for fast-varying small-scale channel information within a given frame structure. We formulate an average achievable rate maximization problem under limited time resources and sensing Cramer-Rao bound (CRB) constraints, and propose a segmented golden based joint optimization algorithm to efficiently solve this nonconvex problem. Simulation results demonstrate that our proposed scheme achieves significant performance improvement compared with the benchmark schemes, which further validate that the system can leverage additional sensing capabilities to enhance communication efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05267v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bai Zhiyue (Sherman), Dai Minghui (Sherman), Hou Fen (Sherman), Shan hangguan (Sherman), Cai X Lin (Sherman),  Shen (Sherman),  Xuemin</dc:creator>
    </item>
  </channel>
</rss>
