<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 Mar 2024 04:00:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 28 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Study of Three Influencer Archetypes for the Control of Opinion Spread in Time-Varying Social Networks</title>
      <link>https://arxiv.org/abs/2403.18163</link>
      <description>arXiv:2403.18163v1 Announce Type: new 
Abstract: In this work we consider the impact of information spread in time-varying social networks, where agents request to follow other agents with aligned opinions while dropping ties to neighbors whose posts are too dissimilar to their own views. Opinion control and rhetorical influence has a very long history, employing various methods including education, persuasion, propaganda, marketing, and manipulation through mis-, dis-, and mal-information. The automation of opinion controllers, however, has only recently become easily deployable at a wide scale, with the advent of large language models (LLMs) and generative AI that can translate the quantified commands from opinion controllers into actual content with the appropriate nuance. Automated agents in social networks can be deployed for various purposes, such as breaking up echo chambers, bridging valuable new connections between agents, or shaping the opinions of a target population -- and all of these raise important ethical concerns that deserve serious attention and thoughtful discussion and debate. This paper attempts to contribute to this discussion by considering three archetypal influencing styles observed by human drivers in these settings, comparing and contrasting the impact of these different control methods on the opinions of agents in the network. We will demonstrate the efficacy of current generative AI for generating nuanced content consistent with the command signal from automatic opinion controllers like these, and we will report on frameworks for approaching the relevant ethical considerations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18163v1</guid>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Michael DeBuse, Sean Warnick</dc:creator>
    </item>
    <item>
      <title>The process of polarisation as a loss of dimensionality: measuring changes in polarisation using Singular Value Decomposition of network graphs</title>
      <link>https://arxiv.org/abs/2403.18191</link>
      <description>arXiv:2403.18191v1 Announce Type: new 
Abstract: The increasing polarisation in our societies is a major international concern. Current approaches to defining and detecting polarisation largely rely on finding evidence of bimodality in social networks or voter opinion surveys. It is difficult to detect temporal trends in polarisation, as the results usually fall into a binary of polarised or non-polarised, which cannot robustly show that subsequent increases in bimodality are statistically significant.
  Our work is aligned with Baldassari and Gelman's theory that polarisation should be defined as increasing correlation between positions in the ideological field. We also draw from post-structuralist work which argues that polarisation is the process of both the ideological and material layers of society being segregated into two poles, as in cases of apartheid. Thus, in order to measure the polarisation in a society, it would be beneficial to be able to assess social networks directly.
  In this paper we use Random Dot Product Graphs to embed social networks in metric spaces. In the case of a social network, the embedded dimensionality corresponds to the number of reasons any two people may form a social connection. A decrease in the optimal dimensionality for the embedding of the network graph, as measured using truncated Singular Value Decomposition of the graph adjacency matrix, indicates increasing polarisation in the network.
  We apply this method to two different Twitter networks based on discussions of climate change, and show that our methods agree with other researchers' detection of polarisation in this space. We also use networks generated by stochastic block models to explore how an increase of the isolation between distinct communities in a network, or the increase in the predominance of one community over the other, are identifiable as polarisation processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18191v1</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sage Anastasi, Giulio Dalla Riva</dc:creator>
    </item>
    <item>
      <title>Exploring the Deceptive Power of LLM-Generated Fake News: A Study of Real-World Detection Challenges</title>
      <link>https://arxiv.org/abs/2403.18249</link>
      <description>arXiv:2403.18249v1 Announce Type: cross 
Abstract: Recent advancements in Large Language Models (LLMs) have enabled the creation of fake news, particularly in complex fields like healthcare. Studies highlight the gap in the deceptive power of LLM-generated fake news with and without human assistance, yet the potential of prompting techniques has not been fully explored. Thus, this work aims to determine whether prompting strategies can effectively narrow this gap. Current LLM-based fake news attacks require human intervention for information gathering and often miss details and fail to maintain context consistency. Therefore, to better understand threat tactics, we propose a strong fake news attack method called conditional Variational-autoencoder-Like Prompt (VLPrompt). Unlike current methods, VLPrompt eliminates the need for additional data collection while maintaining contextual coherence and preserving the intricacies of the original text. To propel future research on detecting VLPrompt attacks, we created a new dataset named VLPrompt fake news (VLPFN) containing real and fake texts. Our experiments, including various detection methods and novel human study metrics, were conducted to assess their performance on our dataset, yielding numerous findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18249v1</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanshen Sun, Jianfeng He, Limeng Cui, Shuo Lei, Chang-Tien Lu</dc:creator>
    </item>
    <item>
      <title>Many-Objective Evolutionary Influence Maximization: Balancing Spread, Budget, Fairness, and Time</title>
      <link>https://arxiv.org/abs/2403.18755</link>
      <description>arXiv:2403.18755v1 Announce Type: cross 
Abstract: The Influence Maximization (IM) problem seeks to discover the set of nodes in a graph that can spread the information propagation at most. This problem is known to be NP-hard, and it is usually studied by maximizing the influence (spread) and, optionally, optimizing a second objective, such as minimizing the seed set size or maximizing the influence fairness. However, in many practical scenarios multiple aspects of the IM problem must be optimized at the same time. In this work, we propose a first case study where several IM-specific objective functions, namely budget, fairness, communities, and time, are optimized on top of the maximization of influence and minimization of the seed set size. To this aim, we introduce MOEIM (Many-Objective Evolutionary Algorithm for Influence Maximization) a Multi-Objective Evolutionary Algorithm (MOEA) based on NSGA-II incorporating graph-aware operators and a smart initialization. We compare MOEIM in two experimental settings, including a total of nine graph datasets, two heuristic methods, a related MOEA, and a state-of-the-art Deep Learning approach. The experiments show that MOEIM overall outperforms the competitors in most of the tested many-objective settings. To conclude, we also investigate the correlation between the objectives, leading to novel insights into the topic. The codebase is available at https://github.com/eliacunegatti/MOEIM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18755v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3638530.3654161</arxiv:DOI>
      <dc:creator>Elia Cunegatti, Leonardo Lucio Custode, Giovanni Iacca</dc:creator>
    </item>
    <item>
      <title>The Innovation Paradox: Concept Space Expansion with Diminishing Originality and the Promise of Creative AI</title>
      <link>https://arxiv.org/abs/2303.13300</link>
      <description>arXiv:2303.13300v3 Announce Type: replace 
Abstract: Innovation, typically spurred by reusing, recombining, and synthesizing existing concepts, is expected to result in an exponential growth of the concept space over time. However, our statistical analysis of TechNet, which is a comprehensive technology semantic network encompassing over four million concepts derived from patent texts, reveals a linear rather than exponential expansion of the overall technological concept space. Moreover, there is a notable decline in the originality of newly created concepts. These trends can be attributed to the constraints of human cognitive abilities to innovate beyond an ever-growing space of prior art, among other factors. Integrating creative artificial intelligence (CAI) into the innovation process holds the potential to overcome these limitations and alter the observed trends in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.13300v3</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Serhad Sarica, Jianxi Luo</dc:creator>
    </item>
    <item>
      <title>Demystifying Misconceptions in Social Bots Research</title>
      <link>https://arxiv.org/abs/2303.17251</link>
      <description>arXiv:2303.17251v2 Announce Type: replace 
Abstract: Research on social bots aims at advancing knowledge and providing solutions to one of the most debated forms of online manipulation. Yet, social bot research is plagued by widespread biases, hyped results, and misconceptions that set the stage for ambiguities, unrealistic expectations, and seemingly irreconcilable findings. Overcoming such issues is instrumental towards ensuring reliable solutions and reaffirming the validity of the scientific method. In this contribution, we review some recent results in social bots research, highlighting and revising factual errors as well as methodological and conceptual biases. More importantly, we demystify common misconceptions, addressing fundamental points on how social bots research is discussed. Our analysis surfaces the need to discuss research about online disinformation and manipulation in a rigorous, unbiased, and responsible way. This article bolsters such effort by identifying and refuting common fallacious arguments used by both proponents and opponents of social bots research, as well as providing directions toward sound methodologies for future research in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.17251v2</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefano Cresci, Kai-Cheng Yang, Angelo Spognardi, Roberto Di Pietro, Filippo Menczer, Marinella Petrocchi</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Review of Community Detection in Graphs</title>
      <link>https://arxiv.org/abs/2309.11798</link>
      <description>arXiv:2309.11798v3 Announce Type: replace 
Abstract: The study of complex networks has significantly advanced our understanding of community structures which serves as a crucial feature of real-world graphs. Detecting communities in graphs is a challenging problem with applications in sociology, biology, and computer science. Despite the efforts of an interdisciplinary community of scientists, a satisfactory solution to this problem has not yet been achieved. This review article delves into the topic of community detection in graphs, which serves as a thorough exposition of various community detection methods from perspectives of modularity-based method, spectral clustering, probabilistic modelling, and deep learning. Along with the methods, a new community detection method designed by us is also presented. Additionally, the performance of these methods on the datasets with and without ground truth is compared. In conclusion, this comprehensive review provides a deep understanding of community detection in graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.11798v3</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiakang Li, Songning Lai, Zhihao Shuai, Yuan Tan, Yifan Jia, Mianyang Yu, Zichen Song, Xiaokang Peng, Ziyang Xu, Yongxin Ni, Haifeng Qiu, Jiayu Yang, Yutong Liu, Yonggang Lu</dc:creator>
    </item>
    <item>
      <title>Detection and Discovery of Misinformation Sources using Attributed Webgraphs</title>
      <link>https://arxiv.org/abs/2401.02379</link>
      <description>arXiv:2401.02379v3 Announce Type: replace 
Abstract: Website reliability labels underpin almost all research in misinformation detection. However, misinformation sources often exhibit transient behavior, which makes many such labeled lists obsolete over time. We demonstrate that Search Engine Optimization (SEO) attributes provide strong signals for predicting news site reliability. We introduce a novel attributed webgraph dataset with labeled news domains and their connections to outlinking and backlinking domains. We demonstrate the success of graph neural networks in detecting news site reliability using these attributed webgraphs, and show that our baseline news site reliability classifier outperforms current SoTA methods on the PoliticalNews dataset, achieving an F1 score of 0.96. Finally, we introduce and evaluate a novel graph-based algorithm for discovering previously unknown misinformation news sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.02379v3</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Carragher, Evan M. Williams, Kathleen M. Carley</dc:creator>
    </item>
    <item>
      <title>Partial Mobilization: Tracking Multilingual Information Flows Amongst Russian Media Outlets and Telegram</title>
      <link>https://arxiv.org/abs/2301.10856</link>
      <description>arXiv:2301.10856v3 Announce Type: replace-cross 
Abstract: In response to disinformation and propaganda from Russian online media following the invasion of Ukraine, Russian media outlets such as Russia Today and Sputnik News were banned throughout Europe. To maintain viewership, many of these Russian outlets began to heavily promote their content on messaging services like Telegram. In this work, we study how 16 Russian media outlets interacted with and utilized 732 Telegram channels throughout 2022. Leveraging the foundational model MPNet, DP-means clustering, and Hawkes processes, we trace how narratives spread between news sites and Telegram channels. We show that news outlets not only propagate existing narratives through Telegram but that they source material from the messaging platform. For example, across the websites in our study, between 2.3% (ura.news) and 26.7% (ukraina.ru) of articles discussed content that originated/resulted from activity on Telegram. Finally, tracking the spread of individual topics, we measure the rate at which news outlets and Telegram channels disseminate content within the Russian media ecosystem, finding that websites like ura.news and Telegram channels such as @genshab are the most effective at disseminating their content.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.10856v3</guid>
      <category>cs.CY</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hans W. A. Hanley, Zakir Durumeric</dc:creator>
    </item>
    <item>
      <title>Polyamorous Scheduling</title>
      <link>https://arxiv.org/abs/2403.00465</link>
      <description>arXiv:2403.00465v2 Announce Type: replace-cross 
Abstract: Finding schedules for pairwise meetings between the members of a complex social group without creating interpersonal conflict is challenging, especially when different relationships have different needs. We formally define and study the underlying optimisation problem: Polyamorous Scheduling.
  In Polyamorous Scheduling, we are given an edge-weighted graph and try to find a periodic schedule of matchings in this graph such that the maximal weighted waiting time between consecutive occurrences of the same edge is minimised. We show that the problem is NP-hard and that there is no efficient approximation algorithm with a better ratio than 4/3 unless P = NP. On the positive side, we obtain an $O(\log n)$-approximation algorithm; indeed, a $O(\log \Delta)$-approximation for $\Delta$ the maximum degree, i.e., the largest number of relationships of any individual. We also define a generalisation of density from the Pinwheel Scheduling Problem, "poly density", and ask whether there exists a poly-density threshold similar to the 5/6-density threshold for Pinwheel Scheduling [Kawamura, STOC 2024]. Polyamorous Scheduling is a natural generalisation of Pinwheel Scheduling with respect to its optimisation variant, Bamboo Garden Trimming.
  Our work contributes the first nontrivial hardness-of-approximation reduction for any periodic scheduling problem, and opens up numerous avenues for further study of Polyamorous Scheduling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00465v2</guid>
      <category>cs.DS</category>
      <category>cs.SI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Leszek G\k{a}sieniec, Benjamin Smith, Sebastian Wild</dc:creator>
    </item>
  </channel>
</rss>
