<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Mar 2025 01:53:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Recent Developments in Deep Learning-based Author Name Disambiguation</title>
      <link>https://arxiv.org/abs/2503.13448</link>
      <description>arXiv:2503.13448v1 Announce Type: new 
Abstract: Author Name Disambiguation (AND) is a critical task for digital libraries aiming to link existing authors with their respective publications. Due to the lack of persistent identifiers used by researchers and the presence of intrinsic linguistic challenges, such as homonymy, the development of Deep Learning algorithms to address this issue has become widespread. Many AND deep learning methods have been developed, and surveys exist comparing the approaches in terms of techniques, complexity, performance. However, none explicitly addresses AND methods in the context of deep learning in the latest years (i.e. timeframe 2016-2024). In this paper, we provide a systematic review of state-of-the-art AND techniques based on deep learning, highlighting recent improvements, challenges, and open issues in the field. We find that DL methods have significantly impacted AND by enabling the integration of structured and unstructured data, and hybrid approaches effectively balance supervised and unsupervised learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13448v1</guid>
      <category>cs.DL</category>
      <category>cs.CL</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesca Cappelli, Giovanni Colavizza, Silvio Peroni</dc:creator>
    </item>
    <item>
      <title>Network Analysis, Plot Theory: Revisiting French Literature through Character Networks</title>
      <link>https://arxiv.org/abs/2503.13449</link>
      <description>arXiv:2503.13449v1 Announce Type: new 
Abstract: Character recognition is a technique that enables the automated extraction of characters from texts, while coreference resolution establishes connections between various mentions of the same character, collectively facilitating the creation of expansive character networks (Moretti, 2011). Together, these technologies make it possible to navigate and analyze large literary corpora, opening new avenues for in-depth exploration and understanding of literature. We have created a system specifically for the French language, based on BookNLP-fr (the French counterpart of BookNLP) and NetworkX (a Python package for the manipulation and visualization of complex networks). This allows us to establish connections between series of literary works based on structural features (such as typical relationships between characters) or specific subgenres (for instance, adventure novels featuring a group of young heroes). In this paper, as an illustration, we show the networks obtained at different stages of the short novel Boule de Suif from Maupassant (a French 19th century novelist). These figures effectively illustrate how the relationships between the characters develop over the course of the story.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13449v1</guid>
      <category>cs.DL</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Newman Chen (ENS-PSL, CNRS, U. Sorbonne nouvelle), Fr\'ed\'erique M\'elanie-Becquet (ENS-PSL, CNRS, U. Sorbonne nouvelle), Jean Barr\'e (ENS-PSL, CNRS, U. Sorbonne nouvelle), Thierry Poibeau (ENS-PSL, CNRS, U. Sorbonne nouvelle)</dc:creator>
    </item>
    <item>
      <title>2024 Google Scholar Research Interest Ranking for Top 3260 Computer Science Authors</title>
      <link>https://arxiv.org/abs/2503.13451</link>
      <description>arXiv:2503.13451v1 Announce Type: new 
Abstract: Computer science research spans a diverse array of topics, with scholars exploring numerous subfields. This paper examines the self-reported research interests of the top 3,260 most cited computer science authors on Google Scholar. Using the scholarly Python library, we systematically retrieved and classified their interests into predefined categories based on the Computer Science Ontology (CSO). The analysis highlights a hierarchy of primary research areas, including Artificial Intelligence, Software Engineering, Data Mining, and Computer Systems. Additionally, it investigates the distribution of these interests, identifying emerging trends, established fields, and areas with relatively less attention. These findings provide a current snapshot of research priorities and serve as a foundation for guiding future studies in computer science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13451v1</guid>
      <category>cs.DL</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Atharva Rasane</dc:creator>
    </item>
    <item>
      <title>Digital audiovisual archives in humanities</title>
      <link>https://arxiv.org/abs/2503.13452</link>
      <description>arXiv:2503.13452v1 Announce Type: new 
Abstract: This report, authored in 2003, presents an innovative approach to the management and utilization of audiovisual archives in the humanities and social sciences. Developed by the research team ESCoM, under the auspices of the Maison des Sciences de l'Homme (MSH) in Paris, this program predated platforms like YouTube and was groundbreaking in its vision for the digital preservation, segmentation, and classification of audiovisual content. Its objectives included creating a heritage of scientific knowledge, developing advanced tools for its annotation and reuse, and facilitating the dissemination of specialized research to a broad audience.At its core, the report outlines the development of an integrated environment that allows users to index, annotate, and classify audiovisual segments through personalized ontologies and thematic grids. The proposed methods rely on cutting-edge concepts, such as semantic web technologies, knowledge representation, and conceptual graph editing, to enable researchers and educators to create tailored archives and new multimedia resources. This forward-thinking approach aligns with modern practices of content reuse and republication, demonstrating a vision well ahead of its time.The program also emphasizes the importance of segmenting and indexing audiovisual materials based on user-defined criteria, enabling researchers to identify and highlight specific thematic or conceptual elements within a vast pool of data. By facilitating this level of granularity, the system supports personalized academic and professional applications, including multimedia presentations, educational resources, and research dissemination. It introduces tools such as enhanced media players, ontology builders, and annotation editors to make this process accessible and collaborative.Finally, the report discusses the Opales project, a collaborative initiative that exemplifies this innovative framework. The project developed a prototype environment integrating tools for creating ''hyper-documents'' and supporting multilingual, multi-platform content dissemination. Despite the technological and methodological challenges of the time, the report's vision of interactive, richly annotated audiovisual archives has set the stage for the development of contemporary digital knowledge ecosystems. Its emphasis on semantic representation and user-centric customization continues to resonate in the digital humanities today.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13452v1</guid>
      <category>cs.DL</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Stockinger (ESCOM, PLIDAM EA 4514, Inalco)</dc:creator>
    </item>
    <item>
      <title>E-Semiotics</title>
      <link>https://arxiv.org/abs/2503.13453</link>
      <description>arXiv:2503.13453v1 Announce Type: new 
Abstract: E-Semiotics is a conceptual and practical framework for designing, developing, and managing digital information and knowledge products. It applies semiotic principles to digital environments, focusing on the structural, contextual, and narrative organization of information. Central to E-Semiotics is the concept of ''scenario building,'' which acts as a template or guide for creating and maintaining digital products and services, ensuring usability, adaptability, and efficiency.This approach distinguishes itself from traditional semiotics by addressing the unique features of digital media, such as interactivity, hypertextuality, and modularity. It requires a dual competency in semiotics and technology, making it particularly relevant for developing interactive digital products like e-learning systems, digital libraries, and web portals. E-Semiotics also integrates seamlessly with knowledge management, offering conceptual models and technological tools to optimize the storage, retrieval, and dissemination of information.The methodology includes both a semiotic approach, which focuses on understanding the structural and contextual dimensions of information, and a technological approach, which ensures interoperability, reusability, and scalability of digital tools. It has broad applications in areas such as multi-support publishing, semantic web development, and the creation of dynamic websites and web services. These applications empower organizations, particularly small and medium-sized ones, to leverage digital technologies without extensive technical expertise.E-Semiotics faces challenges like conceptual complexity and economic barriers, but its potential lies in democratizing access to digital tools and fostering innovation. It bridges the gap between theory and practice, offering scalable solutions that respond to evolving user needs. This framework is poised to play a critical role in the digital transformation of communication and knowledge systems, supporting organizations in adapting to the demands of a rapidly changing digital landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13453v1</guid>
      <category>cs.DL</category>
      <category>cs.CY</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Stockinger (Inalco, PLIDAM EA 4514, CFI, ESCOM)</dc:creator>
    </item>
    <item>
      <title>The imperative for reproducibility in building performance simulation research</title>
      <link>https://arxiv.org/abs/2503.13454</link>
      <description>arXiv:2503.13454v1 Announce Type: new 
Abstract: Building Performance Simulation (BPS) uses advanced computational and data science methods. Reproducibility, the ability to obtain the same results by using the same data and methods, is essential in BPS research to ensure the reliability and validity of scientific results. The benefits of reproducible research include enhanced scientific integrity, faster scientific advancements, and valuable educational resources. Despite its importance, reproducibility in BPS is often overlooked due to technical complexities, insufficient documentation, and cultural barriers such as the lack of incentives for sharing code and data. This paper encourages the reproducibility of articles on computational science and proposes to recognize reproductible code and data, with persistent Digital Object Identifier (DOI), as peer-reviewed archival publications. Practical workflows for achieving reproducibility in BPS are presented for the use of MATLAB and Python.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13454v1</guid>
      <category>cs.DL</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/19401493.2024.2441385</arxiv:DOI>
      <arxiv:journal_reference>Journal of Building Performance Simulation, 2025, pp.1-7</arxiv:journal_reference>
      <dc:creator>Christian Ghiaus (CETHIL)</dc:creator>
    </item>
    <item>
      <title>How good is the h-index?</title>
      <link>https://arxiv.org/abs/2503.13456</link>
      <description>arXiv:2503.13456v1 Announce Type: new 
Abstract: The h-index has become a widely used metric for evaluating the productivity and citation impact of researchers. Introduced by physicist Jorge E. Hirsch in 2005, the h-index measures both the quantity (number of publications) and quality (citations) of a researcher's output. While it has gained popularity for its simplicity and practicality, the h-index is not without its limitations. We examine the strengths and weaknesses of this metric, presenting preliminary experimental results that demonstrate the limitations of the h-index. We also propose a potential solution. The primary aim of this work is to shed light on the shortcomings of the h-index and its implications for ranking scientists, motivating them, allocating funding, and advancing science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13456v1</guid>
      <category>cs.DL</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Borji</dc:creator>
    </item>
    <item>
      <title>Los beneficios de un sistema CRIS para la investigaci\'on cient\'ifica</title>
      <link>https://arxiv.org/abs/2503.13459</link>
      <description>arXiv:2503.13459v1 Announce Type: new 
Abstract: The visibility of research projects is crucial for maximizing their scientific and societal impact. Current Research Information Systems (CRIS) centralize data, enhancing access, the dissemination of results, and interdisciplinary collaboration. This article examines how CRIS improves global reach, funding opportunities, and adherence to open science principles, contrasting these advantages with the limitations faced by projects without such systems. CRIS proves to be essential tools for optimizing information management, strengthening research, and positioning institutions within the global scientific community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13459v1</guid>
      <category>cs.DL</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ReIbCi, Vol. 11, No. 3, December 2024, pp. 223-228</arxiv:journal_reference>
      <dc:creator>Kevin Lajpop, Ana Ixcolin</dc:creator>
    </item>
    <item>
      <title>Self-Citations in Academic Excellence: Analysis of the Top 1% Highly Cited India-Affiliated Research Papers</title>
      <link>https://arxiv.org/abs/2503.13460</link>
      <description>arXiv:2503.13460v1 Announce Type: new 
Abstract: Citations demonstrate the credibility, impact, and connection of a paper with the academic community. Self-citations support research continuity but, if excessive, may inflate metrics and raise bias concerns. The aim of the study is to examine the role of self-citations towards the research impact of India. To study this, 3.58 million papers affiliated with India from 1947 to 2024 in the Scopus database were downloaded, and 2.96 million were filtered according to document type and publication year up to 2023. Further filtering based on high citation counts identified the top 1% of highly cited papers, totaling 29,556. The results indicate that the impact of Indian research, measured by highly cited papers, has grown exponentially since 2000, reaching a peak during the 2011-2020 decade. Among the citations received by these 29,556 papers, 6% are self-citations. Papers with a high proportion of self-citations (&gt;90%) are predominantly from recent decades and are associated with smaller team sizes. The findings also reveal that smaller teams are primarily domestic, whereas larger teams are more likely to involve international collaborations. Domestic collaborations dominate smaller team sizes in terms of both self-citations and publications, whereas international collaborations gain prominence as team sizes increase. The results indicate that while domestic collaborations produce a higher number of highly cited papers, international collaborations are more likely to generate self-citations. The top international collaborators in highly cited papers are the USA, followed by UK, and Germany.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13460v1</guid>
      <category>cs.DL</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kiran Sharma, Parul Khurana</dc:creator>
    </item>
    <item>
      <title>Completeness of Datasets Documentation on ML/AI repositories: an Empirical Investigation</title>
      <link>https://arxiv.org/abs/2503.13463</link>
      <description>arXiv:2503.13463v1 Announce Type: new 
Abstract: ML/AI is the field of computer science and computer engineering that arguably received the most attention and funding over the last decade. Data is the key element of ML/AI, so it is becoming increasingly important to ensure that users are fully aware of the quality of the datasets that they use, and of the process generating them, so that possible negative impacts on downstream effects can be tracked, analysed, and, where possible, mitigated. One of the tools that can be useful in this perspective is dataset documentation. The aim of this work is to investigate the state of dataset documentation practices, measuring the completeness of the documentation of several popular datasets in ML/AI repositories. We created a dataset documentation schema -- the Documentation Test Sheet (DTS) -- that identifies the information that should always be attached to a dataset (to ensure proper dataset choice and informed use), according to relevant studies in the literature. We verified 100 popular datasets from four different repositories with the DTS to investigate which information was present. Overall, we observed a lack of relevant documentation, especially about the context of data collection and data processing, highlighting a paucity of transparency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13463v1</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-49008-8_7</arxiv:DOI>
      <arxiv:journal_reference>Progress in Artificial Intelligence. EPIA 2023. Lecture Notes in Computer Science(), vol 14115. Springer, Cham</arxiv:journal_reference>
      <dc:creator>Marco Rondina, Antonio Vetr\`o, Juan Carlos De Martin</dc:creator>
    </item>
    <item>
      <title>Mapping Research Data at the University of Bologna</title>
      <link>https://arxiv.org/abs/2503.13464</link>
      <description>arXiv:2503.13464v1 Announce Type: new 
Abstract: Research data management (RDM) strategies and practices play a pivotal role in adhering to the paradigms of reproducibility and transparency by enabling research sharing in accordance with the principles of Open Science. Discipline-specificity is an essential factor when understanding RDM declinations, to tailor a comprehensive support service and to enhance interdisciplinarity.
  In this paper we present the results of a mapping carried out to gather information on research data generated and managed within the University of Bologna (UniBO). The aim is to identify differences and commonalities between disciplines and potential challenges for institutional support.
  We analyzed the data management plans (DMPs) of European competitive projects drafted by researchers affiliated with UniBO. We applied descriptive statistics to the collected variables to answer three main questions: How diverse is the range of data managed within the University of Bologna? Which trends of problems and patterns in terms of data management can influence/improve data stewardship service? Is there an interdisciplinary approach to data production within the University?
  The research work evidenced many points of contact between different disciplines in terms of data produced, formats used and modest predilection for data reuse. Hot topics such as data confidentiality, needed either on privacy or intellectual property rights (IPR) premises, and long-term preservation pose challenges to all researchers.
  These results show an increasing attention to RDM while highlighting the relevance of training and support to face the relatively new challenges posed by this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13464v1</guid>
      <category>cs.DL</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C. Basalti, G. Caldoni, S. Coppini, B. Gualandi, M. Marino, F. Masini, S. Peroni</dc:creator>
    </item>
    <item>
      <title>La conservazione dei documenti informatici nel contesto sanitario italiano: indagine su stato di attuazione e criticit\`a</title>
      <link>https://arxiv.org/abs/2503.13484</link>
      <description>arXiv:2503.13484v1 Announce Type: new 
Abstract: The realization of digital preservation in compliance with legislation is extremely important, especially in a sensitive domain like healthcare, where guaranteeing document reliability, authenticity, integrity and readability over time is essential to have an immediate return in terms of efficiency of the whole care setting. In this perspective, the present paper highlights critical issues, through detailed surveys addressed to both national health facilites and digital preservers, defining the state of the art of digital preservation practices in the Italian healthcare setting. The final aim is to identify the strategic areas that need technical and regulatory interventions, in order to offer a major boost of innovation to the domain. Results show an extremely variegated context that is not always compliant to the articulated legislation. These results will be used to integrate the new Italian Guidelines on the creation, management and preservation of digital documents published by the Agency of Digital Italy</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13484v1</guid>
      <category>cs.DL</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.4399/97888255369044</arxiv:DOI>
      <arxiv:journal_reference>AIDA INFORMAZIONI, year 38, n-1-2 2020</arxiv:journal_reference>
      <dc:creator>M. T. Guaglianone, E. Sorrentino, E. Cardillo, M. T. Chiaravalloti, A. F. Spagnuolo, G. A. Cavarretta</dc:creator>
    </item>
    <item>
      <title>A Causal Inference Approach for Quantifying Research Impact</title>
      <link>https://arxiv.org/abs/2503.13485</link>
      <description>arXiv:2503.13485v1 Announce Type: new 
Abstract: Deep learning has had a great impact on various fields of computer science by enabling data-driven representation learning in a decade. Because science and technology policy decisions for a nation can be made on the impact of each technology, quantifying research impact is an important task. The number of citations and impact factor can be used to measure the impact for individual research. What would have happened without the research, however, is fundamentally a counterfactual phenomenon. Thus, we propose an approach based on causal inference to quantify the research impact of a specific technical topic. We leverage difference-in-difference to quantify the research impact by applying to bibliometric data. First, we identify papers of a specific technical topic using keywords or category tags from Microsoft Academic Graph, which is one of the largest academic publication dataset. Next, we build a paper citation network between each technical field. Then, we aggregate the cross-field citation count for each research field. Finally, the impact of a specific technical topic for each research field is estimated by applying difference-in-difference. Evaluation results show that deep learning significantly affects computer vision and natural language processing. Besides, deep learning significantly affects cross-field citation especially for speech recognition to computer vision and natural language processing to computer vision. Moreover, our method revealed that the impact of deep learning was 3.1 times of the impact of interpretability for ML models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13485v1</guid>
      <category>cs.DL</category>
      <category>cs.LG</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keiichi Ochiai, Yutaka Matsuo</dc:creator>
    </item>
    <item>
      <title>CARDS: A collection of package, revision, and miscellaneous dependency graphs</title>
      <link>https://arxiv.org/abs/2503.13461</link>
      <description>arXiv:2503.13461v1 Announce Type: cross 
Abstract: CARDS (Corpus of Acyclic Repositories and Dependency Systems) is a collection of directed graphs which express dependency relations, extracted from diverse real-world sources such as package managers, version control systems, and event graphs. Each graph contains anywhere from thousands to hundreds of millions of nodes and edges, which are normalized into a simple, unified format. Both cyclic and acyclic variants are included (as some graphs, such as citation networks, are not entirely acyclic). The dataset is suitable for studying the structure of different kinds of dependencies, enabling the characterization and distinction of various dependency graph types. It has been utilized for developing and testing efficient algorithms which leverage the specificities of source version control graphs. The collection is publicly available at doi.org/10.5281/zenodo.14245890.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13461v1</guid>
      <category>cs.DB</category>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Euxane Tran-Girard (LIGM, CNRS), Laurent Bulteau (LIGM, CNRS), Pierre-Yves David</dc:creator>
    </item>
    <item>
      <title>SciHorizon: Benchmarking AI-for-Science Readiness from Scientific Data to Large Language Models</title>
      <link>https://arxiv.org/abs/2503.13503</link>
      <description>arXiv:2503.13503v1 Announce Type: cross 
Abstract: In recent years, the rapid advancement of Artificial Intelligence (AI) technologies, particularly Large Language Models (LLMs), has revolutionized the paradigm of scientific discovery, establishing AI-for-Science (AI4Science) as a dynamic and evolving field. However, there is still a lack of an effective framework for the overall assessment of AI4Science, particularly from a holistic perspective on data quality and model capability. Therefore, in this study, we propose SciHorizon, a comprehensive assessment framework designed to benchmark the readiness of AI4Science from both scientific data and LLM perspectives. First, we introduce a generalizable framework for assessing AI-ready scientific data, encompassing four key dimensions: Quality, FAIRness, Explainability, and Compliance which are subdivided into 15 sub-dimensions. Drawing on data resource papers published between 2018 and 2023 in peer-reviewed journals, we present recommendation lists of AI-ready datasets for both Earth and Life Sciences, making a novel and original contribution to the field. Concurrently, to assess the capabilities of LLMs across multiple scientific disciplines, we establish 16 assessment dimensions based on five core indicators Knowledge, Understanding, Reasoning, Multimodality, and Values spanning Mathematics, Physics, Chemistry, Life Sciences, and Earth and Space Sciences. Using the developed benchmark datasets, we have conducted a comprehensive evaluation of over 20 representative open-source and closed source LLMs. All the results are publicly available and can be accessed online at www.scihorizon.cn/en.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13503v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.DL</category>
      <category>cs.IR</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuan Qin, Xin Chen, Chengrui Wang, Pengmin Wu, Xi Chen, Yihang Cheng, Jingyi Zhao, Meng Xiao, Xiangchao Dong, Qingqing Long, Boya Pan, Han Wu, Chengzan Li, Yuanchun Zhou, Hui Xiong, Hengshu Zhu</dc:creator>
    </item>
  </channel>
</rss>
