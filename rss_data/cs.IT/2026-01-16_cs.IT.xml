<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Jan 2026 05:00:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>High signal-to-noise ratio asymptotics of entropy-constrained Gaussian channel capacity</title>
      <link>https://arxiv.org/abs/2601.09864</link>
      <description>arXiv:2601.09864v1 Announce Type: new 
Abstract: We study the input-entropy-constrained Gaussian channel capacity problem in the asymptotic high signal-to-noise ratio (SNR) regime. We show that the capacity-achieving distribution as SNR goes to infinity is given by a discrete Gaussian distribution supported on a scaled integer lattice. Further, we show that the gap between the input entropy and the capacity decreases to zero exponentially in SNR, and characterize this exponent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09864v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adway Girish, Shlomo Shamai, Emre Telatar</dc:creator>
    </item>
    <item>
      <title>One-Cold Poisson Channel: A Simple Continuous-Time Channel with Zero Dispersion</title>
      <link>https://arxiv.org/abs/2601.09894</link>
      <description>arXiv:2601.09894v1 Announce Type: new 
Abstract: We introduce the one-cold Poisson channel (OCPC), where the transmitter chooses one of several frequency bands to attenuate at a time. In particular, the perfect OCPC, where the number of bands is unlimited, is an extremely simple continuous-time memoryless channel. It has a capacity 1, zero channel dispersion, and an information spectrum being the degenerate distribution at 1. It is the only known nontrivial (discrete or continuous-time) memoryless channel with a closed-form formula for its optimal non-asymptotic error probability, making it the simplest channel in this sense. A potential application is optical communication with a tunable band rejection filter. Due to its simplicity, we may use it as a basic currency of information that is infinitely divisible, as an alternative to bits which are not infinitely divisible. OCPC with perfect feedback gives a generalization of prefix codes. We also study non-asymptotic coding and channel simulation results for the general OCPC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09894v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheuk Ting Li</dc:creator>
    </item>
    <item>
      <title>Learning-Augmented Perfectly Secure Collaborative Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2601.09916</link>
      <description>arXiv:2601.09916v1 Announce Type: new 
Abstract: This paper presents a perfectly secure matrix multiplication (PSMM) protocol for multiparty computation (MPC) of $\mathrm{A}^{\top}\mathrm{B}$ over finite fields. The proposed scheme guarantees correctness and information-theoretic privacy against threshold-bounded, semi-honest colluding agents, under explicit local storage constraints. Our scheme encodes submatrices as evaluations of sparse masking polynomials and combines coefficient alignment with Beaver-style randomness to ensure perfect secrecy. We demonstrate that any colluding set of parties below the security threshold observes uniformly random shares, and that the recovery threshold is optimal, matching existing information-theoretic limits. Building on this framework, we introduce a learning-augmented extension that integrates tensor-decomposition-based local block multiplication, capturing both classical and learned low-rank methods. We demonstrate that the proposed learning-based PSMM preserves privacy and recovery guarantees for MPC, while providing scalable computational efficiency gains (up to $80\%$) as the matrix dimensions grow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09916v1</guid>
      <category>cs.IT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zixuan He, Mohammad Reza Deylam Salehi, Derya Malak, Photios A. Stavrou</dc:creator>
    </item>
    <item>
      <title>Reconstructing Reed-Solomon Codes from Multiple Noisy Channel Outputs</title>
      <link>https://arxiv.org/abs/2601.09947</link>
      <description>arXiv:2601.09947v1 Announce Type: new 
Abstract: The sequence reconstruction problem, introduced by Levenshtein in 2001, considers a communication setting in which a sender transmits a codeword and the receiver observes K independent noisy versions of this codeword. In this work, we study the problem of efficient reconstruction when each of the $K$ outputs is corrupted by a $q$-ary discrete memoryless symmetric (DMS) substitution channel with substitution probability $p$. Focusing on Reed-Solomon (RS) codes, we adapt the Koetter-Vardy soft-decision decoding algorithm to obtain an efficient reconstruction algorithm. For sufficiently large blocklength and alphabet size, we derive an explicit rate threshold, depending only on $(p, K)$, such that the transmitted codeword can be reconstructed with arbitrarily small probability of error whenever the code rate $R$ lies below this threshold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09947v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shubhransh Singhvi, Han Mao Kiah, Eitan Yaakobi</dc:creator>
    </item>
    <item>
      <title>Private Information Retrieval for Graph-based Replication with Minimal Subpacketization</title>
      <link>https://arxiv.org/abs/2601.09957</link>
      <description>arXiv:2601.09957v1 Announce Type: new 
Abstract: We design new minimal-subpacketization schemes for information-theoretic private information retrieval on graph-based replicated databases. In graph-based replication, the system consists of $K$ files replicated across $N$ servers according to a graph with $N$ vertices and $K$ edges. The client wants to retrieve one desired file, while keeping the index of the desired file private from each server via a query-response protocol. We seek PIR protocols that have (a) high rate, which is the ratio of the file-size to the total download cost, and (b) low subpacketization, which acts as a constraint on the size of the files for executing the protocol. We report two new schemes which have unit-subpacketization (which is minimal): (i) for a special class of graphs known as star graphs, and (ii) for general graphs. Our star-graph scheme has a better rate than previously known schemes with low subpacketization for general star graphs. Our scheme for general graphs uses a decomposition of the graph via independent sets. This scheme achieves a rate lower than prior schemes for the complete graph, however it can achieve higher rates than known for some specific graph classes. An extension of our scheme to the case of multigraphs achieves a higher rate than previous schemes for the complete multi-graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09957v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vayur Shanbhag, Prasad Krishnan</dc:creator>
    </item>
    <item>
      <title>On the Leaky Private Information Retrieval with Side Information</title>
      <link>https://arxiv.org/abs/2601.09960</link>
      <description>arXiv:2601.09960v1 Announce Type: new 
Abstract: This paper investigates the problem of leaky-private Private Information Retrieval with Side Information (L-PIR-SI), which relaxes the requirement of perfect privacy to achieve improved communication efficiency in the presence of side information. While the capacities of PIR-SI under both $W$-privacy and $(W,S)$-privacy have been partially explored, the impact of controlled information leakage in these settings remains unaddressed. We propose a unified probabilistic framework to construct L-PIR-SI schemes where the privacy leakage is quantified by a parameter $\varepsilon$, consistent with differential privacy standards. We characterize the achievable download costs and show that our results generalize several landmark results in the PIR literature: they recover the capacity of PIR-SI when $\varepsilon \to 0$, and reduce to the known bounds for leaky-PIR when side information is absent. This work provides the first look at the trade-offs between leakage, side information, and retrieval efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09960v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingying Huangfu, Tian Bai</dc:creator>
    </item>
    <item>
      <title>Fundamental Limits of Coded Polynomial Aggregation</title>
      <link>https://arxiv.org/abs/2601.10028</link>
      <description>arXiv:2601.10028v1 Announce Type: new 
Abstract: Coded polynomial aggregation (CPA) enables the master to directly recover a weighted aggregation of polynomial evaluations without individually decoding each term, thereby reducing the number of required worker responses. In this paper, we extend CPA to straggler-aware distributed computing systems and introduce a straggler-aware CPA framework with pre-specified non-straggler patterns, where exact recovery is required only for a given collection of admissible non-straggler sets. Our main result shows that exact recovery of the desired aggregation is achievable with fewer worker responses than required by polynomial coded computing based on individual decoding, and that feasibility is fundamentally characterized by the intersection structure of the non-straggler patterns. In particular, we establish necessary and sufficient conditions for exact recovery in straggler-aware CPA and identify an intersection-size threshold that is sufficient to guarantee exact recovery. We further prove that this threshold becomes both necessary and sufficient when the number of admissible non-straggler sets is sufficiently large. We also provide an explicit construction of feasible CPA schemes whenever the intersection size exceeds the derived threshold. Finally, simulations reveal a sharp feasibility transition at the predicted threshold, providing empirical evidence that the bound is tight in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10028v1</guid>
      <category>cs.IT</category>
      <category>cs.DC</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xi Zhong, J\"org Kliewer, Mingyue Ji</dc:creator>
    </item>
    <item>
      <title>Optimal Proximity Gap for Folded Reed--Solomon Codes via Subspace Designs</title>
      <link>https://arxiv.org/abs/2601.10047</link>
      <description>arXiv:2601.10047v1 Announce Type: new 
Abstract: A collection of sets satisfies a $(\delta,\varepsilon)$-proximity gap with respect to some property if for every set in the collection, either (i) all members of the set are $\delta$-close to the property in (relative) Hamming distance, or (ii) only a small $\varepsilon$-fraction of members are $\delta$-close to the property.
  In a seminal work, Ben-Sasson \textit{et al.}\ showed that the collection of affine subspaces exhibits a $(\delta,\varepsilon)$-proximity gap with respect to the property of being Reed--Solomon (RS) codewords with $\delta$ up to the so-called Johnson bound for list decoding. Their technique relies on the Guruswami--Sudan list decoding algorithm for RS codes, which is guaranteed to work in the Johnson bound regime.
  Folded Reed--Solomon (FRS) codes are known to achieve the optimal list decoding radius $\delta$, a regime known as capacity. Moreover, a rich line of list decoding algorithms was developed for FRS codes. It is then natural to ask if FRS codes can be shown to exhibit an analogous $(\delta,\varepsilon)$-proximity gap, but up to the so-called optimal capacity regime. We answer this question in the affirmative (and the framework naturally applies more generally to suitable subspace-design codes).
  An additional motivation to understand proximity gaps for FRS codes is the recent results [BCDZ'25] showing that they exhibit properties similar to random linear codes, which were previously shown to be related to properties of RS codes with random evaluation points in [LMS'25], as well as codes over constant-size alphabet based on AEL [JS'25].</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10047v1</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fernando Granha Jeronimo, Lenny Liu, Pranav Rajpal</dc:creator>
    </item>
    <item>
      <title>Function Correcting Codes for Maximally-Unbalanced Boolean Functions</title>
      <link>https://arxiv.org/abs/2601.10135</link>
      <description>arXiv:2601.10135v1 Announce Type: new 
Abstract: Function-Correcting Codes (FCCs) enable reliable computation of a function of a $k$-bit message over noisy channels without requiring full message recovery. In this work, we study optimal single-error correcting FCCs (SEFCCs) for maximally-unbalanced Boolean functions, where $k$ denotes the message length and $t$ denotes the error-correction capability. We analyze the structure of optimal SEFCC constructions through their associated codeword distance matrices and identify distinct FCC classes based on this structure. We then examine the impact of these structural differences on error performance by evaluating representative FCCs over the additive white Gaussian noise (AWGN) channel using both soft-decision and hard-decision decoding. The results show that FCCs with different distance-matrix structures can exhibit markedly different Data BER and function error behavior, and that the influence of code structure depends strongly on the decoding strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10135v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rajlaxmi Pandey, Shiven Bajpai, Anjana A Mahesh, B. Sundar Rajan</dc:creator>
    </item>
    <item>
      <title>On Existence of Girth-8 QC-LDPC Code with Large Column Weight: Combining Mirror-sequence with Classification Modulo Ten</title>
      <link>https://arxiv.org/abs/2601.10170</link>
      <description>arXiv:2601.10170v1 Announce Type: new 
Abstract: Quasi-cyclic (QC) LDPC codes with large girths play a crucial role in several research and application fields, including channel coding, compressed sensing and distributed storage systems. A major challenge in respect of the code construction is how to obtain such codes with the shortest possible length (or equivalently, the smallest possible circulant size) using algebraic methods instead of search methods. The greatest-common-divisor (GCD) framework we previously proposed has algebraically constructed QC-LDPC codes with column weights of 5 and 6, very short lengths, and a girth of 8. By introducing the concept of a mirror sequence and adopting a new row-regrouping scheme, QC-LDPC codes with column weights of 7 and 8, very short lengths, and a girth of 8 are proposed for arbitrary row weights in this article via an algebraic manner under the GCD framework. Thanks to these novel algebraic methods, the lower bounds (for column weights 7 and 8) on consecutive circulant sizes are both improved by asymptotically about 20%, compared with the existing benchmarks. Furthermore, these new constructions can also offer circulant sizes asymptotically about 25% smaller than the novel bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10170v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guohua Zhang, Xiangya Liu, Jianhua Zhang, Yi Fang</dc:creator>
    </item>
    <item>
      <title>A Low-Complexity Architecture for Multi-access Coded Caching Systems with Arbitrary User-cache Access Topology</title>
      <link>https://arxiv.org/abs/2601.10175</link>
      <description>arXiv:2601.10175v1 Announce Type: new 
Abstract: This paper studies the multi-access coded caching (MACC) problem under arbitrary user-cache access topologies, extending existing models that rely on highly structured and combinatorially designed connectivity. We consider a MACC system consisting of a single server, multiple cache nodes, and multiple user nodes. Each user can access an arbitrary subset of cache nodes to retrieve cached content. The objective is to design a general and low-complexity delivery scheme under fixed cache placement for arbitrary access topologies. We propose a universal graph-based framework for modeling the MACC delivery problem, where decoding conflicts among requested packets are captured by a conflict graph and the delivery design is reduced to a graph coloring problem. In this formulation, a lower transmission load corresponds to using fewer colors. The classical greedy coloring algorithm DSatur achieves a transmission load close to the index-coding converse bound, providing a tight benchmark, but its computational complexity becomes prohibitive for large-scale graphs. To overcome this limitation, we develop a learning-based framework using graph neural networks that efficiently constructs near-optimal coded multicast transmissions and generalizes across diverse access topologies and varying numbers of users. In addition, we extend the index-coding converse bound for uncoded cache placement to arbitrary access topologies and propose a low-complexity greedy approximation. Numerical results demonstrate that the proposed learning-based scheme achieves transmission loads close to those of DSatur and the converse bound while significantly reducing computational time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10175v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ting Yang, Minquan Cheng, Xinping Yi, Robert Caiming Qiu, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Error-Correcting Codes for the Sum Channel</title>
      <link>https://arxiv.org/abs/2601.10256</link>
      <description>arXiv:2601.10256v1 Announce Type: new 
Abstract: We introduce the sum channel, a new channel model motivated by applications in distributed storage and DNA data storage. In the error-free case, it takes as input an $\ell$-row binary matrix and outputs an $(\ell+1)$-row matrix whose first $\ell$ rows equal the input and whose last row is their parity (sum) row. We construct a two-deletion-correcting code with redundancy $2\lceil\log_2\log_2 n\rceil + O(\ell^2)$ for $\ell$-row inputs. When $\ell=2$, we establish an upper bound of $\lceil\log_2\log_2 n\rceil + O(1)$, implying that our redundancy is optimal up to a factor of 2. We also present a code correcting a single substitution with $\lceil \log_2(\ell+1)\rceil$ redundant bits and prove that it is within one bit of optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10256v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lyan Abboud, Eitan Yaakobi</dc:creator>
    </item>
    <item>
      <title>Transmission Mask Analysis for Range-Doppler Sensing in Half-Duplex ISAC</title>
      <link>https://arxiv.org/abs/2601.10259</link>
      <description>arXiv:2601.10259v1 Announce Type: new 
Abstract: In this paper, we analyze the periodic transmission masks for MASked Modulation (MASM) in half-duplex integrated sensing and communication (ISAC), and derive their closed-form expected range-Doppler response $\mathbb{E}\{r(k,l,\nu)\}$. We show that range sidelobes ($k\neq l$) are Doppler-invariant, extending the range-sidelobe optimality to the 2-D setting. For the range mainlobe ($k=l$), periodic masking yields sparse Doppler sidelobes: Cyclic difference sets (CDSs) (in particular Singer CDSs) are minimax-optimal in a moderately dynamic regime, while in a highly dynamic regime the Doppler-sidelobe energy is a concave function of the mask autocorrelation, revealing an inevitable tradeoff with mainlobe fluctuation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10259v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dikai Liu, Yifeng Xiong, Marco Lops, Fan Liu, Jianhua Zhang</dc:creator>
    </item>
    <item>
      <title>Algebraic Properties of PAC Codes</title>
      <link>https://arxiv.org/abs/2601.10262</link>
      <description>arXiv:2601.10262v1 Announce Type: new 
Abstract: We analyze polarization-adjusted convolutional codes using the algebraic representation of polar and Reed-Muller codes. We define a large class of codes, called generalized polynomial polar codes which include PAC codes and Reverse PAC codes. We derive structural properties of generalized polynomial polar codes, such as duality, minimum distance. We also deduce some structural limits in terms of number of minimum weight codewords, and dimension of monomial sub-code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10262v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vlad-Florin Dragoi, Mohammad Rowshan</dc:creator>
    </item>
    <item>
      <title>On the Capacity of Noisy Frequency-based Channels</title>
      <link>https://arxiv.org/abs/2601.10329</link>
      <description>arXiv:2601.10329v1 Announce Type: new 
Abstract: We investigate the capacity of noisy frequency-based channels, motivated by DNA data storage in the short-molecule regime, where information is encoded in the frequency of items types rather than their order. The channel output is a histogram formed by random sampling of items, followed by noisy item identification. While the capacity of the noiseless frequency-based channel has been previously addressed, the effect of identification noise has not been fully characterized. We present a converse bound on the channel capacity that follows from stochastic degradation and the data processing inequality. We then establish an achievable bound, which is based on a Poissonization of the multinomial sampling process, and an analysis of the resulting vector Poisson channel with inter-symbol interference. This analysis refines concentration inequalities for the information density used in Feinstein bound, and explicitly characterizes an additive loss in the mutual information due to identification noise. We apply our results to a DNA storage channel in the short-molecule regime, and quantify the resulting loss in the scaling of the total number of reliably stored bits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10329v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuval Gerzon, Ilan Shomorony, Nir Weinberger</dc:creator>
    </item>
    <item>
      <title>Convertible Codes for Data and Device Heterogeneity</title>
      <link>https://arxiv.org/abs/2601.10341</link>
      <description>arXiv:2601.10341v1 Announce Type: new 
Abstract: Distributed storage systems must handle both data heterogeneity, arising from non-uniform access demands, and device heterogeneity, caused by time-varying node reliability. In this paper, we study convertible codes, which enable the transformation of one code into another with minimum cost in the merge regime, addressing the latter. We derive general lower bounds on the read and write costs of linear code conversion, applicable to arbitrary linear codes. We then focus on Reed-Muller codes, which efficiently handle data heterogeneity, addressing the former issue, and construct explicit conversion procedures that, for the first time, combine both forms of heterogeneity for distributed data storage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10341v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anina Gruica, Benjamin Jany, Stanislav Kruglik</dc:creator>
    </item>
    <item>
      <title>A New Construction Structure on MISO Coded Caching with Linear Subpacketization: Half-Sum Disjoint Packing</title>
      <link>https://arxiv.org/abs/2601.10353</link>
      <description>arXiv:2601.10353v1 Announce Type: new 
Abstract: In the $(L,K,M,N)$ cache-aided multiple-input single-output (MISO) broadcast channel (BC) system, the server is equipped with $L$ antennas and communicates with $K$ single-antenna users through a wireless broadcast channel where the server has a library containing $N$ files, and each user is equipped with a cache of size $M$ files. Under the constraints of uncoded placement and one-shot linear delivery strategies, many schemes achieve the maximum sum Degree-of-Freedom (sum-DoF). However, for general parameters $L$, $M$, and $N$, their subpacketizations increase exponentially with the number of users. We aim to design a MISO coded caching scheme that achieves a large sum-DoF with low subpacketization $F$. An interesting combinatorial structure, called the multiple-antenna placement delivery array (MAPDA), can be used to generate MISO coded caching schemes under these two strategies; moreover, all existing schemes with these strategies can be represented by the corresponding MAPDAs. In this paper, we study the case with $F=K$ (i.e., $F$ grows linearly with $K$) by investigating MAPDAs. Specifically, based on the framework of Latin squares, we transform the design of MAPDA with $F=K$ into the construction of a combinatorial structure called the $L$-half-sum disjoint packing (HSDP). It is worth noting that a $1$-HSDP is exactly the concept of NHSDP, which is used to generate the shared-link coded caching scheme with $F=K$. By constructing $L$-HSDPs, we obtain a class of new schemes with $F=K$. Finally, theoretical and numerical analyses show that our $L$-HSDP schemes significantly reduce subpacketization compared to existing schemes with exponential subpacketization, while only slightly sacrificing sum-DoF, and achieve both a higher sum-DoF and lower subpacketization than the existing schemes with linear subpacketization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10353v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bowen Zheng, Minquan Cheng, Kai Wan, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Generalized Weight Structure of Polar Codes: Selected Template Polynomials</title>
      <link>https://arxiv.org/abs/2601.10362</link>
      <description>arXiv:2601.10362v1 Announce Type: new 
Abstract: Polar codes can be viewed as decreasing monomial codes, revealing a rich algebraic structure governed by the lower-triangular affine (LTA) group. We develop a general framework to compute the Hamming weight of codewords generated by sums of monomials, express these weights in a canonical dyadic form, and derive closed expressions for key structural templates (disjoint sums, nested blocks, complementary flips) that generate the low and intermediate weight spectrum. Combining these templates with the LTA group action, we obtain explicit multiplicity formulas, yielding a unified algebraic method to characterize and enumerate codewords.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10362v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Rowshan, Vlad-Florin Dragoi</dc:creator>
    </item>
    <item>
      <title>A Hybrid Reliability--Weight Framework for Construction of Polar Codes</title>
      <link>https://arxiv.org/abs/2601.10376</link>
      <description>arXiv:2601.10376v1 Announce Type: new 
Abstract: Polar codes are usually constructed by ranking synthetic bit-channels according to reliability, which guarantees capacity-achieving behavior but can yield poor low-weight spectra at short and moderate lengths. Recent algebraic results express the contribution of individual bit-channels to the multiplicities of minimum and near-minimum weight codewords in closed form. In this work we combine these insights into a mixed (reliability--weight) bit-channel ordering. We define a per-bit cost whose distance term is derived from orbit enumeration of minimum-weight codewords and scaled by a Bhattacharyya-type factor, and show that the resulting mixed construction minimises a truncated SC/ML union-bound surrogate within a class of decreasing monomial codes. We relate the mixed metric to error events in SCL decoding via a pruning/ML decomposition, and prove that mixed designs act as local perturbations of reliability-based constructions whose asymptotic impact vanishes as code-length approaches infinity. Numerical results for short and moderate lengths on BPSK-AWGN, implemented via Gaussian approximation and closed-form weight contributions, illustrate the trade-off between pure reliability-based and mixed constructions in terms of minimum distance, multiplicity, and union-bound approximations. All proofs are deferred to the appendices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10376v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Rowshan, Vlad-Florin Dragoi</dc:creator>
    </item>
    <item>
      <title>Codebook Design for Limited Feedback in Near-Field XL-MIMO Systems</title>
      <link>https://arxiv.org/abs/2601.10391</link>
      <description>arXiv:2601.10391v1 Announce Type: new 
Abstract: In this paper, we study efficient codebook design for limited feedback in extremely large-scale multiple-input-multiple-output (XL-MIMO) frequency division duplexing (FDD) systems. It is worth noting that existing codebook designs for XL-MIMO, such as polar-domain codebook, have not well taken into account user (location) distribution in practice, thereby incurring excessive feedback overhead. To address this issue, we propose in this paper a novel and efficient feedback codebook tailored to user distribution. To this end, we first consider a typical scenario where users are uniformly distributed within a specific polar-region, based on which a sum-rate maximization problem is formulated to jointly optimize angle-range samples and bit allocation among angle/range feedback. This problem is challenging to solve due to the lack of a closed-form expression for the received power in terms of angle and range samples. By leveraging a Voronoi partitioning approach, we show that uniform angle sampling is optimal for received power maximization. For more challenging range sampling design, we obtain a tight lower-bound on the received power and show that geometric sampling, where the ratio between adjacent samples is constant, can maximize the lower bound and thus serves as a high-quality suboptimal solution. We then extend the proposed framework to accommodate more general non-uniform user distribution via an alternating sampling method. Furthermore, theoretical analysis reveals that as the array size increases, the optimal allocation of feedback bits increasingly favors range samples at the expense of angle samples. Finally, numerical results validate the superior rate performance and robustness of the proposed codebook design under various system setups, achieving significant gains over benchmark schemes, including the widely used polar-domain codebook.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10391v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liujia Yao, Changsheng You, Zixuan Huang, Chao Zhou, Zhaohui Yang, Xiaoyang Li</dc:creator>
    </item>
    <item>
      <title>Multiaccess Coded Caching with Heterogeneous Retrieval Costs</title>
      <link>https://arxiv.org/abs/2601.10394</link>
      <description>arXiv:2601.10394v1 Announce Type: new 
Abstract: The multiaccess coded caching (MACC) system, as formulated by Hachem {\it et al.}, consists of a central server with a library of $N$ files, connected to $K$ cache-less users via an error-free shared link, and $K$ cache nodes, each equipped with cache memory of size $M$ files. Each user can access $L$ neighboring cache nodes under a cyclic wrap-around topology. Most existing studies operate under the strong assumption that users can retrieve content from their connected cache nodes at no communication cost. In practice, each user retrieves content from its $L$ different connected cache nodes at varying costs. Additionally, the server also incurs certain costs to transmit the content to the users. In this paper, we focus on a cost-aware MACC system and aim to minimize the total system cost, which includes cache-access costs and broadcast costs. Firstly, we propose a novel coded caching framework based on superposition coding, where the MACC schemes of Cheng \textit{et al.} are layered. Then, a cost-aware optimization problem is derived that optimizes cache placement and minimizes system cost. By identifying a sparsity property of the optimal solution, we propose a structure-aware algorithm with reduced complexity. Simulation results demonstrate that our proposed scheme consistently outperforms the scheme of Cheng {\it et al.} in scenarios with heterogeneous retrieval costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10394v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenbo Huang, Minquan Cheng, Kai Wan, Xiaojun Li, Robert Caiming Qiu, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Placement Delivery Array for Cache-Aided MIMO Systems</title>
      <link>https://arxiv.org/abs/2601.10422</link>
      <description>arXiv:2601.10422v1 Announce Type: new 
Abstract: We consider a $(G,L,K,M,N)$ cache-aided multiple-input multiple-output (MIMO) network, where a server equipped with $L$ antennas and a library of $N$ equal-size files communicates with $K$ users, each equipped with $G$ antennas and a cache of size $M$ files, over a wireless interference channel. Each user requests an arbitrary file from the library. The goal is to design coded caching schemes that simultaneously achieve the maximum sum degrees of freedom (sum-DoF) and low subpacketization. In this paper, we first introduce a unified combinatorial structure, termed the MIMO placement delivery array (MIMO-PDA), which characterizes uncoded placement and one-shot zero-forcing delivery. By analyzing the combinatorial properties of MIMO-PDAs, we derive a sum-DoF upper bound of $\min\{KG, Gt+G\lceil L/G \rceil\}$, where $t=KM/N$, which coincides with the optimal DoF characterization in prior work by Tehrani \emph{et al.}. Based on this upper bound, we present two novel constructions of MIMO-PDAs that achieve the maximum sum-DoF. The first construction achieves linear subpacketization under stringent parameter constraints, while the second achieves ordered exponential subpacketization under substantially milder constraints. Theoretical analysis and numerical comparisons demonstrate that the second construction exponentially reduces subpacketization compared to existing schemes while preserving the maximum sum-DoF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10422v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifei Huang, Kai Wan, Minquan Cheng, Jinyan Wang, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Probabilistic Semantic Communication Over Visible Light Networks With Rate Splitting</title>
      <link>https://arxiv.org/abs/2601.10452</link>
      <description>arXiv:2601.10452v1 Announce Type: new 
Abstract: Visible light communication (VLC) is emerging as a key technology for future wireless communication systems due to its unique physical-layer advantages over traditional radio-frequency (RF)-based systems. However, its integration with higher-layer techniques, such as semantic communication, remains underexplored. This paper investigates the energy efficiency maximization problem in a resource-constrained VLC-based probabilistic semantic communication (PSCom) system. In the considered model, light-emitting diode (LED) transmitters perform semantic compression to reduce data size, which incurs additional computation overhead. The compressed semantic information is transmitted to the users for semantic inference using a shared knowledge base that requires periodic updates to ensure synchronization. In the PSCom system, the knowledge base is represented by probabilistic graphs. To enable simultaneous transmission of both knowledge and information data, rate splitting multiple access (RSMA) is employed. The optimization problem focuses on maximizing energy efficiency by jointly optimizing transmit beamforming, direct current (DC) bias, common rate allocation, and semantic compression ratio, while accounting for both communication and computation costs. To solve this problem, an alternating optimization algorithm based on successive convex approximation (SCA) and Dinkelbach method is developed. Simulation results demonstrate the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10452v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhouxiang Zhao, Zhaohui Yang, Mingzhe Chen, Chen Zhu, Xin Tong, Zhaoyang Zhang</dc:creator>
    </item>
    <item>
      <title>Joint Source-Channel Coding for ISAC: Distortion Tradeoffs and Separation Theorems</title>
      <link>https://arxiv.org/abs/2601.10470</link>
      <description>arXiv:2601.10470v1 Announce Type: new 
Abstract: Integrated Sensing and Communication (ISAC) systems have garnered significant attention due to their capability to simultaneously achieve efficient communication and environmental sensing. A core objective in this field is characterizing the performance tradeoff between sensing and communication. In this paper, we consider a joint source-channel coding (JSCC) framework for the ISAC system that consists of a transmitter with a channel state estimator and a joint source-channel encoder, a state-dependent memoryless channel, and a receiver with a joint source-channel decoder. From an information-theoretic perspective, we establish the tradeoff relationships among channel capacity, distortions in both communication and sensing processes, and the estimation cost. We prove that the separate source and channel coding can achieve joint optimality in this setting. An illustrative example of a binary setting is also provided to validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10470v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gefei Peng, Youlong Wu</dc:creator>
    </item>
    <item>
      <title>A Construction Framework of Coded Caching Scheme for Multi-Access MIMO Systems via Knapsack Problem</title>
      <link>https://arxiv.org/abs/2601.10484</link>
      <description>arXiv:2601.10484v1 Announce Type: new 
Abstract: This paper investigates the coded caching problem in a multi-access multiple-input single-output (MAMISO) network with the combinatorial topology. The considered system consists of a server containing $N$ files, $\Lambda$ cache nodes, and $K$ cache-less users, where each user can access a unique subset of $r$ cache nodes. The server is equipped with $L$ transmit antennas. Our objective is to design a caching scheme that simultaneously achieves a high sum Degree of Freedom (sum-DoF) and low subpacketization complexity. To address this challenge, we formulate the design of multi-antenna placement delivery arrays (MAPDA) as a $0$--$1$ knapsack problem to maximize the achievable DoF, thereby transforming the complex combinatorial caching structure into a tractable optimization framework that yields efficient cache placement and flexible delivery strategies. Theoretical and numerical analyses demonstrate that: for networks with combinatorial topologies, the proposed scheme achieves a higher sum-DoF than existing schemes. Under identical cache size constraints, the subpacketization level remains comparable to existing linear subpacketization schemes. Moreover, under specific system conditions, the proposed scheme attains the theoretical maximum sum-DoF of $\min\{L+KM/N, K\}$ while achieving further reductions subpacketization. For particular combinatorial structures, we further derive optimized constructions that achieve even higher sum-DoF with lower subpacketization. ```</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10484v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siying Luo, Youlong Wu, Mingming Zhang, Minquan Cheng, Dianhua Wu</dc:creator>
    </item>
    <item>
      <title>Coded Caching for Combinatorial Multi-Access Hotplug Networks from $t$-Designs</title>
      <link>https://arxiv.org/abs/2601.10503</link>
      <description>arXiv:2601.10503v1 Announce Type: new 
Abstract: We study hotplug coded caching in combinatorial multi-access networks, which generalizes existing hotplug coded caching models by allowing users to access multiple caches, while only a subset of caches is online during the delivery phase. We first generalize the Hotplug Placement Delivery Array (HpPDA) framework to the combinatorial multi-access setting. Based on this generalized framework, we propose a t-design-based coded caching scheme for combinatorial multi-access networks. We characterize a class of design parameters under which every active user has access to a sufficient number of coded subfiles to decode its requested file, and show that appropriate parameter choices allow for the elimination of redundant multicast transmissions. As a result, the proposed scheme achieves a family of rate memory trade offs with flexible subpacketization. We present numerical comparisons illustrating that the proposed t-scheme outperforms existing hotplug coded caching schemes in certain memory regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10503v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dhruv Pratap Singh, Anjana A. Mahesh, B. Sundar Rajan</dc:creator>
    </item>
    <item>
      <title>A New Construction Structure on Coded Caching with Linear Subpacketization: Non-Half-Sum Latin Rectangle</title>
      <link>https://arxiv.org/abs/2601.10505</link>
      <description>arXiv:2601.10505v1 Announce Type: new 
Abstract: Coded caching is recognized as an effective method for alleviating network congestion during peak periods by leveraging local caching and coded multicasting gains. The key challenge in designing coded caching schemes lies in simultaneously achieving low subpacketization and low transmission load. Most existing schemes require exponential or polynomial subpacketization levels, while some linear subpacketization schemes often result in excessive transmission load. Recently, Cheng et al. proposed a construction framework for linear coded caching schemes called Non-Half-Sum Disjoint Packing (NHSDP), where the subpacketization equals the number of users $K$. This paper introduces a novel combinatorial structure, termed the Non-Half-Sum Latin Rectangle (NHSLR), which extends the framework of linear coded caching schemes from $F=K$ (i.e., the construction via NHSDP) to a broader scenario with $F=\mathcal{O}(K)$. By constructing NHSLR, we have obtained a new class of coded caching schemes that achieves linearly scalable subpacketization, while further reducing the transmission load compared with the NHSDP scheme. Theoretical and numerical analyses demonstrate that the proposed schemes not only achieves lower transmission load than existing linear subpacketization schemes but also approaches the performance of certain exponential subpacketization schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10505v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongcheng Yang, Minquan Cheng, Kai Wan, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>A New Construction Structure on Multi-access Coded Caching with Linear Subpacketization: Cyclic Multi-Access Non-Half-Sum Disjoint Packing</title>
      <link>https://arxiv.org/abs/2601.10510</link>
      <description>arXiv:2601.10510v1 Announce Type: new 
Abstract: We consider the $(K,L,M,N)$ multi-access coded caching system introduced by Hachem et al., which consists of a central server with $N$ files and $K$ cache nodes, each of memory size $M$, where each user can access $L$ cache nodes in a cyclic wrap-around fashion. At present, several existing schemes achieve competitive transmission performance, but their subpacketization levels grow exponentially with the number of users. In contrast, schemes with linear or polynomial subpacketization always incur higher transmission loads. We aim to design a multi-access coded caching scheme with linear subpacketization $F$ while maintaining low transmission load. Recently, Cheng et al. proposed a construction framework for coded caching schemes with linear subpacketization (i.e., $F=K$) called non-half-sum disjoint packing (NHSDP). Inspired by this structure, we introduce a novel combinatorial structure named cyclic multi-access non-half-sum disjoint packing (CMA-NHSDP) by extending NHSDP to MACC system. By constructing CMA-NHSDP, we obtain a new class of multi-access coded caching schemes. Theoretical and numerical analyses show that our scheme achieves lower transmission loads than some existing schemes with linear subpacketization. Moreover, the proposed schemes achieves lower transmission load compared to existing schemes with exponential subpacketization in some case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10510v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengyuan Li, Minquan Cheng, Kai Wan, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>On the suboptimality of linear codes for binary distributed hypothesis testing</title>
      <link>https://arxiv.org/abs/2601.10526</link>
      <description>arXiv:2601.10526v1 Announce Type: new 
Abstract: We study a binary distributed hypothesis testing problem where two agents observe correlated binary vectors and communicate compressed information at the same rate to a central decision maker. In particular, we study linear compression schemes and show that simple truncation is the best linear scheme in two cases: (1) testing opposite signs of the same magnitude of correlation, and (2) testing for or against independence. We conjecture, supported by numerical evidence, that truncation is the best linear code for testing any correlations of opposite signs. Further, for testing against independence, we also compute classical random coding exponents and show that truncation, and consequently any linear code, is strictly suboptimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10526v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adway Girish, Robinson D. H. Cung, Emre Telatar</dc:creator>
    </item>
    <item>
      <title>Network Integrated Sensing and Communication</title>
      <link>https://arxiv.org/abs/2601.10538</link>
      <description>arXiv:2601.10538v1 Announce Type: new 
Abstract: Integrated sensing and communication (ISAC) is a cornerstone technology for 6G networks, offering unified support for high-rate communication and high-accuracy sensing. While existing literature extensively covers link-level designs, the transition toward large-scale deployment necessitates a fundamental understanding of network-level performance. This paper investigates a network ISAC model where a source node communicates with a destination via a relay network, while intermediate nodes concurrently perform cooperative sensing over specific spatial regions. We formulate a novel optimization framework that captures the interplay between multi-node routing and sensing coverage. For a one-dimensional path network, we provide an analytical characterization of the complete sensing-throughput region. Extending this to general network topologies, we establish that the sensing-throughput Pareto boundary is piecewise linear and provide physical interpretations for each segment. Our results reveal the fundamental trade-offs between sensing coverage and communication routing, offering key insights for the design of future 6G heterogeneous networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10538v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edward Andrews, Lawrence Ong, Duy T. Ngo, Yao Liu, Min Li</dc:creator>
    </item>
    <item>
      <title>Error-Correcting Codes for Two Bursts of t1-Deletion-t2-Insertion with Low Computational Complexity</title>
      <link>https://arxiv.org/abs/2601.10540</link>
      <description>arXiv:2601.10540v1 Announce Type: new 
Abstract: Burst errors involving simultaneous insertions, deletions, and substitutions occur in practical scenarios, including DNA data storage and document synchronization, motivating developments of channel codes that can correct such errors. In this paper, we address the problem of constructing error-correcting codes (ECCs) capable of handling multiple bursts of $t_1$-deletion-$t_2$-insertion ($(t_1,t_2)$-DI) errors, where each burst consists of $t_1$ deletions followed by $t_2$ insertions in a binary sequence. We make three key contributions: Firstly, we establish the fundamental equivalence of (1) two bursts of $(t_1,t_2)$-DI ECCs, (2) two bursts of $(t_2,t_1)$-DI ECCs, and (3) one burst each of $(t_1,t_2)$-DI and $(t_2,t_1)$-DI ECCs. Then, we derive lower and upper bounds on the code size of two bursts of $(t_1,t_2)$-DI ECCs, which can naturally be extended to the case of multiple bursts. Finally, we present constructions of two bursts of $(t_1,t_2)$-DI ECCs. Compared to the codes obtained by the syndrome compression technique, the resulting codes achieve significantly lower computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10540v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yajuan Liu, Tolga M. Duman</dc:creator>
    </item>
    <item>
      <title>Sparse Signal Recovery from Random Measurements</title>
      <link>https://arxiv.org/abs/2601.10569</link>
      <description>arXiv:2601.10569v1 Announce Type: new 
Abstract: Given the compressed sensing measurements of an unknown vector $z \in \mathbb{R}^n$ using random matrices, we present a simple method to determine $z$ without solving any optimization problem or linear system. Our method uses $\Theta(\log n)$ random sensing matrices in $\mathbb{R}^{k \times n}$ and runs in $O(kn\log n)$ time, where $k = \Theta(s\log n)$ and $s$ is the number of nonzero coordinates in $z$. We adapt our method to determine the support set of $z$ and experimentally compare with some optimization-based methods on binary signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10569v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Siu-Wing Cheng, Man Ting Wong</dc:creator>
    </item>
    <item>
      <title>Fundamental Limits of Multi-User Distributed Computing of Linearly Separable Functions</title>
      <link>https://arxiv.org/abs/2601.10603</link>
      <description>arXiv:2601.10603v1 Announce Type: new 
Abstract: This work establishes the fundamental limits of the classical problem of multi-user distributed computing of linearly separable functions. In particular, we consider a distributed computing setting involving $L$ users, each requesting a linearly separable function over $K$ basis subfunctions from a master node, who is assisted by $N$ distributed servers. At the core of this problem lies a fundamental tradeoff between communication and computation: each server can compute up to $M$ subfunctions, and each server can communicate linear combinations of their locally computed subfunctions outputs to at most $\Delta$ users. The objective is to design a distributed computing scheme that reduces the communication cost (total amount of data from servers to users), and towards this, for any given $K$, $L$, $M$, and $\Delta$, we propose a distributed computing scheme that jointly designs the task assignment and transmissions, and shows that the scheme achieves optimal performance in the real field under various conditions using a novel converse. We also characterize the performance of the scheme in the finite field using another converse based on counting arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10603v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K. K. Krishnan Namboodiri, Elizabath Peter, Derya Malak, Petros Elia</dc:creator>
    </item>
    <item>
      <title>Basis-Spline Assisted Coded Computing: Strategies and Error Bounds</title>
      <link>https://arxiv.org/abs/2601.10616</link>
      <description>arXiv:2601.10616v1 Announce Type: new 
Abstract: Coded computing has become a key framework for reliable distributed computation over decentralized networks, effectively mitigating the impact of stragglers. Although there exists a wide range of coded computing methods to handle both polynomial and non-polynomial functions, computing methods for the latter class have received traction due its inherent challenges in reconstructing non-polynomial functions using a finite number of evaluations. Among them, the state-of-the-art method is Berrut Approximated coded computing, wherein Berrut interpolants, are used for approximating the non-polynomial function. However, since Berrut interpolants have global support characteristics, such methods are known to offer degraded accuracy when the number of stragglers is large. To address this challenge, we propose a coded computing framework based on cubic B-spline interpolation. In our approach, server-side function evaluations are reconstructed at the master node using B-splines, exploiting their local support and smoothness properties to enhance stability and accuracy. We provide a systematic methodology for integrating B-spline interpolation into coded computing and derive theoretical bounds on approximation error in terms of the number of servers and stragglers. Comparative analysis demonstrates that our framework significantly outperforms Berrut-based methods for various non-polynomial functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10616v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rimpi Borah, J. Harshan, V. Lalitha</dc:creator>
    </item>
    <item>
      <title>Converse Bounds for Sun-Jafar-type Weak Private Information Retrieval</title>
      <link>https://arxiv.org/abs/2601.10643</link>
      <description>arXiv:2601.10643v1 Announce Type: new 
Abstract: Building on the well-established capacity-achieving schemes of Sun-Jafar (for replicated storage) and the closely related scheme of Banawan-Ulukus (for MDS-coded setting), a recent work by Chandan et al. proposed new classes of weak private information retrieval (WPIR) schemes for the collusion-free (replication and MDS-coded) setting, as well as for the $T$-colluding scenario. In their work, Chandan et al. characterized the expressions for the rate-privacy trade-offs for these classes of WPIR schemes, under the mutual information leakage and maximal leakage metrics. Explicit achievable trade-offs for the same were also presented, which were shown to be competitive or better than prior WPIR schemes. However, the class-wise optimality of the reported trade-offs were unknown. In this work, we show that the explicit rate-privacy trade-offs reported for the Sun-Jafar-type schemes by Chandan et al. are optimal for the non-colluding and replicated setting. Furthermore, we prove the class-wise optimality for Banawan-Ulukus-type MDS-WPIR and Sun-Jafar-type $T$-colluding WPIR schemes, under threshold-constraints on the system parameters. When these threshold-constraints do not hold, we present counter-examples which show that even higher rates than those reported before can be achieved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10643v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chandan Anand, Jayesh Seshadri, Prasad Krishnan, Gowtham R. Kurri</dc:creator>
    </item>
    <item>
      <title>One-Shot Broadcast Joint Source-Channel Coding with Codebook Diversity</title>
      <link>https://arxiv.org/abs/2601.10648</link>
      <description>arXiv:2601.10648v1 Announce Type: new 
Abstract: We study a one-shot joint source-channel coding setting where the source is encoded once and broadcast to $K$ decoders through independent channels. Success is predicated on at least one decoder recovering the source within a maximum distortion constraint. We find that in the one-shot regime, utilizing disjoint codebooks at each decoder yields a codebook diversity gain, distinct from the channel diversity gain that may be expected when several decoders observe independent realizations of the channel's output but share the same codebook. Coding schemes are introduced that leverage this phenomenon, where first- and second-order achievability bounds are derived via an adaptation of the Poisson matching lemma (Li and Anantharam, 2021) which allows for multiple decoders using disjoint codebooks. We further propose a hybrid coding scheme that partitions decoders into groups to optimally balance codebook and channel diversity. Numerical results on the binary symmetric channel demonstrate that the hybrid approach outperforms strategies where the decoders' codebooks are either fully shared or disjoint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10648v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph Rowan, Buu Phan, Ashish Khisti</dc:creator>
    </item>
    <item>
      <title>Breaking the Storage-Bandwidth Tradeoff in Distributed Storage with Quantum Entanglement</title>
      <link>https://arxiv.org/abs/2601.10676</link>
      <description>arXiv:2601.10676v1 Announce Type: new 
Abstract: This work investigates the use of quantum resources in distributed storage systems. Consider an $(n,k,d)$ distributed storage system in which a file is stored across $n$ nodes such that any $k$ nodes suffice to reconstruct the file. When a node fails, any $d$ helper nodes transmit information to a newcomer to rebuild the system. In contrast to the classical repair, where helper nodes transmit classical bits, we allow them to send classical information over quantum channels to the newcomer. The newcomer then generates its storage by performing appropriate measurements on the received quantum states. In this setting, we fully characterize the fundamental tradeoff between storage and repair bandwidth (total communication cost). Compared to classical systems, the optimal storage--bandwidth tradeoff can be significantly improved with the enhancement of quantum entanglement shared only among the surviving nodes, particularly at the minimum-storage regenerating point. Remarkably, we show that when $d \geq 2k-2$, there exists an operating point at which \textit{both storage and repair bandwidth are simultaneously minimized}. This phenomenon breaks the tradeoff in the classical setting and reveals a fundamentally new regime enabled by quantum communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10676v1</guid>
      <category>cs.IT</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Hu, Mohamed Nomeir, Alptug Aytekin, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Synchronizing Probabilities in Model-Driven Lossless Compression</title>
      <link>https://arxiv.org/abs/2601.10678</link>
      <description>arXiv:2601.10678v1 Announce Type: new 
Abstract: It is well-known in the field of lossless data compression that probabilistic next-symbol prediction can be used to compress sequences of symbols. Deep neural networks are able to capture rich dependencies in data, offering a powerful means of estimating these probabilities and hence an avenue towards more effective compression algorithms. However, both compressor and decompressor must have exactly matching predictions; even small non-deterministic differences (which often happen with learned models due to hardware, software, or computation order) can lead to cascading decoding failures. In this paper, we formalize the problem of prediction mismatch in model-driven compression, and introduce Probability Matching Interval Coding (PMATIC), a model-agnostic algorithm that tolerates bounded prediction mismatch with low overhead. PMATIC works with the predicted probabilities, making it compatible as a drop-in replacement for the arithmetic encoder in model-driven compression tools. We show theoretical correctness and performance bounds for PMATIC, and validate these results on text data. These results confirm that, when paired an advanced prediction model, PMATIC is robust to prediction mismatch while achieving compression rates that out-perform standard modern compression tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10678v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aviv Adler, Jennifer Tang</dc:creator>
    </item>
    <item>
      <title>Implementation of Oblivious Transfer over Binary-Input AWGN Channels by Polar Codes</title>
      <link>https://arxiv.org/abs/2601.10682</link>
      <description>arXiv:2601.10682v1 Announce Type: new 
Abstract: We develop a one-out-of-two-oblivious transfer protocol over the binary-input additive white Gaussian noise channel using polar codes. The scheme uses two decoder views linked by automorphisms of the polar transform and publicly draws the encoder at random from the corresponding automorphism group. This yields perfect receiver privacy at any finite blocklength, since the public encoder distribution is independent of the receiver's choice bit. Sender privacy is obtained asymptotically via channel polarization combined with privacy amplification. Because the construction deliberately injects randomness on selected bad bit-channels, we derive a relaxed reliability criterion and evaluate finite-blocklength performance. Finally, we characterize the polar-transform automorphisms as bit-level permutations of bit-channel indices, and exploit this structure to derive and optimize an achievable finite-blocklength OT rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10682v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pin-Hsun Lin, Hadi Aghaee, Christian Deppe, Eduard A. Jorswieck, Holger Boche</dc:creator>
    </item>
    <item>
      <title>Improved Constructions of Reed-Solomon Codes with Optimal Repair Bandwidth</title>
      <link>https://arxiv.org/abs/2601.10685</link>
      <description>arXiv:2601.10685v1 Announce Type: new 
Abstract: Maximum-distance-separable (MDS) codes are widely used in distributed storage, yet naive repair of a single erasure in an $[n,k]$ MDS code downloads the entire contents of $k$ nodes. Minimum Storage Regenerating (MSR) codes (Dimakis et al., 2010) minimize repair bandwidth by contacting $d&gt;k$ helpers and downloading only a fraction of data from each. Guruswami and Wootters first proposed a linear repair scheme for Reed-Solomon (RS) codes, showing that they can be repaired with lower bandwidth than the naive approach. The existence of RS codes achieving the MSR point (RS-MSR codes) nevertheless remained open until the breakthrough construction of Tamo, Barg, and Ye, which yields RS-MSR codes with subpacketization $\ell = s \prod_{i=1}^n p_i$, where $p_i$ are distinct primes satisfying $p_i \equiv 1 \pmod{s}$ and $s=d+1-k$.
  In this paper, we present an improved construction of RS-MSR codes by eliminating the congruence condition $p_i \equiv 1 \pmod{s}$. Consequently, our construction reduces the subpacketization by a multiplicative factor of $\phi(s)^n$ ( $\phi(\cdot)$ is Euler's totient function) and broadens the range of feasible parameters for RS-MSR codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10685v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Qiu, Weijun Fang, Shu-Tao Xia, Fang-Wei Fu</dc:creator>
    </item>
    <item>
      <title>Perfect Secret Key Generation for a class of Hypergraphical Sources</title>
      <link>https://arxiv.org/abs/2601.10697</link>
      <description>arXiv:2601.10697v1 Announce Type: new 
Abstract: Nitinawarat and Narayan proposed a perfect secret key generation scheme for the so-called \emph{pairwise independent network (PIN) model} by exploiting the combinatorial properties of the underlying graph, namely the spanning tree packing rate. This work considers a generalization of the PIN model where the underlying graph is replaced with a hypergraph, and makes progress towards designing similar perfect secret key generation schemes by exploiting the combinatorial properties of the hypergraph.
  Our contributions are two-fold. We first provide a capacity achieving scheme for a complete $t$-uniform hypergraph on $m$ vertices by leveraging a packing of the complete $t$-uniform hypergraphs by what we refer to as star hypergraphs, and designing a scheme that gives $\binom{m-2}{t-2}$ bits of perfect secret key per star graph. Our second contribution is a 2-bit perfect secret key generation scheme for 3-uniform star hypergraphs whose projections are cycles. This scheme is then extended to a perfect secret key generation scheme for generic 3-uniform hypergraphs by exploiting star graph packing of 3-uniform hypergraphs and Hamiltonian packings of graphs. The scheme is then shown to be capacity achieving for certain classes of hypergraphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10697v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuj Mukherjee, Sagnik Chatterjee, Alhad Sethi</dc:creator>
    </item>
    <item>
      <title>Limits of Rank Recovery in Bilinear Observation Problems</title>
      <link>https://arxiv.org/abs/2601.09754</link>
      <description>arXiv:2601.09754v1 Announce Type: cross 
Abstract: Bilinear observation problems arise in many physical and information-theoretic settings, where observables and states enter multiplicatively. Rank-based diagnostics are commonly used in such problems to assess the effective dimensionality accessible to observation, often under the implicit assumption that rank deficiency can be resolved through numerical refinement. Here we examine this assumption by analyzing the rank and nullity of a bilinear observation operator under systematic tolerance variation. Rather than focusing on a specific reconstruction algorithm, we study the operator directly and identify extended rank plateaus that persist across broad tolerance ranges. These plateaus indicate stable dimensional deficits that are not removed by refinement procedures applied within a fixed problem definition. To investigate the origin of this behavior, we resolve the nullspace into algebraic sectors defined by the block structure of the variables. The nullspace exhibits a pronounced but nonexclusive concentration in specific sectors, revealing an organized internal structure rather than uniform dimensional loss. Comparing refinement with explicit modification of the problem formulation further shows that rank recovery in the reported setting requires a change in the structure of the observation problem itself. Here, "problem modification" refers to changes that alter the bilinear observation structure (e.g., admissible operator/state families or coupling constraints), in contrast to refinements that preserve the original formulation such as tolerance adjustment and numerical reparameterizations. Together, these results delineate limits of rank recovery in bilinear observation problems and clarify the distinction between numerical refinement and problem modification in accessing effective dimensional structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09754v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seungbeom Choi</dc:creator>
    </item>
    <item>
      <title>Zero-Error List Decoding for Classical-Quantum Channels</title>
      <link>https://arxiv.org/abs/2601.09786</link>
      <description>arXiv:2601.09786v1 Announce Type: cross 
Abstract: The aim of this work is to study the zero-error capacity of pure-state classical-quantum channels in the setting of list decoding. We provide an achievability bound for list-size two and a converse bound holding for every fixed list size. The two bounds coincide for channels whose pairwise absolute state overlaps form a positive semi-definite matrix. Finally, we discuss a remarkable peculiarity of the classical-quantum case: differently from the fully classical setting, the rate at which the sphere-packing bound diverges might not be achievable by zero-error list codes, even when we take the limit of fixed but arbitrarily large list size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09786v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Dalai, Filippo Girardi, Ludovico Lami</dc:creator>
    </item>
    <item>
      <title>Nearest Kronecker Product Decomposition Based Subband Adaptive Filter: Algorithms and Applications</title>
      <link>https://arxiv.org/abs/2601.10078</link>
      <description>arXiv:2601.10078v1 Announce Type: cross 
Abstract: Recently, the nearest Kronecker product (NKP) decomposition-based normalized least mean square (NLMS-NKP) algorithm has demonstrated superior convergence performance compared to the conventional NLMS algorithm. However, its convergence rate exhibits significant degradation when processing highly correlated input signals. To address this problem, we propose a type-I NKP-based normalized subband adaptive filter (NSAF) algorithm, namely NSAF-NKP-I. Nevertheless, this algorithm incurs substantially higher computational overhead than the NLMS-NKP algorithm. Remarkably, our enhanced type-II NKP-based NSAF (NSAF-NKP-II) algorithm achieves equivalent convergence performance while substantially reducing computational complexity. Furthermore, to enhance robustness against impulsive noise interference, we develop two robust variants: the maximum correntropy criterion-based robust NSAF-NKP (RNSAF-NKP-MCC) and logarithmic criterion-based robust NSAF-NKP (RNSAF-NKP-LC) algorithms. Additionally, detailed analyses of computational complexity, step-size range, and theoretical steady-state performance are provided for theproposed algorithms. To enhance the practicability of the NSAF-NKP-II algorithm in complex nonlinear environments, we further devise two nonlinear implementations: the trigonometric functional link network-based NKP-NSAF (TFLN-NSAF-NKP) and Volterra series expansion-based NKP-NSAF (Volterra-NKP-NSAF) algorithms. In active noise control (ANC) systems, we further propose the filtered-x NSAF-NKP-II (NKP-FxNSAF) algorithm. Simulation experiments in echo cancellation, sparse system identification, nonlinear processing, and ANC scenarios are conducted to validate the superiority of the proposed algorithms over existing state-of-the-art counterparts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10078v1</guid>
      <category>eess.AS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TASLPRO.2025.3649394</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Audio, Speech and Language Processing, pp. 1-16, December 2025</arxiv:journal_reference>
      <dc:creator>Jianhong Ye, Haiquan Zhao</dc:creator>
    </item>
    <item>
      <title>Distributed Linearly Separable Computation with Arbitrary Heterogeneous Data Assignment</title>
      <link>https://arxiv.org/abs/2601.10177</link>
      <description>arXiv:2601.10177v1 Announce Type: cross 
Abstract: Distributed linearly separable computation is a fundamental problem in large-scale distributed systems, requiring the computation of linearly separable functions over different datasets across distributed workers. This paper studies a heterogeneous distributed linearly separable computation problem, including one master and N distributed workers. The linearly separable task function involves Kc linear combinations of K messages, where each message is a function of one dataset. Distinguished from the existing homogeneous settings that assume each worker holds the same number of datasets, where the data assignment is carefully designed and controlled by the data center (e.g., the cyclic assignment), we consider a more general setting with arbitrary heterogeneous data assignment across workers, where `arbitrary' means that the data assignment is given in advance and `heterogeneous' means that the workers may hold different numbers of datasets. Our objective is to characterize the fundamental tradeoff between the computable dimension of the task function and the communication cost under arbitrary heterogeneous data assignment. Under the constraint of integer communication costs, for arbitrary heterogeneous data assignment, we propose a universal computing scheme and a universal converse bound by characterizing the structure of data assignment, where they coincide under some parameter regimes. We then extend the proposed computing scheme and converse bound to the case of fractional communication costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10177v1</guid>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziting Zhang, Kai Wan, Minquan Cheng, Shuo Shao, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Adversarial Hypothesis Testing for Quantum Channels</title>
      <link>https://arxiv.org/abs/2601.10243</link>
      <description>arXiv:2601.10243v1 Announce Type: cross 
Abstract: This paper presents a systematic study of adversarial hypothesis testing for both quantum-quantum (QQ) and classical-quantum (CQ) channels. Unlike conventional channel discrimination, we consider a framework where the sender, Alice, selects the channel input adversarially to minimize Bob's distinguishability. We analyze this problem across four settings based on whether Alice employs i.i.d. or general inputs and whether the receiver, Bob, is informed of the specific input choice (allowing his measurement to depend on the input). We characterize the Stein exponents for each setting and reveal a striking distinction in behavior: for QQ channels with i.i.d. inputs, Bob's knowledge of the input significantly enhances distinguishability, yet this advantage vanishes when general inputs are permitted. In contrast, for CQ channels, Bob being informed provides a consistent advantage over the corresponding entanglement-breaking channels for both i.i.d. and general inputs. These results demonstrate a unique phenomenon in adversarial hypothesis testing where the CQ channel does not merely behave as a special case of the QQ channel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10243v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Masahito Hayashi, Hao-Chung Cheng, Li Gao</dc:creator>
    </item>
    <item>
      <title>Queueing-Aware Optimization of Reasoning Tokens for Accuracy-Latency Trade-offs in LLM Servers</title>
      <link>https://arxiv.org/abs/2601.10274</link>
      <description>arXiv:2601.10274v1 Announce Type: cross 
Abstract: We consider a single large language model (LLM) server that serves a heterogeneous stream of queries belonging to $N$ distinct task types. Queries arrive according to a Poisson process, and each type occurs with a known prior probability. For each task type, the server allocates a fixed number of internal thinking tokens, which determines the computational effort devoted to that query. The token allocation induces an accuracy-latency trade-off: the service time follows an approximately affine function of the allocated tokens, while the probability of a correct response exhibits diminishing returns. Under a first-in, first-out (FIFO) service discipline, the system operates as an $M/G/1$ queue, and the mean system time depends on the first and second moments of the resulting service-time distribution. We formulate a constrained optimization problem that maximizes a weighted average accuracy objective penalized by the mean system time, subject to architectural token-budget constraints and queue-stability conditions. The objective function is shown to be strictly concave over the stability region, which ensures existence and uniqueness of the optimal token allocation. The first-order optimality conditions yield a coupled projected fixed-point characterization of the optimum, together with an iterative solution and an explicit sufficient condition for contraction. Moreover, a projected gradient method with a computable global step-size bound is developed to guarantee convergence beyond the contractive regime. Finally, integer-valued token allocations are attained via rounding of the continuous solution, and the resulting performance loss is evaluated in simulation results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10274v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emre Ozbas, Melih Bastopcu</dc:creator>
    </item>
    <item>
      <title>Hybrid Encryption with Certified Deletion in Preprocessing Model</title>
      <link>https://arxiv.org/abs/2601.10542</link>
      <description>arXiv:2601.10542v1 Announce Type: cross 
Abstract: Certified deletion allows Alice to outsource data to Bob and, at a later time, obtain a verifiable guarantee that the file has been irreversibly deleted at her request. The functionality, while impossible using classical information alone, can be achieved using quantum information. Existing approaches, rely on one-time pad (OTP) encryption, or use computational hardness assumptions that may be vulnerable to future advances in classical or quantum computing. In this work, we introduce and formalize hybrid encryption with certified deletion in the preprocessing model (pHE-CD) and propose two constructions. The constructions combine an information-theoretic key encapsulation mechanism (iKEM) with a data encapsulation mechanism that provides certified deletion (DEM-CD) and, respectively, provide {\em information-theoretic certified deletion}, where both confidentiality and deletion properties are provided against a computationally unbounded adversary; and {\em everlasting certified deletion}, where confidentiality is computational before deletion, and upon successful verification of the deletion certificate, the message becomes information-theoretically hidden from an adversary that is computationally unbounded. Our pHE-CD schemes provide IND-$q_e$-CPA notion of security and support encryption of arbitrarily long messages. In the second construction, using a computationally secure DEM-CD that is quantum-safe (i.e. constructed using quantum coding and AES), we obtain quantum-safe security with keys that are significantly shorter than the message. Instantiating the proposed framework using quantum enabled kem (qKEM) as the iKEM, is a future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10542v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kunal Dey, Reihaneh Safavi-Naini</dc:creator>
    </item>
    <item>
      <title>A Mirror-Descent Algorithm for Computing the Petz-R\'enyi Capacity of Classical-Quantum Channels</title>
      <link>https://arxiv.org/abs/2601.10558</link>
      <description>arXiv:2601.10558v1 Announce Type: cross 
Abstract: We study the computation of the $\alpha$-R\'enyi capacity of a classical-quantum (c-q) channel for $\alpha\in(0,1)$. We propose an exponentiated-gradient (mirror descent) iteration that generalizes the Blahut-Arimoto algorithm. Our analysis establishes relative smoothness with respect to the entropy geometry, guaranteeing a global sublinear convergence of the objective values. Furthermore, under a natural tangent-space nondegeneracy condition (and a mild spectral lower bound in one regime), we prove local linear (geometric) convergence in Kullback-Leibler divergence on a truncated probability simplex, with an explicit contraction factor once the local curvature constants are bounded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10558v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu-Hong Lai, Hao-Chung Cheng</dc:creator>
    </item>
    <item>
      <title>Achievable Degrees of Freedom Analysis and Optimization in Massive MIMO via Characteristic Mode Analysis</title>
      <link>https://arxiv.org/abs/2601.10576</link>
      <description>arXiv:2601.10576v1 Announce Type: cross 
Abstract: Massive multiple-input multiple-output (MIMO) is esteemed as a critical technology in 6G communications, providing large degrees of freedom (DoF) to improve multiplexing gain. This paper introduces characteristic mode analysis (CMA) to derive the achievable DoF. Unlike existing works primarily focusing on the DoF of the wireless channel,the excitation and radiation properties of antennas are also involved in our DoF analysis, which influences the number of independent data streams for communication of a MIMO system. Specifically, we model the excitation and radiation properties of transceiver antennas using CMA to analyze the excitation and radiation properties of antennas. The CMA-based DoF analysis framework is established and the achievable DoF is derived. A characteristic mode optimization problem of antennas is then formulated to maximize the achievable DoF. A case study where the reconfigurable holographic surface (RHS) antennas are deployed at the transceiver is investigated, and a CMA-based genetic algorithm is later proposed to solve the above problem. By changing the characteristic modes electric field and surface current distribution of RHS, the achievable DoF is enhanced. Full-wave simulation verifies the theoretical analysis on the the achievable DoF and shows that, via the reconfiguration of RHS based on the proposed algorithm, the achievable DoF is improved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10576v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaohua Yue, Siyu Miao, Shuhao Zeng, Fenghan Lin, Boya Di</dc:creator>
    </item>
    <item>
      <title>Parametric RDT approach to computational gap of symmetric binary perceptron</title>
      <link>https://arxiv.org/abs/2601.10628</link>
      <description>arXiv:2601.10628v1 Announce Type: cross 
Abstract: We study potential presence of statistical-computational gaps (SCG) in symmetric binary perceptrons (SBP) via a parametric utilization of \emph{fully lifted random duality theory} (fl-RDT) [96]. A structural change from decreasingly to arbitrarily ordered $c$-sequence (a key fl-RDT parametric component) is observed on the second lifting level and associated with \emph{satisfiability} ($\alpha_c$) -- \emph{algorithmic} ($\alpha_a$) constraints density threshold change thereby suggesting a potential existence of a nonzero computational gap $SCG=\alpha_c-\alpha_a$. The second level estimate is shown to match the theoretical $\alpha_c$ whereas the $r\rightarrow \infty$ level one is proposed to correspond to $\alpha_a$. For example, for the canonical SBP ($\kappa=1$ margin) we obtain $\alpha_c\approx 1.8159$ on the second and $\alpha_a\approx 1.6021$ (with converging tendency towards $\sim 1.59$ range) on the seventh level. Our propositions remarkably well concur with recent literature: (i) in [20] local entropy replica approach predicts $\alpha_{LE}\approx 1.58$ as the onset of clustering defragmentation (presumed driving force behind locally improving algorithms failures); (ii) in $\alpha\rightarrow 0$ regime we obtain on the third lifting level $\kappa\approx 1.2385\sqrt{\frac{\alpha_a}{-\log\left ( \alpha_a \right ) }}$ which qualitatively matches overlap gap property (OGP) based predictions of [43] and identically matches local entropy based predictions of [24]; (iii) $c$-sequence ordering change phenomenology mirrors the one observed in asymmetric binary perceptron (ABP) in [98] and the negative Hopfield model in [100]; and (iv) as in [98,100], we here design a CLuP based algorithm whose practical performance closely matches proposed theoretical predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10628v1</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mihailo Stojnic</dc:creator>
    </item>
    <item>
      <title>Optimal lower bound for quantum channel tomography in away-from-boundary regime</title>
      <link>https://arxiv.org/abs/2601.10683</link>
      <description>arXiv:2601.10683v1 Announce Type: cross 
Abstract: Consider quantum channels with input dimension $d_1$, output dimension $d_2$ and Kraus rank at most $r$. Any such channel must satisfy the constraint $rd_2\geq d_1$, and the parameter regime $rd_2=d_1$ is called the boundary regime. In this paper, we show an optimal query lower bound $\Omega(rd_1d_2/\varepsilon^2)$ for quantum channel tomography to within diamond norm error $\varepsilon$ in the away-from-boundary regime $rd_2\geq 2d_1$, matching the existing upper bound $O(rd_1d_2/\varepsilon^2)$. In particular, this lower bound fully settles the query complexity for the commonly studied case of equal input and output dimensions $d_1=d_2=d$ with $r\geq 2$, in sharp contrast to the unitary case $r=1$ where Heisenberg scaling $\Theta(d^2/\varepsilon)$ is achievable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10683v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kean Chen, Zhicheng Zhang, Nengkun Yu</dc:creator>
    </item>
    <item>
      <title>Quantum Maxwell Erasure Decoder for qLDPC codes</title>
      <link>https://arxiv.org/abs/2601.10713</link>
      <description>arXiv:2601.10713v1 Announce Type: cross 
Abstract: We introduce a quantum Maxwell erasure decoder for CSS quantum low-density parity-check (qLDPC) codes that extends peeling with bounded guessing. Guesses are tracked symbolically and can be eliminated by restrictive checks, giving a tunable tradeoff between complexity and performance via a guessing budget: an unconstrained budget recovers Maximum-Likelihood (ML) performance, while a constant budget yields linear-time decoding and approximates ML. We provide theoretical guarantees on asymptotic performance and demonstrate strong performance on bivariate bicycle and quantum Tanner codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10713v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bruno Costa Alves Freire, Fran\c{c}ois-Marie Le R\'egent, Anthony Leverrier</dc:creator>
    </item>
    <item>
      <title>A Framework of Distributed Source Encryption using Mutual Information Security Criterion and the Strong Converse Theorem</title>
      <link>https://arxiv.org/abs/2507.13294</link>
      <description>arXiv:2507.13294v4 Announce Type: replace 
Abstract: We reinvestigate the general distributed secure source coding based on the common key cryptosystem proposed by Oohama and Santoso (ITW 2021). They proposed a framework of distributed source encryption and derived the necessary and sufficient conditions to have reliable and secure transmission. However, the bounds of the rate region, which specifies both necessary and sufficient conditions to have reliable and secure transmission under the proposed cryptosystem, were derived based on a self-tailored non-standard} security criterion. In this paper we adopt the standard security criterion, i.e., standard mutual information. We successfully establish the bounds of the rate region based on this security criterion. Information spectrum method and a variant of Birkhoff-von Neumann theorem play an important role in deriving the result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13294v4</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yasutada Oohama, Bagus Santoso</dc:creator>
    </item>
    <item>
      <title>A recursive approach to the construction and enumeration of self-orthogonal and self-dual codes over finite commutative chain rings of even characteristic</title>
      <link>https://arxiv.org/abs/2510.06069</link>
      <description>arXiv:2510.06069v2 Announce Type: replace 
Abstract: Let $\mathcal{R}_{e,m}$ be a finite commutative chain ring of even characteristic with maximal ideal $\langle u \rangle$ of nilpotency index $e \geq 2,$ Teichm$\ddot{u}$ller set $\mathcal{T}_{m},$ and residue field $\mathcal{R}_{e,m}/\langle u \rangle$ of order $2^m.$ Suppose that $2 \in \langle u^{\kappa}\rangle \setminus \langle u^{\kappa+1}\rangle$ for some even positive integer $ \kappa \leq e.$ In this paper, we provide a recursive method to construct a self-orthogonal code $\mathcal{C}_e$ of type $\{\lambda_1, \lambda_2, \ldots, \lambda_e\}$ and length $n$ over $\mathcal{R}_{e,m}$ from a chain $\mathcal{D}^{(1)}\subseteq \mathcal{D}^{(2)} \subseteq \cdots \subseteq \mathcal{D}^{(\lceil \frac{e}{2} \rceil)}$ of self-orthogonal codes of length $n$ over $\mathcal{T}_{m},$ and vice versa, where $\dim \mathcal{D}^{(i)}=\lambda_1+\lambda_2+\cdots+\lambda_i$ for $1 \leq i \leq \lceil \frac{e}{2} \rceil,$ the codes $\mathcal{D}^{(\lfloor \frac{e+1}{2} \rfloor-\kappa)},\mathcal{D}^{(\lfloor \frac{e+1}{2} \rfloor -\kappa+1)},\ldots,\mathcal{D}^{(\lfloor \frac{e}{2}\rfloor-\lfloor \frac{\kappa}{2} \rfloor)}$ satisfy certain additional conditions, and $\lambda_1,\lambda_2,\ldots,\lambda_e$ are non-negative integers satisfying $2\lambda_1+2\lambda_2+\cdots+2\lambda_{e-i+1}+\lambda_{e-i+2}+\lambda_{e-i+3}+\cdots+\lambda_i \leq n$ for $\lceil \frac{e+1}{2} \rceil \leq i\leq e.$ This construction guarantees that $Tor_i(\mathcal{C}_e)=\mathcal{D}^{(i)}$ for $1 \leq i \leq \lceil \frac{e}{2} \rceil.$ By employing this recursive construction method, together with the results from group theory and finite geometry, we derive explicit enumeration formulae for all self-orthogonal and self-dual codes of an arbitrary length over $\mathcal{R}_{e,m}.$ We also demonstrate these results through examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06069v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Monika Yadav, Anuradha Sharma</dc:creator>
    </item>
    <item>
      <title>Recursive construction and enumeration of self-orthogonal and self-dual codes over finite commutative chain rings of even characteristic</title>
      <link>https://arxiv.org/abs/2510.06082</link>
      <description>arXiv:2510.06082v2 Announce Type: replace 
Abstract: Let $\mathscr{R}_{e,m}$ denote a finite commutative chain ring of even characteristic with maximal ideal $\langle u \rangle$ of nilpotency index $e \geq 3,$ Teichm$\ddot{u}$ller set $\mathcal{T}_{m},$ and residue field $\mathscr{R}_{e,m}/\langle u \rangle$ of order $2^m.$ Suppose that $2 \in \langle u^{\kappa}\rangle \setminus \langle u^{\kappa+1}\rangle$ for some odd integer $\kappa$ with $3 \leq \kappa \leq e.$ In this paper, we first develop a recursive method to construct a self-orthogonal code $\mathscr{D}_e$ of type $\{\lambda_1, \lambda_2, \ldots, \lambda_e\}$ and length $n$ over $\mathscr{R}_{e,m}$ from a chain $\mathcal{C}^{(1)}\subseteq \mathcal{C}^{(2)} \subseteq \cdots \subseteq \mathcal{C}^{(\lceil \frac{e}{2} \rceil)} $ of self-orthogonal codes of length $n$ over $\mathcal{T}_{m},$ and vice versa, subject to certain conditions, where $\lambda_1,\lambda_2,\ldots,\lambda_e$ are non-negative integers satisfying $2\lambda_1+2\lambda_2+\cdots+2\lambda_{e-i+1}+\lambda_{e-i+2}+\lambda_{e-i+3}+\cdots+\lambda_i \leq n$ for $\lceil \frac{e+1}{2} \rceil \leq i\leq e,$ and
  $\lfloor \cdot \rfloor$ and $\lceil \cdot \rceil$ denote the floor and ceiling functions, respectively. This construction ensures that $Tor_i(\mathscr{D}_e)=\mathcal{C}^{(i)}$ for $1 \leq i \leq \lceil \frac{e}{2} \rceil.$
  With the help of this recursive construction method and by applying results from group theory and finite geometry, we obtain explicit enumeration formulae for all self-orthogonal and self-dual codes of an arbitrary length over $\mathscr{R}_{e,m}.$ We also illustrate these results with some examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06082v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Monika Yadav, Anuradha Sharma</dc:creator>
    </item>
    <item>
      <title>Universal Maximum Likelihood (List) Decoding via Fast Vector-Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2510.21414</link>
      <description>arXiv:2510.21414v2 Announce Type: replace 
Abstract: Maximum-likelihood (ML) decoding for arbitrary block codes remains fundamentally hard, with worst-case time complexity-measured by the total number of multiplications-being no better than straightforward exhaustive search, which requires $q^{k} n$ operations for an $[n,k]_q$ code. This paper introduces a simple, code-agnostic framework that reduces the worst-case complexity by a factor of $n$, down to $q^{k}$ operations, a highly desirable reduction in practice. The result holds for both linear and nonlinear block codes over general memoryless channels and under both hard-decision and soft-decision decoding. It naturally extends to intersymbol-interference (ISI) channels and ML list decoding with only a negligible increase in complexity. Our core insight is that, upon receipt of each sequence at the receiver, the conditional probability of that sequence for each codeword in the codebook (i.e., the \emph{likelihood}) can be expressed as the inner product of two carefully constructed vectors -- the first depending on the received sequence, and the second on that codeword itself. As a result, evaluating the likelihoods for all codewords in the codebook reduces to a single vector-matrix multiplication, and ML decoding (MLD) becomes the simple task of picking the maximum entry in the resulting vector. The only non-trivial cost lies in the vector-matrix product. However, our matrix construction allows the use of the Mailman algorithm to reduce this cost. This time reduction is achieved at the cost of high space complexity, requiring $\mathcal{O}(q^{k+1} n)$ space to store the pre-computed codebook matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21414v2</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Ly, Emina Soljanin, Michael Schleppy</dc:creator>
    </item>
    <item>
      <title>Rate-distortion Theory with Lower Semi-continuous Distortion: A Concentration-compactness Approach</title>
      <link>https://arxiv.org/abs/2601.07246</link>
      <description>arXiv:2601.07246v2 Announce Type: replace 
Abstract: In this paper, we study rate-distortion theory for general sources with an emphasis on the existence of optimal reconstruction distributions. Classical existence results rely on compactness assumptions with continuous distortion that are often violated in general settings. By introducing the concentration-compactness principle into the analysis of the rate-distortion functional, we establish the existence of optimal reconstructions under mild coercivity and lower semi-continuity conditions on the distortion function. Our results provide a unified and transparent existence theorem for rate-distortion problems with lower semi-continuous distortion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07246v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayang Zou, Luyao Fan, Jiayang Gao, Jia Wang</dc:creator>
    </item>
    <item>
      <title>A response-adaptive multi-arm design for continuous endpoints based on a weighted information measure</title>
      <link>https://arxiv.org/abs/2409.04970</link>
      <description>arXiv:2409.04970v2 Announce Type: replace-cross 
Abstract: Multi-arm trials are gaining interest in practice given the statistical and logistical advantages they can offer. The standard approach uses a fixed allocation ratio, but there is a call for making it adaptive and skewing the allocation of patients towards better-performing arms. However, it is well-known that these approaches might suffer from lower statistical power. We present a response-adaptive design for continuous endpoints which explicitly allows to control the trade-off between the number of patients allocated to the "optimal" arm and the statistical power. Such a balance is achieved through the calibration of a tuning parameter, and we explore robust procedures to select it. The proposed criterion is based on a context-dependent information measure which gives greater weight to treatment arms with characteristics close to a pre-specified clinical target. We establish conditions under which the procedure consistently selects the target arm and derive the corresponding limiting allocation ratios. We also introduce a simulation-based hypothesis testing procedure which focuses on selecting the target arm and discuss strategies to effectively control the type-I error rate. The practical implementation of the proposed criterion and its potential advantage over currently used alternatives are illustrated in the context of early Phase IIa proof-of-concept oncology trials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04970v2</guid>
      <category>stat.ME</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gianmarco Caruso, Pavel Mozgunov</dc:creator>
    </item>
    <item>
      <title>Error-Minimizing Measurements in Postselected One-Shot Symmetric Quantum State Discrimination and Acceptance as a Performance Metric</title>
      <link>https://arxiv.org/abs/2409.13379</link>
      <description>arXiv:2409.13379v2 Announce Type: replace-cross 
Abstract: In hypothesis testing with quantum states, given a black box containing one of the two possible states, measurement is performed to detect in favor of one of the hypotheses. In postselected hypothesis testing, a third outcome is added, corresponding to not selecting any of the hypotheses. In postselected scenario, minimum error one-shot symmetric hypothesis testing is characterized in literature conditioned on the fact that one of the selected outcomes occur. We proceed further in this direction to give the set of all possible measurements that lead to the minimum error. We have given an arbitrary error-minimizing measurement in a parametric form. Note that not selecting any of the hypotheses decimates the quality of testing. We further give an example to show that these measurements vary in quality. There is a need to discuss the quality of postselected hypothesis testing. We then characterize the quality of postselected hypothesis testing by defining a new metric acceptance and give expression of acceptance for an arbitrary error-minimizing measurement in terms of some parameters of the measurement. On the set of measurements that achieve minimum error, we have maximized the acceptance, and given an example which achieves that, thus giving an example of the best possible measurement in terms of acceptance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13379v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saurabh Kumar Gupta, Abhishek K. Gupta</dc:creator>
    </item>
    <item>
      <title>Rydberg Atomic Quantum Receivers for Classical Wireless Communications and Sensing: Their Models and Performance</title>
      <link>https://arxiv.org/abs/2412.05554</link>
      <description>arXiv:2412.05554v3 Announce Type: replace-cross 
Abstract: The significant progress of quantum sensing technologies offer numerous radical solutions for measuring a multitude of physical quantities at an unprecedented precision. Among them, Rydberg atomic quantum receivers (RAQRs) emerge as an eminent solution for detecting the electric field of radio frequency (RF) signals, exhibiting great potential in assisting classical wireless communications and sensing. So far, most experimental studies have aimed for the proof of physical concepts to reveal its promise, while the practical signal model of RAQR-aided wireless communications and sensing remained under-explored. Furthermore, the performance of RAQR-based wireless receivers and their advantages over classical RF receivers have not been fully characterized. To fill these gaps, we introduce the RAQR to the wireless community by presenting an end-to-end reception scheme. We then develop a corresponding equivalent baseband signal model relying on a realistic reception flow. Our scheme and model provide explicit design guidance to RAQR-aided wireless systems. We next study the performance of RAQR-aided wireless systems based on our model, and compare them to classical RF receivers. The results show that Doppler broadening-free RAQRs are capable of achieving a substantial received signal-to-noise ratio (SNR) gain of over $27$ decibel (dB) and $40$ dB in the photon shot limit and standard quantum limit regimes, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05554v3</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tierui Gong, Jiaming Sun, Chau Yuen, Guangwei Hu, Yufei Zhao, Yong Liang Guan, Chong Meng Samson See, M\'erouane Debbah, Lajos Hanzo</dc:creator>
    </item>
    <item>
      <title>Information-theoretic coordinate subset and partition selection of multivariate Markov chains via submodular optimization</title>
      <link>https://arxiv.org/abs/2503.23340</link>
      <description>arXiv:2503.23340v2 Announce Type: replace-cross 
Abstract: We study the problem of optimally projecting the transition matrix of a finite ergodic multivariate Markov chain onto a lower-dimensional state space, as well as the problem of finding an optimal partition of coordinates such that the factorized Markov chain gives minimal information loss compared to the original multivariate chain. Specifically, we seek to construct a Markov chain that optimizes various information-theoretic criteria under cardinality constraints. These criteria include entropy rate, information-theoretic distance to factorizability, independence, and stationarity. We formulate these tasks as best subset or partition selection problems over multivariate Markov chains and leverage the (k-)submodular (or (k-)supermodular) structures of the objective functions to develop efficient greedy-based algorithms with theoretical guarantees. Along the way, we introduce a generalized version of the distorted greedy algorithm, which may be of independent interest. Finally, we illustrate the theory and algorithms through extensive numerical experiments with publicly available code on multivariate Markov chains associated with the Bernoulli--Laplace and Curie--Weiss models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23340v2</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zheyuan Lai, Michael C. H. Choi</dc:creator>
    </item>
    <item>
      <title>Quantum circuit complexity and unsupervised machine learning of topological order</title>
      <link>https://arxiv.org/abs/2508.04486</link>
      <description>arXiv:2508.04486v2 Announce Type: replace-cross 
Abstract: Inspired by the close relationship between Kolmogorov complexity and unsupervised machine learning, we explore quantum circuit complexity, an important concept in quantum computation and quantum information science, as a pivot to understand and to build interpretable and efficient unsupervised machine learning for topological order in quantum many-body systems. We argue that Nielsen's quantum circuit complexity represents an intrinsic topological distance between topological quantum many-body phases of matter, and as such plays a central role in interpretable manifold learning of topological order. To span a bridge from conceptual power to practical applicability, we present two theorems that connect Nielsen's quantum circuit complexity for the quantum path planning between two arbitrary quantum many-body states with quantum Fisher complexity (Bures distance) and entanglement generation, respectively. Leveraging these connections, fidelity-based and entanglement-based similarity measures or kernels, which are more practical for implementation, are formulated. Using the two proposed distance measures, unsupervised manifold learning of quantum phases of the bond-alternating XXZ spin chain, the ground state of Kitaev's toric code and random product states, is conducted, demonstrating their superior performance. Moreover, we find that the entanglement-based approach, which captures the long-range structure of quantum entanglement of topological orders, is more robust to local Haar random noises. Relations with classical shadow tomography and shadow kernel learning are also discussed, where the latter can be naturally understood from our approach. Our results establish connections between key concepts and tools of quantum circuit computation, quantum complexity, quantum metrology, and machine learning of topological quantum order.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04486v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yanming Che, Clemens Gneiting, Xiaoguang Wang, Franco Nori</dc:creator>
    </item>
    <item>
      <title>Pulse Shaping Filter Design for Integrated Sensing &amp; Communication with Zak-OTFS</title>
      <link>https://arxiv.org/abs/2510.15195</link>
      <description>arXiv:2510.15195v2 Announce Type: replace-cross 
Abstract: Zak-OTFS provides a framework for integrated sensing &amp; communication (ISAC) in high delay and Doppler spread environments. Pulse shaping filter design enables joint optimization of sensing and communication performance. For sensing, a localized pulse shaping filter enables input-output (I/O) relation estimates close to the physical scattering channel. For communication, orthogonality of the pulse shape on the information lattice prevents inter-symbol interference, and no time and bandwidth expansion enables full spectral efficiency. A filter simultaneously meeting all three objectives is ideal for ISAC. Existing filter designs achieve two, but not all three objectives. In this work, we design pulse shaping filters meeting all three objectives via the Isotropic Orthogonal Transform Algorithm. The proposed filters have improved spectral efficiency, data detection and sensing performance over existing filter choices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15195v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nishant Mehrotra, Sandesh Rao Mattu, Robert Calderbank</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Composite Quantum Hypothesis Testing</title>
      <link>https://arxiv.org/abs/2601.08588</link>
      <description>arXiv:2601.08588v2 Announce Type: replace-cross 
Abstract: This paper investigates symmetric composite binary quantum hypothesis testing (QHT), where the goal is to determine which of two uncertainty sets contains an unknown quantum state. While asymptotic error exponents for this problem are well-studied, the finite-sample regime remains poorly understood. We bridge this gap by characterizing the sample complexity -- the minimum number of state copies required to achieve a target error level. Specifically, we derive lower bounds that generalize the sample complexity of simple QHT and introduce new upper bounds for various uncertainty sets, including of both finite and infinite cardinalities. Notably, our upper and lower bounds match up to universal constants, providing a tight characterization of the sample complexity. Finally, we extend our analysis to the differentially private setting, establishing the sample complexity for privacy-preserving composite QHT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08588v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob Paul Simpson, Efstratios Palias, Sharu Theresa Jose</dc:creator>
    </item>
  </channel>
</rss>
