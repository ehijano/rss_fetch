<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Apr 2025 01:51:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Which kind of research papers influence policymaking</title>
      <link>https://arxiv.org/abs/2504.18889</link>
      <description>arXiv:2504.18889v1 Announce Type: new 
Abstract: This study examines the use of evidence in policymaking by analysing a range of journal and article attributes, as well as online engagement metrics. It employs a large-scale citation analysis of nearly 150,000 articles covering diverse policy topics. The findings highlight that scholarly citations exert the strongest positive influence on policy citations. Articles from journals with a higher citation impact and larger Mendeley readership are cited more frequently in policy documents. Other online engagements, such as news and blog mentions, also boost policy citations, while mentions on social media X have a negative effect. The finding that highly cited and widely read papers are also frequently referenced in policy documents likely reflects the perception among policymakers that such research is more trustworthy. In contrast, papers that derive their influence primarily from social media tend to be cited less often in policy contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18889v1</guid>
      <category>cs.DL</category>
      <category>stat.AP</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pablo Dorta-Gonz\'alez</dc:creator>
    </item>
    <item>
      <title>Effect of perceived preprint effectiveness and research intensity on posting behaviour</title>
      <link>https://arxiv.org/abs/2504.18896</link>
      <description>arXiv:2504.18896v1 Announce Type: new 
Abstract: Open science is increasingly recognised worldwide, with preprint posting emerging as a key strategy. This study explores the factors influencing researchers' adoption of preprint publication, particularly the perceived effectiveness of this practice and research intensity indicators such as publication and review frequency. Using open data from a comprehensive survey with 5,873 valid responses, we conducted regression analyses to control for demographic variables. Researchers' productivity, particularly the number of journal articles and books published, greatly influences the frequency of preprint deposits. The perception of the effectiveness of preprints follows this. Preprints are viewed positively in terms of early access to new research, but negatively in terms of early feedback. Demographic variables, such as gender and the type of organisation conducting the research, do not have a significant impact on the production of preprints when other factors are controlled for. However, the researcher's discipline, years of experience and geographical region generally have a moderate effect on the production of preprints. These findings highlight the motivations and barriers associated with preprint publication and provide insights into how researchers perceive the benefits and challenges of this practice within the broader context of open science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18896v1</guid>
      <category>cs.DL</category>
      <category>stat.AP</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pablo Dorta-Gonz\'alez, Mar\'ia Isabel Dorta-Gonz\'alez</dc:creator>
    </item>
    <item>
      <title>Annif at SemEval-2025 Task 5: Traditional XMTC augmented by LLMs</title>
      <link>https://arxiv.org/abs/2504.19675</link>
      <description>arXiv:2504.19675v1 Announce Type: cross 
Abstract: This paper presents the Annif system in SemEval-2025 Task 5 (LLMs4Subjects), which focussed on subject indexing using large language models (LLMs). The task required creating subject predictions for bibliographic records from the bilingual TIBKAT database using the GND subject vocabulary. Our approach combines traditional natural language processing and machine learning techniques implemented in the Annif toolkit with innovative LLM-based methods for translation and synthetic data generation, and merging predictions from monolingual models. The system ranked first in the all-subjects category and second in the tib-core-subjects category in the quantitative evaluation, and fourth in qualitative evaluations. These findings demonstrate the potential of combining traditional XMTC algorithms with modern LLM techniques to improve the accuracy and efficiency of subject indexing in multilingual contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19675v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.DL</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Osma Suominen, Juho Inkinen, Mona Lehtinen</dc:creator>
    </item>
    <item>
      <title>The Semantic Scholar Open Data Platform</title>
      <link>https://arxiv.org/abs/2301.10140</link>
      <description>arXiv:2301.10140v2 Announce Type: replace 
Abstract: The volume of scientific output is creating an urgent need for automated tools to help scientists keep up with developments in their field. Semantic Scholar (S2) is an open data platform and website aimed at accelerating science by helping scholars discover and understand scientific literature. We combine public and proprietary data sources using state-of-the-art techniques for scholarly PDF content extraction and automatic knowledge graph construction to build the Semantic Scholar Academic Graph, the largest open scientific literature graph to-date, with 200M+ papers, 80M+ authors, 550M+ paper-authorship edges, and 2.4B+ citation edges. The graph includes advanced semantic features such as structurally parsed text, natural language summaries, and vector embeddings. In this paper, we describe the components of the S2 data processing pipeline and the associated APIs offered by the platform. We will update this living document to reflect changes as we add new data offerings and improve existing services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.10140v2</guid>
      <category>cs.DL</category>
      <category>cs.CL</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rodney Kinney, Chloe Anastasiades, Russell Authur, Iz Beltagy, Jonathan Bragg, Alexandra Buraczynski, Isabel Cachola, Stefan Candra, Yoganand Chandrasekhar, Arman Cohan, Miles Crawford, Doug Downey, Jason Dunkelberger, Oren Etzioni, Rob Evans, Sergey Feldman, Joseph Gorney, David Graham, Fangzhou Hu, Regan Huff, Daniel King, Sebastian Kohlmeier, Bailey Kuehl, Michael Langan, Daniel Lin, Haokun Liu, Kyle Lo, Jaron Lochner, Kelsey MacMillan, Tyler Murray, Chris Newell, Smita Rao, Shaurya Rohatgi, Paul Sayre, Zejiang Shen, Amanpreet Singh, Luca Soldaini, Shivashankar Subramanian, Amber Tanaka, Alex D. Wade, Linda Wagner, Lucy Lu Wang, Chris Wilhelm, Caroline Wu, Jiangjiang Yang, Angele Zamarron, Madeleine Van Zuylen, Daniel S. Weld</dc:creator>
    </item>
    <item>
      <title>Arab Spring's Impact on Science through the Lens of Scholarly Attention, Funding, and Migration</title>
      <link>https://arxiv.org/abs/2503.13238</link>
      <description>arXiv:2503.13238v2 Announce Type: replace 
Abstract: The Arab Spring is a major socio-political movement that reshaped democratic aspirations in the Middle East and North Africa, attracting global attention through news, social media, and academic discourse. However, its consequences on the academic landscape in the region are still unclear. Here, we conduct the first study of scholarly attention toward 10 target countries affected by the Arab Spring by analyzing more than 25 million articles published from 2002 to 2019. Using a difference-in-difference statistical framework, we find that most target countries have experienced a significant increase in scholarly attention post-Arab Spring compared to the rest of the world, with Egypt attracting the most attention. We investigate how funding and migration networks relate to scholarly attention and reveal that Saudi Arabia has emerged as a key player among Western nations by attracting researchers and funding projects that shape research on the region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13238v2</guid>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yasaman Asgari, Hongyu Zhou, Ozgur Kadir Ozer, Rezvaneh Rezapour, Mary Ellen Sloane, Alexandre Bovet</dc:creator>
    </item>
    <item>
      <title>Research impact evaluation based on effective authorship contribution sensitivity: h-leadership index</title>
      <link>https://arxiv.org/abs/2503.18236</link>
      <description>arXiv:2503.18236v3 Announce Type: replace 
Abstract: The evaluation of a researcher's performance has traditionally relied on various bibliometric measures, with the h-index being one of the most prominent. However, the h-index only accounts for the number of citations received in a publication and does not account for other factors such as the number of authors or their specific contributions in collaborative works. Therefore, the h-index has been placed on scrutiny as it has motivated academic integrity issues where non-contributing authors get authorship merely for raising their h-index. In this study, we comprehensively evaluate existing metrics in their ability to account for authorship contribution by their position and introduce a novel variant of the h-index, known as the h-leadership index. The h-leadership index aims to advance the fair evaluation of academic contributions in multi-authored publications by giving importance to authorship position beyond the first and last authors, focused by Stanford's ranking of the top 2 \% of world scientists. We assign weighted citations based on a modified complementary unit Gaussian curve, ensuring that the contributions of middle authors are appropriately recognised. We apply the h-leadership index to analyse the top 50 researchers across the Group of 8 (Go8) universities in Australia, demonstrating its potential to provide a more balanced assessment of research performance. We provide open-source software for extending the work further.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18236v3</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hardik A. Jain, Rohitash Chandra</dc:creator>
    </item>
    <item>
      <title>Cutting Through the Clutter: The Potential of LLMs for Efficient Filtration in Systematic Literature Reviews</title>
      <link>https://arxiv.org/abs/2407.10652</link>
      <description>arXiv:2407.10652v2 Announce Type: replace-cross 
Abstract: Systematic literature reviews (SLRs) are essential but labor-intensive due to high publication volumes and inefficient keyword-based filtering. To streamline this process, we evaluate Large Language Models (LLMs) for enhancing efficiency and accuracy in corpus filtration while minimizing manual effort. Our open-source tool LLMSurver presents a visual interface to utilize LLMs for literature filtration, evaluate the results, and refine queries in an interactive way. We assess the real-world performance of our approach in filtering over 8.3k articles during a recent survey construction, comparing results with human efforts. The findings show that recent LLM models can reduce filtering time from weeks to minutes. A consensus scheme ensures recall rates &gt;98.8%, surpassing typical human error thresholds and improving selection accuracy. This work advances literature review methodologies and highlights the potential of responsible human-AI collaboration in academic research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10652v2</guid>
      <category>cs.LG</category>
      <category>cs.DL</category>
      <category>cs.HC</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>16th International EuroVis Workshop on Visual Analytics (EuroVA'25), 2025</arxiv:journal_reference>
      <dc:creator>Lucas Joos, Daniel A. Keim, Maximilian T. Fischer</dc:creator>
    </item>
  </channel>
</rss>
