<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Jun 2024 01:42:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 13 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Game Theoretic Analysis of the Three-Gambler Ruin Game</title>
      <link>https://arxiv.org/abs/2406.07878</link>
      <description>arXiv:2406.07878v1 Announce Type: new 
Abstract: We study the following game. Three players start with initial capitals of $s_{1},s_{2},s_{3}$ dollars; in each round player $P_{m}$ is selected with probability $\frac{1}{3}$; then \emph{he} selects player $P_{n}$ and they play a game in which $P_{m}$ wins from (resp. loses to) $P_{n}$ one dollar with probability $p_{mn}$ (resp. $p_{nm}=1-p_{mn}$). When a player loses all his capital he drops out; the game continues until a single player wins by collecting everybody's money.
  This is a "strategic" version of the classical Gambler's Ruin game. It seems reasonable that a player may improve his winning probability by judicious selection of which opponent to engage in each round. We formulate the situation as a \emph{stochastic game} and prove that it has at least one Nash equilibrium in deterministic stationary strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07878v1</guid>
      <category>cs.GT</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ath. Kehagias, G. Gkyzis, A. Karakoulakis, A. Kyprianidis</dc:creator>
    </item>
    <item>
      <title>Discrete Single-Parameter Optimal Auction Design</title>
      <link>https://arxiv.org/abs/2406.08125</link>
      <description>arXiv:2406.08125v1 Announce Type: new 
Abstract: We study the classic single-item auction setting of Myerson, but under the assumption that the buyers' values for the item are distributed over finite supports. Using strong LP duality and polyhedral theory, we rederive various key results regarding the revenue-maximizing auction, including the characterization through virtual welfare maximization and the optimality of deterministic mechanisms, as well as a novel, generic equivalence between dominant-strategy and Bayesian incentive compatibility.
  Inspired by this, we abstract our approach to handle more general auction settings, where the feasibility space can be given by arbitrary convex constraints, and the objective is a convex combination of revenue and social welfare. We characterize the optimal auctions of such systems as generalized virtual welfare maximizers, by making use of their KKT conditions, and we present an analogue of Myerson's payment formula for general discrete single-parameter auction settings. Additionally, we prove that total unimodularity of the feasibility space is a sufficient condition to guarantee the optimality of auctions with integral allocation rules.
  Finally, we demonstrate this KKT approach by applying it to a setting where bidders are interested in buying feasible flows on trees with capacity constraints, and provide a combinatorial description of the (randomized, in general) optimal auction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08125v1</guid>
      <category>cs.GT</category>
      <category>cs.DM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiannis Giannakopoulos, Johannes Hahn</dc:creator>
    </item>
    <item>
      <title>Monotonic Mechanisms for Selling Multiple Goods</title>
      <link>https://arxiv.org/abs/2210.17150</link>
      <description>arXiv:2210.17150v2 Announce Type: replace 
Abstract: Maximizing the revenue from selling two or more goods has been shown to require the use of $nonmonotonic$ mechanisms, where a higher-valuation buyer may pay less than a lower-valuation one. Here we show that the restriction to $monotonic$ mechanisms may not just lower the revenue, but may in fact yield only a $negligible$ $fraction$ of the maximal revenue; more precisely, the revenue from monotonic mechanisms is no more than k times the simple revenue obtainable by selling the goods separately, or bundled (where k is the number of goods), whereas the maximal revenue may be arbitrarily larger. We then study the class of monotonic mechanisms and its subclass of allocation-monotonic mechanisms, and obtain useful characterizations and revenue bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.17150v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ran Ben-Moshe, Sergiu Hart, Noam Nisan</dc:creator>
    </item>
    <item>
      <title>Autobidders with Budget and ROI Constraints: Efficiency, Regret, and Pacing Dynamics</title>
      <link>https://arxiv.org/abs/2301.13306</link>
      <description>arXiv:2301.13306v3 Announce Type: replace 
Abstract: We study a game between autobidding algorithms that compete in an online advertising platform. Each autobidder is tasked with maximizing its advertiser's total value over multiple rounds of a repeated auction, subject to budget and return-on-investment constraints. We propose a gradient-based learning algorithm that is guaranteed to satisfy all constraints and achieves vanishing individual regret. Our algorithm uses only bandit feedback and can be used with the first- or second-price auction, as well as with any "intermediate" auction format. Our main result is that when these autobidders play against each other, the resulting expected liquid welfare over all rounds is at least half of the expected optimal liquid welfare achieved by any allocation. This holds whether or not the bidding dynamics converges to an equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.13306v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brendan Lucier, Sarath Pattathil, Aleksandrs Slivkins, Mengxiao Zhang</dc:creator>
    </item>
    <item>
      <title>Coordination in Noncooperative Multiplayer Matrix Games via Reduced Rank Correlated Equilibria</title>
      <link>https://arxiv.org/abs/2403.10384</link>
      <description>arXiv:2403.10384v2 Announce Type: replace 
Abstract: Coordination in multiplayer games enables players to avoid the lose-lose outcome that often arises at Nash equilibria. However, designing a coordination mechanism typically requires the consideration of the joint actions of all players, which becomes intractable in large-scale games. We develop a novel coordination mechanism, termed reduced rank correlated equilibria, which reduces the number of joint actions to be considered and thereby mitigates computational complexity. The idea is to approximate the set of all joint actions with the actions used in a set of pre-computed Nash equilibria via a convex hull operation. In a game with n players and each player having m actions, the proposed mechanism reduces the number of joint actions considered from O(m^n) to O(mn). We demonstrate the application of the proposed mechanism to an air traffic queue management problem. Compared with the correlated equilibrium-a popular benchmark coordination mechanism-the proposed approach is capable of solving a problem involving four thousand times more joint actions while yielding similar or better performance in terms of a fairness indicator and showing a maximum optimality gap of 0.066% in terms of the average delay cost. In the meantime, it yields a solution that shows up to 99.5% improvement in a fairness indicator and up to 50.4% reduction in average delay cost compared to the Nash solution, which does not involve coordination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10384v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaehan Im, Yue Yu, David Fridovich-Keil, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>Single-token vs Two-token Blockchain Tokenomics</title>
      <link>https://arxiv.org/abs/2403.15429</link>
      <description>arXiv:2403.15429v2 Announce Type: replace 
Abstract: We consider long-term equilibria that arise in the tokenomics design of proof-of-stake (PoS) blockchain systems that comprise of users and validators, both striving to maximize their own utilities. Validators are system maintainers who get rewarded with tokens for performing the work necessary for the system to function properly, while users compete and pay with such tokens for getting a desired portion of the system service.
  We study how the system service provision and suitable rewards schemes together can lead to equilibria with desirable characteristics (1) viability: the system keeps parties engaged, (2) decentralization: multiple validators are participating, (3) stability: the price path of the underlying token used to transact with the system does not change widely over time, and (4) feasibility: the mechanism is easy to implement as a smart contract, i.e., it does not require fiat reserves on-chain for buy back of tokens or to perform bookkeeping of exponentially growing token holdings. Our analysis enables to put forward a novel generic mechanism for blockchain ``monetary policy'' that we call {\em quantitative rewarding} (QR). We investigate how to implement QR in single-token and two-token proof of stake (PoS) blockchain systems. The latter are systems that utilize one token for the users to pay the transaction fees and a different token for the validators to participate in the PoS protocol and get rewarded. Our approach demonstrates a concrete advantage of the two-token setting in terms of the ability of the QR mechanism to be realized effectively and provide good equilibria. Our analysis also reveals an inherent limitation of the single token setting in terms of implementing an effective blockchain monetary policy - a distinction that is, to the best of our knowledge, highlighted for the first time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15429v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aggelos Kiayias, Philip Lazos, Paolo Penna</dc:creator>
    </item>
    <item>
      <title>Epistemic EFX Allocations Exist for Monotone Valuations</title>
      <link>https://arxiv.org/abs/2405.14463</link>
      <description>arXiv:2405.14463v2 Announce Type: replace 
Abstract: We study the fundamental problem of fairly dividing a set of indivisible items among agents with (general) monotone valuations. The notion of envy-freeness up to any item (EFX) is considered to be one of the most fascinating fairness concepts in this line of work. Unfortunately, despite significant efforts, existence of EFX allocations is a major open problem in fair division, thereby making the study of approximations and relaxations of EFX a natural line of research. Recently, Caragiannis et al. introduced a promising relaxation of EFX, called epistemic EFX (EEFX). We say an allocation to be EEFX if, for every agent, it is possible to shuffle the items in the remaining bundles so that she becomes "EFX-satisfied". Caragiannis et al. prove existence and polynomial-time computability of EEFX allocations for additive valuations. A natural question asks what happens when we consider valuations more general than additive?
  We address this important open question and answer it affirmatively by establishing the existence of EEFX allocations for an arbitrary number of agents with general monotone valuations. To the best of our knowledge, EEFX is the only known relaxation of EFX (beside EF1) to have such strong existential guarantees. Furthermore, we complement our existential result by proving computational and information-theoretic lower bounds. We prove that even for an arbitrary number of (more than one) agents with identical submodular valuations, it is PLS-hard to compute EEFX allocations and it requires exponentially-many value queries to do so.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14463v2</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannaneh Akrami, Nidhi Rathi</dc:creator>
    </item>
    <item>
      <title>Operator Splitting for Learning to Predict Equilibria in Convex Games</title>
      <link>https://arxiv.org/abs/2106.00906</link>
      <description>arXiv:2106.00906v4 Announce Type: replace-cross 
Abstract: Systems of competing agents can often be modeled as games. Assuming rationality, the most likely outcomes are given by an equilibrium (e.g. a Nash equilibrium). In many practical settings, games are influenced by context, i.e. additional data beyond the control of any agent (e.g. weather for traffic and fiscal policy for market economies). Often the exact game mechanics are unknown, yet vast amounts of historical data consisting of (context, equilibrium) pairs are available, raising the possibility of learning a solver which predicts the equilibria given only the context. We introduce Nash Fixed Point Networks (N-FPNs), a class of neural networks that naturally output equilibria. Crucially, N- FPNs employ a constraint decoupling scheme to handle complicated agent action sets while avoiding expensive projections. Empirically, we find N-FPNs are compatible with the recently developed Jacobian-Free Backpropagation technique for training implicit networks, making them significantly faster and easier to train than prior models. Our experiments show N-FPNs are capable of scaling to problems orders of magnitude larger than existing learned game solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.00906v4</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel McKenzie, Howard Heaton, Qiuwei Li, Samy Wu Fung, Stanley Osher, Wotao Yin</dc:creator>
    </item>
    <item>
      <title>Threshold Testing and Semi-Online Prophet Inequalities</title>
      <link>https://arxiv.org/abs/2307.01776</link>
      <description>arXiv:2307.01776v3 Announce Type: replace-cross 
Abstract: We study threshold testing, an elementary probing model with the goal to choose a large value out of $n$ i.i.d. random variables. An algorithm can test each variable $X_i$ once for some threshold $t_i$, and the test returns binary feedback whether $X_i \ge t_i$ or not. Thresholds can be chosen adaptively or non-adaptively by the algorithm. Given the results for the tests of each variable, we then select the variable with highest conditional expectation. We compare the expected value obtained by the testing algorithm with expected maximum of the variables. Threshold testing is a semi-online variant of the gambler's problem and prophet inequalities. Indeed, the optimal performance of non-adaptive algorithms for threshold testing is governed by the standard i.i.d. prophet inequality of approximately $0.745+o(1)$ as $n \to \infty$. We show how adaptive algorithms can significantly improve upon this ratio. Our adaptive testing strategy guarantees a competitive ratio of at least $0.869-o(1)$. Moreover, we show that there are distributions that admit only a constant ratio $c &lt; 1$, even when $n \to \infty$. Finally, when each box can be tested multiple times (with $n$ tests in total), we design an algorithm that achieves a ratio of $1-o(1)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.01776v3</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.ESA.2023.16</arxiv:DOI>
      <dc:creator>Martin Hoefer, Kevin Schewior</dc:creator>
    </item>
  </channel>
</rss>
