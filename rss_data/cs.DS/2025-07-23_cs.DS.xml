<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Jul 2025 04:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimal Pure Differentially Private Sparse Histograms in Near-Linear Deterministic Time</title>
      <link>https://arxiv.org/abs/2507.17017</link>
      <description>arXiv:2507.17017v1 Announce Type: new 
Abstract: We introduce an algorithm that releases a pure differentially private sparse histogram over $n$ participants drawn from a domain of size $d \gg n$. Our method attains the optimal $\ell_\infty$-estimation error and runs in strictly $O(n \ln \ln d)$ time in the word-RAM model, thereby improving upon the previous best known deterministic-time bound of $\tilde{O}(n^2)$ and resolving the open problem of breaking this quadratic barrier (Balcer and Vadhan, 2019). Central to our algorithm is a novel private item blanket technique with target-length padding, which transforms the approximate differentially private stability-based histogram algorithm into a pure differentially private one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17017v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Florian Kerschbaum, Steven Lee, Hao Wu</dc:creator>
    </item>
    <item>
      <title>Compatibility of Max and Sum Objectives for Committee Selection and $k$-Facility Location</title>
      <link>https://arxiv.org/abs/2507.17063</link>
      <description>arXiv:2507.17063v1 Announce Type: new 
Abstract: We study a version of the metric facility location problem (or, equivalently, variants of the committee selection problem) in which we must choose $k$ facilities in an arbitrary metric space to serve some set of clients $C$. We consider four different objectives, where each client $i\in C$ attempts to minimize either the sum or the maximum of its distance to the chosen facilities, and where the overall objective either considers the sum or the maximum of the individual client costs. Rather than optimizing a single objective at a time, we study how compatible these objectives are with each other, and show the existence of solutions which are simultaneously close-to-optimum for any pair of the above objectives. Our results show that when choosing a set of facilities or a representative committee, it is often possible to form a solution which is good for several objectives at the same time, instead of sacrificing one desideratum to achieve another.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17063v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yue Han, Elliot Anshelevich</dc:creator>
    </item>
    <item>
      <title>Advancing Quantum State Preparation using LimTDD</title>
      <link>https://arxiv.org/abs/2507.17170</link>
      <description>arXiv:2507.17170v1 Announce Type: new 
Abstract: Quantum state preparation (QSP) is a fundamental task in quantum computing and quantum information processing. It is critical to the execution of many quantum algorithms, including those in quantum machine learning. In this paper, we propose a family of efficient QSP algorithms tailored to different numbers of available ancilla qubits - ranging from no ancilla qubits, to a single ancilla qubit, to a sufficiently large number of ancilla qubits. Our algorithms are based on a novel decision diagram that is fundamentally different from the approaches used in previous QSP algorithms. Specifically, our approach exploits the power of Local Invertible Map Tensor Decision Diagrams (LimTDDs) - a highly compact representation of quantum states that combines tensor networks and decision diagrams to reduce quantum circuit complexity. Extensive experiments demonstrate that our methods significantly outperform existing approaches and exhibit better scalability for large-scale quantum states, both in terms of runtime and gate complexity. Furthermore, our method shows exponential improvement in best-case scenarios. This paper is an extended version of [1], with three more algorithms proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17170v1</guid>
      <category>cs.DS</category>
      <category>quant-ph</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Hong, Aochu Dai, Chenjian Li, Sanjiang Li, Shenggang Ying, Mingsheng Ying</dc:creator>
    </item>
    <item>
      <title>RLZ-r and LZ-End-r: Enhancing Move-r</title>
      <link>https://arxiv.org/abs/2507.17300</link>
      <description>arXiv:2507.17300v1 Announce Type: new 
Abstract: In pattern matching on strings, a locate query asks for an enumeration of all the occurrences of a given pattern in a given text. The r-index [Gagie et al., 2018] is a recently presented compressed self index that stores the text and auxiliary information in compressed space. With some modifications, locate queries can be answered in optimal time [Nishimoto &amp; Tabei, 2021], which has recently been proven relevant in practice in the form of Move-r [Bertram et al., 2024]. However, there remains the practical bottleneck of evaluating function $\Phi$ for every occurrence to report. This motivates enhancing the index by a compressed representation of the suffix array featuring efficient random access, trading off space for faster answering of locate queries [Puglisi &amp; Zhukova, 2021]. In this work, we build upon this idea considering two suitable compression schemes: Relative Lempel-Ziv [Kuruppu et al., 2010], improving the work by Puglisi and Zhukova, and LZ-End [Kreft &amp; Navarro, 2010], introducing a different trade-off where compression is better than for Relative Lempel-Ziv at the cost of slower access times. We enhance both the r-index and Move-r by the compressed suffix arrays and evaluate locate query performance in an experiment. We show that locate queries can be sped up considerably in both the r-index and Move-r, especially if the queried pattern has many occurrences. The choice between two different compression schemes offers new trade-offs regarding index size versus query performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17300v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Dinklage, Johannes Fischer, Lukas Nalbach, Jan Zumbrink</dc:creator>
    </item>
    <item>
      <title>Residual Prophet Inequalities</title>
      <link>https://arxiv.org/abs/2507.17391</link>
      <description>arXiv:2507.17391v1 Announce Type: new 
Abstract: We introduce a variant of the classic prophet inequality, called \emph{residual prophet inequality} (RPI). In the RPI problem, we consider a finite sequence of $n$ nonnegative independent random values with known distributions, and a known integer $0\leq k\leq n-1$. Before the gambler observes the sequence, the top $k$ values are removed, whereas the remaining $n-k$ values are streamed sequentially to the gambler. For example, one can assume that the top $k$ values have already been allocated to a higher-priority agent. Upon observing a value, the gambler must decide irrevocably whether to accept or reject it, without the possibility of revisiting past values.
  We study two variants of RPI, according to whether the gambler learns online of the identity of the variable that he sees (FI model) or not (NI model). Our main result is a randomized algorithm in the FI model with \emph{competitive ratio} of at least $1/(k+2)$, which we show is tight. Our algorithm is data-driven and requires access only to the $k+1$ largest values of a single sample from the $n$ input distributions. In the NI model, we provide a similar algorithm that guarantees a competitive ratio of $1/(2k+2)$. We further analyze independent and identically distributed instances when $k=1$. We build a single-threshold algorithm with a competitive ratio of at least 0.4901, and show that no single-threshold strategy can get a competitive ratio greater than 0.5464.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17391v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jose Correa, Sebastian Perez-Salazar, Dana Pizarro, Bruno Ziliotto</dc:creator>
    </item>
    <item>
      <title>Fast One-Pass Sparse Approximation of the Top Eigenvectors of Huge Low-Rank Matrices? Yes, $MAM^*$!</title>
      <link>https://arxiv.org/abs/2507.17036</link>
      <description>arXiv:2507.17036v1 Announce Type: cross 
Abstract: Motivated by applications such as sparse PCA, in this paper we present provably-accurate one-pass algorithms for the sparse approximation of the top eigenvectors of extremely massive matrices based on a single compact linear sketch. The resulting compressive-sensing-based approaches can approximate the leading eigenvectors of huge approximately low-rank matrices that are too large to store in memory based on a single pass over its entries while utilizing a total memory footprint on the order of the much smaller desired sparse eigenvector approximations. Finally, the compressive sensing recovery algorithm itself (which takes the gathered compressive matrix measurements as input, and then outputs sparse approximations of its top eigenvectors) can also be formulated to run in a time which principally depends on the size of the sought sparse approximations, making its runtime sublinear in the size of the large matrix whose eigenvectors one aims to approximate. Preliminary experiments on huge matrices having $\sim 10^{16}$ entries illustrate the developed theory and demonstrate the practical potential of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17036v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edem Boahen, Simone Brugiapaglia, Hung-Hsu Chou, Mark Iwen, Felix Krahmer</dc:creator>
    </item>
    <item>
      <title>Triadic First-Order Logic Queries in Temporal Networks</title>
      <link>https://arxiv.org/abs/2507.17215</link>
      <description>arXiv:2507.17215v1 Announce Type: cross 
Abstract: Motif counting is a fundamental problem in network analysis, and there is a rich literature of theoretical and applied algorithms for this problem. Given a large input network $G$, a motif $H$ is a small "pattern" graph indicative of special local structure. Motif/pattern mining involves finding all matches of this pattern in the input $G$. The simplest, yet challenging, case of motif counting is when $H$ has three vertices, often called a "triadic" query. Recent work has focused on "temporal graph mining", where the network $G$ has edges with timestamps (and directions) and $H$ has time constraints.
  Inspired by concepts in logic and database theory, we introduce the study of "thresholded First Order Logic (FOL) Motif Analysis" for massive temporal networks. A typical triadic motif query asks for the existence of three vertices that form a desired temporal pattern. An "FOL" motif query is obtained by having both existential and thresholded universal quantifiers. This allows for query semantics that can mine richer information from networks. A typical triadic query would be "find all triples of vertices $u,v,w$ such that they form a triangle within one hour". A thresholded FOL query can express "find all pairs $u,v$ such that for half of $w$ where $(u,w)$ formed an edge, $(v,w)$ also formed an edge within an hour".
  We design the first algorithm, FOLTY, for mining thresholded FOL triadic queries. The theoretical running time of FOLTY matches the best known running time for temporal triangle counting in sparse graphs. We give an efficient implementation of FOLTY using specialized temporal data structures. FOLTY has excellent empirical behavior, and can answer triadic FOL queries on graphs with nearly 70M edges is less than hour on commodity hardware. Our work has the potential to start a new research direction in the classic well-studied problem of motif analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17215v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Omkar Bhalerao, Yunjie Pan, C. Seshadhri, Nishil Talati</dc:creator>
    </item>
    <item>
      <title>Stable Iterative Solvers for Ill-conditioned Linear Systems</title>
      <link>https://arxiv.org/abs/2507.17673</link>
      <description>arXiv:2507.17673v1 Announce Type: cross 
Abstract: Iterative solvers for large-scale linear systems such as Krylov subspace methods can diverge when the linear system is ill-conditioned, thus significantly reducing the applicability of these iterative methods in practice for high-performance computing solutions of such large-scale linear systems. To address this fundamental problem, we propose general algorithmic frameworks to modify Krylov subspace iterative solution methods which ensure that the algorithms are stable and do not diverge. We then apply our general frameworks to current implementations of the corresponding iterative methods in SciPy and demonstrate the efficacy of our stable iterative approach with respect to numerical experiments across a wide range of synthetic and real-world ill-conditioned linear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17673v1</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vasileios Kalantzis, Mark S. Squillante, Chai Wah Wu</dc:creator>
    </item>
    <item>
      <title>Toward a Lightweight and Robust Design for Caching</title>
      <link>https://arxiv.org/abs/2507.16242</link>
      <description>arXiv:2507.16242v2 Announce Type: replace 
Abstract: The online caching problem aims to minimize cache misses when serving a sequence of requests under a limited cache size. While naive learning-augmented caching algorithms achieve ideal $1$-consistency, they lack robustness guarantees. Existing robustification methods either sacrifice $1$-consistency or introduce significant computational overhead. In this paper, we introduce Guard, a lightweight robustification framework that enhances the robustness of a broad class of learning-augmented caching algorithms to $2H_k + 2$, while preserving their $1$-consistency. Guard achieves the current best-known trade-off between consistency and robustness, with only $O(1)$ additional per-request overhead, thereby maintaining the original time complexity of the base algorithm. Extensive experiments across multiple real-world datasets and prediction models validate the effectiveness of Guard in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16242v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Chen, Hailiang Zhao, Jiaji Zhang, Xueyan Tang, Yixuan Wang, Shuiguang Deng</dc:creator>
    </item>
  </channel>
</rss>
