<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Dec 2025 05:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Solution of Potential-Driven, Steady-State Nonlinear Network Flow Equations via Graph Partitioning</title>
      <link>https://arxiv.org/abs/2512.22124</link>
      <description>arXiv:2512.22124v1 Announce Type: new 
Abstract: The solution of potential-driven steady-state flow in large networks is required in various engineering applications, such as transport of natural gas or water through pipeline networks. The resultant system of nonlinear equations depends on the network topology, and its solution grows more challenging as the network size increases. We present an algorithm that utilizes a given partition of a network into tractable sizes to compute a global solution for the full nonlinear system through local solution of smaller subsystems induced by the partitions. When the partitions are induced by interconnects or transfer points corresponding to networks owned by different operators, the method ensures data is shared solely at the interconnects, leaving network operators free to solve the network flow system corresponding to their own domain in any manner of their choosing. The proposed method is shown to be connected to the Schur complement and the method's viability demonstrated on some challenging test cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22124v1</guid>
      <category>physics.comp-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shriram Srinivasan, Kaarthik Sundar</dc:creator>
    </item>
    <item>
      <title>A Radiation Exchange Factor Transformation with Proven Convergence, Non-Negativity, and Energy Conservation</title>
      <link>https://arxiv.org/abs/2512.22157</link>
      <description>arXiv:2512.22157v1 Announce Type: new 
Abstract: This paper presents a matrix-based exchange factor transformation for solving coupled mixed boundary condition radiative transfer problems on general domains. The method applies to participating media ranging from transparent to absorbing, emitting, and scattering, with boundaries ranging from absorbing to reflecting. Given a first-interaction exchange factor matrix $\mathbf{F}$, the transformation produces an absorption matrix $\mathbf{A}$ and a multiple reflection-scattering matrix $\mathbf{R}$ through a Neumann series that analytically traces all reflection-scattering paths to steady state. The paper establishes rigorous conditions under which the method guarantees convergence, non-negative radiation, and exact energy conservation to machine precision. A comparison with Noble's matrix formulation of Hottel's zonal method reveals a previously unidentified discrepancy in that classical approach; the proposed transformation eliminates this discrepancy. The method is validated against the diffusion approximation in the high-extinction limit and against results of Crosbie and Schrenker for pure and partial scattering cases. The method is applicable to medium-scale general reflecting-scattering problems and scales to large problems when negligible reflection-scattering and high extinction ensure matrix sparsity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22157v1</guid>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikolaj Maack Bielefeld</dc:creator>
    </item>
    <item>
      <title>Integrating Wide and Deep Neural Networks with Squeeze-and-Excitation Blocks for Multi-Target Property Prediction in Additively Manufactured Fiber Reinforced Composites</title>
      <link>https://arxiv.org/abs/2512.22397</link>
      <description>arXiv:2512.22397v1 Announce Type: new 
Abstract: Continuous fiber-reinforced composite manufactured by additive manufacturing (CFRC-AM) offers opportunities for printing lightweight materials with high specific strength. However, their performance is sensitive to the interaction of process and material parameters, making exhaustive experimental testing impractical. In this study, we introduce a data-efficient, multi-input, multi-target learning approach that integrates Latin Hypercube Sampling (LHS)-guided experimentation with a squeeze-and-excitation wide and deep neural network (SE-WDNN) to jointly predict multiple mechanical and manufacturing properties of CFRC-AMs based on different manufacturing parameters. We printed and tested 155 specimens selected from a design space of 4,320 combinations using a Markforged Mark Two 3D printer. The processed data formed the input-output set for our proposed model. We compared the results with those from commonly used machine learning models, including feedforward neural networks, Kolmogorov-Arnold networks, XGBoost, CatBoost, and random forests. Our model achieved the lowest overall test error (MAPE = 12.33%) and showed statistically significant improvements over the baseline wide and deep neural network for several target variables (paired t-tests, p &lt;= 0.05). SHapley Additive exPlanations (SHAP) analysis revealed that reinforcement strategy was the major influence on mechanical performance. Overall, this study demonstrates that the integration of LHS and SE-WDNN enables interpretable and sample-efficient multi-target predictions, guiding parameter selection in CFRC-AM with a balance between mechanical behavior and manufacturing metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22397v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Behzad Parvaresh, Rahmat K. Adesunkanmi, Adel Alaeddini</dc:creator>
    </item>
    <item>
      <title>A survey of interlayer interaction models for graphene and other 2D materials</title>
      <link>https://arxiv.org/abs/2512.22670</link>
      <description>arXiv:2512.22670v1 Announce Type: new 
Abstract: This work presents a survey of mechanical models describing van der Waals interactions between 2D materials, encompassing both continuous elastomer-like materials and discrete (crystalline) 2D materials such as graphene. These interactions give rise to a range of physical phenomena, including contact instabilities, Moir\'e patterns, surface reconstructions, and superlubricity. The underlying contact forces follow from the variation of an interfacial interaction potential. The presentation first discusses normal contact models, and then tangential contact models. Both atomistic and continuum approaches are considered. In addition, the influence of external loading and changes in length scale on the ground state configuration and frictional contact behavior are analyzed. A particular emphasis is placed on discussing strategies that reduce computational cost in multiscale modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22670v1</guid>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gourav Yadav (Department of Mechanical Engineering, Indian Institute of Technology Kanpur, UP 208016, India), Shakti S. Gupta (Department of Mechanical Engineering, Indian Institute of Technology Kanpur, UP 208016, India), Roger A. Sauer (Institute for Structural Mechanics, Ruhr University Bochum, 44801 Bochum, Germany)</dc:creator>
    </item>
    <item>
      <title>Overcoming Computational Bottlenecks in Quantum Hydrodynamics: A Volume-Based Integral Formalism</title>
      <link>https://arxiv.org/abs/2512.22920</link>
      <description>arXiv:2512.22920v1 Announce Type: new 
Abstract: Mesoscopic models of the optical response of metals have emerged as fundamental building blocks in quantum plasmonics, in principle overcoming the computational bottlenecks of ab initio techniques by implementing aspects of the atomistic description of the metal in otherwise classical calculations. Nonetheless, even these approaches are eventually hindered by demanding computations due to sophisticated material response. Here, this issue is addressed for the advanced Self-Consistent Hydrodynamic Drude Model (SC-HDM), which captures both nonlocal electron dynamics and electron spill-out, through a Volume Integral Equation (VIE) method. Adopting an IE-based method shifts perspective from the commonly employed Differential Equation (DE)-based ones, demonstrating significant computational efficiency. The VIE approach is a valuable methodological scaffold: It addresses SC-HDM and simpler models, but can also be adapted to more advanced ones. For spherical nanoparticles (NPs), using the inherent symmetries, similar performance for three increasingly complicated material models is achieved, breaking the taboo that increased sophistication in material response requires taxing simulations. Mesoscopic material-response functions can be readily extracted from the VIE implementation, thus circumventing the need for lengthy microscopic calculations. This method opens a new way of modeling quantum hydrodynamic NPs and will serve as essential benchmarking tool for recipes addressing more complicated geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22920v1</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.mes-hall</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christos Mystilidis, Christos Tserkezis, Guy A. E. Vandenbosch, N. Asger Mortensen, Xuezhi Zheng</dc:creator>
    </item>
    <item>
      <title>Masgent: An AI-assisted Materials Simulation Agent</title>
      <link>https://arxiv.org/abs/2512.23010</link>
      <description>arXiv:2512.23010v1 Announce Type: new 
Abstract: Density functional theory (DFT) and machine learning potentials (MLPs) are essential for predicting and understanding materials properties, yet preparing, executing, and analyzing these simulations typically requires extensive scripting, multi-step procedures, and significant high-performance computing (HPC) expertise. These challenges hinder reproducibility and slow down discovery. Here, we introduce Masgent, an AI-assisted materials simulation agent that unifies structure manipulation, automated VASP input generation, DFT workflow construction and analysis, fast MLP-based simulations, and lightweight machine learning (ML) utilities within a single platform. Powered by large language models (LLMs), Masgent enables researchers to perform complex simulation tasks through natural-language interaction, eliminating most manual scripting and reducing setup time from hours to seconds. By standardizing protocols and integrating advanced simulation and data-driven tools, Masgent democratizes access to state-of-the-art computational methodologies, accelerating hypothesis testing, pre-screening, and exploratory research for both new and experienced practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23010v1</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanghen Liu, Songge Yang, Yu Zhong</dc:creator>
    </item>
    <item>
      <title>Reconstructing Relativistic Magnetohydrodynamics with Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2512.23057</link>
      <description>arXiv:2512.23057v1 Announce Type: new 
Abstract: We construct the first physics-informed neural-network (PINN) surrogates for relativistic magnetohydrodynamics (RMHD) using a hybrid PDE and data-driven workflow. Instead of training for the conservative form of the equations, we work with Jacobians or PDE characteristics directly in terms of primitive variables. We further add to the trainable system the divergence-free condition, without the need of cleaning modes. Using a novel MUON optimizer implementation, we show that a baseline PINN trained on early-time snapshots can extrapolate RMHD dynamics in one and two spatial dimensions, and that posterior residual-guided networks can systematically reduce PDE violations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23057v1</guid>
      <category>physics.comp-ph</category>
      <category>astro-ph.HE</category>
      <category>gr-qc</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Corwin Cheung, Marcos Johnson-Noya, Michael Xiang, Dominic Chang, Alfredo Guevara</dc:creator>
    </item>
    <item>
      <title>Exponential divided differences via Chebyshev polynomials</title>
      <link>https://arxiv.org/abs/2512.23061</link>
      <description>arXiv:2512.23061v1 Announce Type: new 
Abstract: Exponential divided differences arise in numerical linear algebra, matrix-function evaluation, and quantum Monte Carlo simulations, where they serve as kernel weights for time evolution and observable estimation. Efficient and numerically stable evaluation of high-order exponential divided differences for dynamically evolving node sets remains a significant computational challenge. We present a Chebyshev-polynomial-based algorithm that addresses this problem by combining the Chebyshev-Bessel expansion of the exponential function with a direct recurrence for Chebyshev divided differences. The method achieves a computational cost of ${\cal O}(qN)$, where $q$ is the divided-difference order and $N$ is the Chebyshev truncation length. We show that $N$ scales linearly with the spectral width through the decay of modified Bessel coefficients, while the dependence on $q$ enters only through structural polynomial constraints. We further develop an incremental update scheme for dynamic node sets that enables the insertion or removal of a single node in ${\cal O}(N)$ time when the affine mapping interval is held fixed. A full \texttt{C++} reference implementation of the algorithms described in this work is publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23061v1</guid>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Itay Hen</dc:creator>
    </item>
    <item>
      <title>A space-time extension of a conservative two-fluid cut-cell diffusion method for moving geometries</title>
      <link>https://arxiv.org/abs/2512.23358</link>
      <description>arXiv:2512.23358v1 Announce Type: new 
Abstract: We present a space-time extension of a conservative Cartesian cut-cell finite-volume method for two-phase diffusion in prescribed-motion geometries. The formulation follows a two-fluid approach: one scalar field is solved in each phase with discontinuous material properties, coupled by sharp interface conditions enforcing flux continuity and jump laws. To handle moving boundaries on a fixed Cartesian grid, the discrete balance is written over phase-restricted space-time control volumes, whose geometric moments (swept volumes and apertures) are used as weights in the finite-volume operators. This construction naturally accounts for the creation and destruction of cut cells (fresh/dead-cell events) and yields strict discrete conservation. The resulting scheme retains the algebraic structure of the static cut-cell formulation while incorporating motion through local geometric weights and interface coupling operators. A series of verification and validation tests in two and three dimensions demonstrate super-linear accuracy in space, robust behavior under repeated topology changes and conservation across strong coefficient jumps and moving interfaces. The proposed space-time cut-cell framework provides a conservative building block for multiphase transport in evolving geometries and a foundation for future free-boundary extensions such as Stefan-type phase change.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23358v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Louis Libat, Can Sel\c{c}uk, Eric Ch\'enier, Vincent Le Chenadec</dc:creator>
    </item>
    <item>
      <title>PINNs for Electromagnetic Wave Propagation</title>
      <link>https://arxiv.org/abs/2512.23396</link>
      <description>arXiv:2512.23396v1 Announce Type: new 
Abstract: Physics-Informed Neural Networks (PINNs) are a methodology that aims to solve physical systems by directly embedding PDE constraints into the neural network training process. In electromagnetism, where well-established methodologies such as FDTD and FEM already exist, new methodologies are expected to provide clear advantages to be accepted. Despite their mesh-free nature and applicability to inverse problems, PINNs can exhibit deficiencies in terms of accuracy and energy metrics when compared to FDTD solutions. This study demonstrates hybrid training strategies can bring PINNs closer to FDTD-level accuracy and energy consistency.
  This study presents a hybrid methodology addressing common challenges in wave propagation scenarios. The causality collapse problem in time-dependent PINN training is addressed via time marching and causality-aware weighting. In order to mitigate the discontinuities that are introduced by time marching, a two-stage interface continuity loss is applied. In order to suppress loss accumulation, which is manifested as cumulative energy drift in electromagnetic waves, a local Poynting-based regularizer has been developed.
  In the developed PINN model, high field accuracy is achieved with an average 0.09\% $NRMSE$ and 1.01\% $L^2$ error over time. Energy conservation is achieved on the PINN side with only a 0.024\% relative energy mismatch in the 2D PEC cavity scenario. Training is performed without labeled field data, using only physics-based residual losses; FDTD is used solely for post-training evaluation. The results demonstrate that PINNs can achieve competitive results with FDTD in canonical electromagnetic examples and are a viable alternative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23396v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.AI</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nilufer K. Bulut</dc:creator>
    </item>
    <item>
      <title>MultiAtomLiouvilleEquationGenerator: A Mathematica package for Liouville superoperators and master equations of multilevel atomic systems</title>
      <link>https://arxiv.org/abs/2512.23591</link>
      <description>arXiv:2512.23591v1 Announce Type: new 
Abstract: MulAtoLEG (Multi-Atom Liouville Equation Generator) is an open-source Mathematica package for generating Liouville superoperators and Liouville equations, specialized for multilevel atomic systems comprising an arbitrary number of atoms. This scheme is based on an extension to multilevel atomic systems, originally developed by Lehmberg [R. H. Lehmberg, Phys. Rev. A 2, 883 (1970)] as an adjoint master equation for ensembles of two-level emitters and later reformulated by Genes [M. Reitz, C. Sommer and C. Genes, PRX Quantum 3, 010201 (2022)] as a master equation. The package facilitates the generation of equations for complex transition configurations in alkali atoms. Although primarily designed for atomic systems, it can also generate the master and adjoint master equations for general Hamiltonians and Lindbladians. In addition, it includes functionalities to construct the differential equations in the dressed-state basis, where, in many cases, the non-unitary evolution operator can be determined explicitly. To maximize computational efficiency, the package leverages Mathematica's vectorization and sparse linear algebra capabilities. Since MulAtoLEG produces exact equations without approximations, the feasible system size is naturally limited by the available computational resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23591v1</guid>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pablo Yanes-Thomas, Roc\'io J\'auregui-Renaud Santiago F. Caballero-Ben\'itez, Daniel Sahag\'un S\'anchez, Alejandro Kunold</dc:creator>
    </item>
    <item>
      <title>A front-tracking study of retinal detachment treatment by magnetic drop targeting</title>
      <link>https://arxiv.org/abs/2512.22537</link>
      <description>arXiv:2512.22537v1 Announce Type: cross 
Abstract: We investigate the Ferrofluid Drop Targeting (FDT) for the treatment of the Retinal Detachment (RD), considering, for the first time, the real 3D geometry of an eye and magnets configurations as well as the viscoelastic rheology of the medium, i.e., the Vitreous Humor (VH). A Front-Tracking Method (FTM) is extended to handle a general 3D unstructured Eulerian grid and strong wall effects. The challenges include the accuracy and robustness of the solver when the drop spreads on the retina under the effect of a magnetic field, which necessitates the design of a multi-region Eulerian grid and defining a threshold distance between the front and wall, along with the choice of an effective front smoothing and volume correction FTM sub-algorithms near the walls. After model validations, the effect of different design parameters on important objectives, such as the travel time, settling time, retinal coverage area, and impact compressive stress, are studied. The results reveal that, in addition to the magnetic Bond number, the ratio of the drop-to-VH magnetic permeabilities plays a key role in the terminal shape parameters, like the retinal coverage. Additionally, simultaneously increasing these two parameters, significantly increase the total FDT force, coverage area, and stress concentration, while decreasing the drop-VH surface tension can mitigate the stress concentration on the retina.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22537v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ijmultiphaseflow.2025.105410</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Multiphase Flow, Volume 193, December 2025, 105410</arxiv:journal_reference>
      <dc:creator>Mohammad Amin Amini, Gretar Tryggvason, Ehsan Amani</dc:creator>
    </item>
    <item>
      <title>Volume and Surface Area of two Orthogonal, Partially Intersecting Cylinders: A Generalization of the Steinmetz Solid</title>
      <link>https://arxiv.org/abs/2512.22555</link>
      <description>arXiv:2512.22555v1 Announce Type: cross 
Abstract: The intersection of two orthogonal cylinders represents a classical problem in computational geometry with direct applications to engineering design, manufacturing, and numerical simulation. While analytical solutions exist for the fully intersecting case, the Steinmetz solid, partial intersections with arbitrary depth ratios require numerical methods or approximations. This work presents general integral expressions for both the intersection volume and surface area as explicit functions of the intersection depth. Accompanying these exact formulations are empirical approximation functions, which provide closed-form evaluations with relative errors below 15% across the full range of intersection depth. Validation against Quasi-Monte Carlo simulation confirms the accuracy of both the analytical and approximate solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22555v1</guid>
      <category>cs.CE</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fynn Jerome Aschmoneit, Bastiaan Cockx</dc:creator>
    </item>
    <item>
      <title>Variational quantum eigensolver for chemical molecules</title>
      <link>https://arxiv.org/abs/2512.22572</link>
      <description>arXiv:2512.22572v1 Announce Type: cross 
Abstract: Solving interacting multi-particle systems is a central challenge in quantum chemistry and condensed matter physics. In this work, we investigate the computation of ground states and ground-state energies for the He-H+ and H2O molecules using quantum computing techniques. We employ the variational quantum eigensolver (VQE), implemented both on a quantum computer simulator and on an IBM quantum device. The resulting energies are benchmarked against exact ground-state energies obtained via classical methods. Simulations of the H2O molecule were performed on Nottingham's High Performance Computing (HPC) facilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22572v1</guid>
      <category>quant-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Ion, Adam Smith</dc:creator>
    </item>
    <item>
      <title>amangkurat: A Python Library for Symplectic Pseudo-Spectral Solution of the Idealized (1+1)D Nonlinear Klein-Gordon Equation</title>
      <link>https://arxiv.org/abs/2512.22635</link>
      <description>arXiv:2512.22635v1 Announce Type: cross 
Abstract: This study introduces amangkurat, an open-source Python library designed for the robust numerical simulation of relativistic scalar field dynamics governed by the nonlinear Klein-Gordon equation in $(1+1)$D spacetime. The software implements a hybrid computational strategy that couples Fourier pseudo-spectral spatial discretization with a symplectic St\o rmer-Verlet temporal integrator, ensuring both exponential spatial convergence for smooth solutions and long-term preservation of Hamiltonian structure. To optimize performance, the solver incorporates adaptive timestepping based on Courant-Friedrichs-Lewy (CFL) stability criteria and utilizes Just-In-Time (JIT) compilation for parallelized force computation. The library's capabilities are validated across four canonical physical regimes: dispersive linear wave propagation, static topological kink preservation in phi-fourth theory, integrable breather dynamics in the sine-Gordon model, and non-integrable kink-antikink collisions. Beyond standard numerical validation, this work establishes a multi-faceted analysis framework employing information-theoretic entropy metrics (Shannon, R\'{e}nyi, and Tsallis), kernel density estimation, and phase space reconstruction to quantify the distinct phenomenological signatures of these regimes. Statistical hypothesis testing confirms that these scenarios represent statistically distinguishable dynamical populations. Benchmarks on standard workstation hardware demonstrate that the implementation achieves high computational efficiency, making it a viable platform for exploratory research and education in nonlinear field theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22635v1</guid>
      <category>nlin.PS</category>
      <category>hep-th</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandy H. S. Herho, Siti N. Kaban</dc:creator>
    </item>
    <item>
      <title>On the Reynolds-number scaling of Poisson solver complexity</title>
      <link>https://arxiv.org/abs/2512.22644</link>
      <description>arXiv:2512.22644v1 Announce Type: cross 
Abstract: We aim to answer the following question: is the complexity of numerically solving the Poisson equation increasing or decreasing for very large simulations of incompressible flows? Physical and numerical arguments are combined to derive power-law scalings at very high Reynolds numbers. A theoretical convergence analysis for both Jacobi and multigrid solvers defines a two-dimensional phase space divided into two regions depending on whether the number of solver iterations tends to decrease or increase with the Reynolds number. Numerical results indicate that, for Navier-Stokes turbulence, the complexity decreases with increasing Reynolds number, whereas for the one-dimensional Burgers equation it follows the opposite trend. The proposed theoretical framework thus provides a unified perspective on how solver convergence scales with the Reynolds number and offers valuable guidance for the development of next-generation preconditioning and multigrid strategies for extreme-scale simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22644v1</guid>
      <category>physics.flu-dyn</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>F. Xavier Trias, \`Adel Alsalti-Baldellou, Assensi Oliva</dc:creator>
    </item>
    <item>
      <title>A rational length scale for large-eddy simulation of turbulence on anisotropic grids</title>
      <link>https://arxiv.org/abs/2512.22717</link>
      <description>arXiv:2512.22717v1 Announce Type: cross 
Abstract: Due to the prohibitive cost of resolving all relevant scales, direct numerical simulations of turbulence remain unfeasible for most real-world applications. Consequently, dynamically simplified formulations are needed for coarse-grained simulations. In this regard, eddy-viscosity models for Large-Eddy Simulation (LES) are widely used both in academia and industry. These models require a subgrid characteristic length, typically linked to the local grid size. While this length scale corresponds to the mesh step for isotropic grids, its definition for unstructured or anisotropic Cartesian meshes, such as the pancake-like meshes commonly used to capture near-wall turbulence or shear layers, remains an open question. Despite its significant influence on LES model performance, no consensus has been reached on its proper formulation. In this work, we introduce a novel subgrid characteristic length. This length scale is derived from the analysis of the entanglement between the numerical discretization and the filtering in LES. Its mathematical properties and simplicity make it a robust choice for reducing the impact of mesh anisotropies on simulation accuracy. The effectiveness of the proposed subgrid length is demonstrated through simulations of decaying isotropic turbulence and a turbulent channel flow using different codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22717v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1063/5.0277423</arxiv:DOI>
      <arxiv:journal_reference>Physics of Fluids, 37(8):085239, 2025</arxiv:journal_reference>
      <dc:creator>F. Xavier Trias, Jes\'us Ruano, Alexey Duben, Andrey Gorobets</dc:creator>
    </item>
    <item>
      <title>Active-Absorbing Phase Transitions in the Parallel Minority Game</title>
      <link>https://arxiv.org/abs/2512.22826</link>
      <description>arXiv:2512.22826v1 Announce Type: cross 
Abstract: The Parallel Minority Game (PMG) is a synchronous adaptive multi-agent model that exhibits active-absorbing transitions characteristic of non-equilibrium statistical systems. We perform a comprehensive numerical study of the PMG under two families of microscopic decision rules: (i) agents update their choices based on instantaneous population in their alternative choices, and (ii) threshold-based activation that activates agents movement only after overcrowding density crossing a threshold. We measure time-dependent and steady state limits of activity $A(t)$, overcrowding fraction $F(t)$ as functions of the control parameter $g=N/D$, where $N$ is the number of agents and $D$ is the total number of sites. Instantaneous rules display mean-field directed-percolation (MF-DP) scaling with $\beta\approx1.00$, $\delta\approx0.5$, and $\nu_{\parallel}\approx2.0$. Threshold rules, however, produce a distinct non-mean-field universality class with $\beta\approx0.75$ and a systematic failure of MF-DP dynamical scaling. We show that thresholding acts as a relevant perturbation to DP. The results highlight how minimal cognitive features at the agent level fundamentally alter large-scale critical behaviour in socio-economic and active systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22826v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>physics.comp-ph</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aryan Tyagi, Soumyajyoti Biswas, Anirban Chakraborti</dc:creator>
    </item>
    <item>
      <title>An efficient eigenvalue bounding method: CFL condition revisited</title>
      <link>https://arxiv.org/abs/2512.22994</link>
      <description>arXiv:2512.22994v1 Announce Type: cross 
Abstract: Direct and large-eddy simulations of turbulence are often solved using explicit temporal schemes. However, this imposes very small time-steps because the eigenvalues of the (linearized) dynamical system, re-scaled by the time-step, must lie inside the stability region. In practice, fast and accurate estimations of the spectral radii of both the discrete convective and diffusive terms are therefore needed. This is virtually always done using the so-called CFL condition. On the other hand, the large heterogeneity and complexity of modern supercomputing systems are nowadays hindering the efficient cross-platform portability of CFD codes. In this regard, our leitmotiv reads: relying on a minimal set of (algebraic) kernels is crucial for code portability and maintenance! In this context, this work focuses on the computation of eigenbounds for the above-mentioned convective and diffusive matrices which are needed to determine the time-step \`a la CFL. To do so, a new inexpensive method, that does not require to re-construct these time-dependent matrices, is proposed and tested. It just relies on a sparse-matrix vector product where only vectors change on time. Hence, both implementation in existing codes and cross-platform portability are straightforward. The effectiveness and robustness of the method are demonstrated for different test cases on both structured Cartesian and unstructured meshes. Finally, the method is combined with a self-adaptive temporal scheme, leading to significantly larger time-steps compared with other more conventional CFL-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22994v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cpc.2024.109351</arxiv:DOI>
      <arxiv:journal_reference>Computer Physics Communications, 305:109351, 2024</arxiv:journal_reference>
      <dc:creator>F. Xavier Trias, Xavier \'Alvarez-Farr\'e, \`Adel Alsalti-Baldellou, Andrey Gorobets, Assensi Oliva</dc:creator>
    </item>
    <item>
      <title>PI-MFM: Physics-informed multimodal foundation model for solving partial differential equations</title>
      <link>https://arxiv.org/abs/2512.23056</link>
      <description>arXiv:2512.23056v1 Announce Type: cross 
Abstract: Partial differential equations (PDEs) govern a wide range of physical systems, and recent multimodal foundation models have shown promise for learning PDE solution operators across diverse equation families. However, existing multi-operator learning approaches are data-hungry and neglect physics during training. Here, we propose a physics-informed multimodal foundation model (PI-MFM) framework that directly enforces governing equations during pretraining and adaptation. PI-MFM takes symbolic representations of PDEs as the input, and automatically assembles PDE residual losses from the input expression via a vectorized derivative computation. These designs enable any PDE-encoding multimodal foundation model to be trained or adapted with unified physics-informed objectives across equation families. On a benchmark of 13 parametric one-dimensional time-dependent PDE families, PI-MFM consistently outperforms purely data-driven counterparts, especially with sparse labeled spatiotemporal points, partially observed time domains, or few labeled function pairs. Physics losses further improve robustness against noise, and simple strategies such as resampling collocation points substantially improve accuracy. We also analyze the accuracy, precision, and computational cost of automatic differentiation and finite differences for derivative computation within PI-MFM. Finally, we demonstrate zero-shot physics-informed fine-tuning to unseen PDE families: starting from a physics-informed pretrained model, adapting using only PDE residuals and initial/boundary conditions, without any labeled solution data, rapidly reduces test errors to around 1% and clearly outperforms physics-only training from scratch. These results show that PI-MFM provides a practical and scalable path toward data-efficient, transferable PDE solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23056v1</guid>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Min Zhu, Jingmin Sun, Zecheng Zhang, Hayden Schaeffer, Lu Lu</dc:creator>
    </item>
    <item>
      <title>The Open Polymers 2026 (OPoly26) Dataset and Evaluations</title>
      <link>https://arxiv.org/abs/2512.23117</link>
      <description>arXiv:2512.23117v1 Announce Type: cross 
Abstract: Polymers-macromolecular systems composed of repeating chemical units-constitute the molecular foundation of living organisms, while their synthetic counterparts drive transformative advances across medicine, consumer products, and energy technologies. While machine learning (ML) models have been trained on millions of quantum chemical atomistic simulations for materials and/or small molecular structures to enable efficient, accurate, and transferable predictions of chemical properties, polymers have largely not been included in prior datasets due to the computational expense of high quality electronic structure calculations on representative polymeric structures. Here, we address this shortcoming with the creation of the Open Polymers 2026 (OPoly26) dataset, which contains more than 6.57 million density functional theory (DFT) calculations on up to 360 atom clusters derived from polymeric systems, comprising over 1.2 billion total atoms. OPoly26 captures the chemical diversity that makes polymers intrinsically tunable and versatile materials, encompassing variations in monomer composition, degree of polymerization, chain architectures, and solvation environments. We show that augmenting ML model training with the OPoly26 dataset improves model performance for polymer prediction tasks. We also publicly release the OPoly26 dataset to help further the development of ML models for polymers, and more broadly, strive towards universal atomistic models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23117v1</guid>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel S. Levine, Nicholas Liesen, Lauren Chua, James Diffenderfer, Helgi Ingolfsson, Matthew P. Kroonblawd, Nitesh Kumar, Amitesh Maiti, Supun S. Mohottalalage, Muhammed Shuaibi, Brian Van Essen, Brandon M. Wood, C. Lawrence Zitnick, Samuel M. Blau, Evan R. Antoniuk</dc:creator>
    </item>
    <item>
      <title>Anisotropic Photostriction and Strain-modulated Carrier Lifetimes in Orthorhombic Semiconductors</title>
      <link>https://arxiv.org/abs/2512.23187</link>
      <description>arXiv:2512.23187v1 Announce Type: cross 
Abstract: We demonstrate anisotropic photostriction in two-dimensional orthorhombic semiconductors using time-dependent density functional theory. By tracing the dynamics of photoexcited carriers, we establish a quantitative link between carrier density and lattice deformation in layered black phosphorus and germanium selenides. The structural response exhibits significant anisotropy, featuring lattice expansion along the armchair direction and contraction along the zigzag direction, which is attributed to the interplay between charge redistribution and intrinsic lattice anisotropy. Both the magnitude and orientation of the photostrictive strains can be tuned by photodoping densities, enabling precise control over the photoinduced response. Notably, the photoinduced strains significantly increase carrier recombination lifetimes by suppressing nonradiative recombination, primarily due to the enlarged bandgap and weakened nonadiabatic coupling. These results provide microscopic insight into the origin of anisotropic photostriction in low-dimensional systems and lay the groundwork for light-controllable, directionally sensitive optomechanical devices at the atomic scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23187v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianxin Yu, Kun Yang, Jiawen Li, Sheng Meng, Xinghua Shi, Jin Zhang</dc:creator>
    </item>
    <item>
      <title>Spectral Analysis of Hard-Constraint PINNs: The Spatial Modulation Mechanism of Boundary Functions</title>
      <link>https://arxiv.org/abs/2512.23295</link>
      <description>arXiv:2512.23295v1 Announce Type: cross 
Abstract: Physics-Informed Neural Networks with hard constraints (HC-PINNs) are increasingly favored for their ability to strictly enforce boundary conditions via a trial function ansatz $\tilde{u} = A + B \cdot N$, yet the theoretical mechanisms governing their training dynamics have remained unexplored.
  Unlike soft-constrained formulations where boundary terms act as additive penalties, this work reveals that the boundary function $B$ introduces a multiplicative spatial modulation that fundamentally alters the learning landscape.
  A rigorous Neural Tangent Kernel (NTK) framework for HC-PINNs is established, deriving the explicit kernel composition law.
  This relationship demonstrates that the boundary function $B(\vec{x})$ functions as a spectral filter, reshaping the eigenspectrum of the neural network's native kernel.
  Through spectral analysis, the effective rank of the residual kernel is identified as a deterministic predictor of training convergence, superior to classical condition numbers.
  It is shown that widely used boundary functions can inadvertently induce spectral collapse, leading to optimization stagnation despite exact boundary satisfaction.
  Validated across multi-dimensional benchmarks, this framework transforms the design of boundary functions from a heuristic choice into a principled spectral optimization problem, providing a solid theoretical foundation for geometric hard constraints in scientific machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23295v1</guid>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen Xie, Honghang Chi, Haopeng Quan, Yahui Wang, Wei Wang, Yu Ma</dc:creator>
    </item>
    <item>
      <title>Phase-field modeling of multicomponent vesicles in viscoelastic fluid</title>
      <link>https://arxiv.org/abs/2512.23315</link>
      <description>arXiv:2512.23315v1 Announce Type: cross 
Abstract: Multicomponent vesicles suspended in viscoelastic fluids are crucial for understanding a variety of physiological processes. In this work, we develop a continuum surface force (CSF) phase-field model to investigate the hydrodynamics of inextensible multicomponent vesicles in viscoelastic fluid flows with inertial forces. Our model couples a fluid field comprising both Newtonian and Oldroyd-B fluids, a surface concentration field representing the multicomponent distribution on the vesicle membrane, and a phase-field variable governing the membrane evolution. The viscoelasticity effect of extra stress is well incorporated into the full Navier-Stokes equations in the fluid field. The surface concentration field is determined by Cahn-Hilliard equations, while the membrane evolution is governed by a nonlinear advection-diffusion equation. The membrane is coupled to the surrounding fluid through the continuum surface force (CSF) framework. To ensure stable numerical solutions of the highly nonlinear multi-field model, we employ a residual-based variational multiscale (RBVMS) method for the Navier-Stokes equations, a Streamline-Upwind Petrov-Galerkin (SUPG) method for the Oldroyd-B equations, and a standard Galerkin finite element framework for the remaining equations. The system of PDEs is solved using an implicit, monolithic scheme based on the generalized-$\alpha$ time integration method. To enhance spatial accuracy, we employ isogeometric analysis (IGA). We present a series of two-dimensional numerical examples in shear and Poiseuille flows to elucidate the influence of membrane composition and fluid viscoelasticity on the hydrodynamics of multicomponent vesicles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23315v1</guid>
      <category>physics.flu-dyn</category>
      <category>cond-mat.soft</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zuowei Wen, Navid Valizadeh, Timon Rabczuk, Xiaoying Zhuang</dc:creator>
    </item>
    <item>
      <title>Ab initio recombination in the expanding ultracold plasmas</title>
      <link>https://arxiv.org/abs/2512.23433</link>
      <description>arXiv:2512.23433v1 Announce Type: cross 
Abstract: The efficiency of recombination is of crucial importance for the existence of ultracold plasmas, particularly, the ones formed in the magneto-optical traps. Unfortunately, a straightforward simulation of the recombination encounters the problem of huge difference in the spatial and temporal scales for free and bound motion of the electrons. As a result, only the "virtual" electron-ion pairs are usually reproduced in such simulations, and it is necessary to employ some additional criteria to identify them with the recombined atoms (this might be a minimal number of revolutions of the electron about the nearest ion or a maximal distance between them). It is the aim of this paper to present the first successful ab initio simulation of the recombination without any auxiliary assumptions. We employed a special algorithm, which was based on: (i) using the "scalable" reference frame, co-moving with the expanding plasma, (ii) dynamical choice of the number of "mirror" cells, taking into account in calculation of the Coulomb sums, and (iii) accurate treatment of the singular interparticle interactions, without any truncation or "softening" of the Coulomb forces. Then, the recombination events are identified by a series of sharp equidistant peaks in the kinetic and/or potential energies for a sample of particles, which are caused by the captured electrons passing near the pericenters of their orbits; and this is confirmed by a detailed inspection of the particle trajectories. Thereby, we were able to trace formation of the real - rather than "virtual" - electron-ion pairs. The total efficiency of recombination for the realistic experimental conditions was found to be about 20%, which is in perfect agreement both with the laboratory measurements and with the earlier semi-empirical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23433v1</guid>
      <category>physics.plasm-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yurii V. Dumin, Ludmila M. Svirskaya</dc:creator>
    </item>
    <item>
      <title>The Fundamental Lemma of Altermagnetism: Emergence of Alterferrimagnetism</title>
      <link>https://arxiv.org/abs/2512.23589</link>
      <description>arXiv:2512.23589v1 Announce Type: cross 
Abstract: Recent years have seen a proliferation in investigations on Altermagnetism due to its exciting prospects both from an applications perspective and theoretical standpoint. Traditionally, altermagnets are distinguished from collinear antiferromagnets using the central concept of halving subgroups within the spin space group formalism. In this work, we propose the Fundamental Lemma of Altermagnetism (FLAM) deriving the exact conditions required for the existence of altermagnetic phase in a magnetic material on the basis of site-symmetry groups and halving subgroups for a given crystallographic space group. The spin group formalism further clubs ferrimagnetism with ferromagnetism since the same-spin and opposite-spin sublattices lose their meaning in the presence of multiple magnetic species. As a consequence of FLAM, we further propose a class of fully compensated ferrimagnets, termed as Alterferrimagnets (AFiMs), which can show alternating momentum-dependent spin-polarized non-relativistic electronic bands within the first Brillouin zone. We show that alterferrimagnetism is a generalization of traditional collinear altermagnetism where multiple magnetic species are allowed to coexist forming fully compensated magnetic-sublattices, each with individual up-spin and down-spin sublattices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23589v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cond-mat.str-el</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chanchal K. Barman, Bishal Das, Alessio Filippetti, Aftab Alam, Fabio Bernardini</dc:creator>
    </item>
    <item>
      <title>Notes on Quantum Computing for Thermal Science</title>
      <link>https://arxiv.org/abs/2503.19109</link>
      <description>arXiv:2503.19109v4 Announce Type: replace 
Abstract: This document explores the potential of quantum computing in Thermal Science. Conceived as a living document, it will be continuously updated with experimental findings and insights for the research community in Thermal Science. By experiments, we refer both to the search for the most effective algorithms and to the performance of real quantum hardware. Those are fields that are evolving rapidly, driving a technological race to define the best architectures. The development of novel algorithms for engineering problems aims at harnessing the unique strengths of quantum computing. Expectations are high, as users seek concrete evidence of quantum supremacy - a true game changer for engineering applications. Among all heat transfer mechanisms (conduction, convection, radiation), we start with conduction as a paradigmatic test case in the field being characterized by a rich mathematical foundation for our investigations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19109v4</guid>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pietro Asinari, Nada Alghamdi, Paolo De Angelis, Giulio Barletta, Giovanni Trezza, Marina Provenzano, Matteo Maria Piredda, Matteo Fasano, Eliodoro Chiavazzo</dc:creator>
    </item>
    <item>
      <title>Unifying same- and different-material particle charging through stochastic scaling</title>
      <link>https://arxiv.org/abs/2505.23775</link>
      <description>arXiv:2505.23775v3 Announce Type: replace 
Abstract: Triboelectric charging of insulating particles through contact is critical in diverse physical and engineering processes, from dust storms and volcanic eruptions to industrial powder handling. However, many experiments over the years have consistently revealed counterintuitive charging patterns, including variable impact charge under identical conditions, charge sign reversal with repeated impacts, and bipolar charging of differently sized particles. Existing computational models cannot predict these patterns; they either rely on oversimplified heuristics or require inaccessible detailed surface properties. We present a stochastic scaling model (SSM) for particle charging that unifies same-material (particle-particle) and different-material (particle-wall) charging in a single theoretical framework. The model grounds in a physics-based stochastic closure by the mean, variance, skewness, and minimum impact charge measured in a highly-controlled reference experiment. To test the SSM, we implemented it in an open-source Lagrangian-Eulerian CFD solver. When simulating 300 000 insulating particles transported by turbulent wall-bounded flows, the SSM takes less than 0.01% of the CPU time. By scaling the statistical parameters of the reference impact to each collision, the new model reproduces the complex charging patterns observed in experiments without requiring surface-level first-principles inputs. The SSM offers a physically grounded route to large-scale simulations of electrostatic effects across many fields of particle-laden flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23775v3</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.soft</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1103/k45s-g74h</arxiv:DOI>
      <dc:creator>Holger Grosshans, Gizem Ozler, Simon Janta\v{c}</dc:creator>
    </item>
    <item>
      <title>Adaptive Probability Flow Residual Minimization for High-Dimensional Fokker-Planck Equations</title>
      <link>https://arxiv.org/abs/2512.19196</link>
      <description>arXiv:2512.19196v2 Announce Type: replace 
Abstract: Solving high-dimensional Fokker-Planck (FP) equations is a challenge in computational physics and stochastic dynamics, due to the curse of dimensionality (CoD) and the bottleneck of evaluating second-order diffusion terms. Existing deep learning approaches, such as Physics-Informed Neural Networks, face computational challenges as dimensionality increases, driven by the $O(d^2)$ complexity of automatic differentiation for second-order derivatives. While recent probability flow approaches bypass this by learning score functions or matching velocity fields, they often involve serial operations or depend on sampling efficiency in complex distributions. To address these issues, we propose the Adaptive Probability Flow Residual Minimization (A-PFRM) method. We reformulate the second-order FP equation into an equivalent first-order deterministic Probability Flow ODE (PF-ODE) constraint, which avoids explicit Hessian computation. Unlike score matching or velocity matching, A-PFRM solves this problem by minimizing the residual of the continuity equation induced by the PF-ODE. We leverage Continuous Normalizing Flows combined with the Hutchinson Trace Estimator to reduce the training complexity to linear scale $O(d)$, achieving an effective $O(1)$ wall-clock time on GPUs. To address data sparsity in high dimensions, we apply a generative adaptive sampling strategy and theoretically prove that dynamically aligning collocation points with the evolving probability mass is a necessary condition to bound the approximation error. Experiments on diverse benchmarks -- ranging from anisotropic Ornstein-Uhlenbeck (OU) processes and high-dimensional Brownian motions with time-varying diffusion terms, to Geometric OU processes featuring non-Gaussian solutions -- demonstrate that A-PFRM effectively mitigates the CoD, maintaining high accuracy and constant temporal cost for problems up to 100 dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19196v2</guid>
      <category>physics.comp-ph</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaolong Wu, Qifeng Liao</dc:creator>
    </item>
    <item>
      <title>Sparse data assimilation for under-resolved large-eddy simulations</title>
      <link>https://arxiv.org/abs/2407.11746</link>
      <description>arXiv:2407.11746v3 Announce Type: replace-cross 
Abstract: The need for accurate and fast scale-resolving simulations of fluid flows, where turbulent dispersion is a crucial physical feature, is evident. Large-eddy simulations (LES) are computationally more affordable than direct numerical simulations, but their accuracy depends on sub-grid scale models and the quality of the computational mesh. In order to compensate related errors, a data assimilation approach for LES is devised in this work.
  The presented method is based on variational assimilation of sparse time-averaged velocity reference data. Working with the time-averaged LES momentum equation allows to employ a stationary discrete adjoint method. Therefore, a stationary corrective force in the unsteady LES momentum equation is iteratively updated within the gradient-based optimization framework in conjunction with the adjoint gradient. After data assimilation, corrected anisotropic Reynolds stresses are inferred from the stationary corrective force. Ultimately, this corrective force that acts on the mean velocity is replaced by a term that scales the velocity fluctuations through nudging of the corrected anisotropic Reynolds stresses.
  Efficacy of the proposed framework is demonstrated for turbulent flow over periodic hills and around a square cylinder. Coarse meshes are leveraged to further enhance the speed of the optimization procedure. Time- and spanwise-averaged velocity reference data from high-fidelity simulations is taken from the literature.
  Our results demonstrate that adjoint-based assimilation of averaged velocity enables the optimization of the mean flow, vortex shedding frequency (i.e., Strouhal number), and anisotropic Reynolds stresses. This highlights the superiority of scale-resolving simulations such as LES over simulations based on the (unsteady) Reynolds-averaged equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11746v3</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2025.118421</arxiv:DOI>
      <dc:creator>Justin Plogmann, Oliver Brenner, Patrick Jenny</dc:creator>
    </item>
    <item>
      <title>A large language model-type architecture for high-dimensional molecular potential energy surfaces</title>
      <link>https://arxiv.org/abs/2412.03831</link>
      <description>arXiv:2412.03831v2 Announce Type: replace-cross 
Abstract: Computing high-dimensional potential energy surfaces for molecular systems and materials is considered to be a great challenge in computational chemistry with potential impact in a range of areas including the fundamental prediction of reaction rates. In this paper, we design and discuss an algorithm that has similarities to large language models in generative AI and natural language processing. Specifically, we represent a molecular system as a graph which contains a set of nodes, edges, faces, etc. Interactions between these sets, which represent molecular subsystems in our case, are used to construct the potential energy surface for a reasonably sized chemical system with 51 nuclear dimensions. For this purpose, a family of neural networks that pertain to the graph-theoretically obtained subsystems get the job done for this 51 nuclear dimensional system. We then ask if this same family of lower-dimensional graph-based neural networks can be transformed to provide accurate predictions for a 186-dimensional potential energy surface. We find that our algorithm does provide accurate results for this larger-dimensional problem with sub-kcal/mol accuracy for the higher-dimensional potential energy surface problem. Indeed, as a result of these developments, here we produce the first efforts towards a full-dimensional potential energy surface for the protonated 21-water cluster (186 nuclear dimensions) at CCSD level accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03831v2</guid>
      <category>cs.LG</category>
      <category>physics.atm-clus</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:journal_reference>Phys. Rev. X, 2026</arxiv:journal_reference>
      <dc:creator>Xiao Zhu, Srinivasan S. Iyengar</dc:creator>
    </item>
    <item>
      <title>GeoWarp: An automatically differentiable and GPU-accelerated implicit MPM framework for geomechanics based on NVIDIA Warp</title>
      <link>https://arxiv.org/abs/2507.09435</link>
      <description>arXiv:2507.09435v2 Announce Type: replace-cross 
Abstract: The material point method (MPM), a hybrid Lagrangian-Eulerian particle method, is increasingly used to simulate large-deformation and history-dependent behavior of geomaterials. While explicit time integration dominates current MPM implementations due to its algorithmic simplicity, such schemes are unsuitable for quasi-static and long-term processes typical in geomechanics. Implicit MPM formulations are free of these limitations but remain less adopted, largely due to the difficulty of computing the Jacobian matrix required for Newton-type solvers, especially when consistent tangent operators should be derived for complex constitutive models. In this paper, we introduce GeoWarp -- an implicit MPM framework for geomechanics built on NVIDIA Warp -- that exploits GPU parallelism and reverse-mode automatic differentiation to compute Jacobians without manual derivation. To enhance efficiency, we develop a sparse Jacobian construction algorithm that leverages the localized particle-grid interactions intrinsic to MPM. The framework is verified through forward and inverse examples in large-deformation elastoplasticity and coupled poromechanics. Results demonstrate that GeoWarp provides a robust, scalable, and extensible platform for differentiable implicit MPM simulation in computational geomechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09435v2</guid>
      <category>cs.CE</category>
      <category>cs.MS</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.advengsoft.2025.104072</arxiv:DOI>
      <arxiv:journal_reference>Adv. Eng. Softw. 212 (2026) 104072</arxiv:journal_reference>
      <dc:creator>Yidong Zhao, Xuan Li, Chenfanfu Jiang, Jinhyun Choo</dc:creator>
    </item>
    <item>
      <title>Data-driven particle dynamics: Structure-preserving coarse-graining for emergent behavior in non-equilibrium systems</title>
      <link>https://arxiv.org/abs/2508.12569</link>
      <description>arXiv:2508.12569v3 Announce Type: replace-cross 
Abstract: Multiscale systems are ubiquitous in science and technology, but are notoriously challenging to simulate as short spatiotemporal scales must be appropriately linked to emergent bulk physics. When expensive high-dimensional dynamical systems are coarse-grained into low-dimensional models, the entropic loss of information leads to emergent physics which are dissipative, history-dependent, and stochastic. To machine learn coarse-grained dynamics from time-series observations of particle trajectories, we propose a framework using the metriplectic bracket formalism that preserves these properties by construction; most notably, the framework guarantees discrete notions of the first and second laws of thermodynamics, conservation of momentum, and a discrete fluctuation-dissipation balance crucial for capturing non-equilibrium statistics. We introduce the mathematical framework abstractly before specializing to a particle discretization. As labels are generally unavailable for entropic state variables, we introduce a novel self-supervised learning strategy to identify emergent structural variables. We validate the method on benchmark systems and demonstrate its utility on two challenging examples: (1) coarse-graining star polymers at challenging levels of coarse-graining while preserving non-equilibrium statistics, and (2) learning models from high-speed video of colloidal suspensions that capture coupling between local rearrangement events and emergent stochastic dynamics. We provide open-source implementations in both PyTorch and LAMMPS, enabling large-scale inference and extensibility to diverse particle-based systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12569v3</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>physics.comp-ph</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quercus Hernandez, Max Win, Thomas C. O'Connor, Paulo E. Arratia, Nathaniel Trask</dc:creator>
    </item>
    <item>
      <title>Thermoelectric power factors of defective scandium nitride nanostructures from first principles</title>
      <link>https://arxiv.org/abs/2509.14762</link>
      <description>arXiv:2509.14762v2 Announce Type: replace-cross 
Abstract: The thermoelectric properties of scandium nitride are strongly influenced by structural and electronic factors arising from defects and impurities. Nevertheless, the mechanisms by which these microscopic features affect transport are not yet fully understood. Experiments show a large variability in the electronic transport properties, with a strong dependence on the experimental conditions, and attempts to improve thermoelectric efficiency often lead to conflicting effects. In this work, we employ the Landauer approach to analyze the effects of different kinds of structural defects and impurities on electronic transport in scandium nitride. This approach allows us to relate the transport mechanisms to the structural and electronic modifications introduced in the lattice, with atomistic resolution. In light of these new insights, we propose a rationale relating part of the experimental variability to its microscopic origin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14762v2</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cond-mat.mes-hall</category>
      <category>physics.app-ph</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luigi Cigarini, Urszula Danuta Wdowik, Dominik Legut</dc:creator>
    </item>
    <item>
      <title>Revisiting the Broken Symmetry Phase of Solid Hydrogen: A Neural Network Variational Monte Carlo Study</title>
      <link>https://arxiv.org/abs/2512.17703</link>
      <description>arXiv:2512.17703v2 Announce Type: replace-cross 
Abstract: The crystal structure of high-pressure solid hydrogen remains a fundamental open problem. Although the research frontier has mostly shifted toward ultra-high pressure phases above 400 GPa, we show that even the broken symmetry phase observed around 130~GPa requires revisiting due to its intricate coupling of electronic and nuclear degrees of freedom. Here, we develop a first principle quantum Monte Carlo framework based on a deep neural network wave function that treats both electrons and nuclei quantum mechanically within the constant pressure ensemble. Our calculations reveal an unreported ground-state structure candidate for the broken symmetry phase with $Cmcm$ space group symmetry, and we test its stability up to 96 atoms. The predicted structure quantitatively matches the experimental equation of state and X-ray diffraction patterns. Furthermore, our group-theoretical analysis shows that the $Cmcm$ structure is compatible with existing Raman and infrared spectroscopic data. Crucially, static density functional theory calculation reveals the $Cmcm$ structure as a dynamically unstable saddle point on the Born-Oppenheimer potential energy surface, demonstrating that a full quantum many-body treatment of the problem is necessary. These results shed new light on the phase diagram of high-pressure hydrogen and call for further experimental verifications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17703v2</guid>
      <category>cond-mat.str-el</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 30 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengdu Chai, Chen Lin, Xinyang Dong, Yuqiang Li, Wanli Ouyang, Lei Wang, X. C. Xie</dc:creator>
    </item>
  </channel>
</rss>
