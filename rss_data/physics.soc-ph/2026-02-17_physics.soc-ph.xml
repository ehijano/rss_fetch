<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.soc-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.soc-ph</link>
    <description>physics.soc-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.soc-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Feb 2026 02:33:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The gold-rush effect: how innovation speeds up</title>
      <link>https://arxiv.org/abs/2602.13775</link>
      <description>arXiv:2602.13775v1 Announce Type: new 
Abstract: Innovation records often exhibit "hockey-stick" patterns of abrupt, near-singular growth at the collective level. However, this macroscopic explosiveness stands in stark contrast to individual discovery, which remains bounded by cognitive and temporal constraints and follows slow, sublinear accumulation laws. Here, we resolve this micro-macro discrepancy by introducing a minimal multi-scale model that identifies the growth of the explorer population as the primary driver of aggregate acceleration. Building on the Theory of the Adjacent Possible and the Urn Model with Triggering (UMT), we demonstrate that as discoveries expand the space of possibilities, they attract new explorers through a self-reinforcing branching process. This expansion induces a nonlinear mapping between intrinsic time (individual discovery events) and natural time (calendar years), effectively reparameterizing steady individual trajectories into accelerating system-level dynamics. We validate the framework using large-scale patent (EPO) and scientific publication (OpenAlex) datasets, showing that the model accurately reproduces stable per-capita productivity alongside exponential aggregate growth. By providing a quantitative link between individual behavior and collective takeoffs, this work offers a unified foundation for understanding the statistical structure and temporal evolution of innovation ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13775v1</guid>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alessandro Bellina, Gabriele Di Bona, Giordano De Marzo, Vittorio Loreto</dc:creator>
    </item>
    <item>
      <title>Measuring Self-Rating Bias in LLM-Generated Survey Data: A Semantic Similarity Framework for Independent Scale Mapping</title>
      <link>https://arxiv.org/abs/2602.13862</link>
      <description>arXiv:2602.13862v1 Announce Type: new 
Abstract: Synthetic survey data generated by large language models (LLMs) suffers from a fundamental circularity: the same model family that generates text responses also maps them to numerical scales. We calibrate and validate Semantic Similarity Rating (SSR; Maier et al., 2024), which decouples generation from scale mapping via embedding-based cosine similarity against predefined anchor statements. Configuration experiments (N=17 pilot, N=69 cross-validation across 8 domains) show that naturalistic behavioral anchors outperform formal jargon by 29 percentage points (pp), and that SSR achieves 65-67% exact match and 91% within plus/minus 1; a cross-model test with OpenAI text-embedding-3-small reaches 77% exact, confirming cross-provider generalization. Direct LLM baselines (Claude 87%, GPT-4o 83%) establish that SSR's contribution is methodological independence, not accuracy superiority. A control condition removing question text from the LLM prompt actually improves LLM accuracy, ruling out information asymmetry as the explanation for SSR's lower accuracy. A pre-registered circularity experiment (N=345) reveals 4x compressed error variance in LLM rating (sigma^2 = 0.21 vs 0.87 for SSR) and systematic directional bias. A cross-model control (GPT-4o rating Claude-generated text) shows nearly identical compression (within/cross ratio = 0.93), indicating variance compression is a general LLM property rather than a within-model artifact. The calibration dataset, anchor library, and source code are publicly available (see Data Availability).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13862v1</guid>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eduardo Vera Pichardo</dc:creator>
    </item>
    <item>
      <title>Preliminary sonification of ENSO using traditional Javanese gamelan scales</title>
      <link>https://arxiv.org/abs/2602.14560</link>
      <description>arXiv:2602.14560v1 Announce Type: new 
Abstract: Sonification -- the mapping of data to non-speech audio -- offers an underexplored channel for representing complex dynamical systems. We treat El Ni\~{n}o-Southern Oscillation (ENSO), a canonical example of low-dimensional climate chaos, as a test case for culturally-situated sonification evaluated through complex systems diagnostics. Using parameter-mapping sonification of the Ni\~{n}o 3.4 sea surface temperature anomaly index (1870--2024), we encode ENSO variability into two traditional Javanese gamelan pentatonic systems (pelog and slendro) across four composition strategies, then analyze the resulting audio as trajectories in a two-dimensional acoustic phase space. Recurrence-based diagnostics, convex hull geometry, and coupling analysis reveal that the sonification pipeline preserves key dynamical signatures: alternating modes produce the highest trajectory recurrence rates, echoing ENSO's quasi-periodicity; layered polyphonic modes explore the broadest phase space regions; and the two scale families induce qualitatively distinct coupling regimes between spectral brightness and energy -- predominantly anti-phase in pelog but near-independent in slendro. Phase space trajectory analysis provides a rigorous geometric framework for comparing sonification designs within a complex systems context. Perceptual validation remains necessary; we contribute the dynamical systems methodology for evaluating such mappings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14560v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SD</category>
      <category>physics.ao-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandy H. S. Herho, Rusmawan Suwarman, Nurjanna J. Trilaksono, Iwan P. Anwar, Faiz R. Fajary</dc:creator>
    </item>
    <item>
      <title>Modeling medium and low voltage grids using population density</title>
      <link>https://arxiv.org/abs/2602.14894</link>
      <description>arXiv:2602.14894v1 Announce Type: new 
Abstract: The expansion of global electricity distribution systems necessitates the deployment of massive infrastructure. Assessing its implications from a spatial and material perspective requires an understanding of the core drivers of a distribution grid configuration. Our model samples substation locations using a non-linear relationship with population density and constructs the network applying the Kruskal algorithm. This streamlined approach generates realistic grid structures at the local scale and provides accurate estimates of the total network length at the national scale. Using highly granular population data, this local model reveals a profound connection between population spread and distribution grid, which appears to persist at the global level. Potentially driven by the emergent properties of population scaling laws, the full network characteristics appear to be well described by multivariate power laws on aggregated population and area. Validated across 35 countries, these results provide new multi-scale tools for characterizing electrical infrastructure and reveal key determinants of distribution grid extent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14894v1</guid>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emile Emery, Joseph Le Bihan, Jos\'e Halloy</dc:creator>
    </item>
    <item>
      <title>Endogenous Epistemic Weighting under Heterogeneous Information: Beyond Majority Rule</title>
      <link>https://arxiv.org/abs/2602.13499</link>
      <description>arXiv:2602.13499v1 Announce Type: cross 
Abstract: Collective decision-making can be viewed as the problem of aggregating multiple noisy information channels about an unknown state of the world. Classical epistemic justifications of majority rule rely on restrictive assumptions about the homogeneity and symmetry of these channels, which are often violated in realistic environments. This paper introduces the Epistemic Shared-Choice Mechanism (ESCM), a lightweight and auditable procedure that endogenously estimates issue-specific signal reliability and assigns bounded, decision-specific voting weights. Using central limit approximations, the paper provides an analytical comparison between ESCM and unweighted majority rule, showing how their relative epistemic performance depends on the distributional structure of information in the population, including unimodal competence distributions and segmented environments with informed minorities. The results indicate that endogenous and bounded epistemic weighting can improve collective accuracy by merging procedural and epistemic requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13499v1</guid>
      <category>econ.GN</category>
      <category>cs.GT</category>
      <category>physics.soc-ph</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enrico Manfredi</dc:creator>
    </item>
    <item>
      <title>Temporal Shifts and Causal Interactions of Emotions in Social and Mass Media: A Case Study of the "Reiwa Rice Riot" in Japan</title>
      <link>https://arxiv.org/abs/2602.14091</link>
      <description>arXiv:2602.14091v1 Announce Type: cross 
Abstract: In Japan, severe rice shortages in 2024 sparked widespread public controversy across both news media and social platforms, culminating in what has been termed the "Reiwa Rice Riot." This study proposes a framework to analyze the temporal dynamics and causal interactions of emotions expressed on X (formerly Twitter) and in news articles, using the "Reiwa Rice Riot" as a case study. While recent studies have shown that emotions mutually influence each other between social and mass media, the patterns and transmission pathways of such emotional shifts remain insufficiently understood. To address this gap, we applied a machine learning-based emotion classification grounded in Plutchik's eight basic emotions to analyze posts from X and domestic news articles. Our findings reveal that emotional shifts and information dissemination on X preceded those in news media. Furthermore, in both media platforms, the fear was initially the most dominant emotion, but over time intersected with hope which ultimately became the prevailing emotion. Our findings suggest that patterns in emotional expressions on social media may serve as a lens for exploring broader social dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14091v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erina Murata, Masaki Chujyo, Fujio Toriumi</dc:creator>
    </item>
    <item>
      <title>Competition for attention predicts good-to-bad tipping in AI</title>
      <link>https://arxiv.org/abs/2602.14370</link>
      <description>arXiv:2602.14370v1 Announce Type: cross 
Abstract: More than half the global population now carries devices that can run ChatGPT-like language models with no Internet connection and minimal safety oversight -- and hence the potential to promote self-harm, financial losses and extremism among other dangers. Existing safety tools either require cloud connectivity or discover failures only after harm has occurred. Here we show that a large class of potentially dangerous tipping originates at the atomistic scale in such edge AI due to competition for the machinery's attention. This yields a mathematical formula for the dynamical tipping point n*, governed by dot-product competition for attention between the conversation's context and competing output basins, that reveals new control levers. Validated against multiple AI models, the mechanism can be instantiated for different definitions of 'good' and 'bad' and hence in principle applies across domains (e.g. health, law, finance, defense), changing legal landscapes (e.g. EU, UK, US and state level), languages, and cultural settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14370v1</guid>
      <category>cs.AI</category>
      <category>physics.app-ph</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neil F. Johnson, Frank Y. Huo</dc:creator>
    </item>
    <item>
      <title>Human versus Artificial Intelligence; various significant examples in astrophysics</title>
      <link>https://arxiv.org/abs/2602.14567</link>
      <description>arXiv:2602.14567v1 Announce Type: cross 
Abstract: In a recent arXiv posting [1] I reported the result of an experiment: asking Perplexity.ai to compare three items concerning (ordinary) Gamma Ray Burts (GRBs): the data, the standard paradigm(s) and the "Cannonball" (CB) model. Here I ask the same URL to extend this comparison to long--lasting GRBs, binary Neutron-Star mergers and their associated short--hard GRBs, low--luminosity GRBs, X--ray flashes, X--ray transients, and non--solar cosmic rays. The results of this experiment are enlightening but worrisome. Except for this abstract, two footnotes and two other references to standard [2] and CB-model [3] articles and talks, all of what follows is, verbatim, what the cited AI "opines".</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14567v1</guid>
      <category>astro-ph.HE</category>
      <category>hep-ph</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. De R\'ujula</dc:creator>
    </item>
    <item>
      <title>Tracking enduring urban-rural inequities in residential heating and cooling loads across Chinese provinces</title>
      <link>https://arxiv.org/abs/2512.16779</link>
      <description>arXiv:2512.16779v2 Announce Type: replace 
Abstract: Climate change and rising thermal comfort demand make residential heating and cooling central to building-sector decarbonization. This study presents the first bottom-up modeling framework to estimate residential heating and cooling loads across 30 Chinese provinces. The model, developed using EnergyPlus simulations of representative building prototypes, captures energy consumption patterns in both urban and rural housing over the period 1980-2024. The results indicate that: (1) In 2020, Guangdong recorded the highest cooling loads (76.5 TWh/a urban; 63.0 TWh/a rural). Henan exhibited the highest rural heating load (174.6 TWh/a), while urban heating loads were highest in Liaoning and Shandong. (2) Between 1980 and 2024, average urban cooling loads increased from 12.4 to 15.1 kWh/m2 a, whereas rural cooling loads declined from 22.63 to 19.87 kWh/m2 a. Urban heating loads decreased from 44.08 to 39.92 kWh/m2 a, and rural heating loads declined more markedly from 100.15 to 72.42 kWh/m2 a. (3) Urban residential floor area has exceeded rural stock in 22 provinces in recent years, compared with only four provinces in 2000. Moreover, the existence of 12 urban energy-efficiency standards versus a single rural standard highlights persistent envelope-performance disparities. These structural and regulatory differences have produced sustained urban-rural divergence in residential heating and cooling demand. The proposed framework provides a replicable basis for region-specific clean heating strategies and differentiated building standards to support carbon neutrality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.16779v2</guid>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qinwen Tang, Ran Yan, Nan Zhou, Minda Ma</dc:creator>
    </item>
    <item>
      <title>A note on thermodynamics of the production processes</title>
      <link>https://arxiv.org/abs/2601.07616</link>
      <description>arXiv:2601.07616v2 Announce Type: replace 
Abstract: The process of creating goods and services, measured by their value, is considered a process of creating complexity. This allows us to consider the production system as an open thermodynamic system, and to develop a simple heuristic model of the production process. The model includes three production factors: the index of complexity of production equipment (physical capital $K$), human activity (labour $L$), and the substitutive capacity of equipment (substitutive work $P$). The latter is a contribution to the theory of production from the thermodynamic approach, which also involves introducing technological characteristics of production equipment, such as labour requirement ($\overline{\lambda}$) and energy requirement ($\overline{\varepsilon}$), which indicate the amounts of labour and energy required to operate production equipment. By applying thermodynamic principles, we can understand how labour can be replaced by capital and derive the production function with four different formulations. Two of them are known and used by researchers for interpretation the production phenomena; the thermodynamic approach provides some foundation for economic theory, allowing us to decompose unambiguously the growth rate of output over technological level and the growth rates of production factors. Introducing substitute work as a factor of production and technological characteristics of capital expands our ability to plan and analyse production processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07616v2</guid>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladimir Pokrovskii</dc:creator>
    </item>
    <item>
      <title>Predicting Company Growth using Scaling Theory informed Machine Learning</title>
      <link>https://arxiv.org/abs/2410.17587</link>
      <description>arXiv:2410.17587v2 Announce Type: replace-cross 
Abstract: Predicting company growth is a critical yet challenging task because observed dynamics blend an underlying structural growth trend with volatile fluctuations. Here, we propose a Scaling-Theory-Informed Machine Learning (STIML) framework that integrates a scaling-based growth model to capture the mechanism-driven average trend, together with a data-driven forecasting model to learn the residual fluctuations. Using Compustat annual financial statement data (1950--2019) for 31,553 North American companies, we extend the growth model beyond assets to multiple financial indicators, and evaluate STIML against growth model-only and purely data-driven baselines. Across 16 target variables, we show that company growth exhibits a clear separation between trend-driven predictability and fluctuation-driven predictability, with their relative importance depending strongly on company size and volatility. Interpretability analyses further show that STIML captures multivariate dependencies beyond simple autocorrelation, and that macroeconomic variables contribute significantly less to predictive performance on average. Moreover, we find the scaling-based growth model overlooks asymmetric deviations, which instead contain the structured and learnable signals, suggesting a path to refine mechanistic models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17587v2</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>physics.soc-ph</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruyi Tao, Veronica R. Cappelli, Kaiwei Liu, Marcus J. Hamilton, Christopher P. Kempes, Geoffrey B. Wes, Jiang Zhang</dc:creator>
    </item>
    <item>
      <title>Explainable AI: Learning from the Learners</title>
      <link>https://arxiv.org/abs/2601.05525</link>
      <description>arXiv:2601.05525v2 Announce Type: replace-cross 
Abstract: Artificial intelligence now outperforms humans in several scientific and engineering tasks, yet its internal representations often remain opaque. In this Perspective, we argue that explainable artificial intelligence (XAI), combined with causal reasoning, enables {\it learning from the learners}. Focusing on discovery, optimization and certification, we show how the combination of foundation models and explainability methods allows the extraction of causal mechanisms, guides robust design and control, and supports trust and accountability in high-stakes applications. We discuss challenges in faithfulness, generalization and usability of explanations, and propose XAI as a unifying framework for human-AI collaboration in science and engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05525v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ricardo Vinuesa, Steven L. Brunton, Gianmarco Mengaldo</dc:creator>
    </item>
  </channel>
</rss>
