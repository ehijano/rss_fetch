<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Feb 2026 05:00:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Tight Inapproximability for Welfare-Maximizing Autobidding Equilibria</title>
      <link>https://arxiv.org/abs/2602.09110</link>
      <description>arXiv:2602.09110v1 Announce Type: new 
Abstract: We examine the complexity of computing welfare- and revenue-maximizing equilibria in autobidding second-price auctions subject to return-on-spend (RoS) constraints. We show that computing an autobidding equilibrium that approximates the welfare-optimal one within a factor of $2 - \epsilon$ is NP-hard for any constant $\epsilon &gt; 0$. Moreover, deciding whether there exists an autobidding equilibrium that attains a $1/2 + \epsilon$ fraction of the optimal welfare -- unfettered by equilibrium constraints -- is NP-hard for any constant $\epsilon &gt; 0$. This hardness result is tight in view of the fact that the price of anarchy (PoA) is at most $2$, and shows that deciding whether a non-trivial autobidding equilibrium exists -- one that is even marginally better than the worst-case guarantee -- is intractable. For revenue, we establish a stronger logarithmic inapproximability, while under the projection games conjecture, our reduction rules out even a polynomial approximation factor. These results significantly strengthen the APX-hardness of Li and Tang (AAAI '24). Furthermore, we refine our reduction in the presence of ML advice concerning the buyers' valuations, revealing again a close connection between the inapproximability threshold and PoA bounds. Finally, we examine relaxed notions of equilibrium attained by simple learning algorithms, establishing constant inapproximability for both revenue and welfare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09110v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioannis Anagnostides, Ian Gemp, Georgios Piliouras, Kelly Spendlove</dc:creator>
    </item>
    <item>
      <title>Chaos in Autobidding Auctions</title>
      <link>https://arxiv.org/abs/2602.09118</link>
      <description>arXiv:2602.09118v1 Announce Type: new 
Abstract: As autobidding systems increasingly dominate online advertising auctions, characterizing their long-term dynamical behavior is brought to the fore. In this paper, we examine the dynamics of autobidders who optimize value subject to a return-on-spend (RoS) constraint under uniform bid scaling. Our main set of results show that simple autobidding dynamics can exhibit formally chaotic behavior. This significantly strengthens the recent results of Leme, Piliouras, Schneider, Spendlove, and Zuo (EC '24) that went as far as quasiperiodicity. Our proof proceeds by establishing that autobidding dynamics can simulate -- up to an arbitrarily small error -- a broad class of continuous-time nonlinear dynamical systems. This class contains as a special case Chua's circuit, a classic chaotic system renowned for its iconic double scroll attractor. Our reduction develops several modular gadgets, which we anticipate will find other applications going forward. Moreover, in discrete time, we show that different incarnations of mirror descent can exhibit Li-Yorke chaos, topological transitivity, and sensitivity to initial conditions, connecting along the way those dynamics to classic dynamical systems such as the logistic map and the Ricker population model. Taken together, our results reveal that the long-term behavior of ostensibly simple second-price autobidding auctions can be inherently unpredictable and complex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09118v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioannis Anagnostides, Ian Gemp, Georgios Piliouras, Kelly Spendlove</dc:creator>
    </item>
    <item>
      <title>Data Sharing with Endogenous Choices over Differential Privacy Levels</title>
      <link>https://arxiv.org/abs/2602.09357</link>
      <description>arXiv:2602.09357v1 Announce Type: new 
Abstract: We study coalition formation for data sharing under differential privacy when agents have heterogeneous privacy costs. Each agent holds a sensitive data point and decides whether to participate in a data-sharing coalition and how much noise to add to their data. Privacy choices induce a fundamental trade-off: higher privacy reduces individual data-sharing costs but degrades data utility and statistical accuracy for the coalition. These choices generate externalities across agents, making both participation and privacy levels strategic. Our goal is to understand which coalitions are stable, how privacy choices shape equilibrium outcomes, and how decentralized data sharing compares to a centralized, socially optimal benchmark.
  We provide a comprehensive equilibrium analysis across a broad range of privacy-cost regimes, from decreasing costs (e.g., privacy amplification from pooling data) to increasing costs (e.g., greater exposure to privacy attacks in larger coalitions). We first characterize Nash equilibrium coalitions with endogenous privacy levels and show that equilibria may fail to exist and can be non-monotonic in problem parameters. We also introduce a weaker equilibrium notion called robust equilibrium (that allows more widespread equilibrium existence by equipping existing players in the coalition with the power to prevent or veto external players from joining) and fully characterize such equilibria. Finally, we analyze, for both Nash and robust equilibria, the efficiency relative to the social optimum in terms of social welfare and estimator accuracy. We derive bounds that depend sharply on the number of players, properties of the cost profile and how privacy costs scale with coalition size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09357v1</guid>
      <category>cs.GT</category>
      <category>cs.CR</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raef Bassily, Kate Donahue, Diptangshu Sen, Annuo Zhao, Juba Ziani</dc:creator>
    </item>
    <item>
      <title>Enhancing Affine Maximizer Auctions with Correlation-Aware Payment</title>
      <link>https://arxiv.org/abs/2602.09455</link>
      <description>arXiv:2602.09455v1 Announce Type: new 
Abstract: Affine Maximizer Auctions (AMAs), a generalized mechanism family from VCG, are widely used in automated mechanism design due to their inherent dominant-strategy incentive compatibility (DSIC) and individual rationality (IR). However, as the payment form is fixed, AMA's expressiveness is restricted, especially in distributions where bidders' valuations are correlated. In this paper, we propose Correlation-Aware AMA (CA-AMA), a novel framework that augments AMA with a new correlation-aware payment. We show that any CA-AMA preserves the DSIC property and formalize finding optimal CA-AMA as a constraint optimization problem subject to the IR constraint. Then, we theoretically characterize scenarios where classic AMAs can perform arbitrarily poorly compared to the optimal revenue, while the CA-AMA can reach the optimal revenue. For optimizing CA-AMA, we design a practical two-stage training algorithm. We derive that the target function's continuity and the generalization bound on the degree of deviation from strict IR. Finally, extensive experiments showcase that our algorithm can find an approximate optimal CA-AMA in various distributions with improved revenue and a low degree of violation of IR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09455v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoran Sun, Xuanzhi Xia, Xu Chu, Xiaotie Deng</dc:creator>
    </item>
    <item>
      <title>Routing, Cascades, and User Choice for LLMs</title>
      <link>https://arxiv.org/abs/2602.09902</link>
      <description>arXiv:2602.09902v1 Announce Type: new 
Abstract: To mitigate the trade-offs between performance and costs, LLM providers route user tasks to different models based on task difficulty and latency. We study the effect of LLM routing with respect to user behavior. We propose a game between an LLM provider with two models (standard and reasoning) and a user who can re-prompt or abandon tasks if the routed model cannot solve them. The user's goal is to maximize their utility minus the delay from using the model, while the provider minimizes the cost of servicing the user. We solve this Stackelberg game by fully characterizing the user best response and simplifying the provider problem. We observe that in nearly all cases, the optimal routing policy involves a static policy with no cascading that depends on the expected utility of the models to the user. Furthermore, we reveal a misalignment gap between the provider-optimal and user-preferred routes when the user's and provider's rankings of the models with respect to utility and cost differ. Finally, we demonstrate conditions for extreme misalignment where providers are incentivized to throttle the latency of the models to minimize their costs, consequently depressing user utility. The results yield simple threshold rules for single-provider, single-user interactions and clarify when routing, cascading, and throttling help or harm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09902v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafid Mahmood</dc:creator>
    </item>
    <item>
      <title>The Architecture of Illusion: Network Opacity and Strategic Escalation</title>
      <link>https://arxiv.org/abs/2602.10053</link>
      <description>arXiv:2602.10053v1 Announce Type: new 
Abstract: Standard models of bounded rationality typically assume agents either possess accurate knowledge of the population's reasoning abilities (Cognitive Hierarchy) or hold dogmatic, degenerate beliefs (Level-$k$). We introduce the ``Connected Minds'' model, which unifies these frameworks by integrating iterative reasoning with a parameterized network bias. We posit that agents do not observe the global population; rather, they observe a sample biased by their network position, governed by a locality parameter $p$ representing algorithmic ranking, social homophily, or information disclosure. We show that this parameter acts as a continuous bridge: the model collapses to the myopic Level-$k$ recursion as networks become opaque ($p \to 0$) and recovers the standard Cognitive Hierarchy model under full transparency ($p=1$). Theoretically, we establish that network opacity induces a \emph{Sophisticated Bias}, causing agents to systematically overestimate the cognitive depth of their opponents while preserving the log-concavity of belief distributions. This makes $p$ an actionable lever: a planner or platform can tune transparency -- globally or by segment (a personalized $p_k$) -- to shape equilibrium behavior. From a mechanism design perspective, we derive the \emph{Escalation Principle}: in games of strategic complements, restricting information can maximize aggregate effort by trapping agents in echo chambers where they compete against hallucinated, high-sophistication peers. Conversely, we identify a \emph{Transparency Reversal} for coordination games, where maximizing network visibility is required to minimize variance and stabilize outcomes. Our results suggest that network topology functions as a cognitive zoom lens, determining whether agents behave as local imitators or global optimizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10053v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raman Ebrahimi, Sepehr Ilami, Babak Heydari, Isabel Trevino, Massimo Franceschetti</dc:creator>
    </item>
    <item>
      <title>Allocation Proportionality of OWA--Based Committee Scoring Rules</title>
      <link>https://arxiv.org/abs/2602.10083</link>
      <description>arXiv:2602.10083v1 Announce Type: new 
Abstract: While proportionality is frequently named as a desirable property of voting rules, its interpretation in multiwinner voting differs significantly from that in apportionment. We aim to bridge these two distinct notions of proportionality by introducing the concept of allocation proportionality, founded upon the framework of party elections, where each candidate in a multiwinner election is assigned to a party. A voting rule is allocation proportional if each party's share of elected candidates equals that party's aggregate score. Recognizing that no committee scoring rule can universally satisfy allocation proportionality in practice, we introduce a new measure of allocation proportionality degree and discuss how it relates to other quantitative measures of proportionality. This measure allows us to compare OWA-based committee scoring rules according to how much they diverge from the ideal of allocation proportionality. We present experimental results for several common rules: SNTV, $k$-Borda, Chamberlin-Courant, Harmonic Borda, Proportional $k$-Approval Voting, and Bloc Voting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10083v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daria Boratyn, Dariusz Stolicki</dc:creator>
    </item>
    <item>
      <title>The Complexity of Proper Equilibrium in Extensive-Form and Polytope Games</title>
      <link>https://arxiv.org/abs/2602.10096</link>
      <description>arXiv:2602.10096v1 Announce Type: new 
Abstract: The proper equilibrium, introduced by Myerson (1978), is a classic refinement of the Nash equilibrium that has been referred to as the "mother of all refinements." For normal-form games, computing a proper equilibrium is known to be PPAD-complete for two-player games and FIXP$_a$-complete for games with at least three players. However, the complexity beyond normal-form games -- in particular, for extensive-form games (EFGs) -- was a long-standing open problem first highlighted by Miltersen and S{\o}rensen (SODA '08). In this paper, we resolve this problem by establishing PPAD- and FIXP$_a$-membership (and hence completeness) of normal-form proper equilibria in two-player and multi-player EFGs respectively. Our main ingredient is a technique for computing a perturbed (proper) best response that can be computed efficiently in EFGs. This is despite the fact that, as we show, computing a best response using the classic perturbation of Kohlberg and Mertens based on the permutahedron is #P-hard even in Bayesian games. In stark contrast, we show that computing a proper equilibrium in polytope games is NP-hard. This marks the first natural class in which the complexity of computing equilibrium refinements does not collapse to that of Nash equilibria, and the first problem in which equilibrium computation in polytope games is strictly harder -- unless there is a collapse in the complexity hierarchy -- relative to extensive-form games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10096v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian Hu Zhang, Ioannis Anagnostides, Kiriaki Fragkia, Maria-Florina Balcan, Tuomas Sandholm</dc:creator>
    </item>
    <item>
      <title>Mechanism Design for LLM Fine-tuning with Multiple Reward Models</title>
      <link>https://arxiv.org/abs/2405.16276</link>
      <description>arXiv:2405.16276v4 Announce Type: replace 
Abstract: Fine-tuning large language models (LLMs) to aggregate multiple preferences has attracted considerable research attention. With aggregation algorithms advancing, a potential economic scenario arises where fine-tuning services are provided to agents with different preferences. In this context, agents may benefit from strategically misreporting their preferences, but this could harm the aggregation performance. This paper addresses such incentive issues by framing it as a mechanism design problem: an LLM provider determines the fine-tuning objective (training rule) and the pricing scheme (payment rule) for agents. We primarily focus on training rules that maximize social welfare subject to certain regularizations, referred to as SW-Max rules. First, we show that under most circumstances, truthful reporting is sub-optimal with simply a SW-Max rule, thereby highlighting the necessity of payments. Second, we extend the VCG payment to implement SW-Max rules in dominant-strategy incentive compatibility (DSIC). We characterize sufficient conditions for payment equivalence and derive the necessary conditions for a payment rule to implement a SW-Max rule in DSIC and other principles. Third, we demonstrate that our mechanism is approximately DSIC with perturbed input, showcasing its robustness against the inevitable errors in real-world applications. Experiments on real LLM training results further confirm the practical implications of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16276v4</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoran Sun, Yurong Chen, Siwei Wang, Xu Chu, Wei Chen, Xiaotie Deng</dc:creator>
    </item>
    <item>
      <title>Public goods games on any population structure</title>
      <link>https://arxiv.org/abs/2411.00398</link>
      <description>arXiv:2411.00398v2 Announce Type: replace 
Abstract: Understanding the emergence of cooperation in social networks has advanced through pairwise interactions, but the corresponding theory for group-based public goods games (PGGs) remains less explored. Here, we provide theoretical conditions under which cooperation thrives in PGGs on arbitrary population structures, which are accurate under weak selection. We find that a class of networks that would otherwise fail to produce cooperation, such as star graphs, are particularly conducive to cooperation in PGGs. More generally, PGGs can support cooperation on almost all networks, which is robust across all kinds of model details. This fundamental advantage of PGGs derives from self-reciprocity realized by group separations and from clustering through second-order interactions. We also apply PGGs to empirical networks, which shows that PGGs could be a promising interaction mode for the emergence of cooperation in real-world systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00398v2</guid>
      <category>cs.GT</category>
      <category>nlin.CG</category>
      <category>physics.soc-ph</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1126/sciadv.aeb1263</arxiv:DOI>
      <dc:creator>Chaoqian Wang, Qi Su</dc:creator>
    </item>
    <item>
      <title>Strategic Content Creation with Age of GenAI: To Share or Not to Share?</title>
      <link>https://arxiv.org/abs/2505.16358</link>
      <description>arXiv:2505.16358v3 Announce Type: replace 
Abstract: We introduce a game-theoretic framework examining strategic interactions between a platform and its content creators in the presence of AI-generated content. Our model's main novelty is in capturing creators' dual strategic decisions: The investment in content quality and their (possible) consent to share their content with the platform's GenAI, both of which significantly impact their utility. To incentivize creators, the platform strategically allocates a portion of its GenAI-driven revenue to creators who share their content. We focus on the class of full-sharing equilibrium profiles, in which all creators willingly share their content with the platform's GenAI system. Such equilibria are highly desirable both theoretically and practically. Our main technical contribution is formulating and efficiently solving a novel optimization problem that approximates the platform's optimal revenue subject to inducing a full-sharing equilibrium. A key aspect of our approach is identifying conditions under which full-sharing equilibria exist and a surprising connection to the Prisoner's Dilemma. Finally, our simulations demonstrate how revenue-allocation mechanisms affect creator utility and the platform's revenue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16358v3</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3774904.3792308</arxiv:DOI>
      <dc:creator>Gur Keinan, Omer Ben-Porat</dc:creator>
    </item>
    <item>
      <title>The Complexity of Equilibrium Refinements in Potential Games</title>
      <link>https://arxiv.org/abs/2511.03968</link>
      <description>arXiv:2511.03968v2 Announce Type: replace 
Abstract: The complexity of computing equilibrium refinements has been at the forefront of algorithmic game theory research, but it has remained open in the seminal class of potential games; we close this fundamental gap in this paper.
  We first show that computing a pure(-strategy) perfect or proper equilibrium is $\mathsf{PLS}$-complete in concise potential games in normal form. For pure perfect equilibria, we extend this result to general polytope games, which includes extensive-form games. We next turn to more structured classes of games, namely symmetric network congestion and symmetric matroid congestion games. For both classes, we show that a pure perfect equilibrium can be computed in polynomial time, strengthening the existing results for pure Nash equilibria. More broadly, we make a connection between strongly polynomial-time algorithms and efficient perturbed optimization using fractional interpolation. On the other hand, we establish that, for a certain class of potential games, there is an exponential separation in the length of the best-response path between perfect and Nash equilibria. Finally, for mixed strategies, we prove that computing a point geometrically near a perfect equilibrium requires a doubly exponentially small perturbation even in $3$-player potential games in normal form. As a byproduct, this significantly strengthens and simplifies a seminal result of Etessami and Yannakakis (FOCS '07). On the flip side, in the special case of polymatrix potential games, we show that equilibrium refinements are amenable to perturbed gradient descent dynamics, thereby belonging to the complexity class $\mathsf{CLS}$. This provides a principled and practical way of refining the landscape of gradient descent in constrained optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03968v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioannis Anagnostides, Maria-Florina Balcan, Kiriaki Fragkia, Tuomas Sandholm, Emanuel Tewolde, Brian Hu Zhang</dc:creator>
    </item>
    <item>
      <title>Minimal Regret Walras Equilibria for Combinatorial Markets</title>
      <link>https://arxiv.org/abs/2511.09021</link>
      <description>arXiv:2511.09021v3 Announce Type: replace 
Abstract: We consider combinatorial multi-item markets and propose the notion of a $\Delta$-regret Walras equilibrium, which is an allocation of items to players and a set of item prices that achieve the following goals: prices clear the market, the allocation is capacity-feasible, and the players' strategies lead to a total regret of $\Delta$. The regret is defined as the sum of individual player regrets measured by the utility gap with respect to the optimal item bundle given the prices. We derive a complete characterization for the existence of $\Delta$-regret equilibria by introducing the concept of a parameterized social welfare problem, where the right-hand side of the original social welfare problem is changed. Our characterization then relates the achievable regret value with the associated duality/integrality gap of the parameterized social welfare problem. For the special case of monotone valuations this translates to regret bounds recovering the duality/integrality gap of the original social welfare problem. We further establish an interesting connection to the area of sensitivity theory in linear optimization. We show that the sensitivity gap of the optimal-value function of two (configuration) linear programs with changed right-hand side can be used to establish a bound on the achievable regret. Finally, we use these general structural results to translate known approximation algorithms for the social welfare optimization problem into algorithms computing low-regret Walras equilibria. We also demonstrate how to derive strong lower bounds based on integrality and duality gaps but also based on NP-complexity theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09021v3</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alo\"is Duguet, Tobias Harks, Martin Schmidt, Julian Schwarz</dc:creator>
    </item>
    <item>
      <title>Online Resource Allocation via Static Bundle Pricing</title>
      <link>https://arxiv.org/abs/2512.16570</link>
      <description>arXiv:2512.16570v2 Announce Type: replace 
Abstract: Online Resource Allocation addresses the problem of efficiently allocating limited resources to buyers with incomplete knowledge of future requests. In our setting, buyers arrive sequentially requesting a set of items, each with a value drawn from a known distribution. We study the efficiency of static and anonymous bundle pricing in environments where the buyers' valuations exhibit strong complementarities. In such settings, standard item pricing fails to leverage item multiplicities, while static bundle pricing mechanisms are only known for very restricted domains and their analysis relies on domain-specific arguments.
  We develop a unified bundle pricing framework for online resource allocation in three well-studied domains with complementarities: (i) single-minded combinatorial auctions with maximum bundle size $d$; (ii) general single-minded combinatorial auctions; and (iii) network routing, where each buyer aims to route a unit of flow from a source node $s$ to a target node $t$ in a capacitated network. Our approach yields static and anonymous bundle pricing mechanisms whose performance improves exponentially with item multiplicity. For the $d$-single-minded setting with minimum item multiplicity $B$, we obtain an $O(d^{1/B})$-competitive mechanism. For general single-minded combinatorial auctions and online network routing, we obtain $O(m^{1/(B+1)})$-competitive mechanisms, where $m$ is the number of items.
  We complement these results with information-theoretic lower bounds. We show that no online algorithm can achieve a competitive ratio better than $ \widetilde{\Omega}(m^{1/(B+2)})$ for single-minded combinatorial auctions and $ \widetilde{\Omega}(d^{1/(B+1)})$ for the $d$-single-minded setting. Our constructions exploit a deep connection to the extremal combinatorics problem of determining the maximum number of qualitatively independent partitions of a ground set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.16570v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitris Fotakis, Charalampos Platanos, Thanos Tolias</dc:creator>
    </item>
    <item>
      <title>Statistical Equilibrium of Optimistic Beliefs</title>
      <link>https://arxiv.org/abs/2502.09569</link>
      <description>arXiv:2502.09569v2 Announce Type: replace-cross 
Abstract: We study finite normal-form games in which payoffs are subject to random perturbations and players face uncertainty about how these shocks co-move across actions, an ambiguity that naturally arises when only realized (not counterfactual) payoffs are observed. We introduce the Statistical Equilibrium of Optimistic Beliefs (SE-OB), inspired by discrete choice theory. We model players as \textit{optimistic better responders}: they face ambiguity about the dependence structure (copula) of payoff perturbations across actions and resolve this ambiguity by selecting, from a belief set, the joint distribution that maximizes the expected value of the best perturbed payoff. Given this optimistic belief, players choose actions according to the induced random-utility choice rule. We define SE-OB as a fixed point of this two-step response mapping.
  SE-OB generalizes the Nash equilibrium and the structural quantal response equilibrium. We establish existence under standard regularity conditions on belief sets. For the economically important class of marginal belief sets, that is, the set of all joint distributions with fixed action-wise marginals, optimistic belief selection reduces to an optimal coupling problem, and SE-OB admits a characterization via Nash equilibrium of a smooth regularized game, yielding tractability and enabling computation.
  We characterize the relationship between SE-OB and existing equilibrium notions and illustrate its empirical relevance in simulations, where it captures systematic violations of independence of irrelevant alternatives that standard logit-based models fail to explain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09569v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Gui, Bahar Ta\c{s}kesen</dc:creator>
    </item>
    <item>
      <title>Robust Learning with Private Information</title>
      <link>https://arxiv.org/abs/2505.05341</link>
      <description>arXiv:2505.05341v3 Announce Type: replace-cross 
Abstract: Firms increasingly delegate decisions to learning algorithms in platform markets. Standard algorithms perform well when platform policies are stationary, but firms often face ambiguity about whether policies are stationary or adapt strategically to their behavior. When policies adapt, efficient learning under stationarity may backfire: it may reveal a firm's persistent private information, allowing the platform to personalize terms and extract information rents. We study a repeated screening problem in which an agent with a fixed private type commits ex ante to a learning algorithm, facing ambiguity about the principal's policy. We show that a broad class of standard algorithms, including all no-external-regret algorithms, can be manipulated by adaptive principals and permit asymptotic full surplus extraction. We then construct a misspecification-robust learning algorithm that treats stationarity as a testable hypothesis. It achieves the optimal payoff under stationarity at the minimax-optimal rate, while preventing dynamic rent extraction: against any adaptive principal, each type's long-run utility is at least its utility under the menu that maximizes revenue under the principal's prior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05341v3</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kyohei Okumura</dc:creator>
    </item>
    <item>
      <title>Co-Investment with Payoff-Sharing Mechanism for Cooperative Decision-Making in Network Design Games</title>
      <link>https://arxiv.org/abs/2508.12059</link>
      <description>arXiv:2508.12059v4 Announce Type: replace-cross 
Abstract: Network-based systems are inherently interconnected, with the design and performance of subnetworks being interdependent. However, the decisions of self-interested operators may lead to suboptimal outcomes for users and the overall system. This paper explores cooperative mechanisms that can simultaneously benefit both operators and users. We address this challenge using a game-theoretical framework that integrates both non-cooperative and cooperative game theory. In the non-cooperative stage, we propose a network design game in which subnetwork decision-makers strategically design local infrastructures. In the cooperative stage, co-investment with payoff-sharing mechanism is developed to enlarge collective benefits and fairly distribute them. To demonstrate the effectiveness of our framework, we conduct case studies on the Sioux Falls network and real-world public transport networks in Zurich and Winterthur, Switzerland. Our evaluation considers impacts on environmental sustainability, social welfare, and economic efficiency. The proposed framework provides a foundation for improving interdependent networked systems by enabling strategic cooperation among self-interested operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12059v4</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingjia He, Andrea Censi, Runyu Zhang, Emilio Frazzoli, Gioele Zardini</dc:creator>
    </item>
  </channel>
</rss>
