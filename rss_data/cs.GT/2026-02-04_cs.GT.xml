<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Feb 2026 08:34:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A two-player version of the assignment problem</title>
      <link>https://arxiv.org/abs/2602.02628</link>
      <description>arXiv:2602.02628v1 Announce Type: new 
Abstract: We introduce the competitive assignment problem, a two-player version of the well-known assignment problem. Given a set of tasks and a set of agents with different efficiencies for different tasks, Alice and Bob take turns picking agents one by one. Once all agents have been picked, Alice and Bob compute the optimal values $s_A$ and $s_B$ for the assignment problem on their respective sets of agents, i.e. they assign their own agents to tasks (with at most one agent per task and at most one task per agent) so as to maximize the sum of the efficiencies. The score of the game is then defined as $s_A-s_B$. Alice aims at maximizing the score, while Bob aims at minimizing it. This problem can model drafts in sports and card games, or more generally situations where two entities fight for the same resources and then use them to compete against each other. We show that the problem is PSPACE-complete, even restricted to agents that have at most two nonzero efficiencies. On the other hand, in the case of agents having at most one nonzero efficiency, the problem lies in XP parameterized by the number of tasks, and the optimal score can be computed in linear time when there are only two tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02628v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Florian Galliot, Nacim Oijid, Jonas S\'enizergues</dc:creator>
    </item>
    <item>
      <title>Internet of Agentic AI: Incentive-Compatible Distributed Teaming and Workflow</title>
      <link>https://arxiv.org/abs/2602.03145</link>
      <description>arXiv:2602.03145v1 Announce Type: new 
Abstract: Large language models (LLMs) have enabled a new class of agentic AI systems that reason, plan, and act by invoking external tools. However, most existing agentic architectures remain centralized and monolithic, limiting scalability, specialization, and interoperability. This paper proposes a framework for scalable agentic intelligence, termed the Internet of Agentic AI, in which autonomous, heterogeneous agents distributed across cloud and edge infrastructure dynamically form coalitions to execute task-driven workflows. We formalize a network-native model of agentic collaboration and introduce an incentive-compatible workflow-coalition feasibility framework that integrates capability coverage, network locality, and economic implementability. To enable scalable coordination, we formulate a minimum-effort coalition selection problem and propose a decentralized coalition formation algorithm. The proposed framework can operate as a coordination layer above the Model Context Protocol (MCP). A healthcare case study demonstrates how domain specialization, cloud-edge heterogeneity, and dynamic coalition formation enable scalable, resilient, and economically viable agentic workflows. This work lays the foundation for principled coordination and scalability in the emerging era of Internet of Agentic AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03145v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ya-Ting Yang, Quanyan Zhu</dc:creator>
    </item>
    <item>
      <title>Dynamic Programming for Epistemic Uncertainty in Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2602.03381</link>
      <description>arXiv:2602.03381v1 Announce Type: new 
Abstract: In this paper, we propose a general theory of ambiguity-averse MDPs, which treats the uncertain transition probabilities as random variables and evaluates a policy via a risk measure applied to its random return. This ambiguity-averse MDP framework unifies several models of MDPs with epistemic uncertainty for specific choices of risk measures. We extend the concepts of value functions and Bellman operators to our setting. Based on these objects, we establish the consequences of dynamic programming principles in this framework (existence of stationary policies, value and policy iteration algorithms), and we completely characterize law-invariant risk measures compatible with dynamic programming. Our work draws connections among several variants of MDP models and fully delineates what is possible under the dynamic programming paradigm and which risk measures require leaving it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03381v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Axel Benyamine, Julien Grand-Cl\'ement, Marek Petrik, Michael I. Jordan, Alain Durmus</dc:creator>
    </item>
    <item>
      <title>Toward a Sustainable Federated Learning Ecosystem: A Practical Least Core Mechanism for Payoff Allocation</title>
      <link>https://arxiv.org/abs/2602.03387</link>
      <description>arXiv:2602.03387v1 Announce Type: new 
Abstract: Emerging network paradigms and applications increasingly rely on federated learning (FL) to enable collaborative intelligence while preserving privacy. However, the sustainability of such collaborative environments hinges on a fair and stable payoff allocation mechanism. Focusing on coalition stability, this paper introduces a payoff allocation framework based on the least core (LC) concept. Unlike traditional methods, the LC prioritizes the cohesion of the federation by minimizing the maximum dissatisfaction among all potential subgroups, ensuring that no participant has an incentive to break away. To adapt this game-theoretic concept to practical, large-scale networks, we propose a streamlined implementation with a stack-based pruning algorithm, effectively balancing computational efficiency with allocation precision. Case studies in federated intrusion detection demonstrate that our mechanism correctly identifies pivotal contributors and strategic alliances. The results confirm that the practical LC framework promotes stable collaboration and fosters a sustainable FL ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03387v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengwei Ni, Zhidu Li, Wei Chen, Zhaoyang Zhang, Zehua Wang, F. Richard Yu, Victor C. M. Leung</dc:creator>
    </item>
    <item>
      <title>Sequential Linear Contracts on Matroids</title>
      <link>https://arxiv.org/abs/2602.03543</link>
      <description>arXiv:2602.03543v1 Announce Type: new 
Abstract: In this work, we study sequential contracts under matroid constraints. In the sequential setting, an agent can take actions one by one. After each action, the agent observes the stochastic value of the action and then decides which action to take next, if any. At the end, the agent decides what subset of taken actions to use for the principal's reward; and the principal receives the total value of this subset as a reward. Taking each action induces a certain cost for the agent. Thus, to motivate the agent to take actions the principal is expected to offer an appropriate contract. A contract describes the payment from the principal to the agent as a function of the principal's reward obtained through the agent's actions. In this work, we concentrate on studying linear contracts, i.e.\ the contracts where the principal transfers a fraction of their total reward to the agent. We assume that the total principal's reward is calculated based on a subset of actions that forms an independent set in a given matroid. We establish a relationship between the problem of finding an optimal linear contract (or computing the corresponding principal's utility) and the so called matroid (un)reliability problem. Generally, the above problems turn out to be equivalent subject to adding parallel copies of elements to the given matroid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03543v1</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kanstantsin Pashkovich, Jacob Skitsko, Yun Xing</dc:creator>
    </item>
    <item>
      <title>Efficient Investment in Multi-Agent Models of Public Transportation</title>
      <link>https://arxiv.org/abs/2602.03687</link>
      <description>arXiv:2602.03687v1 Announce Type: new 
Abstract: We study two stylized, multi-agent models aimed at investing a limited, indivisible resource in public transportation. In the first model, we face the decision of which potential stops to open along a (e.g., bus) path, given agents' travel demands. While it is known that utilitarian optimal solutions can be identified in polynomial time, we find that computing approximately optimal solutions with respect to egalitarian welfare is NP-complete. This is surprising as we operate on the simple topology of a line graph.
  In the second model, agents navigate a more complex network modeled by a weighted graph where edge weights represent distances. We face the decision of improving travel time along a fixed number of edges. We provide a polynomial-time algorithm that combines Dijkstra's algorithm with a dynamical program to find the optimal decision for one or two agents. By contrast, if the number of agents is variable, we find \np-completeness and inapproximability results for utilitarian and egalitarian welfare. Moreover, we demonstrate implications of our results for a related model of railway network design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03687v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Bullinger, Edith Elkind, Kassian K\"ock</dc:creator>
    </item>
    <item>
      <title>The Evolution of Lying in a Spatially-Explicit Prisoner's Dilemma Model</title>
      <link>https://arxiv.org/abs/2602.02587</link>
      <description>arXiv:2602.02587v1 Announce Type: cross 
Abstract: I present the results from a spatial model of the prisoner's dilemma, played on a toroidal lattice. Each individual has a default strategy of either cooperating ($C$) or defecting ($D$). Two strategies were tested, including ``tit-for-tat'' (TFT), in which individuals play their opponent's last play, or simply playing their default play. Each individual also has a probability of telling the truth ($0 \leq P_{truth} \leq 1$) about their last play. This parameter, which can evolve over time, allows individuals to be, for instance, a defector but present as a cooperator regarding their last play. This leads to interesting dynamics where mixed populations of defectors and cooperators with $P_{truth} \geq 0.75$ move toward populations of truth-telling cooperators. Likewise, mixed populations with $P_{truth} &lt; 0.7$ become populations of lying defectors. Both such populations are stable because they each have higher average scores than populations with intermediate values of $P_{truth}$. Applications of this model are discussed with regards to both humans and animals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02587v1</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.GT</category>
      <category>q-bio.PE</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gregg Hartvigsen</dc:creator>
    </item>
    <item>
      <title>Game-Theoretic and Algorithmic Analyses of Multi-Agent Routing under Crossing Costs</title>
      <link>https://arxiv.org/abs/2602.03455</link>
      <description>arXiv:2602.03455v1 Announce Type: cross 
Abstract: Coordinating the movement of multiple autonomous agents over a shared network is a fundamental challenge in algorithmic robotics, intelligent transportation, and distributed systems. The dominant approach, Multi-Agent Path Finding, relies on centralized control and synchronous collision avoidance, which often requires strict synchronization and guarantees of globally conflict-free execution. This paper introduces the Multi-Agent Routing under Crossing Cost model on mixed graphs, a novel framework tailored to asynchronous settings. In our model, instead of treating conflicts as hard constraints, each agent is assigned a path, and the system is evaluated through a cost function that measures potential head-on encounters. This ``crossing cost'', which is defined as the product of the numbers of agents traversing an edge in opposite directions, quantifies the risk of congestion and delay in decentralized execution.
  Our contributions are both game-theoretic and algorithmic. We model the setting as a congestion game with a non-standard cost function, prove the existence of pure Nash equilibria, and analyze the dynamics leading to them. Equilibria can be found in polynomial time under mild conditions, while the general case is PLS-complete. From an optimization perspective, minimizing the total crossing cost is NP-hard, as the problem generalizes Steiner Orientation. To address this hardness barrier, we design a suite of parameterized algorithms for minimizing crossing cost, with parameters including the number of arcs, edges, agents, and structural graph measures. These yield XP or FPT results depending on the parameter, offering algorithmic strategies for structurally restricted instances. Our framework provides a new theoretical foundation for decentralized multi-agent routing, bridging equilibrium analysis and parameterized complexity to support scalable and risk-aware coordination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03455v1</guid>
      <category>cs.MA</category>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tesshu Hanaka, Nikolaos Melissinos, Hirotaka Ono</dc:creator>
    </item>
    <item>
      <title>When Should Agents Coordinate in Differentiable Sequential Decision Problems?</title>
      <link>https://arxiv.org/abs/2602.03674</link>
      <description>arXiv:2602.03674v1 Announce Type: cross 
Abstract: Multi-robot teams must coordinate to operate effectively. When a team operates in an uncoordinated manner, and agents choose actions that are only individually optimal, the team's outcome can suffer. However, in many domains, coordination requires costly communication. We explore the value of coordination in a broad class of differentiable motion-planning problems. In particular, we model coordinated behavior as a spectrum: at one extreme, agents jointly optimize a common team objective, and at the other, agents make unilaterally optimal decisions given their individual decision variables, i.e., they operate at Nash equilibria. We then demonstrate that reasoning about coordination in differentiable motion-planning problems reduces to reasoning about the second-order properties of agents' objectives, and we provide algorithms that use this second-order reasoning to determine at which times a team of agents should coordinate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03674v1</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caleb Probine, Su Ann Low, David Fridovich-Keil, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>The Learning Approach to Games</title>
      <link>https://arxiv.org/abs/2503.00227</link>
      <description>arXiv:2503.00227v4 Announce Type: replace 
Abstract: This work introduces a unified framework for analyzing games in greater depth. In the existing literature, players' strategies are typically assigned scalar values, and equilibrium concepts are used to identify compatible choices. However, this approach neglects the internal structure of players, thereby failing to accurately model observed behaviors.
  To address this limitation, we propose an abstract definition of a player, consistent with constructions in reinforcement learning. Instead of defining games as external settings, our framework defines them in terms of the players themselves. This offers a language that enables a deeper connection between games and learning. To illustrate the need for this generality, we study a simple two-player game and show that even in basic settings, a sophisticated player may adopt dynamic strategies that cannot be captured by simpler models or compatibility analysis.
  For a general definition of a player, we discuss natural conditions on its components and define competition through their behavior. In the discrete setting, we consider players whose estimates largely follow the standard framework from the literature. We explore connections to correlated equilibrium and highlight that dynamic programming naturally applies to all estimates. In the mean-field setting, we exploit symmetry to construct explicit examples of equilibria. Finally, we conclude by examining relations to reinforcement learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00227v4</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Melih \.I\c{s}eri, Erhan Bayraktar</dc:creator>
    </item>
    <item>
      <title>Online Price Competition under Generalized Linear Demands</title>
      <link>https://arxiv.org/abs/2511.10718</link>
      <description>arXiv:2511.10718v5 Announce Type: replace 
Abstract: We study sequential price competition among $N$ sellers, each influenced by the pricing decisions of their rivals. Specifically, the demand function for each seller $i$ follows the single index model $\lambda_i(\mathbf{p}) = \mu_i(\langle \boldsymbol{\theta}_{i,0}, \mathbf{p} \rangle)$, with known increasing link $\mu_i$ and unknown parameter $\boldsymbol{\theta}_{i,0}$, where the vector $\mathbf{p}$ denotes the vector of prices offered by all the sellers simultaneously at a given instant. Each seller observes only their own realized demand -- unobservable to competitors -- and the prices set by rivals. Our framework generalizes existing approaches that focus solely on linear demand models. We propose a novel decentralized policy, PML-GLUCB, that combines penalized MLE with an upper-confidence pricing rule, removing the need for coordinated exploration phases across sellers -- which is integral to previous linear models -- and accommodating both binary and real-valued demand observations. Relative to a dynamic benchmark policy, each seller achieves $O(N^{2}\sqrt{T}\log(T))$ regret, which essentially matches the optimal rate known in the linear setting. A significant technical contribution of our work is the development of a variant of the elliptical potential lemma -- typically applied in single-agent systems -- adapted to our competitive multi-agent environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10718v5</guid>
      <category>cs.GT</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniele Bracale, Moulinath Banerjee, Cong Shi, Yuekai Sun</dc:creator>
    </item>
    <item>
      <title>Carry-Over Lottery Allocation: Practical Incentive-Compatible Drafts</title>
      <link>https://arxiv.org/abs/2602.02487</link>
      <description>arXiv:2602.02487v2 Announce Type: replace 
Abstract: The NBA Draft lottery is designed to promote competitive balance by awarding better draft positions to weaker teams, but it creates incentives to deliberately lose, a practice known as tanking. We propose a draft mechanism that is simultaneously practical, incentive-compatible, and advantages weaker teams. The Carry-Over Lottery Allocation (COLA) Draft Mechanism represents a paradigm shift in evaluating team quality, replacing a single season's standings with playoff outcomes over multiple years. COLA uses a draft lottery where every non-playoff team receives the same number of lottery tickets, removing incentives to lose additional games after elimination. Lottery tickets that do not win a top draft pick carry over to future lotteries, while playoff success or winning a top pick diminishes a team's accumulated tickets. Over time, COLA rewards teams with poor long-term performance and less prior draft assistance. By retaining the lottery format, COLA preserves transparency and fan engagement.
  Real-world implementation challenges are addressed to demonstrate feasibility, including transitioning from the current system, handling traded draft picks, and accommodating draft classes of varying strength. The most significant challenge occurs in years with exceptionally strong draft classes, where teams may prefer missing the playoffs in order to gain lottery access, violating a foundational assumption: that teams prefer playoff success to lottery participation. We provide a solution to this problem, employing a truth-elicitation mechanism to identify such years and expand lottery eligibility to include as many playoff teams as necessary to preserve anti-tanking incentives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02487v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Timothy Highley, Tannah Duncan, Ilia Volkov</dc:creator>
    </item>
    <item>
      <title>If It's Nice, Do It Twice: We Should Try Iterative Corpus Curation</title>
      <link>https://arxiv.org/abs/2501.15280</link>
      <description>arXiv:2501.15280v2 Announce Type: replace-cross 
Abstract: Recent work demonstrates that filtering harmful content from pretraining data improves model safety without degrading capabilities. We propose a natural extension: do it again. A model trained on filtered data can filter the corpus further; training on this cleaner corpus produces an even cleaner model. We provide theoretical analysis showing this process converges to a self-consistent corpus where the model trained on it approves of its own training data. Even under the weak assumption of constant filter quality, iteration yields decay in harmful content. We argue this framework offers a novel form of scalable oversight. While model internals are opaque, the resulting corpus is human-auditable. Even a single iteration produces a large-scale preference annotations over documents, potentially valuable for interpretability research. We derive bounds on capability-safety tradeoffs and outline open questions. We call on researchers with pretraining infrastructure to empirically test this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15280v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Robin Young</dc:creator>
    </item>
    <item>
      <title>Emergent Alignment via Competition</title>
      <link>https://arxiv.org/abs/2509.15090</link>
      <description>arXiv:2509.15090v2 Announce Type: replace-cross 
Abstract: Aligning AI systems with human values remains a fundamental challenge, but does our inability to create perfectly aligned models preclude obtaining the benefits of alignment? We study a strategic setting where a human user interacts with multiple differently misaligned AI agents, none of which are individually well-aligned. Our key insight is that when the users utility lies approximately within the convex hull of the agents utilities, a condition that becomes easier to satisfy as model diversity increases, strategic competition can yield outcomes comparable to interacting with a perfectly aligned model. We model this as a multi-leader Stackelberg game, extending Bayesian persuasion to multi-round conversations between differently informed parties, and prove three results: (1) when perfect alignment would allow the user to learn her Bayes-optimal action, she can also do so in all equilibria under the convex hull condition (2) under weaker assumptions requiring only approximate utility learning, a non-strategic user employing quantal response achieves near-optimal utility in all equilibria and (3) when the user selects the best single AI after an evaluation period, equilibrium guarantees remain near-optimal without further distributional assumptions. We complement the theory with two sets of experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15090v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Natalie Collina, Surbhi Goel, Aaron Roth, Emily Ryu, Mirah Shi</dc:creator>
    </item>
    <item>
      <title>The incompatibility of the Condorcet winner and loser criteria with positive involvement and resolvability</title>
      <link>https://arxiv.org/abs/2601.10506</link>
      <description>arXiv:2601.10506v5 Announce Type: replace-cross 
Abstract: We prove that there is no preferential voting method satisfying the Condorcet winner and loser criteria, positive involvement (if a candidate $x$ wins in an initial preference profile, then adding a voter who ranks $x$ uniquely first cannot cause $x$ to lose), and $n$-voter resolvability (if $x$ initially ties for winning, then $x$ can be made the unique winner by adding some set of up to $n$ voters). This impossibility theorem holds for any positive integer $n$. It also holds if either the Condorcet loser criterion is replaced by independence of clones or positive involvement is replaced by negative involvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10506v5</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday</dc:creator>
    </item>
  </channel>
</rss>
