<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.med-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.med-ph</link>
    <description>physics.med-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.med-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 31 Jul 2024 04:00:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 31 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Integrating audiological datasets via federated merging of Auditory Profiles</title>
      <link>https://arxiv.org/abs/2407.20765</link>
      <description>arXiv:2407.20765v1 Announce Type: new 
Abstract: Audiological datasets contain valuable knowledge about hearing loss in patients, which can be uncovered using data-driven, federated learning techniques. Our previous approach summarized patient information from one audiological dataset into distinct Auditory Profiles (APs). To cover the complete audiological patient population, however, patient patterns must be analyzed across multiple, separated datasets, and finally, be integrated into a combined set of APs. This study aimed at extending the existing profile generation pipeline with an AP merging step, enabling the combination of APs from different datasets based on their similarity across audiological measures. The 13 previously generated APs (NA=595) were merged with 31 newly generated APs from a second dataset (NB=1272) using a similarity score derived from the overlapping densities of common features across the two datasets. To ensure clinical applicability, random forest models were created for various scenarios, encompassing different combinations of audiological measures. A new set with 13 combined APs is proposed, providing well-separable profiles, which still capture detailed patient information from various test outcome combinations. The classification performance across these profiles is satisfactory. The best performance was achieved using a combination of loudness scaling, audiogram and speech test information, while single measures performed worst. The enhanced profile generation pipeline demonstrates the feasibility of combining APs across datasets, which should generalize to all datasets and could lead to an interpretable population-based profile set in the future. The classification models maintain clinical applicability. Hence, even if only smartphone-based measures are available, a given patient can be classified into an appropriate AP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20765v1</guid>
      <category>physics.med-ph</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samira Saak, Dirk Oetting, Birger Kollmeier, Mareike Buhl</dc:creator>
    </item>
    <item>
      <title>Simultaneous Multi-Slice Diffusion Imaging using Navigator-free Multishot Spiral Acquisition</title>
      <link>https://arxiv.org/abs/2407.20904</link>
      <description>arXiv:2407.20904v1 Announce Type: new 
Abstract: Purpose: This work aims to raise a novel design for navigator-free multiband (MB) multishot uniform-density spiral (UDS) acquisition and reconstruction, and to demonstrate its utility for high-efficiency, high-resolution diffusion imaging. Theory and Methods: Our design focuses on the acquisition and reconstruction of navigator-free MB multishot UDS diffusion imaging. For acquisition, radiofrequency (RF) pulse encoding was employed to achieve Controlled Aliasing in Parallel Imaging (CAIPI) in MB imaging. For reconstruction, a new algorithm named slice-POCS-enhanced Inherent Correction of phase Errors (slice-POCS-ICE) was proposed to simultaneously estimate diffusion-weighted images and inter-shot phase variations for each slice. The efficacy of the proposed methods was evaluated in both numerical simulation and in vivo experiments. Results: In both numerical simulation and in vivo experiments, slice-POCS-ICE estimated phase variations more precisely and provided results with better image quality than other methods. The inter-shot phase variations and MB slice aliasing artifacts were simultaneously resolved using the proposed slice-POCS-ICE algorithm. Conclusion: The proposed navigator-free MB multishot UDS acquisition and reconstruction method is an effective solution for high-efficiency, high-resolution diffusion imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20904v1</guid>
      <category>physics.med-ph</category>
      <category>eess.IV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuancheng Jiang, Guangqi Li, Xin Shao, Hua Guo</dc:creator>
    </item>
    <item>
      <title>vSHARP: variable Splitting Half-quadratic Admm algorithm for Reconstruction of inverse-Problems</title>
      <link>https://arxiv.org/abs/2309.09954</link>
      <description>arXiv:2309.09954v2 Announce Type: replace-cross 
Abstract: Medical Imaging (MI) tasks, such as accelerated parallel Magnetic Resonance Imaging (MRI), often involve reconstructing an image from noisy or incomplete measurements. This amounts to solving ill-posed inverse problems, where a satisfactory closed-form analytical solution is not available. Traditional methods such as Compressed Sensing (CS) in MRI reconstruction can be time-consuming or prone to obtaining low-fidelity images. Recently, a plethora of Deep Learning (DL) approaches have demonstrated superior performance in inverse-problem solving, surpassing conventional methods. In this study, we propose vSHARP (variable Splitting Half-quadratic ADMM algorithm for Reconstruction of inverse Problems), a novel DL-based method for solving ill-posed inverse problems arising in MI. vSHARP utilizes the Half-Quadratic Variable Splitting method and employs the Alternating Direction Method of Multipliers (ADMM) to unroll the optimization process. For data consistency, vSHARP unrolls a differentiable gradient descent process in the image domain, while a DL-based denoiser, such as a U-Net architecture, is applied to enhance image quality. vSHARP also employs a dilated-convolution DL-based model to predict the Lagrange multipliers for the ADMM initialization. We evaluate vSHARP on tasks of accelerated parallel MRI Reconstruction using two distinct datasets and on accelerated parallel dynamic MRI Reconstruction using another dataset. Our comparative analysis with state-of-the-art methods demonstrates the superior performance of vSHARP in these applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09954v2</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>physics.med-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Yiasemis, Nikita Moriakov, Jan-Jakob Sonke, Jonas Teuwen</dc:creator>
    </item>
    <item>
      <title>JSSL: Joint Supervised and Self-supervised Learning for MRI Reconstruction</title>
      <link>https://arxiv.org/abs/2311.15856</link>
      <description>arXiv:2311.15856v2 Announce Type: replace-cross 
Abstract: Purpose: MRI represents an important diagnostic modality; however, its inherently slow acquisition process poses challenges in obtaining fully-sampled k-space data under motion. In the absence of fully-sampled acquisitions, serving as ground truths, training deep learning algorithms in a supervised manner to predict the underlying ground truth image becomes challenging. To address this limitation, self-supervised methods have emerged as a viable alternative, leveraging available subsampled k-space data to train deep neural networks for MRI reconstruction. Nevertheless, these approaches often fall short when compared to supervised methods.
  Methods: We propose Joint Supervised and Self-supervised Learning (JSSL), a novel training approach for deep learning-based MRI reconstruction algorithms aimed at enhancing reconstruction quality in cases where target datasets containing fully-sampled k-space measurements are unavailable. JSSL operates by simultaneously training a model in a self-supervised learning setting, using subsampled data from the target dataset(s), and in a supervised learning manner, utilizing datasets with fully-sampled k-space data, referred to as proxy datasets. We demonstrate JSSL's efficacy using subsampled prostate or cardiac MRI data as the target datasets, with fully-sampled brain and knee, or brain, knee and prostate k-space acquisitions, respectively, as proxy datasets.
  Results: Our results showcase substantial improvements over conventional self-supervised methods, validated using common image quality metrics. Furthermore, we provide theoretical motivations for JSSL and establish rule-of-thumb guidelines for training MRI reconstruction models.
  Conclusion: JSSL effectively enhances MRI reconstruction quality in scenarios where fully-sampled k-space data is not available, leveraging the strengths of supervised learning by incorporating proxy datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15856v2</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>physics.med-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Yiasemis, Nikita Moriakov, Clara I. S\'anchez, Jan-Jakob Sonke, Jonas Teuwen</dc:creator>
    </item>
  </channel>
</rss>
