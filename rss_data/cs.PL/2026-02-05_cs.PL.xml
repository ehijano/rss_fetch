<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Feb 2026 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>CSLib: The Lean Computer Science Library</title>
      <link>https://arxiv.org/abs/2602.04846</link>
      <description>arXiv:2602.04846v1 Announce Type: cross 
Abstract: We introduce CSLib, an open-source framework for proving computer-science-related theorems and writing formally verified code in the Lean proof assistant. CSLib aims to be for computer science what Lean's Mathlib is for mathematics. Mathlib has been tremendously impactful: it is a key reason for Lean's popularity within the mathematics research community, and it has also played a critical role in the training of AI systems for mathematical reasoning. However, the base of computer science knowledge in Lean is currently quite limited. CSLib will vastly enhance this knowledge base and provide infrastructure for using this knowledge in real-world verification projects. By doing so, CSLib will (1) enable the broad use of Lean in computer science education and research, and (2) facilitate the manual and AI-aided engineering of large-scale formally verified systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04846v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Clark Barrett, Swarat Chaudhuri, Fabrizio Montesi, Jim Grundy, Pushmeet Kohli, Leonardo de Moura, Alexandre Rademaker, Sorrachai Yingchareonthawornchai</dc:creator>
    </item>
    <item>
      <title>Getting Python Types Right with RightTyper</title>
      <link>https://arxiv.org/abs/2507.16051</link>
      <description>arXiv:2507.16051v2 Announce Type: replace 
Abstract: Python type annotations enable static type checking, but most code remains untyped because manual annotation is time-consuming and tedious. Past approaches to automatic type inference fall short: static methods struggle with dynamic features and infer overly broad types; AI-based methods are unsound and miss rare types; and dynamic methods impose extreme overheads (up to 270x), lack important language support such as inferring variable types, or produce annotations that cause runtime errors.
  This paper presents RightTyper, a novel hybrid approach for Python that produces accurate and precise type annotations grounded in actual program behavior. RightTyper grounds inference in types observed during actual program execution and combines these observations with static analysis and name resolution to produce substantially higher-quality type annotations than prior approaches. Through principled, statistically guided adaptive sampling, RightTyper balances runtime overhead with the need to observe sufficient execution behavior to infer high-quality type annotations. We evaluate RightTyper against static, dynamic, and AI-based systems on both synthetic benchmarks and real-world code, and find that it consistently achieves higher semantic similarity to ground-truth and developer-written annotations, respectively, while incurring only approximately 25% runtime overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16051v2</guid>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Altmayer Pizzorno, Emery D. Berger</dc:creator>
    </item>
    <item>
      <title>REASONING COMPILER: LLM-Guided Optimizations for Efficient Model Serving</title>
      <link>https://arxiv.org/abs/2506.01374</link>
      <description>arXiv:2506.01374v5 Announce Type: replace-cross 
Abstract: While model serving has unlocked unprecedented capabilities, the high cost of serving large-scale models continues to be a significant barrier to widespread accessibility and rapid innovation. Compiler optimizations have long driven substantial performance improvements, but existing compilers struggle with neural workloads due to the exponentially large and highly interdependent space of possible transformations. Although existing stochastic search techniques can be effective, they are often sample-inefficient and fail to leverage the structural context underlying compilation decisions. We set out to investigate the research question of whether reasoning with large language models (LLMs), without any retraining, can leverage the context-aware decision space of compiler optimizations to significantly improve sample efficiency. To that end, we introduce a novel compilation framework (dubbed REASONING COMPILER) that formulates optimization as a sequential, context-aware decision process guided by a large language model and structured Monte Carlo tree search (MCTS). The LLM acts as a proposal mechanism, suggesting hardware-informed transformations that reflect the current program state and accumulated performance feedback. MCTS incorporates the LLM-generated proposals to balance exploration and exploitation, facilitating a structured, context-sensitive traversal of the expansive compiler optimization space. By achieving substantial speedups with markedly fewer samples than leading neural compilers, our approach demonstrates the potential of LLM-guided reasoning to transform the landscape of compiler optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01374v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Annabelle Sujun Tang, Christopher Priebe, Rohan Mahapatra, Lianhui Qin, Hadi Esmaeilzadeh</dc:creator>
    </item>
  </channel>
</rss>
