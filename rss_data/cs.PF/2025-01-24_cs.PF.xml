<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PF</link>
    <description>cs.PF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Jan 2025 05:01:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Accelerating Gaussian beam tracing method with dynamic parallelism on graphics processing units</title>
      <link>https://arxiv.org/abs/2501.13382</link>
      <description>arXiv:2501.13382v1 Announce Type: new 
Abstract: This study presents a reconstruction of the Gaussian Beam Tracing solution using CUDA, with a particular focus on the utilisation of GPU acceleration as a means of overcoming the performance limitations of traditional CPU algorithms in complex acoustic simulations. The algorithm is implemented and optimised on the NVIDIA RTX A6000 GPU, resulting in a notable enhancement in the performance of the Gaussian Beam Summation (GBS) process. In particular, the GPU-accelerated GBS algorithm demonstrated a significant enhancement in performance, reaching up to 790 times faster in city enviroment and 188 times faster in open plane enviroment compared to the original CPU-based program. To address the challenges of acceleration, the study introduce innovative solutions for handling irregular loops and GPU memory limitations, ensuring the efficient processing of large quantities of rays beyond the GPU's single-process capacity. Furthermore, this work established performance evaluation strategies crucial for analysing and reconstructing similar algorithms. Additionally, the study explored future directions for further accelerating the algorithm, laying the groundwork for ongoing improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13382v1</guid>
      <category>cs.PF</category>
      <category>cs.DC</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhang Sheng, Lishu Duan, Hanbo Jiang</dc:creator>
    </item>
    <item>
      <title>Compiler Support for Speculation in Decoupled Access/Execute Architectures</title>
      <link>https://arxiv.org/abs/2501.13553</link>
      <description>arXiv:2501.13553v1 Announce Type: new 
Abstract: Irregular codes are bottlenecked by memory and communication latency. Decoupled access/execute (DAE) is a common technique to tackle this problem. It relies on the compiler to separate memory address generation from the rest of the program, however, such a separation is not always possible due to control and data dependencies between the access and execute slices, resulting in a loss of decoupling.
  In this paper, we present compiler support for speculation in DAE architectures that preserves decoupling in the face of control dependencies. We speculate memory requests in the access slice and poison mis-speculations in the execute slice without the need for replays or synchronization. Our transformation works on arbitrary, reducible control flow and is proven to preserve sequential consistency. We show that our approach applies to a wide range of architectural work on CPU/GPU prefetchers, CGRAs, and accelerators, enabling DAE on a wider range of codes than before.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13553v1</guid>
      <category>cs.PF</category>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3708493.3712695</arxiv:DOI>
      <dc:creator>Robert Szafarczyk, Syed Waqar Nabi, Wim Vanderbauwhede</dc:creator>
    </item>
    <item>
      <title>Need for Speed: A Comprehensive Benchmark of JPEG Decoders in Python</title>
      <link>https://arxiv.org/abs/2501.13131</link>
      <description>arXiv:2501.13131v1 Announce Type: cross 
Abstract: Image loading represents a critical bottleneck in modern machine learning pipelines, particularly in computer vision tasks where JPEG remains the dominant format. This study presents a systematic performance analysis of nine popular Python JPEG decoding libraries on different computing architectures. We benchmark traditional image processing libraries (Pillow, OpenCV), machine learning frameworks (TensorFlow, PyTorch), and specialized decoders (jpeg4py, kornia-rs) on both ARM64 (Apple M4 Max) and x86\_64 (AMD Threadripper) platforms. Our findings reveal that modern implementations using libjpeg-turbo achieve up to 1.5x faster decoding speeds compared to traditional approaches. We provide evidence-based recommendations for choosing optimal JPEG decoders across different scenarios, from high-throughput training pipelines to real-time applications. This comprehensive analysis helps practitioners make informed decisions about image loading infrastructure, potentially reducing training times and improving system efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13131v1</guid>
      <category>eess.IV</category>
      <category>cs.PF</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladimir Iglovikov</dc:creator>
    </item>
    <item>
      <title>Deciphering boundary layer dynamics in high-Rayleigh-number convection using 3360 GPUs and a high-scaling in-situ workflow</title>
      <link>https://arxiv.org/abs/2501.13240</link>
      <description>arXiv:2501.13240v1 Announce Type: cross 
Abstract: Turbulent heat and momentum transfer processes due to thermal convection cover many scales and are of great importance for several natural and technical flows. One consequence is that a fully resolved three-dimensional analysis of these turbulent transfers at high Rayleigh numbers, which includes the boundary layers, is possible only using supercomputers. The visualization of these dynamics poses an additional hurdle since the thermal and viscous boundary layers in thermal convection fluctuate strongly. In order to track these fluctuations continuously, data must be tapped at high frequency for visualization, which is difficult to achieve using conventional methods. This paper makes two main contributions in this context. First, it discusses the simulations of turbulent Rayleigh-B\'enard convection up to Rayleigh numbers of $Ra=10^{12}$ computed with NekRS on GPUs. The largest simulation was run on 840 nodes with 3360 GPU on the JUWELS Booster supercomputer. Secondly, an in-situ workflow using ASCENT is presented, which was successfully used to visualize the high-frequency turbulent fluctuations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13240v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.PF</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 24 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathis Bode, Damian Alvarez, Paul Fischer, Christos E. Frouzakis, Jens Henrik G\"obbert, Joseph A. Insley, Yu-Hsiang Lan, Victor A. Mateevitsi, Misun Min, Michael E. Papka, Silvio Rizzi, Roshan J. Samuel, J\"org Schumacher</dc:creator>
    </item>
  </channel>
</rss>
