<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Nov 2024 05:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Adaptive Sensor Placement Inspired by Bee Foraging: Towards Efficient Environment Monitoring</title>
      <link>https://arxiv.org/abs/2411.15159</link>
      <description>arXiv:2411.15159v1 Announce Type: new 
Abstract: This paper aims to make a mark in the future of sustainable robotics, where efficient algorithms are required to carry out tasks like environmental monitoring and precision agriculture efficiently. We proposed a hybrid algorithm that combines Artificial Bee Colony (ABC) with Levy flight to optimize adaptive sensor placement alongside an important notion of hotspots from domain knowledge experts. By enhancing exploration and exploitation, our approach significantly improves the identification of critical hotspots. This algorithm also finds its usecases for broader search and rescue operations applications, demonstrating its potential in optimization problems across various domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15159v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>cs.RO</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sai Krishna Reddy Sathi</dc:creator>
    </item>
    <item>
      <title>Optimally Controlling a Random Population</title>
      <link>https://arxiv.org/abs/2411.15181</link>
      <description>arXiv:2411.15181v1 Announce Type: new 
Abstract: The random population control decision problem asks for the existence of a controller capable of gathering almost-surely a whole population of identical finite-state agents simultaneously in a final state. The controller must be able to satisfy this requirement however large the population, provided that it is finite. The problem was previously known to be decidable and EXPTIME-hard. This paper tackles the exact complexity: the problem is EXPTIME-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15181v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hugo Gimbert, Corto Mascle, Patrick Totzke</dc:creator>
    </item>
    <item>
      <title>On the nonlinear programming problems subject to a system of generalized bipolar fuzzy relational equalities defined with continuous t-norms</title>
      <link>https://arxiv.org/abs/2411.15225</link>
      <description>arXiv:2411.15225v1 Announce Type: new 
Abstract: This paper, in the first step, develops the system of bipolar fuzzy relational equations (FRE) to the most general case where the bipolar FREs are defined by an arbitrary continuous t-norm. Also, since fuzzy relational equations are special cases of the bipolar FREs, the proposed system can be also interpreted as a generalization of traditional FREs where the fuzzy compositions are generally defined by any continuous t-norm. The consistency of the continuous bipolar FREs is initially investigated and some necessary and sufficient conditions are derived for determining the feasibility of the proposed system. Subsequently, the feasible solutions set of the problem is completely characterized. It is shown that unlike FREs and those bipolar FREs defined by continuous Archimedean t-norms, the feasible solutions set of the generalized bipolar FREs is formed as the union of a finite number of compact sets that are not necessarily connected. Moreover, five techniques have also been introduced with the aim of simplifying the current problem, and then an algorithm is accordingly presented to find the feasible region of the problem. In the second step, a new class of optimization models is studied where the constraints are defined by the continuous bipolar FREs and the objective function covers a wide range of (non)linear functions such as maximum function, geometric mean function, log-sum-exp function, maximum eigenvalue of a symmetric matrix, support function of a set, etc. It is proved that the problem has a finite number of local optimal solutions and a global optimal solution can always be obtained by choosing a point having the minimum objective value compared to all the local optimal solutions. Finally, to illustrate the discussed study, a step-by-step example is described in several sections, whose constraints are a system of the bipolar FRES defined by Dubois-Prade t-norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15225v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Amin Ghodousian, Mohammad Sedigh Chopannavaz</dc:creator>
    </item>
    <item>
      <title>Gradient Mittag-Leffler and strong stabilizability of time fractional diffusion processes</title>
      <link>https://arxiv.org/abs/2411.15280</link>
      <description>arXiv:2411.15280v1 Announce Type: new 
Abstract: This paper deals with the gradient stability and the gradient stabilizability of Caputo time fractional diffusion linear systems. First, we give sufficient conditions that allow the gradient Mittag-Leffler and strong stability, where we use a direct method based essentially on the spectral properties of the system dynamic. Moreover, we consider a class of linear and distributed feedback controls that Mittag-Leffler and strongly stabilize the state gradient. The proposed results lead to an algorithm that allows us to gradient stabilize the state of the fractional systems under consideration. Finally, we illustrate the effectiveness of the developed algorithm by a numerical example and simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15280v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanaa Zitane, Delfim F. M. Torres</dc:creator>
    </item>
    <item>
      <title>Sparse Polynomial Matrix Optimization</title>
      <link>https://arxiv.org/abs/2411.15479</link>
      <description>arXiv:2411.15479v1 Announce Type: new 
Abstract: A polynomial matrix inequality is a statement that a symmetric polynomial matrix is positive semidefinite over a given constraint set. Polynomial matrix optimization concerns minimizing the smallest eigenvalue of a symmetric polynomial matrix subject to a tuple of polynomial matrix inequalities. This work explores the use of sparsity methods in reducing the complexity of sum-of-squares based methods in verifying polynomial matrix inequalities or solving polynomial matrix optimization. In the unconstrained setting, Newton polytopes can be employed to sparsify the monomial basis, resulting in smaller semidefinite programs. In the general setting, we show how to exploit different types of sparsity (term sparsity, correlative sparsity, matrix sparsity) encoded in polynomial matrices to derive sparse semidefinite programming relaxations for polynomial matrix optimization. For term sparsity, one intriguing phenomenon is that the related block structures do not necessarily converge to the one determined by sign symmetries, which is significantly distinguished from the scalar case. For correlative sparsity, unlike the scalar case, we provide a counterexample showing that asymptotic convergence does not hold under the Archimedean condition and the running intersection property. By employing the theory of matrix-valued measures, we establish several results on detecting global optimality and retrieving optimal solutions under correlative sparsity. The effectiveness of sparsity methods on reducing computational complexity is demonstrated on various examples of polynomial matrix optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15479v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jared Miller, Jie Wang, Feng Guo</dc:creator>
    </item>
    <item>
      <title>Gradient Norm Regularization Second-Order Algorithms for Solving Nonconvex-Strongly Concave Minimax Problems</title>
      <link>https://arxiv.org/abs/2411.15769</link>
      <description>arXiv:2411.15769v1 Announce Type: new 
Abstract: In this paper, we study second-order algorithms for solving nonconvex-strongly concave minimax problems, which have attracted much attention in recent years in many fields, especially in machine learning. We propose a gradient norm regularized trust region (GRTR) algorithm to solve nonconvex-strongly concave minimax problems, where the objective function of the trust region subproblem in each iteration uses a regularized version of the Hessian matrix, and the regularization coefficient and the radius of the ball constraint are proportional to the square root of the gradient norm. The iteration complexity of the proposed GRTR algorithm to obtain an $\mathcal{O}(\epsilon,\sqrt{\epsilon})$-second-order stationary point is proved to be upper bounded by $\tilde{\mathcal{O}}(\rho^{0.5}\kappa^{1.5}\epsilon^{-3/2})$, where $\rho$ and $\kappa$ are the Lipschitz constant of the Jacobian matrix and the condition number of the objective function respectively, which matches the best known iteration complexity of second-order methods for solving nonconvex-strongly concave minimax problems. We further propose a Levenberg-Marquardt algorithm with a gradient norm regularization coefficient and use the negative curvature direction to correct the iteration direction (LMNegCur), which does not need to solve the trust region subproblem at each iteration. We also prove that the LMNegCur algorithm achieves an $\mathcal{O}(\epsilon,\sqrt{\epsilon})$-second-order stationary point within $\tilde{\mathcal{O}}(\rho^{0.5}\kappa^{1.5}\epsilon^{-3/2})$ number of iterations. Numerical results show the efficiency of both proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15769v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun-Lin Wang, Zi Xu</dc:creator>
    </item>
    <item>
      <title>Proximal methods for structured nonsmooth optimization over Riemannian submanifolds</title>
      <link>https://arxiv.org/abs/2411.15776</link>
      <description>arXiv:2411.15776v1 Announce Type: new 
Abstract: In this paper, we consider a class of structured nonsmooth optimization problems over an embedded submanifold of a Euclidean space, where the first part of the objective is the sum of a difference-of-convex (DC) function and a smooth function, while the remaining part is the square of a weakly convex function over a smooth function. This model problem has many important applications in machine learning and scientific computing, for example, the sparse generalized eigenvalue problem. We propose a manifold proximal-gradient-subgradient algorithm (MPGSA) and show that under mild conditions any accumulation point of the solution sequence generated by it is a critical point of the underlying problem. By assuming the Kurdyka-{\L}ojasiewicz property of an auxiliary function, we further establish the convergence of the full sequence generated by MPGSA under some suitable conditions. When the second component of the DC function involved is the maximum of finite continuously differentiable convex functions, we also propose an enhanced MPGSA with guaranteed subsequential convergence to a lifted B-stationary points of the optimization problem. Finally, some preliminary numerical experiments are conducted to illustrate the efficiency of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15776v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qia Li, Na Zhang, Hanwei Yan</dc:creator>
    </item>
    <item>
      <title>Stable gradient-adjusted root mean square propagation on least squares problem</title>
      <link>https://arxiv.org/abs/2411.15877</link>
      <description>arXiv:2411.15877v1 Announce Type: new 
Abstract: Root mean square propagation (abbreviated as RMSProp) is a first-order stochastic algorithm used in machine learning widely. In this paper, a stable gradient-adjusted RMSProp (abbreviated as SGA-RMSProp) with mini-batch stochastic gradient is proposed for the linear least squares problem. R-linear convergence of the algorithm is established on the consistent linear least squares problem. The algorithm is also proved to converge R-linearly to a neighborhood of the minimizer for the inconsistent case, with the region of the neighborhood being controlled by the batch size. Furthermore, numerical experiments are conducted to compare the performances of SGA-RMSProp and stochastic gradient descend (abbreviated as SGD) with different batch sizes. The faster initial convergence rate of SGA-RMSProp is observed through numerical experiments and an adaptive strategy for switching from SGA-RMSProp to SGD is proposed, which combines the benefits of these two algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15877v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runze Li, Jintao Xu, Wenxun Xing</dc:creator>
    </item>
    <item>
      <title>Further extensions on the successive approximation method for hierarchical optimal control problems and its application to learning</title>
      <link>https://arxiv.org/abs/2411.15889</link>
      <description>arXiv:2411.15889v1 Announce Type: new 
Abstract: In this paper, further extensions of the result of the paper "A successive approximation method in functional spaces for hierarchical optimal control problems and its application to learning, arXiv:2410.20617 [math.OC], 2024" concerning a class of learning problem of point estimations for modeling of high-dimensional nonlinear functions are given. In particular, we present two viable extensions within the nested algorithm of the successive approximation method for the hierarchical optimal control problem, that provide better convergence property and computationally efficiency, which ultimately leading to an optimal parameter estimate. The first extension is mainly concerned with the convergence property of the steps involving how the two agents, i.e., the "leader" and the "follower," update their admissible control strategies, where we introduce augmented Hamiltonians for both agents and we further reformulate the admissible control updating steps as as sub-problems within the nested algorithm of the hierarchical optimal control problem that essentially provide better convergence property. Whereas the second extension is concerned with the computationally efficiency of the steps involving how the agents update their admissible control strategies, where we introduce intermediate state variable for each agent and we further embed the intermediate states within the optimal control problems of the "leader" and the "follower," respectively, that further lend the admissible control updating steps to be fully efficient time-parallelized within the nested algorithm of the hierarchical optimal control problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15889v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Getachew K. Befekadu</dc:creator>
    </item>
    <item>
      <title>Analytical Pursuit-Evasion Game Strategy in Arbitrary Keplerian Reference Orbits</title>
      <link>https://arxiv.org/abs/2411.15912</link>
      <description>arXiv:2411.15912v1 Announce Type: new 
Abstract: This paper focuses on developing an analytical strategy for the linear quadratic (LQ) pursuit-evasion game in arbitrary Keplerian reference orbits. The motion of the pursuer and evader is described using the controlled Tschauner-Hempel equations, and the strategy for the pursuit-evasion game is presented from the solution of the differential Riccati equation (DRE). An analytical solution of the DRE is derived for elliptic, parabolic, and hyperbolic reference orbits, thereby leading to an analytical pursuit-evasion game strategy. Based on this analytical strategy, a semi-analytical procedure to solve the pursuit-evasion game equations is proposed. Results obtained from the proposed semi-analytical procedure are in good agreement\deleted{ with} with those obtained from the numerical one. The comparison between the semi-analytical procedure and the numerical one illustrates that the proposed semi-analytical procedure reduces the computation time by more than 99.8% compared to the numerical one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15912v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shuyue Fu, Shengping Gong, Peng Shi</dc:creator>
    </item>
    <item>
      <title>The Proximal Bundle Algorithm Under a Frank-Wolfe Perspective: an Improved Complexity Analysis</title>
      <link>https://arxiv.org/abs/2411.15926</link>
      <description>arXiv:2411.15926v1 Announce Type: new 
Abstract: The proximal bundle algorithm (PBA) is a fundamental and computationally effective algorithm for solving optimization problems with nonsmooth components. We investigate its convergence rate, focusing on composite settings where one function is smooth and the other is piecewise linear. We interpret a sequence of null steps of the PBA as a Frank-Wolfe algorithm on the Moreau envelope of the dual problem. In light of this correspondence, we first extend the linear convergence of Kelley's method on convex piecewise linear functions from the positive homogeneous to the general case. Building on this result, we propose a novel complexity analysis of PBA and derive a $\mathcal{O}(\epsilon^{-4/5})$ iteration complexity, improving upon the best known $\mathcal{O}(\epsilon^{-2})$ guarantee. This approach also unveils new insights on bundle management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15926v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David Fersztand, Xu Andy Sun</dc:creator>
    </item>
    <item>
      <title>When Does Primal Interior Point Method Beat Primal-dual in Linear Optimization?</title>
      <link>https://arxiv.org/abs/2411.16015</link>
      <description>arXiv:2411.16015v1 Announce Type: new 
Abstract: The primal-dual interior point method (IPM) is widely regarded as the most efficient IPM variant for linear optimization. In this paper, we demonstrate that the improved stability of the pure primal IPM can allow speedups relative to a primal-dual solver, particularly as the IPM approaches convergence. The stability of the primal scaling matrix makes it possible to accelerate each primal IPM step using fast preconditioned iterative solvers for the normal equations. Crucially, we identify properties of the central path that make it possible to stabilize the normal equations. Experiments on benchmark datasets demonstrate the efficiency of primal IPM and showcase its potential for practical applications in linear optimization and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16015v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wenzhi Gao, Huikang Liu, Yinyu Ye, Madeleine Udell</dc:creator>
    </item>
    <item>
      <title>Input-Output Stability of Gradient Descent: A Discrete-Time Passivity-Based Approach</title>
      <link>https://arxiv.org/abs/2411.16074</link>
      <description>arXiv:2411.16074v1 Announce Type: new 
Abstract: This paper presents a discrete-time passivity-based analysis of the gradient descent method for a class of functions with sector-bounded gradients. Using a loop transformation, it is shown that the gradient descent method can be interpreted as a passive controller in negative feedback with a very strictly passive system. The passivity theorem is then used to guarantee input-output stability, as well as the global convergence, of the gradient descent method. Furthermore, provided that the lower and upper sector bounds are not equal, the input-output stability of the gradient descent method is guaranteed using the weak passivity theorem for a larger choice of step size. Finally, to demonstrate the utility of this passivity-based analysis, a new variation of the gradient descent method with variable step size is proposed by gain-scheduling the input and output of the gradient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16074v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sepehr Moalemi, James Richard Forbes</dc:creator>
    </item>
    <item>
      <title>Infinite-dimensional Convex Cones: Internal Geometric Structure and Analytical Representation</title>
      <link>https://arxiv.org/abs/2411.16209</link>
      <description>arXiv:2411.16209v1 Announce Type: new 
Abstract: In the paper we consider convex cones in infinite-dimensional real vector spaces which are endowed with no topology. The main purpose is to study an internal geometric structure of convex cones and to obtain an analytical description of those. To this end, we first introduce the notion of an open component of a convex cone and then prove that an arbitrary convex cone is the disjoint union of the partial ordered family of its open components and, moreover, as an ordered set this family is an upper semilattice. We identify the structure of this upper semilattice with the internal geometric structure of a convex cone. We demonstrate that the internal geometric structure of a convex cone is related to its facial structure but in the infinite-dimensional setting these two structures may differ each other. Further, we study the internal geometric structure of conical halfspaces (convex cones whose complements are also convex cones). We show that every conical halfspace is the disjoint union of the linear ordered family of its open components each of which is a conical halfspace in its linear hull. Using the internal geometric structure of conical halfspaces, each asymmetric conical halfspace is associated with a linearly ordered family of linear functions, which generates in turn a real-valued function, called a step-linear one, analytically describing this conical halfspace. At last, we establish that an arbitrary asymmetric convex cone admits an analytical representation by the family of step-linear functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16209v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valentin V. Gorokhovik</dc:creator>
    </item>
    <item>
      <title>New Multi-objective Partial Optimisation Decomposition Strategies for the Thesis Defence Scheduling Problem</title>
      <link>https://arxiv.org/abs/2411.16297</link>
      <description>arXiv:2411.16297v1 Announce Type: new 
Abstract: A new multi-objective method for the thesis defence scheduling problem is introduced. The problem involves appointing committees to defences and assigning them to a time slot and room. A multi-objective approach is necessary to provide a better understanding of possible solutions and trade-offs to decision-makers. However, this type of approach is often time-consuming. The new multi-objective optimisation approach decomposes the monolithic problem into a sequence of multi-objective problems. This leads to significant efficiency gains compared to the augmented-e constraint method. The monolithic model is decomposed into two submodels solved sequentially. In the first stage, genetic algorithms find multiple committee configurations. The performance of these solutions is assessed based on committee assignment quality objectives and a proxy objective predicting performance in the next stage. In the second stage, considering multiple partial solutions found previously, an augmented e-constraint method is solved to find non-dominated solutions regarding the assignment of time slots to defences. These solutions consider schedule quality objectives. Finally, non-dominated solutions are presented based on objective function performance for both points of view. For small-size instances, the method takes 8-32% of the time of an augmented e-constraint method but finds non-dominated sets with slightly worse hyper-volume indicator values. For larger instances, times are 6-18% of monolithic resolutions, and hyper-volume indicator values are better. A real-world case study is presented. The experiment with decomposition found 39 non-dominated solutions in 1600 seconds. The augmented e-constraint method found 9 solutions in 2400 seconds. For the three objectives, the new method found a solution improving the best-performing solution with the other method in the time limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16297v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jo\~ao Almeida, Alexandre Francisco, Daniel Santos, Jos\'e Rui Figueira</dc:creator>
    </item>
    <item>
      <title>On approximations of stochastic optimal control problems with an application to climate equations</title>
      <link>https://arxiv.org/abs/2411.16491</link>
      <description>arXiv:2411.16491v1 Announce Type: new 
Abstract: The paper is devoted to the optimal control of a system with two time-scales, in a regime when the limit equation is not of averaging type but, in the spirit of Wong-Zakai principle, it is a stochastic differential equation for the slow variable, with noise emerging from the fast one. It proves that it is possible to control the slow variable by acting only on the fast scales. The concrete problem, of interest for climate research, is embedded into an abstract framework in Hilbert spaces, with a stochastic process driven by an approximation of a given noise. The principle established here is that convergence of the uncontrolled problem is sufficient for convergence of both the optimal costs and the optimal controls. This target is reached using Girsanov transform and the representation of the optimal cost and the optimal controls using a Forward Backward System. A challenge in this program is represented by the generality considered here of unbounded control actions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16491v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Franco Flandoli, Giuseppina Guatteri, Umberto Pappalettera, Gianmario Tessitore</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Bidding Strategy Optimization in Day-Ahead Energy Market</title>
      <link>https://arxiv.org/abs/2411.16519</link>
      <description>arXiv:2411.16519v1 Announce Type: new 
Abstract: In a day-ahead market, energy buyers and sellers submit their bids for a particular future time, including the amount of energy they wish to buy or sell and the price they are prepared to pay or receive. However, the dynamic for forming the Market Clearing Price (MCP) dictated by the bidding mechanism is frequently overlooked in the literature on energy market modelling. Forecasting models usually focus on predicting the MCP rather than trying to build the optimal supply and demand curves for a given price scenario. Following this approach, the article focuses on developing a bidding strategy for a seller in a continuous action space through a single agent Reinforcement Learning algorithm, specifically the Deep Deterministic Policy Gradient. The algorithm controls the offering curve (action) based on past data (state) to optimize future payoffs (rewards). The participant can access historical data on production costs, capacity, and prices for various sources, including renewable and fossil fuels. The participant gains the ability to operate in the market with greater efficiency over time to maximize individual payout.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16519v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Di Persio, Matteo Garbelli, Luca M. Giordano</dc:creator>
    </item>
    <item>
      <title>Optimal control problems on the co-adjoint Lie groupoids</title>
      <link>https://arxiv.org/abs/2411.16640</link>
      <description>arXiv:2411.16640v1 Announce Type: new 
Abstract: In this work we study the invariant optimal control problem on Lie groupoids. We show that any invariant optimal control problem on a Lie groupoid reduces to its co-adjoint Lie algebroid. In the final section of the paper, we present an illustrative example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16640v1</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ghorbanali Haghighatdoost</dc:creator>
    </item>
    <item>
      <title>Totally $\Delta$-modular IPs with two non-zeros in most rows</title>
      <link>https://arxiv.org/abs/2411.15282</link>
      <description>arXiv:2411.15282v1 Announce Type: cross 
Abstract: Integer programs (IPs) on constraint matrices with bounded subdeterminants are conjectured to be solvable in polynomial time. We give a strongly polynomial time algorithm to solve IPs where the constraint matrix has bounded subdeterminants and at most two non-zeros per row after removing a constant number of rows and columns. This result extends the work by Fiorini, Joret, Weltge \&amp; Yuditsky (J. ACM 2024) by allowing for additional, unifying constraints and variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15282v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Kober</dc:creator>
    </item>
    <item>
      <title>Direct And Inverse Dynamics Problems For A Three-wheel Mobile Robot With Two Drive Wheels</title>
      <link>https://arxiv.org/abs/2411.15318</link>
      <description>arXiv:2411.15318v1 Announce Type: cross 
Abstract: Mobile robots are widely used to perform various technological operations in several sectors of the national economy. These operations are related to transporting goods and equipment, performing work to determine the condition of a technical object or structure, their construction or repair, performing work to study a specific territory and compile relevant maps, etc. Recently, the list of operations that mobile robots can perform has expanded with police and military operations. Obviously, the safety of personnel working nearby and the time required to perform the relevant operations depend on such robots' speed and accuracy of movement. Therefore, an important task arises to study and form the trajectories of movement of mobile robots. Optimization, adaptation, robustness methods, and the theory of movement stability allow us to consider a mobile robot as a dynamic system with several inputs and outputs. The mathematical description of such a dynamic system can be used to analyze and synthesize the desired trajectories of movement by solving the corresponding direct and inverse dynamics problems. Therefore, creating a mathematical model of a mobile robot is a relevant task, the solution of which allows us to create and research robot control systems that ensure movement along predetermined desired trajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15318v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Roman Voliansky</dc:creator>
    </item>
    <item>
      <title>AdamZ: An Enhanced Optimisation Method for Neural Network Training</title>
      <link>https://arxiv.org/abs/2411.15375</link>
      <description>arXiv:2411.15375v1 Announce Type: cross 
Abstract: AdamZ is an advanced variant of the Adam optimiser, developed to enhance convergence efficiency in neural network training. This optimiser dynamically adjusts the learning rate by incorporating mechanisms to address overshooting and stagnation, that are common challenges in optimisation. Specifically, AdamZ reduces the learning rate when overshooting is detected and increases it during periods of stagnation, utilising hyperparameters such as overshoot and stagnation factors, thresholds, and patience levels to guide these adjustments. While AdamZ may lead to slightly longer training times compared to some other optimisers, it consistently excels in minimising the loss function, making it particularly advantageous for applications where precision is critical. Benchmarking results demonstrate the effectiveness of AdamZ in maintaining optimal learning rates, leading to improved model performance across diverse tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15375v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ilia Zaznov (Department of Computer Science, University of Reading, Reading, UK), Atta Badii (Department of Computer Science, University of Reading, Reading, UK), Alfonso Dufour (ICMA Centre, Henley Business School, University of Reading, Reading, UK), Julian Kunkel (Department of Computer Science/GWDG, University of G\"ottingen, Goettingen, Germany)</dc:creator>
    </item>
    <item>
      <title>Learning a local trading strategy: deep reinforcement learning for grid-scale renewable energy integration</title>
      <link>https://arxiv.org/abs/2411.15422</link>
      <description>arXiv:2411.15422v1 Announce Type: cross 
Abstract: Variable renewable generation increases the challenge of balancing power supply and demand. Grid-scale batteries co-located with generation can help mitigate this misalignment. This paper explores the use of reinforcement learning (RL) for operating grid-scale batteries co-located with solar power. Our results show RL achieves an average of 61% (and up to 96%) of the approximate theoretical optimal (non-causal) operation, outperforming advanced control methods on average. Our findings suggest RL may be preferred when future signals are hard to predict. Moreover, RL has two significant advantages compared to simpler rules-based control: (1) that solar energy is more effectively shifted towards high demand periods, and (2) increased diversity of battery dispatch across different locations, reducing potential ramping issues caused by super-position of many similar actions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15422v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Caleb Ju, Constance Crozier</dc:creator>
    </item>
    <item>
      <title>Integrating optimal ridesharing matching into multimodal traffic model: Implications for policy and sustainable transport system</title>
      <link>https://arxiv.org/abs/2411.15427</link>
      <description>arXiv:2411.15427v1 Announce Type: cross 
Abstract: Integrating ridesharing matching explicitly into multimodal traffic models is crucial for accurately assessing the impacts of multimodal transport (MT) on urban economic and environmental aspects. This paper integrates an optimal ridesharing matching method into a path-based deterministic day-to-day traffic assignment framework, considers match cancellations, and captures the interactions between various modes on the road. The model incorporates five traffic modes (solo driving, ridesharing as a driver, ridesharing as a passenger, bus travel, and metro travel) and two groups of travelers based on their ownership status. Its steady state is determined through numerical experiments. The sensitivity analyses reveal that the MT system's performance varies with changes in ownership, bus fare, and ridesharing fare, demonstrating diverse impacts on mode split, travel cost, and emissions across different groups, road links, and regions. Our findings suggest that vehicle restrictions and pricing strategies have both benefits and drawbacks in managing MT system, emphasizing the need for careful consideration of trade-offs and social equity implications in policy-making and implementation. This study not only enhances the theoretical understanding of MT system but also provides valuable support for urban transportation policy-making aimed at achieving efficient, sustainable, and socially equitable transport systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15427v1</guid>
      <category>physics.soc-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yueqi Liu, Ke Han, Zhuoqian Yang, Yanghong Yu, Wen Ji</dc:creator>
    </item>
    <item>
      <title>Beyond inherent robustness: strong stability of MPC despite plant-model mismatch</title>
      <link>https://arxiv.org/abs/2411.15452</link>
      <description>arXiv:2411.15452v1 Announce Type: cross 
Abstract: We consider the asymptotic stability of MPC under plant-model mismatch, considering primarily models where the origin remains a steady state despite mismatch. Our results differ from prior results on the inherent robustness of MPC, which guarantee only convergence to a neighborhood of the origin, the size of which scales with the magnitude of the mismatch. For MPC with quadratic costs, continuous differentiability of the system dynamics is sufficient to demonstrate exponential stability of the closed-loop system despite mismatch. For MPC with general costs, a joint comparison function bound and scaling condition guarantee asymptotic stability despite mismatch. The results are illustrated in both algebraic and engineering examples. The tools developed to establish these results can address the stability of offset-free MPC, an open and interesting question in the MPC research literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15452v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Steven J. Kuntz, James B. Rawlings</dc:creator>
    </item>
    <item>
      <title>Learning Algorithm Hyperparameters for Fast Parametric Convex Optimization</title>
      <link>https://arxiv.org/abs/2411.15717</link>
      <description>arXiv:2411.15717v1 Announce Type: cross 
Abstract: We introduce a machine-learning framework to learn the hyperparameter sequence of first-order methods (e.g., the step sizes in gradient descent) to quickly solve parametric convex optimization problems. Our computational architecture amounts to running fixed-point iterations where the hyperparameters are the same across all parametric instances and consists of two phases. In the first step-varying phase the hyperparameters vary across iterations, while in the second steady-state phase the hyperparameters are constant across iterations. Our learned optimizer is flexible in that it can be evaluated on any number of iterations and is guaranteed to converge to an optimal solution. To train, we minimize the mean square error to a ground truth solution. In the case of gradient descent, the one-step optimal step size is the solution to a least squares problem, and in the case of unconstrained quadratic minimization, we can compute the two and three-step optimal solutions in closed-form. In other cases, we backpropagate through the algorithm steps to minimize the training objective after a given number of steps. We show how to learn hyperparameters for several popular algorithms: gradient descent, proximal gradient descent, and two ADMM-based solvers: OSQP and SCS. We use a sample convergence bound to obtain generalization guarantees for the performance of our learned algorithm for unseen data, providing both lower and upper bounds. We showcase the effectiveness of our method with many examples, including ones from control, signal processing, and machine learning. Remarkably, our approach is highly data-efficient in that we only use $10$ problem instances to train the hyperparameters in all of our examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15717v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rajiv Sambharya, Bartolomeo Stellato</dc:creator>
    </item>
    <item>
      <title>Revenue Maximization in Choice-Based Matching Markets</title>
      <link>https://arxiv.org/abs/2411.15727</link>
      <description>arXiv:2411.15727v1 Announce Type: cross 
Abstract: The primary contribution of this paper resides in devising constant-factor approximation guarantees for revenue maximization in two-sided matching markets, under general pairwise rewards. A major distinction between our work and state-of-the-art results in this context (Ashlagi et al., 2022; Torrico et al., 2023) is that, for the first time, we are able to address reward maximization, reflected by assigning each customer-supplier pair an arbitrarily-valued reward. The specific type of performance guarantees we attain depends on whether one considers the customized model or the inclusive model. The fundamental difference between these settings lies in whether the platform should display to each supplier all selecting customers, as in the inclusive model, or whether the platform can further personalize this set, as in the customized model. Technically speaking, our algorithmic approach and its analysis revolve around presenting novel linear relaxations, leveraging convex stochastic orders, employing approximate dynamic programming, and developing tailor-made analytical ideas. In both models considered, these ingredients allow us to overcome the lack of submodularity and subadditivity that stems from pairwise rewards, plaguing the applicability of existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15727v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dan Nissim, Danny Segev, Alfredo Torrico</dc:creator>
    </item>
    <item>
      <title>Beyond adaptive gradient: Fast-Controlled Minibatch Algorithm for large-scale optimization</title>
      <link>https://arxiv.org/abs/2411.15795</link>
      <description>arXiv:2411.15795v1 Announce Type: cross 
Abstract: Adaptive gradient methods have been increasingly adopted by deep learning community due to their fast convergence and reduced sensitivity to hyper-parameters. However, these methods come with limitations, such as increased memory requirements for elements like moving averages and a poorly understood convergence theory. To overcome these challenges, we introduce F-CMA, a Fast-Controlled Mini-batch Algorithm with a random reshuffling method featuring a sufficient decrease condition and a line-search procedure to ensure loss reduction per epoch, along with its deterministic proof of global convergence to a stationary point. To evaluate the F-CMA, we integrate it into conventional training protocols for classification tasks involving both convolutional neural networks and vision transformer models, allowing for a direct comparison with popular optimizers. Computational tests show significant improvements, including a decrease in the overall training time by up to 68%, an increase in per-epoch efficiency by up to 20%, and in model accuracy by up to 5%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15795v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Corrado Coppola, Lorenzo Papa, Irene Amerini, Laura Palagi</dc:creator>
    </item>
    <item>
      <title>Stability properties of gradient flow dynamics for the symmetric low-rank matrix factorization problem</title>
      <link>https://arxiv.org/abs/2411.15972</link>
      <description>arXiv:2411.15972v1 Announce Type: cross 
Abstract: The symmetric low-rank matrix factorization serves as a building block in many learning tasks, including matrix recovery and training of neural networks. However, despite a flurry of recent research, the dynamics of its training via non-convex factorized gradient-descent-type methods is not fully understood especially in the over-parameterized regime where the fitted rank is higher than the true rank of the target matrix. To overcome this challenge, we characterize equilibrium points of the gradient flow dynamics and examine their local and global stability properties. To facilitate a precise global analysis, we introduce a nonlinear change of variables that brings the dynamics into a cascade connection of three subsystems whose structure is simpler than the structure of the original system. We demonstrate that the Schur complement to a principal eigenspace of the target matrix is governed by an autonomous system that is decoupled from the rest of the dynamics. In the over-parameterized regime, we show that this Schur complement vanishes at an $O(1/t)$ rate, thereby capturing the slow dynamics that arises from excess parameters. We utilize a Lyapunov-based approach to establish exponential convergence of the other two subsystems. By decoupling the fast and slow parts of the dynamics, we offer new insight into the shape of the trajectories associated with local search algorithms and provide a complete characterization of the equilibrium points and their global stability properties. Such an analysis via nonlinear control techniques may prove useful in several related over-parameterized problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15972v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hesameddin Mohammadi, Mohammad Tinati, Stephen Tu, Mahdi Soltanolkotabi, Mihailo R. Jovanovi\'c</dc:creator>
    </item>
    <item>
      <title>Stealth Attacks Against Moving Target Defense for Smart Grid</title>
      <link>https://arxiv.org/abs/2411.16024</link>
      <description>arXiv:2411.16024v1 Announce Type: cross 
Abstract: Data injection attacks (DIAs) pose a significant cybersecurity threat to the Smart Grid by enabling an attacker to compromise the integrity of data acquisition and manipulate estimated states without triggering bad data detection procedures. To mitigate this vulnerability, the moving target defense (MTD) alters branch admittances to mismatch the system information that is available to an attacker, thereby inducing an imperfect DIA construction that results in degradation of attack performance. In this paper, we first analyze the existence of stealth attacks for the case in which the MTD strategy only changes the admittance of a single branch. Equipped with this initial insight, we then extend the results to the case in which multiple branches are protected by the MTD strategy. Remarkably, we show that stealth attacks can be constructed with information only about which branches are protected, without knowledge about the particular admittance value changes. Furthermore, we provide a sufficient protection condition for the MTD strategy via graph-theoretic tools that guarantee that the system is not vulnerable to DIAs. Numerical simulations are implemented on IEEE test systems to validate the obtained results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16024v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ke Sun, I\~naki Esnaola, H. Vincent Poor</dc:creator>
    </item>
    <item>
      <title>Interplay-robust optimization for treating irregularly breathing lung patients with pencil beam scanning</title>
      <link>https://arxiv.org/abs/2411.16230</link>
      <description>arXiv:2411.16230v1 Announce Type: cross 
Abstract: The steep dose gradients obtained with pencil beam scanning allow for precise tumor targeting at the cost of high sensitivity to uncertainties. Robust optimization is commonly applied to mitigate uncertainties in density and patient setup, while its application to motion management, called 4D-robust optimization (4DRO), is typically accompanied by other motion mitigation techniques. In particular, current commercial implementations of 4DRO do not model the interplay effect between the delivery time structure and the patient's motion. Previously, it has been shown that Interplay-robust optimization (IPRO) can mitigate the interplay effect given uncertainty in the patient's breathing frequency. In this study, we investigate and evaluate IPRO in the context where the motion uncertainty is extended to also include variations in breathing amplitude. We model the patients' motion using synthetic 4DCTs, each created by deforming a reference CT based on a motion pattern obtained with 4DMRI. Each synthetic 4DCT contains multiple breathing cycles, partitioned into two sets for scenario generation: one for optimization and one for evaluation. Motion scenarios are then created by randomly concatenating breathing cycles varying in period and amplitude. In addition, a method considering a single breathing cycle for generating optimization scenarios (IPRO-1C) is developed to investigate to which extent robustness can be achieved with limited information. IPRO and IPRO-1C increased the target coverage for all patient cases in terms of the near-worst-case (5th percentile) CTV D98, compared to 4DRO. After normalization of plan doses to equal target coverage, IPRO with 49 scenarios resulted in the greatest decreases in OAR dose, with near-worst-case (95th percentile) improvements averaging 4.2 %. IPRO-1C with 9 scenarios, with comparable computational demands as 4DRO, decreased OAR dose by 1.7 %.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16230v1</guid>
      <category>physics.med-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivar Bengtsson, Anders Forsgren, Albin Fredriksson, Ye Zhang</dc:creator>
    </item>
    <item>
      <title>Dampening parameter distributional shifts under robust control and gain scheduling</title>
      <link>https://arxiv.org/abs/2411.16566</link>
      <description>arXiv:2411.16566v1 Announce Type: cross 
Abstract: Many traditional robust control approaches assume linearity of the system and independence between the system state-input and the parameters of its approximant low-order model. This assumption implies that robust control design introduces no distributional shifts in the parameters of this low-order model. This is generally not true when the underlying actual system is nonlinear, which admits typically state-input coupling with the parameters of the approximating model. Therefore, a robust controller has to be robust under the parameter distribution that will be experienced in the future data, after applying this control, not the parameter distribution seen in the learning data or assumed in the design. In this paper we seek a solution to this problem by restricting the newly designed closed-loop system to be consistent with the learning data and slowing down any distributional shifts in the state-input and parameter spaces. In computational terms, these objectives are formulated as convex semi-definite programs that standard software packages can efficiently solve. We evaluate the proposed approaches on a simple yet telling gain-scheduling problem, which can be equivalently posed as a robust control problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16566v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Ramadan, Mihai Anitescu</dc:creator>
    </item>
    <item>
      <title>Fast Stochastic Composite Minimization and an Accelerated Frank-Wolfe Algorithm under Parallelization</title>
      <link>https://arxiv.org/abs/2205.12751</link>
      <description>arXiv:2205.12751v3 Announce Type: replace 
Abstract: We consider the problem of minimizing the sum of two convex functions. One of those functions has Lipschitz-continuous gradients, and can be accessed via stochastic oracles, whereas the other is "simple". We provide a Bregman-type algorithm with accelerated convergence in function values to a ball containing the minimum. The radius of this ball depends on problem-dependent constants, including the variance of the stochastic oracle. We further show that this algorithmic setup naturally leads to a variant of Frank-Wolfe achieving acceleration under parallelization. More precisely, when minimizing a smooth convex function on a bounded domain, we show that one can achieve an $\epsilon$ primal-dual gap (in expectation) in $\tilde{O}(1/ \sqrt{\epsilon})$ iterations, by only accessing gradients of the original function and a linear maximization oracle with $O(1/\sqrt{\epsilon})$ computing units in parallel. We illustrate this fast convergence on synthetic numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.12751v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Dubois-Taine, Francis Bach, Quentin Berthet, Adrien Taylor</dc:creator>
    </item>
    <item>
      <title>Bilinear optimal control for a fractional diffusive equation</title>
      <link>https://arxiv.org/abs/2210.17494</link>
      <description>arXiv:2210.17494v2 Announce Type: replace 
Abstract: We consider a bilinear optimal control for an evolution equation involving the fractional Laplace operator of order $0&lt;s&lt;1$. We first give some existence and uniqueness results for the considered evolution equation. Next, we establish some weak maximum principle results allowing us to obtain more regularity of our state equation. Then, we consider an optimal control problem which consists to bring the state of the system at final time to a desired state. We show that this optimal control problem has a solution and we derive the first and second order optimality conditions. Finally, under additional assumptions on the initial datum and the given target, we prove that local uniqueness of optimal solutions can be achieved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.17494v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1080/02331934.2024.2421384</arxiv:DOI>
      <arxiv:journal_reference>Optimization, 2024</arxiv:journal_reference>
      <dc:creator>Gis\`ele Mophou, Cyrille Kenne, Mahamadi Warma</dc:creator>
    </item>
    <item>
      <title>An optimization-free approximation Framework for Connected and Automated Vehicles Eco-Trajectory Planning Under limited computing capacity</title>
      <link>https://arxiv.org/abs/2307.11236</link>
      <description>arXiv:2307.11236v5 Announce Type: replace 
Abstract: The trajectory planning problem (TPP) has become increasingly crucial in the research of next-generation transportation systems, but it presents challenges due to the non-linearity of its constraints. One specific case within TPP, namely the Eco-trajectory Planning Problem (EPP), poses even greater computational difficulties due to its nonlinear, high-order, and non-convex objective function. This paper proposes an optimization-free framework to address the eco-trajectory planning problem of connected and automated vehicles (CAVs) in the straight-driving scenario. The framework consists of an offline module and an online module. In the offline module, an optimal eco-trajectory batch is constructed by solving a sequence of simplified optimization problems to minimize fuel consumption, considering various initial and terminal system states. Each candidate trajectory in the batch yields the lowest fuel consumption subject to a specific travel time from the vehicle entry to the departure from the intersection. In the online module, dynamic trajectory planning algorithms based on different scenarios are provided. Both algorithms greatly improve the computational efficiency of planning and only suffer from a limited extent of optimality losses through a batch-based selection process because optimization and calculation are pre-computed in the offline module. The latter algorithm can also handle possible emergencies and prediction errors. Numerical tests are presented and discussed to evaluate the computational quality and efficiency of the optimization-free approximation framework under a mixed-traffic flow environment that incorporates human-driving vehicles (HDV) and connected and automated vehicles (CAV) with different market penetration rates (MPR).</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.11236v5</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanzheng Lei, Yao Cheng, Xianfeng Terry Yang</dc:creator>
    </item>
    <item>
      <title>Continuity of Filters for Discrete-Time Control Problems Defined by Explicit Equations</title>
      <link>https://arxiv.org/abs/2311.12184</link>
      <description>arXiv:2311.12184v2 Announce Type: replace 
Abstract: Discrete time control systems whose dynamics and observations are described by stochastic equations are common in engineering, operations research, health care, and economics. For example, stochastic filtering problems are usually defined via stochastic equations. These problems can be reduced to Markov decision processes (MDPs) whose states are posterior state distributions, and such MDPs are sometimes called filters. This paper investigates sufficient conditions on transition and observation functions for the original problems to guarantee weak continuity of the transition probabilities of the filter MDP. Under mild conditions on cost functions, weak continuity implies the existence of optimal policies minimizing the expected total costs, the validity of optimality equations, and convergence of value iterations to optimal values. This paper uses recent results on weak continuity of filters for partially observable MDPs defined by transition and observation probabilities. It develops a criterion of weak continuity of transition probabilities and a sufficient condition for continuity in total variation of transition probabilities. The results are illustrated with applications to filtering problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.12184v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eugene A. Feinberg, Sayaka Ishizawa, Pavlo O. Kasyanov, David N. Kraemer</dc:creator>
    </item>
    <item>
      <title>Adaptive Partitioning for Chance-Constrained Problems with Finite Support</title>
      <link>https://arxiv.org/abs/2312.13180</link>
      <description>arXiv:2312.13180v3 Announce Type: replace 
Abstract: This paper studies chance-constrained stochastic optimization problems with finite support. It presents an iterative method that solves reduced-size chance-constrained models obtained by partitioning the scenario set. Each reduced problem is constructed to yield a bound on the optimal value of the original problem. We show how to adapt the partitioning of the scenario set so that our adaptive method returns the optimal solution of the original chance-constrained problem in a finite number of iterations. At the heart of the method lie two fundamental operations: refinement and merging. A refinement operation divides a subset of the partition, whereas a merging operation combines a group of subsets into one. We describe how to use these operations to enhance the bound obtained in each step of the method while preserving the small size of the reduced model. Under mild conditions, we prove that, for specific refinement and merge operations, the bound obtained after solving each reduced model strictly improves throughout the iterative process. Our general method allows the seamless integration of various computational enhancements, significantly reducing the computational time required to solve the reduced chance-constrained problems. The method's efficiency is assessed through numerical experiments on chance-constrained multidimensional knapsack problems. We study the impact of our method's components and compare its performance against other methods from the recent literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13180v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marius Roland, Alexandre Forel, Thibaut Vidal</dc:creator>
    </item>
    <item>
      <title>A quadratically convergent semismooth Newton method for nonlinear semidefinite programming without generalized Jacobian regularity</title>
      <link>https://arxiv.org/abs/2402.13814</link>
      <description>arXiv:2402.13814v2 Announce Type: replace 
Abstract: We introduce a quadratically convergent semismooth Newton method for nonlinear semidefinite programming that eliminates the need for the generalized Jacobian regularity, a common yet stringent requirement in existing approaches. Our strategy involves identifying a single nonsingular element within the Bouligand generalized Jacobian, thus avoiding the standard requirement for nonsingularity across the entire generalized Jacobian set, which is often too restrictive for practical applications. The theoretical framework is supported by introducing the weak second order condition (W-SOC) and the weak strict Robinson constraint qualification (W-SRCQ). These conditions not only guarantee the existence of a nonsingular element in the generalized Jacobian but also forge a primal-dual connection in linearly constrained convex quadratic programming. The theoretical advancements further lay the foundation for the algorithmic design of a novel semismooth Newton method, which integrates a correction step to address degenerate issues. Particularly, this correction step ensures the local convergence as well as a superlinear/quadratic convergence rate of the proposed method. Preliminary numerical experiments corroborate our theoretical findings and underscore the practical effectiveness of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13814v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fuxiaoyue Feng, Chao Ding, Xudong Li</dc:creator>
    </item>
    <item>
      <title>Efficient sparse probability measures recovery via Bregman gradient</title>
      <link>https://arxiv.org/abs/2403.02861</link>
      <description>arXiv:2403.02861v2 Announce Type: replace 
Abstract: This paper presents an algorithm tailored for the efficient recovery of sparse probability measures incorporating $\ell_0$-sparse regularization within the probability simplex constraint. Employing the Bregman proximal gradient method, our algorithm achieves sparsity by explicitly solving underlying subproblems. We rigorously establish the convergence properties of the algorithm, showcasing its capacity to converge to a local minimum with a convergence rate of $O(1/k)$ under mild assumptions. To substantiate the efficacy of our algorithm, we conduct numerical experiments, offering a compelling demonstration of its efficiency in recovering sparse probability measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02861v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianting Pan, Ming Yan</dc:creator>
    </item>
    <item>
      <title>Mean-field stochastic linear quadratic control problem with random coefficients</title>
      <link>https://arxiv.org/abs/2406.04621</link>
      <description>arXiv:2406.04621v3 Announce Type: replace 
Abstract: In this paper, we first prove that the mean-field stochastic linear quadratic (MFSLQ for short) control problem with random coefficients has a unique optimal control and derive a preliminary stochastic maximum principle to characterize this optimal control by an optimality system. However, because of the term of the form $\mathbb{E}[A_1(\cdot)^\top Y(\cdot)] $ in the adjoint equation, which cannot be represented in the form $\mathbb{E}[A_1(\cdot)^\top]\mathbb{E} [Y(\cdot)] $, we cannot solve this optimality system explicitly. To this end, we decompose the MFSLQ control problem into two problems without the mean-field terms, and one of them is a constrained problem. The constrained SLQ control problem is solved explicitly by an extended LaGrange multiplier method developed in this article.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04621v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Xiong, Wen Xu</dc:creator>
    </item>
    <item>
      <title>Accelerated forward-backward and Douglas-Rachford splitting dynamics</title>
      <link>https://arxiv.org/abs/2407.20620</link>
      <description>arXiv:2407.20620v2 Announce Type: replace 
Abstract: We examine convergence properties of continuous-time variants of accelerated Forward-Backward (FB) and Douglas-Rachford (DR) splitting algorithms for nonsmooth composite optimization problems. When the objective function is given by the sum of a quadratic and a nonsmooth term, we establish accelerated sublinear and exponential convergence rates for convex and strongly convex problems, respectively. Moreover, for FB splitting dynamics, we demonstrate that accelerated exponential convergence rate carries over to general strongly convex problems. In our Lyapunov-based analysis we exploit the variable-metric gradient interpretations of FB and DR splittings to obtain smooth Lyapunov functions that allow us to establish accelerated convergence rates. We provide computational experiments to demonstrate the merits and the effectiveness of our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20620v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ibrahim K. Ozaslan, Mihailo R. Jovanovi\'c</dc:creator>
    </item>
    <item>
      <title>An Evolutionary Task Scheduling Algorithm Using Fuzzy Fitness Evaluation Method for Communication Satellite Network</title>
      <link>https://arxiv.org/abs/2408.13500</link>
      <description>arXiv:2408.13500v2 Announce Type: replace 
Abstract: Communications satellite network (CSN), as an integral component of the next generation of communication systems, has the capability to offer services globally. Data transmission in this network primarily relies on two modes: inter-satellite communication and satellite-to-ground station communication. The latter directly impacts the successful reception of data by users. However, due to resource and task limitations, finding a satisfactory solution poses a significant challenge. The communication satellite-ground station network scheduling problem (CS-GSNSP) aims to optimize CSN effectiveness by devising a plan that maximizes link construction time while considering constraints associated with satellite operation modes. The large number of tasks and numerous constraints in the problem result in a time-consuming evaluation of fitness function values. To address this issue, we propose a fuzzy fitness evaluation method (FFEM) that employs fuzzy or real evaluation methods based on individual similarity degrees. Additionally, we introduce an evolutionary algorithm based on FFEM, called evolutionary algorithm based on FFEM (FFEEA), for iteratively searching high-quality network construction schemes. In FFEEA, an adaptive crossover approach is used for efficient population search. Finally, extensive experiments are conducted to demonstrate that our proposed fuzzy fitness evaluation method and other improvement strategies significantly enhance satellite network service time. The study introduces a novel approach to enhance the efficiency of solving combinatorial optimization problems, such as CS-GSNSP, by mitigating the complexity associated with fitness evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13500v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xuemei Jiang, Yangyang Guo, Yue Zhang, Yanjie Song, Witold Pedrycz, Lining Xing</dc:creator>
    </item>
    <item>
      <title>Average-case optimization analysis for distributed consensus algorithms on regular graphs</title>
      <link>https://arxiv.org/abs/2409.00605</link>
      <description>arXiv:2409.00605v4 Announce Type: replace 
Abstract: The consensus problem in distributed computing involves a network of agents aiming to compute the average of their initial vectors through local communication, represented by an undirected graph. This paper focuses on the studying of this problem using an average-case analysis approach, particularly over regular graphs. Traditional algorithms for solving the consensus problem often rely on worst-case performance evaluation scenarios, which may not reflect typical performance in real-world applications. Instead, we apply average-case analysis, focusing on the expected spectral distribution of eigenvalues to obtain a more realistic view of performance. Key contributions include deriving the optimal method for consensus on regular graphs, showing its relation to the Heavy Ball method, analyzing its asymptotic convergence rate, and comparing it to various first-order methods through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00605v4</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nhat Trung Nguyen, Alexander Rogozin, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Willems' Fundamental Lemma for Nonlinear Systems with Koopman Linear Embedding</title>
      <link>https://arxiv.org/abs/2409.16389</link>
      <description>arXiv:2409.16389v2 Announce Type: replace 
Abstract: Koopman operator theory and Willems' fundamental lemma both can provide (approximated) data-driven linear representation for nonlinear systems. However, choosing lifting functions for the Koopman operator is challenging, and the quality of the data-driven model from Willems' fundamental lemma has no guarantee for general nonlinear systems. In this paper, we extend Willems' fundamental lemma for a class of nonlinear systems that admit a Koopman linear embedding. We first characterize the relationship between the trajectory space of a nonlinear system and that of its Koopman linear embedding. We then prove that the trajectory space of Koopman linear embedding can be formed by a linear combination of rich-enough trajectories from the nonlinear system. Combining these two results leads to a data-driven representation of the nonlinear system, which bypasses the need for the lifting functions and thus eliminates the associated bias errors. Our results illustrate that both the width (more trajectories) and depth (longer trajectories) of the trajectory library are important to ensure the accuracy of the data-driven model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16389v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xu Shang, Jorge Cort\'es, Yang Zheng</dc:creator>
    </item>
    <item>
      <title>High-order Moreau envelope beyond convexity: An inexact two-level smoothing framework</title>
      <link>https://arxiv.org/abs/2410.19928</link>
      <description>arXiv:2410.19928v2 Announce Type: replace 
Abstract: This paper introduces an inexact two-level smoothing optimization framework (ItsOPT)} for finding first-order critical points of nonsmooth and nonconvex functions. The framework involves two levels of methodologies: at the upper level, a first- or second-order method will be tailored to minimize a smooth approximation of the cost function; at the lower level, the high-order proximal auxiliary problems will be solved inexactly, generating an inexact oracle. As a smoothing technique, in particular, we here introduce the high-order Moreau envelope (HOME) and study its fundamental features under standard assumptions and its differential properties under a variant of prox-regularity. Next, introducing a high-order proximal-point algorithm (HiPPA) and its boosted variant (Boosted HiPPA) at the upper level and solving the proximal subproblem inexactly at the lower level lead to an instance method of the ItsOPT framework. Global and linear convergence results are established under the Kurdyka-{\L}ojasiewicz (KL) property of the cost and envelope functions, along with some reasonable conditions for the accuracy of the proximal terms. Preliminary numerical experiments on a robust low-rank matrix recovery problem indicate a promising performance of the proposed algorithm, validating our theoretical foundations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19928v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alireza Kabgani, Masoud Ahookhosh</dc:creator>
    </item>
    <item>
      <title>Robust stochastic optimization via regularized PHA: application to Energy Management Systems</title>
      <link>https://arxiv.org/abs/2411.02015</link>
      <description>arXiv:2411.02015v2 Announce Type: replace 
Abstract: This paper deals with robust stochastic optimal control problems. The main contribution is an extension of the Progressive Hedging Algorithm (PHA) that enhances outof-sample robustness while preserving numerical complexity. This extension consists of taking up the widespread practice in machine learning of variance penalization into stochastic optimal control problems. Using the Douglas-Rachford splitting method, the author developed a Regularized Progressive Hedging Algorithm (RPHA) with the same numerical complexity as the standard PHA and better out-of-sample performances. In addition, the authors propose a three-step control framework consisting of a random scenario generation method, followed by a scenario reduction algorithm, and a scenario-based optimal control computation using the RPHA. Finally, the authors test the proposed method to simulate a stationary battery's Energy Management System (EMS) using ground truth measurements of electricity consumption and production from a mainly commercial building in Solaize, France. This simulation shows that the proposed method is more efficient than a classical Model Predictive Control (MPC) strategy, which is, in turn, more efficient than the standard PHA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02015v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Malisani (IFPEN), Adrien Spagnol (IFPEN), Vivien Smis-Michel (IFPEN)</dc:creator>
    </item>
    <item>
      <title>Approximate FW Algorithm with a novel DMO method over Graph-structured Support Set</title>
      <link>https://arxiv.org/abs/2411.04389</link>
      <description>arXiv:2411.04389v2 Announce Type: replace 
Abstract: In this project, we reviewed a paper that deals graph-structured convex optimization (GSCO) problem with the approximate Frank-Wolfe (FW) algorithm. We analyzed and implemented the original algorithm and introduced some extensions based on that. Then we conducted experiments to compare the results and concluded that our backtracking line-search method effectively reduced the number of iterations, while our new DMO method (Top-g+ optimal visiting) did not make satisfying enough improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04389v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijian Pan, Hongjiao Qiang</dc:creator>
    </item>
    <item>
      <title>A Generic Workforce Scheduling and Routing Problem with the Vehicle Sharing and Drop-off and Pick-up Policies</title>
      <link>https://arxiv.org/abs/2303.02229</link>
      <description>arXiv:2303.02229v2 Announce Type: replace-cross 
Abstract: This paper introduces a new generic problem to the literature of Workforce Scheduling and Routing Problem. In this problem, multiple workers are assigned to a shared vehicle based on their qualifications and customer demands, and then the route is formed so that a traveler may be dropped off and picked up later to minimize total flow time. We introduced a mixed-integer linear programming model for the problem. To solve the problem, an Adaptive Large Neighborhood Search (ALNS) algorithm was developed with problem-specific heuristics and a decomposition-based constructive upper bound algorithm (UBA). To analyze the impact of newly introduced policies, service area, difficulty of service, distribution of care, and number of demand nodes type instance characteristics are considered. The empirical analyses showed that the ALNS algorithm presents solutions with up to 35% less total flow time than the UBA. The implementation of the proposed drop-off and pick-up (DP) and vehicle sharing policies present up to 24% decrease in total flow time or provide savings on the total cost of service especially when the demand nodes are located in small areas like in urban areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.02229v2</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\"Omer \"Ozt\"urko\u{g}lu, G\"okberk \"Ozsakall{\i}</dc:creator>
    </item>
    <item>
      <title>GSE: Group-wise Sparse and Explainable Adversarial Attacks</title>
      <link>https://arxiv.org/abs/2311.17434</link>
      <description>arXiv:2311.17434v3 Announce Type: replace-cross 
Abstract: Sparse adversarial attacks fool deep neural networks (DNNs) through minimal pixel perturbations, often regularized by the $\ell_0$ norm. Recent efforts have replaced this norm with a structural sparsity regularizer, such as the nuclear group norm, to craft group-wise sparse adversarial attacks. The resulting perturbations are thus explainable and hold significant practical relevance, shedding light on an even greater vulnerability of DNNs. However, crafting such attacks poses an optimization challenge, as it involves computing norms for groups of pixels within a non-convex objective. We address this by presenting a two-phase algorithm that generates group-wise sparse attacks within semantically meaningful areas of an image. Initially, we optimize a quasinorm adversarial loss using the $1/2-$quasinorm proximal operator tailored for non-convex programming. Subsequently, the algorithm transitions to a projected Nesterov's accelerated gradient descent with $2-$norm regularization applied to perturbation magnitudes. Rigorous evaluations on CIFAR-10 and ImageNet datasets demonstrate a remarkable increase in group-wise sparsity, e.g., $50.9\%$ on CIFAR-10 and $38.4\%$ on ImageNet (average case, targeted attack). This performance improvement is accompanied by significantly faster computation times, improved explainability, and a $100\%$ attack success rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17434v3</guid>
      <category>cs.CV</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shpresim Sadiku, Moritz Wagner, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Santal\'o Geometry of Convex Polytopes</title>
      <link>https://arxiv.org/abs/2402.18955</link>
      <description>arXiv:2402.18955v2 Announce Type: replace-cross 
Abstract: The Santal\'o point of a convex polytope is the interior point which leads to a polar dual of minimal volume. This minimization problem is relevant in interior point methods for convex optimization, where the logarithm of the dual volume is known as the universal barrier function. When translating the facet hyperplanes, the Santal\'o point traces out a semi-algebraic set. We describe and compute this geometry using algebraic and numerical techniques. We exploit connections with statistics, optimization and physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18955v2</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitrii Pavlov, Simon Telen</dc:creator>
    </item>
    <item>
      <title>Towards Faster Decentralized Stochastic Optimization with Communication Compression</title>
      <link>https://arxiv.org/abs/2405.20114</link>
      <description>arXiv:2405.20114v2 Announce Type: replace-cross 
Abstract: Communication efficiency has garnered significant attention as it is considered the main bottleneck for large-scale decentralized Machine Learning applications in distributed and federated settings. In this regime, clients are restricted to transmitting small amounts of quantized information to their neighbors over a communication graph. Numerous endeavors have been made to address this challenging problem by developing algorithms with compressed communication for decentralized non-convex optimization problems. Despite considerable efforts, the current results suffer from various issues such as non-scalability with the number of clients, requirements for large batches, or bounded gradient assumption. In this paper, we introduce MoTEF, a novel approach that integrates communication compression with Momentum Tracking and Error Feedback. Our analysis demonstrates that MoTEF achieves most of the desired properties, and significantly outperforms existing methods under arbitrary data heterogeneity. We provide numerical experiments to validate our theoretical findings and confirm the practical superiority of MoTEF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20114v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rustem Islamov, Yuan Gao, Sebastian U. Stich</dc:creator>
    </item>
    <item>
      <title>A Distance Similarity-based Genetic Optimization Algorithm for Satellite Ground Network Planning Considering Feeding Mode</title>
      <link>https://arxiv.org/abs/2408.16300</link>
      <description>arXiv:2408.16300v2 Announce Type: replace-cross 
Abstract: With the rapid development of the satellite industry, the information transmission network based on communication satellites has gradually become a major and important part of the future satellite ground integration network. However, the low transmission efficiency of the satellite data relay back mission has become a problem that is currently constraining the construction of the system and needs to be solved urgently. Effectively planning the task of satellite ground networking by reasonably scheduling resources is crucial for the efficient transmission of task data. In this paper, we hope to provide a task execution scheme that maximizes the profit of the networking task for satellite ground network planning considering feeding mode (SGNPFM). To solve the SGNPFM problem, a mixed-integer planning model with the objective of maximizing the gain of the link-building task is constructed, which considers various constraints of the satellite in the feed-switching mode. Based on the problem characteristics, we propose a distance similarity-based genetic optimization algorithm (DSGA), which considers the state characteristics between the tasks and introduces a weighted Euclidean distance method to determine the similarity between the tasks. To obtain more high-quality solutions, different similarity evaluation methods are designed to assist the algorithm in intelligently screening individuals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16300v2</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yingying Ren, Qiuli Li, Yangyang Guo, Witold Pedrycz, Lining Xing, Anfeng Liu, Yanjie Song</dc:creator>
    </item>
    <item>
      <title>Spectral estimates on hyperbolic surfaces and a necessary condition for observability of the heat semigroup on manifolds</title>
      <link>https://arxiv.org/abs/2410.01323</link>
      <description>arXiv:2410.01323v2 Announce Type: replace-cross 
Abstract: This article is a continuation of arXiv:2401.14977. We study the concentration properties of spectral projectors on manifolds, in connection with the uncertainty principle. In arXiv:2401.14977, the second author proved an optimal uncertainty principle for the spectral projector of the Laplacian on the hyperbolic half-plane. The aim of the present work is to generalize this condition to surfaces with hyperbolic ends. In particular, we tackle the case of cusps, in which the volume of balls of fixed radius is not bounded from below. We establish that spectral estimates hold from sets satisfying a thickness condition, with a proof based on propagation of smallness estimates of Carleman and Logunov--Malinnikova type. We also prove the converse, namely the necessary character of the thickness condition, on any smooth manifold with Ricci curvature bounded from below.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01323v2</guid>
      <category>math.AP</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alix Deleporte, Marc Rouveyrol</dc:creator>
    </item>
  </channel>
</rss>
