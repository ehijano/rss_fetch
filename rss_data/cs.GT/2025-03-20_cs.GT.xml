<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Mar 2025 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Homogeneous Algorithms Can Reduce Competition in Personalized Pricing</title>
      <link>https://arxiv.org/abs/2503.15634</link>
      <description>arXiv:2503.15634v1 Announce Type: new 
Abstract: Firms' algorithm development practices are often homogeneous. Whether firms train algorithms on similar data, aim at similar benchmarks, or rely on similar pre-trained models, the result is correlated predictions. We model the impact of correlated algorithms on competition in the context of personalized pricing. Our analysis reveals that (1) higher correlation diminishes consumer welfare and (2) as consumers become more price sensitive, firms are increasingly incentivized to compromise on the accuracy of their predictions in exchange for coordination. We demonstrate our theoretical results in a stylized empirical study where two firms compete using personalized pricing algorithms. Our results underscore the ease with which algorithms facilitate price correlation without overt communication, which raises concerns about a new frontier of anti-competitive behavior. We analyze the implications of our results on the application and interpretation of US antitrust law.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15634v1</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nathanael Jo, Kathleen Creel, Ashia Wilson, Manish Raghavan</dc:creator>
    </item>
    <item>
      <title>The Algorithmic Landscape of Fair and Efficient Distribution of Delivery Orders in the Gig Economy</title>
      <link>https://arxiv.org/abs/2503.16002</link>
      <description>arXiv:2503.16002v1 Announce Type: new 
Abstract: Distributing services, goods, and tasks in the gig economy heavily relies upon on-demand workers (aka agents), leading to new challenges varying from logistics optimization to the ethical treatment of gig workers. We focus on fair and efficient distribution of delivery tasks -- placed on the vertices of a graph -- among a fixed set of agents. We consider the fairness notion of minimax share (MMS), which aims to minimize the maximum (submodular) cost among agents and is particularly appealing in applications without monetary transfers. We propose a novel efficiency notion -- namely non-wastefulness -- that is desirable in a wide range of scenarios and, more importantly, does not suffer from computational barriers. Specifically, given a distribution of tasks, we can, in polynomial time, i) verify whether the distribution is non-wasteful and ii) turn it into an equivalent non-wasteful distribution. Moreover, we investigate several fixed-parameter tractable and polynomial-time algorithms and paint a complete picture of the (parameterized) complexity of finding fair and efficient distributions of tasks with respect to both the structure of the topology and natural restrictions of the input. Finally, we highlight how our findings shed light on computational aspects of other well-studied fairness notions, such as envy-freeness and its relaxations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16002v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hadi Hosseini, \v{S}imon Schierreich</dc:creator>
    </item>
    <item>
      <title>A Linear Programming Approach to the Super-Stable Roommates Problem</title>
      <link>https://arxiv.org/abs/2503.16052</link>
      <description>arXiv:2503.16052v1 Announce Type: new 
Abstract: The stable roommates problem is a non-bipartite version of the well-known stable matching problem. Teo and Sethuraman proved that, for each instance of the stable roommates problem in the complete graphs, there exists a linear inequality system such that there exists a feasible solution to this system if and only if there exists a stable matching in the given instance. The aim of this paper is to extend the result of Teo and Sethuraman to the stable roommates problem with ties. More concretely, we prove that, for each instance of the stable roommates problem with ties in the complete graphs, there exists a linear inequality system such that there exists a feasible solution to this system if and only if there exists a super-stable matching in the given instance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16052v1</guid>
      <category>cs.GT</category>
      <category>math.CO</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naoyuki Kamiyama</dc:creator>
    </item>
    <item>
      <title>Binary-Report Peer Prediction for Real-Valued Signal Spaces</title>
      <link>https://arxiv.org/abs/2503.16280</link>
      <description>arXiv:2503.16280v1 Announce Type: new 
Abstract: Theoretical guarantees about peer prediction mechanisms typically rely on the discreteness of the signal and report space. However, we posit that a discrete signal model is not realistic: in practice, agents observe richer information and map their signals to a discrete report. In this paper, we formalize a model with real-valued signals and binary reports. We study a natural class of symmetric strategies where agents map their information to a binary value according to a single real-valued threshold. We characterize equilibria for several well-known peer prediction mechanisms which are known to be truthful under the binary report model. In general, even when every threshold would correspond to a truthful equilibrium in the binary signal model, only certain thresholds remain equilibria in our model. Furthermore, by studying the dynamics of this threshold, we find that some of these equilibria are unstable. These results suggest important limitations for the deployment of existing peer prediction mechanisms in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16280v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafael Frongillo, Ian Kash, Mary Monroe</dc:creator>
    </item>
    <item>
      <title>Characterizing the Convergence of Game Dynamics via Potentialness</title>
      <link>https://arxiv.org/abs/2503.16285</link>
      <description>arXiv:2503.16285v1 Announce Type: new 
Abstract: Understanding the convergence landscape of multi-agent learning is a fundamental problem of great practical relevance in many applications of artificial intelligence and machine learning. While it is known that learning dynamics converge to Nash equilibrium in potential games, the behavior of dynamics in many important classes of games that do not admit a potential is poorly understood. To measure how ''close'' a game is to being potential, we consider a distance function, that we call ''potentialness'', and which relies on a strategic decomposition of games introduced by Candogan et al. (2011). We introduce a numerical framework enabling the computation of this metric, which we use to calculate the degree of ''potentialness'' in generic matrix games, as well as (non-generic) games that are important in economic applications, namely auctions and contests. Understanding learning in the latter games has become increasingly important due to the wide-spread automation of bidding and pricing with no-regret learning algorithms. We empirically show that potentialness decreases and concentrates with an increasing number of agents or actions; in addition, potentialness turns out to be a good predictor for the existence of pure Nash equilibria and the convergence of no-regret learning algorithms in matrix games. In particular, we observe that potentialness is very low for complete-information models of the all-pay auction where no pure Nash equilibrium exists, and much higher for Tullock contests, first-, and second-price auctions, explaining the success of learning in the latter. In the incomplete-information version of the all-pay auction, a pure Bayes-Nash equilibrium exists and it can be learned with gradient-based algorithms. Potentialness nicely characterizes these differences to the complete-information version.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16285v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research (TMLR), 2025</arxiv:journal_reference>
      <dc:creator>Martin Bichler, Davide Legacci, Panayotis Mertikopoulos, Matthias Oberlechner, Bary Pradelski</dc:creator>
    </item>
    <item>
      <title>Computing Lindahl Equilibrium for Public Goods with and without Funding Caps</title>
      <link>https://arxiv.org/abs/2503.16414</link>
      <description>arXiv:2503.16414v1 Announce Type: new 
Abstract: Lindahl equilibrium is a solution concept for allocating a fixed budget across several divisible public goods. It always lies in the core, meaning that the equilibrium allocation satisfies desirable stability and proportional fairness properties. We consider a model where agents have separable linear utility functions over the public goods, and the output assigns to each good an amount of spending, summing to at most the available budget.
  In the uncapped setting, each of the public goods can absorb any amount of funding. In this case, it is known that Lindahl equilibrium is equivalent to maximizing Nash social welfare, and this allocation can be computed by a public-goods variant of the proportional response dynamics. We introduce a new convex programming formulation for computing this solution and show that it is related to Nash welfare maximization through duality and reformulation. We then show that the proportional response dynamics is equivalent to running mirror descent on our new formulation, thereby providing a new and immediate proof of the convergence guarantee for the dynamics. Our new formulation has similarities to Shmyrev's convex program for Fisher market equilibrium.
  In the capped setting, each public good has an upper bound on the amount of funding it can receive. In this setting, existence of Lindahl equilibrium was only known via fixed-point arguments. The existence of an efficient algorithm computing one has been a long-standing open question. We prove that our new convex program continues to work when the cap constraints are added, and its optimal solutions are Lindahl equilibria. Thus, we establish that Lindahl equilibrium can be efficiently computed in the capped setting. Our result also implies that approximately core-stable allocations can be efficiently computed for the class of separable piecewise-linear concave (SPLC) utilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16414v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Kroer, Dominik Peters</dc:creator>
    </item>
    <item>
      <title>Temporal Explorability Games</title>
      <link>https://arxiv.org/abs/2412.16328</link>
      <description>arXiv:2412.16328v2 Announce Type: replace 
Abstract: Temporal graphs extend ordinary graphs with discrete time that affects the availability of edges. We consider solving games played on temporal graphs where one player aims to explore the graph, i.e., visit all vertices. The complexity depends majorly on two factors: the presence of an adversary and how edge availability is specified.
  We demonstrate that on static graphs, where edges are always available, solving explorability games is just as hard as solving reachability games. In contrast, on temporal graphs, the complexity of explorability coincides with generalized reachability (NP-complete for one-player and PSPACE- complete for two player games). We further show that if temporal graphs are given symbolically, even one-player reachability and thus explorability and generalized reachability games are PSPACE-hard. For one player, all these are also solvable in PSPACE and for two players, they are in PSPACE, EXP and EXP, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16328v2</guid>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pete Austin, Nicolas Mazzocchi, Sougata Bose, Patrick Totzke</dc:creator>
    </item>
    <item>
      <title>Metric Distortion of Small-group Deliberation</title>
      <link>https://arxiv.org/abs/2502.01380</link>
      <description>arXiv:2502.01380v4 Announce Type: replace 
Abstract: We consider models for social choice where voters rank a set of choices (or alternatives) by deliberating in small groups of size at most $k$, and these outcomes are aggregated by a social choice rule to find the winning alternative. We ground these models in the metric distortion framework, where the voters and alternatives are embedded in a latent metric space, with closer alternative being more desirable for a voter. We posit that the outcome of a small-group interaction optimally uses the voters' collective knowledge of the metric, either deterministically or probabilistically.
  We characterize the distortion of our deliberation models for small $k$, showing that groups of size $k=3$ suffice to drive the distortion bound below the deterministic metric distortion lower bound of $3$, and groups of size $4$ suffice to break the randomized lower bound of $2.11$. We also show nearly tight asymptotic distortion bounds in the group size, showing that for any constant $\epsilon &gt; 0$, achieving a distortion of $1+\epsilon$ needs group size that only depends on $1/\epsilon$, and not the number of alternatives. We obtain these results via formulating a basic optimization problem in small deviations of the sum of $i.i.d.$ random variables, which we solve to global optimality via non-convex optimization. The resulting bounds may be of independent interest in probability theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01380v4</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ashish Goel, Mohak Goyal, Kamesh Munagala</dc:creator>
    </item>
    <item>
      <title>Human Choice Prediction in Language-based Persuasion Games: Simulation-based Off-Policy Evaluation</title>
      <link>https://arxiv.org/abs/2305.10361</link>
      <description>arXiv:2305.10361v5 Announce Type: replace-cross 
Abstract: Recent advances in Large Language Models (LLMs) have spurred interest in designing LLM-based agents for tasks that involve interaction with human and artificial agents. This paper addresses a key aspect in the design of such agents: predicting human decisions in off-policy evaluation (OPE). We focus on language-based persuasion games, where an expert aims to influence the decision-maker through verbal messages. In our OPE framework, the prediction model is trained on human interaction data collected from encounters with one set of expert agents, and its performance is evaluated on interactions with a different set of experts. Using a dedicated application, we collected a dataset of 87K decisions from humans playing a repeated decision-making game with artificial agents. To enhance off-policy performance, we propose a simulation technique involving interactions across the entire agent space and simulated decision-makers. Our learning strategy yields significant OPE gains, e.g., improving prediction accuracy in the top 15% challenging cases by 7.1%. Our code and the large dataset we collected and generated are submitted as supplementary material and publicly available in our GitHub repository: https://github.com/eilamshapira/HumanChoicePrediction</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.10361v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eilam Shapira, Omer Madmon, Reut Apel, Moshe Tennenholtz, Roi Reichart</dc:creator>
    </item>
    <item>
      <title>Learning Nash Equilibrial Hamiltonian for Two-Player Collision-Avoiding Interactions</title>
      <link>https://arxiv.org/abs/2503.07013</link>
      <description>arXiv:2503.07013v2 Announce Type: replace-cross 
Abstract: We consider the problem of learning Nash equilibrial policies for two-player risk-sensitive collision-avoiding interactions. Solving the Hamilton-Jacobi-Isaacs equations of such general-sum differential games in real time is an open challenge due to the discontinuity of equilibrium values on the state space. A common solution is to learn a neural network that approximates the equilibrium Hamiltonian for given system states and actions. The learning, however, is usually supervised and requires a large amount of sample equilibrium policies from different initial states in order to mitigate the risks of collisions. This paper claims two contributions towards more data-efficient learning of equilibrium policies: First, instead of computing Hamiltonian through a value network, we show that the equilibrium co-states have simple structures when collision avoidance dominates the agents' loss functions and system dynamics is linear, and therefore are more data-efficient to learn. Second, we introduce theory-driven active learning to guide data sampling, where the acquisition function measures the compliance of the predicted co-states to Pontryagin's Maximum Principle. On an uncontrolled intersection case, the proposed method leads to more generalizable approximation of the equilibrium policies, and in turn, lower collision probabilities, than the state-of-the-art under the same data acquisition budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07013v2</guid>
      <category>cs.RO</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Zhang, Siddharth Das, Tanner Merry, Wenlong Zhang, Yi Ren</dc:creator>
    </item>
  </channel>
</rss>
