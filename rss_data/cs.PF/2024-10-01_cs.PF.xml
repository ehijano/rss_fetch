<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PF</link>
    <description>cs.PF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 02 Oct 2024 04:01:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Streaming Data in HPC Workflows Using ADIOS</title>
      <link>https://arxiv.org/abs/2410.00178</link>
      <description>arXiv:2410.00178v1 Announce Type: new 
Abstract: The "IO Wall" problem, in which the gap between computation rate and data access rate grows continuously, poses significant problems to scientific workflows which have traditionally relied upon using the filesystem for intermediate storage between workflow stages. One way to avoid this problem in scientific workflows is to stream data directly from producers to consumers and avoiding storage entirely. However, the manner in which this is accomplished is key to both performance and usability. This paper presents the Sustainable Staging Transport, an approach which allows direct streaming between traditional file writers and readers with few application changes. SST is an ADIOS "engine", accessible via standard ADIOS APIs, and because ADIOS allows engines to be chosen at run-time, many existing file-oriented ADIOS workflows can utilize SST for direct application-to-application communication without any source code changes. This paper describes the design of SST and presents performance results from various applications that use SST, for feeding model training with simulation data with substantially higher bandwidth than the theoretical limits of Frontier's file system, for strong coupling of separately developed applications for multiphysics multiscale simulation, or for in situ analysis and visualization of data to complete all data processing shortly after the simulation finishes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00178v1</guid>
      <category>cs.PF</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Greg Eisenhauer, Norbert Podhorszki, Ana Gainaru, Scott Klasky, Philip E. Davis, Manish Parashar, Matthew Wolf, Eric Suchtya, Erick Fredj, Vicente Bolea, Franz P\"oschel, Klaus Steiniger, Michael Bussmann, Richard Pausch, Sunita Chandrasekaran</dc:creator>
    </item>
    <item>
      <title>Tuning Fast Memory Size based on Modeling of Page Migration for Tiered Memory</title>
      <link>https://arxiv.org/abs/2410.00328</link>
      <description>arXiv:2410.00328v1 Announce Type: new 
Abstract: Tiered memory, built upon a combination of fast memory and slow memory, provides a cost-effective solution to meet ever-increasing requirements from emerging applications for large memory capacity. Reducing the size of fast memory is valuable to improve memory utilization in production and reduce production costs because fast memory tends to be expensive. However, deciding the fast memory size is challenging because there is a complex interplay between application characterization and the overhead of page migration used to mitigate the impact of limited fast memory capacity. In this paper, we introduce a system, Tuna, to decide fast memory size based on modeling of page migration. Tuna uses micro-benchmarking to model the impact of page migration on application performance using three metrics. Tuna decides the fast memory size based on offline modeling results and limited information on workload telemetry. Evaluating with common big-memory applications and using 5% as the performance loss target, we show that Tuna in combination with a page management system (TPP) saves fast memory by 8.5% on average (up to 16%). This is in contrast to the 5% saving in fast memory reported by Microsoft Pond for the same workloads (BFS and SSSP) and the same performance loss target.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00328v1</guid>
      <category>cs.PF</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shangye Chen, Jin Huang, Shuangyan Yang, Jie Liu, Huaicheng Li, Dimitrios Nikolopoulos, Junhee Ryu, Jinho Baek, Kwangsik Shin, Dong Li</dc:creator>
    </item>
    <item>
      <title>Analysis of Markovian Arrivals and Service with Applications to Intermittent Overload</title>
      <link>https://arxiv.org/abs/2405.04102</link>
      <description>arXiv:2405.04102v4 Announce Type: replace 
Abstract: In many important real-world queueing settings, arrival and service rates fluctuate over time. We consider the MAMS system, where the arrival and service rates each vary according to an arbitrary finite-state Markov chain, allowing intermittent overload to be modeled. This model has been extensively studied, and we derive results matching those found in the literature via a somewhat novel framework.
  We derive a characterization of mean queue length in the MAMS system, with explicit bounds for all arrival and service chains at all loads, using our new framework. Our bounds are tight in heavy traffic. We prove even stronger bounds for the important special case of two-level arrivals with intermittent overload.
  Our framework is based around the concepts of relative arrivals and relative completions, which have previously been used in studying the MAMS system, under different names. These quantities allow us to tractably capture the transient correlational effect of the arrival and service processes on the mean queue length.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04102v4</guid>
      <category>cs.PF</category>
      <category>math.PR</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isaac Grosof, Yige Hong, Mor Harchol-Balter</dc:creator>
    </item>
  </channel>
</rss>
