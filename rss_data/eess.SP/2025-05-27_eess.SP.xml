<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 May 2025 04:01:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Illuminating the Path: Attention-Assisted Beamforming and Predictive Insights in 5G NR Systems</title>
      <link>https://arxiv.org/abs/2505.18160</link>
      <description>arXiv:2505.18160v1 Announce Type: new 
Abstract: Artificial intelligence advances have recently influenced wireless communications, including beam management in fifth-generation (5G) new radio systems. AI-driven models and algorithms are being applied to enhance tasks such as beam selection, prediction, and refinement by leveraging real-time and historical data. These approaches address challenges such as mobility under complex channel conditions, showing promising results compared to traditional methods. Beam management in 5G refers to processes that ensure optimal alignment between the base station and user equipment for effective signal transmission and reception based on real-time channel state information and user positioning. This study leverages accurate beam prediction to identify a smaller subset of beams, resulting in a more efficient, streamlined, and link-adaptive communication system. The innovative approach presented introduces a precise, attention-based prediction model that derives the entire downlink transmission chain in a commercial grade 5G system. The predicted downlink beams are specifically tailored to handle the complexities of none line-of-sight environments known for high-dimensional channel dynamics and scatterer-induced signal variations. This novel method introduces a paradigm shift in utilizing environmental and channel dynamics in contrast to conventional procedures of beam management, which entails complex methods involving exhaustive techniques to predict the best beams. The presented beam prediction results demonstrate robustness in addressing the challenges posed by signal-dispersive environments, showcasing great potential in mobility scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18160v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dino Pjani\'c, Guoda Tian, Andres Reial, Xuesong Cai, Bo Bernhardsson, Fredrik Tufvesson</dc:creator>
    </item>
    <item>
      <title>Accelerating Battery Material Optimization through iterative Machine Learning</title>
      <link>https://arxiv.org/abs/2505.18162</link>
      <description>arXiv:2505.18162v1 Announce Type: new 
Abstract: The performance of battery materials is determined by their composition and the processing conditions employed during commercial-scale fabrication, where raw materials undergo complex processing steps with various additives to yield final products. As the complexity of these parameters expands with the development of industry, conventional one-factor-at-a-time (OFAT) experiment becomes old fashioned. While domain expertise aids in parameter optimization, this traditional approach becomes increasingly vulnerable to cognitive limitations and anthropogenic biases as the complexity of factors grows. Herein, we introduce an iterative machine learning (ML) framework that integrates active learning to guide targeted experimentation and facilitate incremental model refinement. This method systematically leverages comprehensive experimental observations, including both successful and unsuccessful results, effectively mitigating human-induced biases and alleviating data scarcity. Consequently, it significantly accelerates exploration within the high-dimensional design space. Our results demonstrate that active-learning-driven experimentation markedly reduces the total number of experimental cycles necessary, underscoring the transformative potential of ML-based strategies in expediting battery material optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18162v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Seon-Hwa Lee, Insoo Ye, Changhwan Lee, Jieun Kim, Geunho Choi, Sang-Cheol Nam, Inchul Park</dc:creator>
    </item>
    <item>
      <title>Ray Antenna Array: A Novel Cost-Effective Multi-Antenna Architecture for Enhanced Wireless Communication</title>
      <link>https://arxiv.org/abs/2505.18163</link>
      <description>arXiv:2505.18163v1 Announce Type: new 
Abstract: This paper proposes a novel multi-antenna architecture, termed ray antenna array (RAA), which aims to enhance wireless communication performance in a cost-effective manner. RAA is composed of massive cheap antenna elements and a few radio frequency (RF) chains. The massive antenna elements are arranged in a novel ray-like structure, with each ray corresponding to a simple uniform linear array (sULA) with a carefully designed orientation. The antenna elements of each sULA are directly connected to an RF combiner, so that the sULA in each ray is able to form a beam towards a direction matching the ray orientation without relying on any analog or digital beamforming. By further designing a ray selection network (RSN), appropriate sULAs are selected to connect to the RF chains for further baseband processing. Compared to conventional multi-antenna architectures like hybrid analog/digital beamforming (HBF), the proposed RAA has two major advantages. First, it can significantly reduce hardware costs since no phase shifters, which are usually expensive especially in high-frequency systems, are required. Besides, RAA can greatly improve system performance by configuring antenna elements with higher directionality, as each sULA only needs to be responsible for a portion of the total coverage angle. To demonstrate such advantages, in this paper, we first present the input-output model for RAA-based wireless communications, based on which the ray orientations of the RAA are designed. Furthermore, efficient algorithms for joint ray selection and beamforming are proposed for single-user and multi-user RAA-based wireless communications. Simulation results demonstrate the superior performance of RAA compared to HBF while significantly reducing hardware cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18163v1</guid>
      <category>eess.SP</category>
      <category>cs.AR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenjun Dong, Zhiwen Zhou, Yong Zeng</dc:creator>
    </item>
    <item>
      <title>A Comprehensive PPG-based Dataset for HR/HRV Studies</title>
      <link>https://arxiv.org/abs/2505.18165</link>
      <description>arXiv:2505.18165v1 Announce Type: new 
Abstract: Heart rate (HR) and heart rate variability (HRV) are important vital signs for human physical and mental health. Recent research has demonstrated that photoplethysmography (PPG) sensors can infer HR and HRV. However, it is difficult to find a comprehensive PPG-based dataset for HR/HRV studies, especially for various study needs: multiple scenes, long-term monitoring, and multimodality (multiple PPG channels and extra acceleration data). In this study, we collected a comprehensive multimodal long-term dataset to address the gap of missing an all-in-one HR/HRV dataset (denoted as UTSA-PPG). We began by reviewing state-of-the-art datasets, emphasizing their strengths and limitations. Following this, we developed a custom data acquisition system and then collected the UTSA-PPG dataset and compared its key features with those of existing datasets. Additionally, five case studies were conducted, including comparisons with state-of-the-art datasets. The outcomes highlight the value of our dataset, demonstrating its utility for HR/HRV estimation exploration and its potential to aid researchers in creating generalized models for targeted research challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18165v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingye Xu, Yuntong Zhang, Wei Wang, Mimi Xie, Dakai Zhu</dc:creator>
    </item>
    <item>
      <title>Dim and Small Target Detection for Drone Broadcast Frames Based on Time-Frequency Analysis</title>
      <link>https://arxiv.org/abs/2505.18167</link>
      <description>arXiv:2505.18167v1 Announce Type: new 
Abstract: We propose a dim and small target detection algorithm for drone broadcast frames based on the time-frequency analysis of communication protocol. Specifically, by analyzing modulation parameters and frame structures, the prior knowledge of transmission frequency, signal bandwidth, Zadoff-Chu (ZC) sequences, and frame length of drone broadcast frames is established. The RF signals are processed through the designed filter banks, and the frequency domain parameters of bounding boxes generated by the detector are corrected with transmission frequency and signal bandwidth. Given the remarkable correlation characteristics of ZC sequences, the frequency domain parameters of bounding boxes with low confidence scores are corrected based on ZC sequences and frame length, which improves the detection accuracy of dim targets under low signal-to noise ratio (SNR) situations. Besides, a segmented energy refinement method is applied to mitigate the deviation caused by interference signals with high energy strength, which ulteriorly corrects the time domain detection parameters for dim targets. As the sampling duration increases, the detection speed improves while the detection accuracy of broadcast frames termed as small targets decreases. The trade-off between detection accuracy and speed versus sampling duration is established, which helps to meet different drone regulation requirements. Simulation results demonstrate that the proposed algorithm improves the average intersection over union, precision, and recall by 3\%, 1.4\%, and 2.4\%, respectively, compared to existing algorithms. The proposed algorithm also performs strong robustness under varying flight distances, diverse types of environment noise, and different flight visual environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18167v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Li, Jing Li, Zhanyu Ju, Fengkui Gong, Lu Lv</dc:creator>
    </item>
    <item>
      <title>Load Forecasting in the Era of Smart Grids: Opportunities and Advanced Machine Learning Models</title>
      <link>https://arxiv.org/abs/2505.18170</link>
      <description>arXiv:2505.18170v1 Announce Type: new 
Abstract: Electric energy is difficult to store, requiring stricter control over its generation, transmission, and distribution. A persistent challenge in power systems is maintaining real-time equilibrium between electricity demand and supply. Oversupply contributes to resource wastage, while undersupply can strain the grid, increase operational costs, and potentially impact service reliability. To maintain grid stability, load forecasting is needed. Accurate load forecasting balances generation and demand by striving to predict future electricity consumption. This thesis examines and evaluates four machine learning frameworks for short term load forecasting, including gradient boosting decision tree methods such as Extreme Gradient Boosting (XGBoost) and Light Gradient Boosting Machine (LightGBM). A hybrid framework is also developed. In addition, two recurrent neural network architectures, Long Short Term Memory (LSTM) networks and Gated Recurrent Units (GRU), are designed and implemented. Pearson Correlation Coefficient is applied to assess the relationships between electricity demand and exogenous variables. The experimental results show that, for the specific dataset and forecasting task in this study, machine learning-based models achieved improved forecasting performance compared to a classical ARIMA baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18170v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aurausp Maneshni</dc:creator>
    </item>
    <item>
      <title>IoT-Enabled Hemodynamic Surveillance System: AD8232 Bioelectric Signal Processing with ESP32</title>
      <link>https://arxiv.org/abs/2505.18173</link>
      <description>arXiv:2505.18173v1 Announce Type: new 
Abstract: This dissertation proposes an electrocardiogram (ECG) tracking device that diagnoses cardiopulmonary problems using the Internet of Things (IoT) desired results. The initiative is built on the internet observing an electrocardiogram with the AD8232 heart rhythm sensor and the ESP32 expansion kit, using an on-premise connected device platform to transform sensing input into meaningful data. That subsequently supervises an ECG signal and delivers it to an intelligent phone via Wi-Fi for data analysis. That is the pace of the circulating. Assessing body temperature, pulse rate, and coronary arteries are vital measures to defend your health. The heartbeat rate may be measured in two ways: there are by palpating the pulse at the wrist or neck directly or other alternative by utilizing a cardiac sensor. Monitoring alcohol levels in cardiac patients is critical for measuring the influence of liquor on their health and the efficacy of therapy. It assists in recognizing the association between alcohol consumption and cardiac issues, rather than rhythm recorded in beats per minute (bpm). An IR transmitter/receiver pair (OLED) needs to stay compatible up near the sensor's knuckle current or voltage pulse. The detector's electrical output is evaluated by suitable electronic circuits to produce a visual clue (digital display). We must design a cost-effective, user-friendly, and efficient ECG monitoring system with contemporary technology for both persons imprisoned by disease or aging, as well as healthcare professionals. Microcontroller combined with software. A smartphone application is created to monitor the cardiovascular health of distant patients in real-time</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18173v1</guid>
      <category>eess.SP</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.RO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hemalatha R J, Shubham Malhotra, Shivapanchakshari T G, Lokesh K, Dev Anand D, Samson Jebakumar S</dc:creator>
    </item>
    <item>
      <title>NMCSE: Noise-Robust Multi-Modal Coupling Signal Estimation Method via Optimal Transport for Cardiovascular Disease Detection</title>
      <link>https://arxiv.org/abs/2505.18174</link>
      <description>arXiv:2505.18174v1 Announce Type: new 
Abstract: Electrocardiogram (ECG) and Phonocardiogram (PCG) signals are linked by a latent coupling signal representing the electrical-to-mechanical cardiac transformation. While valuable for cardiovascular disease (CVD) detection, this coupling signal is traditionally estimated using deconvolution methods that amplify noise, limiting clinical utility. In this paper, we propose Noise-Robust Multi-Modal Coupling Signal Estimation (NMCSE), which reformulates the problem as distribution matching via optimal transport theory. By jointly optimizing amplitude and temporal alignment, NMCSE mitigates noise amplification without additional preprocessing. Integrated with our Temporal-Spatial Feature Extraction network, NMCSE enables robust multi-modal CVD detection. Experiments on the PhysioNet 2016 dataset with realistic hospital noise demonstrate that NMCSE reduces estimation errors by approximately 30% in Mean Squared Error while maintaining higher Pearson Correlation Coefficients across all tested signal-to-noise ratios. Our approach achieves 97.38% accuracy and 0.98 AUC in CVD detection, outperforming state-of-the-art methods and demonstrating robust performance for real-world clinical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18174v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhixin li, Peihong Zhang, Rui Sang, Yuxuan Liu, Shengchen Li</dc:creator>
    </item>
    <item>
      <title>Evaluation in EEG Emotion Recognition: State-of-the-Art Review and Unified Framework</title>
      <link>https://arxiv.org/abs/2505.18175</link>
      <description>arXiv:2505.18175v1 Announce Type: new 
Abstract: Electroencephalography-based Emotion Recognition (EEG-ER) has become a growing research area in recent years. Analyzing 216 papers published between 2018 and 2023, we uncover that the field lacks a unified evaluation protocol, which is essential to fairly define the state of the art, compare new approaches and to track the field's progress. We report the main inconsistencies between the used evaluation protocols, which are related to ground truth definition, evaluation metric selection, data splitting types (e.g., subject-dependent or subject-independent) and the use of different datasets. Capitalizing on this state-of-the-art research, we propose a unified evaluation protocol, EEGain (https://github.com/EmotionLab/EEGain), which enables an easy and efficient evaluation of new methods and datasets. EEGain is a novel open source software framework, offering the capability to compare - and thus define - state-of-the-art results. EEGain includes standardized methods for data pre-processing, data splitting, evaluation metrics, and the ability to load the six most relevant datasets (i.e., AMIGOS, DEAP, DREAMER, MAHNOB-HCI, SEED, SEED-IV) in EEG-ER with only a single line of code. In addition, we have assessed and validated EEGain using these six datasets on the four most common publicly available methods (EEGNet, DeepConvNet, ShallowConvNet, TSception). This is a significant step to make research on EEG-ER more reproducible and comparable, thereby accelerating the overall progress of the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18175v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Natia Kukhilava, Tatia Tsmindashvili, Rapael Kalandadze, Anchit Gupta, Sofio Katamadze, Fran\c{c}ois Br\'emond, Laura M. Ferrari, Philipp M\"uller, Benedikt Emanuel Wirth</dc:creator>
    </item>
    <item>
      <title>Machine Learning-Based Analysis of ECG and PCG Signals for Rheumatic Heart Disease Detection: A Scoping Review (2015-2025)</title>
      <link>https://arxiv.org/abs/2505.18182</link>
      <description>arXiv:2505.18182v1 Announce Type: new 
Abstract: Objective: To conduct a systematic assessment of machine learning applications that utilize electrocardiogram (ECG) and heart sound data in the development of cost-effective detection tools for rheumatic heart disease (RHD) from the year 2015 to 2025, thereby supporting the World Heart Federation's "25 by 25" mortality reduction objective through the creation of alternatives to echocardiography in underserved regions. Methods: Following PRISMA-ScR guidelines, we conducted a comprehensive search across PubMed, IEEE Xplore, Scopus, and Embase for peer-reviewed literature focusing on ML-based ECG/PCG analysis for RHD detection. Two independent reviewers screened studies, and data extraction focused on methodology, validation approaches, and performance metrics. Results: Analysis of 37 relevant studies revealed that convolutional neural networks (CNNs) have become the predominant technology in post-2020 implementations, achieving a median accuracy of 93.7%. However, 73% of studies relied on single-center datasets, only 10.8% incorporated external validation, and none addressed cost-effectiveness. Performance varied markedly across different valvular lesions, and despite 44% of studies originating from endemic regions, significant gaps persisted in implementation science and demographic diversity. Conclusion: While ML-based ECG/PCG analysis shows promise for RHD detection, substantial methodological limitations hinder clinical translation. Future research must prioritize standardized benchmarking frameworks, multimodal architectures, cost-effectiveness assessments, and prospective trials in endemic settings. Significance: This review provides a critical roadmap for developing accessible ML-based RHD screening tools to help bridge the diagnostic gap in resourceconstrained settings where conventional auscultation misses up to 90% of cases and echocardiography remains inaccessible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18182v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Damilare Emmanuel Olatunji, Julius Dona Zannu, Carine Pierrette Mukamakuza, Godbright Nixon Uiso, Mona Mamoun Mubarak Aman, John Bosco Thuo, Chol Buol, Nchofon Tagha Ghogomu, Evelyne Umubyeyi</dc:creator>
    </item>
    <item>
      <title>FRAME-C: A knowledge-augmented deep learning pipeline for classifying multi-electrode array electrophysiological signals</title>
      <link>https://arxiv.org/abs/2505.18183</link>
      <description>arXiv:2505.18183v1 Announce Type: new 
Abstract: Amyotrophic lateral sclerosis (ALS) is a fatal neurodegenerative disorder characterized by motor neuron degeneration, with alterations in neural excitability serving as key indicators. Recent advancements in induced pluripotent stem cell (iPSC) technology have enabled the generation of human iPSC-derived neuronal cultures, which, when combined with multi-electrode array (MEA) electrophysiology, provide rich spatial and temporal electrophysiological data. Traditionally, MEA data is analyzed using handcrafted features based on potentially imperfect domain knowledge, which while useful may not fully capture all useful characteristics inherent in the data. Machine learning, particularly deep learning, has the potential to automatically learn relevant characteristics from raw data without solely relying on handcrafted feature extraction. However, handcrafted features remain critical for encoding domain knowledge and improving interpretability, especially with limited or noisy data. This study introduces FRAME-C, a knowledge-augmented machine learning pipeline that combines domain knowledge, raw spike waveform data, and deep learning techniques to classify MEA signals and identify ALS-specific phenotypes. FRAME-C leverages deep learning to learn important features from spike waveforms while incorporating handcrafted features such as spike amplitude, inter-spike interval, and spike duration, preserving key spatial and temporal information. We validate FRAME-C on both simulated and real MEA data from human iPSC-derived neuronal cultures, demonstrating superior performance over existing classification methods. FRAME-C shows over 11% improvement on real data and up to 25% on simulated data. We also show FRAME-C can evaluate handcrafted feature importance, providing insights into ALS phenotypes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18183v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nisal Ranasinghe, Dzung Do-Ha, Simon Maksour, Tamasha Malepathirana, Sachith Seneviratne, Lezanne Ooi, Saman Halgamuge</dc:creator>
    </item>
    <item>
      <title>AI- Enhanced Stethoscope in Remote Diagnostics for Cardiopulmonary Diseases</title>
      <link>https://arxiv.org/abs/2505.18184</link>
      <description>arXiv:2505.18184v1 Announce Type: new 
Abstract: The increase in cardiac and pulmonary diseases presents an alarming and pervasive health challenge on a global scale responsible for unexpected and premature mortalities. In spite of how serious these conditions are, existing methods of detection and treatment encounter challenges, particularly in achieving timely diagnosis for effective medical intervention. Manual screening processes commonly used for primary detection of cardiac and respiratory problems face inherent limitations, increased by a scarcity of skilled medical practitioners in remote or under-resourced areas. To address this, our study introduces an innovative yet efficient model which integrates AI for diagnosing lung and heart conditions concurrently using the auscultation sounds. Unlike the already high-priced digital stethoscope, our proposed model has been particularly designed to deploy on low-cost embedded devices and thus ensure applicability in under-developed regions that actually face an issue of accessing medical care. Our proposed model incorporates MFCC feature extraction and engineering techniques to ensure that the signal is well analyzed for accurate diagnostics through the hybrid model combining Gated Recurrent Unit with CNN in processing audio signals recorded from the low-cost stethoscope. Beyond its diagnostic capabilities, the model generates digital audio records that facilitate in classifying six pulmonary and five cardiovascular diseases. Hence, the integration of a cost effective stethoscope with an efficient AI empowered model deployed on a web app providing real-time analysis, represents a transformative step towards standardized healthcare</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18184v1</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hania Ghouse, Juveria Tanveen, Abdul Muqtadir Ahmed, Uma N. Dulhare</dc:creator>
    </item>
    <item>
      <title>BrainOmni: A Brain Foundation Model for Unified EEG and MEG Signals</title>
      <link>https://arxiv.org/abs/2505.18185</link>
      <description>arXiv:2505.18185v1 Announce Type: new 
Abstract: Electroencephalography (EEG) and magnetoencephalography (MEG) measure neural activity non-invasively by capturing electromagnetic fields generated by dendritic currents. Although rooted in the same biophysics, EEG and MEG exhibit distinct signal patterns, further complicated by variations in sensor configurations across modalities and recording devices. Existing approaches typically rely on separate, modality- and dataset-specific models, which limits the performance and cross-domain scalability. This paper proposes BrainOmni, the first brain foundation model that generalises across heterogeneous EEG and MEG recordings. To unify diverse data sources, we introduce BrainTokenizer,the first tokenizer that quantises spatiotemporal brain activity into discrete representations. Central to BrainTokenizer is a novel Sensor Encoder that encodes sensor properties such as spatial layout, orientation, and type, enabling compatibility across devices and modalities. Building upon the discrete representations, BrainOmni learns unified semantic embeddings of brain signals by self-supervised pretraining. To the best of our knowledge, it is the first foundation model to support both EEG and MEG signals, as well as the first to incorporate large-scale MEG pretraining. A total of 1,997 hours of EEG and 656 hours of MEG data are curated and standardised from publicly available sources for pretraining. Experiments show that BrainOmni outperforms both existing foundation models and state-of-the-art task-specific models on a range of downstream tasks. It also demonstrates strong generalisation to unseen EEG and MEG devices. Further analysis reveals that joint EEG-MEG (EMEG) training yields consistent improvements across both modalities. Code and model checkpoints will be released upon acceptance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18185v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qinfan Xiao, Ziyun Cui, Chi Zhang, Siqi Chen, Wen Wu, Andrew Thwaites, Alexandra Woolgar, Bowen Zhou, Chao Zhang</dc:creator>
    </item>
    <item>
      <title>Improving Generative Inverse Design of Rectangular Patch Antennas with Test Time Optimization</title>
      <link>https://arxiv.org/abs/2505.18188</link>
      <description>arXiv:2505.18188v1 Announce Type: new 
Abstract: We propose a two-stage deep learning framework for the inverse design of rectangular patch antennas. Our approach leverages generative modeling to learn a latent representation of antenna frequency response curves and conditions a subsequent generative model on these responses to produce feasible antenna geometries. We further demonstrate that leveraging search and optimization techniques at test-time improves the accuracy of the generated designs and enables consideration of auxiliary objectives such as manufacturability. Our approach generalizes naturally to different design criteria, and can be easily adapted to more complex geometric design spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18188v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Beck LaBash, Shahriar Khushrushahi, Fabian Ruehle</dc:creator>
    </item>
    <item>
      <title>Generating Realistic Multi-Beat ECG Signals</title>
      <link>https://arxiv.org/abs/2505.18189</link>
      <description>arXiv:2505.18189v1 Announce Type: new 
Abstract: Generating synthetic ECG data has numerous applications in healthcare, from educational purposes to simulating scenarios and forecasting trends. While recent diffusion models excel at generating short ECG segments, they struggle with longer sequences needed for many clinical applications. This paper proposes a novel three-layer synthesis framework for generating realistic long-form ECG signals. We first generate high-fidelity single beats using a diffusion model, then synthesize inter-beat features preserving critical temporal dependencies, and finally assemble beats into coherent long sequences using feature-guided matching. Our comprehensive evaluation demonstrates that the resulting synthetic ECGs maintain both beat-level morphological fidelity and clinically relevant inter-beat relationships. In arrhythmia classification tasks, our long-form synthetic ECGs significantly outperform end-to-end long-form ECG generation using the diffusion model, highlighting their potential for increasing utility for downstream applications. The approach enables generation of unprecedented multi-minute ECG sequences while preserving essential diagnostic characteristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18189v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paul P\"ohl, Viktor Schlegel, Hao Li, Anil Bharath</dc:creator>
    </item>
    <item>
      <title>PhySense: Sensor Placement Optimization for Accurate Physics Sensing</title>
      <link>https://arxiv.org/abs/2505.18190</link>
      <description>arXiv:2505.18190v1 Announce Type: new 
Abstract: Physics sensing plays a central role in many scientific and engineering domains, which inherently involves two coupled tasks: reconstructing dense physical fields from sparse observations and optimizing scattered sensor placements to observe maximum information. While deep learning has made rapid advances in sparse-data reconstruction, existing methods generally omit optimization of sensor placements, leaving the mutual enhancement between reconstruction and placement on the shelf. To change this suboptimal practice, we propose PhySense, a synergistic two-stage framework that learns to jointly reconstruct physical fields and to optimize sensor placements, both aiming for accurate physics sensing. The first stage involves a flow-based generative model enhanced by cross-attention to adaptively fuse sparse observations. \correct{Leveraging the reconstruction feedback, }the second stage performs sensor placement via projected gradient descent to satisfy spatial constraints. \correct{We further prove that the learning objectives of the two stages are consistent with classical variance-minimization principles, providing theoretical guarantees.} Extensive experiments across three challenging benchmarks, especially a 3D geometry dataset, indicate PhySense achieves state-of-the-art physics sensing accuracy and discovers informative sensor placements previously unconsidered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18190v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuezhou Ma, Haixu Wu, Hang Zhou, Huikun Weng, Jianmin Wang, Mingsheng Long</dc:creator>
    </item>
    <item>
      <title>SzCORE as a benchmark: report from the seizure detection challenge at the 2025 AI in Epilepsy and Neurological Disorders Conference</title>
      <link>https://arxiv.org/abs/2505.18191</link>
      <description>arXiv:2505.18191v1 Announce Type: new 
Abstract: Reliable automatic seizure detection from long-term EEG remains a challenge, as current machine learning models often fail to generalize across patients or clinical settings. Manual EEG review remains the clinical standard, underscoring the need for robust models and standardized evaluation. To rigorously assess algorithm performance, we organized a challenge using a private dataset of continuous EEG recordings from 65 subjects (4,360 hours). Expert neurophysiologists annotated the data, providing ground truth for seizure events. Participants were required to detect seizure onset and duration, with evaluation based on event-based metrics, including sensitivity, precision, F1-score, and false positives per day. The SzCORE framework ensured standardized evaluation. The primary ranking criterion was the event-based F1-score, reflecting clinical relevance by balancing sensitivity and false positives. The challenge received 30 submissions from 19 teams, with 28 algorithms evaluated. Results revealed wide variability in performance, with a top F1-score of 43% (sensitivity 37%, precision 45%), highlighting the ongoing difficulty of seizure detection. The challenge also revealed a gap between reported performance and real-world evaluation, emphasizing the importance of rigorous benchmarking. Compared to previous challenges and commercial systems, the best-performing algorithm in this contest showed improved performance. Importantly, the challenge platform now supports continuous benchmarking, enabling reproducible research, integration of new datasets, and clinical evaluation of seizure detection algorithms using a standardized framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18191v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.PF</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan Dan, Amirhossein Shahbazinia, Christodoulos Kechris, David Atienza</dc:creator>
    </item>
    <item>
      <title>Large Language Model-Driven Distributed Integrated Multimodal Sensing and Semantic Communications</title>
      <link>https://arxiv.org/abs/2505.18194</link>
      <description>arXiv:2505.18194v1 Announce Type: new 
Abstract: Traditional single-modal sensing systems-based solely on either radio frequency (RF) or visual data-struggle to cope with the demands of complex and dynamic environments. Furthermore, single-device systems are constrained by limited perspectives and insufficient spatial coverage, which impairs their effectiveness in urban or non-line-of-sight scenarios. To overcome these challenges, we propose a novel large language model (LLM)-driven distributed integrated multimodal sensing and semantic communication (LLM-DiSAC) framework. Specifically, our system consists of multiple collaborative sensing devices equipped with RF and camera modules, working together with an aggregation center to enhance sensing accuracy. First, on sensing devices, LLM-DiSAC develops an RF-vision fusion network (RVFN), which employs specialized feature extractors for RF and visual data, followed by a cross-attention module for effective multimodal integration. Second, a LLM-based semantic transmission network (LSTN) is proposed to enhance communication efficiency, where the LLM-based decoder leverages known channel parameters, such as transceiver distance and signal-to-noise ratio (SNR), to mitigate semantic distortion. Third, at the aggregation center, a transformer-based aggregation model (TRAM) with an adaptive aggregation attention mechanism is developed to fuse distributed features and enhance sensing accuracy. To preserve data privacy, a two-stage distributed learning strategy is introduced, allowing local model training at the device level and centralized aggregation model training using intermediate features. Finally, evaluations on a synthetic multi-view RF-visual dataset generated by the Genesis simulation engine show that LLM-DiSAC achieves a good performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18194v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yubo Peng, Luping Xiang, Bingxin Zhang, Kun Yang</dc:creator>
    </item>
    <item>
      <title>CrossRF: A Domain-Invariant Deep Learning Approach for RF Fingerprinting</title>
      <link>https://arxiv.org/abs/2505.18200</link>
      <description>arXiv:2505.18200v1 Announce Type: new 
Abstract: Radio Frequency (RF) fingerprinting offers a promising approach for drone identification and security, although it suffers from significant performance degradation when operating on different transmission channels. This paper presents CrossRF, a domain-invariant deep learning approach that addresses the problem of cross-channel RF fingerprinting for Unmanned Aerial Vehicle (UAV) identification. Our approach aims to minimize the domain gap between different RF channels by using adversarial learning to train a more robust model that maintains consistent identification performance despite channel variations. We validate our approach using the UAVSig dataset, comprising real-world over-the-air RF signals from identical drone models operating across several frequency channels, ensuring that the findings correspond to real-world scenarios. The experimental results show CrossRF's efficiency, achieving up to 99.03% accuracy when adapting from Channel 3 to Channel 4, compared to only 26.39% using conventional methods. The model maintains robust performance in more difficult multi-channel scenarios (87.57% accuracy adapting from Channels 1,3 to 2,4) and achieves 89.45% accuracy with 0.9 precision for controller classification. These results confirm CrossRF's ability to significantly reduce performance degradation due to cross-channel variations while maintaining high identification accuracy with minimal training data requirements, making it particularly suitable for practical drone security applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18200v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fahrettin Emin Tiras, Hayriye Serra Altinoluk</dc:creator>
    </item>
    <item>
      <title>CC-OTDR Sequence Shaping Enabling Joint Co-directional Sensing and Communication</title>
      <link>https://arxiv.org/abs/2505.18225</link>
      <description>arXiv:2505.18225v1 Announce Type: new 
Abstract: CC-OTDR signal envelope shaping is introduced to reduce the impact of non-linear signal interactions on a neighboring wavelength data channel when co-propagating the probing signal with the data signal. Joint co-directional acoustic sensing and 200 Gbps transmission are demonstrated over a 50 km link.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18225v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. Ali Allousch, Andr\'e Sandmann</dc:creator>
    </item>
    <item>
      <title>Current-Steering DAC Architecture Design for Amplitude Mismatch Error Minimization</title>
      <link>https://arxiv.org/abs/2505.18353</link>
      <description>arXiv:2505.18353v1 Announce Type: new 
Abstract: We propose a novel digital-to-analog converter (DAC) weighting architecture that statistically minimizes the distortion caused by random current mismatches. Unlike binary, thermometer-coded, and segmented DACs, the current weights of the proposed architecture are not an integer power of 2 or any other integer number. We present a heuristic algorithm for a static mapping of DAC input codewords into corresponding DAC switches. High-level Matlab simulations are performed to illustrate the static performance improvement over the segmented structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18353v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ISCAS58744.2024.10558417</arxiv:DOI>
      <dc:creator>Ramin Babaee, Shahab Oveis Gharan, Martin Bouchard</dc:creator>
    </item>
    <item>
      <title>Frequency and Bandwidth Design of FR3-Band Acoustic Filters</title>
      <link>https://arxiv.org/abs/2505.18388</link>
      <description>arXiv:2505.18388v1 Announce Type: new 
Abstract: This article presents an approach to control the operating frequency and fractional bandwidth (FBW) of miniature acoustic filters in thin-film lithium niobate (TFLN). More specifically, we used the first-order antisymmetric (A1) mode in lateral-field-excited bulk acoustic wave resonators (XBARs) to achieve efficient operation at 20.5 GHz. Our technique leverages the thickness-dependent resonance frequency of A1 XBARs, combined with the in-plane anisotropic properties of 128$^\circ$ Y-cut TFLN, to customize filter characteristics. The implemented three-element ladder filter prototype achieves an insertion loss (IL) of only 1.79 dB and a controlled 3-dB FBW of 8.58% at 20.5 GHz, with an out-of-band (OoB) rejection greater than 14.9 dB across the entire FR3 band, while featuring a compact footprint of 0.90 $\times$ 0.74 mm$^2$. Moreover, an eight-element filter prototype shows an IL of 3.80 dB, an FBW of 6.12% at 22.0 GHz, and a high OoB rejection of 22.97 dB, demonstrating the potential for expanding to higher-order filters. As frequency allocation requirements become more stringent in future FR3 bands, our technique showcases promising capability in enabling compact and monolithic filter banks toward next-generation acoustic filters for 6G and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18388v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taran Anusorn, Omar Barrera, Jack Kramer, Ian Anderson, Ziqian Yao, Vakhtang Chulukhadze, Ruochen Lu</dc:creator>
    </item>
    <item>
      <title>A DSP-Free Carrier Phase Recovery System using 16-Offset-QAM Laser Forwarded Links for 400Gb/s and Beyond</title>
      <link>https://arxiv.org/abs/2505.18534</link>
      <description>arXiv:2505.18534v1 Announce Type: new 
Abstract: Optical interconnects are becoming a major bottleneck in scaling up future GPU racks and network switches within data centers. Although 200 Gb/s optical transceivers using PAM-4 modulation have been demonstrated, achieving higher data rates and energy efficiencies requires high-order coherent modulations like 16-QAM. Current coherent links rely on energy-intensive digital signal processing (DSP) for channel impairment compensation and carrier phase recovery (CPR), which consumes approximately 50pJ/b - 10x higher than future intra-data center requirements. For shorter links, simpler or DSP-free CPR methods can significantly reduce power and complexity. While Costas loops enable CPR for QPSK, they face challenges in scaling to higher-order modulations (e.g., 16/64-QAM) due to varying symbol amplitudes. In this work, we propose an optical coherent link architecture using laser forwarding and a novel DSP-free CPR system using offset-QAM modulation. The proposed analog CPR feedback loop is highly scalable, capable of supporting arbitrary offset-QAM modulations without requiring architectural modifications. This scalability is achieved through its phase error detection mechanism, which operates independently of the data rate and modulation type. We validated this method using GlobalFoundry's monolithic 45nm silicon photonics PDK models, with circuit- and system-level implementation at 100GBaud in the O-band. We will investigate the feedback loop dynamics, circuit-level implementations, and phase-noise performance of the proposed CPR loop. Our method can be adopted to realize low-power QAM optical interconnects for future coherent-lite pluggable transceivers as well as co-packaged optics (CPO) applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18534v1</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marziyeh Rezaei, Dan Sturm, Pengyu Zeng, Sajjad Moazeni</dc:creator>
    </item>
    <item>
      <title>FDMA-Based Passive Multiple Users SWIPT Utilizing Resonant Beams</title>
      <link>https://arxiv.org/abs/2505.18641</link>
      <description>arXiv:2505.18641v1 Announce Type: new 
Abstract: The rapid development of IoT technology has led to a shortage of spectrum resources and energy, giving rise to simultaneous wireless information and power transfer (SWIPT) technology. However, traditional multiple input multiple output (MIMO)-based SWIPT faces challenges in target detection. We have designed a passive multi-user resonant beam system (MU-RBS) that can achieve efficient power transfer and communication through adaptive beam alignment. The frequency division multiple access (FDMA) is employed in the downlink (DL) channel, while frequency conversion is utilized in the uplink (UL) channel to avoid echo interference and co-channel interference, and the system architecture design and corresponding mathematical model are presented. The simulation results show that MU-RBS can achieve adaptive beam-forming without the target transmitting pilot signals, has high directivity, and as the number of iterations increases, the power transmission efficiency, signal-to-noise ratio and spectral efficiency of the UL and DL are continuously optimized until the system reaches the optimal state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18641v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixuan Guo, Mingliang Xiong, Wen Fang, Qingwei Jiang, Qingwen Liu, Gang Yan</dc:creator>
    </item>
    <item>
      <title>EOTNet: Deep Memory Aided Bayesian Filter for Extended Object Tracking</title>
      <link>https://arxiv.org/abs/2505.18684</link>
      <description>arXiv:2505.18684v1 Announce Type: new 
Abstract: Extended object tracking methods based on random matrices, founded on Bayesian filters, have been able to achieve efficient recursive processes while jointly estimating the kinematic states and extension of the targets. Existing random matrix approaches typically assume that the evolution of state and extension follows a first-order Markov process, where the current estimate of the target depends solely on the previous moment. However, in real-world scenarios, this assumption fails because the evolution of states and extension is usually non-Markovian. In this paper, we introduce a novel extended object tracking method: a Bayesian recursive neural network assisted by deep memory. Initially, we propose an equivalent model under a non-Markovian assumption and derive the implementation of its Bayesian filtering framework. Thereafter, Gaussian approximation and moment matching are employed to derive the analytical solution for the proposed Bayesian filtering framework. Finally, based on the closed-form solution, we design an end-to-end trainable Bayesian recursive neural network for extended object tracking. Experiment results on simulated and real-world datasets show that the proposed methods outperforms traditional extended object tracking methods and state-of-the-art deep learning approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18684v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhixing Wang, Le Zheng, Shi Yan, Ruud J. G. van Sloun, Nir Shlezinger, Yonina C. Eldar</dc:creator>
    </item>
    <item>
      <title>Waveform Coexistence-Driven RSMA: A Pioneering Strategy for Future 6G Networks</title>
      <link>https://arxiv.org/abs/2505.18739</link>
      <description>arXiv:2505.18739v1 Announce Type: new 
Abstract: Two critical approaches have emerged in the literature for the successful realization of 6G wireless networks: the coexistence of multiple waveforms and the adoption of non-orthogonal multiple access. These strategies hold transformative potential for addressing the limitations of current systems and enabling the robust and scalable design of next-generation wireless networks. This paper presents a novel rate splitting multiple access (RSMA) framework that leverages the coexistence of affine frequency division multiplexing (AFDM) and orthogonal frequency division multiplexing (OFDM). By transmitting common data via AFDM at higher power in the affine domain and private data via OFDM at lower power in the frequency domain, the proposed framework eliminates the reliance on successive interference cancellation (SIC), significantly simplifying receiver design. Furthermore, two data mapping approaches are proposed: a clean pilot method, where pilots are allocated without any data overlapping, ensuring clear separation, and an embedded pilot method, where pilots overlap with data for more efficient resource utilization. Channel estimation is then performed for different channel types. Simulation results demonstrate the robustness and efficiency of the proposed approach, achieving superior performance in efficiency, reliability, and adaptability under diverse channel conditions. This framework transforms non-orthogonal multi-access design, paving the way for scalable and efficient solutions in 6G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18739v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kenza Abela, Shaima Abidrabbu, Ayoub Ammar Boudjelal, Huseyin Arslan</dc:creator>
    </item>
    <item>
      <title>Season-Independent PV Disaggregation Using Multi-Scale Net Load Temporal Feature Extraction and Weather Factor Fusion</title>
      <link>https://arxiv.org/abs/2505.18747</link>
      <description>arXiv:2505.18747v1 Announce Type: new 
Abstract: With the advancement of energy Internet and energy system integration, the increasing adoption of distributed photovoltaic (PV) systems presents new challenges on smart monitoring and measurement for utility companies, particularly in separating PV generation from net electricity load. Existing methods struggle with feature extraction from net load and capturing the relevance between weather factors. This paper proposes a PV disaggregation method that integrates Hierarchical Interpolation (HI) and multi-head self-attention mechanisms. By using HI to extract net load features and multi-head self-attention to capture the complex dependencies between weather factors, the method achieves precise PV generation predictions. Simulation experiments demonstrate the effectiveness of the proposed method in real-world data, supporting improved monitoring and management of distributed energy systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18747v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/EI264398.2024.10990379</arxiv:DOI>
      <dc:creator>Xiaolu Chen, Chenghao Huang, Yanru Zhang, Hao Wang</dc:creator>
    </item>
    <item>
      <title>Distributed Expectation Propagation for Multi-Object Tracking over Sensor Networks</title>
      <link>https://arxiv.org/abs/2505.18795</link>
      <description>arXiv:2505.18795v1 Announce Type: new 
Abstract: In this paper, we present a novel distributed expectation propagation algorithm for multiple sensors, multiple objects tracking in cluttered environments. The proposed framework enables each sensor to operate locally while collaboratively exchanging moment estimates with other sensors, thus eliminating the need to transmit all data to a central processing node. Specifically, we introduce a fast and parallelisable Rao-Blackwellised Gibbs sampling scheme to approximate the tilted distributions, which enhances the accuracy and efficiency of expectation propagation updates. Results demonstrate that the proposed algorithm improves both communication and inference efficiency for multi-object tracking tasks with dynamic sensor connectivity and varying clutter levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18795v1</guid>
      <category>eess.SP</category>
      <category>cs.RO</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qing Li, Runze Gan, James R. Hopgood, Michael E. Davies, Simon J. Godsill</dc:creator>
    </item>
    <item>
      <title>A Derivative-Free Position Optimization Approach for Movable Antenna Multi-User Communication Systems</title>
      <link>https://arxiv.org/abs/2505.19012</link>
      <description>arXiv:2505.19012v1 Announce Type: new 
Abstract: Movable antennas (MAs) have emerged as a disruptive technology in wireless communications for enhancing spatial degrees of freedom through continuous antenna repositioning within predefined regions, thereby creating favorable channel propagation conditions. In this paper, we study the problem of position optimization for MA-enabled multi-user MISO systems, where a base station (BS), equipped with multiple MAs, communicates with multiple users each equipped with a single fixed-position antenna (FPA). To circumvent the difficulty of acquiring the channel state information (CSI) from the transmitter to the receiver over the entire movable region, we propose a derivative-free approach for MA position optimization. The basic idea is to treat position optimization as a closed-box optimization problem and calculate the gradient of the unknown objective function using zeroth-order (ZO) gradient approximation techniques. Specifically, the proposed method does not need to explicitly estimate the global CSI. Instead, it adaptively refines its next movement based on previous measurements such that it eventually converges to an optimum or stationary solution. Simulation results show that the proposed derivative-free approach is able to achieve higher sample and computational efficiencies than the CSI estimation-based position optimization approach, particularly for challenging scenarios where the number of multi-path components (MPCs) is large or the number of pilot signals is limited.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19012v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xianlong Zeng, Jun Fang, Peilan Wang, Weidong Mei, Ying-Chang Liang</dc:creator>
    </item>
    <item>
      <title>Movable-Element STARS-Assisted Near-Field Wideband Communications</title>
      <link>https://arxiv.org/abs/2505.19048</link>
      <description>arXiv:2505.19048v1 Announce Type: new 
Abstract: A novel movable-element simultaneously transmitting and reflecting surface (ME-STARS)-assisted near-field wideband communication framework is proposed. In particular, the position of each STARS element can be adjusted to combat the significant wideband beam squint issue in the near field instead of using costly true-time delay components. Four practical ME-STARS element movement modes are proposed, namely region-based (RB), horizontal-based (HB), vertical-based (VB), and diagonal-based (DB) modes. Based on this, a near-field wideband multi-user downlink communication scenario is considered, where a sum rate maximization problem is formulated by jointly optimizing the base station (BS) precoding, ME-STARS beamforming, and element positions. To solve this intractable problem, a two-layer algorithm is developed. For the inner layer, the block coordinate descent optimization framework is utilized to solve the BS precoding and ME-STARS beamforming in an iterative manner. For the outer layer, the particle swarm optimization-based heuristic search method is employed to determine the desired element positions. Numerical results show that:1) the ME-STARSs can effectively address the beam squint for near-field wideband communications compared to conventional STARSs with fixed element positions; 2) the RB mode achieves the most efficient beam squint effect mitigation, while the DB mode achieves the best trade-off between performance gain and hardware overhead; and 3) an increase in the number of ME-STARS elements or BS subcarriers substantially improves the system performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19048v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangyu Zhu, Xidong Mu, Li Guo, Ao Huang, Shibiao Xu</dc:creator>
    </item>
    <item>
      <title>Foundation Model for Wireless Technology Recognition Using IQ Timeseries</title>
      <link>https://arxiv.org/abs/2505.19390</link>
      <description>arXiv:2505.19390v1 Announce Type: new 
Abstract: Wireless Technology Recognition (WTR) is essential in modern communication systems, enabling efficient spectrum management and the seamless coexistence of diverse technologies. In real-world conditions, WTR solutions should be able to handle signals from various resources with different sampling rates, capturing devices, and frequency bands. However, traditional WTR methods, which rely on energy detection, Convolutional Neural Network (CNN) models, or Deep Learning (DL), lack the robustness and adaptability required to generalize across unseen environments, different sampling devices, and previously unencountered signal classes. In this work, we introduce a Transformer-based foundation model for WTR, trained in an unsupervised manner on large-scale, unlabeled wireless signal datasets. Foundation models are designed to learn general-purpose representations that transfer effectively across tasks and domains, allowing generalization towards new technologies and WTR sampling devices. Our approach leverages input patching for computational efficiency and incorporates a two-stage training pipeline: unsupervised pre-training followed by lightweight fine-tuning. This enables the model to generalize to new wireless technologies and environments using only a small number of labeled samples. Experimental results demonstrate that our model achieves superior accuracy across varying sampling rates and frequency bands while maintaining low computational complexity, supporting the vision of a reusable wireless foundation model adaptable to new technologies with minimal retraining.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19390v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammad Cheraghinia, Eli De Poorter, Jaron Fontaine, Merouane Debbah, Adnan Shahid</dc:creator>
    </item>
    <item>
      <title>Empirical 3D Channel Modeling for Cellular-Connected UAVs: A Triple-Layer Machine Learning Approach</title>
      <link>https://arxiv.org/abs/2505.19478</link>
      <description>arXiv:2505.19478v1 Announce Type: new 
Abstract: This work proposes an empirical air to ground (A2G) propagation model specifically designed for cellular connected unmanned aerial vehicles (UAVs). An in depth aerial drive test was carried out within an operating Long Term Evolution (LTE) network, gathering thorough measurements of key network parameters. Rigid preprocessing and statistical analysis of these data produced a strong foundation for training a new triple layer machine learning (ML) model. The proposed ML framework employs a systematic hierarchical approach. Accordingly, the first two layers, Stepwise Linear Regression (STW) and Ensemble of Bagged Trees (EBT) generate predictions independently, meanwhile, the third layer, Gaussian Process Regression (GPR), explicitly acts as an aggregation layer, refining these predictions to accurately estimate Key Performance Indicators (KPIs) such as Reference Signal Received Power (RSRP), Reference Signal Received Quality (RSRQ), Received Signal Strength (RSSI), and Path Loss (PL). Compared to traditional single layer ML or computationally intensive ray tracing approaches, the proposed triple layer ML framework significantly improves predictive accuracy and robustness, achieving around 99 percent accuracy in training and above 90 percent in testing while utilizing a minimal but effective feature set log transformed 3D and 2D propagation distances, azimuth, and elevation angles. This streamlined feature selection substantially reduces computing complexity, thus enhancing scalability across various operating environments. The proposed frameworks practicality and efficacy for real world deployment in UAV integrated cellular networks are further demonstrated by comparative analyses, which underscore its substantial improvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19478v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haider A. H. Alobaidy, Mehran Behjati, Rosdiadee Nordin, Muhammad Aidiel Zulkifley, Nor Fadzilah Abdullah, Nur Fahimah Mat Salleh</dc:creator>
    </item>
    <item>
      <title>Near-Field Secure Beamfocusing With Receiver-Centered Protected Zone</title>
      <link>https://arxiv.org/abs/2505.19523</link>
      <description>arXiv:2505.19523v1 Announce Type: new 
Abstract: This work studies near-field secure communications through transmit beamfocusing. We examine the benefit of having a protected eavesdropper-free zone around the legitimate receiver, and we determine the worst-case secrecy performance against a potential eavesdropper located anywhere outside the protected zone. A max-min optimization problem is formulated for the beamfocusing design with and without artificial noise transmission. Despite the NP-hardness of the problem, we develop a synchronous gradient descent-ascent framework that approximates the global maximin solution. A low-complexity solution is also derived that delivers excellent performance over a wide range of operating conditions. We further extend this study to a scenario where it is not possible to physically enforce a protected zone. To this end, we consider secure communications through the creation of a virtual protected zone using a full-duplex legitimate receiver. Numerical results demonstrate that exploiting either the physical or virtual receiver-centered protected zone with appropriately designed beamfocusing is an effective strategy for achieving secure near-field communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19523v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cen Liu, Xiangyun Zhou, Nan Yang, Salman Durrani, A. Lee Swindlehurst</dc:creator>
    </item>
    <item>
      <title>Water Level Sensing via Communication Signals in a Bi-Static System</title>
      <link>https://arxiv.org/abs/2505.19539</link>
      <description>arXiv:2505.19539v1 Announce Type: new 
Abstract: Accurate water level sensing is essential for flood monitoring, agricultural irrigation, and water resource optimization. Traditional methods require dedicated sensor deployments, leading to high installation costs, vulnerability to interference, and limited resolution. This work proposes PMNs-WaterSense, a novel scheme leveraging Channel State Information (CSI) from existing mobile networks for water level sensing. Our scheme begins with a CSI-power method to eliminate phase offsets caused by clock asynchrony in bi-static systems. We then apply multi-domain filtering across the time (Doppler), frequency (delay), and spatial (Angle-of-Arrival, AoA) domains to extract phase features that finely capture variations in path length over water. To resolve the $2\pi$ phase ambiguity, we introduce a Kalman filter-based unwrapping technique. Additionally, we exploit transceiver geometry to convert path length variations into water level height changes, even with limited antenna configurations. We validate our framework through controlled experiments with 28 GHz mmWave and 3.1 GHz LTE signals in real time, achieving average height estimation errors of 0.025 cm and 0.198 cm, respectively. Moreover, real-world river monitoring with 2.6 GHz LTE signals achieves an average error of 4.8 cm for a 1-meter water level change, demonstrating its effectiveness in practical deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19539v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhongqin Wang, J. Andrew Zhang, Kai Wu, Y. Jay Guo</dc:creator>
    </item>
    <item>
      <title>Accurate Radar-Based Detection of Sleep Apnea Using Overlapping Time-Interval Averaging</title>
      <link>https://arxiv.org/abs/2505.19701</link>
      <description>arXiv:2505.19701v1 Announce Type: new 
Abstract: Radar-based respiratory measurement is a promising tool for the noncontact detection of sleep apnea. Our team has reported that apnea events can be accurately detected using the statistical characteristics of the amplitude of respiratory displacement. However, apnea and hypopnea events are often followed by irregular breathing, reducing the detection accuracy. This study proposes a new method to overcome this performance degradation by repeatedly applying the detection method to radar data sets corresponding to multiple overlapping time intervals. Averaging the detected classes over multiple time intervals gives an analog value between 0 and 1, which can be interpreted as the probability that there is an apnea event. We show that the proposed method can mitigate the effect of irregular breathing that occurs after apnea / hypopnea events, and its performance is confirmed by experimental data taken from seven patients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19701v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kodai Hasegawa, Shigeaki Okumura, Hirofumi Taki, Hironobu Sunadome, Satoshi Hamada, Susumu Sato, Kazuo Chin, Takuya Sakamoto</dc:creator>
    </item>
    <item>
      <title>Bit Error Rate and Performance Analysis of Multi-User OTFS under Nakagami-m Fading for 6G and Beyond Networks</title>
      <link>https://arxiv.org/abs/2505.19843</link>
      <description>arXiv:2505.19843v1 Announce Type: new 
Abstract: Orthogonal Time-Frequency Space modulation stands out as a promising waveform for 6G and beyond wireless communication systems, offering superior performance over conventional methods, particularly in high-mobility scenarios and dispersive channel conditions. Error performance analysis remains crucial for accurately characterizing the reliability of wireless communication systems under practical constraints. In this paper, we systematically investigate the bit error rate performance of OTFS modulation over Nakagami-m fading channels in both single-user and multi-user scenarios. In analytical approaches, mathematical frameworks are employed for distinct receiver configurations: the Single-input Single-output scenario leverages Erlang probability density function of squared-Nakagami variables to derive closed-form BER expressions, while the Single-input Multiple-output case applies moment matching techniques with Gamma approximation to model multiple user interference, subsequently yielding Signal-to-interference-plus-noise Ratio characterizations through Meijer-G functions. This study examines single-path and multi-path channel conditions, evaluating the relationship between path multiplicity and error performance metrics while considering various fading intensities through Nakagami-m fading parameters. The derived closed-form BER expressions are validated through maximum likelihood detection based Monte Carlo simulations, demonstrating strong correlation between analytical and numerical results across various SNR regions. Furthermore, comparative benchmark evaluations against conventional orthogonal frequency division multiplexing with MLD reveal that OTFS consistently achieves superior error performance in high-mobility scenarios. In multipath fading environments, OTFS achieves superior diversity gain compared to conventional OFDM, which refers to enhanced error performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19843v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emir Aslandogan, Haci Ilhan</dc:creator>
    </item>
    <item>
      <title>Power allocation for cell-free MIMO integrated sensing and communication</title>
      <link>https://arxiv.org/abs/2505.19845</link>
      <description>arXiv:2505.19845v1 Announce Type: new 
Abstract: In this paper, we investigate integrated sensing and communication (ISAC) in a cell-free (CF) multiple-input multiple-output (MIMO) network with single-antenna access points (APs), where each AP functions either as a transmitter for both sensing and communication or as a receiver for target-reflected signals. We derive closed-form Cramer-Rao lower bounds (CRLBs) for location and velocity estimation under arbitrary power allocation ratios, assuming the radar cross-section (RCS) is deterministic and unknown over the observation interval. A power allocation optimization problem is formulated to maximize the communication signal-to-interference-plus-noise ratio (SINR), subject to CRLB-based sensing constraints and per-transmitter power limits. To solve the resulting nonlinear and non-convex problem, we propose a penalty function and projection-based modified conjugate gradient algorithm with inexact line search (PP-MCG-ILS), and an alternative method based on a modified steepest descent approach (PP-MSD-ILS). Additionally, for power minimization in pure sensing scenarios, we introduce a penalty function-based normalized conjugate gradient algorithm (P-NCG-ILS). We analyze the convergence behavior and qualitatively compare the computational complexity of the proposed algorithms. Simulation results confirm the accuracy of the derived CRLBs and demonstrate the effectiveness of the proposed power allocation strategies in enhancing both sensing and overall ISAC performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19845v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guoqing Xia, Pei Xiao, Qu Luo, Bing Ji, Yue Zhang, Huiyu Zhou</dc:creator>
    </item>
    <item>
      <title>OFDMA for Pinching Antenna Systems</title>
      <link>https://arxiv.org/abs/2505.19902</link>
      <description>arXiv:2505.19902v1 Announce Type: new 
Abstract: Pinching-antenna (PA) systems route millimeter wave (mmWave) signals through a leaky waveguide and radiate them at "pinch" apertures, offering low-cost line-of-sight (LoS) coverage. However, when multiple PAs serve multiple users simultaneously, the downlink channel becomes strongly frequency-selective, creating inter-symbol interference (ISI) that existing single-carrier designs overlook. This paper models the overall channel as a finite impulse response (FIR) filter, characterizes its frequency selectivity, and explicitly accounts for the resulting ISI. To overcome ISI, we introduce an orthogonal frequency-division multiple access (OFDMA)-based framework and formulate a max-min resource-allocation problem to achieve user fairness. A lightweight two-stage heuristic-greedy subcarrier assignment, followed by per-user water-filling, achieves near-optimal fairness with polynomial complexity. Simulation results for an indoor layout demonstrate that the proposed scheme notably increases the minimum user rate compared to time-division single-carrier baselines and remains robust under moderate LoS blockage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19902v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thrassos K. Oikonomou, Sotiris A. Tegos, Panagiotis D. Diamantoulakis, Yuanwei Liu, George K. Karagiannidis</dc:creator>
    </item>
    <item>
      <title>On the Robustness of RSMA to Adversarial BD-RIS-Induced Interference</title>
      <link>https://arxiv.org/abs/2505.20146</link>
      <description>arXiv:2505.20146v1 Announce Type: new 
Abstract: This article investigates the robustness of rate-splitting multiple access (RSMA) in multi-user multiple-input multiple-output (MIMO) systems to interference attacks against channel acquisition induced by beyond-diagonal RISs (BD-RISs). Two primary attack strategies, random and aligned interference, are proposed for fully connected and group-connected BD-RIS architectures. Valid random reflection coefficients are generated exploiting the Takagi factorization, while potent aligned interference attacks are achieved through optimization strategies based on a quadratically constrained quadratic program (QCQP) reformulation followed by projections onto the unitary manifold. Our numerical findings reveal that, when perfect channel state information (CSI) is available, RSMA behaves similarly to space-division multiple access (SDMA) and thus is highly susceptible to the attack, with BD-RIS inducing severe performance loss and significantly outperforming diagonal RIS. However, under imperfect CSI, RSMA consistently demonstrates significantly greater robustness than SDMA, particularly as the system's transmit power increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20146v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Arthur S. de Sena, Jacek Kibilda, Nurul H. Mahmood, Andre Gomes, Luiz A. DaSilva, Matti Latva-aho</dc:creator>
    </item>
    <item>
      <title>Identification of Power System Dynamic Model Parameters using the Fisher Information Matrix</title>
      <link>https://arxiv.org/abs/2505.20200</link>
      <description>arXiv:2505.20200v1 Announce Type: new 
Abstract: The expected decrease in system inertia and frequency stability motivates the development and maintenance of dynamic system models by Transmission System Operators. However, some dynamic model parameters can be unavailable due to market unbundling, or inaccurate due to aging infrastructure, non-documented tuning of controllers, or other factors. In this paper, we propose the use of a numerical approximation of the Fisher Information Matrix (nFIM) for efficient inference of dynamic model parameters. Thanks to the proposed numerical implementation, the method is scalable to Electromagnetic Transient (EMT) models, which can quickly become computationally complex even for small study systems. Case studies show that the nFIM is coherent with parameter variances of single- and multi-parameter least-squares estimators when applied to an IEEE 9-bus dynamic model with artificial measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20200v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dawn Virginillo, Asja Dervi\v{s}kadi\'c, Mario Paolone</dc:creator>
    </item>
    <item>
      <title>Interpretable Multi-Task PINN for Emotion Recognition and EDA Prediction</title>
      <link>https://arxiv.org/abs/2505.18169</link>
      <description>arXiv:2505.18169v1 Announce Type: cross 
Abstract: Understanding and predicting human emotional and physiological states using wearable sensors has important applications in stress monitoring, mental health assessment, and affective computing. This study presents a novel Multi-Task Physics-Informed Neural Network (PINN) that performs Electrodermal Activity (EDA) prediction and emotion classification simultaneously, using the publicly available WESAD dataset. The model integrates psychological self-report features (PANAS and SAM) with a physics-inspired differential equation representing EDA dynamics, enforcing biophysically grounded constraints through a custom loss function. This loss combines EDA regression, emotion classification, and a physics residual term for improved interpretability.
  The architecture supports dual outputs for both tasks and is trained under a unified multi-task framework. Evaluated using 5-fold cross-validation, the model achieves an average EDA RMSE of 0.0362, Pearson correlation of 0.9919, and F1-score of 94.08 percent. These results outperform classical models such as SVR and XGBoost, as well as ablated variants like emotion-only and EDA-only models.
  In addition, the learned physical parameters including decay rate (alpha_0), emotional sensitivity (beta), and time scaling (gamma) are interpretable and stable across folds, aligning with known principles of human physiology. This work is the first to introduce a multi-task PINN framework for wearable emotion recognition, offering improved performance, generalizability, and model transparency. The proposed system provides a foundation for future interpretable and multimodal applications in healthcare and human-computer interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18169v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nischal Mandal</dc:creator>
    </item>
    <item>
      <title>Riemannian Flow Matching for Brain Connectivity Matrices via Pullback Geometry</title>
      <link>https://arxiv.org/abs/2505.18193</link>
      <description>arXiv:2505.18193v1 Announce Type: cross 
Abstract: Generating realistic brain connectivity matrices is key to analyzing population heterogeneity in brain organization, understanding disease, and augmenting data in challenging classification problems. Functional connectivity matrices lie in constrained spaces--such as the set of symmetric positive definite or correlation matrices--that can be modeled as Riemannian manifolds. However, using Riemannian tools typically requires redefining core operations (geodesics, norms, integration), making generative modeling computationally inefficient. In this work, we propose DiffeoCFM, an approach that enables conditional flow matching (CFM) on matrix manifolds by exploiting pullback metrics induced by global diffeomorphisms on Euclidean spaces. We show that Riemannian CFM with such metrics is equivalent to applying standard CFM after data transformation. This equivalence allows efficient vector field learning, and fast sampling with standard ODE solvers. We instantiate DiffeoCFM with two different settings: the matrix logarithm for covariance matrices and the normalized Cholesky decomposition for correlation matrices. We evaluate DiffeoCFM on three large-scale fMRI datasets with more than 4600 scans from 2800 subjects (ADNI, ABIDE, OASIS-3) and two EEG motor imagery datasets with over 30000 trials from 26 subjects (BNCI2014-002 and BNCI2015-001). It enables fast training and achieves state-of-the-art performance, all while preserving manifold constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18193v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antoine Collas, Ce Ju, Nicolas Salvy, Bertrand Thirion</dc:creator>
    </item>
    <item>
      <title>Mechanical in-sensor computing: a programmable meta-sensor for structural damage classification without external electronic power</title>
      <link>https://arxiv.org/abs/2505.18579</link>
      <description>arXiv:2505.18579v1 Announce Type: cross 
Abstract: Structural health monitoring (SHM) involves sensor deployment, data acquisition, and data interpretation, commonly implemented via a tedious wired system. The information processing in current practice majorly depends on electronic computers, albeit with universal applications, delivering challenges such as high energy consumption and low throughput due to the nature of digital units. In recent years, there has been a renaissance interest in shifting computations from electronic computing units to the use of real physical systems, a concept known as physical computation. This approach provides the possibility of thinking out of the box for SHM, seamlessly integrating sensing and computing into a pure-physical entity, without relying on external electronic power supplies, thereby properly coping with resource-restricted scenarios. The latest advances of metamaterials (MM) hold great promise for this proactive idea. In this paper, we introduce a programmable metamaterial-based sensor (termed as MM-sensor) for physically processing structural vibration information to perform specific SHM tasks, such as structural damage warning (binary classification) in this initiation, without the need for further information processing or resource-consuming, that is, the data collection and analysis are completed in-situ at the sensor level. We adopt the configuration of a locally resonant metamaterial plate (LRMP) to achieve the first fabrication of the MM-sensor. We take advantage of the bandgap properties of LRMP to physically differentiate the dynamic behavior of structures before and after damage. By inversely designing the geometric parameters, our current approach allows for adjustments to the bandgap features. This is effective for engineering systems with a first natural frequency ranging from 9.54 Hz to 81.86 Hz.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18579v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tingpeng Zhang, Xuzhang Peng, Mingyuan Zhou, Guobiao Hu, Zhilu Lai</dc:creator>
    </item>
    <item>
      <title>Simultaneous Optimization of Efficiency and Degradation in Tunable HTL-Free Perovskite Solar Cells with MWCNT-Integrated Back Contact Using a Machine Learning-Derived Polynomial Regressor</title>
      <link>https://arxiv.org/abs/2505.18693</link>
      <description>arXiv:2505.18693v1 Announce Type: cross 
Abstract: Perovskite solar cells (PSCs) without a hole transport layer (HTL) offer a cost-effective and stable alternative to conventional architectures, utilizing only an absorber layer and an electron transport layer (ETL). This study presents a machine learning (ML)-driven framework to optimize the efficiency and stability of HTL-free PSCs by integrating experimental validation with numerical simulations. Excellent agreement is achieved between a fabricated device and its simulated counterpart at a molar fraction \( x = 68.7\% \) in \(\mathrm{MAPb}_{1-x}\mathrm{Sb}_{2x/3}\mathrm{I}_3\), where MA is methylammonium. A dataset of 1650 samples is generated by varying molar fraction, absorber defect density, thickness, and ETL doping, with corresponding efficiency and 50-hour degradation as targets. A fourth-degree polynomial regressor (PR-4) shows the best performance, achieving RMSEs of 0.0179 and 0.0117, and \( R^2 \) scores of 1 and 0.999 for efficiency and degradation, respectively. The derived model generalizes beyond the training range and is used in an L-BFGS-B optimization algorithm with a weighted objective function to maximize efficiency and minimize degradation. This improves device efficiency from 13.7\% to 16.84\% and reduces degradation from 6.61\% to 2.39\% over 1000 hours. Finally, the dataset is labeled into superior and inferior classes, and a multilayer perceptron (MLP) classifier achieves 100\% accuracy, successfully identifying optimal configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18693v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ihtesham Ibn Malek, Hafiz Imtiaz, Samia Subrina</dc:creator>
    </item>
    <item>
      <title>Smart Energy Guardian: A Hybrid Deep Learning Model for Detecting Fraudulent PV Generation</title>
      <link>https://arxiv.org/abs/2505.18755</link>
      <description>arXiv:2505.18755v1 Announce Type: cross 
Abstract: With the proliferation of smart grids, smart cities face growing challenges due to cyber-attacks and sophisticated electricity theft behaviors, particularly in residential photovoltaic (PV) generation systems. Traditional Electricity Theft Detection (ETD) methods often struggle to capture complex temporal dependencies and integrating multi-source data, limiting their effectiveness. In this work, we propose an efficient ETD method that accurately identifies fraudulent behaviors in residential PV generation, thus ensuring the supply-demand balance in smart cities. Our hybrid deep learning model, combining multi-scale Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), and Transformer, excels in capturing both short-term and long-term temporal dependencies. Additionally, we introduce a data embedding technique that seamlessly integrates time-series data with discrete temperature variables, enhancing detection robustness. Extensive simulation experiments using real-world data validate the effectiveness of our approach, demonstrating significant improvements in the accuracy of detecting sophisticated energy theft activities, thereby contributing to the stability and fairness of energy systems in smart cities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18755v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ISC260477.2024.11004263</arxiv:DOI>
      <dc:creator>Xiaolu Chen, Chenghao Huang, Yanru Zhang, Hao Wang</dc:creator>
    </item>
    <item>
      <title>ALPCAHUS: Subspace Clustering for Heteroscedastic Data</title>
      <link>https://arxiv.org/abs/2505.18918</link>
      <description>arXiv:2505.18918v1 Announce Type: cross 
Abstract: Principal component analysis (PCA) is a key tool in the field of data dimensionality reduction. Various methods have been proposed to extend PCA to the union of subspace (UoS) setting for clustering data that come from multiple subspaces like K-Subspaces (KSS). However, some applications involve heterogeneous data that vary in quality due to noise characteristics associated with each data sample. Heteroscedastic methods aim to deal with such mixed data quality. This paper develops a heteroscedastic-focused subspace clustering method, named ALPCAHUS, that can estimate the sample-wise noise variances and use this information to improve the estimate of the subspace bases associated with the low-rank structure of the data. This clustering algorithm builds on K-Subspaces (KSS) principles by extending the recently proposed heteroscedastic PCA method, named LR-ALPCAH, for clusters with heteroscedastic noise in the UoS setting. Simulations and real-data experiments show the effectiveness of accounting for data heteroscedasticity compared to existing clustering algorithms. Code available at https://github.com/javiersc1/ALPCAHUS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18918v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Javier Salazar Cavazos, Jeffrey A Fessler, Laura Balzano</dc:creator>
    </item>
    <item>
      <title>Design of a Wearable Parallel Electrical Impedance Imaging System for Healthcare</title>
      <link>https://arxiv.org/abs/2505.19146</link>
      <description>arXiv:2505.19146v1 Announce Type: cross 
Abstract: A wireless wearable electrical impedance tomography (EIT) system has been developed using the AD5933 for real-time lung respiration imaging. The system uses a current injection method tailored to the human body's impedance characteristics. It applies a voltage excitation and measures the resulting current as the voltage passes through the body. Additionally, measures are taken to suppress the effects of parasitic capacitance, which can lead to signal oscillations and leakage currents. Additionally, to improve data acquisition speed, five AD5933 units are used for parallel measurements, with multiple measures taken to ensure high synchronization during the parallel acquisition process. The results demonstrate conductivity images generated from the EIT system, with data collected from a water tank, human lungs during respiration, and a human calf at rest, confirming that this portable EIT system can measure biological tissues with high precision and low cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19146v1</guid>
      <category>physics.med-ph</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bowen Li, Zekun Chen, Xuefei Chen, Luhao Zhang, Shili Liang</dc:creator>
    </item>
    <item>
      <title>RIS-Assisted Survivable Fronthaul Design in Cell-Free Massive MIMO System</title>
      <link>https://arxiv.org/abs/2505.19152</link>
      <description>arXiv:2505.19152v1 Announce Type: cross 
Abstract: This paper investigates the application of reconfigurable intelligent surfaces (RISs) to improve fronthaul link survivability in cell-free massive MIMO (CF mMIMO) systems. To enhance the fronthaul survivability, two complementary mechanisms are considered. Firstly, RIS is set to provide reliable line-of-sight (LOS) connectivity and enhance the mmWave backup link. Secondly, a resource-sharing scheme that leverages redundant cable capacity through neighboring master access points (APs) to guarantee availability is considered. We formulate the redundant capacity minimization problem as a RIS-assisted multi-user MIMO rate control optimization problem, developing a novel solution that combines a modified weighted minimum mean square error (WMMSE) algorithm for precoding design with Riemannian gradient descent for RIS phase shift optimization. Our numerical evaluations show that RIS reduces the required redundant capacity by 65.6% compared to the no RIS case to reach a 99% survivability. The results show that the most substantial gains of RIS occur during complete outages of the direct disconnected master AP-CPU channel. These results demonstrate RIS's potential to significantly enhance fronthaul reliability while minimizing infrastructure costs in next-generation wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19152v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenyu Li, \"Ozlem Tu\u{g}fe Demir, Emil Bj\"ornson, Cicek Cavdar</dc:creator>
    </item>
    <item>
      <title>BR-ASR: Efficient and Scalable Bias Retrieval Framework for Contextual Biasing ASR in Speech LLM</title>
      <link>https://arxiv.org/abs/2505.19179</link>
      <description>arXiv:2505.19179v1 Announce Type: cross 
Abstract: While speech large language models (SpeechLLMs) have advanced standard automatic speech recognition (ASR), contextual biasing for named entities and rare words remains challenging, especially at scale. To address this, we propose BR-ASR: a Bias Retrieval framework for large-scale contextual biasing (up to 200k entries) via two innovations: (1) speech-and-bias contrastive learning to retrieve semantically relevant candidates; (2) dynamic curriculum learning that mitigates homophone confusion which negatively impacts the final performance. The is a general framework that allows seamless integration of the retrieved candidates into diverse ASR systems without fine-tuning. Experiments on LibriSpeech test-clean/-other achieve state-of-the-art (SOTA) biased word error rates (B-WER) of 2.8%/7.1% with 2000 bias words, delivering 45% relative improvement over prior methods. BR-ASR also demonstrates high scalability: when expanding the bias list to 200k where traditional methods generally fail, it induces only 0.3 / 2.9% absolute WER / B-WER degradation with a 99.99% pruning rate and only 20ms latency per query on test-other.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19179v1</guid>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xun Gong, Anqi Lv, Zhiming Wang, Huijia Zhu, Yanmin Qian</dc:creator>
    </item>
    <item>
      <title>Towards a Spatiotemporal Fusion Approach to Precipitation Nowcasting</title>
      <link>https://arxiv.org/abs/2505.19258</link>
      <description>arXiv:2505.19258v1 Announce Type: cross 
Abstract: With the increasing availability of meteorological data from various sensors, numerical models and reanalysis products, the need for efficient data integration methods has become paramount for improving weather forecasts and hydrometeorological studies. In this work, we propose a data fusion approach for precipitation nowcasting by integrating data from meteorological and rain gauge stations in Rio de Janeiro metropolitan area with ERA5 reanalysis data and GFS numerical weather prediction. We employ the spatiotemporal deep learning architecture called STConvS2S, leveraging a structured dataset covering a 9 x 11 grid. The study spans from January 2011 to October 2024, and we evaluate the impact of integrating three surface station systems. Among the tested configurations, the fusion-based model achieves an F1-score of 0.2033 for forecasting heavy precipitation events (greater than 25 mm/h) at a one-hour lead time. Additionally, we present an ablation study to assess the contribution of each station network and propose a refined inference strategy for precipitation nowcasting, integrating the GFS numerical weather prediction (NWP) data with in-situ observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19258v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Felipe Curcio, Pedro Castro, Augusto Fonseca, Rafaela Castro, Raquel Franco, Eduardo Ogasawara, Victor Stepanenko, Fabio Porto, Mariza Ferro, Eduardo Bezerra</dc:creator>
    </item>
    <item>
      <title>FlowSE: Efficient and High-Quality Speech Enhancement via Flow Matching</title>
      <link>https://arxiv.org/abs/2505.19476</link>
      <description>arXiv:2505.19476v1 Announce Type: cross 
Abstract: Generative models have excelled in audio tasks using approaches such as language models, diffusion, and flow matching. However, existing generative approaches for speech enhancement (SE) face notable challenges: language model-based methods suffer from quantization loss, leading to compromised speaker similarity and intelligibility, while diffusion models require complex training and high inference latency. To address these challenges, we propose FlowSE, a flow-matching-based model for SE. Flow matching learns a continuous transformation between noisy and clean speech distributions in a single pass, significantly reducing inference latency while maintaining high-quality reconstruction. Specifically, FlowSE trains on noisy mel spectrograms and optional character sequences, optimizing a conditional flow matching loss with ground-truth mel spectrograms as supervision. It implicitly learns speech's temporal-spectral structure and text-speech alignment. During inference, FlowSE can operate with or without textual information, achieving impressive results in both scenarios, with further improvements when transcripts are available. Extensive experiments demonstrate that FlowSE significantly outperforms state-of-the-art generative methods, establishing a new paradigm for generative-based SE and demonstrating the potential of flow matching to advance the field. Our code, pre-trained checkpoints, and audio samples are available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19476v1</guid>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziqian Wang, Zikai Liu, Xinfa Zhu, Yike Zhu, Mingshuai Liu, Jun Chen, Longshuai Xiao, Chao Weng, Lei Xie</dc:creator>
    </item>
    <item>
      <title>Customising Electricity Contracts at Scale with Large Language Models</title>
      <link>https://arxiv.org/abs/2505.19551</link>
      <description>arXiv:2505.19551v1 Announce Type: cross 
Abstract: The electricity system becomes more complex, connecting massive numbers of end-users and distributed generators. Adding or removing grid connections requires expert studies to align technical constraints with user requests. In times of labour shortages, carrying out these studies represents a significant amount of time that engineers at system operators spend in planning departments. As time is limited, only standard block connectivity contracts can be offered to end-users, or the requests pile up. Even if offers are made, these often do not perfectly match the user's requirements, leading to overpaying or underusing the grid capacity. This paper investigates whether end-users can negotiate individual, flexible time-of-use contracts directly with the grid using Large Language Models (LLM) in chats at scale. The LLM-based chat has direct access to a model of the grid and studies the grid's technical constraints just as an expert engineer. The advantage of this system is that end-users can directly interact with grid models through natural language; no intermediate is needed to service, analyse, study, assess, advise, consult and engineer. This initial study paves the way toward developing this tailored LLM system, resulting in possible high-efficiency gains for grid planning and customer management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19551v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jochen L. Cremer</dc:creator>
    </item>
    <item>
      <title>Mel-McNet: A Mel-Scale Framework for Online Multichannel Speech Enhancement</title>
      <link>https://arxiv.org/abs/2505.19576</link>
      <description>arXiv:2505.19576v1 Announce Type: cross 
Abstract: Online multichannel speech enhancement has been intensively studied recently. Though Mel-scale frequency is more matched with human auditory perception and computationally efficient than linear frequency, few works are implemented in a Mel-frequency domain. To this end, this work proposes a Mel-scale framework (namely Mel-McNet). It processes spectral and spatial information with two key components: an effective STFT-to-Mel module compressing multi-channel STFT features into Mel-frequency representations, and a modified McNet backbone directly operating in the Mel domain to generate enhanced LogMel spectra. The spectra can be directly fed to vocoders for waveform reconstruction or ASR systems for transcription. Experiments on CHiME-3 show that Mel-McNet can reduce computational complexity by 60% while maintaining comparable enhancement and ASR performance to the original McNet. Mel-McNet also outperforms other SOTA methods, verifying the potential of Mel-scale speech enhancement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19576v1</guid>
      <category>eess.AS</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yujie Yang, Bing Yang, Xiaofei Li</dc:creator>
    </item>
    <item>
      <title>Capacity-Optimized Pre-Equalizer Design for Visible Light Communication Systems</title>
      <link>https://arxiv.org/abs/2505.19709</link>
      <description>arXiv:2505.19709v1 Announce Type: cross 
Abstract: Since commercial LEDs are primarily designed for illumination rather than data transmission, their modulation bandwidth is inherently limited to a few MHz. This becomes a major bottleneck in the implementation of visible light communication (VLC) systems necessiating the design of pre-equalizers. While state-of-the-art equalizer designs primarily focus on the data rate increasing through bandwidth expansion, they often overlook the accompanying degradation in signal-to-noise ratio (SNR). Achieving effective bandwidth extension without introducing excessive SNR penalties remains a significant challenge, since the channel capacity is a non-linear function of both parameters. In this paper, we present a fundamental analysis of how the parameters of the LED and pre-equalization circuits influence the channel capacity in intensity modulation and direct detection (IMDD)-based VLC systems. We derive a closed-form expression for channel capacity model that is an explicitly function of analog pre-equalizer circuit parameters. Building upon the derived capacity expression, we propose a systematic design methodology for analog pre-equalizers that effectively balances bandwidth and SNR, thereby maximizing the overall channel capacity across a wide range of channel attenuations. We present extensive numerical results to validate the effectiveness of the proposed design and demonstrate the improvements over conventional bandwidth-optimized pre-equalizer designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19709v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runxin Zhang, Yulin Shao, Jian Xiong, Lu Lu, Murat Uysal</dc:creator>
    </item>
    <item>
      <title>Task-Oriented Low-Label Semantic Communication With Self-Supervised Learning</title>
      <link>https://arxiv.org/abs/2505.19940</link>
      <description>arXiv:2505.19940v1 Announce Type: cross 
Abstract: Task-oriented semantic communication enhances transmission efficiency by conveying semantic information rather than exact messages. Deep learning (DL)-based semantic communication can effectively cultivate the essential semantic knowledge for semantic extraction, transmission, and interpretation by leveraging massive labeled samples for downstream task training. In this paper, we propose a self-supervised learning-based semantic communication framework (SLSCom) to enhance task inference performance, particularly in scenarios with limited access to labeled samples. Specifically, we develop a task-relevant semantic encoder using unlabeled samples, which can be collected by devices in real-world edge networks. To facilitate task-relevant semantic extraction, we introduce self-supervision for learning contrastive features and formulate the information bottleneck (IB) problem to balance the tradeoff between the informativeness of the extracted features and task inference performance. Given the computational challenges of the IB problem, we devise a practical and effective solution by employing self-supervised classification and reconstruction pretext tasks. We further propose efficient joint training methods to enhance end-to-end inference accuracy over wireless channels, even with few labeled samples. We evaluate the proposed framework on image classification tasks over multipath wireless channels. Extensive simulation results demonstrate that SLSCom significantly outperforms conventional digital coding methods and existing DL-based approaches across varying labeled data set sizes and SNR conditions, even when the unlabeled samples are irrelevant to the downstream tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19940v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Run Gu, Wei Xu, Zhaohui Yang, Dusit Niyato, Aylin Yener</dc:creator>
    </item>
    <item>
      <title>You Can Wash Hands Better: Accurate Daily Handwashing Assessment with a Smartwatch</title>
      <link>https://arxiv.org/abs/2112.06657</link>
      <description>arXiv:2112.06657v5 Announce Type: replace 
Abstract: Hand hygiene is among the most effective daily practices for preventing infectious diseases such as influenza, malaria, and skin infections. While professional guidelines emphasize proper handwashing to reduce the risk of viral infections, surveys reveal that adherence to these recommendations remains low. To address this gap, we propose UWash, a wearable solution leveraging smartwatches to evaluate handwashing procedures, aiming to raise awareness and cultivate high-quality handwashing habits. We frame the task of handwashing assessment as an action segmentation problem, similar to those in computer vision, and introduce a simple yet efficient two-stream UNet-like network to achieve this goal. Experiments involving 51 subjects demonstrate that UWash achieves 92.27% accuracy in handwashing gesture recognition, an error of &lt;0.5 seconds in onset/offset detection, and an error of &lt;5 points in gesture scoring under user-dependent settings. The system also performs robustly in user-independent and user-independent-location-independent evaluations. Remarkably, UWash maintains high performance in real-world tests, including evaluations with 10 random passersby at a hospital 9 months later and 10 passersby in an in-the-wild test conducted 2 years later. UWash is the first system to score handwashing quality based on gesture sequences, offering actionable guidance for improving daily hand hygiene. The code and dataset are publicly available at https://github.com/aiotgroup/UWash</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.06657v5</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TMC.2025.3571805</arxiv:DOI>
      <dc:creator>Fei Wang, Tingting Zhang, Xilei Wu, Pengcheng Wang, Xin Wang, Han Ding, Jingang Shi, Jinsong Han, Dong Huang</dc:creator>
    </item>
    <item>
      <title>GRN-Transformer: Enhancing Motion Artifact Detection in PICU Photoplethysmogram Signals</title>
      <link>https://arxiv.org/abs/2308.03722</link>
      <description>arXiv:2308.03722v2 Announce Type: replace 
Abstract: This study investigates artifact detection in clinical photoplethysmogram signals using Transformer-based models. Recent findings have shown that in detecting artifacts from the Pediatric Critical Care Unit at CHU Sainte-Justine (CHUSJ), semi-supervised learning label propagation and conventional supervised machine learning (K-nearest neighbors) outperform the Transformer-based attention mechanism, particularly in limited data scenarios. However, these methods exhibit sensitivity to data volume and limited improvement with increased data availability. We propose the GRN-Transformer, an innovative model that integrates the Gated Residual Network (GRN) into the Transformer architecture to overcome these limitations. The GRN-Transformer demonstrates superior performance, achieving remarkable metrics of 98% accuracy, 90% precision, 97% recall, and 93% F1 score, clearly surpassing the Transformer's results of 95% accuracy, 85% precision, 86% recall, and 85% F1 score. By integrating the GRN, which excels at feature extraction, with the Transformer's attention mechanism, the proposed GRN-Transformer overcomes the limitations of previous methods. It achieves smoother training and validation loss, effectively mitigating overfitting and demonstrating enhanced performance in small datasets with imbalanced classes. The GRN-Transformer's potential impact on artifact detection can significantly improve the reliability and accuracy of the clinical decision support system at CHUSJ, ultimately leading to improved patient outcomes and safety. Remarkably, the proposed model stands as the pioneer in its domain, being the first of its kind to detect artifacts from PPG signals. Further research could explore its applicability to other medical domains and datasets with similar constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.03722v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thanh-Dung Le, Clara Macabiau, K\'evin Albert, Philippe Jouvet, Rita Noumeir</dc:creator>
    </item>
    <item>
      <title>Transformer Meets Gated Residual Networks To Enhance Photoplethysmogram Artifact Detection Informed by Mutual Information Neural Estimation</title>
      <link>https://arxiv.org/abs/2405.16177</link>
      <description>arXiv:2405.16177v2 Announce Type: replace 
Abstract: This study delves into the effectiveness of various learning methods in improving Transformer models, focusing particularly on the Gated Residual Network Transformer (GRN-Transformer) in the context of pediatric intensive care units (PICU) with limited data availability. Our findings indicate that Transformers trained via supervised learning are less effective compared to MLP, CNN, and LSTM networks in such environments. Yet, leveraging unsupervised and self-supervised learning on unannotated data, with subsequent fine-tuning on annotated data, notably enhances Transformer performance, although not to the level of the GRN-Transformer. Central to our research is the analysis of different activation functions for the Gated Linear Unit (GLU), a crucial element of the GRN structure. We also employ Mutual Information Neural Estimation (MINE) to evaluate the GRN's contribution. Additionally, the study examines the effects of integrating GRN within the Transformer's Attention mechanism versus using it as a separate intermediary layer. Our results highlight that GLU with sigmoid activation stands out, achieving 0.98 accuracy, 0.91 precision, 0.96 recall, and 0.94 F1 score. The MINE analysis supports the hypothesis that GRN enhances the mutual information between the hidden representations and the output. Moreover, the use of GRN as an intermediate filter layer proves more beneficial than incorporating it within the Attention mechanism. In summary, this research clarifies how GRN bolsters GRN-Transformer's performance, surpassing other learning techniques. These findings offer a promising avenue for adopting sophisticated models like Transformers in data-constrained environments, such as PPG artifact detection in PICU settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16177v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thanh-Dung Le, Clara Macabiau, K\'evin Albert, Symeon Chatzinotas, Philippe Jouvet, Rita Noumeir</dc:creator>
    </item>
    <item>
      <title>Semi-Supervised Model-Free Bayesian State Estimation from Compressed Measurements</title>
      <link>https://arxiv.org/abs/2407.07368</link>
      <description>arXiv:2407.07368v5 Announce Type: replace 
Abstract: We consider data-driven Bayesian state estimation from compressed measurements (BSCM) of a model-free process. The dimension of the temporal measurement vector is lower than that of the temporal state vector to be estimated, leading to an under-determined inverse problem. The underlying dynamical model of the state's evolution is unknown for a 'model-free process.' Hence, it is difficult to use traditional model-driven methods, for example, Kalman and particle filters. Instead, we consider data-driven methods. We experimentally show that two existing unsupervised learning-based data-driven methods fail to address the BSCM problem in a model-free process. The methods are -- data-driven nonlinear state estimation (DANSE) and deep Markov model (DMM). While DANSE provides good predictive/forecasting performance to model the temporal measurement data as a time series, its unsupervised learning lacks suitable regularization for tackling the BSCM task. We then propose a semi-supervised learning approach and develop a semi-supervised learning-based DANSE method, referred to as SemiDANSE. In SemiDANSE, we use a large amount of unlabelled data along with a limited amount of labelled data, i.e., pairwise measurement-and-state data, which provides the desired regularization. Using three benchmark dynamical systems, we empirically show that the data-driven SemiDANSE provides competitive state estimation performance for BSCM using a handful of different measurement systems, against a hybrid method called KalmanNet and two model-driven methods (extended Kalman filter and unscented Kalman filter) that know the dynamical models exactly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07368v5</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anubhab Ghosh, Yonina C. Eldar, Saikat Chatterjee</dc:creator>
    </item>
    <item>
      <title>A Homogeneous Graph Neural Network for Precoding and Power Allocation in Scalable Wireless Networks</title>
      <link>https://arxiv.org/abs/2408.17252</link>
      <description>arXiv:2408.17252v3 Announce Type: replace 
Abstract: Deep learning is widely used in wireless communications but struggles with fixed neural network sizes, which limit their adaptability in environments where the number of users and antennas varies. To overcome this, this paper introduced a generalization strategy for precoding and power allocation in scalable wireless networks. Initially, we employ an innovative approach to abstract the wireless network into a homogeneous graph. This primarily focuses on bypassing the heterogeneous features between transmitter (TX) and user entities to construct a virtual homogeneous graph serving optimization objectives, thereby enabling all nodes in the virtual graph to share the same neural network. This ``TX entity'' is known as a base station (BS) in cellular networks and an access point (AP) in cell-free networks. Subsequently, we design a universal graph neural network, termed the information carrying graph neural network (ICGNN), to capture and integrate information from this graph, maintaining permutation invariance. Lastly, using ICGNN as the core algorithm, we tailor the neural network's input and output for specific problem requirements and validate its performance in two scenarios: 1) in cellular networks, we develop a matrix-inverse-free multi-user multi-input multi-output (MU-MIMO) precoding scheme using the conjugate gradient (CG) method, adaptable to varying user and antenna numbers; 2) in a cell-free network, facing dynamic variations in the number of users served by APs, the number of APs serving each user, and the number of antennas per AP, we propose a universal power allocation scheme. Simulations demonstrate that the proposed approach not only significantly reduces computational complexity but also achieves, and potentially exceeds, the spectral efficiency (SE) of conventional algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.17252v3</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingjun Sun, Shaochuan Wu, Haojie Wang, Yuanwei Liu, Guoyu Li, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>High-resolution urban air pollution and thermal comfort mapping: an application of drive mobile sensing platform for smart city services</title>
      <link>https://arxiv.org/abs/2412.17831</link>
      <description>arXiv:2412.17831v2 Announce Type: replace 
Abstract: Air pollutant exposure exhibits significant spatial and temporal variability, with localized hotspots, particularly in traffic microenvironments, posing health risks to commuters. Although widely used for air quality assessment, fixed-site monitoring stations are limited by sparse distribution, high costs, and maintenance needs, making them less effective in capturing on-road pollution levels. This study utilizes a fleet of 314 taxis equipped with sensors to measure NO\textsubscript{2}, PM\textsubscript{2.5}, and PM\textsubscript{10} concentrations and identify high-exposure hotspots. The findings reveal disparities between mobile and stationary measurements, map the spatiotemporal exposure patterns, and highlight local hotspots. These results demonstrate the potential of mobile monitoring to provide fine-scale, on-road air pollution assessments, offering valuable insights for policymakers to design targeted interventions and protect public health, particularly for sensitive populations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17831v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hui Zhong, Hongliang Lu, Ting Gand, Yonghong Liud, Xinhu Zheng</dc:creator>
    </item>
    <item>
      <title>SDM Optical Systems with MMSE Equalizers: Information Rates and Performance Monitoring</title>
      <link>https://arxiv.org/abs/2501.18765</link>
      <description>arXiv:2501.18765v2 Announce Type: replace 
Abstract: The information rate of coupled space-division multiplexing (SDM) transmission systems is impaired by the stochastic effects of mode-dependent gain (MDG) and mode-dependent loss (MDL), turning it into a random variable and reducing its average value. In systems operating with minimum mean squared error (MMSE) equalizers and no channel-state information (CSI), co-channel interference further reduces the instantaneous and average information rates. Analytical solutions for the average information rate in MDG- and MDL-impaired systems under strong coupling have been presented in early studies assuming ideal maximum-likelihood (ML) equalization. However, to the best of our knowledge, a solution encompassing co-channel interference under MMSE equalization has not been presented yet. In this work, we derive statistical models for the MMSE equalizer coefficients and develop analytical solutions for the post-filtering information rate. We also use these statistical models and analytical solutions to carry out MDG and signal-to-noise ratio (SNR) monitoring in coupled SDM systems. The derived analytical solutions and monitoring techniques are validated by Monte-Carlo simulations, exhibiting a suitable accuracy within practical operational values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18765v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/JLT.2025.3573029</arxiv:DOI>
      <dc:creator>Lucas Alves Zischler, Darli A. A. Mello</dc:creator>
    </item>
    <item>
      <title>A Sigma Point-based Low Complexity Algorithm for Multipath-based SLAM in MIMO Systems</title>
      <link>https://arxiv.org/abs/2503.15286</link>
      <description>arXiv:2503.15286v2 Announce Type: replace 
Abstract: Multipath-based simultaneous localization and mapping (MP-SLAM) is a promising approach in wireless networks to jointly obtain position information of transmitters/receivers and information of the propagation environment. MP-SLAM models specular reflections at flat surfaces as virtual anchors (VAs), which are mirror images of base stations. Particle-based methods offer high flexibility and can approximate posterior probability density functions of the mobile agent state and the map feature states, (i.e., VA states) with complex shapes. However, they often require a large number of particles to counteract degeneracy in high-dimensional parameter spaces, leading to high computational complexity. Conversely using an insufficient number of particles leads to reduced estimation accuracy. In this paper, we introduce a low-complexity MP-SLAM algorithm using a sigma point (SP)-based implementation of the sum-product algorithm (SPA). We model the messages of continuous states of the agent and the VAs as Gaussian distributions and approximate nonlinearities via SP-transformations. This approach substantially reduces the computational complexity without decreasing accuracy. Since probabilistic data association yields Gaussian mixtures for the agent and VA states, we use moment matching to combine each mixture into a single Gaussian. Numerical results using synthetic and real data demonstrate that our method achieves significantly reduced computational runtimes compared to particle-based schemes, while exhibiting comparable (or even superior) localization and mapping performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15286v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Masiero, Alexander Venus, Erik Leitinger</dc:creator>
    </item>
    <item>
      <title>Conformal Robust Beamforming via Generative Channel Models</title>
      <link>https://arxiv.org/abs/2504.06934</link>
      <description>arXiv:2504.06934v2 Announce Type: replace 
Abstract: Traditional approaches to outage-constrained beamforming optimization rely on statistical assumptions about channel distributions and estimation errors. However, the resulting outage probability guarantees are only valid when these assumptions accurately reflect reality. This paper tackles the fundamental challenge of providing outage probability guarantees that remain robust regardless of specific channel or estimation error models. To achieve this, we propose a two-stage framework: (i) construction of a channel uncertainty set using a generative channel model combined with conformal prediction, and (ii) robust beamforming via the solution of a min-max optimization problem. The proposed method separates the modeling and optimization tasks, enabling principled uncertainty quantification and robust decision-making. Simulation results confirm the effectiveness and reliability of the framework in achieving model-agnostic outage guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06934v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Su, Qiushuo Hou, Ruisi He, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Autoregressive Stochastic Clock Jitter Compensation in Analog-to-Digital Converters</title>
      <link>https://arxiv.org/abs/2505.05030</link>
      <description>arXiv:2505.05030v2 Announce Type: replace 
Abstract: This paper deals with the mathematical modeling and compensation of stochastic discrete time clock jitter in Analog-to-Digital Converters (ADCs). Two novel, computationally efficient de-jittering sample pilots-based algorithms for baseband signals are proposed: one consisting in solving a sequence of weighted least-squares problems and another that fully leverages the correlated jitter structure in a Kalman filter-type routine. Alongside, a comprehensive and rigorous mathematical analysis of the linearization errors committed is presented, and the work is complemented with extensive synthetic simulations and performance benchmarking with the scope of gauging and stress-testing the techniques in different scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05030v2</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniele Gerosa, Rui Hou, Vimar Bj\"ork, Ulf Gustavsson, Thomas Eriksson</dc:creator>
    </item>
    <item>
      <title>An Improved Approach to Estimate the Internal Resistance of a Battery During the HPPC Test</title>
      <link>https://arxiv.org/abs/2505.06410</link>
      <description>arXiv:2505.06410v2 Announce Type: replace 
Abstract: This paper considers the problem of resistance estimation in electronic systems including battery management systems (BMS) and battery chargers. In typical applications, the battery resistance is obtained through an approximate method computed as the ratio of the voltage difference to the applied current excitation pulse or vice versa for admittance. When estimating the battery resistance, this approach ignores the change in the open circuit voltage (OCV) as a result of the excitation signal. In this paper, we formally demonstrate and quantify the effect of the OCV drop on the errors in internal resistance estimation. Then, we propose a novel method to accurately estimate the internal resistance by accounting for the change in OCV caused by the applied current excitation signal. The proposed approach is based on a novel observation model that allows one to estimate the effect of OCV without requiring any additional information, such as the state of charge (SOC), parameters of the OCV-SOC curve, and the battery capacity. As such, the proposed approach is independent of the battery chemistry, size, age, and the ambient temperature. A performance analysis of the proposed approach using the battery simulator shows significant performance gain in the range of 30% to more than 250% in percentage estimation error. Then, the proposed approach is applied for resistance estimation during the hybrid pulse power characterization (HPPC) of cylindrical Li-ion battery cells. Results from tested batteries show that the proposed approach reduced the overestimated internal resistance of the batteries by up to 20 m{\Omega}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06410v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Prarthana Pillai, Smeet Desai, Krishna R. Pattipati, Balakumar Balasingam</dc:creator>
    </item>
    <item>
      <title>Evaluating the Scalability of Binary and Ternary CNN Workloads on RRAM-based Compute-in-Memory Accelerators</title>
      <link>https://arxiv.org/abs/2505.07490</link>
      <description>arXiv:2505.07490v2 Announce Type: replace 
Abstract: The increasing computational demand of Convolutional Neural Networks (CNNs) necessitates energy-efficient acceleration strategies. Compute-in-Memory (CIM) architectures based on Resistive Random Access Memory (RRAM) offer a promising solution by reducing data movement and enabling low-power in-situ computations. However, their efficiency is limited by the high cost of peripheral circuits, particularly Analog-to-Digital Converters (ADCs). Large crossbars and low ADC resolutions are often used to mitigate this, potentially compromising accuracy. This work introduces novel simulation methods to model the impact of resistive wire parasitics and limited ADC resolution on RRAM crossbars. Our parasitics model employs a vectorised algorithm to compute crossbar output currents with errors below 0.15% compared to SPICE. Additionally, we propose a variable step-size ADC and a calibration methodology that significantly reduces ADC resolution requirements. These accuracy models are integrated with a statistics-based energy model. Using our framework, we conduct a comparative analysis of binary and ternary CNNs. Experimental results demonstrate that the ternary CNNs exhibit greater resilience to wire parasitics and lower ADC resolution but suffer a 40% reduction in energy efficiency. These findings provide valuable insights for optimising RRAM-based CIM accelerators for energy-efficient deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07490v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jos\'e Cubero-Cascante, Rebecca Pelke, Noah Flohr, Arunkumar Vaidyanathan, Rainer Leupers, Jan Moritz Joseph</dc:creator>
    </item>
    <item>
      <title>Channel Estimation for Wideband XL-MIMO: A Constrained Deep Unrolling Approach</title>
      <link>https://arxiv.org/abs/2505.07717</link>
      <description>arXiv:2505.07717v2 Announce Type: replace 
Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) enables the formation of narrow beams, effectively mitigating path loss in high-frequency communications. This capability makes the integration of wideband high-frequency communications and XL-MIMO a key enabler for future 6G networks. Realizing the full potential of such wideband XL-MIMO systems depends critically on acquiring accurate channel state information. However, channel estimation is significantly challenging due to inherent wideband XL-MIMO channel characteristics, including near-field propagation, beam split, and spatial non-stationarity. To effectively capture these channel characteristics, we formulate channel estimation as a maximum a posteriori problem, which facilitates the use of prior channel knowledge. We then propose an unrolled proximal gradient descent algorithm with learnable step sizes, which employs a dedicated neural network for proximal mapping. This design empowers the proposed algorithm to implicitly learn prior channel knowledge directly from data, thereby eliminating the need for explicit regularization functions. To improve the convergence, we introduce a monotonic descent constraint on the layer-wise estimation error and provide theoretical analyses to characterize the algorithm's convergence behavior. Simulation results show that the proposed unrolling-based algorithm outperforms the traditional and deep learning-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07717v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peicong Zheng, Xuantao Lyu, Ye Wang, Yi Gong</dc:creator>
    </item>
    <item>
      <title>RainfalLTE: A Zero-effect Rainfall Sensing System Utilizing Existing LTE Infrastructure</title>
      <link>https://arxiv.org/abs/2505.13818</link>
      <description>arXiv:2505.13818v2 Announce Type: replace 
Abstract: Environmental sensing is an important research topic in the integrated sensing and communication (ISAC) system. Current works often focus on static environments, such as buildings and terrains. However, dynamic factors like rainfall can cause serious interference to wireless signals. In this paper, we propose a system called RainfalLTE that utilizes the downlink signal of LTE base stations for device-independent rain sensing. In articular, it is fully compatible with current communication modes and does not require any additional hardware. We evaluate it with LTE data and rainfall information provided by a weather radar in Badaling Town, Beijing The results show that for 10 classes of rainfall, RainfalLTE achieves over 97% identification accuracy. Our case study shows that the assistance of rainfall information can bring more than 40% energy saving, which provides new opportunities for the design and optimization of ISAC systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13818v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xianbin Jiang, Fei Shang, Haohua Du, Panlong Yang, Xing Guo, Lihong Liang, Yuanting Zhang, Xiang-Yang Li</dc:creator>
    </item>
    <item>
      <title>Distortion Resilience for Goal-Oriented Semantic Communication</title>
      <link>https://arxiv.org/abs/2309.14587</link>
      <description>arXiv:2309.14587v2 Announce Type: replace-cross 
Abstract: Recent research efforts on Semantic Communication (SemCom) have mostly considered accuracy as a main problem for optimizing goal-oriented communication systems. However, these approaches introduce a paradox: the accuracy of Artificial Intelligence (AI) tasks should naturally emerge through training rather than being dictated by network constraints. Acknowledging this dilemma, this work introduces an innovative approach that leverages the rate distortion theory to analyze distortions induced by communication and compression, thereby analyzing the learning process. Specifically, we examine the distribution shift between the original data and the distorted data, thus assessing its impact on the AI model's performance. Founding upon this analysis, we can preemptively estimate the empirical accuracy of AI tasks, making the goal-oriented SemCom problem feasible. To achieve this objective, we present the theoretical foundation of our approach, accompanied by simulations and experiments that demonstrate its effectiveness. The experimental results indicate that our proposed method enables accurate AI task performance while adhering to network constraints, establishing it as a valuable contribution to the field of signal processing. Furthermore, this work advances research in goal-oriented SemCom and highlights the significance of data-driven approaches in optimizing the performance of intelligent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14587v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minh-Duong Nguyen, Quang-Vinh Do, Zhaohui Yang, Quoc-Viet Pham, Won-Joo Hwang</dc:creator>
    </item>
    <item>
      <title>A Novel Transformer-Based Self-Supervised Learning Method to Enhance Photoplethysmogram Signal Artifact Detection</title>
      <link>https://arxiv.org/abs/2401.01013</link>
      <description>arXiv:2401.01013v2 Announce Type: replace-cross 
Abstract: Recent research at CHU Sainte Justine's Pediatric Critical Care Unit (PICU) has revealed that traditional machine learning methods, such as semi-supervised label propagation and K-nearest neighbors, outperform Transformer-based models in artifact detection from PPG signals, mainly when data is limited. This study addresses the underutilization of abundant unlabeled data by employing self-supervised learning (SSL) to extract latent features from these data, followed by fine-tuning on labeled data. Our experiments demonstrate that SSL significantly enhances the Transformer model's ability to learn representations, improving its robustness in artifact classification tasks. Among various SSL techniques, including masking, contrastive learning, and DINO (self-distillation with no labels)-contrastive learning exhibited the most stable and superior performance in small PPG datasets. Further, we delve into optimizing contrastive loss functions, which are crucial for contrastive SSL. Inspired by InfoNCE, we introduce a novel contrastive loss function that facilitates smoother training and better convergence, thereby enhancing performance in artifact classification. In summary, this study establishes the efficacy of SSL in leveraging unlabeled data, particularly in enhancing the capabilities of the Transformer model. This approach holds promise for broader applications in PICU environments, where annotated data is often limited.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01013v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ACCESS.2024.3488595</arxiv:DOI>
      <arxiv:journal_reference>IEEE Access, 2024</arxiv:journal_reference>
      <dc:creator>Thanh-Dung Le, Clara Macabiau, K\'evin Albert, Philippe Jouvet, Rita Noumeir</dc:creator>
    </item>
    <item>
      <title>Modulated differentiable STFT and balanced spectrum metric for freight train wheelset bearing cross-machine transfer monitoring under speed fluctuations</title>
      <link>https://arxiv.org/abs/2406.11917</link>
      <description>arXiv:2406.11917v3 Announce Type: replace-cross 
Abstract: The service conditions of wheelset bearings has a direct impact on the safe operation of railway heavy haul freight trains as the key components. However, speed fluctuation of the trains and few fault samples are the two main problems that restrict the accuracy of bearing fault diagnosis. Therefore, a cross-machine transfer diagnosis (pyDSN) network coupled with interpretable modulated differentiable short-time Fourier transform (STFT) and physics-informed balanced spectrum quality metric is proposed to learn domain-invariant and discriminative features under time-varying speeds. Firstly, due to insufficiency in extracting extract frequency components of time-varying speed signals using fixed windows, a modulated differentiable STFT (MDSTFT) that is interpretable with STFT-informed theoretical support, is proposed to extract the robust time-frequency spectrum (TFS). During training process, multiple windows with different lengths dynamically change. Also, in addition to the classification metric and domain discrepancy metric, we creatively introduce a third kind of metric, referred to as the physics-informed metric, to enhance transferable TFS. A physics-informed balanced spectrum quality (BSQ) regularization loss is devised to guide an optimization direction for MDSTFT and model. With it, not only can model acquire high-quality TFS, but also a physics-restricted domain adaptation network can be also acquired, making it learn real-world physics knowledge, ultimately diminish the domain discrepancy across different datasets. The experiment is conducted in the scenario of migrating from the laboratory datasets to the freight train dataset, indicating that the hybrid-driven pyDSN outperforms existing methods and has practical value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11917v3</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.aei.2024.102568</arxiv:DOI>
      <arxiv:journal_reference>Advanced Engineering Informatics 62 (2024) 102568</arxiv:journal_reference>
      <dc:creator>Chao He, Hongmei Shi, Ruixin Li, Jianbo Li, ZuJun Yu</dc:creator>
    </item>
    <item>
      <title>ALMA: a mathematics-driven approach for determining tuning parameters in generalized LASSO problems, with applications to MRI</title>
      <link>https://arxiv.org/abs/2406.19239</link>
      <description>arXiv:2406.19239v2 Announce Type: replace-cross 
Abstract: Magnetic Resonance Imaging (MRI) is a powerful technique employed for non-invasive in vivo visualization of internal structures. Sparsity is often deployed to accelerate the signal acquisition or overcome the presence of motion artifacts, improving the quality of image reconstruction. Image reconstruction algorithms use TV-regularized LASSO (Total Variation-regularized LASSO) to retrieve the missing information of undersampled signals, by cleaning the data of noise and while optimizing sparsity. A tuning parameter moderates the balance between these two aspects; its choice affecting the quality of the reconstructions. Currently, there is a lack of general deterministic techniques to choose these parameters, which are oftentimes manually selected and thus hinder the reliability of the reconstructions. Here, we present ALMA (Algorithm for Lagrange Multipliers Approximation), an iterative mathematics-inspired technique that computes tuning parameters for generalized LASSO problems during MRI reconstruction. We analyze quantitatively the performance of these parameters for imaging reconstructions via TV-LASSO in an MRI context on phantoms. Although our study concentrates on TV-LASSO, the techniques developed here hold significant promise for a wide array of applications. ALMA is not only adaptable to more generalized LASSO problems but is also robust to accommodate other forms of regularization beyond total variation. Moreover, it extends effectively to handle non-Cartesian sampling trajectories, broadening its utility in complex data reconstruction scenarios. More generally, ALMA provides a powerful tool for numerically solving constrained optimization problems across various disciplines, offering a versatile and impactful solution for advanced computational challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19239v2</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <category>physics.med-ph</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gianluca Giacchi, Isidoros Iakovidis, Bastien Milani, Micah Murray, Benedetta Franceschiello</dc:creator>
    </item>
    <item>
      <title>Revealing the evanescent components in Kronecker-product based codebooks: insights and implications</title>
      <link>https://arxiv.org/abs/2407.06772</link>
      <description>arXiv:2407.06772v2 Announce Type: replace-cross 
Abstract: The orthogonal bases of discrete Fourier transform (DFT) has been recognized as the standard spatial-domain bases for Type I, Type II and enhanced Type II codewords by the 3rd Generation Partnership Project (3GPP). For uniform planar arrays, these spatial-domain bases are derived as the Kronecker product of one-dimensional DFT bases. Theoretically, each spatial basis corresponds to a beam directed towards a specific angle of departure and the set of bases represent the orthogonal beams that cover the front hemisphere of an array. While the Kronecker-product based precoding scheme facilitates the concise indexing of a codeword in the codebooks through precoding matrix indicators (PMIs) in channel state information feedback, it introduces redundant spatial beams characterized by high spatial-frequency components. This paper investigates the presence of codewords representing high spatial-frequency components within the Kronecker-product based codebooks. Through theoretical analysis and simulations, we confirm the redundancy of these codewords in MIMO communications, advocating for their removal from the codebooks to enhance system performance. Several topics relevant to the high spatial components are also involved in the discussion. Practical suggestions regarding future standard design are provided based on our theoretical analysis and simulation results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06772v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Yang, Yijian Chen, Yunqi Sun, Yuan Si, Hongkang Yu, Shujuan Zhang, Zhaohua Lu</dc:creator>
    </item>
    <item>
      <title>The Impact of LoRA Adapters for LLMs on Clinical NLP Classification Under Data Limitations</title>
      <link>https://arxiv.org/abs/2407.19299</link>
      <description>arXiv:2407.19299v2 Announce Type: replace-cross 
Abstract: Fine-tuning Large Language Models (LLMs) for clinical Natural Language Processing (NLP) poses significant challenges due to the domain gap and limited data availability. This study investigates the effectiveness of various adapter techniques, equivalent to Low-Rank Adaptation (LoRA), for fine-tuning LLMs in a resource-constrained hospital environment. We experimented with four structures-Adapter, Lightweight, TinyAttention, and Gated Residual Network (GRN)-as final layers for clinical notes classification. We fine-tuned biomedical pre-trained models, including CamemBERT-bio, AliBERT, and DrBERT, alongside two Transformer-based models. Our extensive experimental results indicate that i) employing adapter structures does not yield significant improvements in fine-tuning biomedical pre-trained LLMs, and ii) simpler Transformer-based models, trained from scratch, perform better under resource constraints. Among the adapter structures, GRN demonstrated superior performance with accuracy, precision, recall, and an F1 score of 0.88. Moreover, the total training time for LLMs exceeded 1000 hours, compared to under 6 hours for simpler transformer-based models, highlighting that LLMs are more suitable for environments with extensive computational resources and larger datasets. Consequently, this study demonstrates that simpler Transformer-based models can be effectively trained from scratch, providing a viable solution for clinical NLP tasks in low-resource environments with limited data availability. By identifying the GRN as the most effective adapter structure, we offer a practical approach to enhance clinical note classification without requiring extensive computational resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19299v2</guid>
      <category>cs.CL</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thanh-Dung Le, Ti Ti Nguyen, Vu Nguyen Ha, Symeon Chatzinotas, Philippe Jouvet, Rita Noumeir</dc:creator>
    </item>
    <item>
      <title>Fast Hyperspectral Neutron Tomography</title>
      <link>https://arxiv.org/abs/2410.22500</link>
      <description>arXiv:2410.22500v2 Announce Type: replace-cross 
Abstract: Hyperspectral neutron computed tomography is a tomographic imaging technique in which thousands of wavelength-specific neutron radiographs are measured for each tomographic view. In conventional hyperspectral reconstruction, data from each neutron wavelength bin are reconstructed separately, which is extremely time-consuming. These reconstructions often suffer from poor quality due to low signal-to-noise ratios. Consequently, material decomposition based on these reconstructions tends to produce inaccurate estimates of the material spectra and erroneous volumetric material separation. In this paper, we present two novel algorithms for processing hyperspectral neutron data: fast hyperspectral reconstruction and fast material decomposition. Both algorithms rely on a subspace decomposition procedure that transforms hyperspectral views into low-dimensional projection views within an intermediate subspace, where tomographic reconstruction is performed. The use of subspace decomposition dramatically reduces reconstruction time while reducing both noise and reconstruction artifacts. We apply our algorithms to both simulated and measured neutron data and demonstrate that they reduce computation and improve the quality of the results relative to conventional methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22500v2</guid>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Samin Nur Chowdhury, Diyu Yang, Shimin Tang, Singanallur V. Venkatakrishnan, Hassina Z. Bilheux, Gregery T. Buzzard, Charles A. Bouman</dc:creator>
    </item>
    <item>
      <title>Semantic-Aware Resource Management for C-V2X Platooning via Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2411.04672</link>
      <description>arXiv:2411.04672v2 Announce Type: replace-cross 
Abstract: Semantic communication transmits the extracted features of information rather than raw data, significantly reducing redundancy, which is crucial for addressing spectrum and energy challenges in 6G networks. In this paper, we introduce semantic communication into a cellular vehicle-to-everything (C-V2X)- based autonomous vehicle platoon system for the first time, aiming to achieve efficient management of communication resources in a dynamic environment. Firstly, we construct a mathematical model for semantic communication in platoon systems, in which the DeepSC model and MU-DeepSC model are used to semantically encode and decode unimodal and multi-modal data, respectively. Then, we propose the quality of experience (QoE) metric based on semantic similarity and semantic rate. Meanwhile, we consider the success rate of semantic information transmission (SRS) metric to ensure the fairness of channel resource allocation. Next, the optimization problem is posed with the aim of maximizing the QoE in vehicle-to-vehicle (V2V) links while improving SRS. To solve this mixed integer nonlinear programming problem (MINLP) and adapt to time-varying channel conditions, the paper proposes a distributed semantic-aware multi-modal resource allocation (SAMRA) algorithm based on multi-agent reinforcement learning (MARL), referred to as SAMRAMARL. The algorithm can dynamically allocate channels and power and determine semantic symbol length based on the contextual importance of the transmitted information, ensuring efficient resource utilization. Finally, extensive simulations have demonstrated that SAMRAMARL outperforms existing methods, achieving significant gains in QoE, SRS, and communication delay in C-V2X platooning scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04672v2</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjun Zhang, Qiong Wu, Pingyi Fan, Kezhi Wang, Nan Cheng, Wen Chen, Khaled B. Letaief</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning-Based Resource Allocation for Hybrid Bit and Generative Semantic Communications in Space-Air-Ground Integrated Networks</title>
      <link>https://arxiv.org/abs/2412.05647</link>
      <description>arXiv:2412.05647v3 Announce Type: replace-cross 
Abstract: In this paper, we introduce a novel framework consisting of hybrid bit-level and generative semantic communications for efficient downlink image transmission within space-air-ground integrated networks (SAGINs). The proposed model comprises multiple low Earth orbit (LEO) satellites, unmanned aerial vehicles (UAVs), and ground users. Considering the limitations in signal coverage and receiver antennas that make the direct communication between satellites and ground users unfeasible in many scenarios, thus UAVs serve as relays and forward images from satellites to the ground users. Our hybrid communication framework effectively combines bit-level transmission with several semantic-level image generation modes, optimizing bandwidth usage to meet stringent satellite link budget constraints and ensure communication reliability and low latency under low signal-to-noise ratio (SNR) conditions. To reduce the transmission delay while ensuring reconstruction quality for the ground user, we propose a novel metric to measure delay and reconstruction quality in the proposed system, and employ a deep reinforcement learning (DRL)-based strategy to optimize resource allocation in the proposed network. Simulation results demonstrate the superiority of the proposed framework in terms of communication resource conservation, reduced latency, and maintaining high image quality, significantly outperforming traditional solutions. Therefore, the proposed framework can ensure that real-time image transmission requirements in SAGINs, even under dynamic network conditions and user demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05647v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chong Huang, Xuyang Chen, Gaojie Chen, Pei Xiao, Geoffrey Ye Li, Wei Huang</dc:creator>
    </item>
    <item>
      <title>Separate Source Channel Coding Is Still What You Need: An LLM-based Rethinking</title>
      <link>https://arxiv.org/abs/2501.04285</link>
      <description>arXiv:2501.04285v4 Announce Type: replace-cross 
Abstract: Along with the proliferating research interest in Semantic Communication (SemCom), Joint Source Channel Coding (JSCC) has dominated the attention due to the widely assumed existence in efficiently delivering information semantics. Nevertheless, this paper challenges the conventional JSCC paradigm, and advocates for adoption of Separate Source Channel Coding (SSCC) to enjoy the underlying more degree of freedom for optimization. We demonstrate that SSCC, after leveraging the strengths of Large Language Model (LLM) for source coding and Error Correction Code Transformer (ECCT) complemented for channel decoding, offers superior performance over JSCC. Our proposed framework also effectively highlights the compatibility challenges between SemCom approaches and digital communication systems, particularly concerning the resource costs associated with the transmission of high precision floating point numbers. Through comprehensive evaluations, we establish that empowered by LLM-based compression and ECCT-enhanced error correction, SSCC remains a viable and effective solution for modern communication systems. In other words, separate source and channel coding is still what we need!</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04285v4</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.12142/ZTECOM.202501005</arxiv:DOI>
      <arxiv:journal_reference>ZTE Communications, vol. 23, no. 1, pp. 30-44, Mar. 2025</arxiv:journal_reference>
      <dc:creator>Tianqi Ren, Rongpeng Li, Ming-min Zhao, Xianfu Chen, Guangyi Liu, Yang Yang, Zhifeng Zhao, Honggang Zhang</dc:creator>
    </item>
    <item>
      <title>Deep Active Speech Cancellation with Mamba-Masking Network</title>
      <link>https://arxiv.org/abs/2502.01185</link>
      <description>arXiv:2502.01185v2 Announce Type: replace-cross 
Abstract: We present a novel deep learning network for Active Speech Cancellation (ASC), advancing beyond Active Noise Cancellation (ANC) methods by effectively canceling both noise and speech signals. The proposed Mamba-Masking architecture introduces a masking mechanism that directly interacts with the encoded reference signal, enabling adaptive and precisely aligned anti-signal generation-even under rapidly changing, high-frequency conditions, as commonly found in speech. Complementing this, a multi-band segmentation strategy further improves phase alignment across frequency bands. Additionally, we introduce an optimization-driven loss function that provides near-optimal supervisory signals for anti-signal generation. Experimental results demonstrate substantial performance gains, achieving up to 7.2dB improvement in ANC scenarios and 6.2dB in ASC, significantly outperforming existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01185v2</guid>
      <category>cs.SD</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yehuda Mishaly, Lior Wolf, Eliya Nachmani</dc:creator>
    </item>
    <item>
      <title>Adaptive Sensor Steering Strategy Using Deep Reinforcement Learning for Dynamic Data Acquisition in Digital Twins</title>
      <link>https://arxiv.org/abs/2504.10248</link>
      <description>arXiv:2504.10248v2 Announce Type: replace-cross 
Abstract: This paper introduces a sensor steering methodology based on deep reinforcement learning to enhance the predictive accuracy and decision support capabilities of digital twins by optimising the data acquisition process. Traditional sensor placement techniques are often constrained by one-off optimisation strategies, which limit their applicability for online applications requiring continuous informative data assimilation. The proposed approach addresses this limitation by offering an adaptive framework for sensor placement within the digital twin paradigm. The sensor placement problem is formulated as a Markov decision process, enabling the training and deployment of an agent capable of dynamically repositioning sensors in response to the evolving conditions of the physical structure as represented by the digital twin. This ensures that the digital twin maintains a highly representative and reliable connection to its physical counterpart. The proposed framework is validated through a series of comprehensive case studies involving a cantilever plate structure subjected to diverse conditions, including healthy and damaged conditions. The results demonstrate the capability of the deep reinforcement learning agent to adaptively reposition sensors improving the quality of data acquisition and hence enhancing the overall accuracy of digital twins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10248v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Collins O. Ogbodo, Timothy J. Rogers, Mattia Dal Borgo, David J. Wagg</dc:creator>
    </item>
    <item>
      <title>Revenue Optimization in Video Caching Networks with Privacy-Preserving Demand Predictions</title>
      <link>https://arxiv.org/abs/2505.07872</link>
      <description>arXiv:2505.07872v2 Announce Type: replace-cross 
Abstract: Performance of video streaming, which accounts for most of the traffic in wireless communication, can be significantly improved by caching popular videos at the wireless edge. Determining the cache content that optimizes performance (defined via a revenue function) is thus an important task, and prediction of the future demands based on past history can make this process much more efficient. However, since practical video caching networks involve various parties (e.g., users, isp, and csp) that do not wish to reveal information such as past history to each other, privacy-preserving solutions are required. Motivated by this, we propose a proactive caching method based on users' privacy-preserving multi-slot future demand predictions -- obtained from a trained Transformer -- to optimize revenue. Specifically, we first use a privacy-preserving fl algorithm to train a Transformer to predict multi-slot future demands of the users. However, prediction accuracy is not perfect and decreases the farther into the future the prediction is done. We model the impact of prediction errors invoking the file popularities, based on which we formulate a long-term system revenue optimization to make the cache placement decisions. As the formulated problem is NP-hard, we use a greedy algorithm to efficiently obtain an approximate solution. Simulation results validate that (i) the fl solution achieves results close to the centralized (non-privacy-preserving) solution and (ii) optimization of revenue may provide different solutions than the classical chr criterion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07872v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijing Zhang, Ferdous Pervej, Andreas F. Molisch</dc:creator>
    </item>
    <item>
      <title>LLM-Based Emulation of the Radio Resource Control Layer: Towards AI-Native RAN Protocols</title>
      <link>https://arxiv.org/abs/2505.16821</link>
      <description>arXiv:2505.16821v2 Announce Type: replace-cross 
Abstract: Integrating large AI models (LAMs) into 6G mobile networks promises to redefine protocol design and control-plane intelligence by enabling autonomous, cognitive network operations. While industry concepts, such as ETSI's Experiential Networked Intelligence (ENI), envision LAM-driven agents for adaptive network slicing and intent-based management, practical implementations still face challenges in protocol literacy and real-world deployment. This paper presents an end-to-end demonstration of a LAM that generates standards-compliant, ASN.1-encoded Radio Resource Control (RRC) messages as part of control-plane procedures inside a gNB. We treat RRC messaging as a domain-specific language and fine-tune a decoder-only transformer model (LLaMA class) using parameter-efficient Low-Rank Adaptation (LoRA) on RRC messages linearized to retain their ASN.1 syntactic structure before standard byte-pair encoding tokenization. This enables combinatorial generalization over RRC protocol states while minimizing training overhead. On 30k field-test request-response pairs, our 8 B model achieves a median cosine similarity of 0.97 with ground-truth messages on an edge GPU -- a 61 % relative gain over a zero-shot LLaMA-3 8B baseline -- indicating substantially improved structural and semantic RRC fidelity. Overall, our results show that LAMs, when augmented with Radio Access Network (RAN)-specific reasoning, can directly orchestrate control-plane procedures, representing a stepping stone toward the AI-native air-interface paradigm. Beyond RRC emulation, this work lays the groundwork for future AI-native wireless standards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16821v2</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziming Liu, Bryan Liu, Alvaro Valcarce, Xiaoli Chu</dc:creator>
    </item>
  </channel>
</rss>
