<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Apr 2025 04:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Transformer-Driven Neural Beamforming with Imperfect CSI in Urban Macro Wireless Channels</title>
      <link>https://arxiv.org/abs/2504.11667</link>
      <description>arXiv:2504.11667v1 Announce Type: new 
Abstract: The literature is abundant with methodologies focusing on using transformer architectures due to their prominence in wireless signal processing and their capability to capture long-range dependencies via attention mechanisms. In particular, depthwise separable convolutions enhance parameter efficiency for the process of high-dimensional data characteristics of MIMO systems. In this work, we introduce a novel unsupervised deep learning framework that integrates depthwise separable convolutions and transformers to generate beamforming weights under imperfect channel state information (CSI) for a multi-user single-input multiple-output (MU-SIMO) system in dense urban environments. The primary goal is to enhance throughput by maximizing sum-rate while ensuring reliable communication. Spectral efficiency and block error rate (BLER) are considered as performance metrics. Experiments are carried out under various conditions to compare the performance of the proposed NNBF framework against baseline methods zero-forcing beamforming (ZFBF) and minimum mean square error (MMSE) beamforming. Experimental results demonstrate the superiority of the proposed framework over the baseline techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11667v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cemil Vahapoglu, Timothy J. O'Shea, Wan Liu, Tamoghna Roy, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Beyond ISAC: Toward Integrated Heterogeneous Service Provisioning via Elastic Multi-Dimensional Multiple Access</title>
      <link>https://arxiv.org/abs/2504.11692</link>
      <description>arXiv:2504.11692v1 Announce Type: new 
Abstract: Integrated heterogeneous service provisioning (IHSP) is a promising paradigm that is designed to concurrently support a variety of heterogeneous services, extending beyond sensing and communication to meet the diverse needs of emerging applications. However, a primary challenge of IHSP is addressing the conflicts between multiple competing service demands under constrained resources. In this paper, we overcome this challenge by the joint use of two novel elastic design strategies: compromised service value assessment and flexible multi-dimensional resource multiplexing. Consequently, we propose a value-prioritized elastic multi-dimensional multiple access (MDMA) mechanism for IHSP systems. First, we modify the Value-of-Service (VoS) metric by incorporating elastic parameters to characterize user-specific tolerance and compromise in response to various performance degradations under constrained resources. This VoS metric serves as the foundation for prioritizing services and enabling effective fairness service scheduling among concurrent competing demands. Next, we adapt the MDMA to elastically multiplex services using appropriate multiple access schemes across different resource domains. This protocol leverages user-specific interference tolerances and cancellation capabilities across different domains to reduce resource-demanding conflicts and co-channel interference within the same domain. Then, we maximize the system's VoS by jointly optimizing MDMA design and power allocation. Since this problem is non-convex, we propose a monotonic optimization-assisted dynamic programming (MODP) algorithm to obtain its optimal solution. Additionally, we develop the VoS-prioritized successive convex approximation (SCA) algorithm to efficiently find its suboptimal solution. Finally, simulations are presented to validate the effectiveness of the proposed designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11692v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Chen, Xianbin Wang, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>Sliding Block Martingale based Multi-hop Delay QoS Analysis</title>
      <link>https://arxiv.org/abs/2504.11769</link>
      <description>arXiv:2504.11769v1 Announce Type: new 
Abstract: With the growing density of wireless networks and demand for multi-hop transmissions, precise delay Quality of Service (QoS) analysis has become a critical challenge. This paper introduces a multi-hop delay QoS analysis framework based on the sliding block martingale, addressing the loose boundary issue of prior methods that rely on service process martingales and min-plus transformations. By constructing a sliding block martingale with a window, we capture both long-term trends and short-term fluctuations in the backlog, eliminating the reliance on the generalized incremental property. The framework redefines delay unreliability events using cascading attributes, deriving a more compact Delay Unreliability Probability Boundary (DUPB). To improve the efficiency of solving the key parameter $\theta$, we propose a Micrometric Intervals based Supermartingale Upcrossing Estimate Theorem, quantifying the upper bound of event occurrence frequency to constrain the solution space of $\theta$. Simulations based on the 3GPP UMa/UMi channel model validate the framework's effectiveness. Results show that in 2-7 hop scenarios, the maximum deviation between theoretical boundaries and Monte Carlo simulations is $4.116 \times 10^{-5}$, with a lower RMSE than existing methods. Iteration count and CPU time for solving $\theta$ are reduced by $59\%-72\%$ and $60.6\%-70.5\%$, respectively, improving analysis efficiency. Furthermore, the derived minimum service rate for multi-hop queues offers a valuable reference for resource allocation. The framework demonstrates high accuracy, scalability, and practicality in complex multi-hop networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11769v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuchao Dang, Xuefen Chi</dc:creator>
    </item>
    <item>
      <title>DALC: Distributed Arithmetic Coding Aided by Linear Codes</title>
      <link>https://arxiv.org/abs/2504.11784</link>
      <description>arXiv:2504.11784v1 Announce Type: new 
Abstract: Distributed Arithmetic Coding (DAC) has emerged as a feasible solution to the Slepian-Wolf problem, particularly in scenarios with non-stationary sources and for data sequences with lengths ranging from small to medium. Due to the inherent decoding ambiguity in DAC, the number of candidate paths grows exponentially with the increase in source length. To select the correct decoding path from the set of candidates, DAC decoders utilize the Maximum A Posteriori (MAP) metric to rank the decoding sequences, outputting the path with the highest MAP metric as the decoding result of the decoder. However, this method may still inadvertently output incorrect paths that have a MAP metric higher than the correct decoding path, despite not being the correct decoding path. To address the issue, we propose Distributed Arithmetic Coding Aided by Linear Codes (DALC), which employs linear codes to constrain the decoding process, thereby eliminating some incorrect paths and preserving the correct one. During the encoding phase, DALC generates the parity bits of the linear code for encoding the source data. In the decoding phase, each path in the set of candidate paths is verified in descending order according to the MAP metric until a path that meets the verification criteria is encountered, which is then outputted as the decoding result. DALC enhances the decoding performance of DAC by excluding candidate paths that do not meet the constraints imposed by linear codes. Our experimental results demonstrate that DALC reduces the Bit Error Rate(BER), with especially improvements in skewed source data scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11784v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junwei Zhou, HaoYun Xiao, Jianwen Xi, Qiuzhen Lin</dc:creator>
    </item>
    <item>
      <title>On Codes from Split Metacyclic Groups</title>
      <link>https://arxiv.org/abs/2504.11960</link>
      <description>arXiv:2504.11960v1 Announce Type: new 
Abstract: The paper presents a comprehensive study of group codes from non-abelian split metacyclic group algebras. We derive an explicit Wedderburn-like decomposition of finite split metacyclic group algebras over fields with characteristic coprime to the group order. Utilizing this decomposition, we develop a systematic theory of metacyclic codes, providing their algebraic description and proving that they can be viewed as generalized concatenated codes with cyclic inner codes and skew quasi-cyclic outer codes. We establish bounds on the minimum distance of metacyclic codes and investigate the class of induced codes. Furthermore, we show the feasibility of constructing a partial key-recovery attack against certain McEliece-type cryptosystems based on metacyclic codes by exploiting their generalized concatenated structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11960v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.RA</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kirill Vedenev</dc:creator>
    </item>
    <item>
      <title>On the Intersection and Composition properties of conditional independence</title>
      <link>https://arxiv.org/abs/2504.11978</link>
      <description>arXiv:2504.11978v1 Announce Type: new 
Abstract: Compositional graphoids are fundamental discrete structures which appear in probabilistic reasoning, particularly in the area of graphical models. They are semigraphoids which satisfy the Intersection and Composition properties. These important properties, however, are not enjoyed by general probability distributions. We survey what is known in terms of sufficient conditions for Intersection and Composition and derive a set of new sufficient conditions in the context of discrete random variables based on conditional information inequalities for Shannon entropies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11978v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Boege</dc:creator>
    </item>
    <item>
      <title>Network-Centric Countermeasures Against Integrated Sensing Enabled Jamming Adversaries</title>
      <link>https://arxiv.org/abs/2504.12009</link>
      <description>arXiv:2504.12009v1 Announce Type: new 
Abstract: Recent developments in Integrated Sensing and Communication have led to new adversarial models in wireless security through Integrated Sensing and Jamming (ISAJ) adversaries. ISAJ adversaries, owing to their sensing capabilities, are known to inject jamming energy over the victim's frequency band, and also use generalized energy measurements on various network frequencies to detect the presence of countermeasures. Existing countermeasures against such ISAJ adversaries are laid under the assumption that the adversary does not have the knowledge of the countermeasure. However, according to Kerchoffs' principle in cryptography, security of a countermeasure should only rely on the secret-keys, not on the obfuscation of the countermeasure. On testing the security of existing countermeasures, we observe that they violate Kerchoffs' principle, thus motivating the need for new countermeasures. In this regard, we propose a novel network-centric countermeasure against ISAJ adversaries, wherein a group of users in the network assist the victim to reliably communicate her messages in a covert manner. Firstly, we analyse the error performance of the proposed countermeasure, and study its behavior on the number of assisting users in the network. Subsequently, to validate its security against Kerchoffs' principle, we study the Shannon's entropy associated with the presence of the victim's messages in the network and analyse its behaviour as a function of the number of assisting users. Finally, to study the interplay between reliability and covertness, we pose interesting optimization problems and solve them to choose the underlying parameters of the countermeasure and the number of assisting users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12009v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soumita Hazra, J. Harshan</dc:creator>
    </item>
    <item>
      <title>Generalized Restart Mechanism for Successive-Cancellation Flip Decoding of Polar Codes</title>
      <link>https://arxiv.org/abs/2504.12071</link>
      <description>arXiv:2504.12071v1 Announce Type: new 
Abstract: Polar codes are a class of linear error-correction codes that have received a lot of attention due to their ability to achieve channel capacity in an arbitrary binary discrete memoryless channel (B-DMC) with low-complexity successive-cancellation (SC) decoding. However, practical implementations often require better error-correction performance than what SC decoding provides, particularly at short to moderate code lengths. Successive-cancellation flip (SCF) decoding algorithm was proposed to improve error-correction performance with an aim to detect and correct the first wrongly estimated bit in a codeword before resuming SC decoding. At each additional SC decoding trial, i.e., decoding attempt beyond the initial unsuccessful trial, one bit estimated as the least reliable is flipped. Dynamic SCF (DSCF) is a variation of SCF, where multiple bits may be flipped simultaneously per trial. Despite the improved error-correction performance compared to the SC decoder, SCF-based decoders have variable execution time, which leads to high average execution time and latency. In this work, we propose the generalized restart mechanism (GRM) that allows to skip decoding computations that are identical between the initial trial and any additional trial. Under DSCF decoding with up to 3-bit flips per decoding trial, our proposed GRM is shown to reduce the average execution time by 25% to 60% without any negative effect on error-correction performance. The proposed mechanism is adaptable to state-of-the-art latency-reduction techniques. When applied to Fast-DSCF-3 decoding, the additional reduction brought by the GRM is 15% to 22%. For the DSCF-3 decoder, the proposed mechanism requires approximately 4% additional memory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12071v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s11265-025-01949-8</arxiv:DOI>
      <dc:creator>Ilshat Sagitov, Charles Pillet, Alexios Balatsoukas-Stimming, Pascal Giard</dc:creator>
    </item>
    <item>
      <title>Successive-Cancellation Flip and Perturbation Decoder of Polar Codes</title>
      <link>https://arxiv.org/abs/2504.12102</link>
      <description>arXiv:2504.12102v1 Announce Type: new 
Abstract: In this paper, two decoding algorithms based on Successive Cancellation (SC) are proposed to improve the error-correction performance of cyclic redundancy check (CRC)-aided polar codes while aiming for a low-complexity implementation. Comparisons with Dynamic SC Flip (DSCF) and SC Perturbation (SCP) are carried out since the proposed DSCF and Perturbation (DSCFP) and Perturbed DSCF (PDSCF) algorithms combine both methods. The analysis includes comparisons with several code lengths $N$ and various number of decoding attempts $T_{max}$. For $N=1024$ and the coding rate $R=\frac{1}{2}$, the DSCFP and the SCP algorithms with $T_{max}=17$ are bested by approximately $0.1$\,dB at block error rate (BLER) of $0.001$. At $\text{BLER}=10^{-6}$ and for $T_{max}=64$, the gain is of $0.375$ dB and $&gt;0.5$ dB with respect to DSCF and SCP, respectively. At high signal-to-noise ratio, the average computational complexity of the proposed algorithms is virtually equivalent to that of SC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12102v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles Pillet, Ilshat Sagitov, Dominic Deslandes, Pascal Giard</dc:creator>
    </item>
    <item>
      <title>Improvement of the square-root low bounds on the minimum distances of BCH codes and Matrix-product codes</title>
      <link>https://arxiv.org/abs/2504.12116</link>
      <description>arXiv:2504.12116v1 Announce Type: new 
Abstract: The task of constructing infinite families of self-dual codes with unbounded lengths and minimum distances exhibiting square-root lower bounds is extremely challenging, especially when it comes to cyclic codes. Recently, the first infinite family of Euclidean self-dual binary and nonbinary cyclic codes, whose minimum distances have a square-root lower bound and have a lower bound better than square-root lower bounds are constructed in \cite{Chen23} for the lengths of these codes being unbounded. Let $q$ be a power of a prime number and $Q=q^2$. In this paper, we first improve the lower bounds on the minimum distances of Euclidean and Hermitian duals of BCH codes with length $\frac{q^m-1}{q^s-1}$ over $\mathbb{F}_q$ and $\frac{Q^m-1}{Q-1}$ over $\mathbb{F}_Q$ in \cite{Fan23,GDL21,Wang24} for the designed distances in some ranges, respectively, where $\frac{m}{s}\geq 3$. Then based on matrix-product construction and some lower bounds on the minimum distances of BCH codes and their duals, we obtain several classes of Euclidean and Hermitian self-dual codes, whose minimum distances have square-root lower bounds or a square-root-like lower bounds. Our lower bounds on the minimum distances of Euclidean and Hermitian self-dual cyclic codes improved many results in \cite{Chen23}. In addition, our lower bounds on the minimum distances of the duals of BCH codes are almost $q^s-1$ or $q$ times that of the existing lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12116v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoqiang Wang, Liuyi Li, Yansheng Wu, Dabin Zheng, Shuxian Lu</dc:creator>
    </item>
    <item>
      <title>The Optimal Condition Number for ReLU Function</title>
      <link>https://arxiv.org/abs/2504.12194</link>
      <description>arXiv:2504.12194v1 Announce Type: new 
Abstract: ReLU is a widely used activation function in deep neural networks. This paper explores the stability properties of the ReLU map. For any weight matrix $\boldsymbol{A} \in \mathbb{R}^{m \times n}$ and bias vector $\boldsymbol{b} \in \mathbb{R}^{m}$ at a given layer, we define the condition number $\beta_{\boldsymbol{A},\boldsymbol{b}}$ as $\beta_{\boldsymbol{A},\boldsymbol{b}} = \frac{\mathcal{U}_{\boldsymbol{A},\boldsymbol{b}}}{\mathcal{L}_{\boldsymbol{A},\boldsymbol{b}}}$, where $\mathcal{U}_{\boldsymbol{A},\boldsymbol{b}}$
  and $\mathcal{L}_{\boldsymbol{A},\boldsymbol{b}}$ are the upper and lower Lipschitz constants, respectively. We first demonstrate that for any given $\boldsymbol{A}$ and $\boldsymbol{b}$, the condition number satisfies $\beta_{\boldsymbol{A},\boldsymbol{b}} \geq \sqrt{2}$. Moreover, when the weights of the network at a given layer are initialized as random i.i.d. Gaussian variables and the bias term is set to zero, the condition number asymptotically approaches this lower bound. This theoretical finding suggests that Gaussian weight initialization is optimal for preserving distances in the context of random deep neural network weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12194v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Xia, Haoyu Zhou</dc:creator>
    </item>
    <item>
      <title>Adaptive Error Correction for Entanglement Distillation</title>
      <link>https://arxiv.org/abs/2504.11670</link>
      <description>arXiv:2504.11670v1 Announce Type: cross 
Abstract: Quantum network applications impose a variety of requirements on entanglement resources in terms of rate, fidelity, latency, and more. The repeaters in the quantum network must combine good methods for entanglement generation, effective entanglement distillation, and smart routing protocols to satisfy these application requirements. In this work, we focus on quantum error correction-based entanglement distillation in a linear chain of quantum repeaters. While conventional approaches reuse the same distillation scheme over multiple hop lengths after entanglement swaps, we propose a novel adaptive error correction scheme that boosts end-to-end metrics. Specifically, depending on the network operation point, we adapt the code used in distillation over successive rounds to monotonically increase the rate while also improving fidelity. We demonstrate the effectiveness of this strategy using three codes: [[9,1,3]], [[9,2,3]], [[9,3,3]]. We compare the performance of four different protocols that combine the codes in different ways, where we define a new performance metric, efficiency, that incorporates both overall rate and fidelity. While we highlight our innovation under minimal assumptions on noise, the method can be easily generalized to realistic network settings. By combining our approach with good entanglement generation methods and smart routing protocols, we can achieve application requirements in a systematic, resource-efficient, way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11670v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sijie Cheng, Narayanan Rengaswamy</dc:creator>
    </item>
    <item>
      <title>Battery-aware Cyclic Scheduling in Energy-harvesting Federated Learning</title>
      <link>https://arxiv.org/abs/2504.12181</link>
      <description>arXiv:2504.12181v1 Announce Type: cross 
Abstract: Federated Learning (FL) has emerged as a promising framework for distributed learning, but its growing complexity has led to significant energy consumption, particularly from computations on the client side. This challenge is especially critical in energy-harvesting FL (EHFL) systems, where device availability fluctuates due to limited and time-varying energy resources. We propose FedBacys, a battery-aware FL framework that introduces cyclic client participation based on users' battery levels to cope with these issues. FedBacys enables clients to save energy and strategically perform local training just before their designated transmission time by clustering clients and scheduling their involvement sequentially. This design minimizes redundant computation, reduces system-wide energy usage, and improves learning stability. Our experiments demonstrate that FedBacys outperforms existing approaches in terms of energy efficiency and performance consistency, exhibiting robustness even under non-i.i.d. training data distributions and with very infrequent battery charging. This work presents the first comprehensive evaluation of cyclic client participation in EHFL, incorporating both communication and computation costs into a unified, resource-aware scheduling strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12181v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eunjeong Jeong, Nikolaos Pappas</dc:creator>
    </item>
    <item>
      <title>Kernels for Storage Capacity and Dual Index Coding</title>
      <link>https://arxiv.org/abs/2504.12274</link>
      <description>arXiv:2504.12274v1 Announce Type: cross 
Abstract: The storage capacity of a graph measures the maximum amount of information that can be stored across its vertices, such that the information at any vertex can be recovered from the information stored at its neighborhood. The study of this graph quantity is motivated by applications in distributed storage and by its intimate relations to the index coding problem from the area of network information theory. In the latter, one wishes to minimize the amount of information that has to be transmitted to a collection of receivers, in a way that enables each of them to discover its required data using some prior side information.
  In this paper, we initiate the study of the Storage Capacity and Index Coding problems from the perspective of parameterized complexity. We prove that the Storage Capacity problem parameterized by the solution size admits a kernelization algorithm producing kernels of linear size. We also provide such a result for the Index Coding problem, in the linear and non-linear settings, where it is parameterized by the dual value of the solution, i.e., the length of the transmission that can be saved using the side information. A key ingredient in the proofs is the crown decomposition technique due to Chor, Fellows, and Juedes (WG 2003, WG 2004). As an application, we significantly extend an algorithmic result of Dau, Skachek, and Chee (IEEE Trans. Inform. Theory, 2014).</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12274v1</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ishay Haviv</dc:creator>
    </item>
    <item>
      <title>Local Grammar-Based Coding Revisited</title>
      <link>https://arxiv.org/abs/2209.13636</link>
      <description>arXiv:2209.13636v3 Announce Type: replace 
Abstract: In the setting of minimal local grammar-based coding, the input string is represented as a grammar with the minimal output length defined via simple symbol-by-symbol encoding. This paper discusses four contributions to this field. First, we invoke a simple harmonic bound on ranked probabilities, which reminds Zipf's law and simplifies universality proofs for minimal local grammar-based codes. Second, we refine known bounds on the vocabulary size, showing its partial power-law equivalence with mutual information and redundancy. These bounds are relevant for linking Zipf's law with the neural scaling law for large language models. Third, we develop a framework for universal codes with fixed infinite vocabularies, recasting universal coding as matching ranked patterns that are independent of empirical data. Finally, we analyze grammar-based codes with finite vocabularies being empirical rank lists, proving that that such codes are also universal. These results extend foundations of universal grammar-based coding and reaffirm previously stated connections to power laws for human language and language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.13636v3</guid>
      <category>cs.IT</category>
      <category>cs.CL</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>{\L}ukasz D\k{e}bowski</dc:creator>
    </item>
    <item>
      <title>Puncturing Quantum Stabilizer Codes</title>
      <link>https://arxiv.org/abs/2410.17754</link>
      <description>arXiv:2410.17754v3 Announce Type: replace 
Abstract: Classical coding theory contains several techniques to obtain new codes from other codes, including puncturing and shortening. For quantum codes, a form of puncturing is known, but its description is based on the code space rather than its generators. In this work, we generalize the puncturing procedure to allow more freedom in the choice of which coded states are kept and which are removed. We describe this puncturing by focusing on the stabilizer matrix containing the generators of the code. In this way, we are able to explicitly describe the stabilizer matrix of the punctured code given the stabilizer matrix of the original stabilizer code. The additional freedom in the procedure also opens up new ways to construct new codes from old, and we present several ways to utilize this for the search of codes with good or even optimal parameters. In particular, we use the construction to obtain codes whose parameters exceed the best previously known. Lastly, we generalize the proof of the Griesmer bound from the classical setting to stabilizer codes since the proof relies heavily on the puncturing technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17754v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.RA</category>
      <category>quant-ph</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaron Skovsted Gundersen, Ren\'e B{\o}dker Christensen, Markus Grassl, Petar Popovski, Rafa{\l} Wisniewski</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning-Based Resource Allocation for Hybrid Bit and Generative Semantic Communications in Space-Air-Ground Integrated Networks</title>
      <link>https://arxiv.org/abs/2412.05647</link>
      <description>arXiv:2412.05647v2 Announce Type: replace 
Abstract: In this paper, we introduce a novel framework consisting of hybrid bit-level and generative semantic communications for efficient downlink image transmission within space-air-ground integrated networks (SAGINs). The proposed model comprises multiple low Earth orbit (LEO) satellites, unmanned aerial vehicles (UAVs), and ground users. Considering the limitations in signal coverage and receiver antennas that make the direct communication between satellites and ground users unfeasible in many scenarios, thus UAVs serve as relays and forward images from satellites to the ground users. Our hybrid communication framework effectively combines bit-level transmission with several semantic-level image generation modes, optimizing bandwidth usage to meet stringent satellite link budget constraints and ensure communication reliability and low latency under low signal-to-noise ratio (SNR) conditions. To reduce the transmission delay while ensuring reconstruction quality for the ground user, we propose a novel metric to measure delay and reconstruction quality in the proposed system, and employ a deep reinforcement learning (DRL)-based strategy to optimize resource allocation in the proposed network. Simulation results demonstrate the superiority of the proposed framework in terms of communication resource conservation, reduced latency, and maintaining high image quality, significantly outperforming traditional solutions. Therefore, the proposed framework can ensure that real-time image transmission requirements in SAGINs, even under dynamic network conditions and user demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05647v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chong Huang, Xuyang Chen, Gaojie Chen, Pei Xiao, Geoffrey Ye Li, Wei Huang</dc:creator>
    </item>
    <item>
      <title>Separate Source Channel Coding Is Still What You Need: An LLM-based Rethinking</title>
      <link>https://arxiv.org/abs/2501.04285</link>
      <description>arXiv:2501.04285v3 Announce Type: replace 
Abstract: Along with the proliferating research interest in Semantic Communication (SemCom), Joint Source Channel Coding (JSCC) has dominated the attention due to the widely assumed existence in efficiently delivering information semantics. %has emerged as a pivotal area of research, aiming to enhance the efficiency and reliability of information transmission through deep learning-based methods. Nevertheless, this paper challenges the conventional JSCC paradigm, and advocates for adoption of Separate Source Channel Coding (SSCC) to enjoy the underlying more degree of freedom for optimization. We demonstrate that SSCC, after leveraging the strengths of Large Language Model (LLM) for source coding and Error Correction Code Transformer (ECCT) complemented for channel decoding, offers superior performance over JSCC. Our proposed framework also effectively highlights the compatibility challenges between SemCom approaches and digital communication systems, particularly concerning the resource costs associated with the transmission of high precision floating point numbers. Through comprehensive evaluations, we establish that empowered by LLM-based compression and ECCT-enhanced error correction, SSCC remains a viable and effective solution for modern communication systems. In other words, separate source and channel coding is still what we need!</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04285v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianqi Ren, Rongpeng Li, Ming-min Zhao, Xianfu Chen, Guangyi Liu, Yang Yang, Zhifeng Zhao, Honggang Zhang</dc:creator>
    </item>
    <item>
      <title>Zero Estimation Cost Strategy for Witsenhausen Counterexample with Causal Encoder</title>
      <link>https://arxiv.org/abs/2501.18308</link>
      <description>arXiv:2501.18308v2 Announce Type: replace 
Abstract: We propose a zero estimation cost (ZEC) scheme for causal-encoding noncausal-decoding vector-valued Witsenhausen counterexample based on the coordination coding result. In contrast to source coding, our goal is to communicate a controlled system state. The introduced ZEC scheme is a joint control-communication approach that transforms the system state into a sequence that can be efficiently communicated using block coding. Numerical results show that our approach significantly reduces the power required for achieving zero-estimation-cost state reconstruction at the decoder. In the second part, we introduce a more general non-zero estimation cost (Non-ZEC) scheme. We observe numerically that the Non-ZEC scheme operates as a time-sharing mechanism between the two-point strategy and the ZEC scheme. Overall, by leveraging block-coding gain, our proposed methods substantially improve the power-estimation trade-off for Witsenhausen counterexample.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18308v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mengyuan Zhao, Tobias J. Oechtering, Ma\"el Le Treust</dc:creator>
    </item>
    <item>
      <title>An Efficient Reservation Protocol for Medium Access: When Tree Splitting Meets Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2504.02376</link>
      <description>arXiv:2504.02376v2 Announce Type: replace 
Abstract: As an enhanced version of massive machine-type communication in 5G, massive communication has emerged as one of the six usage scenarios anticipated for 6G, owing to its potential in industrial internet-of-things and smart metering. Driven by the need for random multiple-access (RMA) in massive communication, as well as, next-generation Wi-Fi, medium access control has attracted considerable recent attention. Holding the promise of attaining bandwidth-efficient collision resolution, multiaccess reservation no doubt plays a central role in RMA, e.g., the distributed coordination function (DCF) in IEEE 802.11. In this paper, we are interested in maximizing the bandwidth efficiency of reservation protocols for RMA under quality-of-service constraints. Particularly, we present a tree splitting based reservation scheme, in which the attempting probability is dynamically optimized by partially observable Markov decision process or reinforcement learning (RL). The RL-empowered tree-splitting algorithm guarantees that all these terminals with backlogged packets at the beginning of a contention cycle can be scheduled, thereby providing a first-in-first-out service. More importantly, it substantially reduces the reservation bandwidth determined by the communication complexity of DCF, through judiciously conceived coding and interaction for exchanging information required by distributed ordering. Simulations demonstrate that the proposed algorithm outperforms the CSMA/CA based DCF in IEEE 802.11.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02376v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yutao Chen, Wei Chen</dc:creator>
    </item>
    <item>
      <title>A Hierarchical Decomposition of Kullback-Leibler Divergence: Disentangling Marginal Mismatches from Statistical Dependencies</title>
      <link>https://arxiv.org/abs/2504.09029</link>
      <description>arXiv:2504.09029v2 Announce Type: replace 
Abstract: The Kullback-Leibler (KL) divergence is a foundational measure for comparing probability distributions. Yet in multivariate settings, its single value often obscures the underlying reasons for divergence, conflating mismatches in individual variable distributions (marginals) with effects arising from statistical dependencies. We derive an algebraically exact, additive, and hierarchical decomposition of the KL divergence between a joint distribution P(X1,...,Xn) and a standard product reference distribution Q(X1,...,Xn) = product_i q(Xi), where variables are assumed independent and identically distributed according to a common reference q. The total divergence precisely splits into two primary components: (1) the summed divergence of each marginal distribution Pi(Xi) from the common reference q(Xi), quantifying marginal deviations; and (2) the total correlation (or multi-information), capturing the total statistical dependency among variables. Leveraging Mobius inversion on the subset lattice, we further decompose this total correlation term into a hierarchy of signed contributions from distinct pairwise, triplet, and higher-order statistical interactions, expressed using standard Shannon information quantities. This decomposition provides an algebraically complete and interpretable breakdown of KL divergence using established information measures, requiring no approximations or model assumptions. Numerical validation using hypergeometric sampling confirms the decomposition's exactness to machine precision across diverse system configurations. This framework enables a precise diagnosis of divergence origins--distinguishing marginal effects from interaction effects--with potential applications across machine learning, econometrics, and complex systems analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09029v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Cook</dc:creator>
    </item>
    <item>
      <title>Conformal Calibration: Ensuring the Reliability of Black-Box AI in Wireless Systems</title>
      <link>https://arxiv.org/abs/2504.09310</link>
      <description>arXiv:2504.09310v2 Announce Type: replace 
Abstract: AI is poised to revolutionize telecommunication networks by boosting efficiency, automation, and decision-making. However, the black-box nature of most AI models introduces substantial risk, possibly deterring adoption by network operators. These risks are not addressed by the current prevailing deployment strategy, which typically follows a best-effort train-and-deploy paradigm. This paper reviews conformal calibration, a general framework that moves beyond the state of the art by adopting computationally lightweight, advanced statistical tools that offer formal reliability guarantees without requiring further training or fine-tuning. Conformal calibration encompasses pre-deployment calibration via uncertainty quantification or hyperparameter selection; online monitoring to detect and mitigate failures in real time; and counterfactual post-deployment performance analysis to address "what if" diagnostic questions after deployment. By weaving conformal calibration into the AI model lifecycle, network operators can establish confidence in black-box AI models as a dependable enabling technology for wireless systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09310v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Osvaldo Simeone, Sangwoo Park, Matteo Zecchin</dc:creator>
    </item>
    <item>
      <title>Deep Variational Multivariate Information Bottleneck -- A Framework for Variational Losses</title>
      <link>https://arxiv.org/abs/2310.03311</link>
      <description>arXiv:2310.03311v3 Announce Type: replace-cross 
Abstract: Variational dimensionality reduction methods are widely used for their accuracy, generative capabilities, and robustness. We introduce a unifying framework that generalizes both such as traditional and state-of-the-art methods. The framework is based on an interpretation of the multivariate information bottleneck, trading off the information preserved in an encoder graph (defining what to compress) against that in a decoder graph (defining a generative model for data). Using this approach, we rederive existing methods, including the deep variational information bottleneck, variational autoencoders, and deep multiview information bottleneck. We naturally extend the deep variational CCA (DVCCA) family to beta-DVCCA and introduce a new method, the deep variational symmetric information bottleneck (DVSIB). DSIB, the deterministic limit of DVSIB, connects to modern contrastive learning approaches such as Barlow Twins, among others. We evaluate these methods on Noisy MNIST and Noisy CIFAR-100, showing that algorithms better matched to the structure of the problem like DVSIB and beta-DVCCA produce better latent spaces as measured by classification accuracy, dimensionality of the latent variables, sample efficiency, and consistently outperform other approaches under comparable conditions. Additionally, we benchmark against state-of-the-art models, achieving superior or competitive accuracy. Our results demonstrate that this framework can seamlessly incorporate diverse multi-view representation learning algorithms, providing a foundation for designing novel, problem-specific loss functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03311v3</guid>
      <category>cs.LG</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eslam Abdelaleem, Ilya Nemenman, K. Michael Martini</dc:creator>
    </item>
    <item>
      <title>Resilience of Rademacher chaos of low degree</title>
      <link>https://arxiv.org/abs/2402.10504</link>
      <description>arXiv:2402.10504v4 Announce Type: replace-cross 
Abstract: The resilience of a Rademacher chaos is the maximum number of adversarial sign-flips that the chaos can sustain without having its largest atom probability significantly altered. Inspired by probabilistic lower-bound guarantees for the resilience of linear Rademacher chaos, obtained by Bandeira, Ferber, and Kwan (Advances in Mathematics, Vol. $319$, $2017$), we provide probabilistic lower-bound guarantees for the resilience of Rademacher chaos of arbitrary yet sufficiently low degree.
  Our main results distinguish between Rademacher chaos of order two and those of higher order. In that, our first main result pertains to the resilience of decoupled bilinear Rademacher forms where different asymptotic behaviour is observed for sparse and dense matrices. For our second main result, we bootstrap our first result in order to provide resilience guarantees for quadratic Rademacher chaos. Our third main result, generalises the first and handles the resilience of decoupled Rademacher chaos of arbitrary yet sufficiently low order.
  Our results for decoupled Rademacher chaos of order two and that of higher order whilst are established through the same conceptual framework, differ substantially. A difference incurred due to the implementation of the same conceptual argument. The order two result is established using Dudley's maximal inequality for sub-Gaussian processes, the Hanson-Wright inequality, as well as the Kolmogorov-Rogozin inequality. To handle higher order chaos, appeals to Dudley's inequality as well as the Hanson-Wright inequality are replaced with tools suited for random tensors. Appeals to the Hanson-Wright inequality are replaced with appeals to a concentration result for random tensors put forth by Adamczak and Wolff.
  Our results are instance-dependent and thus allow for the efficient computation of resilience guarantees provided the order of the chaos is constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10504v4</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elad Aigner-Horev, Daniel Rosenberg, Roi Weiss</dc:creator>
    </item>
    <item>
      <title>Shuffled Linear Regression via Spectral Matching</title>
      <link>https://arxiv.org/abs/2410.00078</link>
      <description>arXiv:2410.00078v2 Announce Type: replace-cross 
Abstract: Shuffled linear regression (SLR) seeks to estimate latent features through a linear transformation, complicated by unknown permutations in the measurement dimensions. This problem extends traditional least-squares (LS) and Least Absolute Shrinkage and Selection Operator (LASSO) approaches by jointly estimating the permutation, resulting in shuffled LS and shuffled LASSO formulations. Existing methods, constrained by the combinatorial complexity of permutation recovery, often address small-scale cases with limited measurements. In contrast, we focus on large-scale SLR, particularly suited for environments with abundant measurement samples. We propose a spectral matching method that efficiently resolves permutations by aligning spectral components of the measurement and feature covariances. Rigorous theoretical analyses demonstrate that our method achieves accurate estimates in both shuffled LS and shuffled LASSO settings, given a sufficient number of samples. Furthermore, we extend our approach to address simultaneous pose and correspondence estimation in image registration tasks. Experiments on synthetic datasets and real-world image registration scenarios show that our method outperforms existing algorithms in both estimation accuracy and registration performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00078v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.SP</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hang Liu, Anna Scaglione</dc:creator>
    </item>
    <item>
      <title>Local Clustering and Global Spreading of Receptors for Optimal Spatial Gradient Sensing</title>
      <link>https://arxiv.org/abs/2410.03395</link>
      <description>arXiv:2410.03395v2 Announce Type: replace-cross 
Abstract: Spatial information from cell-surface receptors is crucial for processes that require signal processing and sensing of the environment. Here, we investigate the optimal placement of such receptors through a theoretical model that minimizes uncertainty in gradient estimation. Without requiring a priori knowledge of the physical limits of sensing or biochemical processes, we reproduce the emergence of clusters that closely resemble those observed in real cells. On perfect spherical surfaces, optimally placed receptors spread uniformly. When perturbations break their symmetry, receptors cluster in regions of high curvature, massively reducing estimation uncertainty. This agrees with mechanistic models that minimize elastic preference discrepancies between receptors and cell membranes. We further extend our model to motile receptors responding to cell-shape changes and external fluid flow, demonstrating the relevance of our model in realistic scenarios. Our findings provide a simple and utilitarian explanation for receptor clustering at high-curvature regions when high sensing accuracy is paramount.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03395v2</guid>
      <category>physics.bio-ph</category>
      <category>cond-mat.soft</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>q-bio.CB</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevLett.134.158401</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Lett. 134, 158401 (2025)</arxiv:journal_reference>
      <dc:creator>Albert Alonso, Robert G. Endres, Julius B. Kirkegaard</dc:creator>
    </item>
    <item>
      <title>Variants of Solovay reducibility</title>
      <link>https://arxiv.org/abs/2410.15563</link>
      <description>arXiv:2410.15563v3 Announce Type: replace-cross 
Abstract: Outside of the left-c.e. reals, Solovay reducibility is considered to be behaved badly [10.1007/978-0-387-68441-3]. Proposals for variants of Solovay reducibility that are better suited for the investigation of arbitrary, not necessarily left-c.e. reals were made by Rettinger and Zheng [10.1007/978-3-540-27798-9_39], and, recently, by Titov [10.11588/heidok.00034250] and by Kumabe and co-authors [10.4115/jla.2020.12.2; 10.3233/COM-230486]. These variants all coincide with the original version of Solovay reducibility on the left-c.e. reals. Furthermore, they are all defined in terms of translation functions. The latter translate between computable approximations in the case of Rettinger and Zheng, are monotone in the case of Titov, and are functions between reals in the case of Kumabe et al.
  In what follows, we derive new results on the mentioned variants and their relation to each other. In particular, we obtain that Solovay reducibility defined in terms of translation function on rationals implies Solovay reducibility defined in terms of translation functions on reals, and we show that the original version of Solovay reducibility is strictly weaker than its monotone variant.
  Solovay reducibility and its variants mentioned so far have tight connections to Martin-L\"of randomness, the strongest and most central notion of a random sequence. For the investigation of Schnorr randomness, total variants of Solovay reducibility have been introduced by Merkle and Titov [10.48550/arXiv.2407.14869] in 2022 and, independently, by Kumabe et al. [10.3233/COM-230486] in 2024, the latter again via real-valued translation functions. In what follows, we show that total Solovay reducibility defined in terms of rational functions implies total Solovay reducibility defined in terms of real functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15563v3</guid>
      <category>math.LO</category>
      <category>cs.IT</category>
      <category>cs.LO</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ivan Titov</dc:creator>
    </item>
    <item>
      <title>A generalisation of bent vectors for Butson Hadamard matrices</title>
      <link>https://arxiv.org/abs/2412.16579</link>
      <description>arXiv:2412.16579v2 Announce Type: replace-cross 
Abstract: An $n\times n$ complex matrix $M$ with entries in the $k^{\textrm{th}}$ roots of unity which satisfies $MM^{\ast} = nI_{n}$ is called a Butson Hadamard matrix. While a matrix with entries in the $k^{\textrm{th}}$ roots typically does not have an eigenvector with entries in the same set, such vectors and their generalisations turn out to have multiple applications. A bent vector for $M$ satisfies $M{\bf x} = \lambda {\bf y}$ where ${\bf x}$ has entries in the $k^{\textrm{th}}$ roots of unity and all entries of $\textbf{y}$ are complex numbers of norm $1$. Such a bent vector ${\bf x}$ is self-dual if ${\bf y} = \mu{\bf x}$ and conjugate self-dual if ${\bf y} = \mu\overline{\bf x}$ for some $\mu$ of norm $1$.
  Using techniques from algebraic number theory, we prove some order conditions and non-existence results for self-dual and conjugate self-dual bent vectors; using tensor constructions and Bush-type matrices we give explicit examples. We conclude with an application to the covering radius of certain non-linear codes generalising the Reed Muller codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16579v2</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jos\'e Andr\'es Armario, Ronan Egan, Hadi Kharaghani, Padraig \'O Cath\'ain</dc:creator>
    </item>
    <item>
      <title>SuperARC: An Agnostic Test for Narrow, General, and Super Intelligence Based On the Principles of Recursive Compression and Algorithmic Probability</title>
      <link>https://arxiv.org/abs/2503.16743</link>
      <description>arXiv:2503.16743v2 Announce Type: replace-cross 
Abstract: We introduce an open-ended test grounded in algorithmic probability that can avoid benchmark contamination in the quantitative evaluation of frontier models in the context of their Artificial General Intelligence (AGI) and Superintelligence (ASI) claims. Unlike other tests, this test does not rely on statistical compression methods (such as GZIP or LZW), which are more closely related to Shannon entropy than to Kolmogorov complexity and are not able to test beyond simple pattern matching. The test challenges aspects of AI, in particular LLMs, related to features of intelligence of fundamental nature such as synthesis and model creation in the context of inverse problems (generating new knowledge from observation). We argue that metrics based on model abstraction and abduction (optimal Bayesian `inference') for predictive `planning' can provide a robust framework for testing intelligence, including natural intelligence (human and animal), narrow AI, AGI, and ASI. We found that LLM model versions tend to be fragile and incremental as a result of memorisation only with progress likely driven by the size of training data. The results were compared with a hybrid neurosymbolic approach that theoretically guarantees universal intelligence based on the principles of algorithmic probability and Kolmogorov complexity. The method outperforms LLMs in a proof-of-concept on short binary sequences. We prove that compression is equivalent and directly proportional to a system's predictive power and vice versa. That is, if a system can better predict it can better compress, and if it can better compress, then it can better predict. Our findings strengthen the suspicion regarding the fundamental limitations of LLMs, exposing them as systems optimised for the perception of mastery over human language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16743v2</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Hern\'andez-Espinosa, Luan Ozelim, Felipe S. Abrah\~ao, Hector Zenil</dc:creator>
    </item>
  </channel>
</rss>
