<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.ed-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.ed-ph</link>
    <description>physics.ed-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.ed-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Jun 2025 02:06:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Where's the Line? A Classroom Activity on Ethical and Constructive Use of Generative AI in Physics</title>
      <link>https://arxiv.org/abs/2506.00229</link>
      <description>arXiv:2506.00229v1 Announce Type: new 
Abstract: Generative AI tools like ChatGPT are rapidly reshaping how students and instructors engage with course material-and how they think about academic integrity. This paper presents a classroom activity designed to help physics students critically examine the ethical and educational implications of using AI in coursework. Through a structured sequence of case analysis, discussion, and optional policy drafting, students develop the metacognitive, ethical, and collaborative skills needed to navigate emerging technologies with thoughtfulness and integrity. Grounded in research on constructivist learning, metacognition, and student agency, the activity positions students as co-creators of an ethical and engaged learning environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00229v1</guid>
      <category>physics.ed-ph</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zosia Krusberg</dc:creator>
    </item>
    <item>
      <title>Scaling Physical Reasoning with the PHYSICS Dataset</title>
      <link>https://arxiv.org/abs/2506.00022</link>
      <description>arXiv:2506.00022v2 Announce Type: cross 
Abstract: Large Language Models (LLMs) have achieved remarkable progress on advanced reasoning tasks such as mathematics and coding competitions. Meanwhile, physics, despite being both reasoning-intensive and essential to real-world understanding, received limited academic and industrial attention. This paper introduces PHYSICS, a dataset containing 16,568 high-quality physics problems spanning subjects and difficulty levels, to facilitate this issue. Specifically, PHYSICS is curated with exercises from over 100 textbooks through a carefully designed pipeline for quality control. It covers five major physics domains: Mechanics, Electromagnetism, Thermodynamics, Optics, and Modern Physics. It also spans a wide range of difficulty levels, from high school to graduate-level physics courses. To utilize the data for improving and evaluating the model's physical reasoning capabilities, we split the dataset into training and test sets, and provide reasoning paths generated by powerful reasoning models for the training data to facilitate model training. In addition, for the evaluation part, we find that existing evaluation frameworks exhibit biases in aspects such as units, simplification, and precision in physics domain. To balance efficiency and accuracy, we introduce a Rule+Model evaluation framework tailored to physics problems. Our evaluations on current state-of-the-art open-source and proprietary models highlight the limitations of current models in handling physics-related tasks. We hope that our dataset and evaluation methodology will jointly advance the development of LLMs in the field of physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00022v2</guid>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>physics.ed-ph</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shenghe Zheng, Qianjia Cheng, Junchi Yao, Mengsong Wu, Haonan He, Ning Ding, Yu Cheng, Shuyue Hu, Lei Bai, Dongzhan Zhou, Ganqu Cui, Peng Ye</dc:creator>
    </item>
    <item>
      <title>Reflections of Cultural Wealth: Exploring Identity in Physics through Photo Elicitation</title>
      <link>https://arxiv.org/abs/2505.21739</link>
      <description>arXiv:2505.21739v2 Announce Type: replace 
Abstract: This paper presents a photo elicitation project that invites students to explore their identities in STEM and surface the cultural wealth they bring into the physics classroom. Grounded in critical race theory, educational theory, and affective neuroscience, the project asks students to take original photographs representing aspects of their lived experience-such as motivation, belonging, and support systems-and to write short reflections connecting these images to their journey in science. The activity affirms students' backgrounds and values as meaningful resources for learning physics, while also fostering connection, inclusion, and reflective engagement. Practical guidance for implementation is provided. This adaptable, low-barrier practice offers an accessible entry point for instructors seeking to humanize physics education in powerful and inclusive ways.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21739v2</guid>
      <category>physics.ed-ph</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zosia Krusberg</dc:creator>
    </item>
    <item>
      <title>SeePhys: Does Seeing Help Thinking? -- Benchmarking Vision-Based Physics Reasoning</title>
      <link>https://arxiv.org/abs/2505.19099</link>
      <description>arXiv:2505.19099v3 Announce Type: replace-cross 
Abstract: We present SeePhys, a large-scale multimodal benchmark for LLM reasoning grounded in physics questions ranging from middle school to PhD qualifying exams. The benchmark covers 7 fundamental domains spanning the physics discipline, incorporating 21 categories of highly heterogeneous diagrams. In contrast to prior works where visual elements mainly serve auxiliary purposes, our benchmark features a substantial proportion of vision-essential problems (75%) that mandate visual information extraction for correct solutions. Through extensive evaluation, we observe that even the most advanced visual reasoning models (e.g., Gemini-2.5-pro and o4-mini) achieve sub-60% accuracy on our benchmark. These results reveal fundamental challenges in current large language models' visual understanding capabilities, particularly in: (i) establishing rigorous coupling between diagram interpretation and physics reasoning, and (ii) overcoming their persistent reliance on textual cues as cognitive shortcuts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19099v3</guid>
      <category>cs.AI</category>
      <category>physics.ed-ph</category>
      <category>physics.pop-ph</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kun Xiang, Heng Li, Terry Jingchen Zhang, Yinya Huang, Zirong Liu, Peixin Qu, Jixi He, Jiaqi Chen, Yu-Jie Yuan, Jianhua Han, Hang Xu, Hanhui Li, Mrinmaya Sachan, Xiaodan Liang</dc:creator>
    </item>
  </channel>
</rss>
