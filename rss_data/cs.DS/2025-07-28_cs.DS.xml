<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Jul 2025 02:13:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Truly Subcubic Combinatorial Algorithm for Induced 4-Cycle Detection</title>
      <link>https://arxiv.org/abs/2507.18845</link>
      <description>arXiv:2507.18845v1 Announce Type: new 
Abstract: We present the first truly subcubic, combinatorial algorithm for detecting an induced $4$-cycle in a graph. The running time is $O(n^{2.84})$ on $n$-node graphs, thus separating the task of detecting induced $4$-cycles from detecting triangles, which requires $n^{3-o(1)}$ time combinatorially under the popular BMM hypothesis.
  Significant work has gone into characterizing the exact time complexity of induced $H$-detection, relative to the complexity of detecting cliques of various sizes. Prior work identified the question of whether induced $4$-cycle detection is triangle-hard as the only remaining case towards completing the lowest level of the classification, dubbing it a "curious" case [Dalirrooyfard, Vassilevska W., FOCS 2022]. Our result can be seen as a negative resolution of this question.
  Our algorithm deviates from previous techniques in the large body of subgraph detection algorithms and employs the trendy topic of graph decomposition that has hitherto been restricted to more global problems (as in the use of expander decompositions for flow problems) or to shaving subpolynomial factors (as in the application of graph regularity lemmas). While our algorithm is slower than the (non-combinatorial) state-of-the-art $\tilde{O}(n^{\omega})$-time algorithm based on polynomial identity testing [Vassilevska W., Wang, Williams, Yu, SODA 2014], combinatorial advancements often come with other benefits. In particular, we give the first nontrivial deterministic algorithm for detecting induced $4$-cycles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18845v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Abboud, Shyan Akmal, Nick Fischer</dc:creator>
    </item>
    <item>
      <title>String Consensus Problems with Swaps and Substitutions</title>
      <link>https://arxiv.org/abs/2507.19139</link>
      <description>arXiv:2507.19139v2 Announce Type: new 
Abstract: String consensus problems aim at finding a string that minimizes some given distance with respect to an input set of strings. In particular, in the Closest string problem, we are given a set of strings of equal length and a radius $d$. The objective is to find a new string that differs from each input string by at most $d$ substitutions. We study a generalization of this problem where, in addition to substitutions, swaps of adjacent characters are also permitted, each operation incurring a unit cost. Amir et al. showed that this generalized problem is NP-hard, even when only swaps are allowed. In this paper, we show that it is FPT with respect to the parameter $d$. Moreover, we investigate a variant in which the goal is to minimize the sum of distances from the output string to all input strings. For this version, we present a polynomial-time algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19139v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Est\'eban Gabory, Laurent Bulteau, Gabriele Fici, Hilde Verbeek</dc:creator>
    </item>
    <item>
      <title>Budget and Profit Approximations for Spanning Tree Interdiction</title>
      <link>https://arxiv.org/abs/2507.19178</link>
      <description>arXiv:2507.19178v1 Announce Type: new 
Abstract: We give polynomial time logarithmic approximation guarantees for the budget minimization, as well as for the profit maximization versions of minimum spanning tree interdiction. In this problem, the goal is to remove some edges of an undirected graph with edge weights and edge costs, so as to increase the weight of a minimum spanning tree. In the budget minimization version, the goal is to minimize the total cost of the removed edges, while achieving a desired increase $\Delta$ in the weight of the minimum spanning tree. An alternative objective within the same framework is to maximize the profit of interdiction, namely the increase in the weight of the minimum spanning tree, subject to a budget constraint. There are known polynomial time $O(1)$ approximation guarantees for a similar objective (maximizing the total cost of the tree, rather than the increase). However, the guarantee does not seem to apply to the increase in cost. Moreover, the same techniques do not seem to apply to the budget version.
  Our approximation guarantees are motivated by studying the question of minimizing the cost of increasing the minimum spanning tree by any amount. We show that in contrast to the budget and profit problems, this version of interdiction is polynomial time-solvable, and we give an efficient algorithm for solving it. The solution motivates a graph-theoretic relaxation of the NP-hard interdiction problem. The gain in minimum spanning tree weight, as a function of the set of removed edges, is super-modular. Thus, the budget problem is an instance of minimizing a linear function subject to a super-modular covering constraint. We use the graph-theoretic relaxation to design and analyze a batch greedy-based algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19178v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rafail Ostrovsky, Yuval Rabani, Yoav Siman Tov</dc:creator>
    </item>
    <item>
      <title>Query Efficient Structured Matrix Learning</title>
      <link>https://arxiv.org/abs/2507.19290</link>
      <description>arXiv:2507.19290v1 Announce Type: new 
Abstract: We study the problem of learning a structured approximation (low-rank, sparse, banded, etc.) to an unknown matrix $A$ given access to matrix-vector product (matvec) queries of the form $x \rightarrow Ax$ and $x \rightarrow A^Tx$. This problem is of central importance to algorithms across scientific computing and machine learning, with applications to fast multiplication and inversion for structured matrices, building preconditioners for first-order optimization, and as a model for differential operator learning. Prior work focuses on obtaining query complexity upper and lower bounds for learning specific structured matrix families that commonly arise in applications.
  We initiate the study of the problem in greater generality, aiming to understand the query complexity of learning approximations from general matrix families. Our main result focuses on finding a near-optimal approximation to $A$ from any finite-sized family of matrices, $\mathcal{F}$. Standard results from matrix sketching show that $O(\log|\mathcal{F}|)$ matvec queries suffice in this setting. This bound can also be achieved, and is optimal, for vector-matrix-vector queries of the form $x,y\rightarrow x^TAy$, which have been widely studied in work on rank-$1$ matrix sensing.
  Surprisingly, we show that, in the matvec model, it is possible to obtain a nearly quadratic improvement in complexity, to $\tilde{O}(\sqrt{\log|\mathcal{F}|})$. Further, we prove that this bound is tight up to log-log factors.Via covering number arguments, our result extends to well-studied infinite families. As an example, we establish that a near-optimal approximation from any \emph{linear matrix family} of dimension $q$ can be learned with $\tilde{O}(\sqrt{q})$ matvec queries, improving on an $O(q)$ bound achievable via sketching techniques and vector-matrix-vector queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19290v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noah Amsel, Pratyush Avi, Tyler Chen, Feyza Duman Keles, Chinmay Hegde, Cameron Musco, Christopher Musco, David Persson</dc:creator>
    </item>
    <item>
      <title>Edge-weighted Matching in the Dark</title>
      <link>https://arxiv.org/abs/2507.19366</link>
      <description>arXiv:2507.19366v1 Announce Type: new 
Abstract: We present a $0.659$-competitive Quadratic Ranking algorithm for the Oblivious Bipartite Matching problem, a distribution-free version of Query-Commit Matching. This result breaks the $1-\frac{1}{e}$ barrier, addressing an open question raised by Tang, Wu, and Zhang (JACM 2023). Moreover, the competitive ratio of this distribution-free algorithm improves the best existing $0.641$ ratio for Query-Commit Matching achieved by the distribution-dependent algorithm of Chen, Huang, Li, and Tang (SODA 2025).
  Quadratic Ranking is a novel variant of the classic Ranking algorithm. We parameterize the algorithm with two functions, and let two key expressions in the definition and analysis of the algorithm be quadratic forms of the two functions. We show that the quadratic forms are the unique choices that satisfy a set of natural properties. Further, they allow us to optimize the choice of the two functions using powerful quadratic programming solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19366v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyi Huang, Enze Sun, Xiaowei Wu, Jiahao Zhao</dc:creator>
    </item>
    <item>
      <title>Downward self-reducibility in the total function polynomial hierarchy</title>
      <link>https://arxiv.org/abs/2507.19108</link>
      <description>arXiv:2507.19108v1 Announce Type: cross 
Abstract: A problem $\mathcal{P}$ is considered downward self-reducible, if there exists an efficient algorithm for $\mathcal{P}$ that is allowed to make queries to only strictly smaller instances of $\mathcal{P}$. Downward self-reducibility has been well studied in the case of decision problems, and it is well known that any downward self-reducible problem must lie in $\mathsf{PSPACE}$. Harsha, Mitropolsky and Rosen [ITCS, 2023] initiated the study of downward self reductions in the case of search problems. They showed the following interesting collapse: if a problem is in $\mathsf{TFNP}$ and also downward self-reducible, then it must be in $\mathsf{PLS}$. Moreover, if the problem admits a unique solution then it must be in $\mathsf{UEOPL}$.
  We demonstrate that this represents just the tip of a much more general phenomenon, which holds for even harder search problems that lie higher up in the total function polynomial hierarchy ($\mathsf{TF\Sigma_i^P}$). In fact, even if we allow our downward self-reduction to be much more powerful, such a collapse will still occur.
  We show that any problem in $\mathsf{TF\Sigma_i^P}$ which admits a randomized downward self-reduction with access to a $\mathsf{\Sigma_{i-1}^P}$ oracle must be in $\mathsf{PLS}^{\mathsf{\Sigma_{i-1}^P}}$. If the problem has \textit{essentially unique solutions} then it lies in $\mathsf{UEOPL}^{\mathsf{\Sigma_{i-1}^P}}$.
  As one (out of many) application of our framework, we get new upper bounds for the problems $\mathrm{Range Avoidance}$ and $\mathrm{Linear Ordering Principle}$ and show that they are both in $\mathsf{UEOPL}^{\mathsf{NP}}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19108v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karthik Gajulapalli, Surendra Ghentiyala, Zeyong Li, Sidhant Saraogi</dc:creator>
    </item>
    <item>
      <title>Cycle-factors of regular graphs via entropy</title>
      <link>https://arxiv.org/abs/2507.19417</link>
      <description>arXiv:2507.19417v1 Announce Type: cross 
Abstract: It is a classical result that a random permutation of $n$ elements has, on average, about $\log n$ cycles. We generalise this fact to all directed $d$-regular graphs on $n$ vertices by showing that, on average, a random cycle-factor of such a graph has $\mathcal{O}((n\log d)/d)$ cycles. This is tight up to the constant factor and improves the best previous bound of the form $\mathcal{O}(n/\sqrt{\log d})$ due to Vishnoi. Our results also yield randomised polynomial-time algorithms for finding such a cycle-factor and for finding a tour of length $(1+\mathcal{O}((\log d)/d)) \cdot n$ if the graph is connected. This makes progress on a conjecture of Magnant and Martin and on a problem studied by Vishnoi and by Feige, Ravi, and Singh. Our proof uses the language of entropy to exploit the fact that the upper and lower bounds on the number of perfect matchings in regular bipartite graphs are extremely close.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19417v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micha Christoph, Nemanja Dragani\'c, Ant\'onio Gir\~ao, Eoin Hurley, Lukas Michel, Alp M\"uyesser</dc:creator>
    </item>
    <item>
      <title>Minmax-Regret $k$-Sink Location on a Dynamic Tree Network with Uniform Capacities</title>
      <link>https://arxiv.org/abs/1806.03814</link>
      <description>arXiv:1806.03814v2 Announce Type: replace 
Abstract: A dynamic flow network $G$ with uniform capacity $c$ is a graph in which at most $c$ units of flow can enter an edge in one time unit. If flow enters a vertex faster than it can leave, congestion occurs. The evacuation problem is to evacuate all flow to sinks assuming that all flow is confluent, i.e., all flow passing through a particular vertex must follow the same exit edge. The $k$-sink location problem is to place $k$-sinks so as to minimize this evacuation time. Although the $k$-sink location problem is NP-Hard on a general graph it can be solved in $\tilde O(k^2 n)$ time on trees.
  The concept of minmax-regret arises from robust optimization. For each source, a range of possible flow values is provided and any scenario with flow values in those ranges might occur. The goal is to find a sink placement that minimizes, over all possible scenarios, the difference between the evacuation time to those sinks and the minimal evacuation time of that scenario.
  The Minmax-Regret $k$-Sink Location on a Dynamic Path Networks with uniform capacities is polynomial solvable in $n$ and $k$. Similarly, the Minmax-Regret $k$-center problem on trees is polynomial solvable in $n$ and $k$. Prior to this work, polynomial time solutions to the Minmax-Regret $k$-Sink Location on Dynamic Tree Networks with uniform capacities were only known for $k=1$. This paper solves this problem, for general $k,$ in time
  $$O\Bigl( \max(k^2 \log^2 k,\log ^2n)\, k^4 n^2 \log^5 n\Bigr)$$</description>
      <guid isPermaLink="false">oai:arXiv.org:1806.03814v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mordecai J. Golin, Sai Sandeep</dc:creator>
    </item>
    <item>
      <title>Kernelization for list $H$-coloring for graphs with small vertex cover</title>
      <link>https://arxiv.org/abs/2507.12005</link>
      <description>arXiv:2507.12005v2 Announce Type: replace-cross 
Abstract: For a fixed graph $H$, in the List $H$-Coloring problem, we are given a graph $G$ along with list $L(v) \subseteq V(H)$ for every $v \in V(G)$, and we have to determine if there exists a list homomorphism $\varphi$ from $(G,L)$ to $H$, i.e., an edge preserving mapping $\varphi: V(G)\to V(H)$ that satisfies $\varphi(v)\in L(v)$ for every $v\in V(G)$. Note that if $H$ is the complete graph on $q$ vertices, the problem is equivalent to List $q$-Coloring. We investigate the kernelization properties of List $H$-Coloring parameterized by the vertex cover number of $G$: given an instance $(G,L)$ and a vertex cover of $G$ of size $k$, can we reduce $(G,L)$ to an equivalent instance $(G',L')$ of List $H$-Coloring where the size of $G'$ is bounded by a low-degree polynomial $p(k)$ in $k$? This question has been investigated previously by Jansen and Pieterse [Algorithmica 2019], who provided an upper bound, which turns out to be optimal if $H$ is a complete graph, i.e., for List $q$-Coloring. This result was one of the first applications of the method of kernelization via bounded-degree polynomials. We define two new integral graph invariants, $c^*(H)$ and $d^*(H)$, with $d^*(H) \leq c^*(H) \leq d^*(H)+1$, and show that for every graph $H$, List $H$-Coloring
  -- has a kernel with $\mathcal{O}(k^{c^*(H)})$ vertices,
  -- admits no kernel of size $\mathcal{O}(k^{d^*(H)-\varepsilon})$ for any $\varepsilon &gt; 0$, unless the polynomial hierarchy collapses.
  -- Furthermore, if $c^*(H) &gt; d^*(H)$, then there is a kernel with $\mathcal{O}(k^{c^*(H)-\varepsilon})$ vertices where $\varepsilon \geq 2^{1-c^*(H)}$.
  Additionally, we show that for some classes of graphs, including powers of cycles and graphs $H$ where $\Delta(H) \leq c^*(H)$ (which in particular includes cliques), the bound $d^*(H)$ is tight, using the polynomial method. We conjecture that this holds in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12005v2</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marta Piecyk, Astrid Pieterse, Pawe{\l} Rz\k{a}\.zewski, Magnus Wahlstr\"om</dc:creator>
    </item>
    <item>
      <title>Certificate-Sensitive Subset Sum: Realizing Instance Complexity</title>
      <link>https://arxiv.org/abs/2507.15511</link>
      <description>arXiv:2507.15511v3 Announce Type: replace-cross 
Abstract: We present, to our knowledge, the first deterministic, certificate-sensitive algorithm for a canonical NP-complete problem whose runtime provably adapts to the structure of each input. For a Subset-Sum instance $(S, t)$, let $\Sigma(S)$ denote the set of distinct subset sums and define $U = |\Sigma(S)|$. This set serves as an information-theoretically minimal witness, the instance-complexity (IC) certificate.
  Our solver, IC-SubsetSum, enumerates every element of $\Sigma(S)$ in deterministic time $O(U \cdot n^2)$ and space $O(U \cdot n)$. A randomized variant achieves expected runtime $O(U \cdot n)$. The algorithm's complexity is thus directly governed by the certificate size, and this structure-sensitive performance is paired with a guaranteed worst-case runtime of $O^*(2^{n/2 - \varepsilon})$ for some constant $\varepsilon &gt; 0$, the first such result to strictly outperform classical methods on every instance.
  We revisit fine-grained reductions that rely on the classical $2^{n/2}$ hardness of SubsetSum and show that these arguments hold only for collision-free instances where $U$ is maximal. IC-SubsetSum reframes this barrier structurally and introduces a new paradigm for certificate-sensitive algorithms across NP-complete problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15511v3</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jesus Salas</dc:creator>
    </item>
  </channel>
</rss>
