<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Aug 2024 02:29:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A value-focused thinking approach to measure community resilience</title>
      <link>https://arxiv.org/abs/2408.00901</link>
      <description>arXiv:2408.00901v1 Announce Type: new 
Abstract: Community resilience refers to the ability to prepare for, absorb, recover from, and adapt to disruptive events, but specific definitions and measures for resilience can vary widely from researcher to researcher or from discipline to discipline. Community resilience is often measured using a set of indicators based on census, socioeconomic, and community organizational data, but these metrics and measures for community resilience provide little guidance for policymakers to determine how best to increase the community resilience. This article proposes to measure community resilience based on value focused thinking. We propose an objectives hierarchy that begins with a community decision makers' fundamental objective for resilience. Six high level objectives for community resilience, including social resilience, economic resilience, infrastructure resilience, environmental resilience, availability of resources, and functionality of critical services, are broken down into measurable attributes that focus on specific outcomes that a decision maker would like to achieve if a disruption occurs. This new way of assessing resilience is applied to measure the resilience of an illustrative community to an improvised explosive device, a cyberattack, a tornado, a flood, and a winter storm. Keywords: Community Resilience, Resiliency, Risk Analysis</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00901v1</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rohit Suresh, Parastoo Akbari, Cameron A MacKenzie</dc:creator>
    </item>
    <item>
      <title>High-Impact Innovations and Hidden Gender Disparities in Inventor-Evaluator Networks</title>
      <link>https://arxiv.org/abs/2408.00905</link>
      <description>arXiv:2408.00905v1 Announce Type: new 
Abstract: We study of millions of scientific, technological, and artistic innovations and find that the innovation gap faced by women is far from universal. No gap exists for conventional innovations. Rather, the gap is pervasively rooted in innovations that combine ideas in unexpected ways - innovations most critical to scientific breakthroughs. Further, at the USPTO we find that female examiners reject up to 33 percent more unconventional innovations by women inventors than do male examiners, suggesting that gender discrimination weakly explains this innovation gap. Instead, new data indicate that a configuration of institutional practices explains the innovation gap. These practices compromise the expertise women examiners need to accurately assess unconventional innovations and then "over-assign" women examiners to women innovators, undermining women's innovations. These institutional impediments negatively impact innovation rates in science but have the virtue of being more amenable to actionable policy changes than does culturally ingrained gender discrimination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00905v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>cs.DL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tara Sowrirajan, Ryan Whalen, Brian Uzzi</dc:creator>
    </item>
    <item>
      <title>A Note on Computing Betweenness Centrality from the 2-core</title>
      <link>https://arxiv.org/abs/2408.01157</link>
      <description>arXiv:2408.01157v1 Announce Type: new 
Abstract: A central task in network analysis is to identify important nodes in a graph. Betweenness centrality (BC) is a popular centrality measure that captures the significance of nodes based on the number of shortest paths each node intersects with. In this note, we derive a recursive formula to compute the betweenness centralities of a graph from the betweenness centralities of its 2-core.Furthermore, we analyze mathematically the significant impact of removing degree-one nodes on the estimation of betweenness centrality within the context of the popular pivot sampling scheme for Single-Source Shortest Path (SSSP) computations, as described in the Brandes-Pich approach and implemented in widely used software such as NetworkX. We demonstrate both theoretically and empirically that removing degree-1 nodes can reduce the sample complexity needed to achieve better accuracy, thereby decreasing the overall runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01157v1</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charalampos E. Tsourakakis</dc:creator>
    </item>
    <item>
      <title>Detection and Characterization of Coordinated Online Behavior: A Survey</title>
      <link>https://arxiv.org/abs/2408.01257</link>
      <description>arXiv:2408.01257v1 Announce Type: new 
Abstract: Coordination is a fundamental aspect of life. The advent of social media has made it integral also to online human interactions, such as those that characterize thriving online communities and social movements. At the same time, coordination is also core to effective disinformation, manipulation, and hate campaigns. This survey collects, categorizes, and critically discusses the body of work produced as a result of the growing interest on coordinated online behavior. We reconcile industry and academic definitions, propose a comprehensive framework to study coordinated online behavior, and review and critically discuss the existing detection and characterization methods. Our analysis identifies open challenges and promising directions of research, serving as a guide for scholars, practitioners, and policymakers in understanding and addressing the complexities inherent to online coordination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01257v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Mannocci, Michele Mazza, Anna Monreale, Maurizio Tesconi, Stefano Cresci</dc:creator>
    </item>
    <item>
      <title>Ginzburg--Landau Functionals in the Large-Graph Limit</title>
      <link>https://arxiv.org/abs/2408.00422</link>
      <description>arXiv:2408.00422v1 Announce Type: cross 
Abstract: Ginzburg--Landau (GL) functionals on graphs, which are relaxations of graph-cut functionals on graphs, have yielded a variety of insights in image segmentation and graph clustering. In this paper, we study large-graph limits of GL functionals by taking a functional-analytic view of graphs as nonlocal kernels. For a graph $W_n$ with $n$ nodes, the corresponding graph GL functional $\GL^{W_n}_\ep$ is an energy for functions on $W_n$. We minimize GL functionals on sequences of growing graphs that converge to functions called graphons. For such sequences of graphs, we show that the graph GL functional $\Gamma$-converges to a continuous and nonlocal functional that we call the \emph{graphon GL functional}. We also investigate the sharp-interface limits of the graph GL and graphon GL functionals, and we relate these limits to a nonlocal total variation. We express the limiting GL functional in terms of Young measures and thereby obtain a probabilistic interpretation of the variational problem in the large-graph limit. Finally, to develop intuition about the graphon GL functional, we compute the GL minimizer for several example families of graphons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00422v1</guid>
      <category>math.FA</category>
      <category>cs.SI</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edith Zhang, James Scott, Qiang Du, Mason A. Porter</dc:creator>
    </item>
    <item>
      <title>Y Social: an LLM-powered Social Media Digital Twin</title>
      <link>https://arxiv.org/abs/2408.00818</link>
      <description>arXiv:2408.00818v1 Announce Type: cross 
Abstract: In this paper we introduce Y, a new-generation digital twin designed to replicate an online social media platform. Digital twins are virtual replicas of physical systems that allow for advanced analyses and experimentation. In the case of social media, a digital twin such as Y provides a powerful tool for researchers to simulate and understand complex online interactions. {\tt Y} leverages state-of-the-art Large Language Models (LLMs) to replicate sophisticated agent behaviors, enabling accurate simulations of user interactions, content dissemination, and network dynamics. By integrating these aspects, Y offers valuable insights into user engagement, information spread, and the impact of platform policies. Moreover, the integration of LLMs allows Y to generate nuanced textual content and predict user responses, facilitating the study of emergent phenomena in online environments.
  To better characterize the proposed digital twin, in this paper we describe the rationale behind its implementation, provide examples of the analyses that can be performed on the data it enables to be generated, and discuss its relevance for multidisciplinary research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00818v1</guid>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giulio Rossetti, Massimo Stella, R\'emy Cazabet, Katherine Abramski, Erica Cau, Salvatore Citraro, Andrea Failla, Riccardo Improta, Virginia Morini, Valentina Pansanella</dc:creator>
    </item>
    <item>
      <title>Rumour Spreading Depends on the Latent Geometry and Degree Distribution in Social Network Models</title>
      <link>https://arxiv.org/abs/2408.01268</link>
      <description>arXiv:2408.01268v1 Announce Type: cross 
Abstract: We study push-pull rumour spreading in small-world models for social networks where the degrees follow a power-law. In a non-geometric setting Fountoulakis, Panagiotou and Sauerwald have shown that rumours always spread fast (SODA 2012). On the other hand, Janssen and Mehrabian have found that rumours spread slowly in a spatial preferential attachment model (SIDMA 2017). We study the question systematically for the model of geometric inhomogeneous random graphs (GIRGs), which has been found to be a good theoretical and empirical fit for social networks. Our result is two-fold: with classical Euclidean geometry both slow and fast rumour spreading may occur, depending on the exponent of the power law and the prevalence of weak ties in the networks, and we fully characterise the phase boundaries between those two regimes. Depending on the parameters, fast spreading may either mean polylogarithmic time or even doubly logarithmic time. Secondly, we show that rumour spreading is always fast in a non-metric geometry. The considered non-metric geometry allows to model social connections where resemblance of vertices in a single attribute, such as familial kinship, already strongly indicates the presence of an edge. Classical Euclidean Geometry fails to capture such ties.
  For some regimes in the Euclidean setting, the efficient pathways for spreading rumours differ from previously identified paths. A vertex of degree $d$ can transmit the rumour efficiently to a vertex of larger degree by a chain of length $3$, where one of the two intermediaries has constant degree, and the other has degree $d^{c}$ for some constant $c&lt;1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01268v1</guid>
      <category>math.PR</category>
      <category>cs.SI</category>
      <category>math.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Kaufmann, Kostas Lakis, Johannes Lengler, Raghu Raman Ravi, Ulysse Schaller, Konstantin Sturm</dc:creator>
    </item>
    <item>
      <title>A New Perspective to Node Influence Evaluation in Complex Network Using Subgraph Tr-Centrality</title>
      <link>https://arxiv.org/abs/2012.13617</link>
      <description>arXiv:2012.13617v2 Announce Type: replace 
Abstract: There is great significance in evaluating a node's Influence ranking in complex networks. Over the years, many researchers have presented different measures for quantifying node interconnectedness within networks. Therefore, this paper introduces a centrality measure called Tr-centrality which focuses on using the node triangle structure and the node neighborhood information to define the strength of a node, which is defined as the summation of Gruebler's Equation of the node's one-hop triangle neighborhood to the number of all the edges in the subgraph. Furthermore, we socially consider it as the local trust of a node. To verify the validity of Tr-centrality [1], we apply it to four real-world networks with different densities and shapes, and Tr-centrality has proven to yield better results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.13617v2</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.14025.36960</arxiv:DOI>
      <dc:creator>Auwal Tijjani Amshi</dc:creator>
    </item>
    <item>
      <title>A Novel Method for News Article Event-Based Embedding</title>
      <link>https://arxiv.org/abs/2405.13071</link>
      <description>arXiv:2405.13071v2 Announce Type: replace-cross 
Abstract: Embedding news articles is a crucial tool for multiple fields, such as media bias detection, identifying fake news, and making news recommendations. However, existing news embedding methods are not optimized to capture the latent context of news events. Most embedding methods rely on full-text information and neglect time-relevant embedding generation. In this paper, we propose a novel lightweight method that optimizes news embedding generation by focusing on entities and themes mentioned in articles and their historical connections to specific events. We suggest a method composed of three stages. First, we process and extract events, entities, and themes from the given news articles. Second, we generate periodic time embeddings for themes and entities by training time-separated GloVe models on current and historical data. Lastly, we concatenate the news embeddings generated by two distinct approaches: Smooth Inverse Frequency (SIF) for article-level vectors and Siamese Neural Networks for embeddings with nuanced event-related information. We leveraged over 850,000 news articles and 1,000,000 events from the GDELT project to test and evaluate our method. We conducted a comparative analysis of different news embedding generation methods for validation. Our experiments demonstrate that our approach can both improve and outperform state-of-the-art methods on shared event detection tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13071v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koren Ishlach, Itzhak Ben-David, Michael Fire, Lior Rokach</dc:creator>
    </item>
  </channel>
</rss>
