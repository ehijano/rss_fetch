<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Nov 2025 02:49:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Evolution of A4L: A Data Architecture for AI-Augmented Learning</title>
      <link>https://arxiv.org/abs/2511.11877</link>
      <description>arXiv:2511.11877v1 Announce Type: new 
Abstract: As artificial intelligence (AI) becomes more deeply integrated into educational ecosystems, the demand for scalable solutions that enable personalized learning continues to grow. These architectures must support continuous data flows that power personalized learning and access to meaningful insights to advance learner success at scale. At the National AI Institute for Adult Learning and Online Education (AI-ALOE), we have developed an Architecture for AI-Augmented Learning (A4L) to support analysis and personalization of online education for adult learners. A4L1.0, an early implementation by Georgia Tech's Design Intelligence Laboratory, demonstrated how the architecture supports analysis of meso- and micro-learning by integrating data from Learning Management Systems (LMS) and AI tools. These pilot studies informed the design of A4L2.0. In this chapter, we describe A4L2.0 that leverages 1EdTech Consortium's open standards such as Edu-API, Caliper Analytics, and Learning Tools Interoperability (LTI) to enable secure, interoperable data integration across data systems like Student Information Systems (SIS), LMS, and AI tools. The A4L2.0 data pipeline includes modules for data ingestion, preprocessing, organization, analytics, and visualization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11877v1</guid>
      <category>cs.ET</category>
      <category>cs.CY</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ploy Thajchayapong, Suzanne Carbonaro, Tim Couper, Blaine Helmick, Spencer Rugaber, Ashok Goel</dc:creator>
    </item>
    <item>
      <title>QPU Micro-Kernels for Stencil Computation</title>
      <link>https://arxiv.org/abs/2511.12617</link>
      <description>arXiv:2511.12617v1 Announce Type: new 
Abstract: We introduce QPU micro-kernels: shallow quantum circuits that perform a stencil node update and return a Monte Carlo estimate from repeated measurements. We show how to use them to solve Partial Differential Equations (PDEs) explicitly discretized on a computational stencil. From this point of view, the QPU serves as a sampling accelerator. Each micro-kernel consumes only stencil inputs (neighbor values and coefficients), runs a shallow parameterized circuit, and reports the sample mean of a readout rule. The resource footprint in qubits and depth is fixed and independent of the global grid. This makes micro-kernels easy to orchestrate from a classical host and to parallelize across grid points. We present two realizations. The Bernoulli micro-kernel targets convex-sum stencils by encoding values as single-qubit probabilities with shot allocation proportional to stencil weights. The branching micro-kernel prepares a selector over stencil branches and applies addressed rotations to a single readout qubit. In contrast to monolithic quantum PDE solvers that encode the full space-time problem in one deep circuit, our approach keeps the classical time loop and offloads only local updates. Batching and in-circuit fusion amortize submission and readout overheads. We test and validate the QPU micro-kernel method on two PDEs commonly arising in scientific computing: the Heat and viscous Burgers' equations. On noiseless quantum circuit simulators, accuracy improves as the number of samples increases. On the IBM Brisbane quantum computer, single-step diffusion tests show lower errors for the Bernoulli realization than for branching at equal shot budgets, with QPU micro-kernel execution dominating the wall time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12617v1</guid>
      <category>cs.ET</category>
      <category>cs.DC</category>
      <category>quant-ph</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano Markidis, Luca Pennati, Marco Pasquale, Gilbert Netzer, Ivy Peng</dc:creator>
    </item>
    <item>
      <title>Segmented Exponent Alignment and Dynamic Wordline Activation for Floating-Point Analog CIM Macros</title>
      <link>https://arxiv.org/abs/2511.12624</link>
      <description>arXiv:2511.12624v1 Announce Type: new 
Abstract: With the rise of compute-in-memory (CIM) accelerators, floating-point multiply-and-accumulate (FP-MAC) operations have gained extensive attention for their higher accuracy over integer MACs in neural networks. However, the hardware overhead caused by exponent comparison and mantissa alignment, along with the delay introduced by bit-serial input methods, remains a hinder to implement FP-MAC efficiently. In view of this, we propose Segmented Exponent Alignment (SEA) and Dynamic Wordline Activation (DWA) strategies. SEA exploits the observation that input exponents are often clustered around zero or within a narrow range. By segmenting the exponent space and aligning mantissas accordingly, SEA eliminates the need for maximum exponent detection and reduces input mantissa shifting, and thus reduces the processing latency. DWA further reduces latency and maintains accuracy by activating wordlines based on the exponent segments defined by SEA. Simulation results demonstrate that, when compared with conventional comparison tree based maximum exponent alignment method, our approach saves 63.8\% power consumption, and achieves a 40.87\% delay reduction on the VGG16-CIFAR10 benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12624v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiping Yang, Shilin Zhou, Hui Xu, Jiawei Xue, Changlin Chen</dc:creator>
    </item>
    <item>
      <title>PolicyBot - Reliable Question Answering over Policy Documents</title>
      <link>https://arxiv.org/abs/2511.13489</link>
      <description>arXiv:2511.13489v1 Announce Type: new 
Abstract: All citizens of a country are affected by the laws and policies introduced by their government. These laws and policies serve essential functions for citizens. Such as granting them certain rights or imposing specific obligations. However, these documents are often lengthy, complex, and difficult to navigate, making it challenging for citizens to locate and understand relevant information. This work presents PolicyBot, a retrieval-augmented generation (RAG) system designed to answer user queries over policy documents with a focus on transparency and reproducibility. The system combines domain-specific semantic chunking, multilingual dense embeddings, multi-stage retrieval with reranking, and source-aware generation to provide responses grounded in the original documents. We implemented citation tracing to reduce hallucinations and improve user trust, and evaluated alternative retrieval and generation configurations to identify effective design choices. The end-to-end pipeline is built entirely with open-source tools, enabling easy adaptation to other domains requiring document-grounded question answering. This work highlights design considerations, practical challenges, and lessons learned in deploying trustworthy RAG systems for governance-related contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13489v1</guid>
      <category>cs.ET</category>
      <category>cs.IR</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gautam Nagarajan, Omir Kumar, Sudarsun Santhiappan</dc:creator>
    </item>
    <item>
      <title>Optimal Multi-Constrained Workflow Scheduling for Cyber-Physical Systems in the Edge-Cloud Continuum</title>
      <link>https://arxiv.org/abs/2511.07466</link>
      <description>arXiv:2511.07466v1 Announce Type: cross 
Abstract: The emerging edge-hub-cloud paradigm has enabled the development of innovative latency-critical cyber-physical applications in the edge-cloud continuum. However, this paradigm poses multiple challenges due to the heterogeneity of the devices at the edge of the network, their limited computational, communication, and energy capacities, as well as their different sensing and actuating capabilities. To address these issues, we propose an optimal scheduling approach to minimize the overall latency of a workflow application in an edge-hub-cloud cyber-physical system. We consider multiple edge devices cooperating with a hub device and a cloud server. All devices feature heterogeneous multicore processors and various sensing, actuating, or other specialized capabilities. We present a comprehensive formulation based on continuous-time mixed integer linear programming, encapsulating multiple constraints often overlooked by existing approaches. We conduct a comparative experimental evaluation between our method and a well-established and effective scheduling heuristic, which we enhanced to consider the constraints of the specific problem. The results reveal that our technique outperforms the heuristic, achieving an average latency improvement of 13.54% in a relevant real-world use case, under varied system configurations. In addition, the results demonstrate the scalability of our method under synthetic workflows of varying sizes, attaining a 33.03% average latency decrease compared to the heuristic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07466v1</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/COMPSAC61105.2024.00072</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC), Osaka, Japan, 2024, pp. 483-492</arxiv:journal_reference>
      <dc:creator>Andreas Kouloumpris, Georgios L. Stavrinides, Maria K. Michael, Theocharis Theocharides</dc:creator>
    </item>
    <item>
      <title>ARise: an Augmented Reality Mobile Application to Improve Cultural Heritage Resilience</title>
      <link>https://arxiv.org/abs/2511.11610</link>
      <description>arXiv:2511.11610v1 Announce Type: cross 
Abstract: The preservation of cultural heritage faces increasing threats from climate change effects and environmental hazards, demanding innovative solutions that can promote awareness and resilience. This paper presents ARise, an Augmented Reality mobile application designed to enhance public engagement with cultural sites while raising awareness about the local impacts of climate change. Based on a user-centered co-creative methodology involving stakeholders from five European regions, ARise integrates multiple data sourcess - a Crowdsourcing Chatbot, a Social Media Data Analysis tool, and an AI-based Artwork Generation module - to deliver immersive and emotionally engaging experiences. Although formal user testing is forthcoming, this prototype demonstrates the potential of AR to support education, cultural sustainability, and climate adaptation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11610v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.2312/dh.20253340</arxiv:DOI>
      <arxiv:journal_reference>Digital Heritage 2025</arxiv:journal_reference>
      <dc:creator>Angelica Urbanelli, Marina Nadalin, Mario Chiesa, Rojin Bayat, Massimo Migliorini, Claudio Rossi</dc:creator>
    </item>
    <item>
      <title>Looking Forward: Challenges and Opportunities in Agentic AI Reliability</title>
      <link>https://arxiv.org/abs/2511.11921</link>
      <description>arXiv:2511.11921v1 Announce Type: cross 
Abstract: This chapter presents perspectives for challenges and future development in building reliable AI systems, particularly, agentic AI systems. Several open research problems related to mitigating the risks of cascading failures are discussed. The chapter also sheds lights on research challenges and opportunities in aspects including dynamic environments, inconsistent task execution, unpredictable emergent behaviors, as well as resource-intensive reliability mechanisms. In addition, several research directions along the line of testing and evaluating reliability of agentic AI systems are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11921v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.PF</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liudong Xing (Jing),  Janet (Jing),  Lin</dc:creator>
    </item>
    <item>
      <title>FERMI-ML: A Flexible and Resource-Efficient Memory-In-Situ SRAM Macro for TinyML acceleration</title>
      <link>https://arxiv.org/abs/2511.12544</link>
      <description>arXiv:2511.12544v1 Announce Type: cross 
Abstract: The growing demand for low-power and area-efficient TinyML inference on AIoT devices necessitates memory architectures that minimise data movement while sustaining high computational efficiency. This paper presents FERMI-ML, a Flexible and Resource-Efficient Memory-In-Situ (MIS) SRAM macro designed for TinyML acceleration. The proposed 9T XNOR-based RX9T bit-cell integrates a 5T storage cell with a 4T XNOR compute unit, enabling variable-precision MAC and CAM operations within the same array. A 22-transistor (C22T) compressor-tree-based accumulator facilitates logarithmic 1-64-bit MAC computation with reduced delay and power compared to conventional adder trees. The 4 KB macro achieves dual functionality for in-situ computation and CAM-based lookup operations, supporting Posit-4 or FP-4 precision. Post-layout results at 65 nm show operation at 350 MHz with 0.9 V, delivering a throughput of 1.93 TOPS and an energy efficiency of 364 TOPS/W, while maintaining a Quality-of-Result (QoR) above 97.5% with InceptionV4 and ResNet-18. FERMI-ML thus demonstrates a compact, reconfigurable, and energy-aware digital Memory-In-Situ macro capable of supporting mixed-precision TinyML workloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12544v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mukul Lokhande, Akash Sankhe, S. V. Jaya Chand, Santosh Kumar Vishvakarma</dc:creator>
    </item>
    <item>
      <title>Quantum Hyperdimensional Computing: a foundational paradigm for quantum neuromorphic architectures</title>
      <link>https://arxiv.org/abs/2511.12664</link>
      <description>arXiv:2511.12664v1 Announce Type: cross 
Abstract: A significant challenge in quantum computing (QC) is developing learning models that truly align with quantum principles, as many current approaches are complex adaptations of classical frameworks. In this work, we introduce Quantum Hyperdimensional Computing (QHDC), a fundamentally new paradigm. We demonstrate that the core operations of its classical counterpart, Hyperdimensional Computing (HDC), a brain-inspired model, map with remarkable elegance and direct correspondence onto the native operations of a QC. This suggests HDC is exceptionally well-suited for a quantum-native implementation. We establish a direct, resource-efficient mapping: (i) hypervectors are mapped to quantum states, (ii) the bundling operation is implemented as a quantum-native averaging process using a Linear Combination of Unitaries (LCU) and Oblivious Amplitude Amplification (OAA), (iii) the binding operation is realized via quantum phase oracles, (iv) the permutation operation is implemented using the Quantum Fourier Transform (QFT), and (v) vector similarity is calculated using quantum state fidelity measurements based on the Hadamard Test. We present the first-ever implementation of this framework, validated through symbolic analogical reasoning and supervised classification tasks. The viability of QHDC is rigorously assessed via a comparative analysis of results from classical computation, ideal quantum simulation, and execution of a 156-qubit IBM Heron r3 quantum processor. Our results validate the proposed mappings and demonstrate the versatility of the framework, establishing QHDC as a physically realizable technology. This work lays the foundation for a new class of quantum neuromorphic algorithms and opens a promising avenue for tackling complex cognitive and biomedical problems intractable for classical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12664v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.SC</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabio Cumbo, Rui-Hao Li, Bryan Raubenolt, Jayadev Joshi, Abu Kaisar Mohammad Masum, Sercan Aygun, Daniel Blankenberg</dc:creator>
    </item>
    <item>
      <title>Electric Truck Platooning with Charging Consideration and Leader Swapping</title>
      <link>https://arxiv.org/abs/2511.12965</link>
      <description>arXiv:2511.12965v1 Announce Type: cross 
Abstract: Electric trucks are increasingly deployed to reduce the trucking sector's carbon footprint, but their limited range and charging needs create operational challenges on mid- to long-haul routes. Truck platooning can mitigate range anxiety through energy savings and, in turn, influence routing and charging decisions, yet most existing studies focus on a single highway corridor and do not capture network-wide operations. We study electric truck platooning on a general road network, where trucks must select routes and charging stations with heterogeneous prices and charging speeds, form platoons on shared arcs, and possibly take detours that trade off platoon savings with additional labor hours. We further allow in-platoon position swaps so that leading responsibility rotates, balancing battery usage and avoiding early depletion of any single truck. To jointly optimize routing paths, charging-station choices, labor time, and platoon formation and position swaps, we formulate a mixed-integer linear program (MILP). Because exact methods become intractable on realistic instances, we develop an Adaptive Large Neighborhood Search (ALNS) algorithm enhanced with a savings-based bounding scheme, infeasible-pair elimination, and candidate-station filtering. Computational experiments on test instances with up to 150 trucks show that incorporating platooning can reduce total operational costs by up to 2.77 percent, while the proposed algorithm cuts computation time by up to 99.96 percent compared with CPLEX and solves 150-truck instances in about 120 seconds, indicating strong potential for real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12965v1</guid>
      <category>math.OC</category>
      <category>cs.ET</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilang Hao, Zhibin Chen</dc:creator>
    </item>
    <item>
      <title>MM-Telco: Benchmarks and Multimodal Large Language Models for Telecom Applications</title>
      <link>https://arxiv.org/abs/2511.13131</link>
      <description>arXiv:2511.13131v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have emerged as powerful tools for automating complex reasoning and decision-making tasks. In telecommunications, they hold the potential to transform network optimization, automate troubleshooting, enhance customer support, and ensure regulatory compliance. However, their deployment in telecom is hindered by domain-specific challenges that demand specialized adaptation. To overcome these challenges and to accelerate the adaptation of LLMs for telecom, we propose MM-Telco, a comprehensive suite of multimodal benchmarks and models tailored for the telecom domain. The benchmark introduces various tasks (both text based and image based) that address various practical real-life use cases such as network operations, network management, improving documentation quality, and retrieval of relevant text and images. Further, we perform baseline experiments with various LLMs and VLMs. The models fine-tuned on our dataset exhibit a significant boost in performance. Our experiments also help analyze the weak areas in the working of current state-of-art multimodal LLMs, thus guiding towards further development and research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13131v1</guid>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gagan Raj Gupta, Anshul Kumar, Manish Rai, Apu Chakraborty, Ashutosh Modi, Abdelaali Chaoub, Soumajit Pramanik, Moyank Giri, Yashwanth Holla, Sunny Kumar, M. V. Kiran Sooraj</dc:creator>
    </item>
    <item>
      <title>HPC-Accelerated Simulation and Calibration for Silicon Quantum Dots</title>
      <link>https://arxiv.org/abs/2511.13330</link>
      <description>arXiv:2511.13330v1 Announce Type: cross 
Abstract: Quantum computers (QCs) have the potential to solve critical problems significantly faster than today's most advanced supercomputers. One major challenge in realizing this technology is designing robust electrostatic pulses to realize unitaries on qubits. Current practice when calibrating unitaries involves recursive experimentation to find the highest-fidelity pulses. To accelerate this process for experimentalists, we implement Qalibrate, a fast, JAX-enabled simulator that generates pulses given target unitaries. Specifically, we generate a propagator that models the time evolution of three-electron spin qubits and integrate our gradient-based optimizer to generate the pulses. The simulation involves solving the Lindblad master equation, which we parallelize by employing an approximation of the time evolution called the Magnus expansion. Qalibrate shows up to a 34x speedup compared to an existing ODE simulator, making progress towards generating robust pulses for n-qubit systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13330v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dhilan Nag, Suhun Kim, Cole Johnson, Collin Sumrell</dc:creator>
    </item>
    <item>
      <title>Evaluation of Domain-Specific Architectures for General-Purpose Applications in Apple Silicon</title>
      <link>https://arxiv.org/abs/2511.13450</link>
      <description>arXiv:2511.13450v1 Announce Type: cross 
Abstract: The rise of AI and its growing computational demands have driven the integration of domain-specific accelerators (such as GPUs, TPUs, and NPUs) across the entire computing infrastructure. Following the precedent set by the GPGPU which popularized GPUs for general-purpose tasks, this research asks whether this phenomenon can be replicated with specialized accelerators like NPUs in new contexts. This paper evaluates the potential of the Apple Neural Engine (ANE) designed for high energy efficiency in Machine Learning workloads, in the context of general-purpose HPC applications. We evaluate the performance and energy consumption of classic HPC algorithms such as GEMM, Jacobi or Multigrid methods on Apple's ANE across the M1 and the latest M4 architectures. Results confirm that, when algorithms are properly adapted, the ANE achieves competitive performance (up to 3.8 TFlops on the M4-Pro, comparable to the GPU's 4.7 TFlops on the same SoC for GEMM operation) while demonstrating significantly superior energy efficiency (e.g., GEMM consumes 5.2 Watts on the ANE versus 24 Watts on GPU counterpart in M4 architectures).</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13450v1</guid>
      <category>cs.PF</category>
      <category>cs.ET</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\'Alvaro Corrochano L\'opez, Carlos Garc\'ia S\'anchez</dc:creator>
    </item>
    <item>
      <title>The Quick Red Fox gets the best Data Driven Classroom Interviews: A manual for an interview app and its associated methodology</title>
      <link>https://arxiv.org/abs/2511.13466</link>
      <description>arXiv:2511.13466v1 Announce Type: cross 
Abstract: Data Driven Classroom Interviews (DDCIs) are an interviewing technique that is facilitated by recent technological developments in the learning analytics community. DDCIs are short, targeted interviews that allow researchers to contextualize students' interactions with a digital learning environment (e.g., intelligent tutoring systems or educational games) while minimizing the amount of time that the researcher interrupts that learning experience, and focusing researcher time on the events they most want to focus on DDCIs are facilitated by a research tool called the Quick Red Fox (QRF)--an open-source server-client Android app that optimizes researcher time by directing interviewers to users that have just displayed an interesting behavior (previously defined by the research team). QRF integrates with existing student modeling technologies (e.g., behavior-sensing, affect-sensing, detection of self-regulated learning) to alert researchers to key moments in a learner's experience. This manual documents the tech while providing training on the processes involved in developing triggers and interview techniques; it also suggests methods of analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13466v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jaclyn Ocumpaugh, Luc Paquette, Ryan S. Baker, Amanda Barany, Jeff Ginger, Nathan Casano, Andres F. Zambrano, Xiner Liu, Zhanlan Wei, Yiqui Zhou, Qianhui Liu, Stephen Hutt, Alexandra M. A. Andres, Nidhi Nasiar, Camille Giordano, Martin van Velsen, Micheal Mogessi</dc:creator>
    </item>
    <item>
      <title>A First Look at Ethereum Blob Revolution: Market, Strategies, and Optimality</title>
      <link>https://arxiv.org/abs/2411.03892</link>
      <description>arXiv:2411.03892v4 Announce Type: replace-cross 
Abstract: As a key enabler of Web3, Ethereum has long faced scalability challenges. The recent EIP-4844 upgrade aims to alleviate the scalability issue by introducing the ''blob'', a new data structure for Layer-2 rollups that enables off-chain storage with much reduced costs. Yet, this new mechanism's impact on Ethereum, and the wider Web3 ecosystem, remains largely underexplored. In this paper, we conduct the first large-scale empirical analysis of the post-EIP-4844 ecosystem, leveraging a dataset of 319.5 million transactions, out of which 1.3 million are blob-carrying. Our analysis reveals two major trends: (1) average block size has increased 2.5 times, from 150 KB to 400 KB, while the share of conventional transactions has shrunk from over $150$ KB to around 80 KB; (2) rollups are rapidly migrating from expensive calldata, falling from approximately 7,500 to nearly zero, toward cheap blobs, rising from zero to about 10,000. These shifts introduce a new economic game between block builders and rollups. Thus, we develop a game-theoretic model to characterize their equilibrium strategies: a profit-maximizing inclusion rule for builders, and a cost-minimizing blob batching strategy for rollups. Empirically, however, we find notable economic inefficiencies: for example, 29.48% of blob-containing blocks are built sub-optimally, yielding less revenue than available alternatives. These findings highlight the intricacies of the blob marketplace, and our work has established both methodological and empirical foundations to understand the evolving post-EIP4844 Ethereum ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03892v4</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Huang, Shuzheng Wang, Yuming Huang, Gareth Tyson, Huayi Duan, Jing Tang</dc:creator>
    </item>
    <item>
      <title>Tile Reconfiguration by a Finite Automaton</title>
      <link>https://arxiv.org/abs/2501.08663</link>
      <description>arXiv:2501.08663v2 Announce Type: replace-cross 
Abstract: Shape formation is one of the most thoroughly studied problems in programmable matter and swarm robotics. However, in many models, the class of shapes that can be formed is highly restricted due to the particles' limited memory. In the hybrid model, an active agent with the computational power of a deterministic finite automaton can form shapes by lifting and placing passive tiles on the triangular lattice. We study the shape reconfiguration problem where the agent additionally has the ability to distinguish so-called target nodes from non-target nodes and needs to form a target shape from the initial tile configuration. We present a worst-case optimal $O(mn)$ algorithm for simply connected target shapes, where $m$ is the initial number of unoccupied target nodes and $n$ is the total number of tiles. Furthermore, we show how an agent can reconfigure a large class of target shapes with holes in $O(n^4)$ steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08663v2</guid>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Friemel, David Liedtke, Christian Scheffer</dc:creator>
    </item>
    <item>
      <title>qc-kmeans: A Quantum Compressive K-Means Algorithm for NISQ Devices</title>
      <link>https://arxiv.org/abs/2510.22540</link>
      <description>arXiv:2510.22540v2 Announce Type: replace-cross 
Abstract: Clustering on NISQ hardware is constrained by data loading and limited qubits. We present \textbf{qc-kmeans}, a hybrid compressive $k$-means that summarizes a dataset with a constant-size Fourier-feature sketch and selects centroids by solving small per-group QUBOs with shallow QAOA circuits. The QFF sketch estimator is unbiased with mean-squared error $O(\varepsilon^2)$ for $B,S=\Theta(\varepsilon^{-2})$, and the peak-qubit requirement $q_{\text{peak}}=\max\{D,\lceil \log_2 B\rceil + 1\}$ does not scale with the number of samples. A refinement step with elitist retention ensures non-increasing surrogate cost. In Qiskit Aer simulations (depth $p{=}1$), the method ran with $\le 9$ qubits on low-dimensional synthetic benchmarks and achieved competitive sum-of-squared errors relative to quantum baselines; runtimes are not directly comparable. On nine real datasets (up to $4.3\times 10^5$ points), the pipeline maintained constant peak-qubit usage in simulation. Under IBM noise models, accuracy was similar to the idealized setting. Overall, qc-kmeans offers a NISQ-oriented formulation with shallow, bounded-width circuits and competitive clustering quality in simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22540v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Chumpitaz-Flores, My Duong, Ying Mao, Kaixun Hua</dc:creator>
    </item>
    <item>
      <title>AcousTools: A 'Full-Stack', Python-Based, Acoustic Holography Library</title>
      <link>https://arxiv.org/abs/2511.07336</link>
      <description>arXiv:2511.07336v3 Announce Type: replace-cross 
Abstract: Acoustic Holography is an emerging field where mid-air ultrasound is controlled and manipulated for novel and exciting applications. These range from mid-air haptics, volumetric displays, contactless fabrication, and even chemical and biomedical applications such as drug delivery. To develop these applications, a software framework to predict acoustic behaviour and simulating resulting effects, such as applied forces or scattering patterns is desirable. There have been various software libraries and platforms that attempt to fill this role, but there is yet to be a single piece of software that acts as a 'full-stack' solution. We define this full-stack as the process from abstraction to physicalisation starting with setup, modelling acoustic propagation, transducer phase retrieval, sound field analysis, and control of the acoustic holographic hardware itself. Existing methods fail to fulfil one or more of these categories. To address this, we present AcousTools, a Python-based acoustic holography library, designed to support the full suite of acoustic holographic applications and we show AcousTools's ability to meet each step of the full-stack's requirements. AcousTools has the potential to become the standard code library for acoustic holography, with the uniquely complete suite of features wrapped in a language that is known to be easy to use, AcousTools will increase the ability for researchers to develop novel applications as well as accurately review other's work. The full-stack, aside from software, will also be useful for researchers - providing a way to view and compare methodologies by understanding where they fit into the stack.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07336v3</guid>
      <category>cs.SD</category>
      <category>cs.ET</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Mukherjee, Giorgos Christopoulos, Zhouyang Shen, Sriram Subramanian, Ryuji Hirayama</dc:creator>
    </item>
  </channel>
</rss>
