<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Dec 2024 05:01:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An overview of meta-analytic methods for economic research</title>
      <link>https://arxiv.org/abs/2412.10608</link>
      <description>arXiv:2412.10608v1 Announce Type: new 
Abstract: Meta-analysis is the use of statistical methods to combine the results of individual studies to estimate the overall effect size for a specific outcome of interest. The direction and magnitude of this estimated effect, along with its confidence interval, provide insights into the phenomenon or relationship being investigated. As an extension of the standard meta-analysis, meta-regression analysis incorporates multiple moderators representing identifiable study characteristics into the meta-analysis model, thereby explaining some of the heterogeneity in true effect sizes across studies. This form of meta-analysis is especially designed to quantitatively synthesize empirical evidence in economics. This study provides an overview of the meta-analytic procedures tailored for economic research. By addressing key challenges, including between-study heterogeneity, publication bias, and effect size dependence, it aims to equip researchers with the tools and insights needed to conduct rigorous and informative meta-analytic studies in economics and related disciplines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10608v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amin Haghnejad, Mahboobeh Farahati</dc:creator>
    </item>
    <item>
      <title>Do LLMs Act as Repositories of Causal Knowledge?</title>
      <link>https://arxiv.org/abs/2412.10635</link>
      <description>arXiv:2412.10635v1 Announce Type: new 
Abstract: Large language models (LLMs) offer the potential to automate a large number of tasks that previously have not been possible to automate, including some in science. There is considerable interest in whether LLMs can automate the process of causal inference by providing the information about causal links necessary to build a structural model. We use the case of confounding in the Coronary Drug Project (CDP), for which there are several studies listing expert-selected confounders that can serve as a ground truth. LLMs exhibit mediocre performance in identifying confounders in this setting, even though text about the ground truth is in their training data. Variables that experts identify as confounders are only slightly more likely to be labeled as confounders by LLMs compared to variables that experts consider non-confounders. Further, LLM judgment on confounder status is highly inconsistent across models, prompts, and irrelevant concerns like multiple-choice option ordering. LLMs do not yet have the ability to automate the reporting of causal links.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10635v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nick Huntington-Klein, Eleanor J. Murray</dc:creator>
    </item>
    <item>
      <title>Forecasting realized covariances using HAR-type models</title>
      <link>https://arxiv.org/abs/2412.10791</link>
      <description>arXiv:2412.10791v1 Announce Type: new 
Abstract: We investigate methods for forecasting multivariate realized covariances matrices applied to a set of 30 assets that were included in the DJ30 index at some point, including two novel methods that use existing (univariate) log of realized variance models that account for attenuation bias and time-varying parameters. We consider the implications of some modeling choices within the class of heterogeneous autoregressive models. The following are our key findings. First, modeling the logs of the marginal volatilities is strongly preferred over direct modeling of marginal volatility. Thus, our proposed model that accounts for attenuation bias (for the log-response) provides superior one-step-ahead forecasts over existing multivariate realized covariance approaches. Second, accounting for measurement errors in marginal realized variances generally improves multivariate forecasting performance, but to a lesser degree than previously found in the literature. Third, time-varying parameter models based on state-space models perform almost equally well. Fourth, statistical and economic criteria for comparing the forecasting performance lead to some differences in the models' rankings, which can partially be explained by the turbulent post-pandemic data in our out-of-sample validation dataset using sub-sample analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10791v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matias Quiroz, Laleh Tafakori, Hans Manner</dc:creator>
    </item>
    <item>
      <title>Treatment Evaluation at the Intensive and Extensive Margins</title>
      <link>https://arxiv.org/abs/2412.11179</link>
      <description>arXiv:2412.11179v1 Announce Type: new 
Abstract: This paper provides a solution to the evaluation of treatment effects in selective samples when neither instruments nor parametric assumptions are available. We provide sharp bounds for average treatment effects under a conditional monotonicity assumption for all principal strata, i.e. units characterizing the complete intensive and extensive margins. Most importantly, we allow for a large share of units whose selection is indifferent to treatment, e.g. due to non-compliance. The existence of such a population is crucially tied to the regularity of sharp population bounds and thus conventional asymptotic inference for methods such as Lee bounds can be misleading. It can be solved using smoothed outer identification regions for inference. We provide semiparametrically efficient debiased machine learning estimators for both regular and smooth bounds that can accommodate high-dimensional covariates and flexible functional forms. Our study of active labor market policy reveals the empirical prevalence of the aforementioned indifference population and supports results from previous impact analysis under much weaker assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11179v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Phillip Heiler, Asbj{\o}rn Kaufmann, Bezirgen Veliyev</dc:creator>
    </item>
    <item>
      <title>VAR models with an index structure: A survey with new results</title>
      <link>https://arxiv.org/abs/2412.11278</link>
      <description>arXiv:2412.11278v1 Announce Type: new 
Abstract: The main aim of this paper is to review recent advances in the multivariate autoregressive index model [MAI], originally proposed by &lt;cite&gt;reinsel1983some&lt;/cite&gt;, and their applications to economic and financial time series. MAI has recently gained momentum because it can be seen as a link between two popular but distinct multivariate time series approaches: vector autoregressive modeling [VAR] and the dynamic factor model [DFM]. Indeed, on the one hand, the MAI is a VAR model with a peculiar reduced-rank structure; on the other hand, it allows for identification of common components and common shocks in a similar way as the DFM. The focus is on recent developments of the MAI, which include extending the original model with individual autoregressive structures, stochastic volatility, time-varying parameters, high-dimensionality, and cointegration. In addition, new insights on previous contributions and a novel model are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11278v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gianluca Cubadda</dc:creator>
    </item>
    <item>
      <title>Moderating the Mediation Bootstrap for Causal Inference</title>
      <link>https://arxiv.org/abs/2412.11285</link>
      <description>arXiv:2412.11285v1 Announce Type: new 
Abstract: Mediation analysis is a form of causal inference that investigates indirect effects and causal mechanisms. Confidence intervals for indirect effects play a central role in conducting inference. The problem is non-standard leading to coverage rates that deviate considerably from their nominal level. The default inference method in the mediation model is the paired bootstrap, which resamples directly from the observed data. However, a residual bootstrap that explicitly exploits the assumed causal structure (X-&gt;M-&gt;Y) could also be applied. There is also a debate whether the bias-corrected (BC) bootstrap method is superior to the percentile method, with the former showing liberal behavior (actual coverage too low) in certain circumstances. Moreover, bootstrap methods tend to be very conservative (coverage higher than required) when mediation effects are small. Finally, iterated bootstrap methods like the double bootstrap have not been considered due to their high computational demands. We investigate the issues mentioned in the simple mediation model by a large-scale simulation. Results are explained using graphical methods and the newly derived finite-sample distribution. The main findings are: (i) conservative behavior of the bootstrap is caused by extreme dependence of the bootstrap distribution's shape on the estimated coefficients (ii) this dependence leads to counterproductive correction of the the double bootstrap. The added randomness of the BC method inflates the coverage in the absence of mediation, but still leads to (invalid) liberal inference when the mediation effect is small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11285v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kees Jan van Garderen, Noud van Giersbergen</dc:creator>
    </item>
    <item>
      <title>An Identification and Dimensionality Robust Test for Instrumental Variables Models</title>
      <link>https://arxiv.org/abs/2311.14892</link>
      <description>arXiv:2311.14892v2 Announce Type: replace 
Abstract: Using modifications of Lindeberg's interpolation technique, I propose a new identification-robust test for the structural parameter in a heteroskedastic instrumental variables model. While my analysis allows the number of instruments to be much larger than the sample size, it does not require many instruments, making my test applicable in settings that have not been well studied. Instead, the proposed test statistic has a limiting chi-squared distribution so long as an auxiliary parameter can be consistently estimated. This is possible using machine learning methods even when the number of instruments is much larger than the sample size. To improve power, a simple combination with the sup-score statistic of Belloni et al. (2012) is proposed. I point out that first-stage F-statistics calculated on LASSO selected variables may be misleading indicators of identification strength and demonstrate favorable performance of my proposed methods in both empirical data and simulation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14892v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manu Navjeevan</dc:creator>
    </item>
    <item>
      <title>Estimating Causal Effects of Discrete and Continuous Treatments with Binary Instruments</title>
      <link>https://arxiv.org/abs/2403.05850</link>
      <description>arXiv:2403.05850v2 Announce Type: replace 
Abstract: We propose an instrumental variable framework for identifying and estimating causal effects of discrete and continuous treatments with binary instruments. The basis of our approach is a local copula representation of the joint distribution of the potential outcomes and unobservables determining treatment assignment. This representation allows us to introduce an identifying assumption, so-called copula invariance, that restricts the local dependence of the copula with respect to the treatment propensity. We show that copula invariance identifies treatment effects for the entire population and other subpopulations such as the treated. The identification results are constructive and lead to practical estimation and inference procedures based on distribution regression. An application to estimating the effect of sleep on well-being uncovers interesting patterns of heterogeneity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05850v2</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Chernozhukov, Iv\'an Fern\'andez-Val, Sukjin Han, Kaspar W\"uthrich</dc:creator>
    </item>
    <item>
      <title>Nonparametric Causal Decomposition of Group Disparities</title>
      <link>https://arxiv.org/abs/2306.16591</link>
      <description>arXiv:2306.16591v4 Announce Type: replace-cross 
Abstract: We introduce a new nonparametric causal decomposition approach that identifies the mechanisms by which a treatment variable contributes to a group-based outcome disparity. Our approach distinguishes three mechanisms: group differences in 1) treatment prevalence, 2) average treatment effects, and 3) selection into treatment based on individual-level treatment effects. Our approach reformulates classic Kitagawa-Blinder-Oaxaca decompositions in causal and nonparametric terms, complements causal mediation analysis by explaining group disparities instead of group effects, and isolates conceptually distinct mechanisms conflated in recent random equalization decompositions. In contrast to all prior approaches, our framework uniquely identifies differential selection into treatment as a novel disparity-generating mechanism. Our approach can be used for both the retrospective causal explanation of disparities and the prospective planning of interventions to change disparities. We present both an unconditional and a conditional decomposition, where the latter quantifies the contributions of the treatment within levels of certain covariates. We develop nonparametric estimators that are $\sqrt{n}$-consistent, asymptotically normal, semiparametrically efficient, and multiply robust. We apply our approach to analyze the mechanisms by which college graduation causally contributes to intergenerational income persistence (the disparity in adult income between the children of high- vs low-income parents). Empirically, we demonstrate a previously undiscovered role played by the new selection component in intergenerational income persistence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16591v4</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ang Yu, Felix Elwert</dc:creator>
    </item>
    <item>
      <title>Policy Learning for Optimal Dynamic Treatment Regimes with Observational Data</title>
      <link>https://arxiv.org/abs/2404.00221</link>
      <description>arXiv:2404.00221v5 Announce Type: replace-cross 
Abstract: Public policies and medical interventions often involve dynamics in their treatment assignments, where individuals receive a series of interventions over multiple stages. We study the statistical learning of optimal dynamic treatment regimes (DTRs) that guide the optimal treatment assignment for each individual at each stage based on the individual's evolving history. We propose a doubly robust, classification-based approach to learning the optimal DTR using observational data under the assumption of sequential ignorability. This approach learns the optimal DTR through backward induction. At each step, it constructs an augmented inverse probability weighting (AIPW) estimator of the policy value function and maximizes it to learn the optimal policy for the corresponding stage. We show that the resulting DTR can achieve an optimal convergence rate of $n^{-1/2}$ for welfare regret under mild convergence conditions on estimators of the nuisance components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00221v5</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shosei Sakaguchi</dc:creator>
    </item>
  </channel>
</rss>
