<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PF</link>
    <description>cs.PF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Sep 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Noise Injection for__Performance Bottleneck Analysis</title>
      <link>https://arxiv.org/abs/2509.08446</link>
      <description>arXiv:2509.08446v1 Announce Type: new 
Abstract: Bottleneck evaluation plays a crucial part in performance tuning of HPC applications, as it directly influences the search for optimizations and the selection of the best hardware for a given code. In this paper, we introduce a new model-agnostic, instruction-accurate framework for bottleneck analysis based on performance noise injection. This method provides a precise analysis that complements existing techniques, particularly in quantifying unused resource slack. Specifically, we classify programs based on whether they are limited by computation, data access bandwidth, or latency by injecting additional noise instructions that target specific bottleneck sources. Our approach is built on the LLVM compiler toolchain, ensuring easy portability across different architectures and microarchitectures which constitutes an improvement over many state-of-the-art tools. We validate our framework on a range of hardware benchmarks and kernels, including a detailedstudy of a sparse-matrix--vector product (SPMXV) kernel, where we successfully detect distinct performance regimes. These insights further inform hardware selection, as demonstrated by our comparative evaluation between HBM and DDR memory systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08446v1</guid>
      <category>cs.PF</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>31st European Conference on Parallel and Distributed Processing, Aug 2025, Dresden, Germany. pp.3-23</arxiv:journal_reference>
      <dc:creator>Aur\'elien Delval (LI-PaRAD, UVSQ), Pablo de Oliveira Castro (LI-PaRAD, UVSQ), William Jalby (LI-PaRAD, UVSQ), Etienne Renault</dc:creator>
    </item>
    <item>
      <title>Memshare: Memory Sharing for Multicore Computation in R with an Application to Feature Selection by Mutual Information using PDE</title>
      <link>https://arxiv.org/abs/2509.08632</link>
      <description>arXiv:2509.08632v1 Announce Type: new 
Abstract: We present memshare\footnote{The Software package is published as a CRAN package under https://CRAN.R-project.org/package=memshare, a package that enables shared memory multicore computation in R by allocating buffers in C++ shared memory and exposing them to R through ALTREP views. We compare memshare to SharedObject (Bioconductor) discuss semantics and safety, and report a 2x speedup over SharedObject with no additional resident memory in a column wise apply benchmark. Finally, we illustrate a downstream analytics use case: feature selection by mutual information in which densities are estimated per feature via Pareto Density Estimation (PDE). The analytical use-case is an RNA seq dataset consisting of N=10,446 cases and d=19,637 gene expressions requiring roughly n_threads * 10GB of memory in the case of using parallel R sessions. Such and larger use-cases are common in big data analytics and make R feel limiting sometimes which is mitigated by the addition of the library presented in this work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08632v1</guid>
      <category>cs.PF</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael C. Thrun, Julian M\"arte</dc:creator>
    </item>
    <item>
      <title>Aurora: Architecting Argonne's First Exascale Supercomputer for Accelerated Scientific Discovery</title>
      <link>https://arxiv.org/abs/2509.08207</link>
      <description>arXiv:2509.08207v1 Announce Type: cross 
Abstract: Aurora is Argonne National Laboratory's pioneering Exascale supercomputer, designed to accelerate scientific discovery with cutting-edge architectural innovations. Key new technologies include the Intel(TM) Xeon(TM) Data Center GPU Max Series (code-named Sapphire Rapids) with support for High Bandwidth Memory (HBM), alongside the Intel(TM) Data Center GPU Max Series (code-named Ponte Vecchio) on each compute node. Aurora also integrates the Distributed Asynchronous Object Storage (DAOS), a novel exascale storage solution, and leverages Intel's oneAPI programming environment. This paper presents an in-depth exploration of Aurora's node architecture, the HPE Slingshot interconnect, the supporting software ecosystem, and DAOS. We provide insights into standard benchmark performance and applications readiness efforts via Aurora's Early Science Program and the Exascale Computing Project.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08207v1</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <category>cs.CE</category>
      <category>cs.PF</category>
      <pubDate>Thu, 11 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin S. Allen, James Anchell, Victor Anisimov, Thomas Applencourt, Abhishek Bagusetty, Ramesh Balakrishnan, Riccardo Balin, Solomon Bekele, Colleen Bertoni, Cyrus Blackworth, Renzo Bustamante, Kevin Canada, John Carrier, Christopher Chan-nui, Lance C. Cheney, Taylor Childers, Paul Coffman, Susan Coghlan, Michael D'Mello, Murali Emani, Kyle G. Felker, Sam Foreman, Olivier Franza, Longfei Gao, Marta Garc\'ia, Mar\'ia Garzar\'an, Balazs Gerofi, Yasaman Ghadar, Neha Gupta, Kevin Harms, V\"ain\"o Hatanp\"a\"a, Brian Holland, Carissa Holohan, Brian Homerding, Khalid Hossain, Louise Huot, Huda Ibeid, Joseph A. Insley, Sai Jayanthi, Hong Jiang, Wei Jiang, Xiao-Yong Jin, Jeongnim Kim, Christopher Knight, Kalyan Kumaran, JaeHyuk Kwack, Ti Leggett, Ben Lenard, Chris Lewis, Nevin Liber, Johann Lombardi, Raymond M. Loy, Ye Luo, Bethany Lusch, Nilakantan Mahadevan, Victor A. Mateevitsi, Gordon McPheeters, Ryan Milner, Vitali A. Morozov, Servesh Muralidharan, Tom Musta, Mrigendra Nagar, Vikram Narayana, Marieme Ngom, Anthony-Trung Nguyen, Nathan Nichols, Aditya Nishtala, James C. Osborn, Michael E. Papka, Scott Parker, Saumil S. Patel, Adrian C. Pope, Sucheta Raghunanda, Esteban Rangel, Paul M. Rich, Silvio Rizzi, Kris Rowe, Varuni Sastry, Adam Scovel, Filippo Simini, Haritha Siddabathuni Som, Patrick Steinbrecher, Rick Stevens, Xinmin Tian, Peter Upton, Thomas Uram, Archit K. Vasan, \'Alvaro V\'azquez-Mayagoitia, Kaushik Velusamy, Brice Videau, Venkatram Vishwanath, Brian Whitney, Timothy J. Williams, Michael Woodacre, Sam Zeltner, Gengbin Zheng, Huihuo Zheng</dc:creator>
    </item>
  </channel>
</rss>
