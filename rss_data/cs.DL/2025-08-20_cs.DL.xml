<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Aug 2025 04:01:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Using Artificial Intuition in Distinct, Minimalist Classification of Scientific Abstracts for Management of Technology Portfolios</title>
      <link>https://arxiv.org/abs/2508.13182</link>
      <description>arXiv:2508.13182v1 Announce Type: new 
Abstract: Classification of scientific abstracts is useful for strategic activities but challenging to automate because the sparse text provides few contextual clues. Metadata associated with the scientific publication can be used to improve performance but still often requires a semi-supervised setting. Moreover, such schemes may generate labels that lack distinction -- namely, they overlap and thus do not uniquely define the abstract. In contrast, experts label and sort these texts with ease. Here we describe an application of a process we call artificial intuition to replicate the expert's approach, using a Large Language Model (LLM) to generate metadata. We use publicly available abstracts from the United States National Science Foundation to create a set of labels, and then we test this on a set of abstracts from the Chinese National Natural Science Foundation to examine funding trends. We demonstrate the feasibility of this method for research portfolio management, technology scouting, and other strategic activities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13182v1</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Prateek Ranka, Fred Morstatter, Andrea Belz, Alexandra Graddy-Reed</dc:creator>
    </item>
    <item>
      <title>The Role of AI in Facilitating Interdisciplinary Collaboration: Evidence from AlphaFold</title>
      <link>https://arxiv.org/abs/2508.13234</link>
      <description>arXiv:2508.13234v1 Announce Type: new 
Abstract: The acceleration of artificial intelligence (AI) in science is recognized and many scholars have begun to explore its role in interdisciplinary collaboration. However, the mechanisms and extent of this impact are still unclear. This study, using AlphaFold's impact on structural biologists, examines how AI technologies influence interdisciplinary collaborative patterns. By analyzing 1,247 AlphaFold-related papers and 7,700 authors from Scopus, we employ bibliometric analysis and causal inference to compare interdisciplinary collaboration between AlphaFold adopters and non-adopters. Contrary to the widespread belief that AI facilitates interdisciplinary collaboration, our findings show that AlphaFold increased structural biology-computer science collaborations by just 0.48%, with no measurable effect on other disciplines. Specifically, AI creates interdisciplinary collaboration demands with specific disciplines due to its technical characteristics, but this demand is weakened by technological democratization and other factors. These findings demonstrate that artificial intelligence (AI) alone has limited efficacy in bridging disciplinary divides or fostering meaningful interdisciplinary collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13234v1</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naixuan Zhao, Chunli Wei, Xinyan Zhang, Jiang Li</dc:creator>
    </item>
    <item>
      <title>FAIR sharing of Chromatin Tracing datasets using the newly developed 4DN FISH Omics Format</title>
      <link>https://arxiv.org/abs/2508.13255</link>
      <description>arXiv:2508.13255v1 Announce Type: cross 
Abstract: A key output of the NIH Common Fund 4D Nucleome (4DN) project is the open publication of datasets on the structure of the human cell nucleus and genome. In recent years, multiplexed Fluorescence In Situ Hybridization (FISH) and FISH-omics methods have rapidly expanded, enabling quantification of chromatin organization in single cells, sometimes alongside RNA and protein measurements. These approaches have deepened our understanding of how 3D chromosome architecture relates to transcriptional activity and cell development in health and disease. However, results from Chromatin Tracing FISH-omics experiments remain difficult to share, reuse, and analyze due to the absence of standardized data-exchange specifications. Building on the recent release of microscopy metadata standards, we introduce the 4DN FISH Omics Format-Chromatin Tracing (FOF-CT), a community-developed standard for processed results from diverse imaging techniques. Current studies generally use one of two representations: ball-and-stick, where genomic segments appear as individual fluorescence spots, or volumetric, representing them as clouds of single-molecule localizations. This manuscript focuses on ball-and-stick methods, including those from the pioneering study of Wang et al. (2016) and related techniques. We describe the FOF-CT structure and present newly deposited datasets in the 4DN Data Portal and the OME Image Data Resource (IDR), highlighting their potential for reuse, integration, and modeling. We also outline example analysis pipelines and illustrate biological insights enabled by standardized, FAIR-compliant Chromatin Tracing datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13255v1</guid>
      <category>q-bio.OT</category>
      <category>cs.DL</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rahi Navelkar, Andrea Cosolo, Bogdan Bintu, Yubao Cheng, Vincent Gardeux, Silvia Gutnik, Taihei Fujimori, Antonina Hafner, Atishay Jay, Bojing Blair Jia, Adam Paul Jussila, Gerard Llimos, Antonios Lioutas, Nuno MC Martins, William J Moore, Yodai Takei, Frances Wong, Kaifu Yang, Huaiying Zhang, Quan Zhu, Magda Bienko, Lacramioara Bintu, Long Cai, Bart Deplancke, Marcelo Nollmann, Susan E Mango, Bing Ren, Peter J Park, Ahilya N Sawh, Andrew Schroeder, Jason R Swedlow, Golnaz Vahedi, Chao-Ting Wu, Sarah Aufmkolk, Alistair N Boettiger, Irene Farabella, Caterina Strambio-De-Castillia, Siyuan Wang</dc:creator>
    </item>
  </channel>
</rss>
