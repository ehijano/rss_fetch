<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Mar 2025 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Leveraging MoE-based Large Language Model for Zero-Shot Multi-Task Semantic Communication</title>
      <link>https://arxiv.org/abs/2503.15722</link>
      <description>arXiv:2503.15722v1 Announce Type: new 
Abstract: Multi-task semantic communication (SC) can reduce the computational resources in wireless systems since retraining is not required when switching between tasks. However, existing approaches typically rely on task-specific embeddings to identify the intended task, necessitating retraining the entire model when given a new task. Consequently, this drives the need for a multi-task SC system that can handle new tasks without additional training, known as zero-shot learning. Inspired by the superior zero-shot capabilities of large language models (LLMs), we leverage pre-trained instruction-tuned LLMs, referred to as fine-tuned language net (FLAN), to improve the generalization capability. We incorporate a mixture-of-experts (MoE) architecture in the FLAN model and propose MoE-FLAN-SC architecture for multi-task SC systems. Our proposed MoE-FLAN-SC architecture can further improve the performance of FLAN-T5 model without increasing the computational cost. Moreover, we design a multi-task feature extraction module (FEM) which can adaptively extract relevant features across various tasks given the provided features and signal-to-noise ratio (SNR). Simulation results show that our proposed MoE-FLAN-SC architecture outperforms three state-of-the-art models in terms of the average accuracy on four different unseen tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15722v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sin-Yu Huang, Renjie Liao, Vincent W. S. Wong</dc:creator>
    </item>
    <item>
      <title>Enhancing Physical Layer Security in Cognitive Radio-Enabled NTNs with Beyond Diagonal RIS</title>
      <link>https://arxiv.org/abs/2503.15787</link>
      <description>arXiv:2503.15787v1 Announce Type: new 
Abstract: Beyond diagonal reconfigurable intelligent surfaces (BD-RIS) have emerged as a transformative technology for enhancing wireless communication by intelligently manipulating the propagation environment. This paper explores the potential of BD-RIS in improving cognitive radio enabled multilayer non-terrestrial networks (NTNs). It is assumed that a high-altitude platform station (HAPS) has set up the primary network, while an uncrewed aerial vehicle (UAV) establishes the secondary network in the HAPS footprint. We formulate a joint optimization problem to maximize the secrecy rate by optimizing BD-RIS phase shifts and the secondary transmitter power allocation while controlling the interference temperature from the secondary network to the primary network. To solve this problem efficiently, we decouple the original problem into two sub-problems, which are solved iteratively by relying on alternating optimization. Simulation results demonstrate the effectiveness of BD-RIS in cognitive radio-enabled multilayer NTNs to accommodate the secondary network while satisfying the constraints imposed from the primary network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15787v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wali Ullah Khan, Chandan Kumar Sheemar, Eva Lagunas, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>Age of Information in Multi-Relay Networks with Maximum Age Scheduling</title>
      <link>https://arxiv.org/abs/2503.16084</link>
      <description>arXiv:2503.16084v1 Announce Type: new 
Abstract: We propose and evaluate age of information (AoI)-aware multiple access mechanisms for the Internet of Things (IoT) in multi-relay two-hop networks. The network considered comprises end devices (EDs) communicating with a set of relays in ALOHA fashion, with new information packets to be potentially transmitted every time slot. The relays, in turn, forward the collected packets to an access point (AP), the final destination of the information generated by the EDs. More specifically, in this work we investigate the performance of four age-aware algorithms that prioritize older packets to be transmitted, namely max-age matching (MAM), iterative max-age scheduling (IMAS), age-based delayed request (ABDR), and buffered ABDR (B-ABDR). The former two algorithms are adapted into the multi-relay setup from previous research, and achieve satisfactory average AoI and average peak AoI performance, at the expense of a significant amount of information exchange between the relays and the AP. The latter two algorithms are newly proposed to let relays decide which one(s) will transmit in a given time slot, requiring less signaling than the former algorithms. We provide an analytical formulation for the AoI lower bound performance, compare the performance of all algorithms in this set-up, and show that they approach the lower bound. The latter holds especially true for B-ABDR, which approaches the lower bound the most closely, tilting the scale in its favor, as it also requires far less signaling than MAM and IMAS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16084v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Martins de Jesus, Felippe Moraes Pereira, Jo\~ao Luiz Rebelatto, Richard Demo Souza, Onel Alcaraz L\'opez</dc:creator>
    </item>
    <item>
      <title>Learning Linear Block Codes with Gradient Quantization</title>
      <link>https://arxiv.org/abs/2503.16169</link>
      <description>arXiv:2503.16169v1 Announce Type: new 
Abstract: This study investigates the problem of learning linear block codes optimized for Belief-Propagation decoders significantly improving performance compared to the state-of-the-art. Our previous research is extended with an enhanced system design that facilitates a more effective learning process for the parity check matrix. We simplify the input dataset, restrict the number of parameters to learn and improve the gradient back-propagation within the model. We also introduce novel optimizers specifically designed for discrete-valued weights. Based on conventional gradient computation, these optimizers provide discrete weights updates, enabling finer control and improving explainability of the learning process. Through these changes, we consistently achieve improved code performance, provided appropriately chosen hyper-parameters. To rigorously evaluate the performance of learned codes in the context of short to medium block lengths, we propose a comprehensive code performance assessment framework. This framework enables a fair comparison between our learning methodology and random search approaches, ensuring statistical significance in our results. The proposed model pave the way for a new approach to the efficient learning of linear block codes tailored to specific decoder structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16169v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Louis-Adrien Dufr\`ene, Quentin Lampin, Guillaume Larue</dc:creator>
    </item>
    <item>
      <title>Distributed Algorithm for Cooperative Joint Localization and Tracking Using Multiple-Input Multiple-Output Radars</title>
      <link>https://arxiv.org/abs/2503.16236</link>
      <description>arXiv:2503.16236v1 Announce Type: new 
Abstract: We propose a distributed joint localization and tracking algorithm using a message passing framework, for multiple-input multiple-output radars. We employ the mean field approach to derive an iterative algorithm. The obtained algorithm features a small communication overhead that scales linearly with the number of radars in the system. The proposed algorithm shows good estimation accuracy in two simulated scenarios even below 0 dB signal to noise ratio. In both cases the ground truth falls within the 95 % confidence interval of the estimated posterior for the majority of the track.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16236v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Astrid Holm Filtenborg Kitchen, Mikkel Sebastian Lundsgaard Br{\o}ndt, Marie Saugstrup Jensen, Troels Pedersen, Anders Malthe Westerkam</dc:creator>
    </item>
    <item>
      <title>On the Secrecy Performance of $\alpha$-$\mathcal{F}$ Channels with Pointing Errors</title>
      <link>https://arxiv.org/abs/2503.15618</link>
      <description>arXiv:2503.15618v1 Announce Type: cross 
Abstract: This paper investigates the physical layer security (PLS) performance of $\alpha$-$\mathcal{F}$ fading channels with pointing errors under passive and active eavesdropping scenarios. Novel analytical expressions are derived for key PLS metrics, including the probability of strictly positive secrecy capacity, the average secrecy capacity, and the secure outage probability. An asymptotic analysis is also investigated to provide further insights into the system behavior under high signal-to-noise ratio conditions. The analytical results are validated through Monte Carlo simulations, with several performance curves presented for a range of channel and system parameters. All expressions derived in this work are original and have not been previously published.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15618v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel M. C. Neves, Hugerles S. Silva, Higo T. P. Silva, Wamberto J. L. Queiroz, Felipe A. P. Figueiredo, Rausley A. A. de Souza</dc:creator>
    </item>
    <item>
      <title>A Speech Production Model for Radar: Connecting Speech Acoustics with Radar-Measured Vibrations</title>
      <link>https://arxiv.org/abs/2503.15627</link>
      <description>arXiv:2503.15627v1 Announce Type: cross 
Abstract: Millimeter Wave (mmWave) radar has emerged as a promising modality for speech sensing, offering advantages over traditional microphones. Prior works have demonstrated that radar captures motion signals related to vocal vibrations, but there is a gap in the understanding of the analytical connection between radar-measured vibrations and acoustic speech signals. We establish a mathematical framework linking radar-captured neck vibrations to speech acoustics. We derive an analytical relationship between neck surface displacements and speech. We use data from 66 human participants, and statistical spectral distance analysis to empirically assess the model. Our results show that the radar-measured signal aligns more closely with our model filtered vibration signal derived from speech than with raw speech itself. These findings provide a foundation for improved radar-based speech processing for applications in speech enhancement, coding, surveillance, and authentication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15627v1</guid>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isabella Lenz, Yu Rong, Daniel Bliss, Julie Liss, Visar Berisha</dc:creator>
    </item>
    <item>
      <title>Nonparametric Bellman Mappings for Value Iteration in Distributed Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2503.16192</link>
      <description>arXiv:2503.16192v1 Announce Type: cross 
Abstract: This paper introduces novel Bellman mappings (B-Maps) for value iteration (VI) in distributed reinforcement learning (DRL), where multiple agents operate over a network without a centralized fusion node. Each agent constructs its own nonparametric B-Map for VI while communicating only with direct neighbors to achieve consensus. These B-Maps operate on Q-functions represented in a reproducing kernel Hilbert space, enabling a nonparametric formulation that allows for flexible, agent-specific basis function design. Unlike existing DRL methods that restrict information exchange to Q-function estimates, the proposed framework also enables agents to share basis information in the form of covariance matrices, capturing additional structural details. A theoretical analysis establishes linear convergence rates for both Q-function and covariance-matrix estimates toward their consensus values. The optimal learning rates for consensus-based updates are dictated by the ratio of the smallest positive eigenvalue to the largest one of the network's Laplacian matrix. Furthermore, each nodal Q-function estimate is shown to lie very close to the fixed point of a centralized nonparametric B-Map, effectively allowing the proposed DRL design to approximate the performance of a centralized fusion center. Numerical experiments on two well-known control problems demonstrate the superior performance of the proposed nonparametric B-Maps compared to prior methods. Notably, the results reveal a counter-intuitive finding: although the proposed approach involves greater information exchange -- specifically through the sharing of covariance matrices -- it achieves the desired performance with lower cumulative communication cost than existing DRL schemes, highlighting the crucial role of basis information in accelerating the learning process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16192v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuki Akiyama, Konstantinos Slavakis</dc:creator>
    </item>
    <item>
      <title>Scalable Multiport Antenna Array Characterization with PCB-Realized Tunable Load Network Providing Additional "Virtual" VNA Ports</title>
      <link>https://arxiv.org/abs/2503.16256</link>
      <description>arXiv:2503.16256v1 Announce Type: cross 
Abstract: We prototype a PCB-realized tunable load network whose ports serve as additional "virtual" VNA ports in a "Virtual VNA" measurement setup. The latter enables the estimation of a many-port antenna array's scattering matrix with a few-port VNA, without any reconnections. We experimentally validate the approach for various eight-element antenna arrays in an anechoic chamber in the 700-900 MHz regime. We also improve the noise robustness of a step of the "Virtual VNA" post-processing algorithms by leveraging spectral correlations. Altogether, our PCB-realized VNA Extension Kit offers a scalable solution to characterize very large antenna arrays because of its low cost, small footprint, fully automated operation, and modular nature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16256v1</guid>
      <category>physics.app-ph</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean Tapie, Philipp del Hougne</dc:creator>
    </item>
    <item>
      <title>Dynamic Metasurface-Backed Luneburg Lens for Multiplexed Backscatter Communication</title>
      <link>https://arxiv.org/abs/2503.16366</link>
      <description>arXiv:2503.16366v1 Announce Type: cross 
Abstract: Backscatter communications is attractive for its low power requirements due to the lack of actively radiating components; however, commonly used devices are typically limited in range and functionality. Here, we design and demonstrate a flattened Luneburg lens combined with a spatially-tunable dynamic metasurface to create a low-power backscatter communicator. The Luneburg lens is a spherically-symmetric lens that focuses a collimated beam from any direction, enabling a wide field-of-view with no aberrations. By applying quasi-conformal transformation optics (QCTO), we design a flattened Luneburg lens to facilitate its seamless interface with the planar metasurface. The gradient index of the Luneburg lens is realized through additive manufacturing. We show that the flattened Luneburg lens with a reflective surface at the flattened focal plane is able to achieve diffraction-limited retroreflection, enabling long-range backscatter communication. When an interrogator transmits towards the metasurface-backed Luneburg lens, the device can modulate the reflected signal phase across a wide field of regard to communicate data. We experimentally show that the spatial control over the metasurface allows different bit streams to be simultaneously communicated in different directions. Additionally, we show that the device is able to prevent eavesdroppers from receiving information, thus securing communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16366v1</guid>
      <category>physics.optics</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Kim, Tim Sleasman, Avrami Rakovsky, Ra'id Awadallah, David B. Shrekenhamer</dc:creator>
    </item>
    <item>
      <title>SelfReplay: Adapting Self-Supervised Sensory Models via Adaptive Meta-Task Replay</title>
      <link>https://arxiv.org/abs/2404.15305</link>
      <description>arXiv:2404.15305v2 Announce Type: replace 
Abstract: Self-supervised learning has emerged as a method for utilizing massive unlabeled data for pre-training models, providing an effective feature extractor for various mobile sensing applications. However, when deployed to end-users, these models encounter significant domain shifts attributed to user diversity. We investigate the performance degradation that occurs when self-supervised models are fine-tuned in heterogeneous domains. To address the issue, we propose SelfReplay, a few-shot domain adaptation framework for personalizing self-supervised models. SelfReplay proposes self-supervised meta-learning for initial model pre-training, followed by a user-side model adaptation by replaying the self-supervision with user-specific data. This allows models to adjust their pre-trained representations to the user with only a few samples. Evaluation with four benchmarks demonstrates that SelfReplay outperforms existing baselines by an average F1-score of 8.8%p. Our on-device computational overhead analysis on a commodity off-the-shelf (COTS) smartphone shows that SelfReplay completes adaptation within an unobtrusive latency (in three minutes) with only a 9.54% memory consumption, demonstrating the computational efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15305v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Hyungjun Yoon, Jaehyun Kwak, Biniyam Aschalew Tolera, Gaole Dai, Mo Li, Taesik Gong, Kimin Lee, Sung-Ju Lee</dc:creator>
    </item>
    <item>
      <title>Activity Detection for Massive Random Access using Covariance-based Matching Pursuit</title>
      <link>https://arxiv.org/abs/2405.02741</link>
      <description>arXiv:2405.02741v3 Announce Type: replace 
Abstract: The Internet of Things paradigm heavily relies on a network of a massive number of machine-type devices (MTDs) that monitor various phenomena. Consequently, MTDs are randomly activated at different times whenever a change occurs. In general, fewer MTDs are simultaneously activated across the network, resembling targeted sampling in compressed sensing. Therefore, signal recovery in machine-type communications is addressed through joint user activity detection and channel estimation algorithms built using compressed sensing theory. However, most of these algorithms follow a two-stage procedure in which a channel is first estimated and later mapped to find active users. This approach is inefficient because the estimated channel information is subsequently discarded. To overcome this limitation, we introduce a novel covariance-learning matching pursuit (CL-MP) algorithm that bypasses explicit channel estimation. Instead, it focuses on estimating the indices of the active users greedily. Simulation results presented in terms of probability of miss detection, exact recovery rate, and computational complexity validate the proposed technique's superior performance and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02741v3</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leatile Marata, Esa Ollila, Hirley Alves</dc:creator>
    </item>
    <item>
      <title>NeuroLM: A Universal Multi-task Foundation Model for Bridging the Gap between Language and EEG Signals</title>
      <link>https://arxiv.org/abs/2409.00101</link>
      <description>arXiv:2409.00101v3 Announce Type: replace 
Abstract: Recent advancements for large-scale pre-training with neural signals such as electroencephalogram (EEG) have shown promising results, significantly boosting the development of brain-computer interfaces (BCIs) and healthcare. However, these pre-trained models often require full fine-tuning on each downstream task to achieve substantial improvements, limiting their versatility and usability, and leading to considerable resource wastage. To tackle these challenges, we propose NeuroLM, the first multi-task foundation model that leverages the capabilities of Large Language Models (LLMs) by regarding EEG signals as a foreign language, endowing the model with multi-task learning and inference capabilities. Our approach begins with learning a text-aligned neural tokenizer through vector-quantized temporal-frequency prediction, which encodes EEG signals into discrete neural tokens. These EEG tokens, generated by the frozen vector-quantized (VQ) encoder, are then fed into an LLM that learns causal EEG information via multi-channel autoregression. Consequently, NeuroLM can understand both EEG and language modalities. Finally, multi-task instruction tuning adapts NeuroLM to various downstream tasks. We are the first to demonstrate that, by specific incorporation with LLMs, NeuroLM unifies diverse EEG tasks within a single model through instruction tuning. The largest variant NeuroLM-XL has record-breaking 1.7B parameters for EEG signal processing, and is pre-trained on a large-scale corpus comprising approximately 25,000-hour EEG data. When evaluated on six diverse downstream datasets, NeuroLM showcases the huge potential of this multi-task learning paradigm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00101v3</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>The Thirteenth International Conference on Learning Representations, 2025</arxiv:journal_reference>
      <dc:creator>Wei-Bang Jiang, Yansen Wang, Bao-Liang Lu, Dongsheng Li</dc:creator>
    </item>
    <item>
      <title>Polarforming for Wireless Communications: Modeling and Performance Analysis</title>
      <link>https://arxiv.org/abs/2409.07771</link>
      <description>arXiv:2409.07771v2 Announce Type: replace 
Abstract: This paper presents, for the first time, the concept of polarforming for wireless communications. Polarforming refers to a novel technique that enables the polarization of an antenna to shape into a desired polarization state for aligning with the polarization of an electromagnetic (EM) wave. It can fully leverage polarization diversity to enhance the performance of wireless communication systems through polarization matching. To implement polarforming, we propose a new paradigm of phase shifter (PS)-based polarization-reconfigurable antennas (PRAs) that can form linear, circular, and general elliptical polarizations by phase shift control. To further demonstrate the benefits of polarforming, we investigate a PRA-aided wireless communication system equipped with tunable polarization of antennas. We characterize the multiple-input multiple-output (MIMO) channel capacity of the considered system as a function of the phase shifts of PS-based PRAs. We also provide a detailed polarforming interpretation under the single-input single-output (SISO) scenario and theoretically show how polarforming differs from the conventional (analog) beamforming based on PSs. Moreover, we develop an alternating optimization approach to maximize the channel capacity for the systems with single-antenna transmitter/receiver. Based on the water-filling principle, we also derive an upper bound on the MIMO channel capacity with PS-based PRAs and then maximize this capacity bound by optimizing the phase shifts through alternating optimization. Finally, comprehensive simulation results are presented, which not only validate the effectiveness of polarforming in combating channel depolarization but also exhibit substantial performance improvements over conventional systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07771v2</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zijian Zhou, Jingze Ding, Chenbo Wang, Bingli Jiao, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Physically Parameterized Differentiable MUSIC for DoA Estimation with Uncalibrated Arrays</title>
      <link>https://arxiv.org/abs/2411.15144</link>
      <description>arXiv:2411.15144v3 Announce Type: replace 
Abstract: Direction of arrival (DoA) estimation is a common sensing problem in radar, sonar, audio, and wireless communication systems. It has gained renewed importance with the advent of the integrated sensing and communication paradigm. To fully exploit the potential of such sensing systems, it is crucial to take into account potential hardware impairments that can negatively impact the obtained performance. This study introduces a joint DoA estimation and hardware impairment learning scheme following a model-based approach. Specifically, a differentiable version of the multiple signal classification (MUSIC) algorithm is derived, allowing efficient learning of the considered impairments. The proposed approach supports both supervised and unsupervised learning strategies, showcasing its practical potential. Simulation results indicate that the proposed method successfully learns significant inaccuracies in both antenna locations and complex gains. Additionally, the proposed method outperforms the classical MUSIC algorithm in the DoA estimation task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15144v3</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baptiste Chatelier (INSA Rennes, IETR, MERCE-France), Jos\'e Miguel Mateos-Ramos (MERCE-France), Vincent Corlay (MERCE-France), Christian H\"ager (INSA Rennes, IETR), Matthieu Crussi\`ere (INSA Rennes, IETR), Henk Wymeersch (INSA Rennes, IETR), Luc Le Magoarou (INSA Rennes, IETR)</dc:creator>
    </item>
    <item>
      <title>Antenna Position Optimization for Movable Antenna-Empowered Near-Field Sensing</title>
      <link>https://arxiv.org/abs/2502.03169</link>
      <description>arXiv:2502.03169v3 Announce Type: replace 
Abstract: Movable antennas (MAs) show great promise for enhancing the sensing capabilities of future sixth-generation (6G) networks. With the growing prevalence of near-field propagation at ultra-high frequencies, this paper focuses on the application of MAs for near-field sensing to jointly estimate the angle and distance information of a target. First, to gain essential insights into MA-enhanced near-field sensing, we investigate two simplified cases with only the spatial angle-of-arrival (AoA) or distance estimation, respectively, assuming that the other information is already known. We derive the worst-case Cramer-Rao bounds (CRBs) on the mean square errors (MSEs) of the AoA estimation and the distance estimation via the multiple signal classification (MUSIC) algorithm in these two cases. Then, we jointly optimize the positions of the MAs within a linear array to minimize these CRBs and derive their closed-form solutions, which yield an identical array geometry to MA-aided far-field sensing. Furthermore, we proceed to the more challenging case with the joint AoA and distance estimation and derive the worst-case CRB under the two-dimensional (2D) MUSIC algorithm. The corresponding CRB minimization problem is efficiently solved by adopting a discrete sampling-based approach. Numerical results demonstrate that the proposed MA-enhanced near-field sensing significantly outperforms conventional sensing with fixed-position antennas (FPAs). Moreover, the joint angle and distance estimation results in a different array geometry from that in the individual estimation of angle or distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03169v3</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yushen Wang, Weidong Mei, Xin Wei, Boyu Ning, Zhi Chen</dc:creator>
    </item>
    <item>
      <title>Artificial Intelligence-derived Vascular Age from Photoplethysmography: A Novel Digital Biomarker for Cardiovascular Health</title>
      <link>https://arxiv.org/abs/2502.12990</link>
      <description>arXiv:2502.12990v3 Announce Type: replace 
Abstract: With the increasing availability of wearable devices, photoplethysmography (PPG) has emerged as a promising non-invasive tool for monitoring human hemodynamics. We propose a deep learning framework to estimate vascular age (AI-vascular age) from PPG signals, incorporating a distribution-aware loss to address biases caused by imbalanced data. The model was developed using data from the UK Biobank (UKB), with 98,672 participants in the development cohort and 113,559 participants (144,683 data pairs) for clinical evaluation. After adjusting for key confounders, individuals with a vascular age gap (AI-vascular age minus calendar age) exceeding 9 years had a significantly higher risk of major adverse cardiovascular and cerebrovascular events (MACCE) (HR = 2.37, p &lt; 0.005) and secondary outcomes, including diabetes (HR = 2.69, p &lt; 0.005), hypertension (HR = 2.88, p &lt; 0.005), coronary heart disease (HR = 2.20, p &lt; 0.005), heart failure (HR = 2.15, p &lt; 0.005), myocardial infarction (HR = 2.51, p &lt; 0.005), stroke (HR = 2.55, p &lt; 0.005), and all-cause mortality (HR = 2.51, p &lt; 0.005). Conversely, participants with a vascular age gap below -9 years exhibited a significantly lower incidence of these outcomes. We further evaluated the longitudinal applicability of AI-vascular age using serial PPG data from the UKB, demonstrating its value in risk stratification by leveraging AI-vascular age at two distinct time points to predict future MACCE incidence. External validation was performed on a MIMIC-III-derived cohort (n = 2,343), where each one-year increase in vascular age gap was significantly associated with elevated in-hospital mortality risk (OR = 1.02, p &lt; 0.005). In conclusion, our study establishes AI-vascular age as a novel, non-invasive digital biomarker for cardiovascular health assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12990v3</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangkun Nie, Qinghao Zhao, Gongzheng Tang, Yaxin Li, Shenda Hong</dc:creator>
    </item>
    <item>
      <title>Self-supervised New Activity Detection in Sensor-based Smart Environments</title>
      <link>https://arxiv.org/abs/2401.10288</link>
      <description>arXiv:2401.10288v2 Announce Type: replace-cross 
Abstract: With the rapid advancement of ubiquitous computing technology, human activity analysis based on time series data from a diverse range of sensors enables the delivery of more intelligent services. Despite the importance of exploring new activities in real-world scenarios, existing human activity recognition studies generally rely on predefined known activities and often overlook detecting new patterns (novelties) that have not been previously observed during training. Novelty detection in human activities becomes even more challenging due to (1) diversity of patterns within the same known activity, (2) shared patterns between known and new activities, and (3) differences in sensor properties of each activity dataset. We introduce CLAN, a two-tower model that leverages Contrastive Learning with diverse data Augmentation for New activity detection in sensor-based environments. CLAN simultaneously and explicitly utilizes multiple types of strongly shifted data as negative samples in contrastive learning, effectively learning invariant representations that adapt to various pattern variations within the same activity. To enhance the ability to distinguish between known and new activities that share common features, CLAN incorporates both time and frequency domains, enabling the learning of multi-faceted discriminative representations. Additionally, we design an automatic selection mechanism of data augmentation methods tailored to each dataset's properties, generating appropriate positive and negative pairs for contrastive learning. Comprehensive experiments on real-world datasets show that CLAN achieves a 9.24% improvement in AUROC compared to the best-performing baseline model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10288v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyunju Kim, Dongman Lee</dc:creator>
    </item>
    <item>
      <title>Integrating Atmospheric Sensing and Communications for Resource Allocation in NTNs</title>
      <link>https://arxiv.org/abs/2407.06705</link>
      <description>arXiv:2407.06705v2 Announce Type: replace-cross 
Abstract: The integration of Non-Terrestrial Networks (NTNs) with Low Earth Orbit (LEO) satellite constellations into 5G and Beyond is essential to achieve truly global connectivity. A distinctive characteristic of LEO mega constellations is that they constitute a global infrastructure with predictable dynamics, which enables the pre-planned allocation of radio resources. However, the different bands that can be used for ground-to-satellite communication are affected differently by atmospheric conditions such as precipitation, which introduces uncertainty on the attenuation of the communication links at high frequencies. Based on this, we present a compelling case for applying integrated sensing and communications (ISAC) in heterogeneous and multi-layer LEO satellite constellations over wide areas. Specifically, we propose a sensing-assisted communications framework and frame structure that not only enables the accurate estimation of the atmospheric attenuation in the communication links through sensing but also leverages this information to determine the optimal serving satellites and allocate resources efficiently for downlink communication with users on the ground. The results show that, by dedicating an adequate amount of resources for sensing and solving the association and resource allocation problems jointly, it is feasible to increase the average throughput by 59% and the fairness by 700% when compared to solving these problems separately.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06705v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Israel Leyva-Mayorga, Fabio Saggese, Lintao Li, Petar Popovski</dc:creator>
    </item>
    <item>
      <title>Model-based learning for multi-antenna multi-frequency location-to-channel mapping</title>
      <link>https://arxiv.org/abs/2407.07719</link>
      <description>arXiv:2407.07719v3 Announce Type: replace-cross 
Abstract: Years of study of the propagation channel showed a close relation between a location and the associated communication channel response. The use of a neural network to learn the location-to-channel mapping can therefore be envisioned. The Implicit Neural Representation (INR) literature showed that classical neural architecture are biased towards learning low-frequency content, making the location-to-channel mapping learning a non-trivial problem. Indeed, it is well known that this mapping is a function rapidly varying with the location, on the order of the wavelength. This paper leverages the model-based machine learning paradigm to derive a problem-specific neural architecture from a propagation channel model. The resulting architecture efficiently overcomes the spectral-bias issue. It only learns low-frequency sparse correction terms activating a dictionary of high-frequency components. The proposed architecture is evaluated against classical INR architectures on realistic synthetic data, showing much better accuracy. Its mapping learning performance is explained based on the approximated channel model, highlighting the explainability of the model-based machine learning paradigm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07719v3</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baptiste Chatelier (IETR, MERCE-France, INSA Rennes), Vincent Corlay (MERCE-France), Matthieu Crussi\`ere (IETR, INSA Rennes), Luc Le Magoarou (IETR, INSA Rennes)</dc:creator>
    </item>
    <item>
      <title>Exponentially Consistent Nonparametric Linkage-Based Clustering of Data Sequences</title>
      <link>https://arxiv.org/abs/2411.13922</link>
      <description>arXiv:2411.13922v2 Announce Type: replace-cross 
Abstract: In this paper, we consider nonparametric clustering of $M$ independent and identically distributed (i.i.d.) data sequences generated from {\em unknown} distributions. The distributions of the $M$ data sequences belong to $K$ underlying distribution clusters. Existing results on exponentially consistent nonparametric clustering algorithms, like single linkage-based (SLINK) clustering and $k$-medoids distribution clustering, assume that the maximum intra-cluster distance ($d_L$) is smaller than the minimum inter-cluster distance ($d_H$). First, in the fixed sample size (FSS) setting, we show that exponential consistency can be achieved for SLINK clustering under a less strict assumption, $d_I &lt; d_H$, where $d_I$ is the maximum distance between any two sub-clusters of a cluster that partition the cluster. Note that $d_I &lt; d_L$ in general. Thus, our results show that SLINK is exponentially consistent for a larger class of problems than previously known. In our simulations, we also identify examples where $k$-medoids clustering is unable to find the true clusters, but SLINK is exponentially consistent. Then, we propose a sequential clustering algorithm, named SLINK-SEQ, based on SLINK and prove that it is also exponentially consistent. Simulation results show that the SLINK-SEQ algorithm requires fewer expected number of samples than the FSS SLINK algorithm for the same probability of error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13922v2</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bhupender Singh, Ananth Ram Rajagopalan, Srikrishna Bhashyam</dc:creator>
    </item>
    <item>
      <title>CLIMB: Data Foundations for Large Scale Multimodal Clinical Foundation Models</title>
      <link>https://arxiv.org/abs/2503.07667</link>
      <description>arXiv:2503.07667v2 Announce Type: replace-cross 
Abstract: Recent advances in clinical AI have enabled remarkable progress across many clinical domains. However, existing benchmarks and models are primarily limited to a small set of modalities and tasks, which hinders the development of large-scale multimodal methods that can make holistic assessments of patient health and well-being. To bridge this gap, we introduce Clinical Large-Scale Integrative Multimodal Benchmark (CLIMB), a comprehensive clinical benchmark unifying diverse clinical data across imaging, language, temporal, and graph modalities. CLIMB comprises 4.51 million patient samples totaling 19.01 terabytes distributed across 2D imaging, 3D video, time series, graphs, and multimodal data. Through extensive empirical evaluation, we demonstrate that multitask pretraining significantly improves performance on understudied domains, achieving up to 29% improvement in ultrasound and 23% in ECG analysis over single-task learning. Pretraining on CLIMB also effectively improves models' generalization capability to new tasks, and strong unimodal encoder performance translates well to multimodal performance when paired with task-appropriate fusion strategies. Our findings provide a foundation for new architecture designs and pretraining strategies to advance clinical AI research. Code is released at https://github.com/DDVD233/climb.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07667v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Wei Dai, Peilin Chen, Malinda Lu, Daniel Li, Haowen Wei, Hejie Cui, Paul Pu Liang</dc:creator>
    </item>
    <item>
      <title>SCAN-BEST: Efficient Sub-6GHz-Aided Near-field Beam Selection with Formal Reliability Guarantees</title>
      <link>https://arxiv.org/abs/2503.13801</link>
      <description>arXiv:2503.13801v2 Announce Type: replace-cross 
Abstract: As millimeter-wave (mmWave) multiple-input multiple-output (MIMO) systems continue to incorporate larger antenna arrays, the range of near-field propagation expands, making it more likely for users close to the transmitter to fall within the near-field regime. Traditional far-field beam training methods are no longer effective in this context. Additionally, near-field beam training presents challenges, since the training codebook must account for both angular and distance dimensions, leading to large codebook sizes. To reduce the in-band training overhead, we propose the Sub-6G Channel-Aided Near-field BEam SelecTion (SCAN-BEST) framework, which is motivated by the spatial-temporal congruence between sub-6 GHz (sub-6G) and mmWave channels. SCAN-BEST utilizes preprocessed sub-6G channel estimates as input, and employs a convolutional neural network (CNN) to predict the probability of each beam being optimal within the near-field beam training codebook. Given the prediction uncertainty arising from the variance between sub-6G and mmWave channels, we introduce a conformal risk control (CRC)-based module that generates a set of beam candidates for further limited in-band training, enabling the final beam selection to formally meet user-defined target coverage rate. Numerical results confirm the thereoretical properties of SCAN-BEST in terms of the achieved coverage rate of the beam candidates and various metrics. Moreover, SCAN-BEST enjoys good scalability and robustness to various sub-6G system configurations, including to the sizes of calibration datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13801v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weicao Deng, Binpu Shi, Min Li, Osvaldo Simeone</dc:creator>
    </item>
  </channel>
</rss>
