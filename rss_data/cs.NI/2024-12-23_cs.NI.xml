<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Dec 2024 03:43:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Joint Task Offloading and Routing in Wireless Multi-hop Networks Using Biased Backpressure Algorithm</title>
      <link>https://arxiv.org/abs/2412.15385</link>
      <description>arXiv:2412.15385v1 Announce Type: new 
Abstract: A significant challenge for computation offloading in wireless multi-hop networks is the complex interaction among traffic flows in the presence of interference. Existing approaches often ignore these key effects and/or rely on outdated queueing and channel state information. To fill these gaps, we reformulate joint offloading and routing as a routing problem on an extended graph with physical and virtual links. We adopt the state-of-the-art shortest path-biased Backpressure routing algorithm, which allows the destination and the route of a job to be dynamically adjusted at every time step based on network-wide long-term information and real-time states of local neighborhoods. In large networks, our approach achieves smaller makespan than existing approaches, such as separated Backpressure offloading and joint offloading and routing based on linear programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15385v1</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <category>eess.SP</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongyuan Zhao, Jake Perazzone, Gunjan Verma, Kevin Chan, Ananthram Swami, Santiago Segarra</dc:creator>
    </item>
    <item>
      <title>Traffic-Aware Cost-Optimized Fronthaul Planning for Ultra-Dense Networks</title>
      <link>https://arxiv.org/abs/2412.15478</link>
      <description>arXiv:2412.15478v1 Announce Type: new 
Abstract: The cost and limited capacity of fronthaul links pose significant challenges for the deployment of ultra-dense networks (UDNs), specifically for cell-free massive MIMO systems. Hence, cost-effective planning of reliable fronthaul networks is crucial for the future deployment of UDNs. We propose an optimization framework for traffic-aware hybrid fronthaul network planning, aimed at minimizing total costs through a mixed-integer linear program (MILP) that considers fiber optics and mmWave, along with optimizing key performance metrics. The results demonstrate superiority of the proposed approach, highlighting the cost-effectiveness and performance advantages when compared to different deployment schemes. Moreover, our results also reveal different trends that are critical for Service Providers (SPs) during the fronthaul planning phase of future-proof networks that can adapt to evolving traffic demands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15478v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LWC.2024.3515032</arxiv:DOI>
      <dc:creator>Anas S. Mohammed, Hussein A. Ammar, Krishnendu S. Tharakan, Hesham ElSawy, Hossam S. Hassanein</dc:creator>
    </item>
    <item>
      <title>Securing the Management Plane in Intent-based Cellular Networks</title>
      <link>https://arxiv.org/abs/2412.15946</link>
      <description>arXiv:2412.15946v1 Announce Type: new 
Abstract: IBN is an emerging network management paradigm that allows automated closed-loop control and management of network devices and services. Closed-loop control requires security primitives to avoid intrusive human impact on network policies, posing a serious security challenge. This paper addresses this critical problem by securing the management plane in IBN systems. We propose a novel security framework based on WireGuard that augments the existing standards to secure intent communication between intent stakeholders. The framework guarantees isolation through WireGuard tunnels and provides inherent authentication and access control mechanisms to avoid intrusion in IBN systems. This work contributes to developing secure, efficient, and flexible communication channels within the IBN ecosystem, ensuring the integrity and confidentiality of network intents and operational data. Experimental results show the suitability and superiority of WireGuard compared to OpenVPN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15946v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kashif Mehmood, Katina Kralevska, Danilo Gligoroski</dc:creator>
    </item>
    <item>
      <title>TinyLLM: A Framework for Training and Deploying Language Models at the Edge Computers</title>
      <link>https://arxiv.org/abs/2412.15304</link>
      <description>arXiv:2412.15304v1 Announce Type: cross 
Abstract: Language models have gained significant interest due to their general-purpose capabilities, which appear to emerge as models are scaled to increasingly larger parameter sizes. However, these large models impose stringent requirements on computing systems, necessitating significant memory and processing requirements for inference. This makes performing inference on mobile and edge devices challenging, often requiring invocating remotely-hosted models via network calls. Remote inference, in turn, introduces issues like latency, unreliable network connectivity, and privacy concerns. To address these challenges, we explored the possibility of deviating from the trend of increasing model size. Instead, we hypothesize that much smaller models (~30-120M parameters) can outperform their larger counterparts for specific tasks by carefully curating the data used for pre-training and fine-tuning. We investigate this within the context of deploying edge-device models to support sensing applications. We trained several foundational models through a systematic study and found that small models can run locally on edge devices, achieving high token rates and accuracy. Based on these findings, we developed a framework that allows users to train foundational models tailored to their specific applications and deploy them at the edge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15304v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Savitha Viswanadh Kandala, Pramuka Medaranga, Ambuj Varshney</dc:creator>
    </item>
    <item>
      <title>Coexistence Options and Performance Analysis of 100 Gbit/s Coherent PON in Brownfield DWDM Networks</title>
      <link>https://arxiv.org/abs/2412.15743</link>
      <description>arXiv:2412.15743v1 Announce Type: cross 
Abstract: We study system architectures for the coexistence of future coherent PON and DWDM networks. Considering deployed optical filters, we observe filtering penalties &lt; 1dB at a laser frequency accuracy &lt; 12GHz when using a cost-effective architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15743v1</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriele Di Rosa, Martin Kuipers, Jim Zou, Ognjen Jovanovic, J\"org-Peter Elbers</dc:creator>
    </item>
    <item>
      <title>APIRL: Deep Reinforcement Learning for REST API Fuzzing</title>
      <link>https://arxiv.org/abs/2412.15991</link>
      <description>arXiv:2412.15991v1 Announce Type: cross 
Abstract: REST APIs have become key components of web services. However, they often contain logic flaws resulting in server side errors or security vulnerabilities. HTTP requests are used as test cases to find and mitigate such issues. Existing methods to modify requests, including those using deep learning, suffer from limited performance and precision, relying on undirected search or making limited usage of the contextual information. In this paper we propose APIRL, a fully automated deep reinforcement learning tool for testing REST APIs. A key novelty of our approach is the use of feedback from a transformer module pre-trained on JSON-structured data, akin to that used in API responses. This allows APIRL to learn the subtleties relating to test outcomes, and generalise to unseen API endpoints. We show APIRL can find significantly more bugs than the state-of-the-art in real world REST APIs while minimising the number of required test cases. We also study how reward functions, and other key design choices, affect learnt policies in a thorough ablation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15991v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Myles Foley, Sergio Maffeis</dc:creator>
    </item>
    <item>
      <title>VaulTor: Putting the TEE in Tor</title>
      <link>https://arxiv.org/abs/2412.16064</link>
      <description>arXiv:2412.16064v1 Announce Type: cross 
Abstract: Online services that desire to operate anonymously routinely host themselves as 'Hidden Services' in the Tor network. However, these services are frequently threatened by deanonymization attacks, whereby their IP address and location may be inferred by the authorities. We present VaulTor, a novel architecture for the Tor network to ensure an extra layer of security for the Hidden Services against deanonymization attacks. In this new architecture, a volunteer (vault) is incentivized to host the web application content on behalf of the Hidden Service. The vault runs the hosted application in a Trusted Execution Environment (TEE) and becomes the point of contact for interested clients. This setup can substantially reduce the uptime requirement of the original Hidden Service provider and hence significantly decrease the chance of deanonymization attacks against them. We also show that the VaulTor architecture does not cause any noticeable performance degradation in accessing the hosted content (the performance degradation ranges from 2.6-5.5%).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16064v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Humza Ikram, Rumaisa Habib, Muaz Ali, Zartash Afzal Uzmi</dc:creator>
    </item>
    <item>
      <title>Stochastic Analysis of Entanglement-assisted Quantum Communication Channels</title>
      <link>https://arxiv.org/abs/2412.16157</link>
      <description>arXiv:2412.16157v1 Announce Type: cross 
Abstract: In this paper, we present a queueing model for quantum communication networks, a rapidly growing field of research inspired by its technological promise and recent experimental successes. The model consists of a primary queue and a service queue where Bell pairs are formed and stored. The Bell pairs are by nature extremely short-lived rendering the service queue (the quantum queue) much faster than the primary queue. We study the asymptotic behaviour of this multi-scale queueing system utilizing the theory of stochastic averaging principle. We prove a Functional Law of Large Numbers (FLLN) and a Functional Central Limit Theorem (FCLT) for the standard queue averaging the dynamics of the fast service queue. Our proofs are probablistic and rely on the stochastic analysis of Stochastic Differential Equations (SDEs) driven by Poisson Random Measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16157v1</guid>
      <category>math.PR</category>
      <category>cs.NI</category>
      <category>quant-ph</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karim S. Elsayed, Olga Izyumtseva, Wasiur R. KhudaBukhsh, Amr Rizk</dc:creator>
    </item>
    <item>
      <title>Quantum-Assisted Online Task Offloading and Resource Allocation in MEC-Enabled Satellite-Aerial-Terrestrial Integrated Networks</title>
      <link>https://arxiv.org/abs/2312.15808</link>
      <description>arXiv:2312.15808v2 Announce Type: replace 
Abstract: In the era of Internet of Things (IoT), multi-access edge computing (MEC)-enabled satellite-aerial-terrestrial integrated network (SATIN) has emerged as a promising technology to provide massive IoT devices with seamless and reliable communication and computation services. This paper investigates the cooperation of low Earth orbit (LEO) satellites, high altitude platforms (HAPs), and terrestrial base stations (BSs) to provide relaying and computation services for vastly distributed IoT devices. Considering the uncertainty in dynamic SATIN systems, we formulate a stochastic optimization problem to minimize the time-average expected service delay by jointly optimizing resource allocation and task offloading while satisfying the energy constraints. To solve the formulated problem, we first develop a Lyapunov-based online control algorithm to decompose it into multiple one-slot problems. Since each one-slot problem is a large-scale mixed-integer nonlinear program (MINLP) that is intractable for classical computers, we further propose novel hybrid quantum-classical generalized Benders' decomposition (HQCGBD) algorithms to solve the problem efficiently by leveraging quantum advantages in parallel computing. Numerical results validate the effectiveness of the proposed MEC-enabled SATIN schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15808v2</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Zhang, Yanmin Gong, Lei Fan, Yu Wang, Zhu Han, Yuanxiong Guo</dc:creator>
    </item>
    <item>
      <title>LoLaFL: Low-Latency Federated Learning via Forward-only Propagation</title>
      <link>https://arxiv.org/abs/2412.14668</link>
      <description>arXiv:2412.14668v2 Announce Type: replace-cross 
Abstract: Federated learning (FL) has emerged as a widely adopted paradigm for enabling edge learning with distributed data while ensuring data privacy. However, the traditional FL with deep neural networks trained via backpropagation can hardly meet the low-latency learning requirements in the sixth generation (6G) mobile networks. This challenge mainly arises from the high-dimensional model parameters to be transmitted and the numerous rounds of communication required for convergence due to the inherent randomness of the training process. To address this issue, we adopt the state-of-the-art principle of maximal coding rate reduction to learn linear discriminative features and extend the resultant white-box neural network into FL, yielding the novel framework of Low-Latency Federated Learning (LoLaFL) via forward-only propagation. LoLaFL enables layer-wise transmissions and aggregation with significantly fewer communication rounds, thereby considerably reducing latency. Additionally, we propose two \emph{nonlinear} aggregation schemes for LoLaFL. The first scheme is based on the proof that the optimal NN parameter aggregation in LoLaFL should be harmonic-mean-like. The second scheme further exploits the low-rank structures of the features and transmits the low-rank-approximated covariance matrices of features to achieve additional latency reduction. Theoretic analysis and experiments are conducted to evaluate the performance of LoLaFL. In comparison with traditional FL, the two nonlinear aggregation schemes for LoLaFL can achieve reductions in latency of over 91\% and 98\%, respectively, while maintaining comparable accuracies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14668v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Mon, 23 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jierui Zhang, Jianhao Huang, Kaibin Huang</dc:creator>
    </item>
  </channel>
</rss>
