<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 31 Dec 2024 03:19:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Solving Crystal Structures by Carrying Out the Calculation of the Single-Atom R1 Method in a Lottery Mode</title>
      <link>https://arxiv.org/abs/2412.18625</link>
      <description>arXiv:2412.18625v1 Announce Type: cross 
Abstract: As originally designed [Zhang &amp; Donahue (2024), Acta Cryst. A80, 2370248.], after one cycle of calculation, the single-atom R1 (sR1) method required a user to intelligently determine a partial structure to start the next cycle. In this paper, a lottery scheme has been designed to randomly split a parent model into two child models. This allows the calculation to be carried out in care-free manner. By chance, one child model may have higher amounts of "good" atoms than the parent model. Thus, its expansion in the next cycle favors an improved model. These "lucky" results are carried onto the next cycles. while "unlucky" results in which no improvements occur are discarded. Furthermore, unchanged models are carried onto the next cycles in those "unlucky" occasions. On average a child model has the same fraction of "good" atoms as the parent. Only a substantial statistical fluctuation results in appreciable deviation. This lottery scheme works because such fluctuations do happen. Indeed, test applications with the computing power accessibly by the author have demonstrated that the designed scheme can drive an sR1 calculation to or close to reaching a correct structure solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18625v1</guid>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaodong Zhang</dc:creator>
    </item>
    <item>
      <title>Evaluating authorship disambiguation quality through anomaly analysis on researchers' career transition</title>
      <link>https://arxiv.org/abs/2412.18757</link>
      <description>arXiv:2412.18757v1 Announce Type: cross 
Abstract: Authorship disambiguation is crucial for advancing studies in science of science. However, assessing the quality of authorship disambiguation in large-scale databases remains challenging since it is difficult to manually curate a gold-standard dataset that contains disambiguated authors. Through estimating the timing of when 5.8 million biomedical researchers became independent Principal Investigators (PIs) with authorship metadata extracted from the OpenAlex -- the largest open-source bibliometric database -- we unexpectedly discovered an anomaly: over 60% of researchers appeared as the last authors in their first career year. We hypothesized that this improbable finding results from poor name disambiguation, suggesting that such an anomaly may serve as an indicator of low-quality authorship disambiguation. Our findings indicated that authors who lack affiliation information, which makes it more difficult to disambiguate, were far more likely to exhibit this anomaly compared to those who included their affiliation information. In contrast, authors with Open Researcher and Contributor ID (ORCID) -- expected to have higher quality disambiguation -- showed significantly lower anomaly rates. We further applied this approach to examine the authorship disambiguation quality by gender over time, and we found that the quality of disambiguation for female authors was lower than that for male authors before 2010, suggesting that gender disparity findings based on pre-2010 data may require careful reexamination. Our results provide a framework for systematically evaluating authorship disambiguation quality in various contexts, facilitating future improvements in efforts to authorship disambiguation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18757v1</guid>
      <category>cs.DL</category>
      <category>cs.CE</category>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huaxia Zhou, Mengyi Sun</dc:creator>
    </item>
    <item>
      <title>Readout of strongly coupled NV center-pair spin states with deep neural networks</title>
      <link>https://arxiv.org/abs/2412.19581</link>
      <description>arXiv:2412.19581v1 Announce Type: cross 
Abstract: Optically addressable electron spin clusters are of interest for quantum computation, simulation and sensing. However, with interaction length scales of a few tens of nanometers in the strong coupling regime, they are unresolved in conventional confocal microscopy, making individual readout problematic. Here we show that when using a single shot readout technique, collective states of the combined register space become accessible. By using spin to charge conversion of the defects we draw the connection between the intricate photon count statistics with spin state tomography using deep neural networks. This approach is particularly versatile with further scaling the number of constituent spins in a cluster due to complexity of the analytical treatment. We perform a proof of concept measurement of the correlated classical signal, paving the way for using our technique in realistic applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19581v1</guid>
      <category>quant-ph</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Joliffe, Vadim Vorobyov, J\"org Wrachtrup</dc:creator>
    </item>
    <item>
      <title>Automated Review Generation Method Based on Large Language Models</title>
      <link>https://arxiv.org/abs/2407.20906</link>
      <description>arXiv:2407.20906v3 Announce Type: replace-cross 
Abstract: Literature research, vital for scientific work, faces the challenge of surging information volumes exceeding researchers' processing capabilities. We present an automated review generation method based on large language models (LLMs) to overcome efficiency bottlenecks and reduce cognitive load. Our statistically validated evaluation framework demonstrates that the generated reviews match or exceed manual quality, offering broad applicability across research fields without requiring users' domain knowledge. Applied to propane dehydrogenation (PDH) catalysts, our method swiftly analyzed 343 articles, averaging seconds per article per LLM account, producing comprehensive reviews spanning 35 topics, with extended analysis of 1041 articles providing insights into catalysts' properties. Through multi-layered quality control, we effectively mitigated LLMs' hallucinations, with expert verification confirming accuracy and citation integrity while demonstrating hallucination risks reduced to below 0.5\% with 95\% confidence. Released Windows application enables one-click review generation, enhancing research productivity and literature recommendation efficiency while setting the stage for broader scientific explorations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20906v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shican Wu, Xiao Ma, Dehui Luo, Lulu Li, Xiangcheng Shi, Xin Chang, Xiaoyun Lin, Ran Luo, Chunlei Pei, Changyin Du, Zhi-Jian Zhao, Jinlong Gong</dc:creator>
    </item>
    <item>
      <title>Gaussian Process Phase Interpolation for estimating the asymptotic phase of a limit cycle oscillator from time series data</title>
      <link>https://arxiv.org/abs/2409.03290</link>
      <description>arXiv:2409.03290v2 Announce Type: replace-cross 
Abstract: Rhythmic activity commonly observed in biological systems, occurring from the cellular level to the organismic level, is typically modeled as limit cycle oscillators. Phase reduction theory serves as a useful analytical framework for elucidating the synchronization mechanism of these oscillators. Essentially, this theory describes the dynamics of a multi-dimensional nonlinear oscillator using a single variable called asymptotic phase. In order to understand and control the rhythmic phenomena in the real world, it is crucial to estimate the asymptotic phase from the observed data. In this study, we propose a new method, Gaussian Process Phase Interpolation (GPPI), for estimating the asymptotic phase from time series data. The GPPI method first evaluates the asymptotic phase on the limit cycle and subsequently estimates the asymptotic phase outside the limit cycle employing Gaussian process regression. Thanks to the high expressive power of Gaussian processes, the GPPI is capable of capturing a variety of functions. Furthermore, it is easily applicable even when the dimension of the system increases. The performance of the GPPI is tested by using simulation data from the Stuart-Landau oscillator and the Hodgkin-Huxley oscillator. The results demonstrate that the GPPI can accurately estimate the asymptotic phase even in the presence of high observation noise and strong nonlinearity. Additionally, the GPPI is demonstrated as an effective tool for data-driven phase control of a Hodgkin-Huxley oscillator. Thus, the proposed GPPI will facilitate the data-driven modeling of the limit cycle oscillators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03290v2</guid>
      <category>nlin.AO</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.chaos.2024.115913</arxiv:DOI>
      <dc:creator>Taichi Yamamoto, Hiroya Nakao, Ryota Kobayashi</dc:creator>
    </item>
    <item>
      <title>Comparative Analysis of Machine Learning-Based Imputation Techniques for Air Quality Datasets with High Missing Data Rates</title>
      <link>https://arxiv.org/abs/2412.13966</link>
      <description>arXiv:2412.13966v2 Announce Type: replace-cross 
Abstract: Urban pollution poses serious health risks, particularly in relation to traffic-related air pollution, which remains a major concern in many cities. Vehicle emissions contribute to respiratory and cardiovascular issues, especially for vulnerable and exposed road users like pedestrians and cyclists. Therefore, accurate air quality monitoring with high spatial resolution is vital for good urban environmental management. This study aims to provide insights for processing spatiotemporal datasets with high missing data rates. In this study, the challenge of high missing data rates is a result of the limited data available and the fine granularity required for precise classification of PM2.5 levels. The data used for analysis and imputation were collected from both mobile sensors and fixed stations by Dynamic Parcel Distribution, the Environmental Protection Agency, and Google in Dublin, Ireland, where the missing data rate was approximately 82.42%, making accurate Particulate Matter 2.5 level predictions particularly difficult. Various imputation and prediction approaches were evaluated and compared, including ensemble methods, deep learning models, and diffusion models. External features such as traffic flow, weather conditions, and data from the nearest stations were incorporated to enhance model performance. The results indicate that diffusion methods with external features achieved the highest F1 score, reaching 0.9486 (Accuracy: 94.26%, Precision: 94.42%, Recall: 94.82%), with ensemble models achieving the highest accuracy of 94.82%, illustrating that good performance can be obtained despite a high missing data rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13966v2</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sen Yan, David J. O'Connor, Xiaojun Wang, Noel E. O'Connor, Alan F. Smeaton, Mingming Liu</dc:creator>
    </item>
  </channel>
</rss>
