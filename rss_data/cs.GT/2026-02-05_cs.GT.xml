<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Feb 2026 02:46:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Robustness of Stable Matchings When Attributes and Salience Determine Preferences</title>
      <link>https://arxiv.org/abs/2602.04115</link>
      <description>arXiv:2602.04115v1 Announce Type: new 
Abstract: In many matching markets--such as athlete recruitment or academic admissions--participants on one side are evaluated by attribute vectors known to the other side, which in turn applies individual \emph{salience vectors} to assign relative importance to these attributes. Since saliences are known to change in practice, a central question arises: how robust is a stable matching to such perturbations? We address several fundamental questions in this context.
  First, we formalize robustness as a radius within which a stable matching remains immune to blocking pairs under any admissible perturbation of salience vectors (which are assumed to be normalized). Given a stable matching and a radius, we present a polynomial-time algorithm to verify whether the matching is stable within the specified radius. We also give a polynomial-time algorithm for computing the maximum robustness radius of a given stable matching. Further, we design an anytime search algorithm that uses certified lower and upper bounds to approximate the most robust stable matching, and we characterize the robustness-cost relationship through efficiently computable bounds that delineate the achievable tradeoff between robustness and cost. Finally, we show that for each stable matching, the set of salience profiles that preserve its stability factors is a product of low-dimensional polytopes within the simplex. This geometric structure precisely characterizes the polyhedral shape of each robustness region; its volume can then be computed efficiently, with approximate methods available as the dimension grows, thereby linking robustness analysis in matching markets with classical tools from convex geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04115v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit Ronen, S. S. Ravi, Sarit Kraus</dc:creator>
    </item>
    <item>
      <title>Optimal Rates for Feasible Payoff Set Estimation in Games</title>
      <link>https://arxiv.org/abs/2602.04397</link>
      <description>arXiv:2602.04397v1 Announce Type: new 
Abstract: We study a setting in which two players play a (possibly approximate) Nash equilibrium of a bimatrix game, while a learner observes only their actions and has no knowledge of the equilibrium or the underlying game. A natural question is whether the learner can rationalize the observed behavior by inferring the players' payoff functions. Rather than producing a single payoff estimate, inverse game theory aims to identify the entire set of payoffs consistent with observed behavior, enabling downstream use in, e.g., counterfactual analysis and mechanism design across applications like auctions, pricing, and security games. We focus on the problem of estimating the set of feasible payoffs with high probability and up to precision $\epsilon$ on the Hausdorff metric. We provide the first minimax-optimal rates for both exact and approximate equilibrium play, in zero-sum as well as general-sum games. Our results provide learning-theoretic foundations for set-valued payoff inference in multi-agent environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04397v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Annalisa Barbara, Riccardo Poiani, Martino Bernasconi, Andrea Celli</dc:creator>
    </item>
    <item>
      <title>Graph-Based Audits for Meek Single Transferable Vote Elections</title>
      <link>https://arxiv.org/abs/2602.04527</link>
      <description>arXiv:2602.04527v1 Announce Type: new 
Abstract: In the context of election security, a Risk-Limiting Audit (RLA) is a statistical framework that uses a minimal partial recount of the ballots to guarantee that the results of the election were correctly reported. A generalized RLA framework has remained elusive for algorithmic election rules such as the Single Transferable Vote (STV) rule, because of the dependence of these rules on the chronology of eliminations and elections leading to the outcome of the election. This paper proposes a new graph-based approach to audit these algorithmic election rules, by considering the space of all possible sequences of elections and eliminations. If we fix a subgraph of this universal space ahead of the audit, a sufficient strategy is to verify statistically that the true election sequence does not leave the fixed subgraph. This makes for a flexible framework to audit these elections in a chronology-agnostic way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04527v1</guid>
      <category>cs.GT</category>
      <category>stat.AP</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edouard Heitzmann</dc:creator>
    </item>
    <item>
      <title>Winning in the Limit: Average-Case Committee Selection with Many Candidates</title>
      <link>https://arxiv.org/abs/2602.04815</link>
      <description>arXiv:2602.04815v1 Announce Type: new 
Abstract: We study the committee selection problem in the canonical impartial culture model with a large number of voters and an even larger candidate set. Here, each voter independently reports a uniformly random preference order over the candidates. For a fixed committee size $k$, we ask when a committee can collectively beat every candidate outside the committee by a prescribed majority level $\alpha$. We focus on two natural notions of collective dominance, $\alpha$-winning and $\alpha$-dominating sets, and we identify sharp threshold phenomena for both of them using probabilistic methods, duality arguments, and rounding techniques.
  We first consider $\alpha$-winning sets. A set $S$ of $k$ candidates is $\alpha$-winning if, for every outside candidate $a \notin S$, at least an $\alpha$-fraction of voters rank some member of $S$ above $a$. We show a sharp threshold at \[ \alpha_{\mathrm{win}}^\star = 1 - \frac{1}{k}. \] Specifically, an $\alpha$-winning set of size $k$ exists with high probability when $\alpha &lt; \alpha_{\mathrm{win}}^\star$, and is unlikely to exist when $\alpha &gt; \alpha_{\mathrm{win}}^\star$.
  We then study the stronger notion of $\alpha$-dominating sets. A set $S$ of $k$ candidates is $\alpha$-dominating if, for every outside candidate $a \notin S$, there exists a single committee member $b \in S$ such that at least an $\alpha$-fraction of voters prefer $b$ to $a$. Here we establish an analogous sharp threshold at \[ \alpha_{\mathrm{dom}}^\star = \frac{1}{2} - \frac{1}{2k}. \] As a corollary, our analysis yields an impossibility result for $\alpha$-dominating sets: for every $k$ and every $\alpha &gt; \alpha_{\mathrm{dom}}^\star = 1 / 2 - 1 / (2k)$, there exist preference profiles that admit no $\alpha$-dominating set of size $k$. This corollary improves the best previously known bounds for all $k \geq 2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04815v1</guid>
      <category>cs.GT</category>
      <category>cs.DM</category>
      <category>econ.TH</category>
      <category>math.CO</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Lin, Shenyu Qin, Kangning Wang, Lirong Xia</dc:creator>
    </item>
    <item>
      <title>Properties of the core and other solution concepts of Bel coalitional games in the ex-ante scenario</title>
      <link>https://arxiv.org/abs/2602.04817</link>
      <description>arXiv:2602.04817v1 Announce Type: new 
Abstract: We study the properties of the core and other solution concepts of Bel coalitional games, that generalize classical coalitional games by introducing uncertainty in the framework. In this uncertain environment, we work with contracts, that specify how agents divide the values of the coalitions in the different states of the world. Every agent can have different a priori knowledge on the true state of the world, which is modeled through the Dempster-Shafer theory, while agents' preferences between contracts are modeled by the Choquet integral. We focus on the "ex-ante" scenario, when the contract is evaluated before uncertainty is resolved. We investigate the geometrical structure of the ex-ante core when agents have the same a priori knowledge which is a probability distribution. Finally, we define the (pre)nucleolus, the kernel and the bargaining set (a la Mas-Colell) in the ex-ante situation and we study their properties. It is found that the inclusion relations among these solution concepts are the same as in the classical case. Coincidence of the ex-ante core and the ex-ante bargaining set holds for convex Bel coalitional games, at the price of strengthening the definition of bargaining sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04817v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michel Grabisch, Silvia Lorenzini</dc:creator>
    </item>
    <item>
      <title>Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2601.07463</link>
      <description>arXiv:2601.07463v1 Announce Type: cross 
Abstract: Offline multi-agent reinforcement learning (MARL) aims to solve cooperative decision-making problems in multi-agent systems using pre-collected datasets. Existing offline MARL methods primarily constrain training within the dataset distribution, resulting in overly conservative policies that struggle to generalize beyond the support of the data. While model-based approaches offer a promising solution by expanding the original dataset with synthetic data generated from a learned world model, the high dimensionality, non-stationarity, and complexity of multi-agent systems make it challenging to accurately estimate the transitions and reward functions in offline MARL. Given the difficulty of directly modeling joint dynamics, we propose a local-to-global (LOGO) world model, a novel framework that leverages local predictions-which are easier to estimate-to infer global state dynamics, thus improving prediction accuracy while implicitly capturing agent-wise dependencies. Using the trained world model, we generate synthetic data to augment the original dataset, expanding the effective state-action space. To ensure reliable policy learning, we further introduce an uncertainty-aware sampling mechanism that adaptively weights synthetic data by prediction uncertainty, reducing approximation error propagation to policies. In contrast to conventional ensemble-based methods, our approach requires only an additional encoder for uncertainty estimation, significantly reducing computational overhead while maintaining accuracy. Extensive experiments across 8 scenarios against 8 baselines demonstrate that our method surpasses state-of-the-art baselines on standard offline MARL benchmarks, establishing a new model-based baseline for generalizable offline multi-agent learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07463v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sijia li, Xinran Li, Shibo Chen, Jun Zhang</dc:creator>
    </item>
    <item>
      <title>Mobility-as-a-service (MaaS) system as a multi-leader-multi-follower game: A single-level variational inequality (VI) formulation</title>
      <link>https://arxiv.org/abs/2601.19880</link>
      <description>arXiv:2601.19880v1 Announce Type: cross 
Abstract: This study models a Mobility-as-a-Service (MaaS) system as a multi-leader-multi-follower game that captures the complex interactions among the MaaS platform, service operators, and travelers. We consider a coopetitive setting where the MaaS platform purchases service capacity from service operators and sells multi-modal trips to travelers following an origin-destination-based pricing scheme; meanwhile, service operators use their remaining capacities to serve single-modal trips. As followers, travelers make both mode choices, including whether to use MaaS, and route choices in the multi-modal transportation network, subject to prices and congestion. Inspired by the dual formulation for traffic assignment problems, we propose a novel single-level variational inequality (VI) formulation by introducing a virtual traffic operator, along with the MaaS platform and multiple service operators. A key advantage of the proposed VI formulation is that it supports parallel solution procedures and thus enables large-scale applications. We prove that an equilibrium solution always exists given the negotiated wholesale price of service capacity. Numerical experiments on a small network further demonstrate that the wholesale price can be tailored to align with varying system-wide objectives. The proposed MaaS system demonstrates potential for creating a "win-win-win" outcome -- service operators and travelers are better off compared to the "without MaaS" scenario, meanwhile the MaaS platform remains profitable. Such a Pareto-improving regime can be explicitly specified with the wholesale capacity price. Similar conclusions are drawn from the experiment of an extended multi-modal Sioux Falls network, which also validates the scalability of the proposed model and solution algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19880v1</guid>
      <category>econ.GN</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Yao, Xinyu Ma, Kenan Zhang</dc:creator>
    </item>
    <item>
      <title>Dynamic Matching Under Patience Imbalance</title>
      <link>https://arxiv.org/abs/2602.03995</link>
      <description>arXiv:2602.03995v1 Announce Type: cross 
Abstract: We study a dynamic matching problem on a two-sided platform with unbalanced patience, in which long-lived supply accumulates over time with a unit waiting cost per period, while short-lived demand departs if not matched promptly. High- or low-quality agents arrive sequentially with one supply agent and one demand agent arriving in each period, and matching payoffs are supermodular. In the centralized benchmark, the optimal policy follows a threshold-based rule that rations high-quality supply, preserving it for future high-quality demand. In the decentralized system, where self-interested agents decide whether to match under an exogenously specified payoff allocation proportion, we characterize a welfare-maximizing Markov perfect equilibrium. Unlike outcomes in the centralized benchmark or in full-backlog markets, the equilibrium exhibits distinct matching patterns in which low-type demand may match with high-type supply even when low-type supply is available. Unlike settings in which both sides have long-lived agents and perfect coordination is impossible, the decentralized system can always be perfectly aligned with the centralized optimum by appropriately adjusting the allocation of matching payoffs across agents on both sides. Finally, when the arrival probabilities for H- and L-type arrivals are identical on both sides, we compare social welfare across systems with different patience levels: full backlog on both sides, one-sided backlog, and no backlog. In the centralized setting, social welfare is weakly ordered across systems. However, in the decentralized setting, the social welfare ranking across the three systems depends on the matching payoff allocation rule and the unit waiting cost, and enabling patience can either increase or decrease social welfare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03995v1</guid>
      <category>econ.TH</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhiyuan Chen (David),  Rui (David),  Chen, Ming Hu, Yun Zhou</dc:creator>
    </item>
    <item>
      <title>Maximin Relative Improvement: Fair Learning as a Bargaining Problem</title>
      <link>https://arxiv.org/abs/2602.04155</link>
      <description>arXiv:2602.04155v1 Announce Type: cross 
Abstract: When deploying a single predictor across multiple subpopulations, we propose a fundamentally different approach: interpreting group fairness as a bargaining problem among subpopulations. This game-theoretic perspective reveals that existing robust optimization methods such as minimizing worst-group loss or regret correspond to classical bargaining solutions and embody different fairness principles. We propose relative improvement, the ratio of actual risk reduction to potential reduction from a baseline predictor, which recovers the Kalai-Smorodinsky solution. Unlike absolute-scale methods that may not be comparable when groups have different potential predictability, relative improvement provides axiomatic justification including scale invariance and individual monotonicity. We establish finite-sample convergence guarantees under mild conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04155v1</guid>
      <category>stat.ML</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiwoo Han, Moulinath Banerjee, Yuekai Sun</dc:creator>
    </item>
    <item>
      <title>MaMa: A Game-Theoretic Approach for Designing Safe Agentic Systems</title>
      <link>https://arxiv.org/abs/2602.04431</link>
      <description>arXiv:2602.04431v1 Announce Type: cross 
Abstract: LLM-based multi-agent systems have demonstrated impressive capabilities, but they also introduce significant safety risks when individual agents fail or behave adversarially. In this work, we study the automated design of agentic systems that remain safe even when a subset of agents is compromised. We formalize this challenge as a Stackelberg security game between a system designer (the Meta-Agent) and a best-responding Meta-Adversary that selects and compromises a subset of agents to minimize safety. We propose Meta-Adversary-Meta-Agent (MaMa), a novel algorithm for approximately solving this game and automatically designing safe agentic systems. Our approach uses LLM-based adversarial search, where the Meta-Agent iteratively proposes system designs and receives feedback based on the strongest attacks discovered by the Meta-Adversary. Empirical evaluations across diverse environments show that systems designed with MaMa consistently defend against worst-case attacks while maintaining performance comparable to systems optimized solely for task success. Moreover, the resulting systems generalize to stronger adversaries, as well as ones with different attack objectives or underlying LLMs, demonstrating robust safety beyond the training setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04431v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan N\"other, Adish Singla, Goran Radanovic</dc:creator>
    </item>
    <item>
      <title>The impact of heterogeneity on the co-evolution of cooperation and epidemic spreading in complex networks</title>
      <link>https://arxiv.org/abs/2602.04481</link>
      <description>arXiv:2602.04481v1 Announce Type: cross 
Abstract: The dynamics of herd immunity depend crucially on the interaction between collective social behavior and disease transmission, but the role of heterogeneity in this context frequently remains unclear. Here, we dissect this co-evolutionary feedback by coupling a public goods game with an epidemic model on complex networks, including multiplex and real-world networks. Our results reveals a dichotomy in how heterogeneity shapes outcomes. We demonstrate that structural heterogeneity in social networks acts as a powerful catalyst for cooperation and disease suppression. This emergent effect is driven by highly connected hubs who, facing amplified personal risk, adopt protective strategies out of self-interest. In contrast, heterogeneity in individual infection costs proves detrimental, undermining cooperation and amplifying the epidemic. This creates a ``weakest link'' problem, where individuals with low perceived risk act as persistent free-riders and disease reservoirs, degrading the collective response. Our findings establish that heterogeneity is a double-edged sword: its impact is determined by whether it creates an asymmetry of influence (leverage points) or an asymmetry of motivation (weakest links), recommending disease intervention policies that facilitate cooperative transition in hubs (strengthening the leverage point) and homogenize incentives to weakest links.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04481v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <category>q-bio.PE</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehran Noori, Nahid Azimi-Tafreshi, Mohammad Salahshour</dc:creator>
    </item>
    <item>
      <title>From Competition to Collaboration: Designing Sustainable Mechanisms Between LLMs and Online Forums</title>
      <link>https://arxiv.org/abs/2602.04572</link>
      <description>arXiv:2602.04572v1 Announce Type: cross 
Abstract: While Generative AI (GenAI) systems draw users away from (Q&amp;A) forums, they also depend on the very data those forums produce to improve their performance. Addressing this paradox, we propose a framework of sequential interaction, in which a GenAI system proposes questions to a forum that can publish some of them. Our framework captures several intricacies of such a collaboration, including non-monetary exchanges, asymmetric information, and incentive misalignment. We bring the framework to life through comprehensive, data-driven simulations using real Stack Exchange data and commonly used LLMs. We demonstrate the incentive misalignment empirically, yet show that players can achieve roughly half of the utility in an ideal full-information scenario. Our results highlight the potential for sustainable collaboration that preserves effective knowledge sharing between AI systems and human knowledge platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04572v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niv Fono, Yftah Ziser, Omer Ben-Porat</dc:creator>
    </item>
    <item>
      <title>The Complexity of Min-Max Optimization with Product Constraints</title>
      <link>https://arxiv.org/abs/2602.04665</link>
      <description>arXiv:2602.04665v1 Announce Type: cross 
Abstract: We study the computational complexity of the problem of computing local min-max equilibria of games with a nonconvex-nonconcave utility function $f$. From the work of Daskalakis, Skoulakis, and Zampetakis [DSZ21], this problem was known to be hard in the restrictive case in which players are required to play strategies that are jointly constrained, leaving open the question of its complexity under more natural constraints. In this paper, we settle the question and show that the problem is PPAD-hard even under product constraints and, in particular, over the hypercube.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04665v1</guid>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martino Bernasconi, Matteo Castiglioni</dc:creator>
    </item>
    <item>
      <title>Online Budget Allocation with Censored Semi-Bandit Feedback</title>
      <link>https://arxiv.org/abs/2508.05844</link>
      <description>arXiv:2508.05844v2 Announce Type: replace 
Abstract: We study a stochastic budget-allocation problem over $K$ tasks. At each round $t$, the learner chooses an allocation $X_t \in \Delta_K$. Task $k$ succeeds with probability $F_k(X_{t,k})$, where $F_1,\dots,F_K$ are nondecreasing budget-to-success curves, and upon success yields a random reward with unknown mean $\mu_k$. The learner observes which tasks succeed, and observes a task's reward only upon success (censored semi-bandit feedback). This model captures, for instance, splitting payments across crowdsourcing workers or distributing bids across simultaneous auctions, and subsumes stochastic multi-armed bandits and semi-bandits.
  We design an optimism-based algorithm that operates under censored semi-bandit feedback. Our main result shows that in diminishing-returns regimes, the regret of this algorithm scales polylogarithmically with the horizon $T$ without any ad hoc tuning. For general nondecreasing curves, we prove that the same algorithm (with the same tuning) achieves a worst-case regret upper bound of $\tilde O(K\sqrt{T})$. Finally, we establish a matching worst-case regret lower bound of $\Omega(K\sqrt{T})$ that holds even for full-feedback algorithms, highlighting the intrinsic hardness of our problem outside diminishing returns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05844v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Bachoc, Nicol\`o Cesa-Bianchi, Tommaso Cesari, Roberto Colomboni</dc:creator>
    </item>
    <item>
      <title>Learning-Augmented Facility Location Mechanisms for Envy Ratio</title>
      <link>https://arxiv.org/abs/2512.11193</link>
      <description>arXiv:2512.11193v2 Announce Type: replace 
Abstract: The augmentation of algorithms with predictions of the optimal solution, such as from a machine-learning algorithm, has garnered significant attention in recent years, particularly in facility location problems. Moving beyond the traditional focus on utilitarian and egalitarian objectives, we design learning-augmented facility location mechanisms on a line for the envy ratio objective, a fairness metric defined as the maximum ratio between the utilities of any two agents. For the deterministic setting, we propose the $\alpha$-Bounding Interval Mechanism ($\alpha$-BIM), which utilizes predictions to achieve $\alpha$-consistency and $\frac{\alpha}{\alpha - 1}$-robustness for a selected parameter $\alpha \in [1,2]$, and prove its optimality. We also resolve open questions raised by Ding et al. [10], devising a randomized mechanism without predictions to improve upon the best-known approximation ratio from $2$ to approximately $1.8944$. Building upon these advancements, we construct a novel randomized mechanism, the Bias-Aware Mechanism (BAM), which incorporates predictions to achieve improved consistency and robustness guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11193v2</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haris Aziz, Yuhang Guo, Alexander Lam, Houyu Zhou</dc:creator>
    </item>
    <item>
      <title>Axioms for Top Trading Cycles in Multi-Object Reallocation</title>
      <link>https://arxiv.org/abs/2404.04822</link>
      <description>arXiv:2404.04822v5 Announce Type: replace-cross 
Abstract: This paper studies multi-object reallocation without monetary transfers, where agents initially own multiple indivisible objects and have strict preferences over bundles (e.g., shift exchange among workers at a firm). Focusing on marginal rules that elicit only rankings over individual objects, we provide axiomatic characterizations of the generalized Top Trading Cycles rule (TTC) on the lexicographic and responsive domains. On the lexicographic domain, TTC is characterized by balancedness, individual-good efficiency, the worst-endowment lower bound, and either truncation-proofness or drop strategy-proofness. On the responsive domain, TTC is the unique marginal rule satisfying individual-good efficiency, truncation-proofness, and either the worst-endowment lower bound or individual rationality. In the Shapley--Scarf housing market, TTC is characterized by Pareto efficiency, individual rationality, and truncation-proofness. Finally, on the conditionally lexicographic domain, the augmented Top Trading Cycles rule is characterized by balancedness, Pareto efficiency, the worst-endowment lower bound, and drop strategy-proofness. The conditionally lexicographic domain is a maximal domain on which Pareto efficiency coincides with individual-good efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04822v5</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacob Coreno, Di Feng</dc:creator>
    </item>
    <item>
      <title>Sequential Selection with Expirations</title>
      <link>https://arxiv.org/abs/2406.15691</link>
      <description>arXiv:2406.15691v2 Announce Type: replace-cross 
Abstract: Motivated by applications where impatience is pervasive and evaluation times are uncertain, we study a selection model where options may expire at an unknown point in time and evaluation times are stochastic. Initially, the decision-maker (DM) has access to $n$ options with known non-negative values: these options have unknown stochastic evaluation and expiration times with known distributional information, which we assume to be independent. When the DM is free, we can select an available option that occupies the DM for an unknown amount of time and collect its value. The objective is to maximize the expected total value obtained from options selected by the DM. Natural formulations of this problem suffer from the curse of dimensionality. In fact, this problem is NP-hard even in the deterministic case. Hence, we focus on efficiently computable approximation algorithms that can provide high expected reward compared to the optimal expected value. Towards this end, we first provide a compact linear programming (LP) relaxation that gives an upper bound on the expected value obtained by the optimal policy. Then we design a polynomial-time algorithm that is nearly a $(1/2)\cdot (1-1/e)$-approximation to the optimal LP value (so also to the optimal expected value). We next shift our focus to the case of independent and identically distributed (i.i.d.) evaluation times. In this case, we show that the greedy policy that always selects the highest-valued option whenever the DM is free obtains a $1/2$-approximation to the optimal expected value. Our approaches extend effortlessly, and we demonstrate their flexibility by providing approximations to natural extensions of our problem. Finally, we evaluate our LP-based policies and the greedy policy empirically on synthetic and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15691v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yihua Xu, Rohan Ghuge, Sebastian Perez-Salazar</dc:creator>
    </item>
    <item>
      <title>No Screening is More Efficient with Multiple Objects</title>
      <link>https://arxiv.org/abs/2408.10077</link>
      <description>arXiv:2408.10077v3 Announce Type: replace-cross 
Abstract: We study efficient mechanism design for allocating multiple heterogeneous objects. The aim is to maximize the residual surplus, the total value generated from an allocation minus the costs of screening. We discover a robust trend indicating that no-screening mechanisms, such as serial dictatorship with exogenous priority order, tend to perform better as the variety of goods increases. We analyze the underlying reasons by characterizing asymptotically efficient mechanisms in a stylized environment. We also apply an automated mechanism design approach to numerically derive efficient mechanisms and validate the trend in general environments. Building on these implications, we propose the register-invite-book system (RIB) as an efficient system for scheduling vaccinations against pandemic diseases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10077v3</guid>
      <category>econ.TH</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shunya Noda, Genta Okada</dc:creator>
    </item>
    <item>
      <title>Steering the Herd: A Framework for LLM-based Control of Social Learning</title>
      <link>https://arxiv.org/abs/2504.02648</link>
      <description>arXiv:2504.02648v4 Announce Type: replace-cross 
Abstract: Algorithms increasingly serve as information mediators--from social media feeds and targeted advertising to the increasing ubiquity of LLMs. This engenders a joint process where agents combine private, algorithmically-mediated signals with learning from peers to arrive at decisions. To study such settings, we introduce a model of controlled sequential social learning in which an information-mediating planner (e.g. an LLM) controls the information structure of agents while they also learn from the decisions of earlier agents. The planner may seek to improve social welfare (altruistic planner) or to induce a specific action the planner prefers (biased planner). Our framework presents a new optimization problem for social learning that combines dynamic programming with decentralized action choices and Bayesian belief updates. We prove the convexity of the value function and characterize the optimal policies of altruistic and biased planners, which attain desired tradeoffs between the costs they incur and the payoffs they earn from induced agent choices. Notably, in some regimes the biased planner intentionally obfuscates the agents' signals. Even under stringent transparency constraints--information parity with individuals, no lying or cherry-picking, and full observability--we show that information mediation can substantially shift social welfare in either direction. We complement our theory with simulations in which LLMs act as both planner and agents. Notably, the LLM planner in our simulations exhibits emergent strategic behavior in steering public opinion that broadly mirrors the trends predicted, though key deviations suggest the influence of non-Bayesian reasoning consistent with the cognitive patterns of both humans and LLMs trained on human-like data. Together, we establish our framework as a tractable basis for studying the impact and regulation of LLM information mediators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02648v4</guid>
      <category>eess.SY</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raghu Arghal, Kevin He, Shirin Saeedi Bidokhti, Saswati Sarkar</dc:creator>
    </item>
    <item>
      <title>Achieving Logarithmic Regret in KL-Regularized Zero-Sum Markov Games</title>
      <link>https://arxiv.org/abs/2510.13060</link>
      <description>arXiv:2510.13060v2 Announce Type: replace-cross 
Abstract: Reverse Kullback-Leibler (KL) divergence-based regularization with respect to a fixed reference policy is widely used in modern reinforcement learning to preserve the desired traits of the reference policy and sometimes to promote exploration (using uniform reference policy, known as entropy regularization). Beyond serving as a mere anchor, the reference policy can also be interpreted as encoding prior knowledge about good actions in the environment. In the context of alignment, recent game-theoretic approaches have leveraged KL regularization with pretrained language models as reference policies, achieving notable empirical success in self-play methods. Despite these advances, the theoretical benefits of KL regularization in game-theoretic settings remain poorly understood. In this work, we develop and analyze algorithms that provably achieve improved sample efficiency under KL regularization. We study both two-player zero-sum matrix games and Markov games: for matrix games, we propose OMG, an algorithm based on best response sampling with optimistic bonuses, and extend this idea to Markov games through the algorithm SOMG, which also uses best response sampling and a novel concept of superoptimistic bonuses. Both algorithms achieve a logarithmic regret in $T$ that scales inversely with the KL regularization strength $\beta$ in addition to the traditional $\widetilde{\mathcal{O}}(\sqrt{T})$ regret without the $\beta^{-1}$ dependence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13060v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anupam Nayak, Tong Yang, Osman Yagan, Gauri Joshi, Yuejie Chi</dc:creator>
    </item>
  </channel>
</rss>
