<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Feb 2025 02:53:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Inverse Surrogate Model of a Soft X-Ray Spectrometer using Domain Adaptation</title>
      <link>https://arxiv.org/abs/2502.17505</link>
      <description>arXiv:2502.17505v1 Announce Type: cross 
Abstract: In this study, we present a method to create a robust inverse surrogate model for a soft X-ray spectrometer. During a beamtime at an electron storage ring, such as BESSY II, instrumentation and beamlines are required to be correctly aligned and calibrated for optimal experimental conditions. In order to automate these processes, machine learning methods can be developed and implemented, but in many cases these methods require the use of an inverse model which maps the output of the experiment, such as a detector image, to the parameters of the device. Due to limited experimental data, such models are often trained with simulated data, which creates the challenge of compensating for the inherent differences between simulation and experiment. In order to close this gap, we demonstrate the application of data augmentation and adversarial domain adaptation techniques, with which we can predict absolute coordinates for the automated alignment of our spectrometer. Bridging the simulation-experiment gap with minimal real-world data opens new avenues for automated experimentation using machine learning in scientific instrumentation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17505v1</guid>
      <category>physics.ins-det</category>
      <category>cs.AI</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enrico Ahlers, Peter Feuer-Forson, Gregor Hartmann, Rolf Mitzner, Peter Baumg\"artel, Jens Viefhaus</dc:creator>
    </item>
    <item>
      <title>Ultimate Sensitivity in X-ray Diffraction: Angular Moments vs. Shot Noise</title>
      <link>https://arxiv.org/abs/2502.17977</link>
      <description>arXiv:2502.17977v1 Announce Type: cross 
Abstract: The sensitivity of x-ray diffraction experiments towards Bragg peak parameters constitutes a crucial performance attribute of experimental setups. Frequently, diffraction peaks are characterized by model-free angular moment analysis, which offers a greater versatility compared to traditional model-based peak fitting. Here, we have determined the ultimate sensitivity of angular moments for diffraction data that is limited by photon shot noise. We report experimentally achieved sensitivities of the first moment below $1/1000$th of a detector pixel and below $1\mu$rad. We have demonstrated the validity of our theoretical predictions by an excellent agreement with experimental results from three different setups. The provided formulas for the uncertainties of angular moments allow for the rapid determination of experimentally achieved sensitivities from single diffraction frames.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17977v1</guid>
      <category>physics.optics</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Modregger, Felix Wittwer, Ahmar Khaliq, Niklas Pyrlik, James A. D. Ball, Jan Garrevoet, Gerald Falkenberg, Alexander Liehr, Michael Stuckelberger</dc:creator>
    </item>
    <item>
      <title>Probabilistic Analysis of Event-Mode Experimental Data</title>
      <link>https://arxiv.org/abs/2502.17994</link>
      <description>arXiv:2502.17994v1 Announce Type: cross 
Abstract: Neutron and x-ray scattering experiments traditionally rely upon histogrammed data sets, which are analysed using least-squares curve fitting of multiple probability distribution components to quantify separately the various scientific contributions of interest. The main advantage to these methods is the relative ease of deployment due to their intuitive nature. Despite great popularity, these methods have known drawbacks, which can cause systematic errors and biases in some common scenarios in this field. Improvements over the base methods include dynamic optimisation of histogram bin width and the application of modern numerical optimisation methods that have greater stability, but, whilst reduced, the systematic effects carried by this stack nonetheless remain. In this study, we demonstrate analysis of neutron scattering event data using neither any numerical integration or histogramming steps, nor least squares fitting. The benefits of the new methodology are revealed: more accurate parameter values, orders of magnitude greater efficiency (i.e. fewer data points required for the same parameter accuracy) and a reduced impact of inherent systematic error. The main drawbacks are a less intuitive analysis method and an increase in computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17994v1</guid>
      <category>physics.ins-det</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Phillip M. Bentley, Thomas H. Rod</dc:creator>
    </item>
    <item>
      <title>Near-instantaneous Atmospheric Retrievals and Model Comparison with FASTER</title>
      <link>https://arxiv.org/abs/2502.18045</link>
      <description>arXiv:2502.18045v1 Announce Type: cross 
Abstract: In the era of the James Webb Space Telescope (JWST), the dramatic improvement in the spectra of exoplanetary atmospheres demands a corresponding leap forward in our ability to analyze them: atmospheric retrievals need to be performed on thousands of spectra, applying to each large ensembles of models (that explore atmospheric chemistry, thermal profiles and cloud models) to identify the best one(s). In this limit, traditional Bayesian inference methods such as nested sampling become prohibitively expensive. We introduce FASTER (Fast Amortized Simulation-based Transiting Exoplanet Retrieval), a neural-network based method for performing atmospheric retrieval and Bayesian model comparison at a fraction of the computational cost of classical techniques. We demonstrate that the marginal posterior distributions of all parameters within a model as well as the posterior probabilities of the models we consider match those computed using nested sampling both on mock spectra, and for the real NIRSpec PRISM spectrum of WASP-39b. The true power of the FASTER framework comes from its amortized nature, which allows the trained networks to perform practically instantaneous Bayesian inference and model comparison over ensembles of spectra -- real or simulated -- at minimal additional computational cost. This offers valuable insight into the expected results of model comparison (e.g., distinguishing cloudy from cloud-free and isothermal from non-isothermal models), as well as their dependence on the underlying parameters, which is computationally unfeasible with nested sampling. This approach will constitute as large a leap in spectral analysis as the original retrieval methods based on Markov Chain Monte Carlo have proven to be.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18045v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Lueber, Konstantin Karchev, Chloe Fisher, Matthias Heim, Roberto Trotta, Kevin Heng</dc:creator>
    </item>
    <item>
      <title>Sparsity covariance: a source of uncertainty when estimating correlation functions with a discrete sample of observations in the sky</title>
      <link>https://arxiv.org/abs/2502.18327</link>
      <description>arXiv:2502.18327v1 Announce Type: cross 
Abstract: Cosmological observables rely heavily on summary statistics such as two-point correlation functions. In many practical cases (e.g. the weak-lensing cosmic shear), those correlation functions are estimated from a finite, discrete sample of measurements that are randomly distributed in the sky. The result then inevitably depends on the sample at hand, regardless of any experimental noise. This sample dependence is a source of uncertainty for cosmological observables which I call sparsity covariance. This article proposes a mathematical definition and a generic method to compute sparsity covariance. It is then applied to the concrete case of cosmic shear, showing that sparsity covariance mostly enhances shape noise, whose amplitude is determined by the apparent ellipticity of galaxies rather than their intrinsic ellipticity. In general, sparsity covariance is non-negligible when the signal-to-noise ratio of individual measurements in the sample is comparable to, or larger than, unity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18327v1</guid>
      <category>astro-ph.CO</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre Fleury</dc:creator>
    </item>
    <item>
      <title>Assessing the similarity of real matrices with arbitrary shape</title>
      <link>https://arxiv.org/abs/2403.17687</link>
      <description>arXiv:2403.17687v3 Announce Type: replace-cross 
Abstract: Assessing the similarity of matrices is valuable for analyzing the extent to which data sets exhibit common features in tasks such as data clustering, dimensionality reduction, pattern recognition, group comparison, and graph analysis. Methods proposed for comparing vectors, such as cosine similarity, can be readily generalized to matrices. However, this approach usually neglects the inherent two-dimensional structure of matrices. Here, we propose singular angle similarity (SAS), a measure for evaluating the structural similarity between two arbitrary, real matrices of the same shape based on singular value decomposition. After introducing the measure, we compare SAS with standard measures for matrix comparison and show that only SAS captures the two-dimensional structure of matrices. Further, we characterize the behavior of SAS in the presence of noise and as a function of matrix dimensionality. Finally, we apply SAS to two use cases: square non-symmetric matrices of probabilistic network connectivity, and non-square matrices representing neural brain activity. For synthetic data of network connectivity, SAS matches intuitive expectations and allows for a robust assessment of similarities and differences. For experimental data of brain activity, SAS captures differences in the structure of high-dimensional responses to different stimuli. We conclude that SAS is a suitable measure for quantifying the shared structure of matrices with arbitrary shape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17687v3</guid>
      <category>q-bio.NC</category>
      <category>physics.data-an</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jasper Albers, Anno C. Kurth, Robin Gutzen, Aitor Morales-Gregorio, Michael Denker, Sonja Gr\"un, Sacha J. van Albada, Markus Diesmann</dc:creator>
    </item>
    <item>
      <title>Correlated Growth of Causal Networks</title>
      <link>https://arxiv.org/abs/2412.16647</link>
      <description>arXiv:2412.16647v2 Announce Type: replace-cross 
Abstract: The study of causal structure in complex systems has gained increasing attention, with many recent studies exploring causal networks that capture cause-effect relationships across diverse fields. Despite increasing empirical evidence linking causal structures to network topological correlations, the mechanisms underlying the emergence of these correlations in causal networks remain poorly understood. In this work, we propose a general growth framework for causal networks, incorporating two key types of correlations: causal and dynamic. We analytically demonstrate that degree correlations emerge as a consequence of marginal dependencies on these correlations. Our theoretical predictions align quantitatively with empirical data from four large-scale innovation networks. Our theory not only sheds light on the origins of topological correlations but also provides a general framework for understanding correlated growth across causal systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16647v2</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>nlin.AO</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiazhen Liu, Kunal Tamang, Dashun Wang, Chaoming Song</dc:creator>
    </item>
    <item>
      <title>Fast, accurate, and predictive method for atom detection in site-resolved images of microtrap arrays</title>
      <link>https://arxiv.org/abs/2502.08511</link>
      <description>arXiv:2502.08511v2 Announce Type: replace-cross 
Abstract: We introduce a new method, rooted in estimation theory, to detect the individual atoms in site-resolved images of microtrap arrays, such as optical lattices or optical tweezers arrays. Using simulated images, we demonstrate a ten-fold reduction of the detection error rate compared to the popular method based on Wiener deconvolution, under a wide range of experimental conditions. The runtime is fully compatible with real-time applications, even for a very large arrays. Finally, we propose a rigorous definition for the signal-to-noise ratio of an image, and show that it can be used as a predictor for the detection error rate, which opens new prospect for the design of future experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08511v2</guid>
      <category>quant-ph</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Marc Cheneau, Romaric Journet, Matthieu Boffety, Fran\c{c}ois Goudail, Caroline Kulcs\'ar, Pauline Trouv\'e-Peloux</dc:creator>
    </item>
  </channel>
</rss>
