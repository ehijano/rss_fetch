<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 May 2025 04:00:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Scalable 28nm IC implementation of coupled oscillator network featuring tunable topology and complexity</title>
      <link>https://arxiv.org/abs/2505.10248</link>
      <description>arXiv:2505.10248v1 Announce Type: new 
Abstract: Integrated circuit implementations of coupled oscillator networks have recently gained increased attention. The focus is usually on using these networks for analogue computing, for example for solving computational optimization tasks. For use within analog computing, these networks are run close to critical dynamics. On the other hand, such networks are also used as an analogy of transport networks such as electrical power grids to answer the question of how exactly such critical dynamic states can be avoided. However, simulating large network of coupled oscillators is computationally intensive, with specifc regards to electronic ones. We have developed an integrated circuit using integrated Phase-Locked Loop (PLL) with modifications, that allows to flexibly vary the topology as well as a complexity parameter of the network during operation. The proposed architecture, inspired by the brain, employs a clustered architecture, with each cluster containing 7 PLLs featuring programmable coupling mechanisms. Additionally, the inclusion of a RISC-V processor enables future algorithmic implementations. Thus, we provide a practical alternative for large-scale network simulations both in the field of analog computing and transport network stability research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10248v1</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S. Y. Neyaz, A. Ashok, M. Schiek, C. Grewing, A. Zambanini, S. van Waasen</dc:creator>
    </item>
    <item>
      <title>Generative diffusion model surrogates for mechanistic agent-based biological models</title>
      <link>https://arxiv.org/abs/2505.09630</link>
      <description>arXiv:2505.09630v1 Announce Type: cross 
Abstract: Mechanistic, multicellular, agent-based models are commonly used to investigate tissue, organ, and organism-scale biology at single-cell resolution. The Cellular-Potts Model (CPM) is a powerful and popular framework for developing and interrogating these models. CPMs become computationally expensive at large space- and time- scales making application and investigation of developed models difficult. Surrogate models may allow for the accelerated evaluation of CPMs of complex biological systems. However, the stochastic nature of these models means each set of parameters may give rise to different model configurations, complicating surrogate model development. In this work, we leverage denoising diffusion probabilistic models to train a generative AI surrogate of a CPM used to investigate \textit{in vitro} vasculogenesis. We describe the use of an image classifier to learn the characteristics that define unique areas of a 2-dimensional parameter space. We then apply this classifier to aid in surrogate model selection and verification. Our CPM model surrogate generates model configurations 20,000 timesteps ahead of a reference configuration and demonstrates approximately a 22x reduction in computational time as compared to native code execution. Our work represents a step towards the implementation of DDPMs to develop digital twins of stochastic biological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09630v1</guid>
      <category>q-bio.QM</category>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <category>cs.PF</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tien Comlekoglu, J. Quetzalc\'oatl Toledo-Mar\'in, Douglas W. DeSimone, Shayn M. Peirce, Geoffrey Fox, James A. Glazier</dc:creator>
    </item>
    <item>
      <title>Differentiable Quantum Architecture Search in Quantum-Enhanced Neural Network Parameter Generation</title>
      <link>https://arxiv.org/abs/2505.09653</link>
      <description>arXiv:2505.09653v1 Announce Type: cross 
Abstract: The rapid advancements in quantum computing (QC) and machine learning (ML) have led to the emergence of quantum machine learning (QML), which integrates the strengths of both fields. Among QML approaches, variational quantum circuits (VQCs), also known as quantum neural networks (QNNs), have shown promise both empirically and theoretically. However, their broader adoption is hindered by reliance on quantum hardware during inference. Hardware imperfections and limited access to quantum devices pose practical challenges. To address this, the Quantum-Train (QT) framework leverages the exponential scaling of quantum amplitudes to generate classical neural network parameters, enabling inference without quantum hardware and achieving significant parameter compression. Yet, designing effective quantum circuit architectures for such quantum-enhanced neural programmers remains non-trivial and often requires expertise in quantum information science. In this paper, we propose an automated solution using differentiable optimization. Our method jointly optimizes both conventional circuit parameters and architectural parameters in an end-to-end manner via automatic differentiation. We evaluate the proposed framework on classification, time-series prediction, and reinforcement learning tasks. Simulation results show that our method matches or outperforms manually designed QNN architectures. This work offers a scalable and automated pathway for designing QNNs that can generate classical neural network parameters across diverse applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09653v1</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Yen-Chi Chen, Chen-Yu Liu, Kuan-Cheng Chen, Wei-Jia Huang, Yen-Jui Chang, Wei-Hao Huang</dc:creator>
    </item>
    <item>
      <title>Chisme: Fully Decentralized Differentiated Deep Learning for Edge Intelligence</title>
      <link>https://arxiv.org/abs/2505.09854</link>
      <description>arXiv:2505.09854v1 Announce Type: cross 
Abstract: As demand for intelligent services rises and edge devices become more capable, distributed learning at the network edge has emerged as a key enabling technology. While existing paradigms like federated learning (FL) and decentralized FL (DFL) enable privacy-preserving distributed learning in many scenarios, they face potential challenges in connectivity and synchronization imposed by resource-constrained and infrastructure-less environments. While more robust, gossip learning (GL) algorithms have generally been designed for homogeneous data distributions and may not suit all contexts. This paper introduces Chisme, a novel suite of protocols designed to address the challenges of implementing robust intelligence in the network edge, characterized by heterogeneous data distributions, episodic connectivity, and lack of infrastructure. Chisme includes both synchronous DFL (Chisme-DFL) and asynchronous GL (Chisme-GL) variants that enable collaborative yet decentralized model training that considers underlying data heterogeneity. We introduce a data similarity heuristic that allows agents to opportunistically infer affinity with each other using the existing communication of model updates in decentralized FL and GL. We leverage the heuristic to extend DFL's model aggregation and GL's model merge mechanisms for better personalized training while maintaining collaboration. While Chisme-DFL is a synchronous decentralized approach whose resource utilization scales linearly with network size, Chisme-GL is fully asynchronous and has a lower, constant resource requirement independent of network size. We demonstrate that Chisme methods outperform their standard counterparts in model training over distributed and heterogeneous data in network scenarios ranging from less connected and reliable networks to fully connected and lossless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09854v1</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harikrishna Kuttivelil, Katia Obraczka</dc:creator>
    </item>
    <item>
      <title>Demystifying AI Agents: The Final Generation of Intelligence</title>
      <link>https://arxiv.org/abs/2505.09932</link>
      <description>arXiv:2505.09932v1 Announce Type: cross 
Abstract: The trajectory of artificial intelligence (AI) has been one of relentless acceleration, evolving from rudimentary rule-based systems to sophisticated, autonomous agents capable of complex reasoning and interaction. This whitepaper chronicles this remarkable journey, charting the key technological milestones--advancements in prompting, training methodologies, hardware capabilities, and architectural innovations--that have converged to create the AI agents of today. We argue that these agents, exemplified by systems like OpenAI's ChatGPT with plugins and xAI's Grok, represent a culminating phase in AI development, potentially constituting the "final generation" of intelligence as we currently conceive it. We explore the capabilities and underlying technologies of these agents, grounded in practical examples, while also examining the profound societal implications and the unprecedented pace of progress that suggests intelligence is now doubling approximately every six months. The paper concludes by underscoring the critical need for wisdom and foresight in navigating the opportunities and challenges presented by this powerful new era of intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09932v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin J McNamara, Rhea Pritham Marpu</dc:creator>
    </item>
    <item>
      <title>Optimal normalization in quantum-classical hybrid models for anti-cancer drug response prediction</title>
      <link>https://arxiv.org/abs/2505.10037</link>
      <description>arXiv:2505.10037v1 Announce Type: cross 
Abstract: Quantum-classical Hybrid Machine Learning (QHML) models are recognized for their robust performance and high generalization ability even for relatively small datasets. These qualities offer unique advantages for anti-cancer drug response prediction, where the number of available samples is typically small. However, such hybrid models appear to be very sensitive to the data encoding used at the interface of a neural network and a quantum circuit, with suboptimal choices leading to stability issues. To address this problem, we propose a novel strategy that uses a normalization function based on a moderated gradient version of the $\tanh$. This method transforms the outputs of the neural networks without concentrating them at the extreme value ranges. Our idea was evaluated on a dataset of gene expression and drug response measurements for various cancer cell lines, where we compared the prediction performance of a classical deep learning model and several QHML models. These results confirmed that QHML performed better than the classical models when data was optimally normalized. This study opens up new possibilities for biomedical data analysis using quantum computers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10037v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>quant-ph</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takafumi Ito, Lysenko Artem, Tatsuhiko Tsunoda</dc:creator>
    </item>
    <item>
      <title>Unlocking Innate Computing Abilities in Electric Grids</title>
      <link>https://arxiv.org/abs/2505.10382</link>
      <description>arXiv:2505.10382v1 Announce Type: cross 
Abstract: High energy consumption of artificial intelligence has gained momentum worldwide, which necessitates major investments on expanding efficient and carbon-neutral generation and data center infrastructure in electric power grids. Going beyond the conventional ideation, this article unleashes innate computational abilities in the power grid network circuits itself. By programming power electronic converters (PECs) to mimic biological neurons, we sustainably transform power grids into a neural network and enable it to optimize, compute and make data-driven decisions using distributed PECs. Instead of seen merely as an energy delivery platform, this article conceptualizes a novel application for electric grid to be used as a computing asset without affecting its operation. To illustrate its computational abilities, we solve a affine transformation task in a microgrid with five PECs. By encoding the digital data into the control of PECs, our preliminary results conclude that computing using electric grids does not disturb its operation. From a scientific perspective, this work fundamentally merges energy and computing optimization theories by harnessing inherent high-dimensional computational relationships in electric grids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10382v1</guid>
      <category>eess.SY</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yubo Song, Subham Sahoo</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Parameter Tuning of Level-1 QAOA for Ising Models</title>
      <link>https://arxiv.org/abs/2501.16419</link>
      <description>arXiv:2501.16419v2 Announce Type: replace-cross 
Abstract: The Quantum Approximate Optimisation Algorithm (QAOA) is a hybrid quantum-classical algorithm for solving combinatorial optimisation problems. QAOA encodes solutions into the ground state of a Hamiltonian, approximated by a $p$-level parameterised quantum circuit composed of problem and mixer Hamiltonians, with parameters optimised classically. While deeper QAOA circuits can offer greater accuracy, practical applications are constrained by complex parameter optimisation and physical limitations such as gate noise, restricted qubit connectivity, and state-preparation-and-measurement errors, limiting implementations to shallow depths. This work focuses on QAOA$_1$ (QAOA at $p=1$) for QUBO problems, represented as Ising models. Despite QAOA$_1$ having only two parameters, $(\gamma, \beta)$, we show that their optimisation is challenging due to a highly oscillatory landscape, with oscillation rates increasing with the problem size, density, and weight. This behaviour necessitates high-resolution grid searches to avoid distortion of cost landscapes that may result in inaccurate minima. We propose an efficient optimisation strategy that reduces the two-dimensional $(\gamma, \beta)$ search to a one-dimensional search over $\gamma$, with $\beta^*$ computed analytically. We establish the maximum permissible sampling period required to accurately map the $\gamma$ landscape and provide an algorithm to estimate the optimal parameters in polynomial time. Furthermore, we rigorously prove that for regular graphs on average, the globally optimal $\gamma^* \in \mathbb{R}^+$ values are concentrated very close to zero and coincide with the first local optimum, enabling gradient descent to replace exhaustive line searches. This approach is validated using Recursive QAOA (RQAOA), where it consistently outperforms both coarsely optimised RQAOA and semidefinite programs across all tested QUBO instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16419v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <category>math.OC</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V Vijendran, Dax Enshan Koh, Eunok Bae, Hyukjoon Kwon, Ping Koy Lam, Syed M Assad</dc:creator>
    </item>
    <item>
      <title>vNV-Heap: An Ownership-Based Virtually Non-Volatile Heap for Embedded Systems</title>
      <link>https://arxiv.org/abs/2501.17707</link>
      <description>arXiv:2501.17707v3 Announce Type: replace-cross 
Abstract: The Internet of Batteryless Things might revolutionize our understanding of connected devices by harvesting required operational energy from the environment. These systems come with the system-software challenge that the intermittently powered IoT devices have to checkpoint their state in non-volatile memory to later resume with this state when sufficient energy is available. The scarce energy resources demand that only modified data is persisted before a power failure, which requires precise modification tracking.
  We present vNV-Heap, the first ownership-based virtually Non-Volatile Heap for intermittently powered systems with guaranteed power-failure resilience. The heap exploits ownership systems, a zero-cost (i.e., compile-time) abstraction for example implemented by Rust, to track modifications and virtualize object persistence. To achieve power-failure resilience, our heap is designed and implemented to guarantee bounded operations by static program code analysis: For example, the heap allows for determining a worst-case energy consumption for the operation of persisting modified and currently volatile objects. The evaluation of our open-source implementation on an embedded hardware platform (i.e., ESP32-C3) shows that using our heap abstraction is more energy efficient than existing approaches while also providing runtime guarantees by static worst-case bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17707v3</guid>
      <category>cs.OS</category>
      <category>cs.ET</category>
      <category>cs.PL</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3735452.3735534</arxiv:DOI>
      <dc:creator>Markus Elias Gerber, Luis Gerhorst, Ishwar Mudraje, Kai Vogelgesang, Thorsten Herfet, Peter W\"agemann</dc:creator>
    </item>
    <item>
      <title>Rubikon: Intelligent Tutoring for Rubik's Cube Learning Through AR-enabled Physical Task Reconfiguration</title>
      <link>https://arxiv.org/abs/2503.12619</link>
      <description>arXiv:2503.12619v2 Announce Type: replace-cross 
Abstract: Learning to solve a Rubik's Cube requires the learners to repeatedly practice a skill component, e.g., identifying a misplaced square and putting it back. However, for 3D physical tasks such as this, generating sufficient repeated practice opportunities for learners can be challenging, in part because it is difficult for novices to reconfigure the physical object to specific states. We propose Rubikon, an intelligent tutoring system for learning to solve the Rubik's Cube. Rubikon reduces the necessity for repeated manual configurations of the Rubik's Cube without compromising the tactile experience of handling a physical cube. The foundational design of Rubikon is an AR setup, where learners manipulate a physical cube while seeing an AR-rendered cube on a display. Rubikon automatically generates configurations of the Rubik's Cube to target learners' weaknesses and help them exercise diverse knowledge components. In a between-subjects experiment, we showed that Rubikon learners scored 25% higher on a post-test compared to baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12619v2</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <pubDate>Fri, 16 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3715336.3735788</arxiv:DOI>
      <dc:creator>Haocheng Ren, Muzhe Wu, Gregory Croisdale, Anhong Guo, Xu Wang</dc:creator>
    </item>
  </channel>
</rss>
