<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Jul 2025 01:36:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>CNeuroMod-THINGS, a densely-sampled fMRI dataset for visual neuroscience</title>
      <link>https://arxiv.org/abs/2507.09024</link>
      <description>arXiv:2507.09024v1 Announce Type: new 
Abstract: Data-hungry neuro-AI modelling requires ever larger neuroimaging datasets. CNeuroMod-THINGS meets this need by capturing neural representations for a wide set of semantic concepts using well-characterized stimuli in a new densely-sampled, large-scale fMRI dataset. Importantly, CNeuroMod-THINGS exploits synergies between two existing projects: the THINGS initiative (THINGS) and the Courtois Project on Neural Modelling (CNeuroMod). THINGS has developed a common set of thoroughly annotated images broadly sampling natural and man-made objects which is used to acquire a growing collection of large-scale multimodal neural responses. Meanwhile, CNeuroMod is acquiring hundreds of hours of fMRI data from a core set of participants during controlled and naturalistic tasks, including visual tasks like movie watching and videogame playing. For CNeuroMod-THINGS, four CNeuroMod participants each completed 33-36 sessions of a continuous recognition paradigm using approximately 4000 images from the THINGS stimulus set spanning 720 categories. We report behavioural and neuroimaging metrics that showcase the quality of the data. By bridging together large existing resources, CNeuroMod-THINGS expands our capacity to model broad slices of the human visual experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09024v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Marie St-Laurent, Basile Pinsard, Oliver Contier, Elizabeth DuPre, Katja Seeliger, Valentina Borghesani, Julie A. Boyle, Lune Bellec, Martin N. Hebart</dc:creator>
    </item>
    <item>
      <title>Co-evolutionary Balance State of the Autism inter-Brain Network: A Neurofunctional Framework for Biomarker Discovery</title>
      <link>https://arxiv.org/abs/2507.09045</link>
      <description>arXiv:2507.09045v1 Announce Type: new 
Abstract: Autism spectrum disorder (ASD) is a neurodevelopmental condition characterized by deficits in social communication and repetitive behaviors; however, objective neurophysiological biomarkers remain lacking. We propose a coevolutionary balance paradigm that quantifies network level energy via a Hamiltonian integrating regional activity measured by fractional amplitude of low frequency fluctuations (fALFF) and resting state functional connectivity (FC). Analysis of resting state fMRI data from 93 adult males with ASD and 93 matched controls revealed that empirical networks showed lower energy than 1000 topology preserving null models (paired t = -4.12, p less than or equal to 1e-4). Participants with ASD exhibited more negative whole brain energy (t = -3.239, p = 0.0015), driven by increased agreement links and reduced imbalanced same motifs. Subnetwork analysis indicated greater energy in the Default Mode Network after false discovery rate correction (p less than 0.016) and enhanced energy between the Default Mode, Salience and Dorsal Attention networks (p less than 0.032). Energy metrics and inter network connectivity correlated with Autism Diagnostic Interview Revised and Autism Diagnostic Observation Schedule severity scores (absolute correlation greater than or equal to 0.29, p less than 0.02). A k nearest neighbors classifier using nine principal features including motif proportions, global node link alignment, inter network fALFF weighted and FC strengths, subnetwork magnetization and pairwise energy achieved an accuracy of 79 percent with balanced sensitivity and specificity. These results demonstrate that coevolutionary energy detects interpretable network disruptions and establishes a robust framework for ASD classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09045v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. Rezaei Afshar, H. Pouretemad, G. Reza Jafari</dc:creator>
    </item>
    <item>
      <title>Cellular Mechanisms of Phase Maintenance in a Pyloric Motif of a Central Pattern Generator</title>
      <link>https://arxiv.org/abs/2507.09360</link>
      <description>arXiv:2507.09360v1 Announce Type: new 
Abstract: In many neural networks, patterns controlling rhythmic behaviors are maintained across a wide range of periods. In the crustacean pyloric central pattern generator (CPG), a constant bursting pattern is preserved over a three-to-fivefold range of periods. We idescribe how neuromodulation could adjust neuronal properties to preserve phase relations as the period changes. We developed a biophysical model implementing a reduced pyloric network motif, which has a bursting neuron and two follower neurons interconnected through inhibitory synaptic coupling. We described cellular mechanisms supporting phase maintenance and investigated possible coordination between these mechanisms in four dynamically distinct ensembles of a pyloric CPG producing a triphasic pattern. The coordinated variation of the voltages of half-activation for potassium (VK2) and hyperpolarization-activated (Vh) currents provides a family of three mechanisms for control of burst duration, interburst interval, and latency to spiking. The mechanisms are determined by the Cornerstone bifurcation, one of the Shilnikov blue sky catastrophe scenarios. In Mechanism 1, in a bursting neuron, the burst duration increases as VK2 nears a blue-sky catastrophe bifurcation, while the interburst interval grows as Vh approaches a saddle-node on an invariant circle bifurcation. In Mechanism 2, a silent neuron responds with a single burst to short input; the burst duration grows as VK2 approaches a saddle-node bifurcation for periodic orbits. In Mechanism 3, a spiking neuron responds with a pause to short input; the pause duration grows as Vh nears a saddle-node bifurcation for stationary states. In all three mechanisms, the measured quantities grow without bound as the bifurcation parameter nears its critical value, consistent with an inverse-square-root law.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09360v1</guid>
      <category>q-bio.NC</category>
      <category>nlin.PS</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabrielle O'Brien, Adam L. Weaver, William H. Barnett, Dmitry A. Kozhanov, Gennady S. Cymbalyuk</dc:creator>
    </item>
    <item>
      <title>Self-supervised pretraining of vision transformers for animal behavioral analysis and neural encoding</title>
      <link>https://arxiv.org/abs/2507.09513</link>
      <description>arXiv:2507.09513v1 Announce Type: new 
Abstract: The brain can only be fully understood through the lens of the behavior it generates -- a guiding principle in modern neuroscience research that nevertheless presents significant technical challenges. Many studies capture behavior with cameras, but video analysis approaches typically rely on specialized models requiring extensive labeled data. We address this limitation with BEAST (BEhavioral Analysis via Self-supervised pretraining of Transformers), a novel and scalable framework that pretrains experiment-specific vision transformers for diverse neuro-behavior analyses. BEAST combines masked autoencoding with temporal contrastive learning to effectively leverage unlabeled video data. Through comprehensive evaluation across multiple species, we demonstrate improved performance in three critical neuro-behavioral tasks: extracting behavioral features that correlate with neural activity, and pose estimation and action segmentation in both the single- and multi-animal settings. Our method establishes a powerful and versatile backbone model that accelerates behavioral analysis in scenarios where labeled data remains scarce.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09513v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanchen Wang, Han Yu, Ari Blau, Yizi Zhang, The International Brain Laboratory, Liam Paninski, Cole Hurwitz, Matt Whiteway</dc:creator>
    </item>
    <item>
      <title>Dissociating Cognitive Load and Stress Responses Using Single-Channel EEG: Behavioral and Neural Correlates of Anxiety Across Cognitive States</title>
      <link>https://arxiv.org/abs/2507.10093</link>
      <description>arXiv:2507.10093v1 Announce Type: new 
Abstract: Identifying neural markers of stress and cognitive load is key to developing scalable tools for mental state assessment. This study evaluated whether a single-channel high-density EEG (hdrEEG) system could dissociate cognitive and stress-related activity during a brief auditory task-based protocol. Sixty-eight healthy adults completed resting state recordings, cognitively demanding auditory tasks, and exposure to unpredictable literalized startle stimuli. Participants also rated their stress and anxiety using a modified State-Trait Anxiety Inventory (STAI). EEG analysis focused on frequency bands (Theta, Gamma, Delta) and machine-learning-derived features (A0, ST4, VC9, T2). A double dissociation emerged: Theta and VC9 increased under cognitive load but not startle, supporting their sensitivity to executive function. In contrast, Gamma and A0 were elevated by the startle stimulus, consistent with stress reactivity. ST4 tracked cognitive effort and worry, while T2 negatively correlated with self-reported calmness, indicating relevance to emotional regulation. These results demonstrate that a short, uniform assessment using portable EEG can yield multiple reliable biomarkers of cognitive and affective states. The findings have implications for clinical, occupational, and educational settings, and may inform future neurofeedback protocols targeting simultaneous regulation of attention and stress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10093v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Neta Batya Maimon, Lior Molcho, Talya Zaimer, Ofir Chibotero, Nathan Intrator, Eliezer Yahalom</dc:creator>
    </item>
    <item>
      <title>The Evaluation of Breathing 5:5 effect on resilience, stress and balance center measured by Single-Channel EEG</title>
      <link>https://arxiv.org/abs/2507.10175</link>
      <description>arXiv:2507.10175v1 Announce Type: new 
Abstract: Slow-paced breathing is a promising intervention for reducing anxiety and enhancing emotional regulation through its effects on autonomic and central nervous system function. This study examined the neurophysiological and subjective effects of a 5:5 breathing protocol on stress-related EEG biomarkers using a mobile single-channel EEG system. Thirty-eight healthy adults were randomly assigned to either an intervention group (n = 20), which completed two sessions spaced two weeks apart with daily breathing practice, or a control group (n = 18), which completed one session. In each session, participants underwent an auditory EEG assessment with resting, mental load, and startle conditions. The intervention group also completed a guided breathing session during the first visit and practiced the technique between sessions. EEG biomarkers (ST4, Alpha, Delta, Gamma, VC0) and subjective anxiety levels (STAI) were assessed before and after the intervention. A significant reduction in Gamma power was observed in the intervention group immediately following the first breathing session during mental load (p = .002), indicating acute stress reduction. Across sessions, long-term breathing practice led to increased Alpha and Delta power and reduced ST4 activity, suggesting cumulative improvements in emotional regulation and cognitive efficiency. Correlational analyses revealed that changes in VC0 and Alpha were significantly associated with subjective reports of tension, focus difficulty, and calmness. Guided slow-paced breathing at a 5:5 rhythm produces both immediate and sustained effects on neural markers of stress and cognition, with corresponding improvements in subjective anxiety. These findings support EEG-based monitoring as a scalable method for evaluating breath-based interventions and promoting real-time emotional self-regulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10175v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eliezer Yahalom, Neta Maimon, Lior Molcho, Talya Zeimer, Ofir Chibotero, Nathan Intrator</dc:creator>
    </item>
    <item>
      <title>Beyond vividness: Content analysis of induced hallucinations reveals the hidden structure of individual differences in visual imagery</title>
      <link>https://arxiv.org/abs/2507.09011</link>
      <description>arXiv:2507.09011v1 Announce Type: cross 
Abstract: A rapidly alternating red and black display known as Ganzflicker induces visual hallucinations that reflect the generative capacity of the visual system. Recent proposals regarding the imagery spectrum, that is, differences in the visual system of individuals with absent imagery, typical imagery, and vivid imagery, suggest these differences should impact the complexity of other internally generated visual experiences. Here, we used tools from natural language processing to analyze free-text descriptions of hallucinations from over 4,000 participants, asking whether people with different imagery phenotypes see different things in their mind's eye during Ganzflicker-induced hallucinations. Strong imagers described complex, naturalistic content, while weak imagers reported simple geometric patterns. Embeddings from vision language models better captured these differences than text-only language models, and participants with stronger imagery used language with richer sensorimotor associations. These findings may reflect individual variation in coordination between early visual areas and higher-order regions relevant for the imagery spectrum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09011v1</guid>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ana Chkhaidze, Reshanne R. Reeder, Connor Gag, Anastasia Kiyonaga, Seana Coulson</dc:creator>
    </item>
    <item>
      <title>Algorithm Development in Neural Networks: Insights from the Streaming Parity Task</title>
      <link>https://arxiv.org/abs/2507.09897</link>
      <description>arXiv:2507.09897v1 Announce Type: cross 
Abstract: Even when massively overparameterized, deep neural networks show a remarkable ability to generalize. Research on this phenomenon has focused on generalization within distribution, via smooth interpolation. Yet in some settings neural networks also learn to extrapolate to data far beyond the bounds of the original training set, sometimes even allowing for infinite generalization, implying that an algorithm capable of solving the task has been learned. Here we undertake a case study of the learning dynamics of recurrent neural networks (RNNs) trained on the streaming parity task in order to develop an effective theory of algorithm development. The streaming parity task is a simple but nonlinear task defined on sequences up to arbitrary length. We show that, with sufficient finite training experience, RNNs exhibit a phase transition to perfect infinite generalization. Using an effective theory for the representational dynamics, we find an implicit representational merger effect which can be interpreted as the construction of a finite automaton that reproduces the task. Overall, our results disclose one mechanism by which neural networks can generalize infinitely from finite training experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09897v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Loek van Rossem, Andrew M. Saxe</dc:creator>
    </item>
    <item>
      <title>Leveraging Swin Transformer for enhanced diagnosis of Alzheimer's disease using multi-shell diffusion MRI</title>
      <link>https://arxiv.org/abs/2507.09996</link>
      <description>arXiv:2507.09996v1 Announce Type: cross 
Abstract: Objective: This study aims to support early diagnosis of Alzheimer's disease and detection of amyloid accumulation by leveraging the microstructural information available in multi-shell diffusion MRI (dMRI) data, using a vision transformer-based deep learning framework.
  Methods: We present a classification pipeline that employs the Swin Transformer, a hierarchical vision transformer model, on multi-shell dMRI data for the classification of Alzheimer's disease and amyloid presence. Key metrics from DTI and NODDI were extracted and projected onto 2D planes to enable transfer learning with ImageNet-pretrained models. To efficiently adapt the transformer to limited labeled neuroimaging data, we integrated Low-Rank Adaptation. We assessed the framework on diagnostic group prediction (cognitively normal, mild cognitive impairment, Alzheimer's disease dementia) and amyloid status classification.
  Results: The framework achieved competitive classification results within the scope of multi-shell dMRI-based features, with the best balanced accuracy of 95.2% for distinguishing cognitively normal individuals from those with Alzheimer's disease dementia using NODDI metrics. For amyloid detection, it reached 77.2% balanced accuracy in distinguishing amyloid-positive mild cognitive impairment/Alzheimer's disease dementia subjects from amyloid-negative cognitively normal subjects, and 67.9% for identifying amyloid-positive individuals among cognitively normal subjects. Grad-CAM-based explainability analysis identified clinically relevant brain regions, including the parahippocampal gyrus and hippocampus, as key contributors to model predictions.
  Conclusion: This study demonstrates the promise of diffusion MRI and transformer-based architectures for early detection of Alzheimer's disease and amyloid pathology, supporting biomarker-driven diagnostics in data-limited biomedical settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09996v1</guid>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quentin Dessain, Nicolas Delinte, Bernard Hanseeuw, Laurence Dricot, Beno\^it Macq</dc:creator>
    </item>
    <item>
      <title>Intrinsic frequency distribution characterises neural dynamics</title>
      <link>https://arxiv.org/abs/2507.10145</link>
      <description>arXiv:2507.10145v1 Announce Type: cross 
Abstract: Decomposing multivariate time series with certain basic dynamics is crucial for understanding, predicting and controlling nonlinear spatiotemporally dynamic systems such as the brain. Dynamic mode decomposition (DMD) is a method for decomposing nonlinear spatiotemporal dynamics into several basic dynamics (dynamic modes; DMs) with intrinsic frequencies and decay rates. In particular, unlike Fourier transform-based methods, which are used to decompose a single-channel signal into the amplitudes of sinusoidal waves with discrete frequencies at a regular interval, DMD can derive the intrinsic frequencies of a multichannel signal on the basis of the available data; furthermore, it can capture nonstationary components such as alternations between states with different intrinsic frequencies. Here, we propose the use of the distribution of intrinsic frequencies derived from DMDs (DM frequencies) to characterise neural activities. The distributions of DM frequencies in the electroencephalograms of healthy subjects and patients with dementia or Parkinson's disease in a resting state were evaluated. By using the distributions, these patients were distinguished from healthy subjects with significantly greater accuracy than when using amplitude spectra derived by discrete Fourier transform. This finding suggests that the distribution of DM frequencies exhibits distinct behaviour from amplitude spectra, and therefore, the distribution may serve as a new biomarker by characterising the nonlinear spatiotemporal dynamics of electrophysiological signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10145v1</guid>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryohei Fukuma, Yoshinobu Kawahara, Okito Yamashita, Kei Majima, Haruhiko Kishima, Takufumi Yanagisawa</dc:creator>
    </item>
    <item>
      <title>Dynamical stability for dense patterns in discrete attractor neural networks</title>
      <link>https://arxiv.org/abs/2507.10383</link>
      <description>arXiv:2507.10383v1 Announce Type: cross 
Abstract: Neural networks storing multiple discrete attractors are canonical models of biological memory. Previously, the dynamical stability of such networks could only be guaranteed under highly restrictive conditions. Here, we derive a theory of the local stability of discrete fixed points in a broad class of networks with graded neural activities and in the presence of noise. By directly analyzing the bulk and outliers of the Jacobian spectrum, we show that all fixed points are stable below a critical load that is distinct from the classical \textit{critical capacity} and depends on the statistics of neural activities in the fixed points as well as the single-neuron activation function. Our analysis highlights the computational benefits of threshold-linear activation and sparse-like patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10383v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Uri Cohen, M\'at\'e Lengyel</dc:creator>
    </item>
    <item>
      <title>A new mathematical model for brain memory working. Optimal control behavior for Hopfield networks</title>
      <link>https://arxiv.org/abs/2305.14360</link>
      <description>arXiv:2305.14360v5 Announce Type: replace 
Abstract: Recent works have highlighted the need for a new dynamical paradigm in the modeling of brain function and evolution. Specifically, these models should incorporate non-constant and asymmetric synaptic weights $T_{ij}$ in the neuron-neuron interaction matrix, moving beyond the classical Hopfield framework. Krotov and Hopfield proposed a non-constant yet symmetric model, resulting in a vector field that describes gradient-type dynamics, which includes a Lyapunov-like energy function. Firstly, we will outline the general conditions for generating a Hopfield-like vector field of gradient type, recovering the Krotov-Hopfield condition as a particular case. Secondly, we address the issue of symmetry, which we abandon for two key physiological reasons: (1) actual neural connections have a distinctly directional character (axons and dendrites), and (2) the gradient structure derived from symmetry forces the dynamics towards stationary points, leading for every pattern to a recognition or to a free association, if the equilibrium is rather far from the input. We propose a novel model that incorporates a set of limited but variable controls $|\xi_{ij}|\leq K$, which are used to adjust an initially constant interaction matrix, $T_{ij}=A_{ij}+\xi_{ij}$ according to a controlled variational functional. We simulate three potential outcomes when a pattern is submitted: (1) if the dynamics converges to an existing stationary point without activating controls, the system has \emph{recognized} an incoming pattern; (2) if a new stationary point is reached through control activation, the system has \emph{learned} a new pattern; and (3) if the dynamics \emph{wanders}, the system is unable to recognize or learn the submitted pattern. An additional feature (4) models the processes of \emph{forgetting and restoring} memory. Numerical simulations on a basic neural network model support the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.14360v5</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Franco Cardin, Alberto Lovison, Amos Maritan, Aram Megighian</dc:creator>
    </item>
    <item>
      <title>Bayesian Theory of Consciousness as Exchangeable Emotion-Cognition Inference</title>
      <link>https://arxiv.org/abs/2407.09488</link>
      <description>arXiv:2407.09488v3 Announce Type: replace 
Abstract: This paper proposes a unified framework in which consciousness emerges as a cycle-consistent, affectively anchored inference process, recursively structured by the interaction of emotion and cognition. Drawing from information theory, optimal transport, and the Bayesian brain hypothesis, we formalize emotion as a low-dimensional structural prior and cognition as a specificity-instantiating update. This emotion-cognition cycle minimizes joint uncertainty by aligning emotionally weighted priors with context-sensitive cognitive appraisals. Subjective experience thus arises as the informational footprint of temporally extended, affect-modulated simulation. We introduce the Exchangeable Integration Theory of Consciousness (EITC), modeling conscious episodes as conditionally exchangeable samples drawn from a latent affective self-model. This latent variable supports integration, via a unified cause-effect structure with nonzero irreducibility, and differentiation, by preserving contextual specificity across episodes. We connect this architecture to the Bayesian theory of consciousness through Rao-Blackwellized inference, which stabilizes inference by marginalizing latent self-structure while enabling adaptive updates. This mechanism ensures coherence, prevents inference collapse, and supports goal-directed simulation. The formal framework builds on De Finetti's exchangeability theorem, integrated information theory, and KL-regularized optimal transport. Overall, consciousness is reframed as a recursive inference process, shaped by emotion, refined by cognition, stabilized through exchangeability, and unified through a latent self-model that integrates experience across time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09488v3</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Xin Li</dc:creator>
    </item>
    <item>
      <title>Fairness, not Emotion, Drives Socioeconomic Decision Making</title>
      <link>https://arxiv.org/abs/2409.10322</link>
      <description>arXiv:2409.10322v2 Announce Type: replace 
Abstract: Emotion and fairness play a key role in mediating socioeconomic decisions in humans; however, the underlying neurocognitive mechanism remains largely unknown. This exploratory study unraveled the interplay between agents' emotions and the fairness of their monetary proposal in rational decision-making, backed by ERP analyses at a group as well as a strategic level. In a time-bound ultimatum-game paradigm, 40 participants were exposed to three distinct proposers' emotions (Happy, Neutral, Disgusted) followed by one of the three offer ranges (Low, Intermediate, High). Our findings show a robust influence of economic fairness on acceptance rates. A multilevel generalized linear model showed offer as the dominant predictor of trial-specific responses. Subsequent clustering grouped participants into five clusters, which the Drift Diffusion Model corroborates. Pertinent neural markers demonstrated the recognition of facial expressions; however, they had minimal effect during socioeconomic decision-making. Our study explores individualistic decision-making processes revealing different cognitive strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10322v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rudra Mukhopadhyay, Sourin Chatterjee, Koel Das</dc:creator>
    </item>
    <item>
      <title>Emergent functions of noise-driven spontaneous activity: Homeostatic maintenance of criticality and memory consolidation</title>
      <link>https://arxiv.org/abs/2502.10946</link>
      <description>arXiv:2502.10946v2 Announce Type: replace 
Abstract: Unlike digital computers, the brain exhibits spontaneous activity even during complete rest, despite the evolutionary pressure for energy efficiency. Inspired by the critical brain hypothesis, which proposes that the brain operates optimally near a critical point of phase transition in the dynamics of neural networks to improve computational efficiency, we postulate that spontaneous activity plays a homeostatic role in the development and maintenance of criticality. Criticality in the brain is associated with the balance between excitatory and inhibitory synaptic inputs (EI balance), which is essential for maintaining neural computation performance. Here, we hypothesize that both criticality and EI balance are stabilized by appropriate noise levels and spike-timing-dependent plasticity (STDP) windows. Using spiking neural network (SNN) simulations and in vitro experiments with dissociated neuronal cultures, we demonstrated that while repetitive stimuli transiently disrupt both criticality and EI balance, spontaneous activity can develop and maintain these properties and prolong the fading memory of past stimuli. Our findings suggest that the brain may achieve self-optimization and memory consolidation as emergent functions of noise-driven spontaneous activity. This noise-harnessing mechanism provides insights for designing energy-efficient neural networks, and may explain the critical function of sleep in maintaining homeostasis and consolidating memory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10946v2</guid>
      <category>q-bio.NC</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Narumitsu Ikeda, Dai Akita, Hirokazu Takahashi</dc:creator>
    </item>
    <item>
      <title>Distinct Modes of Functional Neural Organization in Autism: Insights from Dynamical Systems Analysis of Resting-State EEG</title>
      <link>https://arxiv.org/abs/2506.23013</link>
      <description>arXiv:2506.23013v2 Announce Type: replace 
Abstract: While differences in patterns of functional connectivity and neural synchronization have been reported between individuals on the autism spectrum and neurotypical peers at various age stages, these differences appear to be subtle and may not be captured by typical quantitative measures of EEG. We used the dynamical systems approach to analyze resting-state EEG to investigate fine-grained spatiotemporal organization of brain networks in autistic and neurotypical young adults. While power spectra showed minimal group differences, autistic participants exhibited higher Lyapunov exponents (indicating less stable neural dynamics), weaker phase synchronization, and lower clustering/efficiency of functional networks during eyes-open resting state, suggesting more random and less stably connected neural dynamics in comparison to those of neurotypical peers. Closing the eyes regularized neural dynamics in autistic but not neurotypical participants, with increases in synchrony strength, transient desynchronization patterning, and functional connectivity observed in the autistic group. The results point to the distinct modes of neural dynamics organization likely reflecting cumulative developmental adaptations to sensory inputs that shape both resting-state neural activity and cognitive processing strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23013v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.biopsycho.2025.109077</arxiv:DOI>
      <arxiv:journal_reference>Biological Psychology (2025), 199:109077</arxiv:journal_reference>
      <dc:creator>Sungwoo Ahn, Leonid L Rubchinsky, Evie A Malaia</dc:creator>
    </item>
  </channel>
</rss>
