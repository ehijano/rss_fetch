<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 Aug 2024 04:04:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The effects of data preprocessing on probability of default model fairness</title>
      <link>https://arxiv.org/abs/2408.15452</link>
      <description>arXiv:2408.15452v1 Announce Type: new 
Abstract: In the context of financial credit risk evaluation, the fairness of machine learning models has become a critical concern, especially given the potential for biased predictions that disproportionately affect certain demographic groups. This study investigates the impact of data preprocessing, with a specific focus on Truncated Singular Value Decomposition (SVD), on the fairness and performance of probability of default models. Using a comprehensive dataset sourced from Kaggle, various preprocessing techniques, including SVD, were applied to assess their effect on model accuracy, discriminatory power, and fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15452v1</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.30574/wjaets.2024.12.2.0354</arxiv:DOI>
      <dc:creator>Di Wu</dc:creator>
    </item>
    <item>
      <title>BayesSRW: Bayesian Sampling and Re-weighting approach for variance reduction</title>
      <link>https://arxiv.org/abs/2408.15454</link>
      <description>arXiv:2408.15454v1 Announce Type: new 
Abstract: In this paper, we address the challenge of sampling in scenarios where limited resources prevent exhaustive measurement across all subjects. We consider a setting where samples are drawn from multiple groups, each following a distribution with unknown mean and variance parameters. We introduce a novel sampling strategy, motivated simply by Cauchy-Schwarz inequality, which minimizes the variance of the population mean estimator by allocating samples proportionally to both the group size and the standard deviation. This approach improves the efficiency of sampling by focusing resources on groups with greater variability, thereby enhancing the precision of the overall estimate. Additionally, we extend our method to a two-stage sampling procedure in a Bayes approach, named BayesSRW, where a preliminary stage is used to estimate the variance, which then informs the optimal allocation of the remaining sampling budget. Through simulation examples, we demonstrate the effectiveness of our approach in reducing estimation uncertainty and providing more reliable insights in applications ranging from user experience surveys to high-dimensional peptide array studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15454v1</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carol Liu</dc:creator>
    </item>
    <item>
      <title>Marginal homogeneity tests with panel data</title>
      <link>https://arxiv.org/abs/2408.15862</link>
      <description>arXiv:2408.15862v1 Announce Type: new 
Abstract: A panel dataset satisfies marginal homogeneity if the time-specific marginal distributions are homogeneous or time-invariant. Marginal homogeneity is relevant in economic settings such as dynamic discrete games. In this paper, we propose several tests for the hypothesis of marginal homogeneity and investigate their properties. We consider an asymptotic framework in which the number of individuals n in the panel diverges, and the number of periods T is fixed. We implement our tests by comparing a studentized or non-studentized T-sample version of the Cramer-von Mises statistic with a suitable critical value. We propose three methods to construct the critical value: asymptotic approximations, the bootstrap, and time permutations. We show that the first two methods result in asymptotically exact hypothesis tests. The permutation test based on a non-studentized statistic is asymptotically exact when T=2, but is asymptotically invalid when T&gt;2. In contrast, the permutation test based on a studentized statistic is always asymptotically exact. Finally, under a time-exchangeability assumption, the permutation test is exact in finite samples, both with and without studentization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15862v1</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federico Bugni, Jackson Bunting, Muyang Ren</dc:creator>
    </item>
    <item>
      <title>Adapting to Misspecification</title>
      <link>https://arxiv.org/abs/2305.14265</link>
      <description>arXiv:2305.14265v4 Announce Type: replace 
Abstract: Empirical research typically involves a robustness-efficiency tradeoff. A researcher seeking to estimate a scalar parameter can invoke strong assumptions to motivate a restricted estimator that is precise but may be heavily biased, or they can relax some of these assumptions to motivate a more robust, but variable, unrestricted estimator. When a bound on the bias of the restricted estimator is available, it is optimal to shrink the unrestricted estimator towards the restricted estimator. For settings where a bound on the bias of the restricted estimator is unknown, we propose adaptive estimators that minimize the percentage increase in worst case risk relative to an oracle that knows the bound. We show that adaptive estimators solve a weighted convex minimax problem and provide lookup tables facilitating their rapid computation. Revisiting some well known empirical studies where questions of model specification arise, we examine the advantages of adapting to -- rather than testing for -- misspecification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.14265v4</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Timothy B. Armstrong, Patrick Kline, Liyang Sun</dc:creator>
    </item>
    <item>
      <title>Challenges in Statistically Rejecting the Perfect Competition Hypothesis Using Imperfect Competition Data</title>
      <link>https://arxiv.org/abs/2310.04576</link>
      <description>arXiv:2310.04576v4 Announce Type: replace 
Abstract: We theoretically prove why statistically rejecting the null hypothesis of perfect competition is challenging, known as a common problem in the literature. We also assess the finite sample performance of the conduct parameter test in homogeneous goods markets, showing that statistical power increases with the number of markets, a larger conduct parameter, and a stronger demand rotation instrument. However, even with a moderate number of markets and five firms, rejecting the null hypothesis of perfect competition remains difficult, irrespective of instrument strength or the use of optimal instruments. Our findings suggest that empirical results failing to reject perfect competition are due to the limited number of markets rather than methodological shortcomings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04576v4</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuri Matsumura, Suguru Otani</dc:creator>
    </item>
    <item>
      <title>Option Pricing with Time-Varying Volatility Risk Aversion</title>
      <link>https://arxiv.org/abs/2204.06943</link>
      <description>arXiv:2204.06943v3 Announce Type: replace-cross 
Abstract: We introduce a pricing kernel with time-varying volatility risk aversion that can explain the observed time variation in the shape of the pricing kernel. Dynamic volatility risk aversion, combined with the Heston-Nandi GARCH model, leads to a convenient option pricing model, denoted DHNG. The variance risk ratio emerges as a fundamental variable, and we show that it is closely related to economic fundamentals and common measures of sentiment and uncertainty. DHNG yields a closed-form pricing formula for the VIX, and we propose a novel approximation method that provides analytical expressions for option prices. We estimate the model using S&amp;P 500 returns, the VIX, and option prices, and find that dynamic volatility risk aversion leads to a substantial reduction in VIX and option pricing errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.06943v3</guid>
      <category>q-fin.PR</category>
      <category>econ.EM</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Reinhard Hansen, Chen Tong</dc:creator>
    </item>
    <item>
      <title>Measuring the Quality of Answers in Political Q&amp;As with Large Language Models</title>
      <link>https://arxiv.org/abs/2404.08816</link>
      <description>arXiv:2404.08816v2 Announce Type: replace-cross 
Abstract: This paper introduces a new approach for measuring the quality of answers in political question-and-answer sessions. We propose to measure answer quality based on the degree to which it allows to infer the initial question accurately. This measure of answer quality reflects how well the answer engages with and addresses the initial question. Drawing an analogy with semantic search, we demonstrate that this measurement approach can be implemented by fine-tuning a large language model on the corpus of observed questions and answers without additional labeled data. We showcase our approach within the context of the Question Period in the Canadian House of Commons, providing valuable insights into the correlates of answer quality. Our findings reveal significant variations in answer quality based on the party affiliation of the members of Parliament asking the question. Additionally, we find a meaningful correlation between answer quality and the topic raised in the question.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08816v2</guid>
      <category>cs.CL</category>
      <category>econ.EM</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>R. Michael Alvarez, Jacob Morrier</dc:creator>
    </item>
  </channel>
</rss>
