<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 11 Mar 2024 04:00:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 11 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Tractability Gap Beyond Nim-Sums: It's Hard to Tell Whether a Bunch of Superstars Are Losers</title>
      <link>https://arxiv.org/abs/2403.04955</link>
      <description>arXiv:2403.04955v1 Announce Type: new 
Abstract: In this paper, we address a natural question at the intersection of combinatorial game theory and computational complexity: "Can a sum of simple tepid games in canonical form be intractable?" To resolve this fundamental question, we consider superstars, positions first introduced in Winning Ways where all options are nimbers. Extending Morris' classic result with hot games to tepid games, we prove that disjunctive sums of superstars are intractable to solve. This is striking as sums of nimbers can be computed in linear time. Our analyses also lead to a family of elegant board games with intriguing complexity, for which we present web-playable versions of the rulesets described within.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04955v1</guid>
      <category>cs.CC</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyle Burke, Matthew Ferland, Svenja Huntemann, Shang-Hua Teng</dc:creator>
    </item>
    <item>
      <title>Quantum PCPs: on Adaptivity, Multiple Provers and Reductions to Local Hamiltonians</title>
      <link>https://arxiv.org/abs/2403.04841</link>
      <description>arXiv:2403.04841v1 Announce Type: cross 
Abstract: We define a general formulation of quantum PCPs, which captures adaptivity and multiple unentangled provers, and give a detailed construction of the quantum reduction to a local Hamiltonian with a constant promise gap. The reduction turns out to be a versatile subroutine to prove properties of quantum PCPs, allowing us to show: (i) Non-adaptive quantum PCPs can simulate adaptive quantum PCPs when the number of proof queries is constant. In fact, this can even be shown to hold when the non-adaptive quantum PCP picks the proof indices simply uniformly at random from a subset of all possible index combinations, answering an open question by Aharonov, Arad, Landau and Vazirani (STOC '09). (ii) If the $q$-local Hamiltonian problem with constant promise gap can be solved in $\mathsf{QCMA}$, then $\mathsf{QPCP}[q] \subseteq \mathsf{QCMA}$ for any $q \in O(1)$. (iii) If $\mathsf{QMA}(k)$ has a quantum PCP for any $k \leq \text{poly}(n)$, then $\mathsf{QMA}(2) = \mathsf{QMA}$, connecting two of the longest-standing open problems in quantum complexity theory. Moreover, we also show that there exists (quantum) oracles relative to which certain quantum PCP statements are false. Hence, any attempt to prove the quantum PCP conjecture requires, just as was the case for the classical PCP theorem, (quantumly) non-relativizing techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04841v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harry Buhrman, Jonas Helsen, Jordi Weggemans</dc:creator>
    </item>
    <item>
      <title>Single Family Algebra Operation on ZDDs Leads To Exponential Blow-Up</title>
      <link>https://arxiv.org/abs/2403.05074</link>
      <description>arXiv:2403.05074v1 Announce Type: cross 
Abstract: Zero-suppressed binary decision diagram (ZDD) is a data structure to represent a family of (sub)sets compactly, and it can be used as a succinct index for a family of sets. To build ZDD representing a desired family of sets, there are many transformation operations that take ZDDs as inputs and output ZDD representing the resultant family after performing operations such as set union and intersection. However, except for some basic operations, the worst-time complexity of taking such transformation on ZDDs has not been extensively studied, and some contradictory statements about it have arisen in the literature. In this paper, we show that many transformation operations on ZDDs cannot be performed in worst-case polynomial time with respect to the size of input ZDDs. This refutes some of the folklore circulated in past literature and resolves an open problem raised by Knuth. Our results are stronger in that such blow-up of computational time occurs even when the ordering, which has a significant impact on the efficiency of treating ZDDs, is reasonable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05074v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kengo Nakamura, Masaaki Nishino, Shuhei Denzumi</dc:creator>
    </item>
    <item>
      <title>On balanceable and simply balanceable regular graphs</title>
      <link>https://arxiv.org/abs/2403.05418</link>
      <description>arXiv:2403.05418v1 Announce Type: cross 
Abstract: We continue the study of balanceable graphs, defined by Caro, Hansberg, and Montejano in 2021 as graphs $G$ such that any $2$-coloring of the edges of a sufficiently large complete graph containing sufficiently many edges of each color contains a balanced copy of $G$. While the problem of recognizing balanceable graphs was conjectured to be NP-complete by Dailly, Hansberg, and Ventura in 2021, balanceable graphs admit an elegant combinatorial characterization: a graph is balanceable if and only there exist two vertex subsets, one containing half of all the graph's edges and another one such that the corresponding cut contains half of all the graph's edges. We consider a special case of this property, namely when one of the two sets is a vertex cover, and call the corresponding graphs simply balanceable. We prove a number of results on balanceable and simply balanceable regular graphs. First, we characterize simply balanceable regular graphs via a condition involving the independence number of the graph. Second, we address a question of Dailly, Hansberg, and Ventura from 2021 and show that every cubic graph is balanceable. Third, using Brooks' theorem, we show that every $4$-regular graph with order divisible by $4$ is balanceable. Finally, we show that it is NP-complete to determine if a $9$-regular graph is simply balanceable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05418v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Milad Ahanjideh, Martin Milani\v{c}, Mary Servatius</dc:creator>
    </item>
    <item>
      <title>Separation of PSPACE and EXP</title>
      <link>https://arxiv.org/abs/2104.14316</link>
      <description>arXiv:2104.14316v2 Announce Type: replace 
Abstract: This article shows that PSPACE not equal EXP. A simple but novel proof technique has been used to separate these two classes. Whether an arbitrary Turing machine accepts an input when the running time is limited has been computed in this paper. Then, the limit goes to infinity. Thus, methods of the recursion theory can be applied to problems of computational complexity theory without violating the relativization barrier.</description>
      <guid isPermaLink="false">oai:arXiv.org:2104.14316v2</guid>
      <category>cs.CC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Reiner Czerwinski</dc:creator>
    </item>
    <item>
      <title>Expected Complexity of Persistent Homology Computation via Matrix Reduction</title>
      <link>https://arxiv.org/abs/2111.02125</link>
      <description>arXiv:2111.02125v3 Announce Type: replace-cross 
Abstract: We study the algorithmic complexity of computing persistent homology of a randomly generated filtration. Specifically, we prove upper bounds for the average fill-in (number of non-zero entries) of the boundary matrix on \v{C}ech, Vietoris--Rips and Erd\H{o}s--R\'enyi filtrations after matrix reduction. Our bounds show that the reduced matrix is expected to be significantly sparser than what the general worst-case predicts. Our method is based on previous results on the expected Betti numbers of the corresponding complexes. We establish a link between these results and the fill-in of the boundary matrix. In the $1$-dimensional case, our bound for \v{C}ech and Vietoris--Rips complexes is asymptotically tight up to a logarithmic factor. We also provide an Erd\H{o}s--R\'enyi filtration realising the worst-case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.02125v3</guid>
      <category>math.AT</category>
      <category>cs.CC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Barbara Giunti, Guillaume Houry, Michael Kerber, Matthias S\"ols</dc:creator>
    </item>
  </channel>
</rss>
