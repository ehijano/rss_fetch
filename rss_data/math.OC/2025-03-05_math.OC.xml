<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Mar 2025 05:00:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Nonsmooth Optimisation and neural networks</title>
      <link>https://arxiv.org/abs/2503.01860</link>
      <description>arXiv:2503.01860v1 Announce Type: new 
Abstract: In this paper, we study neural networks from the point of view of nonsmooth optimisation, namely, quasidifferential calculus. We restrict ourselves to the case of uniform approximation by a neural network without hidden layers, the activation functions are restricted to continuous strictly increasing functions. We develop an algorithm for computing the approximation with one hidden layer through a step-by-step procedure. The nonsmooth analysis techniques demonstrated their efficiency. In particular, they partially explain why the developed step-by-step procedure may run without any objective function improvement after just one step of the procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01860v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vinesha Peiris, Nadezda Sukhorukova</dc:creator>
    </item>
    <item>
      <title>A spectral Levenberg-Marquardt-Deflation method for multiple solutions of semilinear elliptic systems</title>
      <link>https://arxiv.org/abs/2503.01912</link>
      <description>arXiv:2503.01912v1 Announce Type: new 
Abstract: Many nonlinear differential equations arising from practical problems may permit nontrivial multiple solutions relevant to applications, and these multiple solutions are helpful to deeply understand these practical problems and to improve some applications. Developing an efficient numerical method for finding multiple solutions is very necessary due to the nonlinearity and multiple solutions of these equations. Moreover, providing an efficient iteration plays an important role in successfully obtaining multiple solutions with fast and stable convergence. In the current paper, an efficient algorithm for finding multiple solutions of semilinear elliptic systems is proposed, where the trust region Levenberg-Marquardt method is firstly used to iterate the resulted nonlinear algebraic system. When the nonlinear term in these equations has only the first derivative, our algorithm can efficiently find multiple solutions as well. Several numerical experiments are tested to show the efficiency of our algorithm, and some solutions which have not been shown in the literature are also found and shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01912v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lin Li, Yuheng Zhou, Pengcheng Xie, Huiyuan Li</dc:creator>
    </item>
    <item>
      <title>Distributed and Localized Covariance Control of Coupled Systems: A System Level Approach</title>
      <link>https://arxiv.org/abs/2503.02094</link>
      <description>arXiv:2503.02094v1 Announce Type: new 
Abstract: This work is concerned with the finite-horizon optimal covariance steering of networked systems governed by discrete-time stochastic linear dynamics. In contrast with existing work that has only considered systems with dynamically decoupled agents, we consider a dynamically coupled system composed of interconnected subsystems subject to local communication constraints. In particular, we propose a distributed algorithm to compute the localized optimal feedback control policy for each individual subsystem, which depends only on the local state histories of its neighboring subsystems. Utilizing the system-level synthesis (SLS) framework, we first recast the localized covariance steering problem as a convex SLS problem with locality constraints. Subsequently, exploiting its partially separable structure, we decompose the latter problem into smaller subproblems, introducing a transformation to deal with nonseparable instances. Finally, we employ a variation of the consensus alternating direction method of multipliers (ADMM) to distribute computation across subsystems on account of their local information and communication constraints. We demonstrate the effectiveness of our proposed algorithm on a power system with 36 interconnected subsystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02094v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Khalil, Yoonjae Lee, Efstathios Bakolas</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Fact Checking</title>
      <link>https://arxiv.org/abs/2503.02116</link>
      <description>arXiv:2503.02116v1 Announce Type: new 
Abstract: We formulate the problem of fake news detection using distributed fact-checkers (agents) with unknown reliability. The stream of news/statements is modeled as an independent and identically distributed binary source (to represent true and false statements). Upon observing a news, agent $i$ labels the news as true or false which reflects the true validity of the statement with some probability $1-\pi_i$. In other words, agent $i$ misclassified each statement with error probability $\pi_i\in (0,1)$, where the parameter $\pi_i$ models the (un)trustworthiness of agent $i$. We present an algorithm to learn the unreliability parameters, resulting in a distributed fact-checking algorithm. Furthermore, we extensively analyze the discrete-time limit of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02116v1</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashwin Verma, Soheil Mohajer, Behrouz Touri</dc:creator>
    </item>
    <item>
      <title>Nonconvex optimization and convergence of stochastic gradient descent, and solution of asynchronous game</title>
      <link>https://arxiv.org/abs/2503.02155</link>
      <description>arXiv:2503.02155v1 Announce Type: new 
Abstract: We review convergence and behavior of stochastic gradient descent for convex and nonconvex optimization, establishing various conditions for convergence to zero of the variance of the gradient of the objective function, and presenting a number of simple examples demonstrating the approximate evolution of the probability density under iteration, including applications to both classical two-player and asynchronous multiplayer games</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02155v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin Buck, Jessica Babyak, Paolo Piersanti, Kevin Zumbrun, Christiane Gallos, Dorothea Gallos</dc:creator>
    </item>
    <item>
      <title>Sharpness-Aware Minimization: General Analysis and Improved Rates</title>
      <link>https://arxiv.org/abs/2503.02225</link>
      <description>arXiv:2503.02225v1 Announce Type: new 
Abstract: Sharpness-Aware Minimization (SAM) has emerged as a powerful method for improving generalization in machine learning models by minimizing the sharpness of the loss landscape. However, despite its success, several important questions regarding the convergence properties of SAM in non-convex settings are still open, including the benefits of using normalization in the update rule, the dependence of the analysis on the restrictive bounded variance assumption, and the convergence guarantees under different sampling strategies. To address these questions, in this paper, we provide a unified analysis of SAM and its unnormalized variant (USAM) under one single flexible update rule (Unified SAM), and we present convergence results of the new algorithm under a relaxed and more natural assumption on the stochastic noise. Our analysis provides convergence guarantees for SAM under different step size selections for non-convex problems and functions that satisfy the Polyak-Lojasiewicz (PL) condition (a non-convex generalization of strongly convex functions). The proposed theory holds under the arbitrary sampling paradigm, which includes importance sampling as special case, allowing us to analyze variants of SAM that were never explicitly considered in the literature. Experiments validate the theoretical findings and further demonstrate the practical effectiveness of Unified SAM in training deep neural networks for image classification tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02225v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitris Oikonomou, Nicolas Loizou</dc:creator>
    </item>
    <item>
      <title>Regularized higher-order Taylor approximation methods for nonlinear least-squares</title>
      <link>https://arxiv.org/abs/2503.02370</link>
      <description>arXiv:2503.02370v1 Announce Type: new 
Abstract: In this paper, we develop a regularized higher-order Taylor based method for solving composite (e.g., nonlinear least-squares) problems. At each iteration, we replace each smooth component of the objective function by a higher-order Taylor approximation with an appropriate regularization, leading to a regularized higher-order Taylor approximation (RHOTA) algorithm. We derive global convergence guarantees for RHOTA algorithm. In particular, we prove stationary point convergence guarantees for the iterates generated by RHOTA, and leveraging a Kurdyka-{\L}ojasiewicz (KL) type property of the objective function, we derive improved rates depending on the KL parameter. When the Taylor approximation is of order $2$, we present an efficient implementation of RHOTA algorithm, demonstrating that the resulting nonconvex subproblem can be effectively solved utilizing standard convex programming tools. Furthermore, we extend the scope of our investigation to include the behavior and efficacy of RHOTA algorithm in handling systems of nonlinear equations and optimization problems with nonlinear equality constraints deriving new rates under improved constraint qualifications conditions. Finally, we consider solving the phase retrieval problem with a higher-order proximal point algorithm, showcasing its rapid convergence rate for this particular application. Numerical simulations on phase retrieval and output feedback control problems also demonstrate the efficacy and performance of the proposed methods when compared to some state-of-the-art optimization methods and software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02370v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yassine Nabou, Ion Necoara</dc:creator>
    </item>
    <item>
      <title>Pseudo-concave optimization of the first eigenvalue of elliptic operators with application to topology optimization by homogenization</title>
      <link>https://arxiv.org/abs/2503.02391</link>
      <description>arXiv:2503.02391v1 Announce Type: new 
Abstract: We consider optimization problems of the first eigenvalue of linear elliptic operators. It has an application to a two-phase optimal design problem (also known as topology optimization problem) relaxed by the homogenization method. Under certain assumptions, we show that the first eigenvalue is a pseudo-concave function with respect to the density-like parameter and apply the result to optimal design problems of conductivity and elasticity. Due to pseudo-concavity, every stationary point is a global optimal solution for a maximization problem, and there exists a solution that is an extreme point (corresponding to a 0-1 design) for a minimization problem. In numerical experiments, we demonstrate that a global optimal solution or a 0-1 solution can be obtained by a simple projected gradient method. These problems can be used as benchmark problems to test heuristic topology optimization methods used in engineering. The 80-line FreeFEM code is provided in the appendix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02391v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akatsuki Nishioka</dc:creator>
    </item>
    <item>
      <title>The Distributionally Robust Optimization Model of Sparse Principal Component Analysis</title>
      <link>https://arxiv.org/abs/2503.02494</link>
      <description>arXiv:2503.02494v1 Announce Type: new 
Abstract: We consider sparse principal component analysis (PCA) under a stochastic setting where the underlying probability distribution of the random parameter is uncertain. This problem is formulated as a distributionally robust optimization (DRO) model based on a constructive approach to capturing uncertainty in the covariance matrix, which constitutes a nonsmooth constrained min-max optimization problem. We further prove that the inner maximization problem admits a closed-form solution, reformulating the original DRO model into an equivalent minimization problem on the Stiefel manifold. This transformation leads to a Riemannian optimization problem with intricate nonsmooth terms, a challenging formulation beyond the reach of existing algorithms. To address this issue, we devise an efficient smoothing manifold proximal gradient algorithm. We prove the Riemannian gradient consistency and global convergence of our algorithm to a stationary point of the nonsmooth minimization problem. Moreover, we establish the iteration complexity of our algorithm. Finally, numerical experiments are conducted to validate the effectiveness and scalability of our algorithm, as well as to highlight the necessity and rationality of adopting the DRO model for sparse PCA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02494v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Wang, Xin Liu, Xiaojun Chen</dc:creator>
    </item>
    <item>
      <title>On the optimal stopping problem for diffusions and an approximation result for stopping times</title>
      <link>https://arxiv.org/abs/2503.02514</link>
      <description>arXiv:2503.02514v1 Announce Type: new 
Abstract: In this article, we study the classical finite-horizon optimal stopping problem for multidimensional diffusions through an approach that differs from what is typically found in the literature. More specifically, we first prove a key equality for the value function from which a series of results easily follow. This equality enables us to prove that the classical stopping time, at which the value function equals the terminal gain, is the smallest optimal stopping time, without resorting to the martingale approach and relying on the Snell envelope. Moreover, this equality allows us to rigorously demonstrate the dynamic programming principle, thus showing that the value function is the viscosity solution to the corresponding variational inequality. Such an equality also shows that the value function does not change when the class of stopping times varies. To prove this equality, we use an approximation result for stopping times, which is of independent interest and can find application in other stochastic control problems involving stopping times, as switching or impulsive problems, also of mean field type.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02514v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Cosso, Laura Perelli</dc:creator>
    </item>
    <item>
      <title>On damping a control system on a star graph with global time-proportional delay</title>
      <link>https://arxiv.org/abs/2503.02522</link>
      <description>arXiv:2503.02522v1 Announce Type: new 
Abstract: We consider the problem of damping a control system with delay, described by first-order functional-differential equations on a temporal star graph. The delay in the system is time-proportional and propagates through the internal vertex. We study the variational problem of minimizing the energy functional, taking into account the probabilities the of scenarios corresponding to different edges. It is established that the optimal trajectory satisfies Kirchhoff-type conditions at the internal vertex. The equivalence of the variational problem to a certain boundary value problem for second-order functional-differential equations on the graph is proved, and the unique solvability of both problems is established.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02522v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. P. Lednov</dc:creator>
    </item>
    <item>
      <title>Unique existence of solution and Hyers-Ulam stability for a new fractional differential quasi-variational inequality with Mittag-Leffler kernel and its applications</title>
      <link>https://arxiv.org/abs/2503.02669</link>
      <description>arXiv:2503.02669v1 Announce Type: new 
Abstract: This paper considers a new fractional differential quasi-variational inequality with Mittag-Leffler kernel comprising a fractional differential equation with Mittag-Leffler kernel and a quasi-variational inequality in Hilbert spaces. Some properties of the solution for the parameterized quasi-variational inequality are investigated, which improve the known results. Moreover, the unique existence of the solution and Hyers-Ulam stability are obtained for such a novel system under mild conditions. Finally, the obtained abstract results are applied to analyze the unique solvability and stability for a multi-agent optimization problem and a price control problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02669v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeng-bao Wu, Quan-guo Zhang, Tao Chen, Yue Zeng, Nan-jing Huang, Yi-bin Xiao</dc:creator>
    </item>
    <item>
      <title>Deterministic Global Optimization over trained Kolmogorov Arnold Networks</title>
      <link>https://arxiv.org/abs/2503.02807</link>
      <description>arXiv:2503.02807v1 Announce Type: new 
Abstract: To address the challenge of tractability for optimizing mathematical models in science and engineering, surrogate models are often employed. Recently, a new class of machine learning models named Kolmogorov Arnold Networks (KANs) have been proposed. It was reported that KANs can approximate a given input/output relationship with a high level of accuracy, requiring significantly fewer parameters than multilayer perceptrons. Hence, we aim to assess the suitability of deterministic global optimization of trained KANs by proposing their Mixed-Integer Nonlinear Programming (MINLP) formulation. We conduct extensive computational experiments for different KAN architectures. Additionally, we propose alternative convex hull reformulation, local support and redundant constraints for the formulation aimed at improving the effectiveness of the MINLP formulation of the KAN. KANs demonstrate high accuracy while requiring relatively modest computational effort to optimize them, particularly for cases with less than five inputs or outputs. For cases with higher inputs or outputs, carefully considering the KAN architecture during training may improve its effectiveness while optimizing over a trained KAN. Overall, we observe that KANs offer a promising alternative as surrogate models for deterministic global optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02807v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tanuj Karia, Giacomo Lastrucci, Artur M. Schweidtmann</dc:creator>
    </item>
    <item>
      <title>Tracking Control of Euler-Lagrangian Systems with Prescribed State, Input, and Temporal Constraints</title>
      <link>https://arxiv.org/abs/2503.01866</link>
      <description>arXiv:2503.01866v1 Announce Type: cross 
Abstract: The synthesis of a smooth tracking control policy for Euler-Lagrangian (EL) systems with stringent regions of operation induced by state, input and temporal (SIT) constraints is a very challenging task. Most existing solutions rely on prior information of the parameters of the nominal EL dynamics together with bounds on system uncertainty, and incorporate either state or input constraints to guarantee tracking error convergence in a prescribed settling time. Contrary to these approaches, this study proposes an approximation-free adaptive barrier function-based control policy for achieving local prescribed-time convergence of the tracking error to a prescribed-bound in the presence of state and input constraints. This is achieved by imposing time-varying bounds on the filtered tracking error to confine the states within their respective bounds, while also incorporating a saturation function to limit the magnitude of the proposed control action that leverages smooth time-based generator functions for ensuring tracking error convergence within the prescribed-time. Importantly, corresponding feasibility conditions pertaining to the minimum control authority, maximum disturbance rejection capability of the control policy, and the viable set of initial conditions are derived, illuminating the narrow operating domain of the EL systems arising from the interplay of SIT constraints. Numerical validation studies with three different robotic manipulators are employed to demonstrate the efficacy of the proposed scheme. A detailed performance comparison study with leading alternative designs is also undertaken to illustrate the superior performance of the proposed scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01866v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chidre Shravista Kashyap, Pushpak Jagtap, Jishnu Keshavan</dc:creator>
    </item>
    <item>
      <title>Policy iteration for nonconvex viscous Hamilton--Jacobi equations</title>
      <link>https://arxiv.org/abs/2503.02159</link>
      <description>arXiv:2503.02159v1 Announce Type: cross 
Abstract: We study the convergence rates of policy iteration (PI) for nonconvex viscous Hamilton--Jacobi equations using a discrete space-time scheme, where both space and time variables are discretized. We analyze the case with an uncontrolled diffusion term, which corresponds to a possibly degenerate viscous Hamilton--Jacobi equation. We first obtain an exponential convergent result of PI for the discrete space-time schemes. We then investigate the discretization error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02159v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoqin Guo, Hung Vinh Tran, Yuming Paul Zhang</dc:creator>
    </item>
    <item>
      <title>From Data to Uncertainty Sets: a Machine Learning Approach</title>
      <link>https://arxiv.org/abs/2503.02173</link>
      <description>arXiv:2503.02173v1 Announce Type: cross 
Abstract: Existing approaches of prescriptive analytics -- where inputs of an optimization model can be predicted by leveraging covariates in a machine learning model -- often attempt to optimize the mean value of an uncertain objective. However, when applied to uncertain constraints, these methods rarely work because satisfying a crucial constraint in expectation may result in a high probability of violation. To remedy this, we leverage robust optimization to protect a constraint against the uncertainty of a machine learning model's output. To do so, we design an uncertainty set based on the model's loss function. Intuitively, this approach attempts to minimize the uncertainty around a prediction. Extending guarantees from the robust optimization literature, we derive strong guarantees on the probability of violation. On synthetic computational experiments, our method requires uncertainty sets with radii up to one order of magnitude smaller than those of other approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02173v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitris Bertsimas, Benjamin Boucher</dc:creator>
    </item>
    <item>
      <title>Deficient Excitation in Parameter Learning</title>
      <link>https://arxiv.org/abs/2503.02235</link>
      <description>arXiv:2503.02235v1 Announce Type: cross 
Abstract: This paper investigates parameter learning problems under deficient excitation (DE). The DE condition is a rank-deficient, and therefore, a more general evolution of the well-known persistent excitation condition. Under the DE condition, a proposed online algorithm is able to calculate the identifiable and non-identifiable subspaces, and finally give an optimal parameter estimate in the sense of least squares. In particular, the learning error within the identifiable subspace exponentially converges to zero in the noise-free case, even without persistent excitation. The DE condition also provides a new perspective for solving distributed parameter learning problems, where the challenge is posed by local regressors that are often insufficiently excited. To improve knowledge of the unknown parameters, a cooperative learning protocol is proposed for a group of estimators that collect measured information under complementary DE conditions. This protocol allows each local estimator to operate locally in its identifiable subspace, and reach a consensus with neighbours in its non-identifiable subspace. As a result, the task of estimating unknown parameters can be achieved in a distributed way using cooperative local estimators. Application examples in system identification are given to demonstrate the effectiveness of the theoretical results developed in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02235v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ganghui Cao, Shimin Wang, Martin Guay, Jinzhi Wang, Zhisheng Duan, Marios M. Polycarpou</dc:creator>
    </item>
    <item>
      <title>Multi-Partite Output Regulation of Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2503.02313</link>
      <description>arXiv:2503.02313v1 Announce Type: cross 
Abstract: This article proposes a simple, graph-independent perspective on partitioning the node set of a graph and provides multi-agent systems (MASs) with objectives beyond cooperation and bipartition. Specifically, we first introduce the notion of $k$-partition transformation to achieve any desired partition of the nodes. Then, we use this notion to formulate the multi-partite output regulation problem (MORP) of heterogeneous linear MASs, which comprises the existing cooperative output regulation problem (CORP) and bipartite output regulation problem (BORP) as subcases. The goal of the MORP is to design a distributed control law such that each follower that belongs to the same set in the partition asymptotically tracks a predefined multiple of a reference while ensuring the internal stability of the closed-loop system. It is shown that the necessary and sufficient conditions for the solvability of the MORP with a feedforward-based distributed control law follow from the CORP and lead to the first design strategy for the control parameters. However, it has a drawback in terms of scalability due to a partition-dependent condition. We prove that this condition is implied by its partition-independent version under a mild structural condition. This implication yields the second design strategy that is much more scalable than the first one. Finally, numerical examples are provided to illustrate the generality of the MORP and compare both design strategies regarding scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02313v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K\"ur\c{s}ad Metehan G\"ul, Selahattin Burak Sars{\i}lmaz</dc:creator>
    </item>
    <item>
      <title>Goat Optimization Algorithm: A Novel Bio-Inspired Metaheuristic for Global Optimization</title>
      <link>https://arxiv.org/abs/2503.02331</link>
      <description>arXiv:2503.02331v1 Announce Type: cross 
Abstract: This paper presents the Goat Optimization Algorithm (GOA), a novel bio-inspired metaheuristic optimization technique inspired by goats' adaptive foraging, strategic movement, and parasite avoidance behaviors.GOA is designed to balance exploration and exploitation effectively by incorporating three key mechanisms, adaptive foraging for global search, movement toward the best solution for local refinement, and a jump strategy to escape local optima.A solution filtering mechanism is introduced to enhance robustness and maintain population diversity. The algorithm's performance is evaluated on standard unimodal and multimodal benchmark functions, demonstrating significant improvements over existing metaheuristics, including Particle Swarm Optimization (PSO), Grey Wolf Optimizer (GWO), Genetic Algorithm (GA), Whale Optimization Algorithm (WOA), and Artificial Bee Colony (ABC). Comparative analysis highlights GOA's superior convergence rate, enhanced global search capability, and higher solution accuracy.A Wilcoxon rank-sum test confirms the statistical significance of GOA's exceptional performance. Despite its efficiency, computational complexity and parameter sensitivity remain areas for further optimization. Future research will focus on adaptive parameter tuning, hybridization with other metaheuristics, and real-world applications in supply chain management, bioinformatics, and energy optimization. The findings suggest that GOA is a promising advancement in bio-inspired optimization techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02331v1</guid>
      <category>cs.NE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hamed Nozari, Hoessein Abdi, Agnieszka Szmelter-Jarosz</dc:creator>
    </item>
    <item>
      <title>Hamilton-Jacobi-Bellman Equations in the Wasserstein Space for the Optimal Control of the Kushner-Stratonovich Equation</title>
      <link>https://arxiv.org/abs/2503.02654</link>
      <description>arXiv:2503.02654v1 Announce Type: cross 
Abstract: This paper develops a comparison theorem for viscosity solutions of a new class of Hamilton-Jacobi-Bellman (HJB) equations, which is used to solve the separated problem governed by the K-S equation in the Wasserstein space. A distinctive feature of these HJB equations is the simultaneous presence of variational and Lions derivatives, an inevitable consequence of a nonzero observation function. Moreover, the presence of state-dependent correlated noise adds further complexity to the analysis, making the proof of the comparison theorem more challenging. The core proof strategy for the comparison theorem is to introduce a novel adaptation of the doubling variables argument, specifically tailored to tackle the challenges posed by the Wasserstein space. To this end, we construct an entirely new bivariate functional that combines viscosity sub/supsolutions, a smooth gauge-type function, and two Gaussian regularized entropy penalizations. The gauge-type function compensates for the non-differentiability (in the Lions sense) of the 2-Wasserstein distance, while the entropy penalizations ensure that the maximal point of the functional is well-behaved. Another major contribution of this paper is the derivation of the second-order variational and Lions derivatives of the gauge-type function and entropy functional, which are crucial for dealing with the second-order HJB equation. Meanwhile, the simple structure and pleasing regularity of these derivatives make the methodologies developed in this paper applicable within a wider range of theoretical settings. This paper gives the first result concerning the uniqueness of viscosity solutions for second-order HJB equations with variational derivatives in the Wasserstein space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02654v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hexiang Wan, Jie Xiong</dc:creator>
    </item>
    <item>
      <title>Weakly-Constrained 4D Var for Downscaling with Uncertainty using Data-Driven Surrogate Models</title>
      <link>https://arxiv.org/abs/2503.02665</link>
      <description>arXiv:2503.02665v1 Announce Type: cross 
Abstract: Dynamic downscaling typically involves using numerical weather prediction (NWP) solvers to refine coarse data to higher spatial resolutions. Data-driven models such as FourCastNet have emerged as a promising alternative to the traditional NWP models for forecasting. Once these models are trained, they are capable of delivering forecasts in a few seconds, thousands of times faster compared to classical NWP models. However, as the lead times, and, therefore, their forecast window, increase, these models show instability in that they tend to diverge from reality. In this paper, we propose to use data assimilation approaches to stabilize them when used for downscaling tasks. Data assimilation uses information from three different sources, namely an imperfect computational model based on partial differential equations (PDE), from noisy observations, and from an uncertainty-reflecting prior. In this work, when carrying out dynamic downscaling, we replace the computationally expensive PDE-based NWP models with FourCastNet in a ``weak-constrained 4DVar framework" that accounts for the implied model errors. We demonstrate the efficacy of this approach for a hurricane-tracking problem; moreover, the 4DVar framework naturally allows the expression and quantification of uncertainty. We demonstrate, using ERA5 data, that our approach performs better than the ensemble Kalman filter (EnKF) and the unstabilized FourCastNet model, both in terms of forecast accuracy and forecast uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02665v1</guid>
      <category>physics.ao-ph</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philip Dinenis, Vishwas Rao, Mihai Anitescu</dc:creator>
    </item>
    <item>
      <title>On Separation Between Best-Iterate, Random-Iterate, and Last-Iterate Convergence of Learning in Games</title>
      <link>https://arxiv.org/abs/2503.02825</link>
      <description>arXiv:2503.02825v1 Announce Type: cross 
Abstract: Non-ergodic convergence of learning dynamics in games is widely studied recently because of its importance in both theory and practice. Recent work (Cai et al., 2024) showed that a broad class of learning dynamics, including Optimistic Multiplicative Weights Update (OMWU), can exhibit arbitrarily slow last-iterate convergence even in simple $2 \times 2$ matrix games, despite many of these dynamics being known to converge asymptotically in the last iterate. It remains unclear, however, whether these algorithms achieve fast non-ergodic convergence under weaker criteria, such as best-iterate convergence. We show that for $2\times 2$ matrix games, OMWU achieves an $O(T^{-1/6})$ best-iterate convergence rate, in stark contrast to its slow last-iterate convergence in the same class of games. Furthermore, we establish a lower bound showing that OMWU does not achieve any polynomial random-iterate convergence rate, measured by the expected duality gaps across all iterates. This result challenges the conventional wisdom that random-iterate convergence is essentially equivalent to best-iterate convergence, with the former often used as a proxy for establishing the latter. Our analysis uncovers a new connection to dynamic regret and presents a novel two-phase approach to best-iterate convergence, which could be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02825v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Gabriele Farina, Julien Grand-Cl\'ement, Christian Kroer, Chung-Wei Lee, Haipeng Luo, Weiqiang Zheng</dc:creator>
    </item>
    <item>
      <title>On the nature of Bregman functions</title>
      <link>https://arxiv.org/abs/2302.02689</link>
      <description>arXiv:2302.02689v2 Announce Type: replace 
Abstract: Let C be convex, compact, with nonempty interior and h be Legendre with domain C, continuous on C. We prove that h is Bregman if and only if it is strictly convex on C and C is a polytope. This provides insights on sequential convergence of many Bregman divergence based algorithm: abstract compatibility conditions between Bregman and Euclidean topology may equivalently be replaced by explicit conditions on h and C. This also emphasizes that a general convergence theory for these methods (beyond polyhedral domains) would require more refinements than Bregman's conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.02689v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.orl.2024.107183</arxiv:DOI>
      <arxiv:journal_reference>Operations Research Letters, 2024, 57, pp.107183</arxiv:journal_reference>
      <dc:creator>Edouard Pauwels (TSE-R)</dc:creator>
    </item>
    <item>
      <title>A Scalable Approach to Equitable Facility Location</title>
      <link>https://arxiv.org/abs/2401.15452</link>
      <description>arXiv:2401.15452v3 Announce Type: replace 
Abstract: Achieving equitable access to essential services, such as healthcare, food, and education, is a critical goal in urban planning and public policy. However, existing facility location models primarily focus on optimizing average accessibility, often neglecting equity concerns, particularly for disadvantaged populations. This paper proposes a novel, scalable framework for equitable facility location, introducing a linearized proxy for the Kolm-Pollak Equally-Distributed Equivalent (EDE) metric to balance efficiency and fairness. Extensive computational experiments demonstrate that, unlike other facility location models that incorporate measures of equity, our approach scales to extremely large problem instances. Optimal solutions represent significant improvements for the worst-off residents in terms of distance to an open amenity, while also attaining a near-optimal average experience for all users. Two real-world case studies -- supermarket access and polling location access -- illustrate the practical applicability of the framework. Furthermore, the model is extended to handle real-world considerations such as capacity constraints, split demand assignments, and location-specific penalties. By bridging the gap between equity theory and practical optimization, this work offers a robust and versatile tool for researchers and practitioners in urban planning, transportation, and public policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15452v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Drew Horton, Tom Logan, Joshua Murrell, Daphne Skipper, Emily Speakman</dc:creator>
    </item>
    <item>
      <title>Stochastic Polyak Step-sizes and Momentum: Convergence Guarantees and Practical Performance</title>
      <link>https://arxiv.org/abs/2406.04142</link>
      <description>arXiv:2406.04142v2 Announce Type: replace 
Abstract: Stochastic gradient descent with momentum, also known as Stochastic Heavy Ball method (SHB), is one of the most popular algorithms for solving large-scale stochastic optimization problems in various machine learning tasks. In practical scenarios, tuning the step-size and momentum parameters of the method is a prohibitively expensive and time-consuming process. In this work, inspired by the recent advantages of stochastic Polyak step-size in the performance of stochastic gradient descent (SGD), we propose and explore new Polyak-type variants suitable for the update rule of the SHB method. In particular, using the Iterate Moving Average (IMA) viewpoint of SHB, we propose and analyze three novel step-size selections: MomSPS$_{\max}$, MomDecSPS, and MomAdaSPS. For MomSPS$_{\max}$, we provide convergence guarantees for SHB to a neighborhood of the solution for convex and smooth problems (without assuming interpolation). If interpolation is also satisfied, then using MomSPS$_{\max}$, SHB converges to the true solution at a fast rate matching the deterministic HB. The other two variants, MomDecSPS and MomAdaSPS, are the first adaptive step-size for SHB that guarantee convergence to the exact minimizer - without a priori knowledge of the problem parameters and without assuming interpolation. Our convergence analysis of SHB is tight and obtains the convergence guarantees of stochastic Polyak step-size for SGD as a special case. We supplement our analysis with experiments validating our theory and demonstrating the effectiveness and robustness of our algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04142v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dimitris Oikonomou, Nicolas Loizou</dc:creator>
    </item>
    <item>
      <title>Continuation Method for Nonsmooth Model Predictive Control Using Proximal Technique</title>
      <link>https://arxiv.org/abs/2409.14944</link>
      <description>arXiv:2409.14944v2 Announce Type: replace 
Abstract: This paper presents a novel framework for the continuation method of model predictive control based on optimal control problem with a nonsmooth regularizer. Via the proximal operator, the first-order optimality inclusion relation is reformulated into an equation system, to which the continuation method is applicable. In addition, we present constraint qualifications that ensure the well-posedness of the proposed equation system. A numerical example is also presented that demonstrates the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14944v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryotaro Shima, Ryuta Moriyasu, Teruki Kato</dc:creator>
    </item>
    <item>
      <title>Accelerating Reductions Using Graph Neural Networks and a New Concurrent Local Search for the Maximum Weight Independent Set Problem</title>
      <link>https://arxiv.org/abs/2412.14198</link>
      <description>arXiv:2412.14198v2 Announce Type: replace 
Abstract: The Maximum Weight Independent Set problem is a fundamental NP-hard problem in combinatorial optimization with several real-world applications. Given an undirected vertex-weighted graph, the problem is to find a subset of the vertices with the highest possible weight under the constraint that no two vertices in the set can share an edge. An important part of solving this problem in both theory and practice is data reduction rules, which several state-of-the-art algorithms rely on. However, the most complicated rules are often not used in applications since the time needed to check them exhaustively becomes infeasible. In this work, we introduce three main results. First, we introduce several new data reduction rules and evaluate their effectiveness on real-world data. Second, we use a machine learning screening algorithm to speed up the reduction phase, thereby enabling more complicated rules to be applied. Our screening algorithm consults a Graph Neural Network oracle to decide if the probability of successfully reducing the graph is sufficiently large. For this task, we provide a dataset of labeled vertices for use in supervised learning. We also present the first results for this dataset using established Graph Neural Network architectures. Third, we present a new concurrent metaheuristic called Concurrent Difference-Core Heuristic. On the reduced instances, we use our new metaheuristic combined with iterated local search, called CHILS (Concurrent Hybrid Iterated Local Search). For this iterated local search, we provide a new implementation specifically designed to handle large graphs of varying densities. CHILS outperforms the current state-of-the-art on all commonly used benchmark instances, especially the largest ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14198v2</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ernestine Gro{\ss}mann, Kenneth Langedal, Christian Schulz</dc:creator>
    </item>
    <item>
      <title>A Stochastic Newton-type Method for Non-smooth Optimization</title>
      <link>https://arxiv.org/abs/2502.21078</link>
      <description>arXiv:2502.21078v2 Announce Type: replace 
Abstract: We introduce a new framework for analyzing (Quasi-}Newton type methods applied to non-smooth optimization problems. The source of randomness comes from the evaluation of the (approximation) of the Hessian. We derive, using a variant of Chernoff bounds for stopping times, expectation and probability bounds for the random variable representing the number of iterations of the algorithm until approximate first order optimality conditions are validated. As an important distinction to previous results in the literature, we do not require that the estimator is unbiased or that it has finite variance. We then showcase our theoretical results in a stochastic Quasi-Newton method for X-ray free electron laser orbital tomography and in a sketched Newton method for image denoising.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21078v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Titus Pinta</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Nonconvex Sweeping Processes with Variable Time via Finite-Difference Approximations</title>
      <link>https://arxiv.org/abs/2503.00667</link>
      <description>arXiv:2503.00667v2 Announce Type: replace 
Abstract: The paper is devoted to the study of a new class of optimal control problems for nonsmooth dynamical systems governed by nonconvex discontinuous differential inclusions of the sweeping type with involving variable time into optimization. We develop a novel version of the method of discrete approximations of its own qualitative and numerical importance with establishing its well-posedness and strong convergence to optimal solutions of the controlled sweeping process. Using advanced tools of variational analysis and generalized differentiation leads us to deriving new necessary conditions for optimal solutions to discrete approximation problems, which serve as suboptimality conditions for the original continuous-time controlled sweeping process. The obtained results are applied to a class of motion models of practical interest, where the established necessary conditions are used to investigate the agents' interactions and to develop an algorithm for calculating optimal solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00667v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tan H. Cao, Boris S. Mordukhovich, Dao Nguyen, Trang Nguyen, Nguyen N. Thieu</dc:creator>
    </item>
    <item>
      <title>Learning a convex cost-to-go for single step model predictive control</title>
      <link>https://arxiv.org/abs/2312.02650</link>
      <description>arXiv:2312.02650v3 Announce Type: replace-cross 
Abstract: For large uncertain systems, solving model predictive control problems online can be computationally taxing. Using a shorter prediction horizon can help, but may lead to poor performance and instability without appropriate modifications. This work focuses on learning convex objective terms to enable a single-step control horizon, reducing online computational costs. We consider two surrogates for approximating the cost-to-go: (1) a convex interpolating function and (2) an input-convex neural network. Regardless of the surrogate choice, its behavior near the origin and its ability to describe the feasible region are crucial for the closed-loop performance of the new MPC problem. We address this by tailoring the surrogate to ensure good performance in both aspects. We conclude with numerical examples, in which we compare the convex surrogates to using a standard neural network in the objective, solely using an LQR cost-to-go, and to using a neural network to learn a control policy. The proposed approaches are shown to achieve better performance with less data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02650v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>E. M. Turan, Z. Mdoe, J. J\"aschke</dc:creator>
    </item>
    <item>
      <title>A Pontryagin Maximum Principle for agent-based models with convex state space</title>
      <link>https://arxiv.org/abs/2402.13680</link>
      <description>arXiv:2402.13680v2 Announce Type: replace-cross 
Abstract: We derive a first order optimality condition for a class of agent-based systems, as well as for their mean-field counterpart. A relevant difficulty of our analysis is that the state equation is formulated on possibly infinite-dimensional convex subsets of Banach spaces. This is a typical feature of many problems in multi-population dynamics, where a convex set of probability measures may account for the population, the degree of influence or the strategy attached to each agent. Due to the lack of a linear structure and of local compactness, the usual tools of needle variations and linearisation procedures used to derive Pontryagin type conditions have to be generalised to the setting at hand. This is done by considering suitable notions of differentials and by a careful inspection of the underlying functional structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13680v2</guid>
      <category>math.AP</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1051/cocv/2025025</arxiv:DOI>
      <dc:creator>Stefano Almi, Riccardo Durastanti, Francesco Solombrino</dc:creator>
    </item>
    <item>
      <title>Discrete GCBF Proximal Policy Optimization for Multi-agent Safe Optimal Control</title>
      <link>https://arxiv.org/abs/2502.03640</link>
      <description>arXiv:2502.03640v2 Announce Type: replace-cross 
Abstract: Control policies that can achieve high task performance and satisfy safety constraints are desirable for any system, including multi-agent systems (MAS). One promising technique for ensuring the safety of MAS is distributed control barrier functions (CBF). However, it is difficult to design distributed CBF-based policies for MAS that can tackle unknown discrete-time dynamics, partial observability, changing neighborhoods, and input constraints, especially when a distributed high-performance nominal policy that can achieve the task is unavailable. To tackle these challenges, we propose DGPPO, a new framework that simultaneously learns both a discrete graph CBF which handles neighborhood changes and input constraints, and a distributed high-performance safe policy for MAS with unknown discrete-time dynamics. We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that, compared with existing methods, our DGPPO framework obtains policies that achieve high task performance (matching baselines that ignore the safety constraints), and high safety rates (matching the most conservative baselines), with a constant set of hyperparameters across all environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03640v2</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Songyuan Zhang, Oswin So, Mitchell Black, Chuchu Fan</dc:creator>
    </item>
    <item>
      <title>Aligned Multi Objective Optimization</title>
      <link>https://arxiv.org/abs/2502.14096</link>
      <description>arXiv:2502.14096v2 Announce Type: replace-cross 
Abstract: To date, the multi-objective optimization literature has mainly focused on conflicting objectives, studying the Pareto front, or requiring users to balance tradeoffs. Yet, in machine learning practice, there are many scenarios where such conflict does not take place. Recent findings from multi-task learning, reinforcement learning, and LLMs training show that diverse related tasks can enhance performance across objectives simultaneously. Despite this evidence, such phenomenon has not been examined from an optimization perspective. This leads to a lack of generic gradient-based methods that can scale to scenarios with a large number of related objectives. To address this gap, we introduce the Aligned Multi-Objective Optimization framework, propose new algorithms for this setting, and provide theoretical guarantees of their superior performance compared to naive approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14096v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yonathan Efroni (Bill), Ben Kretzu (Bill), Daniel Jiang (Bill), Jalaj Bhandari (Bill),  Zheqing (Bill),  Zhu, Karen Ullrich</dc:creator>
    </item>
  </channel>
</rss>
