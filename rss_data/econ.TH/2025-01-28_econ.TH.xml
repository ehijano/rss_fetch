<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 Jan 2025 05:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Meaningful, Useful and Legitimate Information in the Use of Index Numbers for Decision Making</title>
      <link>https://arxiv.org/abs/2501.14810</link>
      <description>arXiv:2501.14810v1 Announce Type: new 
Abstract: Often information relevant to a decision is summarized in an index number. This paper explores conditions under which conclusions using index numbers are relevant to the decision that needs to be made. Specifically it explores the idea that a statement using scales of measurement is meaningful in the sense that its truth or falsity does not depend on an arbitrary choice of parameters; the concept that a conclusion using index numbers is useful for the specific decision that needs to be made; and the notion that such a conclusion is legitimate in the sense that it is collected and used in a way that satisfies cultural, historical, organizational and legal constraints. While meaningfulness is a precisely defined concept, usefulness and legitimacy are not, and the paper explores properties of these concepts that lay the groundwork for making them more precise. Many examples involving two well-known and widely-used index numbers, body mass indices and air pollution indices, are used to explore the properties of and interrelationships among meaningfulness, usefulness, and legitimacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14810v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fred Roberts, Helen Roberts, Alexis Tsouki\`as</dc:creator>
    </item>
    <item>
      <title>Welfare Modeling with AI as Economic Agents: A Game-Theoretic and Behavioral Approach</title>
      <link>https://arxiv.org/abs/2501.15317</link>
      <description>arXiv:2501.15317v1 Announce Type: new 
Abstract: The integration of artificial intelligence (AI) into economic systems represents a transformative shift in decision-making frameworks, introducing novel dynamics between human and AI agents. This paper proposes a welfare model that incorporates both game-theoretic and behavioral dimensions to optimize interactions within human-AI ecosystems. By leveraging agent-based modeling (ABM), we simulate these interactions, accounting for trust evolution, perceived risks, and cognitive costs. The framework redefines welfare as the aggregate utility of interactions, adjusted for collaboration synergies, efficiency penalties, and equity considerations. Dynamic trust is modeled using Bayesian updating mechanisms, while synergies between agents are quantified through a collaboration index rooted in cooperative game theory. Results reveal that trust-building and skill development are pivotal to maximizing welfare, while sensitivity analyses highlight the trade-offs between AI complexity, equity, and efficiency. This research provides actionable insights for policymakers and system designers, emphasizing the importance of equitable AI adoption and fostering sustainable human-AI collaborations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15317v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sheyan Lalmohammed</dc:creator>
    </item>
    <item>
      <title>TTC Domains</title>
      <link>https://arxiv.org/abs/2501.15422</link>
      <description>arXiv:2501.15422v1 Announce Type: new 
Abstract: We study the classical object reallocation problem under strict preferences, with a focus on characterizing "TTC domains" -- preference domains on which the Top Trading Cycles (TTC) mechanism is the unique mechanism satisfying individual rationality, Pareto efficiency, and strategyproofness. We introduce a sufficient condition for a domain to be a TTC domain, which we call the top-two condition. This condition requires that, within any subset of objects, if two objects can each be most-preferred, they can also be the top-two most-preferred objects (in both possible orders). A weaker version of this condition, applying only to subsets of size three, is shown to be necessary. These results provide a complete characterization of TTC domains for the case of three objects, unify prior studies on specific domains such as single-peaked and single-dipped preferences, and classify several previously unexplored domains as TTC domains or not.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15422v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sumit Goel, Yuki Tamura</dc:creator>
    </item>
    <item>
      <title>Rationalizable Behavior in the Hotelling Model with Waiting Costs</title>
      <link>https://arxiv.org/abs/2501.15545</link>
      <description>arXiv:2501.15545v1 Announce Type: new 
Abstract: This paper revisits the Hotelling model with waiting costs Kohlberg (1983), focusing on two specific settings where pure Nash equilibria do not exist: the asymmetric model with two firms and the symmetric model with three firms. In the asymmetric two-firm model, we show that the weaker concept of point rationalizability has strong predictive power, as it selects exactly two locations for both firms. As the two firms become more similar in their efficiency in handling queues of consumers, the two point rationalizable locations converge towards the center of the line. In the symmetric three-firm model, the set of point rationalizable choices forms an interval. This interval is shrinking in the inefficiency levels of the firms in handling queues of consumers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15545v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joep van Sloun</dc:creator>
    </item>
    <item>
      <title>Rationalizability and Monotonocity in Games with Incomplete Information</title>
      <link>https://arxiv.org/abs/2501.15548</link>
      <description>arXiv:2501.15548v1 Announce Type: new 
Abstract: This paper examines games with strategic complements or substitutes and incomplete information, where players are uncertain about the opponents' parameters. We assume that the players' beliefs about the opponent's parameters are selected from some given set of beliefs. One extreme is the case where these sets only contain a single belief, representing a scenario where the players' actual beliefs about the parameters are commonly known among the players. Another extreme is the situation where these sets contain all possible beliefs, representing a scenario where the players have no information about the opponents' beliefs about parameters. But we also allow for intermediate cases, where these sets contain some, but not all, possible beliefs about the parameters. We introduce an assumption of weakly increasing differences that takes both the choice belief and parameter belief of a player into account. Under this assumption, we demonstrate that greater choice-parameter beliefs leads to greater optimal choices. Moreover, we show that the greatest and least point rationalizable choice of a player is increasing in their parameter, and these can be determined through an iterative procedure. In each round of the iterative procedure, the lowest surviving choice is optimal for the lowest choice-parameter belief, while the greatest surviving choice is optimal for the highest choice-parameter belief.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15548v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joep van Sloun</dc:creator>
    </item>
    <item>
      <title>Efficient Lower Bounding of Single Transferable Vote Election Margins</title>
      <link>https://arxiv.org/abs/2501.14847</link>
      <description>arXiv:2501.14847v1 Announce Type: cross 
Abstract: The single transferable vote (STV) is a system of preferential proportional voting employed in multi-seat elections. Each ballot cast by a voter is a (potentially partial) ranking over a set of candidates. The margin of victory, or simply margin, is the smallest number of ballots that, if manipulated (e.g., their rankings changed, or ballots being deleted or added), can alter the set of winners. Knowledge of the margin of an election gives greater insight into both how much time and money should be spent on auditing the election, and whether uncovered mistakes (such as ballot box losses) throw the election result into doubt -- requiring a costly repeat election -- or can be safely ignored. Lower bounds on the margin can also be used for this purpose, in cases where exact margins are difficult to compute. There is one existing approach to computing lower bounds on the margin of STV elections, while there are multiple approaches to finding upper bounds. In this paper, we present improvements to this existing lower bound computation method for STV margins. In many cases the improvements compute tighter (higher) lower bounds as well as making the computation of lower bounds more computationally efficient. For small elections, in conjunction with existing upper bounding approaches, the new algorithms are able to compute exact margins of victory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14847v1</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <category>econ.TH</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michelle Blom, Alexander Ek, Peter J. Stuckey, Vanessa Teague, Damjan Vukcevic</dc:creator>
    </item>
    <item>
      <title>Heterogeneous Noise and Stable Miscoordination</title>
      <link>https://arxiv.org/abs/2305.10301</link>
      <description>arXiv:2305.10301v2 Announce Type: replace 
Abstract: Coordination games admit two types of equilibria: pure equilibria, where all players successfully coordinate their actions, and mixed equilibria, where players frequently experience miscoordination. The existing literature shows that under many evolutionary dynamics, populations converge to a pure equilibrium from almost any initial distribution of actions. By contrast, we show that under plausible learning dynamics, where agents observe the actions of a random sample of their opponents and adjust their strategies accordingly, stable miscoordination can arise when there is heterogeneity in the sample sizes. This occurs when some agents make decisions based on small samples (anecdotal evidence) while others rely on large samples. Finally, we demonstrate the empirical relevance of our results in a bargaining application.
  Final pre-print of a manuscript accepted for publication in American Economic Journal: Microeconomics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.10301v2</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Srinivas Arigapudi, Yuval Heller, Amnon Schreiber</dc:creator>
    </item>
    <item>
      <title>City formation by dual migration of firms and workers</title>
      <link>https://arxiv.org/abs/2311.05292</link>
      <description>arXiv:2311.05292v4 Announce Type: replace 
Abstract: This paper studies a mathematical model of city formation by migration of firms and workers. The Core-Periphery model in the new economic geography, which considers migration of workers driven by real wage inequality among regions, is extended to incorporate migration of firms driven by real profit inequality among regions. Spatially homogeneous distributions of firms and workers become destabilized and eventually forms several cities in which both the firms and workers agglomerate, and the number of the cities decreases as transport costs become lower.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05292v4</guid>
      <category>econ.TH</category>
      <category>math.DS</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kensuke Ohtake</dc:creator>
    </item>
    <item>
      <title>The Strong Maximum Circulation Algorithm: A New Method for Aggregating Preference Rankings</title>
      <link>https://arxiv.org/abs/2307.15702</link>
      <description>arXiv:2307.15702v4 Announce Type: replace-cross 
Abstract: We present a new optimization-based method for aggregating preferences in settings where each voter expresses preferences over pairs of alternatives. Our approach to identifying a consensus partial order is motivated by the observation that collections of votes that form a cycle can be treated as collective ties. Our approach then removes unions of cycles of votes, or circulations, from the vote graph and determines aggregate preferences from the remainder. Specifically, we study the removal of maximal circulations attained by any union of cycles the removal of which leaves an acyclic graph. We introduce the strong maximum circulation, the removal of which guarantees a unique outcome in terms of the induced partial order, called the strong partial order. The strong maximum circulation also satisfies strong complementary slackness conditions, and is shown to be solved efficiently as a network flow problem. We further establish the relationship between the dual of the maximum circulation problem and Kemeny's method, a popular optimization-based approach for preference aggregation. We also show that identifying a minimum maximal circulation -- i.e., a maximal circulation containing the smallest number of votes -- is an NP-hard problem. Further an instance of the minimum maximal circulation may have multiple optimal solutions whose removal results in conflicting partial orders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15702v4</guid>
      <category>cs.SI</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 28 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan Atkinson, Scott C. Ganz, Dorit S. Hochbaum, James B. Orlin</dc:creator>
    </item>
  </channel>
</rss>
