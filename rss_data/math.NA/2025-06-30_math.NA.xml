<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 01 Jul 2025 04:02:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The lightning method for the heat equation</title>
      <link>https://arxiv.org/abs/2506.22576</link>
      <description>arXiv:2506.22576v1 Announce Type: new 
Abstract: This paper introduces a new method for solving the planar heat equation based on the Lightning Method. The lightning method is a recent development in the numerical solution of linear PDEs which expresses solutions using sums of polynomials and rational functions, or more generally as sums of fundamental solutions. The method is particularly well suited to handle domains with sharp corners where solution singularities are present. Boundary conditions are formed on a set of collocation points which is then solved as an overdetermined linear system. The approach of the present work is to utilize the Laplace transform to obtain a modified Helmholtz equation which is solved by an application of the lightning method. The numerical inversion of the Laplace transform is then performed by means of Talbot integration. Our validation of the method against existing results and multiple challenging test problems shows the method attains spectral accuracy with root-exponential convergence while being robust across a wide range of time intervals and adaptable to a variety of geometric scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22576v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.CV</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hunter L Croix, Alan E. Lindsay</dc:creator>
    </item>
    <item>
      <title>Error Estimates for the Arnoldi Approximation of a Matrix Square Root</title>
      <link>https://arxiv.org/abs/2506.22615</link>
      <description>arXiv:2506.22615v1 Announce Type: new 
Abstract: The Arnoldi process provides an efficient framework for approximating functions of a matrix applied to a vector, i.e., of the form $f(M)\mathbf{b}$, by repeated matrix-vector multiplications. In this paper, we derive an \textit{a priori} error estimate for approximating the action of a matrix square root using the Arnoldi process, where the integral representation of the error is reformulated in terms of the error for solving the linear system $M\mathbf{x}=\mathbf{b}$. The results extend the error analysis of the Lanczos method for Hermitian matrices in [Chen et al., SIAM J. Matrix Anal. Appl., 2022] to non-Hermitian cases. Furthermore, to make the method applicable to large-scale problems, we assume that the matrices are preprocessed utilizing data-sparse approximations preserving positive definiteness, and then establish a refined error bound in this setting. The numerical results on matrices with different structures demonstrate that our theoretical analysis yields a reliable upper bound. Finally, simulations on large-scale matrices arising in particulate suspensions validate the effectiveness and practicality of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22615v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James H. Adler, Xiaozhe Hu, Wenxiao Pan, Zhongqin Xue</dc:creator>
    </item>
    <item>
      <title>A Class of Stochastic Runge-Kutta Methods for Stochastic Differential Equations Converging with Order 1 in $L^p$-Norm</title>
      <link>https://arxiv.org/abs/2506.22657</link>
      <description>arXiv:2506.22657v1 Announce Type: new 
Abstract: For the approximation of solutions for It\^o and Stratonovich stochastic differential equations (SDEs)a new class of efficient stochastic Runge-Kutta (SRK) methods is developed. As the main novelty only two stages are necessary for the proposed SRK methods of order 1 that can be applied to SDEs with non-commutative or with commutative noise. In addition, a variant of the SRK method for SDEs with additive noise is presented. All proposed SRK methods cover also the case of drift-implicit schemes and general order conditions for the coefficients are calculated explicitly. The new class of SRK methods is highly efficient in the sense that it features computational cost depending only linearly on the dimension of the SDE and on the dimension of the driving Wiener process. For all proposed SRK methods strong convergence with order 1 in $L^p$-norm for any $p \geq 2$ is proved. Moreover, sufficient conditions for approximated iterated stochastic integrals are established such that convergence with order 1 in $L^p$-norm is preserved if they are applied for the SRK method. The presented theoretical results are confirmed by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22657v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas R\"o{\ss}ler</dc:creator>
    </item>
    <item>
      <title>Hybrid Explicit-Implicit Predictor-Corrector Exponential Time-Differencing Multistep Pad\'{e} Schemes for Semilinear Parabolic Equations with Time-Delay</title>
      <link>https://arxiv.org/abs/2506.22664</link>
      <description>arXiv:2506.22664v1 Announce Type: new 
Abstract: In this paper, we propose and analyze ETD-Multistep-Pad\'{e} (ETD-MS-Pad\'{e}) and ETD Implicit Multistep-Pad\'{e} (ETD-IMS-Pad\'{e}) for semilinear parabolic delay differential equations with smooth solutions. In our previous work [15], we proposed ETD-RK-Pad\'{e} scheme to compute high-order numerical solutions for nonlinear parabolic reaction-diffusion equation with constant time delay. However, the based ETD-RK numerical scheme in [15] is very complex and the corresponding calculation program is also very complicated. We propose in this paper ETD-MS-Pad\'{e} and ETD-IMS-Pad\'{e} schemes for the solution of semilinear parabolic equations with delay. We synergize the ETD-MS-Pad\'{e} with ETD-IMS-Pad\'{e} to construct efficient predictor-corrector scheme. This new predictor-corrector scheme will become an important tool for solving the numerical solutions of parabolic differential equations. Remarkably, we also conducted experiments in Table$10$ to compare the numerical results of the predictor-corrector scheme with the EERK scheme proposed in paper [42]. The predictor-corrector scheme demonstrated better convergence.
  The main idea is to employ an ETD-based Adams multistep extrapolation for the time integration of the corresponding equation. To overcome the well-known numerical instability associated with computing the exponential operator, we utilize the Pad\'{e} approach to approximate this exponential operator. This methodology leads to the development of the ETD-MS-Pad\'{e} and ETD-IMS-Pad\'{e} schemes, applicable even for arbitrary time orders. We validate the ETD-MS1,2,3,4-Pad\'{e} schemes and ETD-IMS2,3,4 schemes through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22664v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haishen Dai, Huan Lei</dc:creator>
    </item>
    <item>
      <title>A new sparsity promoting residual transform operator for Lasso regression</title>
      <link>https://arxiv.org/abs/2506.22689</link>
      <description>arXiv:2506.22689v1 Announce Type: new 
Abstract: Lasso regression is a widely employed approach within the $\ell_1$ regularization framework used to promote sparsity and recover piecewise smooth signals $f:[a,b) \rightarrow \mathbb{R}$ when the given observations are obtained from noisy, blurred, and/or incomplete data environments. In choosing the regularizing sparsity-promoting operator, it is assumed that the particular type of variability of the underlying signal, for example, piecewise constant or piecewise linear behavior across the entire domain, is both known and fixed. Such an assumption is problematic in more general cases, e.g.~when a signal exhibits piecewise oscillatory behavior with varying wavelengths and magnitudes. To address the limitations of assuming a fixed (and typically low order) variability when choosing a sparsity-promoting operator, this investigation proposes a novel residual transform operator that can be used within the Lasso regression formulation. In a nutshell, the idea is that for a general piecewise smooth signal $f$, it is possible to design two operators $\mathcal L_1$ and $\mathcal L_2$ such that $\mathcal L_1{\boldsymbol f} \approx \mathcal L_2{\boldsymbol f}$, where ${\boldsymbol f} \in \mathbb{R}^n$ is a discretized approximation of $f$, but $\mathcal L_1 \not\approx \mathcal L_2$. The corresponding residual transform operator, $\mathcal L = \mathcal L_1- \mathcal L_2$, yields a result that (1) effectively reduces the variability dependent error that occurs when applying either $\mathcal L_1$ or $\mathcal L_2$ to ${\boldsymbol f}$, a property that holds even when $\mathcal L_1{\boldsymbol f} \approx \mathcal L_2{\boldsymbol f}$ is not a good approximation to the true sparse domain vector of ${\boldsymbol f}$, and (2) does not require $\mathcal L_1$ or $\mathcal L_2$ to have prior information regarding the variability of the underlying signal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22689v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yao Xiao, Anne Gelb, Aditya Viswanathan</dc:creator>
    </item>
    <item>
      <title>A Novel Adaptive Low-Rank Matrix Approximation Method for Image Compression and Reconstruction</title>
      <link>https://arxiv.org/abs/2506.22713</link>
      <description>arXiv:2506.22713v1 Announce Type: new 
Abstract: Low-rank matrix approximation plays an important role in various applications such as image processing, signal processing and data analysis. The existing methods require a guess of the ranks of matrices that represent images or involve additional costs to determine the ranks. A novel efficient orthogonal decomposition with automatic basis extraction (EOD-ABE) is proposed to compute the optimal low-rank matrix approximation with adaptive identification of the optimal rank. By introducing a randomized basis extraction mechanism, EOD-ABE eliminates the need for additional rank determination steps and can compute a rank-revealing approximation to a low-rank matrix. With a computational complexity of $O(mnr)$, where $m$ and $n$ are the dimensions of the matrix and $r$ is its rank, EOD-ABE achieves significant speedups compared to the state-of-the-art methods. Experimental results demonstrate the superior speed, accuracy and robustness of EOD-ABE and indicate that EOD-ABE is a powerful tool for fast image compression and reconstruction and hyperspectral image dimensionality reduction in large-scale applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22713v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiwei Xu, Weijie Shen, Chang Liu, Zhigang Jia</dc:creator>
    </item>
    <item>
      <title>Long-time error estimate and decay of finite element method to a generalized viscoelastic flow</title>
      <link>https://arxiv.org/abs/2506.22782</link>
      <description>arXiv:2506.22782v1 Announce Type: new 
Abstract: This work analyzes the finite element approximation to a viscoelastic flow model, which generalizes the Navier-Stokes equation and Oldroyd's model by introducing the tempered power-law memory kernel. We prove regularity and long-time exponential decay of the solutions, as well as a long-time convolution-type Gr\"onwall inequality to support numerical analysis. A Volterra-Stokes projection is developed and analyzed to facilitate the parabolic-type duality argument, leading to the long-time error estimates and exponential decay of velocity and pressure. A benchmark problem of planar four-to-one contraction flow is simulated to substantiate the generality of the proposed model in comparison with the Navier-Stokes equation and Oldroyd's model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22782v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingwen Guo, Yinnian He, Wenlin Qiu, Xiangcheng Zheng</dc:creator>
    </item>
    <item>
      <title>A Chimera domain decomposition method with weak Dirichlet-Robin coupling for finite element simulation of particulate flows</title>
      <link>https://arxiv.org/abs/2506.22831</link>
      <description>arXiv:2506.22831v1 Announce Type: new 
Abstract: We introduce a new multimesh finite element method for direct numerical simulation of incompressible particulate flows. The proposed approach falls into the category of overlapping domain decomposition / Chimera / overset grid meshes. In addition to calculating the velocity and pressure of the fictitious fluid on a fixed background mesh, we solve the incompressible Navier-Stokes equations on body-fitted submeshes that are attached to moving particles. The submesh velocity and pressure are used to calculate the hydrodynamic forces and torques acting on the particles. The coupling with the background velocity and pressure is enforced via (i) Robin-type boundary conditions for an Arbitrary-Lagrangian-Eulerian (ALE) formulation of the submesh problems and (ii) a Dirichlet-type distributed interior penalty term in the weak form of the background mesh problem. The implementation of the weak Dirichlet-Robin coupling is discussed in the context of discrete projection methods and finite element discretizations. Detailed numerical studies are performed for standard test problems involving fixed and moving immersed objects. A comparison of Chimera results with those produced by fictitious boundary methods illustrates significant gains in the accuracy of drag and lift approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22831v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raphael M\"unster, Otto Mierka, Dmitri Kuzmin, Stefan Turek</dc:creator>
    </item>
    <item>
      <title>A Dilation-based Seamless Multiscale Method For Elliptic Problems</title>
      <link>https://arxiv.org/abs/2506.22912</link>
      <description>arXiv:2506.22912v1 Announce Type: new 
Abstract: Many numerical methods for multiscale differential equations require a scale separation between the larger and the smaller scales to achieve accuracy and computational efficiency. In the area of multiscale dynamical systems, so-called, seamless methods have been introduced to reduce the requirement of scale separation. We will translate these methods to numerical homogenization problems and extend the technique to multiple dimensions. The initial step is to prove that a one-dimensional \sepia{second-order} elliptic operator with oscillatory coefficients can be rewritten as a multiscale dynamical system. Inspired by this, multiscale elliptic operators in higher dimensions are approximated by a novel approach based on local dilation, which provides a middle ground for balancing intractability and accuracy without the need for full resolution. The dilation operator can be further generalized to preserve important structures by properly decomposing the coefficient field. Error estimates are developed and promising numerical results of different examples are included.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22912v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1137/24M1668755</arxiv:DOI>
      <arxiv:journal_reference>Multiscale Modeling &amp; Simulation 23.2 (2025): 1036-1061</arxiv:journal_reference>
      <dc:creator>Ziheng Chen, Bj\"orn Engquist</dc:creator>
    </item>
    <item>
      <title>An approximation theory for Markov chain compression</title>
      <link>https://arxiv.org/abs/2506.22918</link>
      <description>arXiv:2506.22918v1 Announce Type: new 
Abstract: We develop a framework for the compression of reversible Markov chains with rigorous error control. Given a subset of selected states, we construct reduced dynamics that can be lifted to an approximation of the full dynamics, and we prove simple spectral and nuclear norm bounds on the recovery error in terms of a suitably interpreted Nystr\"{o}m approximation error. We introduce two compression schemes: a projective compression based on committor functions and a structure-preserving compression defined in terms of an induced Markov chain over the selected states. The Nystr\"{o}m error appearing in our bounds can be controlled using recent results on column subset selection by nuclear maximization. Numerical experiments validate our theory and demonstrate the scalability of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22918v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark Fornace, Michael Lindsey</dc:creator>
    </item>
    <item>
      <title>PML method for the time-domain stochastic acoustic wave equation and an inverse source problem</title>
      <link>https://arxiv.org/abs/2506.23084</link>
      <description>arXiv:2506.23084v1 Announce Type: new 
Abstract: In this paper, we develop and analyze a time-domain perfectly matched layer (PML) method for the stochastic acoustic wave equation driven by spatially white additive Gaussian noise. We begin by establishing the well-posedness and stability of the direct problem through a rigorous analysis of the associated time-harmonic stochastic Helmholtz equation and the application of an abstract Laplace transform inversion theorem. To address the low regularity of the random source, we employ scattering theory to investigate the meromorphic continuation of the Helmholtz resolvent defined on rough fields. Based on a piecewise constant approximation of the white noise, we construct an approximate wave solution and formulate a time-domain PML method. The convergence of the PML method is established, with explicit dependence on the PML layer's thickness and medium properties, as well as the piecewise constant approximation of the white noise. In addition, we propose a frequency-domain approach for solving the inverse random source problem using time-domain boundary measurements. A logarithmic stability estimate is derived, highlighting the ill-posedness of the inverse problem and offering guidance for the design of effective numerical schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23084v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongxia Guo, Tianjiao Wang, Xiang Xu, Yue Zhao</dc:creator>
    </item>
    <item>
      <title>A residual driven multiscale method for Darcy's flow in perforated domains</title>
      <link>https://arxiv.org/abs/2506.23093</link>
      <description>arXiv:2506.23093v1 Announce Type: new 
Abstract: In this paper, we present a residual-driven multiscale method for simulating Darcy flow in perforated domains, where complex geometries and highly heterogeneous permeability make direct simulations computationally expensive. To address this, we introduce a velocity elimination technique that reformulates the mixed velocity-pressure system into a pressure-only formulation, significantly reducing complexity by focusing on the dominant pressure variable. Our method is developed within the Generalized Multiscale Finite Element Method (GMsFEM) framework. For each coarse block, we construct offline basis functions from local spectral problems that capture key geometric and physical features. Online basis functions are then adaptively enriched using residuals, allowing the method to incorporate global effects such as source terms and boundary conditions, thereby improving accuracy. We provide detailed error analysis demonstrating how the offline and online spaces contribute to the accuracy and efficiency of the solution. Numerical experiments confirm the method's effectiveness, showing substantial reductions in computational cost while maintaining high accuracy, particularly through adaptive online enrichment. These results highlight the method's potential for efficient and accurate simulation of Darcy flow in complex, heterogeneous perforated domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23093v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Xie, Shubin Fu, Yin Yang, Yunqing Huang</dc:creator>
    </item>
    <item>
      <title>An \textsf{AT1} phase-field framework for quasi-static anti-plane shear fracture: Unifying $\xi$-based adaptivity and nonlinear strain energy density function</title>
      <link>https://arxiv.org/abs/2506.23249</link>
      <description>arXiv:2506.23249v1 Announce Type: new 
Abstract: This work introduces a novel \textsf{AT1} phase-field framework for simulating quasi-static anti-plane shear fracture in geometrically linear elastic bodies. A key feature of this framework is the unification of $\xi$-based local mesh adaptivity -- where $\xi$ represents the characteristic length of the damage zone -- and an algebraically nonlinear strain energy density function. A modified Francfort-Marigo energy functional, together with its Ambrosio-Tortorelli-type regularization, is hereby proposed to address challenges within the framework of nonlinearly constituted materials. We dynamically optimize $\xi$ throughout the simulation, significantly enhancing the computational efficiency and accuracy of numerically approximating the local minimizers of the Ambrosio-Tortorelli (\textsf{AT1})-type phase-field model. The proposed regularization for the total energy functional comprises three distinct components: a nonlinear strain energy, an evolving surface energy, and a linear-type regularization term dependent on the length scale of the damage zone. Variational principles applied to this novel energy functional yield a coupled system of governing second-order quasilinear partial differential equations for the mechanics and phase-field variables. These equations are subsequently discretized using the conforming bilinear finite element method. The formulation is underpinned by four crucial parameters: two are integral to the nonlinear strain energy function, while the other two serve as penalty parameters. These penalty parameters are asymptotically calibrated and rigorously utilized in the numerical simulations. Our results demonstrate that this spatially adaptive approach leads to enhanced mesh adaptivity, ensuring the robust convergence of the numerical solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23249v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria P. Fernando, S. M. Mallikarjunaiah</dc:creator>
    </item>
    <item>
      <title>Data-Driven Self-Supervised Learning for the Discovery of Solution Singularity for Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2506.23344</link>
      <description>arXiv:2506.23344v1 Announce Type: new 
Abstract: The appearance of singularities in the function of interest constitutes a fundamental challenge in scientific computing. It can significantly undermine the effectiveness of numerical schemes for function approximation, numerical integration, and the solution of partial differential equations (PDEs), etc. The problem becomes more sophisticated if the location of the singularity is unknown, which is often encountered in solving PDEs. Detecting the singularity is therefore critical for developing efficient adaptive methods to reduce computational costs in various applications. In this paper, we consider singularity detection in a purely data-driven setting. Namely, the input only contains given data, such as the vertex set from a mesh. To overcome the limitation of the raw unlabeled data, we propose a self-supervised learning (SSL) framework for estimating the location of the singularity. A key component is a filtering procedure as the pretext task in SSL, where two filtering methods are presented, based on $k$ nearest neighbors and kernel density estimation, respectively. We provide numerical examples to illustrate the potential pathological or inaccurate results due to the use of raw data without filtering. Various experiments are presented to demonstrate the ability of the proposed approach to deal with input perturbation, label corruption, and different kinds of singularities such interior circle, boundary layer, concentric semicircles, etc.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23344v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Difeng Cai, Paulina Sep\'ulveda</dc:creator>
    </item>
    <item>
      <title>A new family of a posteriori error estimates for non-conforming finite element methods leading to stabilization-free error bounds</title>
      <link>https://arxiv.org/abs/2506.23381</link>
      <description>arXiv:2506.23381v1 Announce Type: new 
Abstract: We propose new a posteriori error estimators for non-conforming finite element discretizations of second-order elliptic PDE problems. These estimators are based on novel reformulations of the standard Prager-Synge identity, and enable to prove efficiency estimates without extra stabilization terms in the error measure for a large class of discretization schemes. We propose a residual-based estimator for which the efficiency constant scales optimally in polynomial degree, as well as two equilibrated estimators that are polynomial-degree-robust. One of the two estimators further leads to guaranteed error bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23381v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>T. Chaumont-Frelet</dc:creator>
    </item>
    <item>
      <title>Fourth-order compact difference schemes for the one-dimensional Euler-Bernoulli beam equation with damping term</title>
      <link>https://arxiv.org/abs/2506.23449</link>
      <description>arXiv:2506.23449v1 Announce Type: new 
Abstract: This paper proposes and analyzes a finite difference method based on compact schemes for the Euler-Bernoulli beam equation with damping terms. The method achieves fourth-order accuracy in space and second-order accuracy in time, while requiring only three spatial grid points within a single compact stencil. Spatial discretization is carried out using a compact finite difference scheme, with a variable substitution technique employed to reduce the order of the equation and effectively handle the damping terms. For the temporal discretization, the Crank-Nicolson scheme is applied. The consistency, stability, and convergence of the proposed method are rigorously proved. Numerical experiments are presented to verify the theoretical results and demonstrate the accuracy and efficiency of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23449v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjie Huang, Hao Wang, Shiquan Zhang, Qinyi Zhang</dc:creator>
    </item>
    <item>
      <title>On the convergence of iterative regularization method assisted by the graph Laplacian with early stopping</title>
      <link>https://arxiv.org/abs/2506.23483</link>
      <description>arXiv:2506.23483v1 Announce Type: new 
Abstract: We present a data-assisted iterative regularization method for solving ill-posed inverse problems in Hilbert space settings. The proposed approach, termed \texttt{IRMGL+\(\Psi\)}, integrates classical iterative techniques with a data-driven regularization term realized through an iteratively updated graph Laplacian. Our method commences by computing a preliminary solution using any suitable reconstruction method, which then serves as the basis for constructing the initial graph Laplacian. The solution is subsequently refined through an iterative process, where the graph Laplacian is simultaneously recalibrated at each step to effectively capture the evolving structure of the solution. A key innovation of this work lies in the formulation of this iterative scheme and the rigorous justification of the classical discrepancy principle as a reliable early stopping criterion specifically tailored to the proposed method. Under standard assumptions, we establish stability and convergence results for the scheme when the discrepancy principle is applied. Furthermore, we demonstrate the robustness and effectiveness of our method through numerical experiments utilizing four distinct initial reconstructors $\Psi$: the adjoint operator (Adj), filtered back projection (FBP), total variation (TV) denoising, and standard Tikhonov regularization (Tik). It is observed that \texttt{IRMGL+Adj} demonstrates a distinct advantage over the other initializers, producing a robust and stable approximate solution directly from a basic initial reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23483v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harshit Bajpai, Gaurav Mittal, Ankik Kumar Giri</dc:creator>
    </item>
    <item>
      <title>Rectangular $C^1$-$Q_k$ Bell finite elements in two and three dimensions</title>
      <link>https://arxiv.org/abs/2506.23702</link>
      <description>arXiv:2506.23702v1 Announce Type: new 
Abstract: Both the function and its normal derivative on the element boundary are $Q_k$ polynomials
  for the Bogner-Fox-Schmit $C^1$-$Q_k$ finite element functions. Mathematically, to keep the optimal order of approximation, their spaces are required to
  include $P_k$ and $P_{k-1}$ polynomials respectively. We construct a Bell type $C^1$-$Q_k$ finite element on rectangular meshes in 2D and 3D,
  which has its normal derivative as a $Q_{k-1}$ polynomial on each face, for $k\ge 4$. We show, with a big reduction of the space, the $C^1$-$Q_k$ Bell
  finite element retains the optimal order of convergence. Numerical experiments are performed, comparing the new elements with the original elements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23702v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongling Hu, Shangyou Zhang</dc:creator>
    </item>
    <item>
      <title>Efficient Numerical Integration for Finite Element Trunk Spaces in 2D and 3D using Machine Learning: A new Optimisation Paradigm to Construct Application-Specific Quadrature Rules</title>
      <link>https://arxiv.org/abs/2506.23741</link>
      <description>arXiv:2506.23741v1 Announce Type: new 
Abstract: Finite element methods usually construct basis functions and quadrature rules for multidimensional domains via tensor products of one-dimensional counterparts. While straightforward, this approach results in integration spaces larger than necessary, especially as the polynomial degree $p$ or the spatial dimension increases, leading to considerable computational overhead. This work starts from the hypothesis that reducing the dimensionality of the polynomial space can lead to quadrature rules with fewer points and lower computational cost, while preserving the exactness of numerical integration. We use trunk spaces that exclude high-degree monomials that do not improve the approximation quality of the discrete space. These reduced spaces retain sufficient expressive power and allow us to construct smaller (more economical) integration domains. Given a maximum degree $p$, we define trial and test spaces $U$ and $V$ as 2D or 3D trunk spaces and form the integration space $\mathcal{S} = U \otimes V$. We then construct exact quadrature rules by solving a non-convex optimisation problem over the number of points $q$, their coordinates, and weights. We use a shallow neural network with linear activations to parametrise the rule, and a random restart strategy to mitigate convergence to poor local minima. When necessary, we dynamically increase $q$ to achieve exact integration. Our construction reaches machine-precision accuracy (errors below 1e-22) using significantly fewer points than standard tensor-product Gaussian quadrature: up to 30\% reduction in 2D for $p \leq 10$, and 50\% in 3D for $p \leq 6$. These results show that combining the mathematical understanding of polynomial structure with numerical optimisation can lead to a practical and extensible methodology for improving the adaptiveness, efficiency, and scalability of quadrature rules for high-order finite element simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23741v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomas Teijeiro, Pouria Behnoudfar, Jamie M. Taylor, David Pardo, Victor M. Calo</dc:creator>
    </item>
    <item>
      <title>Error analysis for a Finite Element Discretization of a radially symmetric harmonic map heat flow problem</title>
      <link>https://arxiv.org/abs/2506.23748</link>
      <description>arXiv:2506.23748v1 Announce Type: new 
Abstract: We consider the harmonic map heat flow problem for a radially symmetric case. For discretization of this problem we apply a $H^1$-conforming finite element method in space combined with a semi-implicit Euler time stepping. The semi-implicit Euler method results in a linear problem in each time step. We restrict to the regime of smooth solutions of the continuous problem and present an error analysis of this discretization method. This results in optimal order discretization error bounds. Key ingredients of the analysis are a discrete energy estimate, that mimics the energy dissipation of the continuous solution, and a convexity property that is essential for discrete stability and for control of the linearization error. We also present numerical results that validate the theoretical ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23748v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nam Anh Nguyen, Arnold Reusken</dc:creator>
    </item>
    <item>
      <title>Dimension and model reduction approaches for linear Bayesian inverse problems with rank-deficient prior covariances</title>
      <link>https://arxiv.org/abs/2506.23892</link>
      <description>arXiv:2506.23892v1 Announce Type: new 
Abstract: Bayesian inverse problems use observed data to update a prior probability distribution for an unknown state or parameter of a scientific system to a posterior distribution conditioned on the data. In many applications, the unknown parameter is high-dimensional, making computation of the posterior expensive due to the need to sample in a high-dimensional space and the need to evaluate an expensive high-dimensional forward model relating the unknown parameter to the data. However, inverse problems often exhibit low-dimensional structure due to the fact that the available data are only informative in a low-dimensional subspace of the parameter space. Dimension reduction approaches exploit this structure by restricting inference to the low-dimensional subspace informed by the data, which can be sampled more efficiently. Further computational cost reductions can be achieved by replacing expensive high-dimensional forward models with cheaper lower-dimensional reduced models. In this work, we propose new dimension and model reduction approaches for linear Bayesian inverse problems with rank-deficient prior covariances, which arise in many practical inference settings. The dimension reduction approach is applicable to general linear Bayesian inverse problems whereas the model reduction approaches are specific to the problem of inferring the initial condition of a linear dynamical system. We provide theoretical approximation guarantees as well as numerical experiments demonstrating the accuracy and efficiency of the proposed approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23892v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Josie K\"onig, Elizabeth Qian, Melina A. Freitag</dc:creator>
    </item>
    <item>
      <title>Structure-preserving approximation of the non-isothermal Cahn-Hilliard system</title>
      <link>https://arxiv.org/abs/2506.23933</link>
      <description>arXiv:2506.23933v1 Announce Type: new 
Abstract: We propose and analyze a structure-preserving approximation of the non-isothermal Cahn-Hilliard equation using conforming finite elements for the spatial discretization and a problem-specific mixed explicit-implicit approach for the temporal discretization. To ensure the preservation of structural properties, i.e. conservation of mass and internal energy as well as entropy production, we introduce a suitable variational formulation for the continuous problem, based on the entropy equation. Analytical findings are supported by numerical tests, including convergence analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23933v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Brunk, Maria Lukacova-Medvidova, Dennis Schumann</dc:creator>
    </item>
    <item>
      <title>Explicit modified Euler approximations of the A\"{i}t-Sahalia type model with Poisson jumps</title>
      <link>https://arxiv.org/abs/2506.23947</link>
      <description>arXiv:2506.23947v1 Announce Type: new 
Abstract: This paper focuses on mean-square approximations of a generalized A\"it-Sahalia interest rate model with Poisson jumps. The main challenge in the construction and analysis of time-discrete numerical schemes is caused by a drift that blows up at the origin, highly nonlinear drift and diffusion coefficients and positivity-preserving requirement. Due to the presence of the Poisson jumps, additional difficulties arise in recovering the exact order $1/2$ of convergence for the time-stepping schemes. By incorporating implicitness in the term $\alpha_{-1}x^{-1} $ and introducing the modifications functions $f_h$ and $g_h$ in the recursion, a novel explicit Euler-type scheme is proposed, which is easy to implement and preserves the positivity of the original model unconditionally, i.e., for any time step-size $h&gt;0$. A mean-square convergence rate of order $1/2$ is established for the proposed scheme in both the non-critical and general critical cases. Finally, numerical experiments are provided to confirm the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23947v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingsong Jiang, Ruishu Liu, Minhong Xu</dc:creator>
    </item>
    <item>
      <title>Full history recursive multilevel Picard approximations suffer from the curse of dimensionality for the Hamilton-Jacobi-Bellman equation of a stochastic control problem</title>
      <link>https://arxiv.org/abs/2506.23969</link>
      <description>arXiv:2506.23969v1 Announce Type: new 
Abstract: Full history recursive multilevel Picard (MLP) approximations have been proved to overcome the curse of dimensionality in the numerical approximation of semilinear heat equations with nonlinearities which are globally Lipschitz continuous with respect to the maximum-norm. Nonlinearities in Hamilton-Jacobi-Bellman equations in stochastic control theory, however, are often (locally) Lipschitz continuous with respect to the standard Euclidean norm. In this paper we prove the surprising fact that MLP approximations for one such example equation suffer from the curse of dimensionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23969v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Hutzenthaler, Tuan Anh Nguyen</dc:creator>
    </item>
    <item>
      <title>Sparse grids vs. random points for high-dimensional polynomial approximation</title>
      <link>https://arxiv.org/abs/2506.24054</link>
      <description>arXiv:2506.24054v1 Announce Type: new 
Abstract: We study polynomial approximation on a $d$-cube, where $d$ is large, and compare interpolation on sparse grids, aka Smolyak's algorithm (SA), with a simple least squares method based on randomly generated points (LS) using standard benchmark functions. Our main motivation is the influential paper [Barthelmann, Novak, Ritter: High dimensional polynomial interpolation on sparse grids, Adv. Comput. Math. 12, 2000]. We repeat and extend their theoretical analysis and numerical experiments for SA and compare to LS in dimensions up to 100. Our extensive experiments demonstrate that LS, even with only slight oversampling, consistently matches the accuracy of SA in low dimensions. In high dimensions, however, LS shows clear superiority.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.24054v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jakob Eggl, Elias Mindlberger, Mario Ullrich</dc:creator>
    </item>
    <item>
      <title>On a result by Meshulam</title>
      <link>https://arxiv.org/abs/2506.22553</link>
      <description>arXiv:2506.22553v1 Announce Type: cross 
Abstract: In 1996, Meshulam proved that every sequence generated by applying projections onto affine subspaces, drawn from a finite collection in Euclidean space, must be bounded.
  In this paper, we extend his result not only from affine subspaces to convex polyhedral subsets, but also from Euclidean to general Hilbert space. Various examples are provided to illustrate the sharpness of the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22553v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heinz H. Bauschke, Tran Thanh Tung</dc:creator>
    </item>
    <item>
      <title>Efficient Tensor Decomposition via Moment Matrix Extension</title>
      <link>https://arxiv.org/abs/2506.22564</link>
      <description>arXiv:2506.22564v1 Announce Type: cross 
Abstract: Motivated by a flurry of recent work on efficient tensor decomposition algorithms, we show that the celebrated moment matrix extension algorithm of Brachat, Comon, Mourrain, and Tsigaridas for symmetric tensor canonical polyadic (CP) decomposition can be made efficient under the right conditions. We first show that the crucial property determining the complexity of the algorithm is the regularity of a target decomposition. This allows us to reduce the complexity of the vanilla algorithm, while also unifying results from previous works. We then show that for tensors in $S^d\mathbb{C}^{n+1}$ with $d$ even, low enough regularity can reduce finding a symmetric tensor decomposition to solving a system of linear equations. For order-$4$ tensors we prove that generic tensors of rank up to $r=2n+1$ can be decomposed efficiently via moment matrix extension, exceeding the rank threshold allowed by simultaneous diagonalization. We then formulate a conjecture that states for generic order-$4$ tensors of rank $r=O(n^2)$ the induced linear system is sufficient for efficient tensor decomposition, matching the asymptotics of existing algorithms and in fact improving the leading coefficient. Towards this conjecture we give computer assisted proofs that the statement holds for $n=2, \dots, 17$. Next we demonstrate that classes of nonidentifiable tensors can be decomposed efficiently via the moment matrix extension algorithm, bypassing the usual need for uniqueness of decomposition. Of particular interest is the class of monomials, for which the extension algorithm is not only efficient but also improves on existing theory by explicitly parameterizing the space of decompositions. Code for implementations of the efficient algorithm for generic tensors and monomials are provided, along with several numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22564v1</guid>
      <category>math.AG</category>
      <category>cs.NA</category>
      <category>cs.SC</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bobby Shi, Julia Lindberg, Joe Kileel</dc:creator>
    </item>
    <item>
      <title>A Rigorous Error Bound for the TG Kernel in Prime Counting</title>
      <link>https://arxiv.org/abs/2506.22634</link>
      <description>arXiv:2506.22634v1 Announce Type: cross 
Abstract: We establish rigorous error bounds for prime counting using a truncated Gaussian (TG) kernel in the explicit formula framework. Our main theorem proves that the approximation error remains globally below 1/2 for all sufficiently large arguments, guaranteeing exact computation of {\pi}(x) through simple rounding, without relying on unproven hypotheses.
  The TG kernel construction employs Gaussian-like test functions with compact support, engineered with vanishing moments to eliminate main terms. For x with 10^8 decimal digits, we demonstrate that only ~1200 nontrivial zeta zeros suffice to achieve the error bound, enabling computation in seconds on modern hardware - a dramatic improvement over classical methods.
  Key contributions include: (1) Explicit tail truncation bounds using Taylor remainder analysis, showing exponential decay; (2) Zero-sum truncation error bounds via unconditional density estimates; (3) Rigorous treatment of trivial zero contributions. All constants are made explicit, ensuring full verifiability.
  The method bridges analytic number theory and practical computation, with potential applications to record-breaking prime counting computations. We discuss algorithmic implications including FFT-based arithmetic for ~330 million bit numbers. The framework's flexibility suggests connections to deeper structures in prime distribution, particularly regarding optimized kernel designs and the interplay between smoothing parameters {\alpha} and truncation heights.
  This work exemplifies how classical analytic techniques, when carefully implemented with modern computational perspectives, yield practical algorithms for problems previously considered purely theoretical. The rigorous error analysis ensures reliability even at astronomical scales, opening new avenues for computational number theory research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22634v1</guid>
      <category>math.NT</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bugra Kilictas, Faruk Alpay</dc:creator>
    </item>
    <item>
      <title>Lower bounds for trace estimation via Block Krylov and other methods</title>
      <link>https://arxiv.org/abs/2506.22701</link>
      <description>arXiv:2506.22701v1 Announce Type: cross 
Abstract: This paper studies theoretical lower bounds for estimating the trace of a matrix function, $\text{tr}(f(A))$, focusing on methods that use Hutchinson's method along with Block Krylov techniques. These methods work by approximating matrix-vector products like $f(A)V$ using a Block Krylov subspace. This is closely related to approximating functions with polynomials. We derive theoretical upper bounds on how many Krylov steps are needed for functions such as $A^{-1/2}$ and $A^{-1}$ by analyzing the upper bounds from the polynomial approximation of their scalar equivalent. In addition, we also develop lower limits on the number of queries needed for trace estimation, specifically for $\text{tr}(W^{-p})$ where $W$ is a Wishart matrix. Our study clarifies the connection between the number of steps in Block Krylov methods and the degree of the polynomial used for approximation. This links the total cost of trace estimation to basic limits in polynomial approximation and how much information is needed for the computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22701v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shi Jie Yu</dc:creator>
    </item>
    <item>
      <title>Denoising Multi-Color QR Codes and Stiefel-Valued Data by Relaxed Regularizations</title>
      <link>https://arxiv.org/abs/2506.22826</link>
      <description>arXiv:2506.22826v1 Announce Type: cross 
Abstract: The handling of manifold-valued data, for instance, plays a central role in color restoration tasks relying on circle- or sphere-valued color models, in the study of rotational or directional information related to the special orthogonal group, and in Gaussian image processing, where the pixel statistics are interpreted as values on the hyperbolic sheet. Especially, to denoise these kind of data, there have been proposed several generalizations of total variation (TV) and Tikhonov-type denoising models incorporating the underlying manifolds. Recently, a novel, numerically efficient denoising approach has been introduced, where the data are embedded in an Euclidean ambient space, the non-convex manifolds are encoded by a series of positive semi-definite, fixed-rank matrices, and the rank constraint is relaxed to obtain a convexification that can be solved using standard algorithms from convex analysis. The aim of the present paper is to extent this approach to new kinds of data like multi-binary and Stiefel-valued data. Multi-binary data can, for instance, be used to model multi-color QR codes whereas Stiefel-valued data occur in image and video-based recognition. For both new data types, we propose TV- and Tikhonov-based denoising modelstogether with easy-to-solve convexification. All derived methods are evaluated on proof-of-concept, synthetic experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22826v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Beinert, Jonas Bresch</dc:creator>
    </item>
    <item>
      <title>Deep neural networks can provably solve Bellman equations for Markov decision processes without the curse of dimensionality</title>
      <link>https://arxiv.org/abs/2506.22851</link>
      <description>arXiv:2506.22851v1 Announce Type: cross 
Abstract: Discrete time stochastic optimal control problems and Markov decision processes (MDPs) are fundamental models for sequential decision-making under uncertainty and as such provide the mathematical framework underlying reinforcement learning theory. A central tool for solving MDPs is the Bellman equation and its solution, the so-called $Q$-function. In this article, we construct deep neural network (DNN) approximations for $Q$-functions associated to MDPs with infinite time horizon and finite control set $A$. More specifically, we show that if the the payoff function and the random transition dynamics of the MDP can be suitably approximated by DNNs with leaky rectified linear unit (ReLU) activation, then the solutions $Q_d\colon \mathbb R^d\to \mathbb R^{|A|}$, $d\in \mathbb{N}$, of the associated Bellman equations can also be approximated in the $L^2$-sense by DNNs with leaky ReLU activation whose numbers of parameters grow at most polynomially in both the dimension $d\in \mathbb{N}$ of the state space and the reciprocal $1/\varepsilon$ of the prescribed error $\varepsilon\in (0,1)$. Our proof relies on the recently introduced full-history recursive multilevel fixed-point (MLFP) approximation scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22851v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnulf Jentzen, Konrad Kleinberg, Thomas Kruse</dc:creator>
    </item>
    <item>
      <title>Differentiable Radar Ambiguity Functions: Mathematical Formulation and Computational Implementation</title>
      <link>https://arxiv.org/abs/2506.22935</link>
      <description>arXiv:2506.22935v1 Announce Type: cross 
Abstract: The ambiguity function is fundamental to radar waveform design, characterizing range and Doppler resolution capabilities. However, its traditional formulation involves non-differentiable operations, preventing integration with gradient-based optimization methods and modern machine learning frameworks. This paper presents the first complete mathematical framework and computational implementation for differentiable radar ambiguity functions. Our approach addresses the fundamental technical challenges that have prevented the radar community from leveraging automatic differentiation: proper handling of complex-valued gradients using Wirtinger calculus, efficient computation through parallelized FFT operations, numerical stability throughout cascaded operations, and composability with arbitrary differentiable operations. We term this approach GRAF (Gradient-based Radar Ambiguity Functions), which reformulates the ambiguity function computation to maintain mathematical equivalence while enabling gradient flow through the entire pipeline. The resulting implementation provides a general-purpose differentiable ambiguity function compatible with modern automatic differentiation frameworks, enabling new research directions including neural network-based waveform generation with ambiguity constraints, end-to-end optimization of radar systems, and integration of classical radar theory with modern deep learning. We provide complete implementation details and demonstrate computational efficiency suitable for practical applications. This work establishes the mathematical and computational foundation for applying modern machine learning techniques to radar waveform design, bridging classical radar signal processing with automatic differentiation frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22935v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc Bara Iniesta</dc:creator>
    </item>
    <item>
      <title>BWLer: Barycentric Weight Layer Elucidates a Precision-Conditioning Tradeoff for PINNs</title>
      <link>https://arxiv.org/abs/2506.23024</link>
      <description>arXiv:2506.23024v1 Announce Type: cross 
Abstract: Physics-informed neural networks (PINNs) offer a flexible way to solve partial differential equations (PDEs) with machine learning, yet they still fall well short of the machine-precision accuracy many scientific tasks demand. In this work, we investigate whether the precision ceiling comes from the ill-conditioning of the PDEs or from the typical multi-layer perceptron (MLP) architecture. We introduce the Barycentric Weight Layer (BWLer), which models the PDE solution through barycentric polynomial interpolation. A BWLer can be added on top of an existing MLP (a BWLer-hat) or replace it completely (explicit BWLer), cleanly separating how we represent the solution from how we take derivatives for the PDE loss. Using BWLer, we identify fundamental precision limitations within the MLP: on a simple 1-D interpolation task, even MLPs with O(1e5) parameters stall around 1e-8 RMSE -- about eight orders above float64 machine precision -- before any PDE terms are added. In PDE learning, adding a BWLer lifts this ceiling and exposes a tradeoff between achievable accuracy and the conditioning of the PDE loss. For linear PDEs we fully characterize this tradeoff with an explicit error decomposition and navigate it during training with spectral derivatives and preconditioning. Across five benchmark PDEs, adding a BWLer on top of an MLP improves RMSE by up to 30x for convection, 10x for reaction, and 1800x for wave equations while remaining compatible with first-order optimizers. Replacing the MLP entirely lets an explicit BWLer reach near-machine-precision on convection, reaction, and wave problems (up to 10 billion times better than prior results) and match the performance of standard PINNs on stiff Burgers' and irregular-geometry Poisson problems. Together, these findings point to a practical path for combining the flexibility of PINNs with the precision of classical spectral solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23024v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jerry Liu, Yasa Baig, Denise Hui Jean Lee, Rajat Vadiraj Dwaraknath, Atri Rudra, Chris R\'e</dc:creator>
    </item>
    <item>
      <title>Shifted Composition IV: Underdamped Langevin and Numerical Discretizations with Partial Acceleration</title>
      <link>https://arxiv.org/abs/2506.23062</link>
      <description>arXiv:2506.23062v1 Announce Type: cross 
Abstract: Quantifying the convergence rate of the underdamped Langevin dynamics (ULD) is a classical topic, in large part due to the possibility for diffusive-to-ballistic speedups -- as was recently established for the continuous-time dynamics via space-time Poincare inequalities. A central challenge for analyzing ULD is that its degeneracy necessitates the development of new analysis approaches, e.g., the theory of hypocoercivity. In this paper, we give a new coupling-based framework for analyzing ULD and its numerical discretizations. First, in the continuous-time setting, we use this framework to establish new parabolic Harnack inequalities for ULD. These are the first Harnack inequalities that decay to zero in contractive settings, thereby reflecting the convergence properties of ULD in addition to just its regularity properties.
  Second, we build upon these Harnack inequalities to develop a local error framework for analyzing discretizations of ULD in KL divergence. This extends our framework in part III from uniformly elliptic diffusions to degenerate diffusions, and shares its virtues: the framework is user-friendly, applies to sophisticated discretization schemes, and does not require contractivity. Applying this framework to the randomized midpoint discretization of ULD establishes (i) the first ballistic acceleration result for log-concave sampling (i.e., sublinear dependence on the condition number), and (ii) the first $d^{1/3}$ iteration complexity guarantee for sampling to constant total variation error in dimension $d$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23062v1</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason M. Altschuler, Sinho Chewi, Matthew S. Zhang</dc:creator>
    </item>
    <item>
      <title>Seeding neural network quantum states with tensor network states</title>
      <link>https://arxiv.org/abs/2506.23550</link>
      <description>arXiv:2506.23550v1 Announce Type: cross 
Abstract: We find an efficient approach to approximately convert matrix product states (MPSs) into restricted Boltzmann machine wave functions consisting of a multinomial hidden unit through a canonical polyadic (CP) decomposition of the MPSs. This method allows us to generate well-behaved initial neural network quantum states for quantum many-body ground-state calculations in polynomial time of the number of variational parameters and systematically shorten the distance between the initial states and the ground states with increasing the rank of the CP decomposition. We demonstrate the efficiency of our method by taking the transverse-field Ising model as an example and discuss possible applications of our method to more general quantum many-body systems in which the ground-state wave functions possess complex nodal structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23550v1</guid>
      <category>cond-mat.str-el</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>quant-ph</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryui Kaneko, Shimpei Goto</dc:creator>
    </item>
    <item>
      <title>Faster Diffusion Models via Higher-Order Approximation</title>
      <link>https://arxiv.org/abs/2506.24042</link>
      <description>arXiv:2506.24042v1 Announce Type: cross 
Abstract: In this paper, we explore provable acceleration of diffusion models without any additional retraining. Focusing on the task of approximating a target data distribution in $\mathbb{R}^d$ to within $\varepsilon$ total-variation distance, we propose a principled, training-free sampling algorithm that requires only the order of
  $$ d^{1+2/K} \varepsilon^{-1/K} $$
  score function evaluations (up to log factor) in the presence of accurate scores, where $K$ is an arbitrarily large fixed integer. This result applies to a broad class of target data distributions, without the need for assumptions such as smoothness or log-concavity. Our theory is robust vis-a-vis inexact score estimation, degrading gracefully as the score estimation error increases -- without demanding higher-order smoothness on the score estimates as assumed in previous work. The proposed algorithm draws insight from high-order ODE solvers, leveraging high-order Lagrange interpolation and successive refinement to approximate the integral derived from the probability flow ODE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.24042v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gen Li, Yuchen Zhou, Yuting Wei, Yuxin Chen</dc:creator>
    </item>
    <item>
      <title>Efficient Shallow Ritz Method For 1D Diffusion Problems</title>
      <link>https://arxiv.org/abs/2404.17750</link>
      <description>arXiv:2404.17750v3 Announce Type: replace 
Abstract: This paper studies the shallow Ritz method for solving the one-dimensional diffusion problem. It is shown that the shallow Ritz method improves the order of approximation dramatically for non-smooth problems. To realize this optimal or nearly optimal order of the shallow Ritz approximation, we develop a damped block Newton (dBN) method that alternates between updates of the linear and non-linear parameters. Per each iteration, the linear and the non-linear parameters are updated by exact inversion and one step of a modified, damped Newton method applied to a reduced non-linear system, respectively. The computational cost of each dBN iteration is $O(n)$.
  Starting with the non-linear parameters as a uniform partition of the interval, numerical experiments show that the dBN is capable of efficiently moving mesh points to nearly optimal locations. To improve efficiency of the dBN further, we propose an adaptive damped block Newton (AdBN) method by combining the dBN with the adaptive neuron enhancement (ANE) method [26].</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17750v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiqiang Cai, Anastassia Doktorova, Robert D. Falgout, C\'esar Herrera</dc:creator>
    </item>
    <item>
      <title>Efficient Shallow Ritz Method For 1D Diffusion-Reaction Problems</title>
      <link>https://arxiv.org/abs/2407.01496</link>
      <description>arXiv:2407.01496v3 Announce Type: replace 
Abstract: This paper studies the shallow Ritz method for solving one-dimensional diffusion-reaction problems. The method is capable of improving the order of approximation for non-smooth problems. By following a similar approach to the one presented in [9], we present a damped block Newton (dBN) method to achieve nearly optimal order of approximation. The dBN method optimizes the Ritz functional by alternating between the linear and non-linear parameters of the shallow ReLU neural network (NN). For diffusion-reaction problems, new difficulties arise: (1) for the linear parameters, the mass matrix is dense and even more ill-conditioned than the stiffness matrix, and (2) for the non-linear parameters, the Hessian matrix is dense and may be singular. This paper addresses these challenges, resulting in a dBN method with computational cost of ${\cal O}(n)$.
  The ideas presented for diffusion-reaction problems can also be applied to least-squares approximation problems. For both applications, starting with the non-linear parameters as a uniform partition, numerical experiments show that the dBN method moves the mesh points to nearly optimal locations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01496v3</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhiqiang Cai, Anastassia Doktorova, Robert D. Falgout, C\'esar Herrera</dc:creator>
    </item>
    <item>
      <title>Sample-based almost-sure quasi-optimal approximation in reproducing kernel Hilbert spaces</title>
      <link>https://arxiv.org/abs/2407.06674</link>
      <description>arXiv:2407.06674v3 Announce Type: replace 
Abstract: This manuscript addresses the problem of approximating an unknown function from point evaluations. When obtaining these point evaluations is costly, minimising the required sample size becomes crucial, and it is unreasonable to reserve a sufficiently large test sample for estimating the approximation accuracy. Therefore, an approximation with a certified quasi-optimality factor is required. This article shows that such an approximation can be obtained when the sought function lies in a reproducing kernel Hilbert space (RKHS) and is to be approximated in a finite-dimensional linear subspace. However, selecting the sample points to minimise the quasi-optimality factor requires optimising over an infinite set of points and computing exact inner products in RKHS, which is often infeasible in practice. Extending results from optimal sampling for $L^2$ approximation, the present manuscript proves that random points, drawn independently from the Christoffel sampling distribution associated with $\mathcal{V}_d$, can yield a controllable quasi-optimality factor with high probability. Inspired by this result, a novel sampling scheme, coined subspace-informed volume sampling, is introduced and evaluated in numerical experiments, where it outperforms classical i.i.d. Christoffel sampling and continuous volume sampling. To reduce the size of such a random sample, an additional greedy subsampling scheme with provable suboptimality bounds is introduced. Our presentation is of independent interest to the community researching the parametrised background data weak (PBDW) method, as it offers a simpler interpretation of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06674v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Trunschke, Anthony Nouy</dc:creator>
    </item>
    <item>
      <title>Solving high-dimensional Hamilton-Jacobi-Bellman equation with functional hierarchical tensor</title>
      <link>https://arxiv.org/abs/2408.04209</link>
      <description>arXiv:2408.04209v3 Announce Type: replace 
Abstract: This work proposes a novel numerical scheme for solving the high-dimensional Hamilton-Jacobi-Bellman equation with a functional hierarchical tensor ansatz. We consider the setting of stochastic control, whereby one applies control to a particle under Brownian motion. In particular, the existence of diffusion presents a new challenge to conventional tensor network methods for deterministic optimal control. To overcome the difficulty, we use a general regression-based formulation where the loss term is the Bellman consistency error combined with a Sobolev-type penalization term. We propose two novel sketching-based subroutines for obtaining the tensor-network approximation to the action-value functions and the value functions, which greatly accelerate the convergence for the subsequent regression phase. We apply the proposed approach successfully to two challenging control problems with Ginzburg-Landau potential in 1D and 2D with 64 variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04209v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xun Tang, Nan Sheng, Lexing Ying</dc:creator>
    </item>
    <item>
      <title>Continuous data assimilation for hydrodynamics: consistent discretization and application to moment recovery</title>
      <link>https://arxiv.org/abs/2409.03872</link>
      <description>arXiv:2409.03872v2 Announce Type: replace 
Abstract: Motivated by the challenge of moment recovery in hydrodynamic approximation in kinetic theory, we propose a data-driven approach for the hydrodynamic models. Inspired by continuous data assimilation, our method introduces a relaxation-based nudging system coupled with a novel discretization technique. This approach facilitates the simultaneous recovery of both the force term and a high-resolution solution from sparsely observed data. To address potential numerical artifacts, we use kernel regression to fit the observed data. We also analyze the convergence of the proposed nudging system under both full and partial data scenarios. When applied to moment systems, the source term involves the derivative of higher-order moments, our approach serves as a crucial step for data preparation in machine-learning based moment closure models. Multiple numerical experiments demonstrate the effectiveness of our algorithm, and we discuss its potential extension to high-dimensional systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03872v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jincheng Lu, Kunlun Qi, Li Wang, Jeff Calder</dc:creator>
    </item>
    <item>
      <title>An optimal diagonalization-based preconditioner for parabolic optimal control problems</title>
      <link>https://arxiv.org/abs/2410.22686</link>
      <description>arXiv:2410.22686v2 Announce Type: replace 
Abstract: In this work, we propose a novel diagonalization-based preconditioner for the all-at-once linear system arising from the optimal control problem of parabolic equations. The proposed preconditioner is constructed based on an $\epsilon$-circulant modification to the rotated block diagonal (RBD) preconditioning technique and can be efficiently diagonalized by fast Fourier transforms in a parallel-in-time fashion. To our knowledge, this marks the first application of the $\epsilon$-circulant modification to RBD preconditioning. Before our work, the studies of parallel-in-time preconditioning techniques for the optimal control problem are mainly focused on $\epsilon$-circulant modification to Schur complement based preconditioners, which involves multiplication of forward and backward evolutionary processes and thus square the condition number. Compared with those Schur complement based preconditioning techniques in the literature, the advantage of the proposed $\epsilon$-circulant modified RBD preconditioning is that it does not involve the multiplication of forward and backward evolutionary processes. When the generalized minimal residual method is deployed on the preconditioned system, we prove that when choosing $\epsilon=\mathcal{O}(\sqrt{\tau})$ with $\tau$ being the temporal step-size, the convergence rate of the preconditioned GMRES solver is independent of the matrix size and the regularization parameter. Numerical results are provided to demonstrate the effectiveness of our proposed solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22686v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sean Y. Hon, Po Yin Fung, Xue-lei Lin</dc:creator>
    </item>
    <item>
      <title>A class of positive-preserving,energy stable and high order numerical schemes for the Poission-Nernst-Planck system</title>
      <link>https://arxiv.org/abs/2502.03892</link>
      <description>arXiv:2502.03892v2 Announce Type: replace 
Abstract: In this paper, we introduce and analyze a class of numerical schemes that demonstrate remarkable superiority in terms of efficiency, the preservation of positivity, energy stability, and high-order precision to solve the time-dependent Poisson-Nernst-Planck (PNP) system, which is
  as a highly versatile and sophisticated model and accommodates a plenitude of applications in the emulation of the translocation of charged particles across a multifarious expanse of physical and biological systems. The numerical schemes presented here are based on the energy variational formulation. It allows the PNP system to be reformulated as a non-constant mobility $H^{-1}$ gradient flow, incorporating singular logarithmic energy potentials. To achieve a fully discrete numerical scheme, we employ a combination of first/second-order semi-implicit time discretization methods, coupled with either the $k$-th order direct discontinuous Galerkin (DDG) method or the finite element (FE) method for spatial discretization. The schemes are verified to possess positivity preservation and energy stability. Optimal error estimates and particular superconvergence results for the fully-discrete numerical solution are established. Numerical experiments are provided to showcase the accuracy, efficiency, and robustness of the proposed schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03892v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Waixiang Cao, Yuzhe Qin, Minqiang Xu</dc:creator>
    </item>
    <item>
      <title>Convergence Properties of Nonlinear GMRES Applied to Linear Systems</title>
      <link>https://arxiv.org/abs/2502.05355</link>
      <description>arXiv:2502.05355v2 Announce Type: replace 
Abstract: The Nonlinear GMRES (NGMRES) proposed by Washio and Oosterlee [Electron. Trans. Numer. Anal, 6(271-290), 1997] is an acceleration method for fixed point iterations. It has been demonstrated to be effective, but its convergence properties have not been extensively studied in the literature so far. In this work we aim to close some of this gap, by offering a convergence analysis for NGMRES applied to linear systems. A central part of our analysis focuses on identifying equivalences between NGMRES and the classical Krylov subspace GMRES method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05355v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Greif, Yunhui He</dc:creator>
    </item>
    <item>
      <title>An equal-order virtual element framework for the coupled Stokes-Temperature equation with nonlinear viscosity</title>
      <link>https://arxiv.org/abs/2502.16196</link>
      <description>arXiv:2502.16196v2 Announce Type: replace 
Abstract: In this work, we present and analyze a novel stabilized virtual element formulation for the coupled Stokes-Temperature equation on polygonal meshes, employing equal-order element pairs where viscosity depends on temperature. The main objective of the proposed virtual elements is to develop a stabilized virtual element problem that avoids higher-order derivative terms and bilinear forms involving velocity, pressure and temperature, thereby avoiding the coupling between virtual element pairs. Moreover, it also reduces the violation of divergence-free constraints and offers reasonable control over the gradient of temperature. We derive the stability of the continuous solution using the Banach fixed-point theorem under sufficiently small data. The stabilized coupled virtual element problem is formulated using the local projection-based stabilization methods. We demonstrate the existence and uniqueness of the stabilized discrete solution using the Brouwer fixed-point theorem and the contraction theorem under the assumption of sufficient small data by showing the well-posedness of the stabilized decoupled virtual element problems. Furthermore, we derive the error estimates with optimal convergence rates in the energy norms. We present several numerical examples to confirm the theoretical findings. Additionally, the numerical behavior of the proposed stabilized method is shown to be robust with respect to linear and non-linear thermal conductivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16196v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sudheer Mishra, Natarajan E</dc:creator>
    </item>
    <item>
      <title>High-Order Flux Splitting Schemes for the Euler Equations of Gas Dynamics</title>
      <link>https://arxiv.org/abs/2504.01699</link>
      <description>arXiv:2504.01699v2 Announce Type: replace 
Abstract: We develop high-order flux splitting schemes for the one- and two-dimensional Euler equations of gas dynamics. The proposed schemes are high-order extensions of the existing first-order flux splitting schemes introduced in [ E. F. Toro, M. E. V\'azquez-Cend\'on, Comput. \&amp; Fluids, 70 (2012), pp. 1--12], where the Euler equations of gas dynamics are split into two subsystems: the advection and pressure systems. In this paper, we formulate the TV splitting within the semi-discrete framework to extend it to higher orders of accuracy for the first time. The second-order extension is obtained by using piecewise linear interpolant to reconstruct the one-sided point values of the unknowns. The third- and fifth-order schemes are developed using the finite-difference alternative weighted essentially non-oscillatory (A-WENO) framework, which is particularly effective in handling multidimensional problems and provides a more straightforward approach to constructing higher-order WENO schemes. These extensions significantly improve the resolution of discontinuities and the accuracy of numerical solutions, as demonstrated by a series of numerical experiments of both the one- and two-dimensional Euler equations of gas dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01699v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaoshuai Chu, Michael Herty, Eleuterio F. Toro</dc:creator>
    </item>
    <item>
      <title>Fast Convolutions on $\mathbb{Z}^2\backslash SE(2)$ via Radial Translational Dependence and Classical FFT</title>
      <link>https://arxiv.org/abs/2504.05149</link>
      <description>arXiv:2504.05149v2 Announce Type: replace 
Abstract: Let $\mathbb{Z}^2\backslash SE(2)$ denote the right coset space of the subgroup consisting of translational isometries of the orthogonal lattice $\mathbb{Z}^2$ in the non-Abelian group of planar motions $SE(2)$. This paper develops a fast and accurate numerical scheme for approximation of functions on $\mathbb{Z}^2\backslash SE(2)$. We address finite Fourier series of functions on the right coset space $\mathbb{Z}^2\backslash SE(2)$ using finite Fourier coefficients. The convergence/error analysis of finite Fourier coefficients are investigated. Conditions are established for the finite Fourier coefficients to converge to the Fourier coefficients. The matrix forms of the finite transforms are discussed. The implementation of the discrete method to compute numerical approximation of $SE(2)$-convolutions with functions which are radial in translations are considered. The paper is concluded by discussing capability of the numerical scheme to develop fast algorithms for approximating multiple convolutions with functions which are radial in translations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05149v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.GR</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arash Ghaani Farashahi, Gregory S. Chirikjian</dc:creator>
    </item>
    <item>
      <title>Central-Upwind Scheme for the Phase-Transition Traffic Flow Model</title>
      <link>https://arxiv.org/abs/2504.12153</link>
      <description>arXiv:2504.12153v2 Announce Type: replace 
Abstract: Phase-transition models are an important family of non-equilibrium continuum traffic flow models, offering properties like replicating complex traffic phenomena, maintaining anisotropy, and promising potentials for accommodating automated vehicles. However, their complex mathematical characteristics such as discontinuous solution domains, pose numerical challenges and limit their exploration in traffic flow theory. This paper focuses on developing a robust and accurate numerical method for phase-transition traffic flow models: We propose a second-order semi-discrete central-upwind scheme specifically designed for discontinuous phase-transition models. This novel scheme incorporates the projection onto appropriate flow domains, ensuring enhanced handling of discontinuities and maintaining physical consistency and accuracy. We demonstrate the efficacy of the proposed scheme through extensive and challenging numerical tests, showcasing their potential to facilitate further research and application in phase-transition traffic flow modeling. The ability of phase-transition models to embed the ``time-gap'' -- a crucial element in automated traffic control -- as a conserved variable aligns seamlessly with the control logic of automated vehicles, presenting significant potential for future applications, and the proposed numerical scheme now substantially facilitates exploring such potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12153v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaoshuai Chu, Alexander Kurganov, Saeed Mohammadian, Zuduo Zheng</dc:creator>
    </item>
    <item>
      <title>Efficient approximations of matrix multiplication using truncated decompositions</title>
      <link>https://arxiv.org/abs/2504.19308</link>
      <description>arXiv:2504.19308v2 Announce Type: replace 
Abstract: We exploit the truncated singular value decomposition and the recently proposed circulant decomposition for an efficient first-order approximation of the multiplication of large dense matrices. A decomposition of each matrix into a sum of a sparse matrix with relatively few dominant entries and a dense residue can also use the above approach, and we present methods for multiplication using a Fourier decomposition and a cycle decomposition-based sparsifications. The proposed methods scale as $\mathcal{O}(n^2 \log n)$ in arithmetic operations for $n \times n$ matrices for usable tolerances in relative error $\sim$ 1\%. Note that different decompositions for the two matrices $A$ and $B$ in the product $AB$ are also possible in this approach, using efficient a priori evaluations for suitability, to improve further on the error tolerances demonstrated here.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19308v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Suvendu Kar, Hariprasad M., Sai Gowri J. N., Murugesan Venkatapathi</dc:creator>
    </item>
    <item>
      <title>An $r$-adaptive finite element method using neural networks for parametric self-adjoint elliptic problem</title>
      <link>https://arxiv.org/abs/2504.21160</link>
      <description>arXiv:2504.21160v2 Announce Type: replace 
Abstract: This work proposes an $r$-adaptive finite element method (FEM) using neural networks (NNs). The method employs the Ritz energy functional as the loss function, currently limiting its applicability to symmetric and coercive problems, such as those arising from self-adjoint elliptic problems. The objective of the NN optimization is to determine the mesh node locations. For simplicity in two-dimensional problems, these locations are assumed to form a tensor product structure. The method is designed to solve parametric partial differential equations (PDEs). For each PDE parameter instance, the optimal $r$-adapted mesh generated by the NN is then solved with a standard FEM. The construction of FEM matrices and load vectors is implemented such that their derivatives with respect to mesh node locations, required for NN training, can be efficiently computed using automatic differentiation. However, the linear equation solver does not need to be differentiable, enabling the use of efficient, readily available `out-of-the-box' solvers. Consequently, the proposed approach retains the robustness and reliability guarantees of the FEM for each parameter instance, while the NN optimization adaptively adjusts the mesh node locations. The method's performance is demonstrated on parametric Poisson problems using one- and two-dimensional tensor product meshes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21160v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danilo Aballay, Federico Fuentes, Vicente Iligaray, \'Angel J. Omella, David Pardo, Manuel A. S\'anchez, Ignacio Tapia, Carlos Uriarte</dc:creator>
    </item>
    <item>
      <title>Convergent Operator-Splitting Scheme for Viscosity Solutions: A Foundation for Learning Domain-to-Solution Maps</title>
      <link>https://arxiv.org/abs/2505.20618</link>
      <description>arXiv:2505.20618v5 Announce Type: replace 
Abstract: This work introduces and rigorously analyzes a novel operator-splitting finite element scheme for approximating viscosity solutions of a broad class of constrained second-order partial differential equations. By decoupling the primary PDE evolution from the enforcement of constraints, the proposed method combines a stabilized finite element method for spatial discretization with an efficient semi-implicit time-stepping strategy.
  The cornerstone of our analysis is a proof that the scheme satisfies a discrete comparison principle. We demonstrate that under a mild time-step restriction and with appropriate stabilization, the discrete operator yields an M-matrix, which is sufficient to guarantee the scheme's monotonicity and consequent $L^\infty$-stability. These properties -- consistency, stability, and monotonicity -- are shown to be sufficient to prove convergence of the numerical approximation to the unique viscosity solution within the celebrated Barles--Souganidis framework. For solutions with enhanced regularity, we further establish an optimal-order error estimate of $O(\Delta t + h^2)$.
  The rigorously established stability of the scheme provides a blueprint for a novel Physics-Constrained Neural Operator (PCNO) architecture. We prove that by emulating the scheme's structure, the PCNO can provably break the curse of dimensionality for the challenging class of domain-to-solution mapping problems with complex topological variations, a problem for which standard learning approaches often fail. Numerical experiments for both a Hamilton-Jacobi equation with state constraints and a controlled reaction-diffusion system are presented to validate the theoretical findings and demonstrate the scheme's effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20618v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Po-Yi Wu</dc:creator>
    </item>
    <item>
      <title>Modular data assimilation for flow prediction</title>
      <link>https://arxiv.org/abs/2506.19002</link>
      <description>arXiv:2506.19002v2 Announce Type: replace 
Abstract: This report develops several modular, 2-step realizations (inspired by Kalman filter algorithms) of nudging-based data assimilation $$Step \ 1 \quad \frac{\widetilde {v}^{n+1}-v^{n}}{k}+v^{n}\cdot \nabla \widetilde {v}^{n+1}-\nu \triangle \widetilde {v}^{n+1}+\nabla q^{n+1}=f(x)$$ $$\nabla \cdot \widetilde {v}^{n+1}=0$$ $$Step \ 2 \quad \frac{v^{n+1}-\widetilde {v}^{n+1}}{k}-\chi I_{H}(u(t^{n+1})-v^{n+1})=0.$$ Several variants of this algorithm are developed. Three main results are developed. The first is that if $I_{H}^{2}=I_{H}$, then Step 2 can be rewritten as the explicit step $$v^{n+1}=\widetilde {v}^{n+1}+\frac{k\chi }{1+k\chi }[I_{H}u(t^{n+1})-I_{H} \widetilde {v}^{n+1}].$$ This means Step 2 has the greater stability of an implicit update and the lesser complexity of an explicit analysis step. The second is that the basic result of nudging (that for $H$ small enough and $\chi$ large enough predictability horizons are infinite) holds for one variant of the modular algorithm. The third is that, for any $H&gt;0$ and any $\chi&gt;0$, one step of the modular algorithm decreases the next step's error and increases (an estimate of) predictability horizons. A method synthesizing assimilation with eddy viscosity models of turbulence is also presented. Numerical tests are given, confirming the effectiveness of the modular assimilation algorithm. The conclusion is that the modular, 2-step method overcomes many algorithmic inadequacies of standard nudging methods and retains a robust mathematical foundation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19002v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aytekin \c{C}{\i}b{\i}k, Rui Fang, William Layton</dc:creator>
    </item>
    <item>
      <title>Spectral Approximation to Fractional Integral Operators</title>
      <link>https://arxiv.org/abs/2506.19332</link>
      <description>arXiv:2506.19332v2 Announce Type: replace 
Abstract: We propose a fast and stable method for constructing matrix approximations to fractional integral operators applied to series in the Chebyshev fractional polynomials. This method utilizes a recurrence relation satisfied by the fractional integrals of mapped Chebyshev polynomials and significantly outperforms existing methods. Through numerical examples, we highlight the broad applicability of these matrix approximations, including the solution of boundary value problems for fractional integral and differential equations. Additional applications include fractional differential equation initial value problems and fractional eigenvalue problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19332v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaolin Liu, Kuan Xu</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of online algorithms for vector-valued kernel regression</title>
      <link>https://arxiv.org/abs/2309.07779</link>
      <description>arXiv:2309.07779v3 Announce Type: replace-cross 
Abstract: We consider the problem of approximating the regression function $f_\mu:\, \Omega \to Y$ from noisy $\mu$-distributed vector-valued data $(\omega_m,y_m)\in\Omega\times Y$ by an online learning algorithm using a reproducing kernel Hilbert space $H$ (RKHS) as prior. In an online algorithm, i.i.d. samples become available one by one via a random process and are successively processed to build approximations to the regression function. Assuming that the regression function essentially belongs to $H$ (soft learning scenario), we provide estimates for the expected squared error in the RKHS norm of the approximations $f^{(m)}\in H$ obtained by a standard regularized online approximation algorithm. In particular, we show an order-optimal estimate $$ \mathbb{E}(\|\epsilon^{(m)}\|_H^2)\le C (m+1)^{-s/(2+s)},\qquad m=1,2,\ldots, $$ where $\epsilon^{(m)}$ denotes the error term after $m$ processed data, the parameter $0&lt;s\leq 1$ expresses an additional smoothness assumption on the regression function, and the constant $C$ depends on the variance of the input noise, the smoothness of the regression function, and other parameters of the algorithm. The proof, which is inspired by results on Schwarz iterative methods in the noiseless case, uses only elementary Hilbert space techniques and minimal assumptions on the noise, the feature map that defines $H$ and the associated covariance operator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07779v3</guid>
      <category>stat.ML</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Griebel, Peter Oswald</dc:creator>
    </item>
    <item>
      <title>Projected gradient descent accumulates at Bouligand stationary points</title>
      <link>https://arxiv.org/abs/2403.02530</link>
      <description>arXiv:2403.02530v3 Announce Type: replace-cross 
Abstract: This paper considers the projected gradient descent (PGD) algorithm for the problem of minimizing a continuously differentiable function on a nonempty closed subset of a Euclidean vector space. Without further assumptions, this problem is intractable and algorithms are only expected to find a stationary point. PGD generates a sequence in the set whose accumulation points are known to be Mordukhovich stationary. In this paper, these accumulation points are proven to be Bouligand stationary, and even proximally stationary if the gradient is locally Lipschitz continuous. These are the strongest stationarity properties that can be expected for the considered problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02530v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/24M1692782</arxiv:DOI>
      <arxiv:journal_reference>SIAM Journal on Optimization, Vol. 35, Iss. 2 (2025)</arxiv:journal_reference>
      <dc:creator>Guillaume Olikier, Ir\`ene Waldspurger</dc:creator>
    </item>
    <item>
      <title>Nearly self-similar blowup of generalized axisymmetric Navier-Stokes equations</title>
      <link>https://arxiv.org/abs/2405.10916</link>
      <description>arXiv:2405.10916v3 Announce Type: replace-cross 
Abstract: We numerically investigate the nearly self-similar blowup of the generalized axisymmetric Navier--Stokes equations. First, we rigorously derive the axisymmetric Navier--Stokes equations with swirl in both odd and even dimensions, marking the first such derivation for dimensions greater than three. Building on this, we generalize the equations to arbitrary positive real-valued dimensions, preserving many known properties of the 3D axisymmetric Navier--Stokes equations. To address scaling instability, we dynamically vary the space dimension to balance advection scaling along the r and z directions. A major contribution of this work is the development of a novel two-scale dynamic rescaling formulation, leveraging the dimension as an additional degree of freedom. This approach enables us to demonstrate a one-scale self-similar blowup with solution-dependent viscosity. Notably, the self-similar profile satisfies the axisymmetric Navier-Stokes equations with constant viscosity. We observe that the effective dimension is approximately 3.188 and appears to converge toward 3 as background viscosity diminishes. Furthermore, we introduce a rescaled Navier--Stokes model derived by dynamically rescaling the axial velocity in 3D. This model retains essential properties of 3D Navier-Stokes. Our numerical study shows that this rescaled Navier--Stokes model with two constant viscosity coefficients exhibits a nearly self-similar blowup with maximum vorticity growth on the order of O(10^{30}).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10916v3</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Y. Hou</dc:creator>
    </item>
    <item>
      <title>Generalized Ellipsoids</title>
      <link>https://arxiv.org/abs/2407.20362</link>
      <description>arXiv:2407.20362v2 Announce Type: replace-cross 
Abstract: We introduce a family of symmetric convex bodies called generalized ellipsoids of degree $d$ (GE-$d$s), with ellipsoids corresponding to the case of $d=0$. Generalized ellipsoids (GEs) retain many geometric, algebraic, and algorithmic properties of ellipsoids. We show that the conditions that the parameters of a GE must satisfy can be checked in strongly polynomial time, and that one can search for GEs of a given degree by solving a semidefinite program whose size grows only linearly with dimension. We give an example of a GE which does not have a second-order cone representation, but show that every GE has a semidefinite representation whose size depends linearly on both its dimension and degree. In terms of expressiveness, we prove that for any integer $m\geq 2$, every symmetric full-dimensional polytope with $2m$ facets and every intersection of $m$ co-centered ellipsoids can be represented exactly as a GE-$d$ with $d \leq 2m-3$. Using this result, we show that every symmetric convex body can be approximated arbitrarily well by a GE-$d$ and we quantify the quality of the approximation as a function of the degree $d$. Finally, we present applications of GEs to several areas, such as time-varying portfolio optimization, stability analysis of switched linear systems, robust-to-dynamics optimization, and robust polynomial regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20362v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.AG</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amir Ali Ahmadi, Abraar Chaudhry, Cemil Dibek</dc:creator>
    </item>
    <item>
      <title>The latent variable proximal point algorithm for variational problems with inequality constraints</title>
      <link>https://arxiv.org/abs/2503.05672</link>
      <description>arXiv:2503.05672v2 Announce Type: replace-cross 
Abstract: The latent variable proximal point (LVPP) algorithm is a framework for solving infinite-dimensional variational problems with pointwise inequality constraints. The algorithm is a saddle point reformulation of the Bregman proximal point algorithm. At the continuous level, the two formulations are equivalent, but the saddle point formulation is more amenable to discretization because it introduces a structure-preserving transformation between a latent function space and the feasible set. Working in this latent space is much more convenient for enforcing inequality constraints than the feasible set, as discretizations can employ general linear combinations of suitable basis functions, and nonlinear solvers can involve general additive updates. LVPP yields numerical methods with observed mesh-independence for obstacle problems, contact, fracture, plasticity, and others besides; in many cases, for the first time. The framework also extends to more complex constraints, providing means to enforce convexity in the Monge--Amp\`ere equation and handling quasi-variational inequalities, where the underlying constraint depends implicitly on the unknown solution. In this paper, we describe the LVPP algorithm in a general form and apply it to ten problems from across mathematics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05672v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J{\o}rgen S. Dokken, Patrick E. Farrell, Brendan Keith, Ioannis P. A. Papadopoulos, Thomas M. Surowiec</dc:creator>
    </item>
  </channel>
</rss>
