<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Nov 2025 05:01:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Sample Complexity of Quadratically Regularized Optimal Transport</title>
      <link>https://arxiv.org/abs/2511.09807</link>
      <description>arXiv:2511.09807v1 Announce Type: new 
Abstract: It is well known that optimal transport suffers from the curse of dimensionality: when the prescribed marginals are approximated by i.i.d. samples, the convergence of the empirical optimal transport problem to the population counterpart slows exponentially with increasing dimension. Entropically regularized optimal transport (EOT) has become the standard bearer in many statistical applications as it avoids this curse. Indeed, EOT has parametric sample complexity, as has been shown in a series of works based on the smoothness of the EOT potentials or the strong concavity of the dual EOT problem. However, EOT produces full-support approximations to the (sparse) OT problem, leading to overspreading in applications, and is computationally unstable for small regularization parameters. The most popular alternative is quadratically regularized optimal transport (QOT), which penalizes couplings by $L^2$ norm instead of relative entropy. QOT produces sparse approximations of OT and is computationally stable. However, its potentials are not smooth (do not belong to a Donsker class) and its dual problem is not strongly concave, hence QOT is often assumed to suffer from the curse of dimensionality. In this paper, we show that QOT nevertheless has parametric sample complexity. More precisely, we establish central limit theorems for its dual potentials, optimal couplings, and optimal costs. Our analysis is based on novel arguments that focus on the regularity of the support of the optimal QOT coupling. Specifically, we establish a Lipschitz property of its sections and leverage VC theory to bound its statistical complexity. Our analysis also leads to gradient estimates of independent interest, including $C^{1,1}$ regularity of the population potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09807v1</guid>
      <category>math.ST</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Gonz\'alez-Sanz, Eustasio del Barrio, Marcel Nutz</dc:creator>
    </item>
    <item>
      <title>Flatness of location-scale-shape models under the Wasserstein metric</title>
      <link>https://arxiv.org/abs/2511.09959</link>
      <description>arXiv:2511.09959v1 Announce Type: new 
Abstract: In Wasserstein geometry, one-dimensional location-scale models are flat both intrinsically and extrinsically-that is, they are curvature-free as well as totally geodesic in the space of probability distributions. In this study, we introduce a class of one-dimensional statistical models, termed the location-scale-shape model, which generalizes several distributions used in extreme-value theory. This model has a shape parameter that specifies the tail heaviness. We investigate the Wasserstein geometry of the location-scale-shape model and show that it is intrinsically flat but extrinsically curved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09959v1</guid>
      <category>math.ST</category>
      <category>math.DG</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ayumu Fukushi, Yoshinori Nakanishi-Ohno, Takeru Matsuda</dc:creator>
    </item>
    <item>
      <title>On High-Dimensional Change-Point Detection Based on Pairwise Distances</title>
      <link>https://arxiv.org/abs/2511.10078</link>
      <description>arXiv:2511.10078v1 Announce Type: new 
Abstract: In change-point analysis, one aims at finding the locations of abrupt distributional changes (if any) in a sequence of multivariate observations. In this article, we propose some nonparametric methods based on averages of pairwise distances for this purpose. These distance-based methods can be conveniently used for high-dimensional data even when the dimension is much larger than the sample size (i.e., the length of the sequence). We carry out some theoretical investigations on the behaviour of these methods not only when the dimension of the data remains fixed and the sample size grows to infinity, but also in situations where the dimension diverges to infinity while the sample size may or may not grow with the dimension. Several high-dimensional datasets are analyzed to compare the empirical performance of these proposed methods against some state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10078v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Spandan Ghoshal, Bilol Banerjee, Anil K. Ghosh</dc:creator>
    </item>
    <item>
      <title>Rough Hurst function estimation</title>
      <link>https://arxiv.org/abs/2511.10103</link>
      <description>arXiv:2511.10103v1 Announce Type: new 
Abstract: The fractional Brownian motion (fBm) is parameterized by the Hurst exponent $H\in(0,1)$, which determines the dependence structure and regularity of sample paths. Empirical findings suggest that the Hurst exponent may be non-constant in time, giving rise to the so-called multifractional Brownian motion (mBm). The It\^o-mBm is an alternative to the classical mBm, and has been shown to admit more intuitive sample path properties in case the Hurst function is rough. In this paper, we show that the It\^o-mBm also allows for a simplified statistical treatment compared to the classical mBm. In particular, estimation of the local Hurst parameter $H(t)$ with H\"older exponent $\eta&gt;0$ achieves rates of convergence which are standard in nonparametric regression, whereas similar results for the classical mBm only hold for the smoother regime $\eta&gt;1$. Furthermore, we derive an estimator of the integrated Hurst exponent $\int_0^t H(s)\, ds$ which achieves a parametric rate of convergence, and use it to construct goodness-of-fit tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10103v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Mies, Benedikt Wilkens</dc:creator>
    </item>
    <item>
      <title>Hawkes autoregressive processes: a new model for multiscale and heterogeneous processes</title>
      <link>https://arxiv.org/abs/2511.10132</link>
      <description>arXiv:2511.10132v1 Announce Type: new 
Abstract: Both Hawkes processes and autoregressive processes depend on linear functionals of their past while modelling different types of data. As different datasets obtained through the recording of the same phenomena may be heterogeneous and occur at different timescales, it is important to study multiscale and heterogenous processes, such as those obtained by combining Hawkes and autoregressive processes. In this paper, we present probabilistic results for this new Hawkes autoregressive (HAR) model, including the existence of a stationary version, a cluster representation, exponential moments and asymptotic behaviour. We also derive statistical results for estimating interactions, extending the well-known LASSO estimation method to Hawkes Autoregressive (HAR) processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10132v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Th\'eo Leblanc</dc:creator>
    </item>
    <item>
      <title>Multi-sensor Distributed Fusion Estimation for $\mathbb{T}_k$-proper Factorizable Signals in Sensor Networks with Fading Measurements</title>
      <link>https://arxiv.org/abs/2511.10141</link>
      <description>arXiv:2511.10141v1 Announce Type: new 
Abstract: The challenge of distributed fusion estimation is investigated for a class of four-dimensional (4D) commutative hypercomplex signals that are $\mathbb{T}_k$-proper factorizable, within the framework of multiple-sensor networks with different fading measurement rates. The fading effects affecting each sensor's measurements are modeled as a stochastic variables with known second-order statistical properties. The estimation process is conducted exclusively based on these second-order statistics. Then, by exploiting the $\mathbb{T}_k$-properness property within a tessarine framework, the dimensionality of the problem is significantly reduced. This reduction in dimensionality enables the development of distributed fusion filtering, prediction, and smoothing algorithms that entail lower computational effort compared with real-valued approaches.
  The performance of the suggested algorithms is assessed through numerical experiments under various uncertainty conditions and $T_k$-proper contexts. Furthermore, simulation results confirm that $\mathbb{T}_k$-proper estimators outperform their quaternion-domain counterparts, underscoring their practical advantages. These findings highlight the potential of $\mathbb{T}_k$-proper estimation techniques for improving multi-sensor data fusion in applications where efficient signal processing is essential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10141v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rosa M. Fern\'andez-Alcal\'a, Jos\'e D. Jim\'enez-L\'opez, Jes\'us Navarro-Moreno, Juan C. Ruiz-Molina</dc:creator>
    </item>
    <item>
      <title>Model-oriented Graph Distances via Partially Ordered Sets</title>
      <link>https://arxiv.org/abs/2511.10625</link>
      <description>arXiv:2511.10625v1 Announce Type: new 
Abstract: A well-defined distance on the parameter space is key to evaluating estimators, ensuring consistency, and building confidence sets. While there are typically standard distances to adopt in a continuous space, this is not the case for combinatorial parameters such as graphs that represent statistical models. Existing proposals like the structural Hamming distance are defined on the graphs rather than the models they represent and can hence lead to undesirable behaviors. We propose a model-oriented framework for defining the distance between graphs that is applicable across many different graph classes. Our approach treats each graph as a statistical model and organizes the graphs in a partially ordered set based on model inclusion. This induces a neighborhood structure, from which we define the model-oriented distance as the length of a shortest path through neighbors, yielding a metric in the space of graphs. We apply this framework to both probabilistic graphical models (e.g., undirected graphs and completed partially directed acyclic graphs) and causal graphical models (e.g., directed acyclic graphs and maximally oriented partially directed acyclic graphs). We analyze the theoretical and empirical behaviors of model-oriented distances. Algorithmic tools are also developed for computing and bounding these distances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10625v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Armeen Taeb, F. Richard Guo, Leonard Henckel</dc:creator>
    </item>
    <item>
      <title>Distributional Treatment Effect Estimation across Heterogeneous Sites via Optimal Transport</title>
      <link>https://arxiv.org/abs/2511.09759</link>
      <description>arXiv:2511.09759v1 Announce Type: cross 
Abstract: We propose a novel framework for synthesizing counterfactual treatment group data in a target site by integrating full treatment and control group data from a source site with control group data from the target. Departing from conventional average treatment effect estimation, our approach adopts a distributional causal inference perspective by modeling treatment and control as distinct probability measures on the source and target sites. We formalize the cross-site heterogeneity (effect modification) as a push-forward transformation that maps the joint feature-outcome distribution from the source to the target site. This transformation is learned by aligning the control group distributions between sites using an Optimal Transport-based procedure, and subsequently applied to the source treatment group to generate the synthetic target treatment distribution. Under general regularity conditions, we establish theoretical guarantees for the consistency and asymptotic convergence of the synthetic treatment group data to the true target distribution. Simulation studies across multiple data-generating scenarios and a real-world application to patient-derived xenograft data demonstrate that our framework robustly recovers the full distributional properties of treatment effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09759v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Borna Bateni, Yubai Yuan, Qi Xu, Annie Qu</dc:creator>
    </item>
    <item>
      <title>Masking criteria for selecting an imputation model</title>
      <link>https://arxiv.org/abs/2511.10048</link>
      <description>arXiv:2511.10048v1 Announce Type: cross 
Abstract: The masking-one-out (MOO) procedure, masking an observed entry and comparing it versus its imputed values, is a very common procedure for comparing imputation models. We study the optimum of this procedure and generalize it to a missing data assumption and establish the corresponding semi-parametric efficiency theory. However, MOO is a measure of prediction accuracy, which is not ideal for evaluating an imputation model. To address this issue, we introduce three modified MOO criteria, based on rank transformation, energy distance, and likelihood principle, that allow us to select an imputation model that properly account for the stochastic nature of data. The likelihood approach further enables an elegant framework of learning an imputation model from the data and we derive its statistical and computational learning theories as well as consistency of BIC model selection. We also show how MOO is related to the missing-at-random assumption. Finally, we introduce the prediction-imputation diagram, a two-dimensional diagram visually comparing both the prediction and imputation utilities for various imputation models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10048v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanjiao Yang, Daniel Suen, Yen-Chi Chen</dc:creator>
    </item>
    <item>
      <title>Bivariate phase-type distributions for experience rating in disability insurance</title>
      <link>https://arxiv.org/abs/2405.19248</link>
      <description>arXiv:2405.19248v3 Announce Type: replace 
Abstract: In this paper, we consider the problem of experience rating within the classic Markov chain life insurance framework. We begin by establishing a link between mixed Poisson distributions and the problem of pricing group disability insurance contracts that exhibit heterogeneity. We focus on shrinkage estimation of disability and recovery rates, taking into account sampling effects such as right-censoring. We then investigate some specific multivariate mixed Poisson models with mixing distributions encompassing independent Gamma, hierarchical Gamma, and multivariate phase-type. In particular, we demonstrate how maximum likelihood estimation for these models can be performed using expectation-maximization algorithms, which might be of independent interest. Finally, we showcase the practicality of the proposed shrinkage estimators through a numerical study based on simulated yet realistic insurance data. Our findings highlight that by allowing for dependency between latent group effects, estimates of recovery and disability rates mutually improve, leading to enhanced predictive performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19248v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Furrer, Jacob Juhl S{\o}rensen, Jorge Yslas</dc:creator>
    </item>
    <item>
      <title>Likelihood Geometry of the Gumbel's Type-I Bivariate Exponential Distribution</title>
      <link>https://arxiv.org/abs/2502.04179</link>
      <description>arXiv:2502.04179v2 Announce Type: replace 
Abstract: In algebraic statistics, the maximum likelihood degree of a statistical model refers to the number of solutions (counted with multiplicity) of the score equations over the complex field. In this paper, the maximum likelihood degree of the association parameter of Gumbel's Type-I bivariate exponential distribution is investigated using algebraic techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04179v2</guid>
      <category>math.ST</category>
      <category>math.AC</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pooja Yadav, Tanuja Srivastava</dc:creator>
    </item>
    <item>
      <title>Likelihood asymptotics of stationary Gaussian arrays</title>
      <link>https://arxiv.org/abs/2502.09229</link>
      <description>arXiv:2502.09229v2 Announce Type: replace 
Abstract: This paper develops an asymptotic likelihood theory for triangular arrays of stationary Gaussian time series depending on a multidimensional unknown parameter. We give sufficient conditions for the associated sequence of statistical models to be locally asymptotically normal in Le Cam's sense, which in particular implies the asymptotic efficiency of the maximum likelihood estimator. Unique features of the array setting covered by our theory include potentially nondiagonal rate matrices as well as spectral densities that satisfy different power-law bounds at different frequencies and may fail to be uniformly integrable. To illustrate our theory, we study efficient estimation for Gaussian processes sampled at high frequency and for a class of autoregressive models with moderate deviations from a unit root.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09229v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carsten H. Chong, Fabian Mies</dc:creator>
    </item>
    <item>
      <title>Rebalancing Markov jump processes for non-reversible continuous-time sampling</title>
      <link>https://arxiv.org/abs/2504.12190</link>
      <description>arXiv:2504.12190v3 Announce Type: replace 
Abstract: Markov chain Monte Carlo methods are central in computational statistics, and typically rely on detailed balance to ensure invariance with respect to a target distribution. Although straightforward to construct by Metropolization, this can induce diffusion-like exploration of the sample space, requiring careful tuning of parameters such as step size. We introduce a general mechanism for constructing non-reversible continuous-time samplers, without requiring detailed balance. Our approach transforms jump processes satisfying a skew-detailed balance condition for a reference measure into processes sampling a target measure absolutely continuous with respect to it. Unbounded balancing functions allow such samplers to dynamically select favourable transitions. We establish invariance under weak criteria and demonstrate how to verify geometric ergodicity. Numerical experiments demonstrate that the resulting samplers are more robust to parameter tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12190v3</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Jansson, Moritz Schauer, Ruben Seyer, Akash Sharma</dc:creator>
    </item>
    <item>
      <title>Minimax Analysis of Estimation Problems in Coherent Imaging</title>
      <link>https://arxiv.org/abs/2508.18503</link>
      <description>arXiv:2508.18503v2 Announce Type: replace 
Abstract: Unlike conventional imaging modalities, such as magnetic resonance imaging, which are often well described by a linear regression framework, coherent imaging systems follow a significantly more complex model. In these systems, the task is to estimate the unknown image ${\boldsymbol x}_o \in \mathbb{R}^n$ from observations ${\boldsymbol y}_1, \ldots, {\boldsymbol y}_L \in \mathbb{R}^m$ of the form \[ {\boldsymbol y}_l = A_l X_o {\boldsymbol w}_l + {\boldsymbol z}_l, \quad l = 1, \ldots, L, \] where $X_o = \mathrm{diag}({\boldsymbol x}_o)$ is an $n \times n$ diagonal matrix, ${\boldsymbol w}_1, \ldots, {\boldsymbol w}_L \stackrel{\text{i.i.d.}}{\sim} \mathcal{N}(0,I_n)$ represent speckle noise, and ${\boldsymbol z}_1, \ldots, {\boldsymbol z}_L \stackrel{\text{i.i.d.}}{\sim} \mathcal{N}(0,\sigma_z^2 I_m)$ denote additive noise. The matrices $A_1, \ldots, A_L$ are known forward operators determined by the imaging system.
  The fundamental limits of conventional imaging systems have been extensively studied through sparse linear regression models. However, the limits of coherent imaging systems remain largely unexplored. Our goal is to close this gap by characterizing the minimax risk of estimating ${\boldsymbol x}_o$ in high-dimensional settings.
  Motivated by insights from sparse regression, we observe that the structure of ${\boldsymbol x}_o$ plays a crucial role in determining the estimation error. In this work, we adopt a general notion of structure based on the covering numbers, which is more appropriate for coherent imaging systems. We show that the minimax mean squared error (MSE) scales as \[ \frac{\max\{\sigma_z^4,\, m^2,\, n^2\}\, k \log n}{m^2 n L}, \] where $k$ is a parameter that quantifies the effective complexity of the class of images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18503v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Xing, Soham Jana, Arian Maleki</dc:creator>
    </item>
    <item>
      <title>Minimax and adaptive estimation of general linear functionals under sparsity</title>
      <link>https://arxiv.org/abs/2509.25595</link>
      <description>arXiv:2509.25595v2 Announce Type: replace 
Abstract: We study estimation of the linear functional $\eta^\top \theta$ of a high-dimensional $s$-sparse mean vector $\theta$ when the loading vector $\eta$ is arbitrary and the noise is symmetric with exponentially decaying tails. Previous analyses for equal loadings treat coordinates as exchangeable and do not yield sharp rates when loadings vary. We give a sharp nonasymptotic characterization of the oracle minimax rate that makes explicit its dependence on $s$, $\eta$, and the noise tail parameter. To attain this rate, we construct an estimator that treats large and small loadings differently with a cutoff calibrated to $\eta$, and we prove a matching lower bound using a sparse prior whose inclusion probabilities and signal magnitudes depend on $\eta$. For unknown sparsity, we identify an $\eta$-dependent threshold for a Lepski type selection and show that the resulting estimator achieves the oracle minimax rate up to a logarithmic factor, and that it cannot be improved for a broad, verifiable class of loading vectors. In analytic examples, we demonstrate how heterogeneity in $\eta$ changes the minimax and adaptive rates. We also extend the theory to non-symmetric noise, hypothesis testing, and estimation with unknown noise variance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25595v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Xie, Dongming Huang</dc:creator>
    </item>
    <item>
      <title>On robust hypothesis testing with respect to Hellinger distance</title>
      <link>https://arxiv.org/abs/2510.16750</link>
      <description>arXiv:2510.16750v2 Announce Type: replace 
Abstract: We study the hypothesis testing problem where the observed samples need not come from either of the specified hypotheses (distributions). In such a situation, we would like our test to be robust to this misspecification and output the distribution closer in Hellinger distance. If the underlying distribution is close to being equidistant from the hypotheses, then this would not be possible. Our main result is quantifying how close the underlying distribution has to be to either of the hypotheses. We also study the composite testing problem, where each hypothesis is a Hellinger ball around a fixed distribution. A generalized likelihood ratio test is known to work for this problem. We give an alternate test for the same.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16750v2</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eeshan Modak</dc:creator>
    </item>
    <item>
      <title>Selecting valid adjustment sets with uncertain causal graphs</title>
      <link>https://arxiv.org/abs/2511.01662</link>
      <description>arXiv:2511.01662v2 Announce Type: replace 
Abstract: Precise knowledge of causal directed acyclic graphs (DAGs) is assumed for standard approaches towards valid adjustment set selection for unbiased estimation, but in practice, the DAG is often inferred from data or expert knowledge, introducing uncertainty. We present techniques to identify valid adjustment sets despite potential errors in the estimated causal graph. Specifically, we assume that only the skeleton of the DAG is known. Under a Bayesian framework, we place a prior on graphs and wish to sample graphs and compute the posterior probability of each set being valid; however, directly doing so is inefficient as the number of sets grows exponentially with the number of nodes in the DAG. We develop theory and techniques so that a limited number of sets are tested while the probability of finding valid adjustment sets remains high. Empirical results demonstrate the effectiveness of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01662v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongyi Hu, St\'ephanie van der Pas</dc:creator>
    </item>
    <item>
      <title>Extending Characterizations of Multivariate Laws via Distance Distributions</title>
      <link>https://arxiv.org/abs/2511.04870</link>
      <description>arXiv:2511.04870v2 Announce Type: replace 
Abstract: We extend a theorem of Maa, Pearl, and Bartoszynski, which links equality of interpoint distance distributions to equality of underlying multivariate distributions, beyond the restrictive class of homogeneous, translation-invariant distance functions. Our approach replaces geometric assumptions on the distance with analytic conditions: volume-regularity of distance-induced balls, Lebesgue differentiability with respect to the distance, and bounded centered oscillations of densities. Under these conditions, equality of interpoint distance distributions continues to imply equality of the generating laws. The result persists under monotone continuous transformations of homogeneous, translation-invariant distances, recovering the original statement, and it extends to compact Riemannian manifolds equipped with the geodesic metric. We further develop a quantitative version of the theorem, i.e., inequalities that connect discrepancies of interpoint distance distributions to the $L^2$-distance between densities, and obtain explicit rates under Ahlfors $\alpha$-regularity of the distance function and $\beta$-H\"older continuity of densities, capturing dependence on dimensionality. Several representative examples illustrate the applicability of the generalization to domain-specific distances used in modern statistics. The examples include non-homogeneous non-translation invariant distances such as Canberra, entropic distances, and the Bray--Curtis dissimilarity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04870v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Annika Betken, Aljosa Marjanovic, Katharina Proksch</dc:creator>
    </item>
    <item>
      <title>The Algorithmic Phase Transition in Symmetric Correlated Spiked Wigner Model</title>
      <link>https://arxiv.org/abs/2511.06040</link>
      <description>arXiv:2511.06040v2 Announce Type: replace 
Abstract: We study the computational task of detecting and estimating correlated signals in a pair of spiked Wigner matrices. Our model consists of observations
  $$
  X = \tfrac{\lambda}{\sqrt{n}} xx^{\top} + W \,, \quad Y = \tfrac{\mu}{\sqrt{n}} yy^{\top} + Z \,.
  $$
  where $x,y \in \mathbb R^n$ are signal vectors with norm $\|x\|,\|y\| \approx\sqrt{n}$ and correlation $\langle x,y \rangle \approx \rho\|x\|\|y\|$, while $W,Z$ are independent Gaussian Wigner matrices. We propose an efficient algorithm that succeeds whenever $F(\lambda,\mu,\rho)&gt;1$, where
  $$
  F(\lambda,\mu,\rho)=\max\Big\{ \lambda,\mu, \frac{ \lambda^2 \rho^2 }{ 1-\lambda^2+\lambda^2 \rho^2 } + \frac{ \mu^2 \rho^2 }{ 1-\mu^2+\mu^2 \rho^2 } \Big\} \,.
  $$
  Our result shows that an algorithm can leverage the correlation between the spikes to detect and estimate the signals even in regimes where efficiently recovering either $x$ from $X$ alone or $y$ from $Y$ alone is believed to be computationally infeasible.
  We complement our algorithmic result with evidence for a matching computational lower bound. In particular, we prove that when $F(\lambda,\mu,\rho)&lt;1$, all algorithms based on {\em low-degree polynomials} fails to distinguish $(X,Y)$ with two independent Wigner matrices. This low-degree analysis strongly suggests that $F(\lambda,\mu,\rho)=1$ is the precise computation threshold for this problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06040v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhangsong Li</dc:creator>
    </item>
    <item>
      <title>Unbiased estimators for the Heston model with stochastic interest rates</title>
      <link>https://arxiv.org/abs/2301.12072</link>
      <description>arXiv:2301.12072v3 Announce Type: replace-cross 
Abstract: We combine the unbiased estimators in Rhee and Glynn (Operations Research: 63(5), 1026-1043, 2015) and the Heston model with stochastic interest rates. Specifically, we first develop a semi-exact log-Euler scheme for the Heston model with stochastic interest rates. Then, under mild assumptions, we show that the convergence rate in the $L^2$ norm is $O(h)$, where $h$ is the step size. The result applies to a large class of models, such as the Heston-Hull-While model, the Heston-CIR model and the Heston-Black-Karasinski model. Numerical experiments support our theoretical convergence rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.12072v3</guid>
      <category>q-fin.CP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Zheng, Jiangtao Pan</dc:creator>
    </item>
    <item>
      <title>Automatic Debiased Machine Learning for Smooth Functionals of Nonparametric M-Estimands</title>
      <link>https://arxiv.org/abs/2501.11868</link>
      <description>arXiv:2501.11868v2 Announce Type: replace-cross 
Abstract: We develop a unified framework for automatic debiased machine learning (autoDML) to simplify inference for a broad class of statistical parameters. It applies to any smooth functional of a nonparametric \emph{M-estimand}, defined as the minimizer of a population risk over an infinite-dimensional linear space. Examples of M-estimands include counterfactual regression, quantile, and survival functions, as well as conditional average treatment effects. Rather than requiring manual derivation of influence functions, the framework automates the construction of debiased estimators using three components: the gradient and Hessian of the loss function and a linear approximation of the target functional. Estimation reduces to solving two risk minimization problems -- one for the M-estimand and one for a Riesz representer. The framework accommodates Neyman-orthogonal loss functions depending on nuisance parameters and extends to vector-valued M-estimands through joint risk minimization. For functionals of M-estimands, we characterize the efficient influence function and construct efficient autoDML estimators via one-step correction, targeted minimum loss estimation, and sieve-based plug-in methods. Under quadratic risk, these estimators exhibit double robustness for linear functionals. We further show they are insensitive to mild misspecification of the M-estimand model, incurring only second-order bias. We illustrate the method by estimating long-term survival probabilities under a semiparametric beta-geometric model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11868v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lars van der Laan, Aurelien Bibaut, Nathan Kallus, Alex Luedtke</dc:creator>
    </item>
    <item>
      <title>Asymmetric Space-Time Covariance Functions via Hierarchical Mixtures</title>
      <link>https://arxiv.org/abs/2511.07959</link>
      <description>arXiv:2511.07959v2 Announce Type: replace-cross 
Abstract: This work is focused on constructing space-time covariance functions through a hierarchical mixture approach that can serve as building blocks for capturing complex dependency structures. This hierarchical mixture approach provides a unified modeling framework that not only constructs a new class of asymmetric space-time covariance functions with closed-form expressions, but also provides corresponding space-time process representations, which further unify constructions for many existing space-time covariance models. This hierarchical mixture framework decomposes the complexity of model specification at different levels of hierarchy, for which parsimonious covariance models can be specified with simple mixing measures to yield flexible properties and closed-form derivation. A characterization theorem is provided for the hierarchical mixture approach on how the mixing measures determine the statistical properties of covariance functions. Several new covariance models resulting from this hierarchical mixture approach are discussed in terms of their practical usefulness. A theorem is also provided to construct a general class of valid asymmetric space-time covariance functions with arbitrary and possibly different degrees of smoothness in space and in time and flexible long-range dependence. The proposed covariance class also bridges a theoretical gap in using the Lagrangian reference framework. The superior performance of several new parsimonious covariance models over existing models is verified with the well-known Irish wind data and the U.S. air temperature data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07959v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pulong Ma</dc:creator>
    </item>
  </channel>
</rss>
