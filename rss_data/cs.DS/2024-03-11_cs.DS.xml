<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 11 Mar 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 11 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Improved Lower Bound for Differentially Private Facility Location</title>
      <link>https://arxiv.org/abs/2403.04874</link>
      <description>arXiv:2403.04874v1 Announce Type: new 
Abstract: We consider the differentially private (DP) facility location problem in the so called super-set output setting proposed by Gupta et al. [SODA 2010]. The current best known expected approximation ratio for an $\epsilon$-DP algorithm is $O\left(\frac{\log n}{\sqrt{\epsilon}}\right)$ due to Cohen-Addad et al. [AISTATS 2022] where $n$ denote the size of the metric space, meanwhile the best known lower bound is $\Omega(1/\sqrt{\epsilon})$ [NeurIPS 2019].
  In this short note, we give a lower bound of $\tilde{\Omega}\left(\min\left\{\log n, \sqrt{\frac{\log n}{\epsilon}}\right\}\right)$ on the expected approximation ratio of any $\epsilon$-DP algorithm, which is the first evidence that the approximation ratio has to grow with the size of the metric space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04874v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pasin Manurangsi</dc:creator>
    </item>
    <item>
      <title>NP-Completeness for the Space-Optimality of Double-Array Tries</title>
      <link>https://arxiv.org/abs/2403.04951</link>
      <description>arXiv:2403.04951v1 Announce Type: new 
Abstract: Indexing a set of strings for prefix search or membership queries is a fundamental task with many applications such as information retrieval or database systems. A classic abstract data type for modelling such an index is a trie. Due to the fundamental nature of this problem, it has sparked much interest, leading to a variety of trie implementations with different characteristics. A trie implementation that has been well-used in practice is the double-array (trie) consisting of merely two integer arrays. While a traversal takes constant time per node visit, the needed space consumption in computer words can be as large as the product of the number of nodes and the alphabet size. Despite that several heuristics have been proposed on lowering the space requirements, we are unaware of any theoretical guarantees.
  In this paper, we study the decision problem whether there exists a double-array of a given size. To this end, we first draw a connection to the sparse matrix compression problem, which makes our problem NP-complete for alphabet sizes linear to the number of nodes. We further propose a reduction from the restricted directed Hamiltonian path problem, leading to NP-completeness even for logarithmic-sized alphabets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04951v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hideo Bannai, Keisuke Goto, Shunsuke Kanda, Dominik K\"oppl</dc:creator>
    </item>
    <item>
      <title>A basic lower bound for property testing</title>
      <link>https://arxiv.org/abs/2403.04999</link>
      <description>arXiv:2403.04999v1 Announce Type: new 
Abstract: An $\epsilon$-test for any non-trivial property (one for which there are both satisfying inputs and inputs of large distance from the property) should use a number of queries that is at least inversely proportional in $\epsilon$. However, to the best of our knowledge there is no reference proof for this intuition. Such a proof is provided here. It is written so as to not require any prior knowledge of the related literature, and in particular does not use Yao's method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04999v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eldar Fischer</dc:creator>
    </item>
    <item>
      <title>Data-Dependent LSH for the Earth Mover's Distance</title>
      <link>https://arxiv.org/abs/2403.05041</link>
      <description>arXiv:2403.05041v1 Announce Type: new 
Abstract: We give new data-dependent locality sensitive hashing schemes (LSH) for the Earth Mover's Distance ($\mathsf{EMD}$), and as a result, improve the best approximation for nearest neighbor search under $\mathsf{EMD}$ by a quadratic factor. Here, the metric $\mathsf{EMD}_s(\mathbb{R}^d,\ell_p)$ consists of sets of $s$ vectors in $\mathbb{R}^d$, and for any two sets $x,y$ of $s$ vectors the distance $\mathsf{EMD}(x,y)$ is the minimum cost of a perfect matching between $x,y$, where the cost of matching two vectors is their $\ell_p$ distance. Previously, Andoni, Indyk, and Krauthgamer gave a (data-independent) locality-sensitive hashing scheme for $\mathsf{EMD}_s(\mathbb{R}^d,\ell_p)$ when $p \in [1,2]$ with approximation $O(\log^2 s)$. By being data-dependent, we improve the approximation to $\tilde{O}(\log s)$.
  Our main technical contribution is to show that for any distribution $\mu$ supported on the metric $\mathsf{EMD}_s(\mathbb{R}^d, \ell_p)$, there exists a data-dependent LSH for dense regions of $\mu$ which achieves approximation $\tilde{O}(\log s)$, and that the data-independent LSH actually achieves a $\tilde{O}(\log s)$-approximation outside of those dense regions. Finally, we show how to "glue" together these two hashing schemes without any additional loss in the approximation.
  Beyond nearest neighbor search, our data-dependent LSH also gives optimal (distributional) sketches for the Earth Mover's Distance. By known sketching lower bounds, this implies that our LSH is optimal (up to $\mathrm{poly}(\log \log s)$ factors) among those that collide close points with constant probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05041v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajesh Jayaram, Erik Waingarten, Tian Zhang</dc:creator>
    </item>
    <item>
      <title>Single Family Algebra Operation on ZDDs Leads To Exponential Blow-Up</title>
      <link>https://arxiv.org/abs/2403.05074</link>
      <description>arXiv:2403.05074v1 Announce Type: new 
Abstract: Zero-suppressed binary decision diagram (ZDD) is a data structure to represent a family of (sub)sets compactly, and it can be used as a succinct index for a family of sets. To build ZDD representing a desired family of sets, there are many transformation operations that take ZDDs as inputs and output ZDD representing the resultant family after performing operations such as set union and intersection. However, except for some basic operations, the worst-time complexity of taking such transformation on ZDDs has not been extensively studied, and some contradictory statements about it have arisen in the literature. In this paper, we show that many transformation operations on ZDDs cannot be performed in worst-case polynomial time with respect to the size of input ZDDs. This refutes some of the folklore circulated in past literature and resolves an open problem raised by Knuth. Our results are stronger in that such blow-up of computational time occurs even when the ordering, which has a significant impact on the efficiency of treating ZDDs, is reasonable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05074v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kengo Nakamura, Masaaki Nishino, Shuhei Denzumi</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithms for Personalized PageRank Computation: A Survey</title>
      <link>https://arxiv.org/abs/2403.05198</link>
      <description>arXiv:2403.05198v1 Announce Type: new 
Abstract: Personalized PageRank (PPR) is a traditional measure for node proximity on large graphs. For a pair of nodes $s$ and $t$, the PPR value $\pi_s(t)$ equals the probability that an $\alpha$-discounted random walk from $s$ terminates at $t$ and reflects the importance between $s$ and $t$ in a bidirectional way. As a generalization of Google's celebrated PageRank centrality, PPR has been extensively studied and has found multifaceted applications in many fields, such as network analysis, graph mining, and graph machine learning. Despite numerous studies devoted to PPR over the decades, efficient computation of PPR remains a challenging problem, and there is a dearth of systematic summaries and comparisons of existing algorithms. In this paper, we recap several frequently used techniques for PPR computation and conduct a comprehensive survey of various recent PPR algorithms from an algorithmic perspective. We classify these approaches based on the types of queries they address and review their methodologies and contributions. We also discuss some representative algorithms for computing PPR on dynamic graphs and in parallel or distributed environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05198v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingji Yang, Hanzhi Wang, Zhewei Wei, Sibo Wang, Ji-Rong Wen</dc:creator>
    </item>
    <item>
      <title>Specifying and Verifying the Convergence Stairs of the Collatz Program</title>
      <link>https://arxiv.org/abs/2403.04777</link>
      <description>arXiv:2403.04777v1 Announce Type: cross 
Abstract: This paper presents an algorithmic method that, given a positive integer $j$, generates the $j$-th convergence stair containing all natural numbers from where the Collatz conjecture holds by exactly $j$ applications of the Collatz function. To this end, we present a novel formulation of the Collatz conjecture as a concurrent program, and provide the general case specification of the $j$-th convergence stair for any $j &gt; 0$. The proposed specifications provide a layered and linearized orientation of Collatz numbers organized in an infinite set of infinite binary trees. To the best of our knowledge, this is the first time that such a general specification is provided, which can have significant applications in analyzing and testing the behaviors of complex non-linear systems. We have implemented this method as a software tool that generates the Collatz numbers of individual stairs. We also show that starting from any value in any convergence stair the conjecture holds. However, to prove the conjecture, one has to show that every natural number will appear in some stair; i.e., the union of all stairs is equal to the set of natural numbers, which remains an open problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04777v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ali Ebnenasir</dc:creator>
    </item>
    <item>
      <title>A Mixed-Integer Conic Program for the Moving-Target Traveling Salesman Problem based on a Graph of Convex Sets</title>
      <link>https://arxiv.org/abs/2403.04917</link>
      <description>arXiv:2403.04917v1 Announce Type: cross 
Abstract: This paper introduces a new formulation that finds the optimum for the Moving-Target Traveling Salesman Problem (MT-TSP), which seeks to find a shortest path for an agent, that starts at a depot, visits a set of moving targets exactly once within their assigned time-windows, and returns to the depot. The formulation relies on the key idea that when the targets move along lines, their trajectories become convex sets within the space-time coordinate system. The problem then reduces to finding the shortest path within a graph of convex sets, subject to some speed constraints. We compare our formulation with the current state-of-the-art Mixed Integer Conic Program (MICP) solver for the MT-TSP. The experimental results show that our formulation outperforms the MICP for instances with up to 20 targets, with up to two orders of magnitude reduction in runtime, and up to a 60\% tighter optimality gap. We also show that the solution cost from the convex relaxation of our formulation provides significantly tighter lower bounds for the MT-TSP than the ones from the MICP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04917v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Allen George Philip, Zhongqiang Ren, Sivakumar Rathinam, Howie Choset</dc:creator>
    </item>
    <item>
      <title>Pattern Masking for Dictionary Matching</title>
      <link>https://arxiv.org/abs/2006.16137</link>
      <description>arXiv:2006.16137v2 Announce Type: replace 
Abstract: In the Pattern Masking for Dictionary Matching (PMDM) problem, we are given a dictionary $\mathcal{D}$ of $d$ strings, each of length $\ell$, a query string $q$ of length $\ell$, and a positive integer $z$, and we are asked to compute a smallest set $K\subseteq\{1,\ldots,\ell\}$, so that if $q[i]$, for all $i\in K$, is replaced by a wildcard, then $q$ matches at least $z$ strings from $\mathcal{D}$. The PMDM problem lies at the heart of two important applications featured in large-scale real-world systems: record linkage of databases that contain sensitive information, and query term dropping. In both applications, solving PMDM allows for providing data utility guarantees as opposed to existing approaches.
  We first show, through a reduction from the well-known $k$-Clique problem, that a decision version of the PMDM problem is NP-complete, even for strings over a binary alphabet. We present a data structure for PMDM that answers queries over $\mathcal{D}$ in time $\mathcal{O}(2^{\ell/2}(2^{\ell/2}+\tau)\ell)$ and requires space $\mathcal{O}(2^{\ell}d^2/\tau^2+2^{\ell/2}d)$, for any parameter $\tau\in[1,d]$. We also approach the problem from a more practical perspective. We show an $\mathcal{O}((d\ell)^{k/3}+d\ell)$-time and $\mathcal{O}(d\ell)$-space algorithm for PMDM if $k=|K|=\mathcal{O}(1)$. We generalize our exact algorithm to mask multiple query strings simultaneously. We complement our results by showing a two-way polynomial-time reduction between PMDM and the Minimum Union problem [Chlamt\'{a}\v{c} et al., SODA 2017]. This gives a polynomial-time $\mathcal{O}(d^{1/4+\epsilon})$-approximation algorithm for PMDM, which is tight under plausible complexity conjectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2006.16137v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Panagiotis Charalampopoulos, Huiping Chen, Peter Christen, Grigorios Loukides, Nadia Pisanti, Solon P. Pissis, Jakub Radoszewski</dc:creator>
    </item>
    <item>
      <title>Learning-Augmented Dynamic Submodular Maximization</title>
      <link>https://arxiv.org/abs/2311.13006</link>
      <description>arXiv:2311.13006v2 Announce Type: replace 
Abstract: In dynamic submodular maximization, the goal is to maintain a high-value solution over a sequence of element insertions and deletions with a fast update time. Motivated by large-scale applications and the fact that dynamic data often exhibits patterns, we ask the following question: can predictions be used to accelerate the update time of dynamic submodular maximization algorithms?
  We consider the model for dynamic algorithms with predictions where predictions regarding the insertion and deletion times of elements can be used for preprocessing. Our main result is an algorithm with an $O(poly(\log \eta, \log w, \log k))$ amortized update time over the sequence of updates that achieves a $1/2 - \epsilon$ approximation in expectation for dynamic monotone submodular maximization under a cardinality constraint $k$, where the prediction error $\eta$ is the number of elements that are not inserted and deleted within $w$ time steps of their predicted insertion and deletion times. This amortized update time is independent of the length of the stream and instead depends on the prediction error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13006v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arpit Agarwal, Eric Balkanski</dc:creator>
    </item>
    <item>
      <title>The Canadian Traveller Problem on outerplanar graphs</title>
      <link>https://arxiv.org/abs/2403.01872</link>
      <description>arXiv:2403.01872v2 Announce Type: replace 
Abstract: We study the PSPACE-complete $k$-Canadian Traveller Problem, where a weighted graph $G=(V,E,\omega)$ with a source $s\in V$ and a target $t\in V$ are given. This problem also has a hidden input $E_* \subsetneq E$ of cardinality at most $k$ representing blocked edges. The objective is to travel from $s$ to $t$ with the minimum distance. At the beginning of the walk, the blockages $E_*$ are unknown: the traveller discovers that an edge is blocked when visiting one of its endpoints. Online algorithms, also called strategies, have been proposed for this problem and assessed with the competitive ratio, i.e. the ratio between the distance actually traversed by the traveller divided by the distance we would have traversed knowing the blockages in advance.
  Even though the optimal competitive ratio is $2k+1$ even on unit-weighted planar graphs of treewidth 2, we design a polynomial-time strategy achieving competitive ratio $9$ on unit-weighted outerplanar graphs. This value $9$ also stands as a lower bound for this family of graphs as we prove that, for any $\varepsilon &gt; 0$, no strategy can achieve a competitive ratio $9-\varepsilon$. Finally, we show that it is not possible to achieve a constant competitive ratio (independent of $G$ and $k$) on weighted outerplanar graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01872v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Laurent Beaudou, Pierre Berg\'e, Vsevolod Chernyshev, Antoine Dailly, Yan Gerard, Aur\'elie Lagoutte, Vincent Limouzy, Lucas Pastor</dc:creator>
    </item>
    <item>
      <title>Linear Programming Based Near-Optimal Pricing for Laminar Bayesian Online Selection</title>
      <link>https://arxiv.org/abs/1807.05477</link>
      <description>arXiv:1807.05477v2 Announce Type: replace-cross 
Abstract: The Bayesian online selection problem aims to design a pricing scheme for a sequence of arriving buyers that maximizes the expected social welfare (or revenue) subject to different structural constraints. Inspired by applications with a hierarchy of service, this paper focuses on the cases where a laminar matroid characterizes the set of served buyers. We give the first Polynomial-Time Approximation Scheme (PTAS) for the problem when the laminar matroid has constant depth. Our approach is based on rounding the solution of a hierarchy of linear programming relaxations that approximate the optimum online solution with any degree of accuracy, plus a concentration argument showing that rounding incurs a small loss. We also study another variation, which we call the production-constrained problem. The allowable set of served buyers is characterized by a collection of production and shipping constraints that form a particular example of a laminar matroid. Using a similar LP-based approach, we design a PTAS for this problem, although in this special case the depth of the underlying laminar matroid is not necessarily a constant. The analysis exploits the negative dependency of the optimum selection rule in the lower levels of the laminar family. Finally, to demonstrate the generality of our technique, we employ the linear programming-based approach employed in the paper to re-derive some of the classic prophet inequalities known in the literature -- as a side result.</description>
      <guid isPermaLink="false">oai:arXiv.org:1807.05477v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nima Anari, Rad Niazadeh, Amin Saberi, Ali Shameli</dc:creator>
    </item>
    <item>
      <title>Probing Quantum Telecloning on Superconducting Quantum Processors</title>
      <link>https://arxiv.org/abs/2308.15579</link>
      <description>arXiv:2308.15579v2 Announce Type: replace-cross 
Abstract: Quantum information can not be perfectly cloned, but approximate copies of quantum information can be generated. Quantum telecloning combines approximate quantum cloning, more typically referred as quantum cloning, and quantum teleportation. Quantum telecloning allows approximate copies of quantum information to be constructed by separate parties, using the classical results of a Bell measurement made on a prepared quantum telecloning state. Quantum telecloning can be implemented as a circuit on quantum computers using a classical co-processor to compute classical feed forward instructions using if statements based on the results of a mid-circuit Bell measurement in real time. We present universal, symmetric, optimal $1 \rightarrow M$ telecloning circuits, and experimentally demonstrate these quantum telecloning circuits for $M=2$ up to $M=10$, natively executed with real time classical control systems on IBM Quantum superconducting processors, known as dynamic circuits. We perform the cloning procedure on many different message states across the Bloch sphere, on $7$ IBM Quantum processors, optionally using the error suppression technique X-X sequence digital dynamical decoupling. Two circuit optimizations are utilized, one which removes ancilla qubits for $M=2, 3$, and one which reduces the total number of gates in the circuit but still uses ancilla qubits. Parallel single qubit tomography with MLE density matrix reconstruction is used in order to compute the mixed state density matrices of the clone qubits, and clone quality is measured using quantum fidelity. These results present one of the largest and most comprehensive NISQ computer experimental analyses on (single qubit) quantum telecloning to date. The clone fidelity sharply decreases to $0.5$ for $M &gt; 5$, but for $M=2$ we are able to achieve a mean clone fidelity of up to $0.79$ using dynamical decoupling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15579v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elijah Pelofske, Andreas B\"artschi, Stephan Eidenbenz, Bryan Garcia, Boris Kiefer</dc:creator>
    </item>
  </channel>
</rss>
