<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.RM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.RM</link>
    <description>q-fin.RM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.RM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 Aug 2024 04:05:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 23 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>EX-DRL: Hedging Against Heavy Losses with EXtreme Distributional Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2408.12446</link>
      <description>arXiv:2408.12446v1 Announce Type: new 
Abstract: Recent advancements in Distributional Reinforcement Learning (DRL) for modeling loss distributions have shown promise in developing hedging strategies in derivatives markets. A common approach in DRL involves learning the quantiles of loss distributions at specified levels using Quantile Regression (QR). This method is particularly effective in option hedging due to its direct quantile-based risk assessment, such as Value at Risk (VaR) and Conditional Value at Risk (CVaR). However, these risk measures depend on the accurate estimation of extreme quantiles in the loss distribution's tail, which can be imprecise in QR-based DRL due to the rarity and extremity of tail data, as highlighted in the literature. To address this issue, we propose EXtreme DRL (EX-DRL), which enhances extreme quantile prediction by modeling the tail of the loss distribution with a Generalized Pareto Distribution (GPD). This method introduces supplementary data to mitigate the scarcity of extreme quantile observations, thereby improving estimation accuracy through QR. Comprehensive experiments on gamma hedging options demonstrate that EX-DRL improves existing QR-based models by providing more precise estimates of extreme quantiles, thereby improving the computation and reliability of risk metrics for complex financial risk management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12446v1</guid>
      <category>q-fin.RM</category>
      <category>cs.LG</category>
      <category>q-fin.ST</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Parvin Malekzadeh, Zissis Poulos, Jacky Chen, Zeyu Wang, Konstantinos N. Plataniotis</dc:creator>
    </item>
    <item>
      <title>Defining and comparing SICR-events for classifying impaired loans under IFRS 9</title>
      <link>https://arxiv.org/abs/2303.03080</link>
      <description>arXiv:2303.03080v3 Announce Type: replace 
Abstract: The IFRS 9 accounting standard requires the prediction of credit deterioration in financial instruments, i.e., significant increases in credit risk (SICR). However, the definition of such a SICR-event is inherently ambiguous, given its current reliance on evaluating the change in the estimated probability of default (PD) against some arbitrary threshold. We examine the shortcomings of this PD-comparison approach and propose an alternative framework for generating SICR-definitions based on three parameters: delinquency, stickiness, and the outcome period. Having varied these framework parameters, we obtain 27 unique SICR-definitions and fit logistic regression models accordingly using rich South African mortgage and macroeconomic data. For each definition and corresponding model, the resulting SICR-rates are analysed at the portfolio-level on their stability over time and their responsiveness to economic downturns. At the account-level, we compare both the accuracy and dynamicity of the SICR-predictions, and discover several interesting trends and trade-offs. These results can help any bank with appropriately setting the three framework parameters in defining SICR-events for prediction purposes. We demonstrate this process by comparing the best-performing SICR-model to the PD-comparison approach, and show the latter's inferiority as an early-warning system. Our work can therefore guide the formulation, modelling, and testing of any SICR-definition, thereby promoting the timeous recognition of credit losses; the main imperative of IFRS 9.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.03080v3</guid>
      <category>q-fin.RM</category>
      <category>q-fin.ST</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arno Botha, Esmerelda Oberholzer, Janette Larney, Riaan de Jongh</dc:creator>
    </item>
    <item>
      <title>Spanning Multi-Asset Payoffs With ReLUs</title>
      <link>https://arxiv.org/abs/2403.14231</link>
      <description>arXiv:2403.14231v2 Announce Type: replace 
Abstract: We propose a distributional formulation of the spanning problem of a multi-asset payoff by vanilla basket options. This problem is shown to have a unique solution if and only if the payoff function is even and absolutely homogeneous, and we establish a Fourier-based formula to calculate the solution. Financial payoffs are typically piecewise linear, resulting in a solution that may be derived explicitly, yet may also be hard to numerically exploit. One-hidden-layer feedforward neural networks instead provide a natural and efficient numerical alternative for discrete spanning. We test this approach for a selection of archetypal payoffs and obtain better hedging results with vanilla basket options compared to industry-favored approaches based on single-asset vanilla hedges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14231v2</guid>
      <category>q-fin.RM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\'ebastien Bossu (LPSM), St\'ephane Cr\'epey (LPSM), Hoang-Dung Nguyen (LPSM)</dc:creator>
    </item>
    <item>
      <title>Neural networks for insurance pricing with frequency and severity data: a benchmark study from data preprocessing to technical tariff</title>
      <link>https://arxiv.org/abs/2310.12671</link>
      <description>arXiv:2310.12671v3 Announce Type: replace-cross 
Abstract: Insurers usually turn to generalized linear models for modeling claim frequency and severity data. Due to their success in other fields, machine learning techniques are gaining popularity within the actuarial toolbox. Our paper contributes to the literature on frequency-severity insurance pricing with machine learning via deep learning structures. We present a benchmark study on four insurance data sets with frequency and severity targets in the presence of multiple types of input features. We compare in detail the performance of: a generalized linear model on binned input data, a gradient-boosted tree model, a feed-forward neural network (FFNN), and the combined actuarial neural network (CANN). The CANNs combine a baseline prediction established with a GLM and GBM, respectively, with a neural network correction. We explain the data preprocessing steps with specific focus on the multiple types of input features typically present in tabular insurance data sets, such as postal codes, numeric and categorical covariates. Autoencoders are used to embed the categorical variables into the neural network, and we explore their potential advantages in a frequency-severity setting. Model performance is evaluated not only on out-of-sample deviance but also using statistical and calibration performance criteria and managerial tools to get more nuanced insights. Finally, we construct global surrogate models for the neural nets' frequency and severity models. These surrogates enable the translation of the essential insights captured by the FFNNs or CANNs to GLMs. As such, a technical tariff table results that can easily be deployed in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12671v3</guid>
      <category>cs.LG</category>
      <category>q-fin.RM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Freek Holvoet, Katrien Antonio, Roel Henckaerts</dc:creator>
    </item>
  </channel>
</rss>
