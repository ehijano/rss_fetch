<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Feb 2026 05:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>VR-PIC: An entropic variance-reduction method for particle-in-cell solutions of the Vlasov-Poisson equation</title>
      <link>https://arxiv.org/abs/2602.15041</link>
      <description>arXiv:2602.15041v1 Announce Type: cross 
Abstract: We extend the recently developed entropic and conservative variance reduction framework [M. Sadr, N. G. Hadjiconstantinou, A variance-reduced direct Monte Carlo simulation method for solving the Boltzmann equation over a wide range of rarefaction, Journal of Computational Physics 472 (2023) 111677.] to the particle-in-cell (PIC) method of solving Vlasov-Poisson equation. We show that a zeroth-order approximation that freezes the importance weights during the velocity-space kick is stable at the expense of introducing bias. Then, we propose a correction for the weight distribution using maximum cross-entropy formulation to ensure conservation laws while minimizing the introduced bias. In several test cases including Sod's shock tube and Landau damping we show that the proposed method maintains the substantial speed-up of variance reduction method compared to the PIC simulations in the low signal regime with minimal changes to the simulation code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15041v1</guid>
      <category>physics.comp-ph</category>
      <category>physics.plasm-ph</category>
      <category>stat.CO</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Windhab, Andreas Adelmann, Mohsen Sadr</dc:creator>
    </item>
    <item>
      <title>bayesics: Core Statistical Methods via Bayesian Inference in R</title>
      <link>https://arxiv.org/abs/2602.15150</link>
      <description>arXiv:2602.15150v1 Announce Type: cross 
Abstract: Bayesian statistics is an integral part of contemporary applied science. bayesics provides a single framework, unified in syntax and output, for performing the most commonly used statistical procedures, ranging from one- and two-sample inference to general mediation analysis. bayesics leans hard away from the requirement that users be familiar with sampling algorithms by using closed-form solutions whenever possible, and automatically selecting the number of posterior samples required for accurate inference when such solutions are not possible. bayesics} focuses on providing key inferential quantities: point estimates, credible intervals, probability of direction, region of practical equivalance (ROPE), and, when applicable, Bayes factors. While algorithmic assessment is not required in bayesics, model assessment is still critical; towards that, bayesics provides diagnostic plots for parametric inference, including Bayesian p-values. Finally, bayesics provides extensions to models implemented in alternative R packages and, in the case of mediation analysis, correction to existing implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15150v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel K. Sewell, Alan T. Arakkal</dc:creator>
    </item>
    <item>
      <title>Tomography by Design: An Algebraic Approach to Low-Rank Quantum States</title>
      <link>https://arxiv.org/abs/2602.15202</link>
      <description>arXiv:2602.15202v1 Announce Type: cross 
Abstract: We present an algebraic algorithm for quantum state tomography that leverages measurements of certain observables to estimate structured entries of the underlying density matrix. Under low-rank assumptions, the remaining entries can be obtained solely using standard numerical linear algebra operations. The proposed algebraic matrix completion framework applies to a broad class of generic, low-rank mixed quantum states and, compared with state-of-the-art methods, is computationally efficient while providing deterministic recovery guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15202v1</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Shakir Showkat Sofi, Charlotte Vermeylen, Lieven De Lathauwer</dc:creator>
    </item>
    <item>
      <title>Multiplierless DFT Approximation Based on the Prime Factor Algorithm</title>
      <link>https://arxiv.org/abs/2602.15218</link>
      <description>arXiv:2602.15218v1 Announce Type: cross 
Abstract: Matrix approximation methods have successfully produced efficient, low-complexity approximate transforms for the discrete cosine transforms and the discrete Fourier transforms. For the DFT case, literature archives approximations operating at small power-of-two blocklenghts, such as \{8, 16, 32\}, or at large blocklengths, such as 1024, which are obtained by means of the Cooley-Tukey-based approximation relying on the small-blocklength approximate transforms. Cooley-Tukey-based approximations inherit the intermediate multiplications by twiddled factors which are usually not approximated; otherwise the effected error propagation would prevent the overall good performance of the approximation. In this context, the prime factor algorithm can furnish the necessary framework for deriving fully multiplierless DFT approximations. We introduced an approximation method based on small prime-sized DFT approximations which entirely eliminates intermediate multiplication steps and prevents internal error propagation. To demonstrate the proposed method, we design a fully multiplierless 1023-point DFT approximation based on 3-, 11- and 31-point DFT approximations. The performance evaluation according to popular metrics showed that the proposed approximations not only presented a significantly lower arithmetic complexity but also resulted in smaller approximation error measurements when compared to competing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15218v1</guid>
      <category>eess.SP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TSP.2025.3634427</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Signal Processing, v. 73, 2025</arxiv:journal_reference>
      <dc:creator>L. Portella, F. M. Bayer, R. J. Cintra</dc:creator>
    </item>
    <item>
      <title>Modified Delayed Acceptance MCMC for Quasi-Bayesian Inference with Linear Moment Conditions</title>
      <link>https://arxiv.org/abs/2511.17117</link>
      <description>arXiv:2511.17117v5 Announce Type: replace 
Abstract: We develop a computationally efficient framework for quasi-Bayesian inference based on linear moment conditions. The approach employs a delayed acceptance Markov chain Monte Carlo (DA-MCMC) algorithm that uses a surrogate target kernel and a proposal distribution derived from an approximate conditional posterior, thereby exploiting the structure of the quasi-likelihood. Two implementations are introduced. DA-MCMC-Exact fully incorporates prior information into the proposal distribution and maximizes per-iteration efficiency, whereas DA-MCMC-Approx omits the prior in the proposal to reduce matrix inversions, improving numerical stability and computational speed in higher dimensions. Simulation studies on heteroskedastic linear regressions show substantial gains over standard MCMC and conventional DA-MCMC baselines, measured by multivariate effective sample size per iteration and per second. The Approx variant yields the best overall throughput, while the Exact variant attains the highest per-iteration efficiency. Applications to two empirical instrumental variable regressions corroborate these findings: the Approx implementation scales to larger designs where other methods become impractical, while still delivering precise inference. Although developed for moment-based quasi-posteriors, the proposed approach also extends to risk-based quasi-Bayesian formulations when first-order conditions are linear and can be transformed analogously. Overall, the proposed algorithms provide a practical and robust tool for quasi-Bayesian analysis in statistical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17117v5</guid>
      <category>stat.CO</category>
      <category>econ.EM</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masahiro Tanaka</dc:creator>
    </item>
    <item>
      <title>Generative Bayesian Inference with GANs</title>
      <link>https://arxiv.org/abs/2208.12113</link>
      <description>arXiv:2208.12113v3 Announce Type: replace-cross 
Abstract: In the absence of explicit or tractable likelihoods, Bayesians often resort to approximate Bayesian computation (ABC) for inference. Our work bridges ABC with deep neural implicit samplers based on generative adversarial networks (GANs) and adversarial variational Bayes. Both ABC and GANs compare aspects of observed and fake data to simulate from posteriors and likelihoods, respectively. We develop a Bayesian GAN (B-GAN) sampler that directly targets the posterior by solving an adversarial optimization problem. B-GAN is driven by a deterministic mapping learned on the ABC reference by conditional GANs. Once the mapping has been trained, iid posterior samples are obtained by filtering noise at a negligible additional cost. We propose two post-processing local refinements using (1) data-driven proposals with importance reweighting, and (2) variational Bayes. We support our findings with frequentist-Bayesian results, showing that the typical total variation distance between the true and approximate posteriors converges to zero for certain neural network generators and discriminators. Our findings on simulated data show highly competitive performance relative to some of the most recent likelihood-free posterior simulators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.12113v3</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuexi Wang, Veronika Ro\v{c}kov\'a</dc:creator>
    </item>
    <item>
      <title>Lattice Random Walk Discretisations of Stochastic Differential Equations</title>
      <link>https://arxiv.org/abs/2508.20883</link>
      <description>arXiv:2508.20883v2 Announce Type: replace-cross 
Abstract: We introduce a lattice random walk discretisation scheme for stochastic differential equations (SDEs) that samples binary or ternary increments at each step, suppressing complex drift and diffusion computations to simple 1 or 2 bit random values. This approach is a significant departure from traditional floating point discretisations and offers several advantages; including compatibility with stochastic computing architectures that avoid floating-point arithmetic in place of directly manipulating the underlying probability distribution of a bitstream, elimination of Gaussian sampling requirements, robustness to quantisation errors, and handling of non-Lipschitz drifts. We prove weak convergence and demonstrate the advantages through experiments on various SDEs, including state-of-the-art diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20883v2</guid>
      <category>math.NA</category>
      <category>cs.ET</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Duffield, Maxwell Aifer, Denis Melanson, Zach Belateche, Patrick J. Coles</dc:creator>
    </item>
    <item>
      <title>Robust $M$-Estimation of Scatter Matrices via Precision Structure Shrinkage</title>
      <link>https://arxiv.org/abs/2601.11099</link>
      <description>arXiv:2601.11099v2 Announce Type: replace-cross 
Abstract: Maronna's and Tyler's $M$-estimators are among the most widely used robust estimators for scatter matrices. However, when the dimension of observations is relatively high, their performance can substantially deteriorate in certain situations, particularly in the presence of clustered outliers. To address this issue, we propose an estimator that shrinks the estimated precision matrix toward the identity matrix. We derive a sufficient condition for its existence, discuss its statistical interpretation, and establish upper and lower bounds for its additive finite sample breakdown point. Numerical experiments confirm the robustness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.11099v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soma Nikai, Yuichi Goto, Koji Tsukuda</dc:creator>
    </item>
    <item>
      <title>Amortised and provably-robust simulation-based inference</title>
      <link>https://arxiv.org/abs/2602.11325</link>
      <description>arXiv:2602.11325v2 Announce Type: replace-cross 
Abstract: Complex simulator-based models are now routinely used to perform inference across the sciences and engineering, but existing inference methods are often unable to account for outliers and other extreme values in data which occur due to faulty measurement instruments or human error. In this paper, we introduce a novel approach to simulation-based inference grounded in generalised Bayesian inference and a neural approximation of a weighted score-matching loss. This leads to a method that is both amortised and provably robust to outliers, a combination not achieved by existing approaches. Furthermore, through a carefully chosen conditional density model, we demonstrate that inference can be further simplified and performed without the need for Markov chain Monte Carlo sampling, thereby offering significant computational advantages, with complexity that is only a small fraction of that of current state-of-the-art approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11325v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ayush Bharti, Charita Dellaporta, Yuga Hikida, Fran\c{c}ois-Xavier Briol</dc:creator>
    </item>
  </channel>
</rss>
