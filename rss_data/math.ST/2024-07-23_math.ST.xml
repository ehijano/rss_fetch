<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 24 Jul 2024 01:41:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 23 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Minimax estimation of functionals in sparse vector model with correlated observations</title>
      <link>https://arxiv.org/abs/2407.14778</link>
      <description>arXiv:2407.14778v1 Announce Type: new 
Abstract: We consider the observations of an unknown $s$-sparse vector ${\boldsymbol \theta}$ corrupted by Gaussian noise with zero mean and unknown covariance matrix ${\boldsymbol \Sigma}$. We propose minimax optimal methods of estimating the $\ell_2$ norm of ${\boldsymbol \theta}$ and testing the hypothesis $H_0: {\boldsymbol \theta}=0$ against sparse alternatives when only partial information about ${\boldsymbol \Sigma}$ is available, such as an upper bound on its Frobenius norm and the values of its diagonal entries to within an unknown scaling factor. We show that the minimax rates of the estimation and testing are leveraged not by the dimension of the problem but by the value of the Frobenius norm of ${\boldsymbol \Sigma}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14778v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhao Wang, Pengkun Yang, Alexandre B. Tsybakov</dc:creator>
    </item>
    <item>
      <title>Bernstein-von Mises theorems for time evolution equations</title>
      <link>https://arxiv.org/abs/2407.14781</link>
      <description>arXiv:2407.14781v1 Announce Type: new 
Abstract: We consider a class of infinite-dimensional dynamical systems driven by non-linear parabolic partial differential equations with initial condition $\theta$ modelled by a Gaussian process `prior' probability measure. Given discrete samples of the state of the system evolving in space-time, one obtains updated `posterior' measures on a function space containing all possible trajectories. We give a general set of conditions under which these non-Gaussian posterior distributions are approximated, in Wasserstein distance for the supremum-norm metric, by the law of a Gaussian random function. We demonstrate the applicability of our results to periodic non-linear reaction diffusion equations \begin{align*} \frac{\partial}{\partial t} u - \Delta u &amp;= f(u) \\ u(0) &amp;= \theta \end{align*} where $f$ is any smooth and compactly supported reaction function. In this case the limiting Gaussian measure can be characterised as the solution of a time-dependent Schr\"odinger equation with `rough' Gaussian initial conditions whose covariance operator we describe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14781v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard Nickl</dc:creator>
    </item>
    <item>
      <title>Nonparametric Estimation of Ordinary Differential Equations: Snake and Stubble</title>
      <link>https://arxiv.org/abs/2407.14989</link>
      <description>arXiv:2407.14989v1 Announce Type: new 
Abstract: We study nonparametric estimation in dynamical systems described by ordinary differential equations (ODEs). Specifically, we focus on estimating the unknown function $f \colon \mathbb{R}^d \to \mathbb{R}^d$ that governs the system dynamics through the ODE $\dot{u}(t) = f(u(t))$, where observations $Y_{j,i} = u_j(t_{j,i}) + \varepsilon_{j,i}$ of solutions $u_j$ of the ODE are made at times $t_{j,i}$ with independent noise $\varepsilon_{j,i}$.
  We introduce two novel models -- the Stubble model and the Snake model -- to mitigate the issue of observation location dependence on $f$, an inherent difficulty in nonparametric estimation of ODE systems. In the Stubble model, we observe many short solutions with initial conditions that adequately cover the domain of interest. Here, we study an estimator based on multivariate local polynomial regression and univariate polynomial interpolation. In the Snake model we observe few long trajectories that traverse the domain on interest. Here, we study an estimator that combines univariate local polynomial estimation with multivariate polynomial interpolation.
  For both models, we establish error bounds of order $n^{-\frac{\beta}{2(\beta +1)+d}}$ for $\beta$-smooth functions $f$ in an infinite dimensional function class of H\"older-type and establish minimax optimality for the Stubble model in general and for the Snake model under some conditions via comparison to lower bounds from parallel work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14989v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christof Sch\"otz</dc:creator>
    </item>
    <item>
      <title>Lower Bounds for Nonparametric Estimation of Ordinary Differential Equations</title>
      <link>https://arxiv.org/abs/2407.14993</link>
      <description>arXiv:2407.14993v1 Announce Type: new 
Abstract: We noisily observe solutions of an ordinary differential equation $\dot u = f(u)$ at given times, where $u$ lives in a $d$-dimensional state space. The model function $f$ is unknown and belongs to a H\"older-type smoothness class with parameter $\beta$. For the nonparametric problem of estimating $f$, we provide lower bounds on the error in two complementary model specifications: the snake model with few, long observed solutions and the stubble model with many short ones. The lower bounds are minimax optimal in some settings. They depend on various parameters, which in the optimal asymptotic regime leads to the same rate for the squared error in both models: it is characterized by the exponent $-2\beta/(2(\beta+1)+d)$ for the total number of observations $n$. To derive these results, we establish a master theorem for lower bounds in general nonparametric regression problems, which makes the proofs more comparable and seems to be a useful tool for future use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14993v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christof Sch\"otz, Maximilian Siebel</dc:creator>
    </item>
    <item>
      <title>Weak-instrument-robust subvector inference in instrumental variables regression: A subvector Lagrange multiplier test and properties of subvector Anderson-Rubin confidence sets</title>
      <link>https://arxiv.org/abs/2407.15256</link>
      <description>arXiv:2407.15256v1 Announce Type: new 
Abstract: We propose a weak-instrument-robust subvector Lagrange multiplier test for instrumental variables regression. We show that it is asymptotically size-correct under a technical condition. This is the first weak-instrument-robust subvector test for instrumental variables regression to recover the degrees of freedom of the commonly used Wald test, which is not robust to weak instruments. Additionally, we provide a closed-form solution for subvector confidence sets obtained by inverting the subvector Anderson-Rubin test. We show that they are centered around a k-class estimator. Also, we show that the subvector confidence sets for single coefficients of the causal parameter are jointly bounded if and only if Anderson's likelihood-ratio test rejects the hypothesis that the first-stage regression parameter is of reduced rank, that is, that the causal parameter is not identified. Finally, we show that if a confidence set obtained by inverting the Anderson-Rubin test is bounded and nonempty, it is equal to a Wald-based confidence set with a data-dependent confidence level. We explicitly compute this Wald-based confidence test.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15256v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Malte Londschien, Peter B\"uhlmann</dc:creator>
    </item>
    <item>
      <title>Distributional limits of graph cuts on discretized grids</title>
      <link>https://arxiv.org/abs/2407.15297</link>
      <description>arXiv:2407.15297v1 Announce Type: new 
Abstract: Graph cuts are among the most prominent tools for clustering and classification analysis. While intensively studied from geometric and algorithmic perspectives, graph cut-based statistical inference still remains elusive to a certain extent. Distributional limits are fundamental in understanding and designing such statistical procedures on randomly sampled data. We provide explicit limiting distributions for balanced graph cuts in general on a fixed but arbitrary discretization. In particular, we show that Minimum Cut, Ratio Cut and Normalized Cut behave asymptotically as the minimum of Gaussians as sample size increases. Interestingly, our results reveal a dichotomy for Cheeger Cut: The limiting distribution of the optimal objective value is the minimum of Gaussians only when the optimal partition yields two sets of unequal volumes, while otherwise the limiting distribution is the minimum of a random mixture of Gaussians. Further, we show the bootstrap consistency for all types of graph cuts by utilizing the directional differentiability of cut functionals. We validate these theoretical findings by Monte Carlo experiments, and examine differences between the cuts and the dependency on the underlying distribution. Additionally, we expand our theoretical findings to the Xist algorithm, a computational surrogate of graph cuts recently proposed in Suchan, Li and Munk (arXiv, 2023), thus demonstrating the practical applicability of our findings e.g. in statistical tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15297v1</guid>
      <category>math.ST</category>
      <category>math.CO</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leo Suchan, Housen Li, Axel Munk</dc:creator>
    </item>
    <item>
      <title>On some recent quasi-copula problems and some new methods</title>
      <link>https://arxiv.org/abs/2407.15393</link>
      <description>arXiv:2407.15393v1 Announce Type: new 
Abstract: The aim of this paper is to present three construction methods for quasi-copulas based on recent developments: a representation of multivariate quasi-copulas by means of infima and suprema of copulas, an extension of a classical result on shuffles of min to the setting of quasi-copulas, and a construction method for quasi-copulas obeying a given signed mass pattern on a patch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15393v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matja\v{z} Omladi\v{c}, Nik Stopar</dc:creator>
    </item>
    <item>
      <title>Persistence-based Modes Inference</title>
      <link>https://arxiv.org/abs/2407.15449</link>
      <description>arXiv:2407.15449v1 Announce Type: new 
Abstract: We consider the estimation of multiple modes of a (multivariate) density. We start by proposing an estimator of the $H_0$ persistence diagram. We then derive from it a procedure to estimate the number of modes, their locations and the associated local maxima. For large classes of piecewise-continuous functions, we show that these estimators achieve nearly minimax rates. These classes involve geometric control over the discontinuities set and differ from commonly considered function classes in mode(s) inference. Although the global regularity assumptions are stronger, we do not suppose regularity (or even continuity) in any neighborhood of the modes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15449v1</guid>
      <category>math.ST</category>
      <category>math.AT</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo Henneuse</dc:creator>
    </item>
    <item>
      <title>Efficient influence functions for Sobol' indices under two designs of experiments</title>
      <link>https://arxiv.org/abs/2407.15468</link>
      <description>arXiv:2407.15468v1 Announce Type: new 
Abstract: In this note, we are interested in the asymptotic efficiency of Sobol' indices esti-mators. After recalling the basis of asymptotic efficiency, we compute the efficientinfluence functions for Sobol' indices in two different contexts: the Pick-Freeze andthe given-data settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15468v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thierry Klein (ENAC, IMT), Agn\`es Lagnoux (IMT), Paul Rochet (OPTIM), Thi Mong Ngoc Nguyen</dc:creator>
    </item>
    <item>
      <title>Non-parametric estimation of conditional quantiles for time series with heavy tails</title>
      <link>https://arxiv.org/abs/2407.15564</link>
      <description>arXiv:2407.15564v1 Announce Type: new 
Abstract: We propose a modified weighted Nadaraya-Watson estimator for the conditional distribution of a time series with heavy tails. We establish the asymptotic normality of the proposed estimator. Simulation study is carried out to assess the performance of the estimator. We illustrate our method using a dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15564v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Deemat C Mathew, Hareesh G,  Sudheesh, K Kattumannil</dc:creator>
    </item>
    <item>
      <title>Orderings of the finite mixture with modified proportional hazard rate model</title>
      <link>https://arxiv.org/abs/2407.15638</link>
      <description>arXiv:2407.15638v2 Announce Type: new 
Abstract: In this paper, we consider finite mixture models with modified proportional hazard rates. Sufficient conditions for the usual stochastic order and the hazard order are established under chain majorization. We study stochastic comparisons under different settings of T-transform for various values of chain majorization. We establish usual stochastic order and hazard rate order between two mixture random variables when a matrix of model parameters and mixing proportions changes to another matrix in some mathematical sense. Sufficient conditions for the star order and Lorenz order are established under weakly supermajorization. The results of this paper are illustrated with numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15638v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lina Guo</dc:creator>
    </item>
    <item>
      <title>A matrix algebra for graphical statistical models</title>
      <link>https://arxiv.org/abs/2407.15744</link>
      <description>arXiv:2407.15744v1 Announce Type: new 
Abstract: Directed mixed graphs permit directed and bidirected edges between any two vertices. They were first considered in the path analysis developed by Sewall Wright and play an essential role in statistical modeling. We introduce a matrix algebra for walks on such graphs. Each element of the algebra is a matrix whose entries are sets of walks on the graph from the corresponding row to the corresponding column. The matrix algebra is then generated by applying addition (set union), multiplication (concatenation), and transpose to the two basic matrices consisting of directed and bidirected edges. We use it to formalize, in the context of Gaussian linear systems, the correspondence between important graphical concepts such as latent projection and graph separation with important probabilistic concepts such as marginalization and (conditional) independence. In two further examples regarding confounder adjustment and the augmentation criterion, we illustrate how the algebra allows us to visualize complex graphical proofs. A "dictionary" and LATEX macros for the matrix algebra are provided in the Appendix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15744v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingyuan Zhao</dc:creator>
    </item>
    <item>
      <title>Huber means on Riemannian manifolds</title>
      <link>https://arxiv.org/abs/2407.15764</link>
      <description>arXiv:2407.15764v1 Announce Type: new 
Abstract: This article introduces Huber means on Riemannian manifolds, providing a robust alternative to the Frechet mean by integrating elements of both square and absolute loss functions. The Huber means are designed to be highly resistant to outliers while maintaining efficiency, making it a valuable generalization of Huber's M-estimator for manifold-valued data. We comprehensively investigate the statistical and computational aspects of Huber means, demonstrating their utility in manifold-valued data analysis. Specifically, we establish minimal conditions for ensuring the existence and uniqueness of the Huber mean and discuss regularity conditions for unbiasedness. The Huber means are statistically consistent and enjoy the central limit theorem. Additionally, we propose a moment-based estimator for the limiting covariance matrix, which is used to construct a robust one-sample location test procedure and an approximate confidence region for location parameters. Huber means are shown to be highly robust and efficient in the presence of outliers or under heavy-tailed distribution. To be more specific, it achieves a breakdown point of at least 0.5, the highest among all isometric equivariant estimators, and is more efficient than the Frechet mean under heavy-tailed distribution. Numerical examples on spheres and the set of symmetric positive-definite matrices further illustrate the efficiency and reliability of the proposed Huber means on Riemannian manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15764v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jongmin Lee, Sungkyu Jung</dc:creator>
    </item>
    <item>
      <title>Accurate Analysis of Sparse Random Projections</title>
      <link>https://arxiv.org/abs/2407.14518</link>
      <description>arXiv:2407.14518v1 Announce Type: cross 
Abstract: There has been recently a lot of research on sparse variants of random projections, faster adaptations of the state-of-the-art dimensionality reduction technique originally due to Johsnon and Lindenstrauss. Although the construction is very simple, its analyses are notoriously complicated. Meeting the demand for both simplicity and accuracy, this work establishes sharp sub-poissonian tail bounds for the distribution of sparse random projections. Compared to other works, this analysis provide superior numerical guarantees (exactly matching impossibility results) while being arguably less complicated (the technique resembles Bennet's Inequality and is of independent interest).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14518v1</guid>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maciej Sk\'orski</dc:creator>
    </item>
    <item>
      <title>On the Distributions of Product and Quotient of two Independent $\hat{I}$-function variates</title>
      <link>https://arxiv.org/abs/2407.14554</link>
      <description>arXiv:2407.14554v1 Announce Type: cross 
Abstract: The study of probability distributions for random variables and their algebraic combinations has been a central focus driving the advancement of probability and statistics. Since the 1920s, the challenge of calculating the probability distributions of sums, differences, products, and quotients of independent random variables have drawn the attention of numerous statisticians and mathematicians who studied the algebraic properties and relationships of random variables. Statistical distributions are highly helpful in data science and machine learning, as they provide a range of possible values for the variables, aiding in the development of a deeper understanding of the underlying problem. In this paper, we have presented a new probability distribution based on the $\hat{I}$-function. Also, we have discussed the applications of the $\hat{I}$ function, particularly in deriving the distributions of product and the quotient involving two independent $\hat{I}$ function variates. Additionally, it has been shown that both the product and quotient of two independent $\hat{I}$-function variates also follow the $\hat{I}$-function distribution. Furthermore, the new distribution, known as the $\hat{I}$-function distribution, includes several well-known classical distributions such as the gamma, beta, exponential, normal H-function, and G-function distributions, among others, as special cases. Therefore, the $\hat{I}$-function distribution can be considered a characterization or generalization of the above-mentioned distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14554v1</guid>
      <category>math.CA</category>
      <category>math.CV</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vilma D'Souza, Shantha Kumari Kurumujji, Arjun K. Rathie</dc:creator>
    </item>
    <item>
      <title>Generalizing and transporting causal inferences from randomized trials in the presence of trial engagement effects</title>
      <link>https://arxiv.org/abs/2407.14703</link>
      <description>arXiv:2407.14703v1 Announce Type: cross 
Abstract: Trial engagement effects are effects of trial participation on the outcome that are not mediated by treatment assignment. Most work on extending (generalizing or transporting) causal inferences from a randomized trial to a target population has, explicitly or implicitly, assumed that trial engagement effects are absent, allowing evidence about the effects of the treatments examined in trials to be applied to non-experimental settings. Here, we define novel causal estimands and present identification results for generalizability and transportability analyses in the presence of trial engagement effects. Our approach allows for trial engagement effects under assumptions of no causal interaction between trial participation and treatment assignment on the absolute or relative scales. We show that under these assumptions, even in the presence of trial engagement effects, the trial data can be combined with covariate data from the target population to identify average treatment effects in the context of usual care as implemented in the target population (i.e., outside the experimental setting). The identifying observed data functionals under these no-interaction assumptions are the same as those obtained under the stronger identifiability conditions that have been invoked in prior work. Therefore, our results suggest a new interpretation for previously proposed generalizability and transportability estimators; this interpretation may be useful in analyses under causal structures where background knowledge suggests that trial engagement effects are present but interactions between trial participation and treatment are negligible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14703v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lawson Ung, Tyler J. VanderWeele, Issa J. Dahabreh</dc:creator>
    </item>
    <item>
      <title>Concentration and limit of large random matrices with given margins</title>
      <link>https://arxiv.org/abs/2407.14942</link>
      <description>arXiv:2407.14942v1 Announce Type: cross 
Abstract: We study large random matrices with i.i.d. entries conditioned to have prescribed row and column sums (margin). This problem has rich connections to relative entropy minimization, Schr\"{o}dinger bridge, the enumeration of contingency tables, and random graphs with given degree sequences. We show that such margin-constrained random matrix is sharply concentrated around a certain deterministic matrix, which we call the \textit{typical table}. Typical tables have dual characterizations: (1) the expectation of the random matrix ensemble with minimum relative entropy from the base model constrained to have the expected target margin, and (2) the expectation of the maximum likelihood model obtained by rank-one exponential tilting of the base model. The structure of the typical table is dictated by two dual variables, which give the maximum likelihood estimates of the tilting parameters. Based on these results, for a sequence of "tame" margins that converges in \( L^{1} \) to a limiting continuum margin as the size of the matrix diverges, we show that the sequence of margin-constrained random matrices converges in cut norm to a limiting kernel, which is the $L^{2}$-limit of the corresponding rescaled typical tables. The rate of convergence is controlled by how fast the margins converge in $L^{1}$. We derive several new results for random contingency tables from our general framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14942v1</guid>
      <category>math.PR</category>
      <category>math.CO</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanbaek Lyu, Sumit Mukherjee</dc:creator>
    </item>
    <item>
      <title>Is Behavior Cloning All You Need? Understanding Horizon in Imitation Learning</title>
      <link>https://arxiv.org/abs/2407.15007</link>
      <description>arXiv:2407.15007v1 Announce Type: cross 
Abstract: Imitation learning (IL) aims to mimic the behavior of an expert in a sequential decision making task by learning from demonstrations, and has been widely applied to robotics, autonomous driving, and autoregressive text generation. The simplest approach to IL, behavior cloning (BC), is thought to incur sample complexity with unfavorable quadratic dependence on the problem horizon, motivating a variety of different online algorithms that attain improved linear horizon dependence under stronger assumptions on the data and the learner's access to the expert.
  We revisit the apparent gap between offline and online IL from a learning-theoretic perspective, with a focus on general policy classes up to and including deep neural networks. Through a new analysis of behavior cloning with the logarithmic loss, we show that it is possible to achieve horizon-independent sample complexity in offline IL whenever (i) the range of the cumulative payoffs is controlled, and (ii) an appropriate notion of supervised learning complexity for the policy class is controlled. Specializing our results to deterministic, stationary policies, we show that the gap between offline and online IL is not fundamental: (i) it is possible to achieve linear dependence on horizon in offline IL under dense rewards (matching what was previously only known to be achievable in online IL); and (ii) without further assumptions on the policy class, online IL cannot improve over offline IL with the logarithmic loss, even in benign MDPs. We complement our theoretical results with experiments on standard RL tasks and autoregressive language generation to validate the practical relevance of our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15007v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dylan J. Foster, Adam Block, Dipendra Misra</dc:creator>
    </item>
    <item>
      <title>Nonlinear Binscatter Methods</title>
      <link>https://arxiv.org/abs/2407.15276</link>
      <description>arXiv:2407.15276v1 Announce Type: cross 
Abstract: Binned scatter plots are a powerful statistical tool for empirical work in the social, behavioral, and biomedical sciences. Available methods rely on a quantile-based partitioning estimator of the conditional mean regression function to primarily construct flexible yet interpretable visualization methods, but they can also be used to estimate treatment effects, assess uncertainty, and test substantive domain-specific hypotheses. This paper introduces novel binscatter methods based on nonlinear, possibly nonsmooth M-estimation methods, covering generalized linear, robust, and quantile regression models. We provide a host of theoretical results and practical tools for local constant estimation along with piecewise polynomial and spline approximations, including (i) optimal tuning parameter (number of bins) selection, (ii) confidence bands, and (iii) formal statistical tests regarding functional form or shape restrictions. Our main results rely on novel strong approximations for general partitioning-based estimators covering random, data-driven partitions, which may be of independent interest. We demonstrate our methods with an empirical application studying the relation between the percentage of individuals without health insurance and per capita income at the zip-code level. We provide general-purpose software packages implementing our methods in Python, R, and Stata.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15276v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matias D. Cattaneo, Richard K. Crump, Max H. Farrell, Yingjie Feng</dc:creator>
    </item>
    <item>
      <title>Conformal Predictions under Markovian Data</title>
      <link>https://arxiv.org/abs/2407.15277</link>
      <description>arXiv:2407.15277v1 Announce Type: cross 
Abstract: We study the split Conformal Prediction method when applied to Markovian data. We quantify the gap in terms of coverage induced by the correlations in the data (compared to exchangeable data). This gap strongly depends on the mixing properties of the underlying Markov chain, and we prove that it typically scales as $\sqrt{t_\mathrm{mix}\ln(n)/n}$ (where $t_\mathrm{mix}$ is the mixing time of the chain). We also derive upper bounds on the impact of the correlations on the size of the prediction set. Finally we present $K$-split CP, a method that consists in thinning the calibration dataset and that adapts to the mixing properties of the chain. Its coverage gap is reduced to $t_\mathrm{mix}/(n\ln(n))$ without really affecting the size of the prediction set. We finally test our algorithms on synthetic and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15277v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fr\'ed\'eric Zheng, Alexandre Proutiere</dc:creator>
    </item>
    <item>
      <title>U-learning for Prediction Inference via Combinatory Multi-Subsampling: With Applications to LASSO and Neural Networks</title>
      <link>https://arxiv.org/abs/2407.15301</link>
      <description>arXiv:2407.15301v1 Announce Type: cross 
Abstract: Epigenetic aging clocks play a pivotal role in estimating an individual's biological age through the examination of DNA methylation patterns at numerous CpG (Cytosine-phosphate-Guanine) sites within their genome. However, making valid inferences on predicted epigenetic ages, or more broadly, on predictions derived from high-dimensional inputs, presents challenges. We introduce a novel U-learning approach via combinatory multi-subsampling for making ensemble predictions and constructing confidence intervals for predictions of continuous outcomes when traditional asymptotic methods are not applicable. More specifically, our approach conceptualizes the ensemble estimators within the framework of generalized U-statistics and invokes the H\'ajek projection for deriving the variances of predictions and constructing confidence intervals with valid conditional coverage probabilities. We apply our approach to two commonly used predictive algorithms, Lasso and deep neural networks (DNNs), and illustrate the validity of inferences with extensive numerical studies. We have applied these methods to predict the DNA methylation age (DNAmAge) of patients with various health conditions, aiming to accurately characterize the aging process and potentially guide anti-aging interventions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15301v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>q-bio.QM</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhe Fei, Yi Li</dc:creator>
    </item>
    <item>
      <title>Off-the-grid prediction and testing for linear combination of translated features</title>
      <link>https://arxiv.org/abs/2212.01169</link>
      <description>arXiv:2212.01169v2 Announce Type: replace 
Abstract: We consider a model where a signal (discrete or continuous) is observed with an additive Gaussian noise process. The signal is issued from a linear combination of a finite but increasing number of translated features. The features are continuously parameterized by their location and depend on some scale parameter. First, we extend previous prediction results for off-the-grid estimators by taking into account here that the scale parameter may vary. The prediction bounds are analogous, but we improve the minimal distance between two consecutive features locations in order to achieve these bounds. Next, we propose a goodness-of-fit test for the model and give non-asymptotic upper bounds of the testing risk and of the minimax separation rate between two distinguishable signals. In particular, our test encompasses the signal detection framework. We deduce upper bounds on the minimal energy,expressed as the $\ell_2$-norm of the linear coefficients, to successfully detect a signal in presence of noise. The general model considered in this paper is a non-linear extension of the classical high-dimensional regression model. It turns out that,in this framework, our upper bound on the minimax separation rate matches (up to a logarithmic factor) the lower bound on the minimax separation rate for signal detection in the high-dimensional linear model associated to a fixed dictionary of features. We also propose a procedure to test whether the features of the observed signal belong to a given finite collection under the assumption that the linear coefficients may vary, but have prescribed signs under the null hypothesis. A non-asymptotic upper bound on the testing risk is given.We illustrate our results on the spikes deconvolution model with Gaussian features on the real line and with the Dirichlet kernel, frequently used in the compressed sensing literature, on the torus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.01169v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cristina Butucea (CREST, FAIRPLAY), Jean-Fran\c{c}ois Delmas (CERMICS), Anne Dutfoy (EDF R&amp;D), Cl\'ement Hardy (CERMICS)</dc:creator>
    </item>
    <item>
      <title>Estimation and variable selection in a joint model of survival times and longitudinal outcomes with random effects</title>
      <link>https://arxiv.org/abs/2306.16765</link>
      <description>arXiv:2306.16765v2 Announce Type: replace 
Abstract: This paper considers a joint survival and mixed-effects model to explain the survival time from longitudinal data and high-dimensional covariates. The longitudinal data is modeled using a nonlinear effects model, where the regression function serves as a link function incorporated into a Cox model as a covariate. In that way, the longitudinal data is related to the survival time at a given time. Additionally, the Cox model takes into account the inclusion of high-dimensional covariates. The main objectives of this research are two-fold: first, to identify the relevant covariates that contribute to explaining survival time, and second, to estimate all unknown parameters of the joint model. For that purpose, we consider the maximization of a Lasso penalized likelihood. To tackle the optimization problem, we implement a pre-conditioned stochastic gradient to handle the latent variables of the nonlinear mixed-effects model associated with a proximal operator to manage the non-differentiability of the penalty. We provide relevant simulations that showcase the performance of the proposed variable selection and parameters' estimation method in the joint modeling of a Cox and logistic model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16765v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Caillebotte (MaIAGE), Estelle Kuhn (MaIAGE), Sarah Lemler (MICS)</dc:creator>
    </item>
    <item>
      <title>Robust Signal Recovery in Hadamard Spaces</title>
      <link>https://arxiv.org/abs/2307.06057</link>
      <description>arXiv:2307.06057v2 Announce Type: replace 
Abstract: We analyze the stability of (strong) laws of large numbers in Hadamard spaces with respect to distributional perturbations. For the inductive means of a sequence of independent, but not necessarily identically distributed random variables, we provide a concentration inequality in quadratic mean, as well as a strong law of large numbers, generalizing a classical result of K.-T. Sturm. For the Fr\'echet mean, we generalize H. Ziezold's law of large numbers in Hadamard spaces. In this case, we neither require our data to be independent, nor identically distributed; reasonably mild conditions on the first two moments of our sample are enough. Additionally, we look at data contamination via a model inspired by Huber's $\varepsilon$-contamination model, in which we replace a random portion of the data with noise. In the most general setup, we do neither require the data, nor the noise to be i.i.d., nor do we require the noise to be independent of the data. To analyze the stability of the (non-symmetric) inductive mean with respect to data loss, data permutation, and noise, a resampling scheme is introduced, and sufficient conditions for its convergence are provided. These results suggest that means in Hadamard spaces are as robust as in Euclidean spaces. This is underlined by a small simulation study, in which we compare the robustness of means on the manifold of positive definite matrices, with means on open books.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.06057v2</guid>
      <category>math.ST</category>
      <category>math.MG</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Georg K\"ostenberger, Thomas Stark</dc:creator>
    </item>
    <item>
      <title>Spectrum-Aware Debiasing: A Modern Inference Framework with Applications to Principal Components Regression</title>
      <link>https://arxiv.org/abs/2309.07810</link>
      <description>arXiv:2309.07810v3 Announce Type: replace 
Abstract: Debiasing is a fundamental concept in high-dimensional statistics. While degrees-of-freedom adjustment is the state-of-the-art technique in high-dimensional linear regression, it is limited to i.i.d. samples and sub-Gaussian covariates. These constraints hinder its broader practical use. Here, we introduce Spectrum-Aware Debiasing--a novel method for high-dimensional regression. Our approach applies to problems with structured dependencies, heavy tails, and low-rank structures. Our method achieves debiasing through a rescaled gradient descent step, deriving the rescaling factor using spectral information of the sample covariance matrix. The spectrum-based approach enables accurate debiasing in much broader contexts. We study the common modern regime where the number of features and samples scale proportionally. We establish asymptotic normality of our proposed estimator (suitably centered and scaled) under various convergence notions when the covariates are right-rotationally invariant. Such designs have garnered recent attention due to their crucial role in compressed sensing. Furthermore, we devise a consistent estimator for its asymptotic variance.
  Our work has two notable by-products: first, we use Spectrum-Aware Debiasing to correct bias in principal components regression (PCR), providing the first debiased PCR estimator in high dimensions. Second, we introduce a principled test for checking alignment between the signal and the eigenvectors of the sample covariance matrix. This test is independently valuable for statistical methods developed using approximate message passing, leave-one-out, or convex Gaussian min-max theorems. We demonstrate our method through simulated and real data experiments. Technically, we connect approximate message passing algorithms with debiasing and provide the first proof of the Cauchy property of vector approximate message passing (V-AMP).</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07810v3</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yufan Li, Pragya Sur</dc:creator>
    </item>
    <item>
      <title>On the Asymptotic Normality of Trimmed and Winsorized L-statistics</title>
      <link>https://arxiv.org/abs/2402.07406</link>
      <description>arXiv:2402.07406v3 Announce Type: replace 
Abstract: There are several ways to establish the asymptotic normality of $L$-statistics, which depend on the choice of the weights-generating function and the cumulative distribution selection of the underlying model. In this study, we focus on stablishing computational formulas for the asymptotic variance of two robust $L$-estimators: the method of trimmed moments (MTM) and the method of winsorized moments (MWM). We demonstrate that two asymptotic approaches for MTM are equivalent for a specific choice of the weights-generating function. These findings enhance the applicability of these estimators across various underlying distributions, making them effective tools in diverse statistical scenarios. Such scenarios include actuarial contexts, such as payment-per-payment and payment-per-loss data scenarios, as well as in evaluating the asymptotic distributional properties of distortion risk measures. The effectiveness of our methodologies depends on the availability of the cumulative distribution function, ensuring broad usability in various statistical environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07406v3</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chudamani Poudyal</dc:creator>
    </item>
    <item>
      <title>Eigenvector overlaps in large sample covariance matrices and nonlinear shrinkage estimators</title>
      <link>https://arxiv.org/abs/2404.18173</link>
      <description>arXiv:2404.18173v2 Announce Type: replace 
Abstract: Consider a data matrix $Y = [\mathbf{y}_1, \cdots, \mathbf{y}_N]$ of size $M \times N$, where the columns are independent observations from a random vector $\mathbf{y}$ with zero mean and population covariance $\Sigma$. Let $\mathbf{u}_i$ and $\mathbf{v}_j$ denote the left and right singular vectors of $Y$, respectively. This study investigates the eigenvector/singular vector overlaps $\langle {\mathbf{u}_i, D_1 \mathbf{u}_j} \rangle$, $\langle {\mathbf{v}_i, D_2 \mathbf{v}_j} \rangle$ and $\langle {\mathbf{u}_i, D_3 \mathbf{v}_j} \rangle$, where $D_k$ are general deterministic matrices with bounded operator norms. We establish the convergence in probability of these eigenvector overlaps toward their deterministic counterparts with explicit convergence rates, when the dimension $M$ scales proportionally with the sample size $N$. Building on these findings, we offer a more precise characterization of the loss for Ledoit and Wolf's nonlinear shrinkage estimators of the population covariance $\Sigma$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18173v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeqin Lin, Guangming Pan</dc:creator>
    </item>
    <item>
      <title>Dynamic Structural Causal Models</title>
      <link>https://arxiv.org/abs/2406.01161</link>
      <description>arXiv:2406.01161v2 Announce Type: replace 
Abstract: We study a specific type of SCM, called a Dynamic Structural Causal Model (DSCM), whose endogenous variables represent functions of time, which is possibly cyclic and allows for latent confounding. As a motivating use-case, we show that certain systems of Stochastic Differential Equations (SDEs) can be appropriately represented with DSCMs. An immediate consequence of this construction is a graphical Markov property for systems of SDEs. We define a time-splitting operation, allowing us to analyse the concept of local independence (a notion of continuous-time Granger (non-)causality). We also define a subsampling operation, which returns a discrete-time DSCM, and which can be used for mathematical analysis of subsampled time-series. We give suggestions how DSCMs can be used for identification of the causal effect of time-dependent interventions, and how existing constraint-based causal discovery algorithms can be applied to time-series data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01161v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>UAI 2024 Workshop on Causal Inference for Time Series Data</arxiv:journal_reference>
      <dc:creator>Philip Boeken, Joris M. Mooij</dc:creator>
    </item>
    <item>
      <title>Cross-validation Approaches for Multi-study Predictions</title>
      <link>https://arxiv.org/abs/2007.12807</link>
      <description>arXiv:2007.12807v4 Announce Type: replace-cross 
Abstract: We consider prediction in multiple studies with potential differences in the relationships between predictors and outcomes. Our objective is to integrate data from multiple studies to develop prediction models for unseen studies. We propose and investigate two cross-validation approaches applicable to multi-study stacking, an ensemble method that linearly combines study-specific ensemble members to produce generalizable predictions. Among our cross-validation approaches are some that avoid reuse of the same data in both the training and stacking steps, as done in earlier multi-study stacking. We prove that under mild regularity conditions the proposed cross-validation approaches produce stacked prediction functions with oracle properties. We also identify analytically in which scenarios the proposed cross-validation approaches increase prediction accuracy compared to stacking with data reuse. We perform a simulation study to illustrate these results. Finally, we apply our method to predicting mortality from long-term exposure to air pollutants, using collections of datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2007.12807v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boyu Ren, Prasad Patil, Francesca Dominici, Giovanni Parmigiani, Lorenzo Trippa</dc:creator>
    </item>
    <item>
      <title>Exact bounds for some quadratic empirical processes with applications</title>
      <link>https://arxiv.org/abs/2207.13594</link>
      <description>arXiv:2207.13594v3 Announce Type: replace-cross 
Abstract: Let $Z_1,\ldots,Z_n$ be i.i.d. isotropic random vectors in $\mathbb{R}^p$, and $T \subset \mathbb{R}^p$ be a compact set. A classical line of empirical process theory characterizes the size of the suprema of the quadratic process \begin{align*} \sup_{t \in T} \bigg| \frac{1}{n}\sum_{i=1}^n \langle Z_i,t \rangle^2-\lVert t \rVert^2 \bigg|, \end{align*} via a single parameter known as the Gaussian width of $T$.
  This paper introduces an improved bound for the suprema of this quadratic process for standard Gaussian vectors $\{Z_i\}$ that can be exactly attained for certain choices of $T$, and is thus referred to as an exact bound. Our exact bound is expressed via a collection of (stochastic) Gaussian widths over spherical sections of $T$ that serves as a natural multi-scale analogue to the Gaussian width of $T$. Compared to the classical bounds for the quadratic process, our new bounds not only determine the optimal constants in the classical bounds that can be attained for some $T$, but also precisely capture certain subtle phase transitional behavior of the quadratic process beyond the reach of the classical bounds.
  To illustrate the utility of our results, we obtain tight versions of the Gaussian Dvoretzky-Milman theorem for random projection, and the Koltchinskii-Lounici theorem for covariance estimation, both with optimal constants. Moreover, our bounds recover the celebrated BBP phase transitional behavior of the top eigenvalue of the sample covariance and its generalization to the sample covariance error.
  The proof of our results exploits recently sharpened Gaussian comparison inequalities. The technical scope of our method of proof is further demonstrated in obtaining an exact bound for a two-sided Chevet inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.13594v3</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiyang Han</dc:creator>
    </item>
    <item>
      <title>Stable convergence of conditional least squares estimators for supercritical continuous state and continuous time branching processes with immigration</title>
      <link>https://arxiv.org/abs/2207.14056</link>
      <description>arXiv:2207.14056v2 Announce Type: replace-cross 
Abstract: We prove stable convergence of conditional least squares estimators of drift parameters for supercritical continuous state and continuous time branching processes with immigration based on discrete time observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.14056v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matyas Barczy</dc:creator>
    </item>
    <item>
      <title>The SPDE approach for spatio-temporal datasets with advection and diffusion</title>
      <link>https://arxiv.org/abs/2208.14015</link>
      <description>arXiv:2208.14015v4 Announce Type: replace-cross 
Abstract: In the task of predicting spatio-temporal fields in environmental science using statistical methods, introducing statistical models inspired by the physics of the underlying phenomena that are numerically efficient is of growing interest. Large space-time datasets call for new numerical methods to efficiently process them. The Stochastic Partial Differential Equation (SPDE) approach has proven to be effective for the estimation and the prediction in a spatial context. We present here the advection-diffusion SPDE with first order derivative in time which defines a large class of nonseparable spatio-temporal models. A Gaussian Markov random field approximation of the solution to the SPDE is built by discretizing the temporal derivative with a finite difference method (implicit Euler) and by solving the spatial SPDE with a finite element method (continuous Galerkin) at each time step. The ''Streamline Diffusion'' stabilization technique is introduced when the advection term dominates the diffusion. Computationally efficient methods are proposed to estimate the parameters of the SPDE and to predict the spatio-temporal field by kriging, as well as to perform conditional simulations. The approach is applied to a solar radiation dataset. Its advantages and limitations are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.14015v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucia Clarotto (MIA Paris-Saclay), Denis Allard (BioSP), Thomas Romary (GEOSCIENCES), Nicolas Desassis (GEOSCIENCES)</dc:creator>
    </item>
    <item>
      <title>Credibility Theory Based on Winsorizing</title>
      <link>https://arxiv.org/abs/2306.09507</link>
      <description>arXiv:2306.09507v4 Announce Type: replace-cross 
Abstract: The classical B\"{u}hlmann credibility model has been widely applied to premium estimation for group insurance contracts and other insurance types. In this paper, we develop a robust B\"{u}hlmann credibility model using the winsorized version of loss data, also known as the winsorized mean (a robust alternative to the traditional individual mean). This approach assumes that the observed sample data come from a contaminated underlying model with a small percentage of contaminated sample data. This framework provides explicit formulas for the structural parameters in credibility estimation for scale-shape distribution families, location-scale distribution families, and their variants, commonly used in insurance risk modeling. Using the theory of \(L\)-estimators (different from the influence function approach), we derive the asymptotic properties of the proposed method and validate them through a comprehensive simulation study, comparing their performance to credibility based on the trimmed mean. By varying the winsorizing/trimming thresholds in several parametric models, we find that all structural parameters derived from the winsorized approach are less volatile than those from the trimmed approach. Using the winsorized mean as a robust risk measure can reduce the influence of parametric loss assumptions on credibility estimation. Additionally, we discuss non-parametric estimations in credibility. Finally, a numerical illustration from the Wisconsin Local Government Property Insurance Fund indicates that the proposed robust credibility approach mitigates the impact of model mis-specification and captures the risk behavior of loss data from a broader perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.09507v4</guid>
      <category>stat.AP</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s13385-024-00391-7</arxiv:DOI>
      <arxiv:journal_reference>European Actuarial Journal, 2024</arxiv:journal_reference>
      <dc:creator>Qian Zhao, Chudamani Poudyal</dc:creator>
    </item>
    <item>
      <title>Optimal single threshold stopping rules and sharp prophet inequalities</title>
      <link>https://arxiv.org/abs/2404.12949</link>
      <description>arXiv:2404.12949v3 Announce Type: replace-cross 
Abstract: This paper considers a finite horizon optimal stopping problem for a sequence of independent and identically distributed random variables. The objective is to design stopping rules that attempt to select the random variable with the highest value in the sequence. The performance of any stopping rule may be benchmarked relative to the selection of a "prophet" that has perfect foreknowledge of the largest value. Such comparisons are typically stated in the form of "prophet inequalities." In this paper we characterize sharp prophet inequalities for single threshold stopping rules as solutions to infinite two person zero sum games on the unit square with special payoff kernels. The proposed game theoretic characterization allows one to derive sharp non-asymptotic prophet inequalities for different classes of distributions. This, in turn, gives rise to a simple and computationally tractable algorithmic paradigm for deriving optimal single threshold stopping rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12949v3</guid>
      <category>math.PR</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Goldenshluger, Yaakov Malinovsky, Assaf Zeevi</dc:creator>
    </item>
    <item>
      <title>Meta-Learning and representation learner: A short theoretical note</title>
      <link>https://arxiv.org/abs/2407.04189</link>
      <description>arXiv:2407.04189v2 Announce Type: replace-cross 
Abstract: Meta-learning, or "learning to learn," is a subfield of machine learning where the goal is to develop models and algorithms that can learn from various tasks and improve their learning process over time. Unlike traditional machine learning methods focusing on learning a specific task, meta-learning aims to leverage experience from previous tasks to enhance future learning. This approach is particularly beneficial in scenarios where the available data for a new task is limited, but there exists abundant data from related tasks. By extracting and utilizing the underlying structure and patterns across these tasks, meta-learning algorithms can achieve faster convergence and better performance with fewer data. The following notes are mainly inspired from \cite{vanschoren2018meta}, \cite{baxter2019learning}, and \cite{maurer2005algorithmic}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04189v2</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mouad El Bouchattaoui</dc:creator>
    </item>
    <item>
      <title>Matrix perturbation bounds via contour bootstrapping</title>
      <link>https://arxiv.org/abs/2407.05230</link>
      <description>arXiv:2407.05230v2 Announce Type: replace-cross 
Abstract: Matrix perturbation bounds play an essential role in the design and analysis of spectral algorithms. In this paper, we introduce a new method to deduce matrix perturbation bounds, which we call "contour bootstrapping". As applications, we work out several new bounds for eigensubspace computation and low rank approximation. Next, we use these bounds to study utility problems in the area of differential privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05230v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Phuc Tran, Van Vu</dc:creator>
    </item>
  </channel>
</rss>
