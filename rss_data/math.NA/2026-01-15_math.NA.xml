<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 Jan 2026 05:00:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Space-time spectral element method for topology optimization of transient heat conduction</title>
      <link>https://arxiv.org/abs/2601.08979</link>
      <description>arXiv:2601.08979v1 Announce Type: new 
Abstract: We develop a space-time spectral element method for topology optimization of transient heat conduction. The forward problem is discretized with summation-by-parts (SBP) operators, and interface/boundary and initial/terminal conditions are imposed weakly via simultaneous approximation terms (SAT), yielding a stable monolithic space-time scheme on heterogeneous domains. Stability is proven under specific conditions on the SAT parameters, scaled with the spatial mesh resolution and material properties. We compute design sensitivities using a discrete space-time adjoint scheme that is dual-consistent with the primal SBP-SAT scheme. Dual consistency ensures that the discrete adjoint consistently approximates the continuous dual problem and, under standard smoothness assumptions, yields superconvergent functional estimates. We validate the resulting optimal designs by comparison with an independently computed reference optimal design and report time-to-solution and cost-of-accuracy curves, comparing against low-order time-marching and all-at-once solvers for the forward and adjoint systems. The proposed scheme attains high accuracy with fewer space-time degrees of freedom and remains stable, reducing time-to-solution and memory compared with an alternative all-at-once solver. This makes it a future candidate for large-scale topology optimization of time-dependent thermal systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08979v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarah Nataj, Magnus Appel, Joe Alexandersen</dc:creator>
    </item>
    <item>
      <title>Nonlinear Inverse Iterations for Spin-Orbit Coupled Quantum Gases</title>
      <link>https://arxiv.org/abs/2601.08990</link>
      <description>arXiv:2601.08990v1 Announce Type: new 
Abstract: This work concerns the computation of ground states of two-component spin-orbit coupled Bose-Einstein condensates (SO-coupled BECs), modelled by a coupled nonlinear eigenvalue problem of Gross-Pitaevskii type. Spin-orbit coupling gives rise to fascinating phenomena, including supersolid-like phases with spatially modulated densities. However, in such complex settings, conventional numerical approaches, such as generalized inverse iterations or gradient descent, often converge very slowly. To overcome this issue, we apply the concept of the J-method [E.~Jarlebring, S.~Kvaal, W.~Michiels. SIAM~J.~Sci.~Comput.~36-4,~2014] to construct a nonlinear inverse iteration scheme whose convergence can be accelerated through spectral shifting, analogous to techniques used for linear eigenproblems. For a fixed shift parameter, we establish local linear convergence rates determined by spectral gaps in the neighbourhood of each quasi-unique ground state. With adaptively chosen shifts, superlinear convergence is observed, which we verify through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08990v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Henning, Laura Huynh</dc:creator>
    </item>
    <item>
      <title>On the unmapped tent pitching for the heterogeneous wave equation</title>
      <link>https://arxiv.org/abs/2601.09337</link>
      <description>arXiv:2601.09337v1 Announce Type: new 
Abstract: The Unmapped Tent Pitching (UTP) algorithm is a space--time domain decomposition method for the parallel solution of hyperbolic problems. It was originally introduced for the homogeneous one-dimensional wave equation in [Ciaramella, Gander, Mazzieri, 2024]. UTP is inspired by the Mapped Tent Pitching (MTP) algorithm [Gopalakrishnan, Sch{\"o}berl, Wintersteiger, 2017], which constructs the solution by iteratively building polytopal space--time subdomains, referred to as tents. In MTP, each physical tent is mapped onto a space--time rectangle, where local problems are solved before being mapped back to the original domain. In contrast, UTP avoids the nonlinear and potentially singular mapping step by computing the solution directly on a physical space--time rectangle that contains the tent, at the expense of redundant computations in the region outside the tent. In this work, we investigate several strategies to extend UTP to heterogeneous media, where the wave propagation speed is piecewise constant over two subregions of the domain. Among the considered approaches, the most efficient in terms of computational time is the one employing space--time subdomains with identical spatial and temporal dimensions in both regions, determined by the maximum propagation speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09337v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcella Bonazzoli (IDEFIX), Gabriele Ciaramella (MOX), Ilario Mazzieri (MOX)</dc:creator>
    </item>
    <item>
      <title>Thermodynamically consistent phase-field modeling and numerical simulation for two-phase fluid-solid dynamics</title>
      <link>https://arxiv.org/abs/2601.09383</link>
      <description>arXiv:2601.09383v1 Announce Type: new 
Abstract: We introduce a coupled Cahn-Hilliard Navier-Stokes model that governs the two-phase dynamics of a system that consists of a fluid and a solid phase and prove its thermodynamic consistency. Moreover, we present an associated fully-discrete numerical method that relies on a continuous finite element approach and a semi-implicit time-stepping method. As the main theoretical result we show that the fully-discrete method satisfies a discrete analog of the free energy dissipation inequality. Numerical experiments confirm the theoretical findings and show the applicability of the method for realistic settings including an extension to chemically reacting flow. In this context, we provide a preprocessing strategy that enables computing fluid flow in complex geometries given a sharp-interface formulation of the initial phase distribution. Moreover, we briefly introduce different solution strategies for the novel discretization based on the monolithic and partitioned solution paradigms and assess these in a comparative study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09383v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cedric Riethm\"uller, Lars von Wolff, Dominik G\"oddeke, Christian Rohde</dc:creator>
    </item>
    <item>
      <title>A Randomized Milstein Scheme for SDEs with Superlinear Drift Coefficient</title>
      <link>https://arxiv.org/abs/2601.09437</link>
      <description>arXiv:2601.09437v1 Announce Type: new 
Abstract: This work presents a randomized-tamed Milstein scheme for stochastic differential equations whose drift coefficient exhibits superlinear growth in the state variable and limited temporal regularity, quantified by $\beta$-H\"older continuity with $\beta \in (0,1]$. The scheme combines a taming mechanism to control the superlinear state dependence with a drift randomization strategy designed to address the challenges posed by low temporal regularity. Under suitable assumptions on temporal smoothness, the scheme achieves an optimal strong $\mathscr{L}^p$-convergence rate of order one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09437v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sani Biswas</dc:creator>
    </item>
    <item>
      <title>A new class of entropy stable fluctuations for the discontinuous Galerkin method with application to the Saint-Venant-Exner model</title>
      <link>https://arxiv.org/abs/2601.09450</link>
      <description>arXiv:2601.09450v1 Announce Type: new 
Abstract: In this work we consider entropy stable discontinuous Galerkin methods applied to nonconservative hyperbolic systems. We introduce a new class of entropy conservative fluctuations that allow us to construct entropy conservative schemes without any system-specific derivations. We demonstrate that a loss of entropy symmetrization for nonconservative systems restricts the design of entropy stable fluctuations and propose a novel blending procedure to construct entropy stable dissipation terms from general numerical viscosity matrices. The resulting methodology is applied to develop a high-order, entropy stable, and well-balanced approximation for the Saint-Venant-Exner system. Numerical tests are presented to verify the theoretical findings and demonstrate the performance and robustness of the proposed scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09450v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Ersing, Andrew R. Winters</dc:creator>
    </item>
    <item>
      <title>Qualitative and Numerical Simulation of a Time-Fractional SEIR Mpox Model Arising in Population Epidemiology</title>
      <link>https://arxiv.org/abs/2601.09479</link>
      <description>arXiv:2601.09479v1 Announce Type: new 
Abstract: Epidemiological modeling is vital in understanding disease dynamics and guiding public health interventions. This study presents a time-fractional SEIR model to describe the transmission dynamics of Mpox, incorporating memory effects via the fractional derivative. We perform an extensive qualitative investigation, proving that there is a unique solution and that the solutions are Hyers-Ulam stable. To approximate the model numerically, we implement the L1 finite difference scheme for the Caputo derivative and solve the resulting nonlinear system using the Newton-Raphson technique. A detailed error analysis is provided, demonstrating that the scheme achieves algebraic convergence. Comparative results with the Fractional Modified Euler method (FMEM) confirm the superior accuracy and stability of the proposed approach. Numerical simulations under biologically relevant parameters illustrate the impact of the non-integer order and vaccination rate on disease progression. The study underscores the effectiveness of fractional order models in capturing epidemic memory effects and positions the L1 scheme as a robust numerical tool for simulating such dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09479v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gaurav Saini, Bappa Ghosh, Sunita Chand, Jugal Mohapatra</dc:creator>
    </item>
    <item>
      <title>Two continuous extensions of the Neural Approximated Virtual Element Method</title>
      <link>https://arxiv.org/abs/2601.09595</link>
      <description>arXiv:2601.09595v1 Announce Type: new 
Abstract: We propose two globally continuous neural-based variants of the Neural Approximated Virtual Element Method (NAVEM), termed B-NAVEM and P-NAVEM. Both approaches construct local basis functions using pre-trained fully connected neural networks while ensuring exact continuity across adjacent mesh elements. B-NAVEM leverages a Physics-Informed Neural Network to approximately solve the local Laplace problem that defines the virtual element basis functions, whereas P-NAVEM directly enforces polynomial reproducibility via a tailored loss function, without requiring harmonicity within the element interior. Numerical experiments assess the methods in terms of computational cost, memory usage, and accuracy during both training and testing phases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09595v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefano Berrone, Moreno Pintore, Gioana Teora</dc:creator>
    </item>
    <item>
      <title>Introduction to the Combination of Reduced Order Models and Domain Decomposition: State of the Art and Perspectives</title>
      <link>https://arxiv.org/abs/2601.09623</link>
      <description>arXiv:2601.09623v1 Announce Type: new 
Abstract: Reduced Order Models (ROMs) have been regarded as an efficient alternative to conventional high-fidelity Computational Fluid Dynamics (CFD) for accelerating the design and optimization processes in engineering applications. Many industrial geometries feature repeating subdomains or contain sub-regions governed by distinct physical phenomena, making them well-suited to Domain Decomposition (DD) techniques. The integration of ROM and DD is promising to further reduce computational costs by constructing local ROMs and assembling them into global solutions. Due to the complexity and necessity of coupling ROMs, many approaches have been proposed in recent years. This review provides a concise overview of existing methodologies combining ROM and DD. We categorize existing methods into intrusive (projection-based) and non-intrusive (data-driven) frameworks. Various strategies for generating local reduced bases and coupling them across subdomains are illustrated. Particular emphasis is placed on intrusive techniques, including equations, numerical algorithms, and practical implementations. The non-intrusive framework is also discussed, highlighting its general procedures, basic formulations, and underlying principles. Finally, we summarise the state of the literature, identify open challenges, and present perspectives on future implementation from an engineering viewpoint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09623v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shenhui Ruan, Andreas G. Class, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>Explaining oscillatory behavior in convection-diffusion discretization</title>
      <link>https://arxiv.org/abs/2601.09657</link>
      <description>arXiv:2601.09657v1 Announce Type: new 
Abstract: For a model convection-diffusion problem, we address the presence of oscillatory discrete solutions, and study difficulties in recovering standard approximation results for its solution. We justify the presence of non-physical oscillations and propose ways to eliminate oscillations. A new approach for error analysis that requires establishing optimal discrete infinity error as a first step is introduced and justified. We emphasize that the discretization of two dimensional convection dominated problems benefit from the efficient discretization of the corresponding one dimensional problem along each stream line. Our results are useful in building new and robust discretizations for multi-dimensional convection dominated problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09657v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Constantin Bacuta</dc:creator>
    </item>
    <item>
      <title>W-DUALMINE: Reliability-Weighted Dual-Expert Fusion With Residual Correlation Preservation for Medical Image Fusion</title>
      <link>https://arxiv.org/abs/2601.08920</link>
      <description>arXiv:2601.08920v1 Announce Type: cross 
Abstract: Medical image fusion integrates complementary information from multiple imaging modalities to improve clinical interpretation. However, existing deep learningbased methods, including recent spatial-frequency frameworks such as AdaFuse and ASFE-Fusion, often suffer from a fundamental trade-off between global statistical similaritymeasured by correlation coefficient (CC) and mutual information (MI)and local structural fidelity. This paper proposes W-DUALMINE, a reliability-weighted dual-expert fusion framework designed to explicitly resolve this trade-off through architectural constraints and a theoretically grounded loss design. The proposed method introduces dense reliability maps for adaptive modality weighting, a dual-expert fusion strategy combining a global-context spatial expert and a wavelet-domain frequency expert, and a soft gradient-based arbitration mechanism. Furthermore, we employ a residual-to-average fusion paradigm that guarantees the preservation of global correlation while enhancing local details. Extensive experiments on CT-MRI, PET-MRI, and SPECT-MRI datasets demonstrate that W-DUALMINE consistently outperforms AdaFuse and ASFE-Fusion in CC and MI metrics while</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08920v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md. Jahidul Islam</dc:creator>
    </item>
    <item>
      <title>Global polynomial-time estimation in statistical nonlinear inverse problems via generalized stability</title>
      <link>https://arxiv.org/abs/2601.09007</link>
      <description>arXiv:2601.09007v1 Announce Type: cross 
Abstract: Non-linear statistical inverse problems pose major challenges both for statistical analysis and computation. Likelihood-based estimators typically lead to non-convex and possibly multimodal optimization landscapes, and Markov chain Monte Carlo (MCMC) methods may mix exponentially slowly. We propose a class of computationally tractable estimators--plug-in and PDE-penalized M-estimators--for inverse problems defined through operator equations of the form $L_f u = g$, where $f$ is the unknown parameter and $u$ is the observed solution. The key idea is to replace the exact PDE constraint by a weakly enforced relaxation, yielding conditionally convex and, in many PDE examples, nested quadratic optimization problems that avoid evaluating the forward map $G(f)$ and do not require PDE solvers. For prototypical non-linear inverse problems arising from elliptic PDEs, including the Darcy flow model $L_f u = \nabla\!\cdot(f\nabla u)$ and a steady-state Schr\"odinger model, we prove that these estimators attain the best currently known statistical convergence rates while being globally computable in polynomial time. In the Darcy model, we obtain an explicit sub-quadratic $o(N^2)$ arithmetic runtime bound for estimating $f$ from $N$ noisy samples. Our analysis is based on new generalized stability estimates, extending classical stability beyond the range of the forward operator, combined with tools from nonparametric M-estimation. We also derive adaptive rates for the Darcy problem, providing a blueprint for designing provably polynomial-time statistical algorithms for a broad class of non-linear inverse problems. Our estimators also provide principled warm-start initializations for polynomial-time Bayesian computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09007v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sven Wang</dc:creator>
    </item>
    <item>
      <title>Discrete Solution Operator Learning for Geometry-Dependent PDEs</title>
      <link>https://arxiv.org/abs/2601.09143</link>
      <description>arXiv:2601.09143v1 Announce Type: cross 
Abstract: Neural operator learning accelerates PDE solution by approximating operators as mappings between continuous function spaces. Yet in many engineering settings, varying geometry induces discrete structural changes, including topological changes, abrupt changes in boundary conditions or boundary types, and changes in the effective computational domain, which break the smooth-variation premise. Here we introduce Discrete Solution Operator Learning (DiSOL), a complementary paradigm that learns discrete solution procedures rather than continuous function-space operators. DiSOL factorizes the solver into learnable stages that mirror classical discretizations: local contribution encoding, multiscale assembly, and implicit solution reconstruction on an embedded grid, thereby preserving procedure-level consistency while adapting to geometry-dependent discrete structures. Across geometry-dependent Poisson, advection-diffusion, linear elasticity, as well as spatiotemporal heat-conduction problems, DiSOL produces stable and accurate predictions under both in-distribution and strongly out-of-distribution geometries, including discontinuous boundaries and topological changes. These results highlight the need for procedural operator representations in geometry-dominated regimes and position discrete solution operator learning as a distinct, complementary direction in scientific machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09143v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinshuai Bai, Haolin Li, Zahra Sharif Khodaei, M. H. Aliabadi, YuanTong Gu, Xi-Qiao Feng</dc:creator>
    </item>
    <item>
      <title>Determination of active forces in actomyosin systems as inverse source problems for the Stokes equation</title>
      <link>https://arxiv.org/abs/2601.09356</link>
      <description>arXiv:2601.09356v1 Announce Type: cross 
Abstract: The identification of forces and stresses is a central task in biophysics research: Knowledge on forces is key to understanding dynamic processes in active biological systems that are able to self-organize and display emergent properties by converting energy into mechanical work. The aim of this paper is to identify forces generated by a filament-motor network of F-actin and myosin -- actomyosin -- and exerted on the surrounding fluid, therefore causing a fluid flow. In particular, we evaluate optical microscopy data stemming from two different physical settings, confined and non-confined active gels. As a theoretical model, we use the Stokes equation together with an incompressibility condition and suitable boundary conditions reflecting the physical settings. The problem of determining the forces from knowledge on the fluid flow is formulated as an inverse source problem. Due to experimental limitations, only incomplete data are available. We provide a rigorous analysis of the forward problems and the impact of missing data, derive the adjoints of the forward operators needed for regularization, and demonstrate our methods on both synthetic and experimentally measured data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09356v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emily Klass, Tram Thi Ngoc Nguyen, Nilay Cicek, Yoav G. Pollack, Sarah K\"oster, Andreas Janshoff, Anne Wald</dc:creator>
    </item>
    <item>
      <title>Variational Bayesian Inference for Tensor Robust Principal Component Analysis</title>
      <link>https://arxiv.org/abs/2412.18717</link>
      <description>arXiv:2412.18717v2 Announce Type: replace 
Abstract: Tensor Robust Principal Component Analysis (TRPCA) holds a crucial position in machine learning and computer vision. It aims to recover underlying low-rank structures and to characterize the sparse structures of noise. Current approaches often encounter difficulties in accurately capturing the low-rank properties of tensors and balancing the trade-off between low-rank and sparse components, especially in a mixed-noise scenario. To address these challenges, we introduce a Bayesian framework for TRPCA, which integrates a low-rank tensor nuclear norm prior and a generalized sparsity-inducing prior. By embedding the priors within the Bayesian framework, our method can automatically determine the optimal tensor nuclear norm and achieve a balance between the nuclear norm and sparse components. Furthermore, our method can be efficiently extended to the weighted tensor nuclear norm model. Experiments conducted on synthetic and real-world datasets demonstrate the effectiveness and superiority of our method compared to state-of-the-art approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18717v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Wang, Huiwen Zheng, Raymond Chan, Youwei Wen</dc:creator>
    </item>
    <item>
      <title>Preconditioning FEM discretisations of the high-frequency Helmholtz and Maxwell equations by either perturbing the coefficients or adding absorption</title>
      <link>https://arxiv.org/abs/2504.13814</link>
      <description>arXiv:2504.13814v2 Announce Type: replace 
Abstract: This paper investigates the following question: given a Galerkin matrix corresponding to a finite-element discretisation of either the Helmholtz or time-harmonic Maxwell equations with variable coefficients, suppose that the coefficients of the underlying PDE are perturbed; how good an approximate inverse (i.e., preconditioner) is the resulting Galerkin matrix to the original Galerkin matrix? An important special case is when the perturbation consists of adding absorption (in the spirit of "shifted Laplacian preconditioning"). The results of this paper improve the Helmholtz results in [Gander, Graham, Spence, 2015] and [Graham, Pembery, Spence, 2021], and extend these results to the time-harmonic Maxwell equations, confirming a conjecture in the recent preprint [Li, Hu, arXiv 2501.18305].</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13814v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Euan A. Spence</dc:creator>
    </item>
    <item>
      <title>A mixed Petrov-Galerkin Cosserat rod finite element formulation</title>
      <link>https://arxiv.org/abs/2507.01552</link>
      <description>arXiv:2507.01552v3 Announce Type: replace 
Abstract: This paper presents a total Lagrangian mixed Petrov-Galerkin finite element formulation that provides a computationally efficient approach for analyzing Cosserat rods that is free of singularities and locking. To achieve a singularity-free orientation parametrization of the rod, the nodal kinematical unknowns are defined as the nodal centerline positions and unit quaternions. We apply Lagrange interpolation to all nodal kinematic coordinates, and in combination with a projection of non-unit quaternions, this leads to an interpolation with orthonormal cross-section-fixed bases. To eliminate locking effects such as shear locking, the variational Hellinger-Reissner principle is applied, resulting in a mixed approach with additional fields composed of resultant contact forces and moments. Since the mixed formulation contains the constitutive law in compliance form, it naturally incorporates constrained theories, such as the Kirchhoff-Love theory. This study specifically examines the influence of the additional internal force fields on the numerical performance, including locking mitigation and robustness. Using well-established benchmark examples, the method demonstrates enhanced computational robustness and efficiency, as evidenced by the reduction in required load steps and iterations when applying the standard Newton-Raphson method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01552v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Marco Herrmann, Domenico Castello, Jonas Breuling, Idoia Cortes Garcia, Leopoldo Greco, Simon R. Eugster</dc:creator>
    </item>
    <item>
      <title>Moments, Time-Inversion and Source Identification for the Heat Equation</title>
      <link>https://arxiv.org/abs/2507.02677</link>
      <description>arXiv:2507.02677v2 Announce Type: replace 
Abstract: We address the initial source identification problem for the heat equation, a notably ill-posed inverse problem characterized by exponential instability. Departing from classical Tikhonov regularization, we propose a novel approach based on moment analysis of the heat flow, transforming the problem into a more stable inverse moment formulation. By evolving the measured terminal time moments backward through their governing ODE system, we recover the moments of the initial distribution. We then reconstruct the source by solving a convex optimization problem that minimizes the total variation of a measure subject to these moment constraints. This formulation naturally promotes sparsity, yielding atomic solutions that are sums of Dirac measures. Compared to existing methods, our moment-based approach reduces exponential error growth to polynomial growth with respect to the terminal time. We provide explicit error estimates on the recovered initial distributions in terms of moment order, terminal time, and measurement errors. In addition, we develop efficient numerical discretization schemes and demonstrate significant stability improvements of our approach through comprehensive numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02677v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1088/1361-6420/ae3797</arxiv:DOI>
      <dc:creator>Kang Liu, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>Hierarchical Importance Sampling for Estimating Occupation Time for SDE Solutions</title>
      <link>https://arxiv.org/abs/2509.13950</link>
      <description>arXiv:2509.13950v2 Announce Type: replace 
Abstract: This study considers the estimation of the complementary cumulative distribution function of the occupation time (i.e., the time spent below a threshold) for a process governed by a stochastic differential equation. The focus is on the right tail, where the underlying event becomes rare, and using variance reduction techniques is essential to obtain computationally efficient estimates. Building on recent developments that relate importance sampling (IS) to stochastic optimal control, this work develops an optimal single level IS (SLIS) estimator based on the solution of an auxiliary Hamilton Jacobi Bellman (HJB) partial differential equation (PDE). The cost of solving the HJB-PDE is incorporated into the total computational work, and an optimized trade off between preprocessing and sampling is proposed to minimize the overall cost. The SLIS approach is extended to the multilevel setting to enhance efficiency, yielding a multilevel IS (MLIS) estimator. A necessary and sufficient condition under which the MLIS method outperforms the SLIS method is established, and a common likelihood MLIS formulation is introduced that satisfies this condition under appropriate regularity assumptions. The classical multilevel Monte Carlo complexity theory can be extended to accommodate settings where the single-level variance varies with the discretization level. As a special case, the variance-decay behavior observed in the IS framework stems from the zero variance property of the optimal control. Notably, the total work complexity of MLIS can be better than an order of two. Numerical experiments in the context of fade duration estimation demonstrate the benefits of the proposed approach and validate these theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13950v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eya Ben Amar, Nadhir Ben Rached, Raul Tempone</dc:creator>
    </item>
    <item>
      <title>Development of a Model Order Reduced Arbitrary Lagrangian Eulerian (MORALE) formulation for structures subjected to dynamic moving loads</title>
      <link>https://arxiv.org/abs/2509.20069</link>
      <description>arXiv:2509.20069v2 Announce Type: replace 
Abstract: In recent developments, it has been demonstrated that the Arbitrary Lagrangian Eulerian (ALE) formulation can be utilized to improve computational efficiency, when simulating the response of structures subjected to moving loads. It is also well established in literature, that Model Order Reduction (MOR) techniques significantly enhance calculation speed. This contribution details the combination of both these tools into a novel Model Order Reduced Arbitrary Lagrangian Eulerian (MORALE) formulation. Both hyperelastic and viscoelastic material models are considered. Simulations of pavement structures subjected to moving loads are then carried out, which show a significant enhancement in computational speed and efficiency. Such an efficient and fast simulation framework is of vital importance in technologies such as digital twins of roadway infrastructure (like pavements), as it enables engineers to quickly run what-if analyses and make informed decisions about the management of the structure under consideration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20069v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1002/nme.70229</arxiv:DOI>
      <dc:creator>Atul Anantheswar, Jannick Kehls, Ines Wollny, Tim Brepols, Stefanie Reese, Michael Kaliske</dc:creator>
    </item>
    <item>
      <title>Multiscale Spectral Generalized Finite Element Methods for Discontinuous Galerkin Schemes</title>
      <link>https://arxiv.org/abs/2510.21289</link>
      <description>arXiv:2510.21289v2 Announce Type: replace 
Abstract: We propose a multiscale spectral generalized finite element method (MS-GFEM) for discontinuous Galerkin (DG) discretizations. The method builds local approximations on overlapping subdomains as the sum of a local source solution and a correction from an optimal spectral coarse space, which is obtained from a generalized eigenproblem. The global solution is then assembled via a partition of unity. We prove nearly exponential decay of the approximation error for second-order elliptic problems with highly heterogeneous diffusion discretized by a weighted symmetric interior-penalty DG scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21289v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Christian Alber, Lukas Holbach</dc:creator>
    </item>
    <item>
      <title>Pretrain Finite Element Method: A Pretraining and Warm-start Framework for PDEs via Physics-Informed Neural Operators</title>
      <link>https://arxiv.org/abs/2601.03086</link>
      <description>arXiv:2601.03086v2 Announce Type: replace 
Abstract: We propose a Pretrained Finite Element Method (PFEM),a physics driven framework that bridges the efficiency of neural operator learning with the accuracy and robustness of classical finite element methods (FEM). PFEM consists of a physics informed pretraining stage and an optional finetuning stage. In the pretraining stage, a neural operator based on the Transolver architecture is trained solely from governing partial differential equations, without relying on labeled solution data. The model operates directly on unstructured point clouds, jointly encoding geometric information, material properties, and boundary conditions, and produces physically consistent initial solutions with extremely high computational efficiency. PDE constraints are enforced through explicit finite element, based differentiation, avoiding the overhead associated with automatic differentiation. In the fine-tuning stage, the pretrained prediction is used as an initial guess for conventional FEM solvers, preserving their accuracy, convergence guarantees, and extrapolation capability while substantially reducing the number of iterations required to reach a prescribed tolerance. PFEM is validated on a broad range of benchmark problems, including linear elasticity and nonlinear hyperelasticity with complex geometries, heterogeneous materials, and arbitrary boundary conditions. Numerical results demonstrate strong generalization in the pretraining stage with relative errors on the order of 1\%, and speedups of up to one order of magnitude in the fine-tuning stage compared to FEM with zero initial guesses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03086v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizheng Wang, Zhongkai Hao, Mohammad Sadegh Eshaghi, Cosmin Anitescu, Xiaoying Zhuang, Timon Rabczuk, Yinghua Liu</dc:creator>
    </item>
    <item>
      <title>A Structure-Preserving Penalization Method for the Single-species Rosenbluth-Fokker-Planck Equation</title>
      <link>https://arxiv.org/abs/2601.08006</link>
      <description>arXiv:2601.08006v2 Announce Type: replace 
Abstract: The Rosenbluth-Fokker-Planck (RFP) equation describes Coulomb collisional dynamics within and across species in plasmas. It belongs to the broader class of anisotropic-diffusion-advection equations, whose numerical approximation is highly-nontrivial due to its nonlinearity, stiffness, and structural properties such as conservation and entropy dissipation (hence with the Maxwellian distribution as the equilibrium state). In this paper, we propose a structure-preserving penalization scheme for the stiff, single-species RFP equation. The scheme features three novel components: 1) a novel generalization of the well-known Chang-Cooper discretization for the RFP equation that is equilibrium-preserving and enables positivity while preserving mass, momentum, and energy; 2) an easy-to-invert isotropic variable-coefficient penalization operator to deal with the temporal stiffness without resorting to a fully implicit scheme, borrowing ideas from explicit-implicit-null (EIN) methods, and 3) an adaptive timestepping strategy that preserves the positivity of the full penalized scheme. The resulting scheme conserves mass, momentum, and energy strictly, is unconditionally stable, and robustly positivity preserving. The scheme is demonstrated with linear and nonlinear anisotropic diffusion examples of increasing complexity, including several single-species RFP examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08006v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hamad El Kahza, Luis Chac\'on, William Taitano, Jingmei Qiu, Jingwei Hu</dc:creator>
    </item>
    <item>
      <title>Classical combinations of quantum states for solving banded circulant linear systems</title>
      <link>https://arxiv.org/abs/2309.11451</link>
      <description>arXiv:2309.11451v2 Announce Type: replace-cross 
Abstract: Solving linear systems is of great importance in numerous fields. Proposed quantum algorithms for preparing solutions for linear systems include the HHL algorithm with subsequent refinements and variational methods. Circulant linear systems appear in many physics-related differential equations. An interesting case is banded circulant linear systems whose non-zero terms are within distance K of the main diagonal. For these systems, we propose an approach based on the classical combination of quantum states (CQS) method relying on convex optimization against the available analytical solution. From decompositions into cyclic permutations, the solution can be approximately represented by a classical combination of a polynomial number of quantum states. We validate our methods using classical simulations as well as execution on an IBM quantum computer. While in the setting of this paper, efficient classical algorithms are available, our results demonstrate the potential applicability of the CQS method for solving physics problems such as heat transfer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.11451v2</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1088/1367-2630/ae3205</arxiv:DOI>
      <arxiv:journal_reference>New Journal of Physics 28, 014507 (2026)</arxiv:journal_reference>
      <dc:creator>Po-Wei Huang, Xiufan Li, Kelvin Koor, Patrick Rebentrost</dc:creator>
    </item>
    <item>
      <title>Numerical stability of force-gradient integrators and their Hessian-free variants in lattice QCD simulations</title>
      <link>https://arxiv.org/abs/2506.08813</link>
      <description>arXiv:2506.08813v2 Announce Type: replace-cross 
Abstract: A comprehensive linear stability analysis of force-gradient integrators and their Hessian-free variants is carried out by investigating the harmonic oscillator as a test equation. The analysis reveals that the linear stability of conventional force-gradient integrators and their Hessian-free counterparts coincides. By performing detailed linear stability investigations for the entire family of self-adjoint integrators with up to eleven exponentials per time step, we detect promising integrator variants that are providing a good trade-off between accuracy and numerical stability. Special attention is given to the application of these promising integrator variants within the Hamiltonian Monte Carlo algorithm, particularly in the context of interacting field theories. Simulations for the two-dimensional Schwinger model are conducted to demonstrate that there are no significant differences in the stability domain of a force-gradient integrator and its Hessian-free counterpart. Lattice QCD simulations with two heavy Wilson fermions emphasize that Hessian-free force-gradient integrators with a larger stability threshold allow for a more efficient computational process compared to conventional splitting methods. Furthermore, detailed investigations of the stability threshold are performed by investigating Nf = 2 twisted-mass fermions and nested integrators, highlighting the reliability of the linear stability threshold for lattice QCD simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08813v2</guid>
      <category>hep-lat</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Sch\"afers, Jacob Finkenrath, Michael G\"unther, Francesco Knechtli</dc:creator>
    </item>
    <item>
      <title>Sobolev Approximation of Deep ReLU Networks in Log-Barron Space</title>
      <link>https://arxiv.org/abs/2601.01295</link>
      <description>arXiv:2601.01295v2 Announce Type: replace-cross 
Abstract: Universal approximation theorems show that neural networks can approximate any continuous function; however, the number of parameters may grow exponentially with the ambient dimension, so these results do not fully explain the practical success of deep models on high-dimensional data. Barron space theory addresses this: if a target function belongs to a Barron space, a two-layer network with $n$ parameters achieves an $O(n^{-1/2})$ approximation error in $L^2$. Yet classical Barron spaces $\mathscr{B}^{s+1}$ still require stronger regularity than Sobolev spaces $H^s$, and existing depth-sensitive results often assume constraints such as $sL \le 1/2$. In this paper, we introduce a log-weighted Barron space $\mathscr{B}^{\log}$, which requires a strictly weaker assumption than $\mathscr{B}^s$ for any $s&gt;0$. For this new function space, we first study embedding properties and carry out a statistical analysis via the Rademacher complexity. Then we prove that functions in $\mathscr{B}^{\log}$ can be approximated by deep ReLU networks with explicit depth dependence. We then define a family $\mathscr{B}^{s,\log}$, establish approximation bounds in the $H^1$ norm, and identify maximal depth scales under which these rates are preserved. Our results clarify how depth reduces regularity requirements for efficient representation, offering a more precise explanation for the performance of deep architectures beyond the classical Barron setting, and for their stable use in high-dimensional problems used today.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01295v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Changhoon Song, Seungchan Ko, Youngjoon Hong</dc:creator>
    </item>
  </channel>
</rss>
