<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Feb 2025 05:00:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Exponential Topology-enabled Scalable Communication in Multi-agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2502.19717</link>
      <description>arXiv:2502.19717v1 Announce Type: new 
Abstract: In cooperative multi-agent reinforcement learning (MARL), well-designed communication protocols can effectively facilitate consensus among agents, thereby enhancing task performance. Moreover, in large-scale multi-agent systems commonly found in real-world applications, effective communication plays an even more critical role due to the escalated challenge of partial observability compared to smaller-scale setups. In this work, we endeavor to develop a scalable communication protocol for MARL. Unlike previous methods that focus on selecting optimal pairwise communication links-a task that becomes increasingly complex as the number of agents grows-we adopt a global perspective on communication topology design. Specifically, we propose utilizing the exponential topology to enable rapid information dissemination among agents by leveraging its small-diameter and small-size properties. This approach leads to a scalable communication protocol, named ExpoComm. To fully unlock the potential of exponential graphs as communication topologies, we employ memory-based message processors and auxiliary tasks to ground messages, ensuring that they reflect global information and benefit decision-making. Extensive experiments on large-scale cooperative benchmarks, including MAgent and Infrastructure Management Planning, demonstrate the superior performance and robust zero-shot transferability of ExpoComm compared to existing communication strategies. The code is publicly available at https://github.com/LXXXXR/ExpoComm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19717v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinran Li, Xiaolu Wang, Chenjia Bai, Jun Zhang</dc:creator>
    </item>
    <item>
      <title>RouteRL: Multi-agent reinforcement learning framework for urban route choice with autonomous vehicles</title>
      <link>https://arxiv.org/abs/2502.20065</link>
      <description>arXiv:2502.20065v1 Announce Type: new 
Abstract: RouteRL is a novel framework that integrates multi-agent reinforcement learning (MARL) with a microscopic traffic simulation, facilitating the testing and development of efficient route choice strategies for autonomous vehicles (AVs). The proposed framework simulates the daily route choices of driver agents in a city, including two types: human drivers, emulated using behavioral route choice models, and AVs, modeled as MARL agents optimizing their policies for a predefined objective. RouteRL aims to advance research in MARL, transport modeling, and human-AI interaction for transportation applications. This study presents a technical report on RouteRL, outlines its potential research contributions, and showcases its impact via illustrative examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20065v1</guid>
      <category>cs.MA</category>
      <category>cs.LG</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmet Onur Akman, Anastasia Psarou, {\L}ukasz Gorczyca, Zolt\'an Gy\"orgy Varga, Grzegorz Jamr\'oz, Rafa{\l} Kucharski</dc:creator>
    </item>
    <item>
      <title>Analysis of Linear Consensus Algorithm on Strongly Connected Graph Using Effective Resistance</title>
      <link>https://arxiv.org/abs/2502.19720</link>
      <description>arXiv:2502.19720v1 Announce Type: cross 
Abstract: We study the performance of the linear consensus algorithm on strongly connected graphs using the linear quadratic (LQ) cost as a performance measure.
  In particular, we derive bounds on the LQ cost by leveraging effective resistance. Our results extend previous analyses -- which were limited to reversible cases -- to the nonreversible setting. To facilitate this generalization, we introduce novel concepts, termed the back-and-forth path and the pivot node, which serve as effective alternatives to traditional techniques that require reversibility. Moreover, we apply our approach to geometric graphs to estimate the LQ cost without the reversibility assumption. The proposed approach provides a framework that can be adapted to other contexts where reversibility is typically assumed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19720v1</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takumi Yonaiyama, Kazuhiro Sato</dc:creator>
    </item>
    <item>
      <title>Constructing Stochastic Matrices for Weighted Averaging in Gossip Networks</title>
      <link>https://arxiv.org/abs/2502.19821</link>
      <description>arXiv:2502.19821v1 Announce Type: cross 
Abstract: The convergence of the gossip process has been extensively studied; however, algorithms that generate a set of stochastic matrices, the infinite product of which converges to a rank-one matrix determined by a given weight vector, have been less explored. In this work, we propose an algorithm for constructing (local) stochastic matrices based on a given gossip network topology and a set of weights for averaging across different consensus clusters, ensuring that the gossip process converges to a finite limit set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19821v1</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erkan Bayram, Mohamed-Ali Belabbas</dc:creator>
    </item>
    <item>
      <title>Social Influence Distorts Ratings in Online Interfaces</title>
      <link>https://arxiv.org/abs/2502.19861</link>
      <description>arXiv:2502.19861v1 Announce Type: cross 
Abstract: Theoretical work on sequential choice and large-scale experiments in online ranking and voting systems has demonstrated that social influence can have a drastic impact on social and technological systems. Yet, the effect of social influence on online rating systems remains understudied and the few existing contributions suggest that online ratings would self-correct given enough users. Here, we propose a new framework for studying the effect of social influence on online ratings. We start from the assumption that people are influenced linearly by the observed average rating, but postulate that their propensity to be influenced varies. When the weight people assign to the observed average depends only on their own latent rating, the resulting system is linear, but the long-term rating may substantially deviate from the true mean rating. When the weight people put on the observed average depends on both their own latent rating and the observed average rating, the resulting system is non-linear, and may support multiple equilibria, suggesting that ratings might be path-dependent and deviations dramatic. Our results highlight potential limitations in crowdsourced information aggregation and can inform the design of more robust online rating systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19861v1</guid>
      <category>cs.SI</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3701716.3715592</arxiv:DOI>
      <dc:creator>Marina Kontalexi, Alexandros Gelastopoulos, Pantelis P. Analytis</dc:creator>
    </item>
    <item>
      <title>Collab-Overcooked: Benchmarking and Evaluating Large Language Models as Collaborative Agents</title>
      <link>https://arxiv.org/abs/2502.20073</link>
      <description>arXiv:2502.20073v1 Announce Type: cross 
Abstract: Large language models (LLMs) based agent systems have made great strides in real-world applications beyond traditional NLP tasks. This paper proposes a new LLM-powered Multi-Agent System (LLM-MAS) benchmark, Collab-Overcooked, built on the popular Overcooked-AI game with more applicable and challenging tasks in interactive environments. Collab-Overcooked extends existing benchmarks from two novel perspectives. First, it provides a multi-agent framework supporting diverse tasks and objectives and encourages collaboration through natural language communication. Second, it introduces a spectrum of process-oriented evaluation metrics to assess the fine-grained collaboration capabilities of different LLM agents, a dimension often overlooked in prior work. We conduct extensive experiments over 10 popular LLMs and show that, while the LLMs present a strong ability in goal interpretation, there is a significant discrepancy in active collaboration and continuous adaption that are critical for efficiently fulfilling complicated tasks. Notably, we highlight the strengths and weaknesses in LLM-MAS and provide insights for improving and evaluating LLM-MAS on a unified and open-sourced benchmark. Environments, 30 open-ended tasks, and an integrated evaluation package are now publicly available at https://github.com/YusaeMeow/Collab-Overcooked.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20073v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haochen Sun, Shuwen Zhang, Lei Ren, Hao Xu, Hao Fu, Caixia Yuan, Xiaojie Wang</dc:creator>
    </item>
    <item>
      <title>Discovering Antagonists in Networks of Systems: Robot Deployment</title>
      <link>https://arxiv.org/abs/2502.20125</link>
      <description>arXiv:2502.20125v1 Announce Type: cross 
Abstract: A contextual anomaly detection method is proposed and applied to the physical motions of a robot swarm executing a coverage task. Using simulations of a swarm's normal behavior, a normalizing flow is trained to predict the likelihood of a robot motion within the current context of its environment. During application, the predicted likelihood of the observed motions is used by a detection criterion that categorizes a robot agent as normal or antagonistic. The proposed method is evaluated on five different strategies of antagonistic behavior. Importantly, only readily available simulated data of normal robot behavior is used for training such that the nature of the anomalies need not be known beforehand. The best detection criterion correctly categorizes at least 80% of each antagonistic type while maintaining a false positive rate of less than 5% for normal robot agents. Additionally, the method is validated in hardware experiments, yielding results similar to the simulated scenarios. Compared to the state-of-the-art approach, both the predictive performance of the normalizing flow and the robustness of the detection criterion are increased.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20125v1</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ingeborg Wenger, Peter Eberhard, Henrik Ebel</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Path Planning in Complex Environments using Gaussian Belief Propagation with Global Path Finding</title>
      <link>https://arxiv.org/abs/2502.20369</link>
      <description>arXiv:2502.20369v1 Announce Type: cross 
Abstract: Multi-agent path planning is a critical challenge in robotics, requiring agents to navigate complex environments while avoiding collisions and optimizing travel efficiency. This work addresses the limitations of existing approaches by combining Gaussian belief propagation with path integration and introducing a novel tracking factor to ensure strict adherence to global paths. The proposed method is tested with two different global path-planning approaches: rapidly exploring random trees and a structured planner, which leverages predefined lane structures to improve coordination. A simulation environment was developed to validate the proposed method across diverse scenarios, each posing unique challenges in navigation and communication. Simulation results demonstrate that the tracking factor reduces path deviation by 28% in single-agent and 16% in multi-agent scenarios, highlighting its effectiveness in improving multi-agent coordination, especially when combined with structured global planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20369v1</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jens H{\o}igaard Jensen, Kristoffer Plagborg Bak S{\o}rensen, Jonas le Fevre Sejersen, Andriy Sarabakha</dc:creator>
    </item>
    <item>
      <title>Leveraging Graph Neural Networks and Multi-Agent Reinforcement Learning for Inventory Control in Supply Chains</title>
      <link>https://arxiv.org/abs/2410.18631</link>
      <description>arXiv:2410.18631v2 Announce Type: replace 
Abstract: Inventory control in modern supply chains has attracted significant attention due to the increasing number of disruptive shocks and the challenges posed by complex dynamics, uncertainties, and limited collaboration. Traditional methods, which often rely on static parameters, struggle to adapt to changing environments. This paper proposes a Multi-Agent Reinforcement Learning (MARL) framework with Graph Neural Networks (GNNs) for state representation to address these limitations.
  Our approach redefines the action space by parameterizing heuristic inventory control policies, making it adaptive as the parameters dynamically adjust based on system conditions. By leveraging the inherent graph structure of supply chains, our framework enables agents to learn the system's topology, and we employ a centralized learning, decentralized execution scheme that allows agents to learn collaboratively while overcoming information-sharing constraints. Additionally, we incorporate global mean pooling and regularization techniques to enhance performance.
  We test the capabilities of our proposed approach on four different supply chain configurations and conduct a sensitivity analysis. This work paves the way for utilizing MARL-GNN frameworks to improve inventory management in complex, decentralized supply chain environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18631v2</guid>
      <category>cs.MA</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Niki Kotecha, Antonio del Rio Chanona</dc:creator>
    </item>
    <item>
      <title>ConvoyLLM: Dynamic Multi-Lane Convoy Control Using LLMs</title>
      <link>https://arxiv.org/abs/2502.17529</link>
      <description>arXiv:2502.17529v2 Announce Type: replace 
Abstract: This paper proposes a novel method for multi-lane convoy formation control that uses large language models (LLMs) to tackle coordination challenges in dynamic highway environments. Each connected and autonomous vehicle in the convoy uses a knowledge-driven approach to make real-time adaptive decisions based on various scenarios. Our method enables vehicles to dynamically perform tasks, including obstacle avoidance, convoy joining/leaving, and escort formation switching, all while maintaining the overall convoy structure. We design a Interlaced formation control strategy based on locally dynamic distributed graphs, ensuring the convoy remains stable and flexible. We conduct extensive experiments in the SUMO simulation platform across multiple traffic scenarios, and the results demonstrate that the proposed method is effective, robust, and adaptable to dynamic environments. The code is available at: https://github.com/chuduanfeng/ConvoyLLM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17529v2</guid>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liping Lu, Zhican He, Duanfeng Chu, Rukang Wang, Saiqian Peng, Pan Zhou</dc:creator>
    </item>
    <item>
      <title>Constrained Serial Dictatorships can be Fair</title>
      <link>https://arxiv.org/abs/2301.06086</link>
      <description>arXiv:2301.06086v2 Announce Type: replace-cross 
Abstract: When allocating indivisible items to agents, it is known that the only strategyproof mechanisms that satisfy a set of rather mild conditions are constrained serial dictatorships: given a fixed order over agents, at each step the designated agent chooses a given number of items (depending on her position in the sequence). Agents who come earlier in the sequence have a larger choice of items; however, this advantage can be compensated by a higher number of items received by those who come later. How to balance priority in the sequence and number of items received is a nontrivial question. We use a previous model, parameterized by a mapping from ranks to scores, a social welfare functional, and a distribution over preference profiles. For several meaningful choices of parameters, we show that the optimal sequence can be computed exactly in polynomial time or approximated using sampling. Our results hold for several probabilistic models on preference profiles, with an emphasis on the Plackett-Luce model. We conclude with experimental results showing how the optimal sequence is impacted by various parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.06086v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sylvain Bouveret, Hugo Gilbert, J\'er\^ome Lang, Guillaume M\'erou\'e</dc:creator>
    </item>
    <item>
      <title>Repeated and incontrovertible collective action failure leads to protester disengagement and radicalisation</title>
      <link>https://arxiv.org/abs/2408.12795</link>
      <description>arXiv:2408.12795v2 Announce Type: replace-cross 
Abstract: Protest is ubiquitous in the 21st Century and the people who participate in such movements do so because they seek to bring about social change. However, social change takes time and involves repeated interactions between individual protesters, social movements and the authorities to whom they appeal for change. These complexities of time and scale have frustrated efforts to isolate the conditions that foster an enduring movement, on the one hand, and the adoption of more radical (unconventional, unacceptable) tactics on the other. Here, we present a novel, theoretically informed and empirically evidenced, agent-based model of collective action that provides a unified framework to address these dual challenges. We model ~10,000 iterations within a simulated society and show that where an authority is responsive, and protesters can (cognitively and/or socially) contest the failure of their movement, a moderate conventional movement prevails. Conversely, where an authority repeatedly and incontrovertibly fails the movement, the population disengages but becomes radicalised (latent radicalism). This latter finding, whereby the whole population is disengaged but prepared to use radical methods to bring about social change, likely reflects the febrile pre-cursor state to sudden, revolutionary change. Results highlight the potential for simulations to reveal emergent, as-yet under-theorized, phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12795v2</guid>
      <category>cs.SI</category>
      <category>cs.MA</category>
      <category>physics.soc-ph</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emma F. Thomas, Mengbin Ye, Simon D. Angus, Tony J. Mathew, Winnifred Louis, Liam Walsh, Silas Ellery, Morgana Lizzio-Wilson, Craig McGarty</dc:creator>
    </item>
    <item>
      <title>Strategic Classification With Externalities</title>
      <link>https://arxiv.org/abs/2410.08032</link>
      <description>arXiv:2410.08032v2 Announce Type: replace-cross 
Abstract: We propose a new variant of the strategic classification problem: a principal reveals a classifier, and $n$ agents report their (possibly manipulated) features to be classified. Motivated by real-world applications, our model crucially allows the manipulation of one agent to affect another; that is, it explicitly captures inter-agent externalities. The principal-agent interactions are formally modeled as a Stackelberg game, with the resulting agent manipulation dynamics captured as a simultaneous game. We show that under certain assumptions, the pure Nash Equilibrium of this agent manipulation game is unique and can be efficiently computed. Leveraging this result, PAC learning guarantees are established for the learner: informally, we show that it is possible to learn classifiers that minimize loss on the distribution, even when a random number of agents are manipulating their way to a pure Nash Equilibrium. We also comment on the optimization of such classifiers through gradient-based approaches. This work sets the theoretical foundations for a more realistic analysis of classifiers that are robust against multiple strategic actors interacting in a common environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08032v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Safwan Hossain, Evi Micha, Yiling Chen, Ariel Procaccia</dc:creator>
    </item>
    <item>
      <title>ChatMotion: A Multimodal Multi-Agent for Human Motion Analysis</title>
      <link>https://arxiv.org/abs/2502.18180</link>
      <description>arXiv:2502.18180v2 Announce Type: replace-cross 
Abstract: Advancements in Multimodal Large Language Models (MLLMs) have improved human motion understanding. However, these models remain constrained by their "instruct-only" nature, lacking interactivity and adaptability for diverse analytical perspectives. To address these challenges, we introduce ChatMotion, a multimodal multi-agent framework for human motion analysis. ChatMotion dynamically interprets user intent, decomposes complex tasks into meta-tasks, and activates specialized function modules for motion comprehension. It integrates multiple specialized modules, such as the MotionCore, to analyze human motion from various perspectives. Extensive experiments demonstrate ChatMotion's precision, adaptability, and user engagement for human motion understanding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18180v2</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Li, Sen Jia, Jianhao Wang, Zhaochong An, Jiaang Li, Jenq-Neng Hwang, Serge Belongie</dc:creator>
    </item>
  </channel>
</rss>
