<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Jan 2026 02:38:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Global polynomial-time estimation in statistical nonlinear inverse problems via generalized stability</title>
      <link>https://arxiv.org/abs/2601.09007</link>
      <description>arXiv:2601.09007v1 Announce Type: new 
Abstract: Non-linear statistical inverse problems pose major challenges both for statistical analysis and computation. Likelihood-based estimators typically lead to non-convex and possibly multimodal optimization landscapes, and Markov chain Monte Carlo (MCMC) methods may mix exponentially slowly. We propose a class of computationally tractable estimators--plug-in and PDE-penalized M-estimators--for inverse problems defined through operator equations of the form $L_f u = g$, where $f$ is the unknown parameter and $u$ is the observed solution. The key idea is to replace the exact PDE constraint by a weakly enforced relaxation, yielding conditionally convex and, in many PDE examples, nested quadratic optimization problems that avoid evaluating the forward map $G(f)$ and do not require PDE solvers. For prototypical non-linear inverse problems arising from elliptic PDEs, including the Darcy flow model $L_f u = \nabla\!\cdot(f\nabla u)$ and a steady-state Schr\"odinger model, we prove that these estimators attain the best currently known statistical convergence rates while being globally computable in polynomial time. In the Darcy model, we obtain an explicit sub-quadratic $o(N^2)$ arithmetic runtime bound for estimating $f$ from $N$ noisy samples. Our analysis is based on new generalized stability estimates, extending classical stability beyond the range of the forward operator, combined with tools from nonparametric M-estimation. We also derive adaptive rates for the Darcy problem, providing a blueprint for designing provably polynomial-time statistical algorithms for a broad class of non-linear inverse problems. Our estimators also provide principled warm-start initializations for polynomial-time Bayesian computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09007v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sven Wang</dc:creator>
    </item>
    <item>
      <title>Stochastic representation of Sarmanov copulas</title>
      <link>https://arxiv.org/abs/2601.09016</link>
      <description>arXiv:2601.09016v1 Announce Type: new 
Abstract: Sarmanov copulas offer a simple and tractable way to build multivariate distributions by perturbing the independence copula. They admit closed-form expressions for densities and many functionals of interest, making them attractive for practical applications. However, the complex conditions on the dependence parameters to ensure that Sarmanov copulas are valid limit their application in high dimensions. Verifying the $d$-increasing property typically requires satisfying a combinatorial set of inequalities that makes direct construction difficult. To circumvent this issue, we develop a stochastic representation for bivariate Sarmanov copulas. We prove that every admissible Sarmanov can be realized as a mixture of independent univariate distributions indexed by a latent Bernoulli pair. The stochastic representation replaces the problem of verifying copula validity with the problem of ensuring nonnegativity of a Bernoulli probability mass function. The representation also recovers classical copula families, including Farlie--Gumbel--Morgenstern, Huang--Kotz, and Bairamov--Kotz--Bek\c{c}i as special cases. We further derive sharp global bounds for Spearman's rho and Kendall's tau. We then introduce a Bernoulli-mixing construction in higher dimensions, leading to a new class of multivariate Sarmanov copulas with easily verifiable parameter constraints and scalable simulation algorithms. Finally, we show that powered versions of bivariate Sarmanov copulas admit a similar stochastic representation through block-maximal order statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09016v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher Blier-Wong</dc:creator>
    </item>
    <item>
      <title>Statistical Guarantees for Data-driven Posterior Tempering</title>
      <link>https://arxiv.org/abs/2601.09122</link>
      <description>arXiv:2601.09122v1 Announce Type: new 
Abstract: Posterior tempering reduces the influence of the likelihood in the calculation of the posterior by raising the likelihood to a fractional power $\alpha$. The resulting power posterior - also known as an $\alpha$-posterior or fractional posterior - has been shown to exhibit appealing properties, including robustness to model misspecification and asymptotic normality (Bernstein-von Mises theorem). However, practical recommendations for selecting the tempering parameter and statistical guarantees for the resulting power posterior remain open questions. Cross-validation-based approaches to tuning this parameter suggest interesting asymptotic regimes for the selected $\alpha$, which can either vanish or behave like a mixture distribution with a point mass at infinity and the remaining mass converging to zero. We formalize the asymptotic properties of the power posterior in these regimes. In particular, we provide sufficient conditions for (i) consistency of the power posterior moments and (ii) asymptotic normality of the power posterior mean. Our analysis required us to establish a new Laplace approximation that is interesting in its own right and is the key technical tool for showing a critical threshold $\alpha\asymp 1/\sqrt{n}$ where the asymptotic normality of the posterior mean breaks. Our results allow for the power to depend on the data in an arbitrary way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09122v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruchira Ray, Marco Avella Medina, Cynthia Rush</dc:creator>
    </item>
    <item>
      <title>On the Kolmogorov Superposition Theorem and Regular Means</title>
      <link>https://arxiv.org/abs/2601.09659</link>
      <description>arXiv:2601.09659v1 Announce Type: new 
Abstract: While Kolmogorov's probability axioms are widely recognized, it is less well known that in an often-overlooked 1930 note, Kolmogorov proposed an axiomatic framework for a unifying concept of the mean -- referred to as regular means. This framework yields a well-defined functional form encompassing the arithmetic, geometric, and harmonic means, among others.
  In this article, we uncover an elegant connection between two key results of Kolmogorov by showing that the class of regular means can be derived directly from the Kolmogorov superposition theorem. This connection is conceptually appealing and illustrates that the superposition theorem deserves wider recognition in Statistics -- not only because of its link to regular means as shown here, but also due to its influence on the development of neural models and its potential connections with other statistical frameworks. In addition, we establish a stability property of regular means, showing that they vary smoothly under small perturbations of the generator. Finally, we provide insights into a recent universal central limit theorem that applies to the broad class of regular means.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09659v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Miguel de Carvalho</dc:creator>
    </item>
    <item>
      <title>Tail-Sensitive KL and R\'enyi Convergence of Unadjusted Hamiltonian Monte Carlo via One-Shot Couplings</title>
      <link>https://arxiv.org/abs/2601.09019</link>
      <description>arXiv:2601.09019v1 Announce Type: cross 
Abstract: Hamiltonian Monte Carlo (HMC) algorithms are among the most widely used sampling methods in high dimensional settings, yet their convergence properties are poorly understood in divergences that quantify relative density mismatch, such as Kullback-Leibler (KL) and R\'enyi divergences. These divergences naturally govern acceptance probabilities and warm-start requirements for Metropolis-adjusted Markov chains. In this work, we develop a framework for upgrading Wasserstein convergence guarantees for unadjusted Hamiltonian Monte Carlo (uHMC) to guarantees in tail-sensitive KL and R\'enyi divergences. Our approach is based on one-shot couplings, which we use to establish a regularization property of the uHMC transition kernel. This regularization allows Wasserstein-2 mixing-time and asymptotic bias bounds to be lifted to KL divergence, and analogous Orlicz-Wasserstein bounds to be lifted to R\'enyi divergence, paralleling earlier work of Bou-Rabee and Eberle (2023) that upgrade Wasserstein-1 bounds to total variation distance via kernel smoothing. As a consequence, our results provide quantitative control of relative density mismatch, clarify the role of discretization bias in strong divergences, and yield principled guarantees relevant both for unadjusted sampling and for generating warm starts for Metropolis-adjusted Markov chains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09019v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nawaf Bou-Rabee, Siddharth Mitra, Andre Wibisono</dc:creator>
    </item>
    <item>
      <title>From Hawkes Processes to Attention: Time-Modulated Mechanisms for Event Sequences</title>
      <link>https://arxiv.org/abs/2601.09220</link>
      <description>arXiv:2601.09220v1 Announce Type: cross 
Abstract: Marked Temporal Point Processes (MTPPs) arise naturally in medical, social, commercial, and financial domains. However, existing Transformer-based methods mostly inject temporal information only via positional encodings, relying on shared or parametric decay structures, which limits their ability to capture heterogeneous and type-specific temporal effects. Inspired by this observation, we derive a novel attention operator called Hawkes Attention from the multivariate Hawkes process theory for MTPP, using learnable per-type neural kernels to modulate query, key and value projections, thereby replacing the corresponding parts in the traditional attention. Benefited from the design, Hawkes Attention unifies event timing and content interaction, learning both the time-relevant behavior and type-specific excitation patterns from the data. The experimental results show that our method achieves better performance compared to the baselines. In addition to the general MTPP, our attention mechanism can also be easily applied to specific temporal structures, such as time series forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09220v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinzi Tan, Kejian Zhang, Junhan Yu, Doudou Zhou</dc:creator>
    </item>
    <item>
      <title>A Constructive Method to Minimize the Index of Coincidence under Marginal Constraints</title>
      <link>https://arxiv.org/abs/2601.09347</link>
      <description>arXiv:2601.09347v1 Announce Type: cross 
Abstract: We consider the problem of minimizing the index of coincidence of a joint distribution under fixed marginal constraints. This objective is motivated by several applications in information theory, where the index of coincidence naturally arises. A closed-form solution is known when the marginals satisfy a strong feasibility condition, but this condition is rarely met in practice. We first show that the measure of the set of marginals for which condition applies vanishes as the dimension grows. We then characterize the structure of the optimal coupling in the general case, proving that it exhibits a monotone staircase of zero entries. Based on this structure, we propose an explicit iterative construction and prove that it converges in finitely many steps to a minimizer. Main result of the paper is a complete constructive solution of index-of-coincidence minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09347v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Jean-Claude Robert Bertrand (AMU ECO)</dc:creator>
    </item>
    <item>
      <title>Extremal Quantiles under Two-Way Clustering</title>
      <link>https://arxiv.org/abs/2402.19268</link>
      <description>arXiv:2402.19268v3 Announce Type: replace 
Abstract: This paper studies extremal quantiles under two-way clustered dependence. We show that the limiting distribution of unconditional intermediate-order tail quantiles is Gaussian. This result is notable because two-way clustering typically leads to non-Gaussian limiting behavior. Remarkably, extremal quantiles remain asymptotically Gaussian even in degenerate cases. Building on this insight, we extend our analysis to extremal quantile regression at intermediate orders. Simulation results corroborate our theoretical findings. Finally, we provide an empirical application to growth-at-risk, showing that earlier empirical conclusions remain robust even after accounting for two-way clustered dependence in panel data and the focus on extreme quantiles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.19268v3</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.TH</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harold D. Chiang, Ryutah Kato, Yuya Sasaki</dc:creator>
    </item>
    <item>
      <title>Bayes linear estimator in the general linear model</title>
      <link>https://arxiv.org/abs/2506.21192</link>
      <description>arXiv:2506.21192v2 Announce Type: replace 
Abstract: The Bayes linear estimator is derived by minimizing the Bayes risk with respect to the squared loss function. Non-unbiased estimators such as ordinary ridge, typical shrinkage, fractional rank, and restricted least squares estimators, as well as classical linear unbiased estimators such as ordinary least squares and generalized least squares estimators, are either Bayes linear estimators or their limit points. In this paper, we discuss the statistical properties and optimality of Bayes linear estimators. First, we explore properties of Bayes linear estimators such as linear sufficiency and linear completeness. Second, we derive necessary and sufficient conditions under which two Bayes linear estimators coincide. In particular, several examples, including Rao's mixed-effects model and the general linear model with a spatial error process, demonstrate that our results can lead to a more efficient estimation procedure. Finally, we establish equivalence conditions for the equality of residual sums of squares when Bayes linear estimators are considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21192v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hirai Mukasa</dc:creator>
    </item>
    <item>
      <title>A Sieve M-Estimator for Entropic Optimal Transport</title>
      <link>https://arxiv.org/abs/2512.21981</link>
      <description>arXiv:2512.21981v4 Announce Type: replace 
Abstract: Entropically regularized optimal transport between probability measures supported on compact subsets of Euclidean space admits a representation as an information projection under moment inequality constraints. Exploiting this structure, I develop a sieve-based approximation of the Fenchel dual, yielding a sequence of finite-dimensional convex programs whose sample analogues provide tractable estimators of the regularized optimal value and associated dual optimizers. Under minimal assumptions--compact support and continuity of the cost function--I establish almost sure consistency of these estimators. I further derive finite-sample bounds for the estimation error of the optimal value, featuring only logarithmic dependence on sieve complexity, and obtain asymptotic stochastic bounds characterized by suprema of centered Gaussian processes. The results furnish general statistical guarantees for sieve-based estimation of entropic optimal transport and apply to settings not covered by existing theory for the empirical Sinkhorn divergence and other sieve-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21981v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rami V. Tabri</dc:creator>
    </item>
    <item>
      <title>Classification of real hyperplane singularities by real log canonical thresholds</title>
      <link>https://arxiv.org/abs/2411.13392</link>
      <description>arXiv:2411.13392v2 Announce Type: replace-cross 
Abstract: The log canonical threshold (lct) is a fundamental invariant in birational geometry, essential for understanding the complexity of singularities in algebraic varieties. Its real counterpart, the real log canonical threshold (rlct), also known as the learning coefficient, has become increasingly relevant in statistics and machine learning, where it plays a critical role in model selection and error estimation for singular statistical models. In this paper, we investigate the rlct and its multiplicity for real (not necessarily reduced) hyperplane arrangements. We derive explicit combinatorial formulas for these invariants, generalizing earlier results that were limited to specific examples. Moreover, we provide a general algebraic theory for real log canonical thresholds, and present a SageMath implementation for efficiently computing the rlct and its multiplicity in the case or real hyperplane arrangements. Applications to examples are given, illustrating how the formulas can also be used to analyze the asymptotic behavior of high-dimensional volume integrals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13392v2</guid>
      <category>math.AG</category>
      <category>math.AC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitra Kosta, Daniel Windisch</dc:creator>
    </item>
    <item>
      <title>Random Multiplexing</title>
      <link>https://arxiv.org/abs/2512.24087</link>
      <description>arXiv:2512.24087v2 Announce Type: replace-cross 
Abstract: As wireless communication applications evolve from traditional multipath environments to high-mobility scenarios like unmanned aerial vehicles, multiplexing techniques have advanced accordingly. Traditional single-carrier frequency-domain equalization (SC-FDE) and orthogonal frequency-division multiplexing (OFDM) have given way to emerging orthogonal time-frequency space (OTFS) and affine frequency-division multiplexing (AFDM). These approaches exploit specific channel structures to diagonalize or sparsify the effective channel, thereby enabling low-complexity detection. However, their reliance on these structures significantly limits their robustness in dynamic, real-world environments. To address these challenges, this paper studies a random multiplexing technique that is decoupled from the physical channels, enabling its application to arbitrary norm-bounded and spectrally convergent channel matrices. Random multiplexing achieves statistical fading-channel ergodicity for transmitted signals by constructing an equivalent input-isotropic channel matrix in the random transform domain. It guarantees the asymptotic replica MAP bit-error rate (BER) optimality of AMP-type detectors for linear systems with arbitrary norm-bounded, spectrally convergent channel matrices and signaling configurations, under the unique fixed point assumption. A low-complexity cross-domain memory AMP (CD-MAMP) detector is considered, leveraging the sparsity of the time-domain channel and the randomness of the equivalent channel. Optimal power allocations are derived to minimize the replica MAP BER and maximize the replica constrained capacity of random multiplexing systems. The optimal coding principle and replica constrained-capacity optimality of CD-MAMP detector are investigated for random multiplexing systems. Additionally, the versatility of random multiplexing in diverse wireless applications is explored.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24087v2</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Liu, Yuhao Chi, Shunqi Huang, Zhaoyang Zhang</dc:creator>
    </item>
  </channel>
</rss>
