<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Sep 2025 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>BiND: A Neural Discriminator-Decoder for Accurate Bimanual Trajectory Prediction in Brain-Computer Interfaces</title>
      <link>https://arxiv.org/abs/2509.03521</link>
      <description>arXiv:2509.03521v1 Announce Type: new 
Abstract: Decoding bimanual hand movements from intracortical recordings remains a critical challenge for brain-computer interfaces (BCIs), due to overlapping neural representations and nonlinear interlimb interactions. We introduce BiND (Bimanual Neural Discriminator-Decoder), a two-stage model that first classifies motion type (unimanual left, unimanual right, or bimanual) and then uses specialized GRU-based decoders, augmented with a trial-relative time index, to predict continuous 2D hand velocities. We benchmark BiND against six state-of-the-art models (SVR, XGBoost, FNN, CNN, Transformer, GRU) on a publicly available 13-session intracortical dataset from a tetraplegic patient. BiND achieves a mean $R^2$ of 0.76 ($\pm$0.01) for unimanual and 0.69 ($\pm$0.03) for bimanual trajectory prediction, surpassing the next-best model (GRU) by 2% in both tasks. It also demonstrates greater robustness to session variability than all other benchmarked models, with accuracy improvements of up to 4% compared to GRU in cross-session analyses. This highlights the effectiveness of task-aware discrimination and temporal modeling in enhancing bimanual decoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03521v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Timothee Robert, MohammadAli Shaeri, Mahsa Shoaran</dc:creator>
    </item>
    <item>
      <title>An analog-electronic implementation of a harmonic oscillator recurrent neural network</title>
      <link>https://arxiv.org/abs/2509.04064</link>
      <description>arXiv:2509.04064v1 Announce Type: new 
Abstract: Oscillatory recurrent networks, such as the Harmonic Oscillator Recurrent Network (HORN) model, offer advantages in parameter efficiency, learning speed, and robustness relative to traditional non-oscillating architectures. Yet, while many implementations of physical neural networks exploiting attractor dynamics have been studied, implementations of oscillatory models in analog-electronic hardware that utilize the networks' transient dynamics so far are lacking. This study explores the feasibility of implementing HORNs in analog-electronic hardware while maintaining the computational performance of the digital counterpart. Using a digital twin approach, we trained a four-node HORN in silico for sequential MNIST classification and transferred the trained parameters to an analog electronic implementation. A set of custom error metrics indicated that the analog system is able to successfully replicate the dynamics of the digital model in most test cases. However, despite the overall well-matching dynamics, when using the readout layer of the digital model on the data generated by the analog system, we only observed $28.39\%$ agreement with the predictions of the digital model. An analysis shows that this mismatch is due to a precision difference between the analog hardware and the floating-point representation exploited by the digital model to perform classification tasks. When the analog system was utilized as a reservoir with a re-trained linear readout, its classification performance could be recovered to that of the digital twin, indicating preserved information content within the analog dynamics. This proof-of-concept establishes that analog electronic circuits can effectively implement oscillatory neural networks for computation, providing a demonstration of energy-efficient analog systems that exploit brain-inspired transient dynamics for computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04064v1</guid>
      <category>q-bio.NC</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Carvalho, Bernd Ulmann, Wolf Singer, Felix Effenberger</dc:creator>
    </item>
    <item>
      <title>Optimal rate-variance coding due to firing threshold adaptation near criticality</title>
      <link>https://arxiv.org/abs/2509.04106</link>
      <description>arXiv:2509.04106v1 Announce Type: new 
Abstract: Recurrently connected neuron populations play key roles in sensory perception and memory storage across various brain regions. While these populations are often assumed to encode information through firing rates, this method becomes unreliable with weak stimuli. We propose that in such cases, information can be transmitted via spatial spike patterns, employing a sparse or combinatorial coding based on firing rate variance. Around the critical point of a stochastic recurrent excitable network, we uncover a synergistic dual-coding scheme, enabled by single-cell threshold adaptation. This scheme optimizes variance coding for weak signals without compromising rate coding for stronger inputs, thus maximizing input/output mutual information. These optimizations are robust across adaptation rules and coupling strengths through self-suppression of internal noise, particularly around the network's phase transition, and are linked to threshold recovery times observed in hippocampal memory circuits (~$10^2$-$10^3$ms). In contrast, nonadaptive networks perform similarly only at criticality, suggesting that threshold adaptation is essential for reliable encoding of weak signals into diverse spatial patterns. Our results imply a fundamental role for near-critical latent adaptive dynamics enabled by dual coding in biological and artificial neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04106v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>nlin.AO</category>
      <category>physics.bio-ph</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mauricio Girardi-Schappo, Leonard Maler, Andr\'e Longtin</dc:creator>
    </item>
    <item>
      <title>Geometric origin of adversarial vulnerability in deep learning</title>
      <link>https://arxiv.org/abs/2509.01235</link>
      <description>arXiv:2509.01235v1 Announce Type: cross 
Abstract: How to balance training accuracy and adversarial robustness has become a challenge since the birth of deep learning. Here, we introduce a geometry-aware deep learning framework that leverages layer-wise local training to sculpt the internal representations of deep neural networks. This framework promotes intra-class compactness and inter-class separation in feature space, leading to manifold smoothness and adversarial robustness against white or black box attacks. The performance can be explained by an energy model with Hebbian coupling between elements of the hidden representation. Our results thus shed light on the physics of learning in the direction of alignment between biological and artificial intelligence systems. Using the current framework, the deep network can assimilate new information into existing knowledge structures while reducing representation interference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01235v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.stat-mech</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yixiong Ren, Wenkang Du, Jianhui Zhou, Haiping Huang</dc:creator>
    </item>
    <item>
      <title>Language Models Do Not Have Human-Like Working Memory</title>
      <link>https://arxiv.org/abs/2505.10571</link>
      <description>arXiv:2505.10571v2 Announce Type: replace 
Abstract: While Large Language Models (LLMs) exhibit remarkable reasoning abilities, we demonstrate that they fundamentally lack a core aspect of human cognition: working memory. Human working memory is an active cognitive system that enables not only the temporary storage of information but also its processing and utilization. Without working memory, individuals may produce unreal conversations, exhibit self-contradiction, and struggle with tasks requiring mental reasoning. Existing evaluations using N-back or context-dependent tasks fail as they allow LLMs to exploit accessible context rather than retain latent information. We introduce three novel tasks, (1) Number Guessing, (2) Yes-No Deduction, and Math Magic, that isolate internal representation from external context. Across seventeen frontier models spanning four major model families, we consistently observe irrational or contradictory behaviors, highlighting LLMs' inability to retain and manipulate latent information. Our work establishes a new benchmark for evaluating working memory in LLMs and identifies this deficit as a critical obstacle to artificial general intelligence. Code and prompts for the experiments are available at https://github.com/penguinnnnn/LLM-Working-Memory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10571v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jen-tse Huang, Kaiser Sun, Wenxuan Wang, Mark Dredze</dc:creator>
    </item>
    <item>
      <title>Data-driven mean-field within whole-brain models</title>
      <link>https://arxiv.org/abs/2509.02799</link>
      <description>arXiv:2509.02799v2 Announce Type: replace 
Abstract: Mean-field models provide a link between microscopic neuronal activity and macroscopic brain dynamics. Their derivation depends on simplifying assumptions, such as all-to-all connectivity, limiting their biological realism. To overcome this, we introduce a data-driven framework in which a multi-layer perceptron (MLP) learns the macroscopic dynamics directly from simulations of a network of spiking neurons. The network connection probability serves here as a new parameter, inaccessible to purely analytical treatment, which is validated against ground truth analytical solutions. Through bifurcation analysis on the trained MLP, we demonstrate the existence of new cusp bifurcation that systematically reshapes the system's phase diagram in a degenerate manner with synaptic coupling. By integrating this data-driven mean-field model into a whole-brain computational framework, we show that it extends beyond the macroscopic emergent dynamics generated by the analytical model. For validation, we use simulation-based inference on synthetic functional magnetic resonance imaging (fMRI) data and demonstrate accurate parameter recovery for the novel mean-field model, while the current state-of-the-art models lead to biased estimates. This work presents a flexible and generic framework for building more realistic whole-brain models, bridging the gap between microscale mechanisms and macroscopic brain recordings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02799v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Martin Breyton, Viktor Sip, Marmaduke Woodman, Meysam Hashemi, Spase Petkoski, Viktor Jirsa</dc:creator>
    </item>
  </channel>
</rss>
