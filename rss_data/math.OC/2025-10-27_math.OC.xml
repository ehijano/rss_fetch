<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 Oct 2025 16:08:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Convex Optimization Approach to the Discrete Hanging Chain Problem</title>
      <link>https://arxiv.org/abs/2510.20917</link>
      <description>arXiv:2510.20917v1 Announce Type: new 
Abstract: In this paper we investigate the discrete version of the classical hanging chain problem. We generalize the problem, by allowing for arbitrary mass and length of each link. We show that the shape of the chain can be obtained by solving a convex optimization problem. Then we use optimality conditions to show that the problem can be further reduced to solving a single non-linear equation, when the links of the chain have symmetric mass and length.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20917v1</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Russell Gabrys, Stefan Sremac</dc:creator>
    </item>
    <item>
      <title>MOCVXPY: a CVXPY extension for multiobjective optimization</title>
      <link>https://arxiv.org/abs/2510.21010</link>
      <description>arXiv:2510.21010v1 Announce Type: new 
Abstract: MOCVXPY is an open-source Python library for convex vector optimization. It is built on top of CVXPY, a domain-specific language for single-objective convex optimization. MOCVXPY enables practitioners to describe their convex vector optimization problem in an intuitive algebraic language, that closely follows the mathematical formulation. This work presents the main features of MOCVXPY, explains some background of the algorithms it employs to solve the optimization problems, and illustrates its functionality through examples and two real-world applications in finance and energy. MOCVXPY is available at https://github.com/salomonl/mocvxpy under the Apache 2.0 licence, with some documentation and examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21010v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ludovic Salomon, Daniel D\"orfler, Andreas L\"ohne</dc:creator>
    </item>
    <item>
      <title>Iso-Riemannian Optimization on Learned Data Manifolds</title>
      <link>https://arxiv.org/abs/2510.21033</link>
      <description>arXiv:2510.21033v1 Announce Type: new 
Abstract: High-dimensional data that exhibit an intrinsic low-dimensional structure are ubiquitous in machine learning and data science. While various approaches allow for learning the corresponding data manifold from finite samples, performing downstream tasks such as optimization directly on these learned manifolds presents a significant challenge. This work introduces a principled framework for optimization on learned data manifolds using iso-Riemannian geometry. Our approach addresses key limitations of classical Riemannian optimization in this setting, specifically, that the Levi-Civita connection fails to yield constant-speed geodesics, and that geodesic convexity assumptions break down under the learned pullback constructions commonly used in practice. To overcome these challenges, we propose new notions of monotonicity and Lipschitz continuity tailored to the iso-Riemannian setting and propose iso-Riemannian descent algorithms for which we provide a detailed convergence analysis. We demonstrate the practical effectiveness of those algorithms on both synthetic and real datasets, including MNIST under a learned pullback structure. Our approach yields interpretable barycentres, improved clustering, and provably efficient solutions to inverse problems, even in high-dimensional settings. These results establish that optimization under iso-Riemannian geometry can overcome distortions inherent to learned manifold mappings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21033v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.DG</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Willem Diepeveen, Melanie Weber</dc:creator>
    </item>
    <item>
      <title>Reliability-Aware Control of Distributed Energy Resources using Multi-Source Data Models</title>
      <link>https://arxiv.org/abs/2510.21062</link>
      <description>arXiv:2510.21062v1 Announce Type: new 
Abstract: Distributed energy resources offer a control-based option to improve distribution system reliability by ensuring system states that positively impact component failure rates. This option is an attractive complement to otherwise costly and lengthy physical infrastructure upgrades. However, required models that adequately map operational decisions and environmental conditions to system failure risk are lacking because of data unavailability and the fact that distribution system failures remain rare events. This paper addresses this gap and proposes a multi-source data model that consistently maps comprehensive weather and system state information to component failure rates. To manage collinearity in the available features, we propose two ensemble tree-based models that systematically identify the most influential features and reduce the dataset's dimensionality based on each feature's impact on failure rate estimates. These estimates are embedded within a sequential, non-convex optimization procedure, that dynamically updates operational control decisions. We perform a numerical experiment to demonstrate the cost and reliability benefits that can be achieved through this reliability-aware control approach and to analyze the properties of each proposed estimation model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21062v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gejia Zhang, Robert Mieth</dc:creator>
    </item>
    <item>
      <title>Complexity of Bilevel Linear Programming with a Single Upper-Level Variable</title>
      <link>https://arxiv.org/abs/2510.21126</link>
      <description>arXiv:2510.21126v1 Announce Type: new 
Abstract: Bilevel linear programming (LP) is one of the simplest classes of bilevel optimization problems, yet it is known to be NP-hard in general. Specifically, determining whether the optimal objective value of a bilevel LP is at least as good as a given threshold, a standard decision version of the problem, is NP-complete. However, this decision problem becomes tractable when either the number of lower-level variables or the number of lower-level constraints is fixed, which prompts the question: What if restrictions are placed on the upper-level problem? In this paper, we address this gap by showing that the decision version of bilevel LP remains NP-complete even when there is only a single upper-level variable, no upper-level constraints (apart from the constraint enforcing optimality of the lower-level decision) and all variables are bounded between 0 and 1. This result implies that fixing the number of variables or constraints in the upper-level problem alone does not lead to tractability in general. On the positive side, we show that there is a polynomial-time algorithm that finds a local optimal solution of such a rational bilevel LP instance. We also demonstrate that many combinatorial optimization problems, such as the knapsack problem and the traveling salesman problem, can be written as such a bilevel LP instance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21126v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nagisa Sugishita, Margarida Carvalho</dc:creator>
    </item>
    <item>
      <title>Linear-Quadratic Non-zero Sum Differential Game with Asymmetric Delayed Information</title>
      <link>https://arxiv.org/abs/2510.21152</link>
      <description>arXiv:2510.21152v1 Announce Type: new 
Abstract: This paper is concerned with a linear-quadratic non-zero sum differential game with asymmetric delayed information. To be specific, two players exist time delays simultaneously which are different, leading the dynamical system being an asymmetric information structure. By virtue of stochastic maximum principle, the stochastic Hamiltonian system is given which is a delayed forward-backward stochastic differential equation. Utilizing discretisation approach and backward iteration technique, we establish the relationship between forward and backward processes under asymmetric delayed information structure and obtain the state-estimate feedback Nash equilibrium of our problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21152v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yuxin Ye, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>Near Optimality of Discrete-Time Approximations for Controlled McKean-Vlasov Diffusions and Interacting Particle Systems</title>
      <link>https://arxiv.org/abs/2510.21208</link>
      <description>arXiv:2510.21208v1 Announce Type: new 
Abstract: We study stochastic optimal control problems for (possibly degenerate) McKean-Vlasov controlled diffusions and obtain discrete-time as well as finite interacting particle approximations. (i) Under mild assumptions, we first prove the existence of optimal relaxed controls by endowing the space of relaxed policies with a compact weak topology. (ii) Establishing continuity of the cost in control policy, we establish near-optimality of piecewise-constant strict policies, show that the discrete-time value functions (finite-horizon and discounted infinite-horizon) converge to their continuous-time counterparts as the timestep converges to zero, and that optimal discrete-time policies are near-optimal for the original continuous-time problem, where rates of convergence are also obtained. (iii) We then extend these approximation and near-optimality results to $N$-particle interacting systems under centralized or decentralized mean-field sharing information structure, proving that the discrete-time McKean-Vlasov policy is asymptotically optimal as $N\to \infty$ and the time step goes to zero. We thus develop an approximation of McKean-Vlasov optimal control problems via discrete-time McKean-Vlasov control problems (and associated numerical methods such as finite model approximation), and also show the near optimality of such approximate policy solutions for the $N$-agent interacting models under centralized and decentralized control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21208v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Somnath Pradhan, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>Time-varying Gaussian Process Bandit Optimization with Experts: no-regret in logarithmically-many side queries</title>
      <link>https://arxiv.org/abs/2510.21274</link>
      <description>arXiv:2510.21274v1 Announce Type: new 
Abstract: We study a time-varying Bayesian optimization problem with bandit feedback, where the reward function belongs to a Reproducing Kernel Hilbert Space (RKHS). We approach the problem via an upper-confidence bound Gaussian Process algorithm, which has been proven to yield no-regret in the stationary case.
  The time-varying case is more challenging and no-regret results are out of reach in general in the standard setting. As such, we instead tackle the question of how many additional observations asked to an expert are required to regain a no-regret property. To do so, we formulate the presence of past observation via an uncertainty injection procedure, and we reframe the problem as a heteroscedastic Gaussian Process regression. In addition, to achieve a no-regret result, we discard long outdated observations and replace them with updated (possibly very noisy) ones obtained by asking queries to an external expert. By leveraging and extending sparse inference to the heteroscedastic case, we are able to secure a no-regret result in a challenging time-varying setting with only logarithmically-many side queries per time step. Our method demonstrates that minimal additional information suffices to counteract temporal drift, ensuring efficient optimization despite time variation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21274v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Eliabelle Mauduit, Elo\"ise Berthier, Andrea Simonetto</dc:creator>
    </item>
    <item>
      <title>Binno: A 1st-order method for Bi-level Nonconvex Nonsmooth Optimization for Matrix Factorizations</title>
      <link>https://arxiv.org/abs/2510.21390</link>
      <description>arXiv:2510.21390v1 Announce Type: new 
Abstract: In this work, we develop a method for nonconvex, nonsmooth bi-level optimization and we introduce Binno, a first order method that leverages proximal constructions together with carefully designed descent conditions and variational analysis. Within this framework, Binno provably enforces a descent property for the overall objective surrogate associated with the bi-level problem. Each iteration performs blockwise proximal-gradient updates for the upper and the lower problems separately and then forms a calibrated, block-diagonal convex combination of the two tentative iterates. A linesearch selects the combination weights to enforce simultaneous descent of both level-wise objectives, and we establish conditions guaranteeing the existence of such weights together with descent directions induced by the associated proximal-gradient maps. We also apply Binno in the context of sparse low-rank factorization, where the upper level uses elementwise $\ell_1$ penalties and the lower level uses nuclear norms, coupled via a Frobenius data term. We test Binno on synthetic matrix and a real traffic-video dataset, attaining lower relative reconstruction error and higher peak signal-to-noise ratio than some standard methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21390v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laura Selicato, Flavia Esposito, Andersen Ang</dc:creator>
    </item>
    <item>
      <title>Optimal policies for environmental assets under spatial heterogeneity and global awareness</title>
      <link>https://arxiv.org/abs/2510.21397</link>
      <description>arXiv:2510.21397v1 Announce Type: new 
Abstract: The aim of this paper is to formulate and study a stochastic model for the management of environmental assets in a geographical context where in each place the local authorities take their policy decisions maximizing their own welfare, hence not cooperating each other. A key feature of our model is that the welfare depends not only on the local environmental asset, but also on the global one, making the problem much more interesting but technically much more complex to study, since strategic interaction among players arise.
  We study the problem first from the $N$-players game perspective and find open and closed loop Nash equilibria in explicit form. We also study the convergence of the $N$-players game (when $n\to +\infty$) to a suitable Mean Field Game whose unique equilibrium is exactly the limit of both the open and closed loop Nash equilibria found above, hence supporting their meaning for the game. Then we solve explicitly the problem from the cooperative perspective of the social planner and compare its solution to the equilibria of the $N$-players game. Moreover we find the Pigouvian tax which aligns the decentralized closed loop equilibrium to the social optimum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21397v1</guid>
      <category>math.OC</category>
      <category>econ.TH</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emmanuelle Augeraud-V\'eron, Daria Ghilli, Fausto Gozzi, Marta Leocata</dc:creator>
    </item>
    <item>
      <title>Robust Regret Control with Uncertainty-Dependent Baseline</title>
      <link>https://arxiv.org/abs/2510.21415</link>
      <description>arXiv:2510.21415v1 Announce Type: new 
Abstract: This paper proposes a robust regret control framework in which the performance baseline adapts to the realization of system uncertainty. The plant is modeled as a discrete-time, uncertain linear time-invariant system with real-parametric uncertainty. The performance baseline is the optimal non-causal controller constructed with full knowledge of the disturbance and the specific realization of the uncertain plant. We show that a controller achieves robust additive regret relative to this baseline if and only if it satisfies a related, robust $H_\infty$ performance condition on a modified plant. One technical issue is that the modified plant can, in general, have a complicated nonlinear dependence on the uncertainty. We use a linear approximation step so that the robust additive regret condition can be recast as a standard $\mu$-synthesis problem. A numerical example is used to demonstrate the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21415v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jietian Liu, Peter Seiler</dc:creator>
    </item>
    <item>
      <title>Plugging Weight-tying Nonnegative Neural Network into Proximal Splitting Method: Architecture for Guaranteeing Convergence to Optimal Point</title>
      <link>https://arxiv.org/abs/2510.21421</link>
      <description>arXiv:2510.21421v1 Announce Type: new 
Abstract: We propose a novel multi-layer neural network architecture that gives a promising neural network empowered optimization approach to the image restoration problem. The proposed architecture is motivated by the recent study of monotone Lipschitz-gradient (MoL-Grad) denoiser (Yukawa and Yamada, 2025) which establishes an ``explainable'' plug-and-play (PnP) framework in the sense of disclosing the objective minimized. The architecture is derived from the gradient of a superposition of functions associated with each layer, having the weights in the encoder and decoder tied with each other. Convexity of the potential, and thus monotonicity of its gradient (denoiser), is ensured by restricting ourselves to nonnegative weights. Unlike the previous PnP approaches with theoretical guarantees, the denoiser is free from constraints on the Lipschitz constant of the denoiser. Our PnP algorithm employing the weight-tying nonnegative neural network converges to a minimizer of the objective involving an ``implicit'' weakly convex regularizer induced by the denoiser. The convergence analysis relies on an efficient technique to preserve the overall convexity even in the ill-conditioned case where the loss function is not strongly convex. The simulation study shows the advantages of the Lipschitz-constraint-free nature of the proposed denoiser in training time as well as deblurring performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21421v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Haruya Shimizu, Masahiro Yukawa</dc:creator>
    </item>
    <item>
      <title>Finite-Time Analysis of Stochastic Nonconvex Nonsmooth Optimization on the Riemannian Manifolds</title>
      <link>https://arxiv.org/abs/2510.21468</link>
      <description>arXiv:2510.21468v1 Announce Type: new 
Abstract: This work addresses the finite-time analysis of nonsmooth nonconvex stochastic optimization under Riemannian manifold constraints. We adapt the notion of Goldstein stationarity to the Riemannian setting as a performance metric for nonsmooth optimization on manifolds. We then propose a Riemannian Online to NonConvex (RO2NC) algorithm, for which we establish the sample complexity of $O(\epsilon^{-3}\delta^{-1})$ in finding $(\delta,\epsilon)$-stationary points. This result is the first-ever finite-time guarantee for fully nonsmooth, nonconvex optimization on manifolds and matches the optimal complexity in the Euclidean setting. When gradient information is unavailable, we develop a zeroth order version of RO2NC algorithm (ZO-RO2NC), for which we establish the same sample complexity. The numerical results support the theory and demonstrate the practical effectiveness of the algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21468v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emre Sahinoglu, Youbang Sun, Shahin Shahrampour</dc:creator>
    </item>
    <item>
      <title>Analysis and Synthesis of Switched Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2510.21490</link>
      <description>arXiv:2510.21490v1 Announce Type: new 
Abstract: Deployment of optimization algorithms on networked systems face challenges associated with time delays and corruptions. One particular instance is the presence of time-varying delays arising from factors such as packet drops and irregular sampling. Fixed time delays can destabilize gradient descent algorithms, and this degradation is exacerbated by time-varying delays. This work concentrates on the analysis and creation of discrete-time optimization algorithms with certified exponential convergence rates that are robust against switched uncertainties between the optimizer and the gradient oracle. These optimization algorithms are implemented by a switch-scheduled output feedback controllers. Rate variation and sawtooth behavior (packet drops) in time-varying delays can be imposed through constraining switching sequences. Analysis is accomplished by bisection in the convergence rate to find Zames-Falb filter coefficents. Synthesis is performed by alternating between a filter coefficient search for a fixed controller, and a controller search for fixed multipliers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21490v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jared Miller, Fabian Jakob, Carsten Scherer, Andrea Iannelli</dc:creator>
    </item>
    <item>
      <title>Multilevel Picard scheme for solving high-dimensional drift control problems with state constraints</title>
      <link>https://arxiv.org/abs/2510.21607</link>
      <description>arXiv:2510.21607v1 Announce Type: new 
Abstract: Motivated by applications to the dynamic control of queueing networks, we develop a simulation-based scheme, the so-called multilevel Picard (MLP) approximation, for solving high-dimensional drift control problems whose states are constrained to stay within the nonnegative orthant, over a finite time horizon. We prove that under suitable conditions, the MLP approximation overcomes the curse of dimensionality in the following sense: To approximate the value function and its gradient evaluated at a given time and state to within a prescribed accuracy $\varepsilon$, the computational complexity grows at most polynomially in the problem dimension $d$ and $1/\varepsilon$. To illustrate the effectiveness of the scheme, we carry out numerical experiments for a class of test problems that are related to the dynamic scheduling problem of parallel server systems in heavy traffic, and demonstrate that the scheme is computationally feasible up to dimension at least $20$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21607v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuan Zhong</dc:creator>
    </item>
    <item>
      <title>A Practical Adaptive Subgame Perfect Gradient Method</title>
      <link>https://arxiv.org/abs/2510.21617</link>
      <description>arXiv:2510.21617v1 Announce Type: new 
Abstract: We present a performant gradient method for smooth convex optimization, drawing inspiration from several recent advances in the field. Our algorithm, the Adaptive Subgame Perfect Gradient Method (ASPGM) is based on the notion of subgame perfection, attaining a dynamic strengthening of minimax optimality. At each iteration, ASPGM makes a momentum-type update, optimized dynamically based on a (limited) memory/bundle of past first-order information. ASPGM is linesearch-free, parameter-free, and adaptive due to its use of recently developed auto-conditioning, restarting, and preconditioning ideas. We show that ASPGM is competitive with state-of-the-art L-BFGS methods on a wide range of smooth convex problems. Unlike quasi-Newton methods, however, our core algorithm underlying ASPGM has strong, subgame perfect, non-asymptotic guarantees, providing certificates of solution quality, resulting in simple stopping criteria and restarting conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21617v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alan Luner, Benjamin Grimmer</dc:creator>
    </item>
    <item>
      <title>Goal-based portfolio selection with fixed transaction costs</title>
      <link>https://arxiv.org/abs/2510.21650</link>
      <description>arXiv:2510.21650v1 Announce Type: new 
Abstract: We study a goal-based portfolio selection problem in which an investor aims to meet multiple financial goals, each with a specific deadline and target amount. Trading the stock incurs a strictly positive transaction cost. Using the stochastic Perron's method, we show that the value function is the unique viscosity solution to a system of quasi-variational inequalities. The existence of an optimal trading strategy and goal funding scheme is established. Numerical results reveal complex optimal trading regions and show that the optimal investment strategy differs substantially from the V-shaped strategy observed in the frictionless case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21650v1</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <category>q-fin.PM</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Bingyan Han, Jingjie Zhang</dc:creator>
    </item>
    <item>
      <title>Advanced Cutting-Plane Algorithms for ACOPF</title>
      <link>https://arxiv.org/abs/2510.21698</link>
      <description>arXiv:2510.21698v1 Announce Type: new 
Abstract: We propose a disciplined, numerically stable, and scalable approach to SDP relaxations of the ACOPF problem based on linear cutting-planes. Our method can be warm-started and, owing to its linear nature, enables the computation of tight and accurate bounds for large-scale multi-period relaxations -- well beyond what nonlinear convex solvers can achieve. Preliminary experiments show promising results when benchmarked against state-of-the-art bounds on PGLIB instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21698v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Bienstock, Matias Villagra</dc:creator>
    </item>
    <item>
      <title>Kernel Learning with Adversarial Features: Numerical Efficiency and Adaptive Regularization</title>
      <link>https://arxiv.org/abs/2510.20883</link>
      <description>arXiv:2510.20883v1 Announce Type: cross 
Abstract: Adversarial training has emerged as a key technique to enhance model robustness against adversarial input perturbations. Many of the existing methods rely on computationally expensive min-max problems that limit their application in practice. We propose a novel formulation of adversarial training in reproducing kernel Hilbert spaces, shifting from input to feature-space perturbations. This reformulation enables the exact solution of inner maximization and efficient optimization. It also provides a regularized estimator that naturally adapts to the noise level and the smoothness of the underlying function. We establish conditions under which the feature-perturbed formulation is a relaxation of the original problem and propose an efficient optimization algorithm based on iterative kernel ridge regression. We provide generalization bounds that help to understand the properties of the method. We also extend the formulation to multiple kernel learning. Empirical evaluation shows good performance in both clean and adversarial settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20883v1</guid>
      <category>stat.ML</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ant\^onio H. Ribeiro, David V\"avinggren, Dave Zachariah, Thomas B. Sch\"on, Francis Bach</dc:creator>
    </item>
    <item>
      <title>Neural Collapse under Gradient Flow on Shallow ReLU Networks for Orthogonally Separable Data</title>
      <link>https://arxiv.org/abs/2510.21078</link>
      <description>arXiv:2510.21078v1 Announce Type: cross 
Abstract: Among many mysteries behind the success of deep networks lies the exceptional discriminative power of their learned representations as manifested by the intriguing Neural Collapse (NC) phenomenon, where simple feature structures emerge at the last layer of a trained neural network. Prior works on the theoretical understandings of NC have focused on analyzing the optimization landscape of matrix-factorization-like problems by considering the last-layer features as unconstrained free optimization variables and showing that their global minima exhibit NC. In this paper, we show that gradient flow on a two-layer ReLU network for classifying orthogonally separable data provably exhibits NC, thereby advancing prior results in two ways: First, we relax the assumption of unconstrained features, showing the effect of data structure and nonlinear activations on NC characterizations. Second, we reveal the role of the implicit bias of the training dynamics in facilitating the emergence of NC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21078v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hancheng Min, Zhihui Zhu, Ren\'e Vidal</dc:creator>
    </item>
    <item>
      <title>Convergence of Stochastic Gradient Langevin Dynamics in the Lazy Training Regime</title>
      <link>https://arxiv.org/abs/2510.21245</link>
      <description>arXiv:2510.21245v1 Announce Type: cross 
Abstract: Continuous-time models provide important insights into the training dynamics of optimization algorithms in deep learning. In this work, we establish a non-asymptotic convergence analysis of stochastic gradient Langevin dynamics (SGLD), which is an It\^o stochastic differential equation (SDE) approximation of stochastic gradient descent in continuous time, in the lazy training regime. We show that, under regularity conditions on the Hessian of the loss function, SGLD with multiplicative and state-dependent noise (i) yields a non-degenerate kernel throughout the training process with high probability, and (ii) achieves exponential convergence to the empirical risk minimizer in expectation, and we establish finite-time and finite-width bounds on the optimality gap. We corroborate our theoretical findings with numerical examples in the regression setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21245v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noah Oberweis, Semih Cayci</dc:creator>
    </item>
    <item>
      <title>Smoothing inequalities for transport metrics in compact spaces</title>
      <link>https://arxiv.org/abs/2510.21380</link>
      <description>arXiv:2510.21380v1 Announce Type: cross 
Abstract: We prove general upper estimates for the distance between two Borel probability measures in Wasserstein metric in terms of the Fourier transforms of the measures. We work in compact manifolds including the torus, the Euclidean unit sphere, compact Lie groups and compact homogeneous spaces, and treat the Wasserstein metric $W_p$ in the full range $1 \le p \le \infty$ for the first time. The proofs are based on a comparison between the Wasserstein metric and a dual Sobolev norm, Riesz transform estimates and Hausdorff--Young inequalities on compact manifolds. As an application, we show that spherical designs are optimally close to the uniform measure on the sphere in Wasserstein metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21380v1</guid>
      <category>math.CA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bence Borda, Jean-Claude Cuenin</dc:creator>
    </item>
    <item>
      <title>Quantum Similarity-Driven QUBO Framework for Multi-Period Supply Chain Allocation using Time-Multiplexed Coherent Ising Machines and Simulated Quantum Annealing</title>
      <link>https://arxiv.org/abs/2510.21544</link>
      <description>arXiv:2510.21544v1 Announce Type: cross 
Abstract: Multi-period stock-keeping unit (SKU) allocation in supply chains is a combinatorial optimization problem that is both NP-hard and operationally critical, requiring simultaneous attention to profitability, feasibility, and diversity. Quadratic unconstrained binary optimization (QUBO) provides a principled framework for such tasks, yet prior studies often rely on simplified assumptions or omit real operational constraints.
  This work proposes a hybrid QUBO framework integrating three advances: (i) a quantum-derived similarity kernel, obtained from a variational RX embedding, to discourage redundant SKU selections; (ii) exact per-period capacity enforcement via slack-bit encoding to maintain feasibility; and (iii) execution on a time-multiplexed Coherent Ising Machine (CIM) benchmarked against simulated quantum annealing (SQA) and classical optimization algorithms. The resulting model, with over one million quadratic terms and about 4,100 variables, captures profit, risk, and capacity interactions within a unified formulation.
  On a dataset of 500 SKUs across eight planning periods, Quanfluence's CIM achieved an energy of minus 2.95 times 10 to the power of 16, producing robust solutions with 288 distinct SKUs (approximately 60 percent of the catalog), 226,813 allocated units, and 12.75 million dollars profit, all with zero capacity violations. These results demonstrate that hybrid quantum-classical QUBO methods can deliver feasible and profitable supply-chain allocations at an industrial scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21544v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rushikesh Ubale, Yasar Mulani, Abhay Suresh, Gregory Byrd, Sangram Deshpande, B. R. Nikilesh, Sanya Nanda</dc:creator>
    </item>
    <item>
      <title>Rate-cost tradeoffs in continuous-time control with a biomolecular application</title>
      <link>https://arxiv.org/abs/2510.21612</link>
      <description>arXiv:2510.21612v1 Announce Type: cross 
Abstract: This paper focuses on rate-limited control of the generalized Ornstein-Uhlenbeck process where the control action can be either multiplicative or additive, and the noise variance can depend on the control action. We derive a lower bound on the data rate necessary to achieve the desired control cost. The lower bound is attained with equality if the control is performed via an additive white Gaussian channel. The system model approximates the dynamics of a discrete-state molecular birth-death process, and the result has direct implications on the control of a biomolecular system via chemical reactions, where the multiplicative control corresponds to the degradation rate, the additive control corresponds to the production rate, and the control objective is to decrease the fluctuations of the controlled molecular species around their desired concentration levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21612v1</guid>
      <category>eess.SY</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE Transactions of Automatic Control, Apr. 2026</arxiv:journal_reference>
      <dc:creator>Yorie Nakahira, Fangzhou Xiao, Victoria Kostina, John C. Doyle</dc:creator>
    </item>
    <item>
      <title>Beyond Smoothed Analysis: Analyzing the Simplex Method by the Book</title>
      <link>https://arxiv.org/abs/2510.21613</link>
      <description>arXiv:2510.21613v1 Announce Type: cross 
Abstract: Narrowing the gap between theory and practice is a longstanding goal of the algorithm analysis community. To further progress our understanding of how algorithms work in practice, we propose a new algorithm analysis framework that we call by the book analysis. In contrast to earlier frameworks, by the book analysis not only models an algorithm's input data, but also the algorithm itself. Results from by the book analysis are meant to correspond well with established knowledge of an algorithm's practical behavior, as they are meant to be grounded in observations from implementations, input modeling best practices, and measurements on practical benchmark instances. We apply our framework to the simplex method, an algorithm which is beloved for its excellent performance in practice and notorious for its high running time under worst-case analysis. The simplex method similarly showcased the state of the art framework smoothed analysis (Spielman and Teng, STOC'01). We explain how our framework overcomes several weaknesses of smoothed analysis and we prove that under input scaling assumptions, feasibility tolerances and other design principles used by simplex method implementations, the simplex method indeed attains a polynomial running time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21613v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eleon Bach, Alexander E. Black, Sophie Huiberts, Sean Kafer</dc:creator>
    </item>
    <item>
      <title>A Novel State-Centric Necessary Condition for Time-Optimal Control of Controllable Linear Systems Based on Augmented Switching Laws (Extended Version)</title>
      <link>https://arxiv.org/abs/2404.08943</link>
      <description>arXiv:2404.08943v4 Announce Type: replace 
Abstract: Most existing necessary conditions for optimal control based on adjoining methods require both state and costate information, yet the unobservability of costates for a given feasible trajectory impedes the determination of optimality in practice. This paper establishes a novel theoretical framework for time-optimal control of controllable linear systems with a single input, proposing the augmented switching law (ASL) that represents the input control and the feasibility in a compact form. Given a feasible trajectory, the perturbed trajectory under the constraints of ASL is guaranteed to be feasible, resulting in a novel state-centric necessary condition without dependence on costate information. A first-order necessary condition is proposed that the Jacobian matrix of the ASL is not of full row rank, which also results in a potential approach to optimizing a given feasible trajectory with the preservation of arc structures. The proposed necessary condition is applied to high-order chain-of-integrator systems with full box constraints, contributing to some theoretical results challenging to reason by costate-based conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08943v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2025.3618613</arxiv:DOI>
      <dc:creator>Yunan Wang, Chuxiong Hu, Yujie Lin, Zeyang Li, Shize Lin, Suqin He</dc:creator>
    </item>
    <item>
      <title>Optimal Rates of Convergence for Entropy Regularization in Discounted Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2406.04163</link>
      <description>arXiv:2406.04163v4 Announce Type: replace 
Abstract: We study the error introduced by entropy regularization in infinite-horizon, discrete, discounted Markov decision processes. We show that this error decreases exponentially in the inverse regularization strength both in a weighted KL-divergence and in value with a problem-specific exponent. This is in contrast to previously known estimates, of the order $O(\tau)$, where $\tau$ is the regularization strength. We provide a lower bound matching our upper bound up to a polynomial term, thereby characterizing the exponential convergence rate for entropy regularization. Our proof relies on the observation that the solutions of entropy-regularized Markov decision processes solve a gradient flow of the unregularized reward with respect to a Riemannian metric common in natural policy gradient methods. This correspondence allows us to identify the limit of this gradient flow as the generalized maximum entropy optimal policy, thereby characterizing the implicit bias of this gradient flow, which corresponds to a time-continuous version of the natural policy gradient method. We use our improved error estimates to show that for entropy-regularized natural policy gradient methods, the overall error decays exponentially in the square root of the number of iterations, improving over existing sublinear guarantees. Finally, we extend our analysis to settings beyond the entropy. In particular, we characterize the implicit bias regarding general convex potentials and their resulting generalized natural policy gradients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04163v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes M\"uller, Semih Cayci</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Performative Optimization</title>
      <link>https://arxiv.org/abs/2407.01344</link>
      <description>arXiv:2407.01344v2 Announce Type: replace 
Abstract: In performative stochastic optimization, decisions can influence the distribution of random parameters, rendering the data-generating process itself decision-dependent. In practice, decision-makers rarely have access to the true distribution map and must instead rely on imperfect surrogate models, which can lead to severely suboptimal solutions under misspecification. Data scarcity or costly collection further exacerbates these challenges in real-world settings. To address these challenges, we propose a distributionally robust framework for performative optimization that explicitly accounts for ambiguity in the decision-dependent distribution. Our framework introduces three modeling paradigms that capture a broad range of applications in machine learning and decision-making under uncertainty. This latter setting has not previously been explored in the performative optimization literature. To tackle the intractability of the resulting nonconvex objectives, we develop an iterative algorithm named repeated robust risk minimization, which alternates between solving a decision-independent distributionally robust optimization problem and updating the ambiguity set based on the previous decision. This decoupling ensures computational tractability at each iteration while enhancing robustness to model uncertainty. We provide reformulations compatible with off-the-shelf solvers and establish theoretical guarantees on convergence and suboptimality. Extensive numerical experiments in strategic classification, revenue management, and portfolio optimization demonstrate significant performance gains over state-of-the-art baselines, highlighting the practical value of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01344v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhuangzhuang Jia, Yijie Wang, Roy Dong, Grani A. Hanasusanto</dc:creator>
    </item>
    <item>
      <title>A Capacitated Collection-and-Delivery-Point Location Problem with Random Utility Maximizing Customers</title>
      <link>https://arxiv.org/abs/2411.04200</link>
      <description>arXiv:2411.04200v2 Announce Type: replace 
Abstract: We consider a strategic decision-making problem where a logistics provider (LP) seeks to locate collection and delivery points (CDPs) with the objective to reduce total logistics costs. The customers maximize utility that depends on their perception of home delivery service as well as the characteristics of the CDPs, including their location. At the strategic planning level, the LP does not have complete information about customers' preferences and their exact location. We introduce a mixed integer non-linear formulation of the problem and propose two linear reformulations. The latter involve sample average approximations and closest assignment constraints, and in one of the formulations we use scenario aggregation to reduce its size. We solve the formulations with a general-purpose solver using a standard Benders decomposition method. Based on extensive computational results and a realistic case study, we find that the problem can be solved efficiently. However, the level of uncertainty in the instances determines which approach is the most efficient. We use an entropy measure to capture the level of uncertainty that can be computed prior to solving. Furthermore, the results highlight the value of accurate demand modeling, as customer preferences have an important impact on the solutions and associated costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04200v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David Pinzon Ulloa, Ammar Metnani, Emma Frejinger</dc:creator>
    </item>
    <item>
      <title>Approximate Energetic Resilience of Nonlinear Systems under Partial Loss of Control Authority</title>
      <link>https://arxiv.org/abs/2502.07603</link>
      <description>arXiv:2502.07603v3 Announce Type: replace 
Abstract: In this paper, we quantify the resilience of nonlinear dynamical systems by studying the increased energy used by all inputs of a system that suffers a partial loss of control authority, either through actuator malfunctions or through adversarial attacks. To quantify the maximal increase in energy, we introduce the notion of an energetic resilience metric. Prior work in this particular setting does not consider general nonlinear dynamical systems. In developing this framework, we first consider the special case of linear driftless systems and recall the energies in the control signal in the nominal and malfunctioning systems. Using these energies, we derive a bound on the energetic resilience metric. For general nonlinear systems, we first obtain a condition on the mean value of the control signal in both the nominal and malfunctioning systems, which allows us to approximate the energy in the control. We then obtain a worst-case approximation of this energy for the malfunctioning system, over all malfunctioning inputs. Assuming this approximation is exact, we derive bounds on the energetic resilience metric when control authority is lost over one actuator. A set of simulation examples demonstrate that the metric is useful in quantifying the resilience of the system without significant conservatism, despite the approximations used in obtaining control energies for nonlinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07603v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ram Padmanabhan, Melkior Ornik</dc:creator>
    </item>
    <item>
      <title>Control analysis and synthesis for general control-affine systems</title>
      <link>https://arxiv.org/abs/2503.05606</link>
      <description>arXiv:2503.05606v2 Announce Type: replace 
Abstract: We study controllability and constructive synthesis for control-affine systems. We introduce trajectory-dependent Gramian maps that extend the linear time-varying Gramian and yield explicit fixed-point synthesis maps. On feasible coercivity classes (uniform eigenvalue lower bounds), the Gramian map is Lipschitz, synthesis iterates exhibit factorial decay, and the Caccioppoli fixed-point theorem gives a unique fixed point that steers the system and satisfies an energy identity. When, in addition, an annihilation (range-alignment) condition holds, this fixed point coincides with the unique global minimum-energy control on the feasible set; if the coercivity bound holds uniformly for all bounded controls, the same conclusion holds on the full bounded-control space. We provide structural conditions on the input matrix that ensure the nonemptiness of the admissible class (and, in fully actuated regimes, equality with the full space) and sufficient conditions for underactuated systems via bounded-amplitude reference controls. Case studies on Hopfield network dynamics illustrate refined estimates that enlarge reachable targets. A trajectory-freezing and compactness step extends the synthesis to general nonlinear control-affine systems. The results yield verifiable controllability criteria with explicit, numerically implementable controllers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05606v2</guid>
      <category>math.OC</category>
      <category>math.CA</category>
      <category>math.DS</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyprien Tamekue, ShiNung Ching</dc:creator>
    </item>
    <item>
      <title>Numerical solution of optimal control problems using quadratic transport regularization</title>
      <link>https://arxiv.org/abs/2503.07105</link>
      <description>arXiv:2503.07105v2 Announce Type: replace 
Abstract: We address optimal control problems on the space of measures for an objective containing a smooth functional and an optimal transport regularization. That is, the quadratic Monge-Kantorovich distance between a given prior measure and the control is penalized in the objective. We consider optimality conditions and reparametrize the problem using the celebrated structure theorem by Brenier. The optimality conditions can be formulated as a piecewise differentiable equation. This is utilized to formulate solution algorithms and to analyze their local convergence properties. We present a numerical example to illustrate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07105v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nicolas Borchard, Gerd Wachsmuth</dc:creator>
    </item>
    <item>
      <title>cuHALLaR: A GPU Accelerated Low-Rank Augmented Lagrangian Method for Large-Scale Semidefinite Programming</title>
      <link>https://arxiv.org/abs/2505.13719</link>
      <description>arXiv:2505.13719v2 Announce Type: replace 
Abstract: This paper introduces cuHALLaR, a GPU-accelerated implementation of the HALLaR method proposed in Monteiro et al. 2024 for solving large-scale semidefinite programming (SDP) problems. We demonstrate how our Julia-based implementation efficiently uses GPU parallelism through optimization of simple, but key, operations, including linear maps, adjoints, and gradient evaluations. Extensive numerical experiments across three SDP problem classes, i.e., maximum stable set, matrix completion, and phase retrieval show significant performance improvements over both CPU implementations and existing GPU-based solvers. For the largest instances, cuHALLaR achieves speedups of 30-140x on matrix completion problems, up to 135x on maximum stable set problems for Hamming graphs with 8.4 million vertices, and 15-47x on phase retrieval problems with dimensions up to 3.2 million. Our approach efficiently handles massive problems with dimensions up to (n,m) equal to (8 million, 300 million) with high precision, solving matrix completion instances with over 8 million rows and columns in just 142 seconds. These results establish cuHALLaR as a very promising GPU-based method for solving large-scale semidefinite programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13719v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacob M. Aguirre, Diego Cifuentes, Vincent Guigues, Renato D. C. Monteiro, Victor Hugo Nascimento, Arnesh Sujanani</dc:creator>
    </item>
    <item>
      <title>Sharper Convergence Rates for Nonconvex Optimisation via Reduction Mappings</title>
      <link>https://arxiv.org/abs/2506.08428</link>
      <description>arXiv:2506.08428v2 Announce Type: replace 
Abstract: Many high-dimensional optimisation problems exhibit rich geometric structures in their set of minimisers, often forming smooth manifolds due to over-parametrisation or symmetries. When this structure is known, at least locally, it can be exploited through reduction mappings that reparametrise part of the parameter space to lie on the solution manifold. These reductions naturally arise from inner optimisation problems and effectively remove redundant directions, yielding a lower-dimensional objective. In this work, we introduce a general framework to understand how such reductions influence the optimisation landscape. We show that well-designed reduction mappings improve curvature properties of the objective, leading to better-conditioned problems and theoretically faster convergence for gradient-based methods. Our analysis unifies a range of scenarios where structural information at optimality is leveraged to accelerate convergence, offering a principled explanation for the empirical gains observed in such optimisation algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08428v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evan Markou, Thalaiyasingam Ajanthan, Stephen Gould</dc:creator>
    </item>
    <item>
      <title>An Efficient Smoothing Damped Newton Method for Large-Scale Mathematical Programs with Equilibrium Constraints</title>
      <link>https://arxiv.org/abs/2506.22603</link>
      <description>arXiv:2506.22603v3 Announce Type: replace 
Abstract: Bilevel hyperparameter optimization has received growing attention thanks to the fast development of machine learning. Due to the tremendous size of data sets, the scale of bilevel hyperparameter optimization problem could be extremely large, posing great challenges in designing efficient numerical algorithms. In this paper, we focus on solving the large-scale mathematical programs with equilibrium constraints (MPEC) derived from hyperparameter selection of L1 support vector classification (L1-SVC). We propose a highly efficient smoothing damped Newton method (SDNM) for solving such MPEC. Compared with most existing algorithms where subproblems are solved by packages, our approach fully takes advantage of the structure of MPEC and therefore is package-free. Moreover, the proposed SDNM converges to C-stationary point under MPEC-LICQ with subproblem enjoys a quadratic convergence rate under proper assumptions. Extensive numerical results over LIBSVM dataset show the superior performance of SDNM over other state-of-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22603v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixin Wang, Qingna Li, Liwei Zhang</dc:creator>
    </item>
    <item>
      <title>Predictability Enables Parallelization of Nonlinear State Space Models</title>
      <link>https://arxiv.org/abs/2508.16817</link>
      <description>arXiv:2508.16817v2 Announce Type: replace 
Abstract: The rise of parallel computing hardware has made it increasingly important to understand which nonlinear state space models can be efficiently parallelized. Recent advances like DEER (arXiv:2309.12252) or DeepPCR (arXiv:2309.16318) have shown that evaluating a state space model can be recast as solving a parallelizable optimization problem, and sometimes this approach can yield dramatic speed-ups in evaluation time. However, the factors that govern the difficulty of these optimization problems remain unclear, limiting the larger adoption of the technique. In this work, we establish a precise relationship between the dynamics of a nonlinear system and the conditioning of its corresponding optimization formulation. We show that the predictability of a system, defined as the degree to which small perturbations in state influence future behavior, impacts the number of optimization steps required for evaluation. In predictable systems, the state trajectory can be computed in $O((\log T)^2)$ time, where $T$ is the sequence length, a major improvement over the conventional sequential approach. In contrast, chaotic or unpredictable systems exhibit poor conditioning, with the consequence that parallel evaluation converges too slowly to be useful. Importantly, our theoretical analysis demonstrates that for predictable systems, the optimization problem is always well-conditioned, whereas for unpredictable systems, the conditioning degrades exponentially as a function of the sequence length. We validate our claims through extensive experiments, providing practical guidance on when nonlinear dynamical systems can be efficiently parallelized, and highlighting predictability as a key design principle for parallelizable models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16817v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>stat.ML</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xavier Gonzalez, Leo Kozachkov, David M. Zoltowski, Kenneth L. Clarkson, Scott W. Linderman</dc:creator>
    </item>
    <item>
      <title>A Two-fold Randomization Framework for Impulse Control Problems</title>
      <link>https://arxiv.org/abs/2509.12018</link>
      <description>arXiv:2509.12018v4 Announce Type: replace 
Abstract: We propose and analyze a randomization scheme for a general class of impulse control problems. The solution to this randomized problem is characterized as the fixed point of a compound operator which consists of a regularized nonlocal operator and a regularized stopping operator. This approach allows us to derive a semi-linear Hamilton-Jacobi-Bellman (HJB) equation. Through an equivalent randomization scheme with a Poisson compound measure, we establish a verification theorem that implies the uniqueness of the solution. Via an iterative approach, we prove the existence of the solution. The existence-and-uniqueness result ensures the randomized problem is well-defined. We then demonstrate that our randomized impulse control problem converges to its classical counterpart as the randomization parameter $\pmb \lambda$ vanishes. This convergence, combined with the value function's $C^{2,\alpha}_{loc}$ regularity, confirms our framework provides a robust approximation and a foundation for developing learning algorithms. Under this framework, we propose an offline reinforcement learning (RL) algorithm. Its policy improvement step is naturally derived from the iterative approach from the existence proof, which enjoys a geometric convergence rate. We implement a model-free version of the algorithm and numerically demonstrate its effectiveness using a widely-studied example. The results show that our RL algorithm can learn the randomized solution, which accurately approximates its classical counterpart. A sensitivity analysis with respect to the volatility parameter $\sigma$ in the state process effectively demonstrates the exploration-exploitation tradeoff.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12018v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoyang Cao, Yuchao Dong, Zhouhao Yang</dc:creator>
    </item>
    <item>
      <title>A Single-Loop Gradient Algorithm for Pessimistic Bilevel Optimization via Smooth Approximation</title>
      <link>https://arxiv.org/abs/2509.26240</link>
      <description>arXiv:2509.26240v3 Announce Type: replace 
Abstract: Bilevel optimization has garnered significant attention in the machine learning community recently, particularly regarding the development of efficient numerical methods. While substantial progress has been made in developing efficient algorithms for optimistic bilevel optimization, the study of methods for solving Pessimistic Bilevel Optimization (PBO) remains relatively less explored, especially the design of fully first-order, single-loop gradient-based algorithms. This paper aims to bridge this research gap. We first propose a novel smooth approximation to the PBO problem, using penalization and regularization techniques. Building upon this approximation, we then propose SiPBA (Single-loop Pessimistic Bilevel Algorithm), a new gradient-based method specifically designed for PBO which avoids second-order derivative information or inner-loop iterations for subproblem solving. We provide theoretical validation for the proposed smooth approximation scheme and establish theoretical convergence for the algorithm SiPBA. Numerical experiments on synthetic examples and practical applications demonstrate the effectiveness and efficiency of SiPBA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26240v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qichao Cao, Shangzhi Zeng, Jin Zhang</dc:creator>
    </item>
    <item>
      <title>CoNeT-GIANT: A compressed Newton-type fully distributed optimization algorithm</title>
      <link>https://arxiv.org/abs/2510.08806</link>
      <description>arXiv:2510.08806v2 Announce Type: replace 
Abstract: Compression techniques are essential in distributed optimization and learning algorithms with high-dimensional model parameters, particularly in scenarios with tight communication constraints such as limited bandwidth. This article presents a communication-efficient second-order distributed optimization algorithm, termed as CoNet-GIANT, equipped with a compression module, designed to minimize the average of local strongly convex functions. CoNet-GIANT incorporates two consensus-based averaging steps at each node: gradient tracking and approximate Newton-type iterations, inspired by the recently proposed Network-GIANT. Under certain sufficient conditions on the step size, CoNet-GIANT achieves significantly faster linear convergence, comparable to that of its first-order counterparts, both in the compressed and uncompressed settings. CoNet-GIANT is efficient in terms of data usage, communication cost, and run-time, making it a suitable choice for distributed optimization over a wide range of wireless networks. Extensive experiments on synthetic data and the widely used CovType dataset demonstrate its superior performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08806v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Souvik Das, Subhrakanti Dey</dc:creator>
    </item>
    <item>
      <title>Learning Mean-Field Games through Mean-Field Actor-Critic Flow</title>
      <link>https://arxiv.org/abs/2510.12180</link>
      <description>arXiv:2510.12180v2 Announce Type: replace 
Abstract: We propose the Mean-Field Actor-Critic (MFAC) flow, a continuous-time learning dynamics for solving mean-field games (MFGs), combining techniques from reinforcement learning and optimal transport. The MFAC framework jointly evolves the control (actor), value function (critic), and distribution components through coupled gradient-based updates governed by partial differential equations (PDEs). A central innovation is the Optimal Transport Geodesic Picard (OTGP) flow, which drives the distribution toward equilibrium along Wasserstein-2 geodesics. We conduct a rigorous convergence analysis using Lyapunov functionals and establish global exponential convergence of the MFAC flow under a suitable timescale. Our results highlight the algorithmic interplay among actor, critic, and distribution components. Numerical experiments illustrate the theoretical findings and demonstrate the effectiveness of the MFAC framework in computing MFG equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12180v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mo Zhou, Haosheng Zhou, Ruimeng Hu</dc:creator>
    </item>
    <item>
      <title>Factor Fitting, Rank Allocation, and Partitioning in Multilevel Low Rank Matrices</title>
      <link>https://arxiv.org/abs/2310.19214</link>
      <description>arXiv:2310.19214v2 Announce Type: replace-cross 
Abstract: We consider multilevel low rank (MLR) matrices, defined as a row and column permutation of a sum of matrices, each one a block diagonal refinement of the previous one, with all blocks low rank given in factored form. MLR matrices extend low rank matrices but share many of their properties, such as the total storage required and complexity of matrix-vector multiplication. We address three problems that arise in fitting a given matrix by an MLR matrix in the Frobenius norm. The first problem is factor fitting, where we adjust the factors of the MLR matrix. The second is rank allocation, where we choose the ranks of the blocks in each level, subject to the total rank having a given value, which preserves the total storage needed for the MLR matrix. The final problem is to choose the hierarchical partition of rows and columns, along with the ranks and factors. This paper is accompanied by an open source package that implements the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.19214v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.MS</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tetiana Parshakova, Trevor Hastie, Eric Darve, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>Mean-Field Sampling for Cooperative Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2412.00661</link>
      <description>arXiv:2412.00661v4 Announce Type: replace-cross 
Abstract: Designing efficient algorithms for multi-agent reinforcement learning (MARL) is fundamentally challenging because the size of the joint state and action spaces grows exponentially in the number of agents. These difficulties are exacerbated when balancing sequential global decision-making with local agent interactions. In this work, we propose a new algorithm $\texttt{SUBSAMPLE-MFQ}$ ($\textbf{Subsample}$-$\textbf{M}$ean-$\textbf{F}$ield-$\textbf{Q}$-learning) and a decentralized randomized policy for a system with $n$ agents. For any $k\leq n$, our algorithm learns a policy for the system in time polynomial in $k$. We prove that this learned policy converges to the optimal policy on the order of $\tilde{O}(1/\sqrt{k})$ as the number of subsampled agents $k$ increases. In particular, this bound is independent of the number of agents $n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00661v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emile Anand, Ishani Karmarkar, Guannan Qu</dc:creator>
    </item>
    <item>
      <title>Bayesian Optimization with Preference Exploration using a Monotonic Neural Network Ensemble</title>
      <link>https://arxiv.org/abs/2501.18792</link>
      <description>arXiv:2501.18792v4 Announce Type: replace-cross 
Abstract: Many real-world black-box optimization problems have multiple conflicting objectives. Rather than attempting to approximate the entire set of Pareto-optimal solutions, interactive preference learning allows to focus the search on the most relevant subset. However, few previous studies have exploited the fact that utility functions are usually monotonic. In this paper, we address the Bayesian Optimization with Preference Exploration (BOPE) problem and propose using a neural network ensemble as a utility surrogate model. This approach naturally integrates monotonicity and supports pairwise comparison data. Our experiments demonstrate that the proposed method outperforms state-of-the-art approaches and exhibits robustness to noise in utility evaluations. An ablation study highlights the critical role of monotonicity in enhancing performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18792v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanyang Wang, Juergen Branke, Matthias Poloczek</dc:creator>
    </item>
    <item>
      <title>Projection-based Lyapunov method for fully heterogeneous weakly-coupled MDPs</title>
      <link>https://arxiv.org/abs/2502.06072</link>
      <description>arXiv:2502.06072v5 Announce Type: replace-cross 
Abstract: Heterogeneity poses a fundamental challenge for many real-world large-scale decision-making problems but remains largely understudied. In this paper, we study the fully heterogeneous setting of a prominent class of such problems, known as weakly-coupled Markov decision processes (WCMDPs). Each WCMDP consists of $N$ arms (or subproblems), which have distinct model parameters in the fully heterogeneous setting, leading to the curse of dimensionality when $N$ is large. We show that, under mild assumptions, an efficiently computable policy achieves an $O(1/\sqrt{N})$ optimality gap in the long-run average reward per arm for fully heterogeneous WCMDPs as $N$ becomes large. This is the first asymptotic optimality result for fully heterogeneous average-reward WCMDPs. Our main technical innovation is the construction of projection-based Lyapunov functions that certify the convergence of rewards and costs to an optimal region, even under full heterogeneity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06072v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiangcheng Zhang, Yige Hong, Weina Wang</dc:creator>
    </item>
    <item>
      <title>Planning and Learning in Average Risk-aware MDPs</title>
      <link>https://arxiv.org/abs/2503.17629</link>
      <description>arXiv:2503.17629v2 Announce Type: replace-cross 
Abstract: For continuing tasks, average cost Markov decision processes have well-documented value and can be solved using efficient algorithms. However, it explicitly assumes that the agent is risk-neutral. In this work, we extend risk-neutral algorithms to accommodate the more general class of dynamic risk measures. Specifically, we propose a relative value iteration (RVI) algorithm for planning and design two model-free Q-learning algorithms, namely a generic algorithm based on the multi-level Monte Carlo (MLMC) method, and an off-policy algorithm dedicated to utility-based shortfall risk measures. Both the RVI and MLMC-based Q-learning algorithms are proven to converge to optimality. Numerical experiments validate our analysis, confirm empirically the convergence of the off-policy algorithm, and demonstrate that our approach enables the identification of policies that are finely tuned to the intricate risk-awareness of the agent that they serve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17629v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Weikai Wang, Erick Delage</dc:creator>
    </item>
    <item>
      <title>SAD Neural Networks: Divergent Gradient Flows and Asymptotic Optimality via o-minimal Structures</title>
      <link>https://arxiv.org/abs/2505.09572</link>
      <description>arXiv:2505.09572v2 Announce Type: replace-cross 
Abstract: We study gradient flows for loss landscapes of fully connected feedforward neural networks with commonly used continuously differentiable activation functions such as the logistic, hyperbolic tangent, softplus or GELU function. We prove that the gradient flow either converges to a critical point or diverges to infinity while the loss converges to an asymptotic critical value. Moreover, we prove the existence of a threshold $\varepsilon&gt;0$ such that the loss value of any gradient flow initialized at most $\varepsilon$ above the optimal level converges to it. For polynomial target functions and sufficiently big architecture and data set, we prove that the optimal loss value is zero and can only be realized asymptotically. From this setting, we deduce our main result that any gradient flow with sufficiently good initialization diverges to infinity. Our proof heavily relies on the geometry of o-minimal structures. We confirm these theoretical findings with numerical experiments and extend our investigation to more realistic scenarios, where we observe an analogous behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09572v2</guid>
      <category>cs.LG</category>
      <category>math.LO</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julian Kranz, Davide Gallon, Steffen Dereich, Arnulf Jentzen</dc:creator>
    </item>
    <item>
      <title>Optimal Control for Transformer Architectures: Enhancing Generalization, Robustness and Efficiency</title>
      <link>https://arxiv.org/abs/2505.13499</link>
      <description>arXiv:2505.13499v2 Announce Type: replace-cross 
Abstract: We study Transformers through the perspective of optimal control theory, using tools from continuous-time formulations to derive actionable insights into training and architecture design. This framework improves the performance of existing Transformer models while providing desirable theoretical guarantees, including generalization and robustness. Our framework is designed to be plug-and-play, enabling seamless integration with established Transformer models and requiring only slight changes to the implementation. We conduct seven extensive experiments on tasks motivated by text generation, sentiment analysis, image classification, and point cloud classification. Experimental results show that the framework improves the test performance of the baselines, while being more parameter-efficient. On character-level text generation with nanoGPT, our framework achieves a 46% reduction in final test loss while using 42% fewer parameters. On GPT-2, our framework achieves a 9.3% reduction in final test loss, demonstrating scalability to larger models. To the best of our knowledge, this is the first work that applies optimal control theory to both the training and architecture of Transformers. It offers a new foundation for systematic, theory-driven improvements and moves beyond costly trial-and-error approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13499v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kelvin Kan, Xingjian Li, Benjamin J. Zhang, Tuhin Sahai, Stanley Osher, Markos A. Katsoulakis</dc:creator>
    </item>
    <item>
      <title>Rolling Ball Optimizer: Learning by ironing out loss landscape wrinkles</title>
      <link>https://arxiv.org/abs/2505.19527</link>
      <description>arXiv:2505.19527v3 Announce Type: replace-cross 
Abstract: Training large neural networks (NNs) requires optimizing high-dimensional data-dependent loss functions. The optimization landscape of these functions is often highly complex and textured, even fractal-like, with many spurious local minima, ill-conditioned valleys, degenerate points, and saddle points. Complicating things further is the fact that these landscape characteristics are a function of the data, meaning that noise in the training data can propagate forward and give rise to unrepresentative small-scale geometry. This poses a difficulty for gradient-based optimization methods, which rely on local geometry to compute updates and are, therefore, vulnerable to being derailed by noisy data. In practice,this translates to a strong dependence of the optimization dynamics on the noise in the data, i.e., poor generalization performance. To remediate this problem, we propose a new optimization procedure: Rolling Ball Optimizer (RBO), that breaks this spatial locality by incorporating information from a larger region of the loss landscape in its updates. We achieve this by simulating the motion of a rigid sphere of finite radius rolling on the loss landscape, a straightforward generalization of Gradient Descent (GD) that simplifies into it in the infinitesimal limit. The radius serves as a hyperparameter that determines the scale at which RBO sees the loss landscape, allowing control over the granularity of its interaction therewith. We are motivated by the intuition that the large-scale geometry of the loss landscape is less data-specific than its fine-grained structure, and that it is easier to optimize. We support this intuition by proving that our algorithm has a smoothing effect on the loss function. Evaluation against SGD, SAM, and Entropy-SGD, on MNIST and CIFAR-10/100 demonstrates promising results in terms of convergence speed, training accuracy, and generalization performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19527v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammed Djameleddine Belgoumri, Mohamed Reda Bouadjenek, Hakim Hacid, Imran Razzak, Sunil Aryal</dc:creator>
    </item>
    <item>
      <title>The Rich and the Simple: On the Implicit Bias of Adam and SGD</title>
      <link>https://arxiv.org/abs/2505.24022</link>
      <description>arXiv:2505.24022v2 Announce Type: replace-cross 
Abstract: Adam is the de facto optimization algorithm for several deep learning applications, but an understanding of its implicit bias and how it differs from other algorithms, particularly standard first-order methods such as (stochastic) gradient descent (GD), remains limited. In practice, neural networks (NNs) trained with SGD are known to exhibit simplicity bias -- a tendency to find simple solutions. In contrast, we show that Adam is more resistant to such simplicity bias. First, we investigate the differences in the implicit biases of Adam and GD when training two-layer ReLU NNs on a binary classification task with Gaussian data. We find that GD exhibits a simplicity bias, resulting in a linear decision boundary with a suboptimal margin, whereas Adam leads to much richer and more diverse features, producing a nonlinear boundary that is closer to the Bayes' optimal predictor. This richer decision boundary also allows Adam to achieve higher test accuracy both in-distribution and under certain distribution shifts. We theoretically prove these results by analyzing the population gradients. Next, to corroborate our theoretical findings, we present extensive empirical results showing that this property of Adam leads to superior generalization across various datasets with spurious correlations where NNs trained with SGD are known to show simplicity bias and do not generalize well under certain distributional shifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24022v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bhavya Vasudeva, Jung Whan Lee, Vatsal Sharan, Mahdi Soltanolkotabi</dc:creator>
    </item>
    <item>
      <title>FSNet: Feasibility-Seeking Neural Network for Constrained Optimization with Guarantees</title>
      <link>https://arxiv.org/abs/2506.00362</link>
      <description>arXiv:2506.00362v2 Announce Type: replace-cross 
Abstract: Efficiently solving constrained optimization problems is crucial for numerous real-world applications, yet traditional solvers are often computationally prohibitive for real-time use. Machine learning-based approaches have emerged as a promising alternative to provide approximate solutions at faster speeds, but they struggle to strictly enforce constraints, leading to infeasible solutions in practice. To address this, we propose the Feasibility-Seeking Neural Network (FSNet), which integrates a feasibility-seeking step directly into its solution procedure to ensure constraint satisfaction. This feasibility-seeking step solves an unconstrained optimization problem that minimizes constraint violations in a differentiable manner, enabling end-to-end training and providing guarantees on feasibility and convergence. Our experiments across a range of different optimization problems, including both smooth/nonsmooth and convex/nonconvex problems, demonstrate that FSNet can provide feasible solutions with solution quality comparable to (or in some cases better than) traditional solvers, at significantly faster speeds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00362v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang T. Nguyen, Priya L. Donti</dc:creator>
    </item>
    <item>
      <title>KOALA++: Efficient Kalman-Based Optimization with Gradient-Covariance Products</title>
      <link>https://arxiv.org/abs/2506.04432</link>
      <description>arXiv:2506.04432v3 Announce Type: replace-cross 
Abstract: We propose KOALA++, a scalable Kalman-based optimization algorithm that explicitly models structured gradient uncertainty in neural network training. Unlike second-order methods, which rely on expensive second order gradient calculation, our method directly estimates the parameter covariance matrix by recursively updating compact gradient covariance products. This design improves upon the original KOALA framework that assumed diagonal covariance by implicitly capturing richer uncertainty structure without storing the full covariance matrix and avoiding large matrix inversions. Across diverse tasks, including image classification and language modeling, KOALA++ achieves accuracy on par or better than state-of-the-art first- and second-order optimizers while maintaining the efficiency of first-order methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04432v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zixuan Xia, Aram Davtyan, Paolo Favaro</dc:creator>
    </item>
    <item>
      <title>Online Learning for Dynamic Vickrey-Clarke-Groves Mechanism in Unknown Environments</title>
      <link>https://arxiv.org/abs/2506.19038</link>
      <description>arXiv:2506.19038v2 Announce Type: replace-cross 
Abstract: We consider the problem of online dynamic mechanism design for sequential auctions in unknown environments, where the underlying market and, thus, the bidders' values vary over time as interactions between the seller and the bidders progress. We model the sequential auctions as an infinite-horizon average-reward Markov decision process (MDP). In each round, the seller determines an allocation and sets a payment for each bidder, while each bidder receives a private reward and submits a sealed bid to the seller. The state, which represents the underlying market, evolves according to an unknown transition kernel and the seller's allocation policy without episodic resets. We first extend the Vickrey-Clarke-Groves (VCG) mechanism to sequential auctions, thereby obtaining a dynamic counterpart that preserves the desired properties: efficiency, truthfulness, and individual rationality. We then focus on the online setting and develop a reinforcement learning algorithm for the seller to learn the underlying MDP and implement a mechanism that closely resembles the dynamic VCG mechanism. We show that the learned mechanism approximately satisfies efficiency, truthfulness, and individual rationality and achieves guaranteed performance in terms of various notions of regret.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19038v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Leon, S. Rasoul Etesami</dc:creator>
    </item>
    <item>
      <title>Total Generalized Variation of the Normal Vector Field and Applications to Mesh Denoising</title>
      <link>https://arxiv.org/abs/2507.13530</link>
      <description>arXiv:2507.13530v2 Announce Type: replace-cross 
Abstract: We propose a novel formulation for the second-order total generalized variation (TGV) of the normal vector on an oriented, triangular mesh embedded in $\R^3$. The normal vector is considered as a manifold-valued function, taking values on the unit sphere. Our formulation extends previous discrete TGV models for piecewise constant scalar data that utilize a Raviart-Thomas function space. To extend this formulation to the manifold setting, a tailor-made tangential Raviart-Thomas type finite element space is constructed in this work. The new regularizer is compared to existing methods in mesh denoising experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13530v2</guid>
      <category>cs.CV</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Lukas Baumg\"artner, Ronny Bergmann, Roland Herzog, Stephan Schmidt, Manuel Wei{\ss}</dc:creator>
    </item>
    <item>
      <title>A Brenier Theorem on $(P_2 (...P_2(H)...), W_2 )$ and Applications to Adapted Transport</title>
      <link>https://arxiv.org/abs/2509.03506</link>
      <description>arXiv:2509.03506v2 Announce Type: replace-cross 
Abstract: We develop Brenier theorems on iterated Wasserstein spaces. For a separable Hilbert space $H$ and $N\geq 1$, we construct a full-support probability $\Lambda$ on $P_2^{N}(H)= P_2(... P_2(H)...)$ that is transport regular: for every $Q$ with finite second moment, transporting $\Lambda$ to $Q$ with cost $W_2^2$ admits a unique optimizer, and this optimizer is of Monge type. The analysis rests on a characterization of optimal couplings on $P_2(H)$ and, more generally, on $P_2^{N}(H)$ via convex potentials on the Lions lift; in the latter case we employ a new adapted version of the lift tailored to the $N$-step structure. A key idea is a new identification between optimal-transport $c$-conjugation (with $c$ given by maximal covariance) and classical convex conjugation on the lift.
  A primary motivation comes from the adapted Wasserstein distance $AW_2$: our results yield a first Brenier theorem for $AW_2$ and characterize $AW_2^2$-optimal couplings through convex functionals on the space of $L_2$-processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03506v2</guid>
      <category>math.PR</category>
      <category>math.FA</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathias Beiglb\"ock, Gudmund Pammer, Stefan Schrott</dc:creator>
    </item>
    <item>
      <title>Adaptive Algorithms with Sharp Convergence Rates for Stochastic Hierarchical Optimization</title>
      <link>https://arxiv.org/abs/2509.15399</link>
      <description>arXiv:2509.15399v2 Announce Type: replace-cross 
Abstract: Hierarchical optimization refers to problems with interdependent decision variables and objectives, such as minimax and bilevel formulations. While various algorithms have been proposed, existing methods and analyses lack adaptivity in stochastic optimization settings: they cannot achieve optimal convergence rates across a wide spectrum of gradient noise levels without prior knowledge of the noise magnitude. In this paper, we propose novel adaptive algorithms for two important classes of stochastic hierarchical optimization problems: nonconvex-strongly-concave minimax optimization and nonconvex-strongly-convex bilevel optimization. Our algorithms achieve sharp convergence rates of $\widetilde{O}(1/\sqrt{T} + \sqrt{\bar{\sigma}}/T^{1/4})$ in $T$ iterations for the gradient norm, where $\bar{\sigma}$ is an upper bound on the stochastic gradient noise. Notably, these rates are obtained without prior knowledge of the noise level, thereby enabling automatic adaptivity in both low and high-noise regimes. To our knowledge, this work provides the first adaptive and sharp convergence guarantees for stochastic hierarchical optimization. Our algorithm design combines the momentum normalization technique with novel adaptive parameter choices. Extensive experiments on synthetic and deep learning tasks demonstrate the effectiveness of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15399v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaochuan Gong, Jie Hao, Mingrui Liu</dc:creator>
    </item>
    <item>
      <title>NPN: Non-Linear Projections of the Null-Space for Imaging Inverse Problems</title>
      <link>https://arxiv.org/abs/2510.01608</link>
      <description>arXiv:2510.01608v2 Announce Type: replace-cross 
Abstract: Imaging inverse problems aim to recover high-dimensional signals from undersampled, noisy measurements, a fundamentally ill-posed task with infinite solutions in the null-space of the sensing operator. To resolve this ambiguity, prior information is typically incorporated through handcrafted regularizers or learned models that constrain the solution space. However, these priors typically ignore the task-specific structure of that null-space. In this work, we propose Non-Linear Projections of the Null-Space (NPN), a novel class of regularization that, instead of enforcing structural constraints in the image domain, promotes solutions that lie in a low-dimensional projection of the sensing matrix's null-space with a neural network. Our approach has two key advantages: (1) Interpretability: by focusing on the structure of the null-space, we design sensing-matrix-specific priors that capture information orthogonal to the signal components that are fundamentally blind to the sensing process. (2) Flexibility: NPN is adaptable to various inverse problems, compatible with existing reconstruction frameworks, and complementary to conventional image-domain priors. We provide theoretical guarantees on convergence and reconstruction accuracy when used within plug-and-play methods. Empirical results across diverse sensing matrices demonstrate that NPN priors consistently enhance reconstruction fidelity in various imaging inverse problems, such as compressive sensing, deblurring, super-resolution, computed tomography, and magnetic resonance imaging, with plug-and-play methods, unrolling networks, deep image prior, and diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01608v2</guid>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roman Jacome, Romario Gualdr\'on-Hurtado, Leon Suarez, Henry Arguello</dc:creator>
    </item>
  </channel>
</rss>
