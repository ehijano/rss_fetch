<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Jun 2025 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Data-driven balanced truncation for second-order systems with generalized proportional damping</title>
      <link>https://arxiv.org/abs/2506.10118</link>
      <description>arXiv:2506.10118v1 Announce Type: new 
Abstract: Structured reduced-order modeling is a central component in the computer-aided design of control systems in which cheap-to-evaluate low-dimensional models with physically meaningful internal structures are computed. In this work, we develop a new approach for the structured data-driven surrogate modeling of linear dynamical systems described by second-order time derivatives via balanced truncation model-order reduction. The proposed method is a data-driven reformulation of position-velocity balanced truncation for second-order systems and generalizes the quadrature-based balanced truncation for unstructured first-order systems to the second-order case. The computed surrogates encode a generalized proportional damping structure, and the damping coefficients are inferred solely from data by minimizing a least-squares error over the coefficients. Several numerical examples demonstrate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10118v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sean Reiter, Steffen W. R. Werner</dc:creator>
    </item>
    <item>
      <title>R-PINN: Recovery-type a-posteriori estimator enhanced adaptive PINN</title>
      <link>https://arxiv.org/abs/2506.10243</link>
      <description>arXiv:2506.10243v1 Announce Type: new 
Abstract: In recent years, with the advancements in machine learning and neural networks, algorithms using physics-informed neural networks (PINNs) to solve PDEs have gained widespread applications. While these algorithms are well-suited for a wide range of equations, they often exhibit suboptimal performance when applied to equations with large local gradients, resulting in substantial localized errors. To address this issue, this paper proposes an adaptive PINN algorithm designed to improve accuracy in such cases. The core idea of the algorithm is to adaptively adjust the distribution of collocation points based on the recovery-type a-posterior error of the current numerical solution, enabling a better approximation of the true solution. This approach is inspired by the adaptive finite element method. By combining the recovery-type a-posteriori estimator, a gradient-recovery estimator commonly used in the adaptive finite element method (FEM) with PINNs, we introduce the Recovery-type a-posteriori estimator enhanced adaptive PINN (R-PINN) and compare its performance with a typical adaptive PINN algorithm, FI-PINN. Our results demonstrate that R-PINN achieves faster convergence with fewer adaptive points and significantly outperforms in the cases with multiple regions of large errors than FI-PINN. Notably, our method is a hybrid numerical approach for solving partial differential equations, integrating adaptive FEM with PINNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10243v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rongxin Lu, Jiwei Jia, Young Ju Lee, Zheng Lu, Chensong Zhang</dc:creator>
    </item>
    <item>
      <title>Enhanced randomized Douglas-Rachford method: Improved probabilities and adaptive momentum</title>
      <link>https://arxiv.org/abs/2506.10261</link>
      <description>arXiv:2506.10261v1 Announce Type: new 
Abstract: Randomized iterative methods have gained recent interest in machine learning and signal processing for solving large-scale linear systems. One such example is the randomized Douglas-Rachford (RDR) method, which updates the iterate by reflecting it through two randomly selected hyperplanes and taking a convex combination with the current point. In this work, we enhance RDR by introducing improved sampling strategies and an adaptive heavy-ball momentum scheme. Specifically, we incorporate without-replacement and volume sampling into RDR, and establish stronger convergence guarantees compared to conventional i.i.d. sampling. Furthermore, we develop an adaptive momentum mechanism that dynamically adjusts step sizes and momentum parameters based on previous iterates, and prove that the resulting method achieves linear convergence in expectation with improved convergence bounds. Numerical experiments demonstrate that the enhanced RDR method consistently outperforms the original version, providing substantial practical benefits across a range of problem settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10261v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liqi Guo, Ruike Xiang, Deren Han, Jiaxin Xie</dc:creator>
    </item>
    <item>
      <title>Complex scaling for open waveguides</title>
      <link>https://arxiv.org/abs/2506.10263</link>
      <description>arXiv:2506.10263v1 Announce Type: new 
Abstract: In this work we analyze the complex scaling method applied to the problem of time-harmonic scalar wave propagation in junctions between `leaky,' or open dielectric waveguides. In [arXiv:2302.04353, arXiv:2310.05816, arXiv:2401.04674, arXiv:2411.11204], it was shown that under suitable assumptions the problem can be reduced to a system of Fredholm second-kind integral equations on an infinite interface, transverse to the waveguides. Here, we show that the kernels appearing in the integral equation admit a rapidly decaying analytic continuation on certain natural totally real submanifolds of $\mathbb{C}^2.$ We then show that for suitable, physically-meaningful, boundary data the resulting solutions to the integral equations themselves admit analytic continuation and satisfy related asymptotic estimates. By deforming the integral equation to a suitable contour, the decay in the kernels, density, and data enable straightforward discretization and truncation, with an error that decays exponentially in the truncation length. We illustrate our results with several representative numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10263v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles L. Epstein, Tristan Goodwill, Jeremy Hoskins, Solomon Quinn, Manas Rachh</dc:creator>
    </item>
    <item>
      <title>Penalty-Based Feedback Control and Finite Element Analysis for the Stabilization of Nonlinear Reaction-Diffusion Equations</title>
      <link>https://arxiv.org/abs/2506.10428</link>
      <description>arXiv:2506.10428v1 Announce Type: new 
Abstract: In this work, first we employ the penalization technique to analyze the Dirichlet boundary feedback control problem pertaining to reaction-diffusion equation. We establish the stabilization result of the equivalent Robin problem in the \(H^{2}\)-norm with respect to the penalty parameter. Furthermore, we prove that the solution of the penalized control problem converges to the corresponding solution of the Dirichlet boundary feedback control problem as the penalty parameter \(\epsilon\) approaches zero. A \(C^{0}\)-conforming finite element method is applied to this problem for the spatial variable while keeping the time variable continuous. We discuss the stabilization of the semi-discrete scheme for the penalized control problem and present an error analysis of its solution. Finally, we validate our theoretical findings through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10428v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sudeep Kundu, Shishu pal Singh</dc:creator>
    </item>
    <item>
      <title>Stability analysis of the free-surface Stokes problem and an unconditionally stable explicit scheme</title>
      <link>https://arxiv.org/abs/2506.10447</link>
      <description>arXiv:2506.10447v1 Announce Type: new 
Abstract: Accurate simulations of ice sheet dynamics, mantle convection, lava flow, and other highly viscous free-surface flows involve solving the coupled Stokes/free-surface equations. In this paper, we theoretically analyze the stability and conservation properties of the weak form of this system for Newtonian fluids and non-Newtonian fluids, at both the continuous and discrete levels. We perform the fully discrete stability analysis for finite element methods used in space with explicit and implicit Euler time-stepping methods used in time. Motivated by the theory, we propose a stabilization term designed for the explicit Euler discretization, which ensures unconditional time stability and permits conservation of the domain volume. Numerical experiments validate and support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10447v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Igor Tominec, Lukas Lundgren, Andr\'e L\"ofgren, Josefin Ahlkrona</dc:creator>
    </item>
    <item>
      <title>Convergence of adaptive boundary element methods driven by functional a posteriori error estimates</title>
      <link>https://arxiv.org/abs/2506.10499</link>
      <description>arXiv:2506.10499v1 Announce Type: new 
Abstract: The recent work [Kurz et al., Numer. Math., 147 (2021)] proposed functional a posteriori error estimates for boundary element methods (BEMs) together with a related adaptive mesh-refinement strategy. Unlike most a posteriori BEM error estimators, the proposed functional error estimators cover Galerkin as well as collocation BEM and, more importantly, do not control the error in the integral density on the boundary, but the error of the potential approximation in the domain, which is of greater relevance in practice. The estimates rely on the numerical solution of auxiliary problems on auxiliary strip domains along the boundary, where the strips are affected by the adaptive mesh-refinement and hence vary. For Galerkin BEM, we prove that the proposed adaptive mesh-refinement algorithm yields convergence of the potential error to zero. Due to the structural difference to residual-based estimators, the proof requires new ideas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10499v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Freiszlinger, Dirk Pauly, Dirk Praetorius</dc:creator>
    </item>
    <item>
      <title>A semi-Lagrangian scheme for First-Order Mean Field Games based on monotone operators</title>
      <link>https://arxiv.org/abs/2506.10509</link>
      <description>arXiv:2506.10509v1 Announce Type: new 
Abstract: We construct a semi-Lagrangian scheme for first-order, time-dependent, and non-local Mean Field Games. The convergence of the scheme to a weak solution of the system is analyzed by exploiting a key monotonicity property. To solve the resulting discrete problem, we implement a Learning Value Algorithm, prove its convergence, and propose an acceleration strategy based on a Policy iteration method. Finally, we present numerical experiments that validate the effectiveness of the proposed schemes and show that the accelerated version significantly improves performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10509v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elisabetta Carlini, Valentina Coscetti</dc:creator>
    </item>
    <item>
      <title>Non-augmented velocity-vorticity-pressure formulation for the Navier--Stokes--Brinkman--Forchheimer problem</title>
      <link>https://arxiv.org/abs/2506.10533</link>
      <description>arXiv:2506.10533v1 Announce Type: new 
Abstract: The flow of incompressible fluid in highly permeable porous media in vorticity - velocity - Bernoulli pressure form leads to a double saddle-point problem in the Navier--Stokes--Brinkman--Forchheimer equations. The paper establishes, for small sources, the existence of solutions on the continuous and discrete level of lowest-order piecewise divergence-free Crouzeix--Raviart finite elements. The vorticity employs a vector version of the pressure space with normal and tangential velocity jump penalisation terms. A simple Raviart--Thomas interpolant leads to pressure-robust a priori error estimates. An explicit residual-based a posteriori error estimate allows for efficient and reliable a posteriori error control. The efficiency for the Forchheimer nonlinearity requires a novel discrete inequality of independent interest. The implementation is based upon a light-weight forest-of-trees data structure handled by a highly parallel set of adaptive {mesh refining} algorithms. Numerical simulations reveal robustness of the a posteriori error estimates and improved convergence rates by adaptive mesh-refining.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10533v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Santiago Badia, Carsten Carstensen, Alberto F. Martin, Ricardo Ruiz-Baier, Segundo Villa-Fuentes</dc:creator>
    </item>
    <item>
      <title>Structure and asymptotic preserving deep neural surrogates for uncertainty quantification in multiscale kinetic equations</title>
      <link>https://arxiv.org/abs/2506.10636</link>
      <description>arXiv:2506.10636v1 Announce Type: new 
Abstract: The high dimensionality of kinetic equations with stochastic parameters poses major computational challenges for uncertainty quantification (UQ). Traditional Monte Carlo (MC) sampling methods, while widely used, suffer from slow convergence and high variance, which become increasingly severe as the dimensionality of the parameter space grows. To accelerate MC sampling, we adopt a multiscale control variates strategy that leverages low-fidelity solutions from simplified kinetic models to reduce variance. To further improve sampling efficiency and preserve the underlying physics, we introduce surrogate models based on structure and asymptotic preserving neural networks (SAPNNs). These deep neural networks are specifically designed to satisfy key physical properties, including positivity, conservation laws, entropy dissipation, and asymptotic limits. By training the SAPNNs on low-fidelity models and enriching them with selected high-fidelity samples from the full Boltzmann equation, our method achieves significant variance reduction while maintaining physical consistency and asymptotic accuracy. The proposed methodology enables efficient large-scale prediction in kinetic UQ and is validated across both homogeneous and nonhomogeneous multiscale regimes. Numerical results demonstrate improved accuracy and computational efficiency compared to standard MC techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10636v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Chen, Giacomo Dimarco, Lorenzo Pareschi</dc:creator>
    </item>
    <item>
      <title>Alternating steepest descent methods for tensor completion with applications to spectromicroscopy</title>
      <link>https://arxiv.org/abs/2506.10661</link>
      <description>arXiv:2506.10661v1 Announce Type: new 
Abstract: In this paper we develop two new Tensor Alternating Steepest Descent algorithms for tensor completion in the low-rank $\star_{M}$-product format, whereby we aim to reconstruct an entire low-rank tensor from a small number of measurements thereof. Both algorithms are rooted in the Alternating Steepest Descent (ASD) method for matrix completion, first proposed in [J. Tanner and K. Wei, Appl. Comput. Harmon. Anal., 40 (2016), pp. 417-429]. In deriving the new methods we target the X-ray spectromicroscopy undersampling problem, whereby data are collected by scanning a specimen on a rectangular viewpoint with X-ray beams of different energies. The recorded absorptions coefficients of the mixed specimen materials are naturally stored in a third-order tensor, with spatial horizontal and vertical axes, and an energy axis. To speed the X-ray spectromicroscopy measurement process up, only a fraction of tubes from (a reshaped version of) this tensor are fully scanned, leading to a tensor completion problem. In this framework we can apply any transform (such as the Fourier transform) to the tensor tube by tube, providing a natural way to work with the $\star_{M}$-tensor algebra, and propose: (1) a tensor completion algorithm that is essentially ASD reformulated in the $\star_{M}$-induced metric space and (2) a tensor completion algorithm that solves a set of (readily parallelizable) independent matrix completion problems for the frontal slices of the transformed tensor. The two new methods are tested on real X-ray spectromicroscopy data, demonstrating that they achieve the same reconstruction error with fewer samples from the tensor compared to the matrix completion algorithms applied to a flattened tensor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10661v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oliver Townsend, Sergey Dolgov, Silvia Gazzola, Misha Kilmer</dc:creator>
    </item>
    <item>
      <title>Semi-discrete moduli of smoothness and their applications in one- and two- sided error estimates</title>
      <link>https://arxiv.org/abs/2506.10723</link>
      <description>arXiv:2506.10723v1 Announce Type: new 
Abstract: In this paper, we introduce a new semi-discrete modulus of smoothness, which generalizes the definition given by Kolomoitsev and Lomako (KL) in 2023 (in the paper published in the J. Approx. Theory), and we establish very general one- and two- sided error estimates under non-restrictive assumptions. The proposed results have been proved exploiting the regularization and approximation properties of certain Steklov integrals introduced by Sendov and Popov in 1983, and differ from the ones given by Kolomoitsev and Lomako. In addition, the proof of the original KL approximation theorems were strictly related to the application of certain classical results of the trigonometric best approximation, and thus, they are applicable only for operators of the trigonometric type. By the definition of semi-discrete moduli of smoothness here proposed, we are able to deduce applications also for operators that are not necessarily of the trigonometric type, and can also be used to derive sharper estimates than those that can be achieved by the classical averaged moduli of smoothness ($\tau$-moduli). Furthermore, a Rathore-type theorem is established, and a new notion of K-functional is also introduced showing its equivalence with the semi-discrete modulus of smoothness and its realization. One-sided estimates of approximation can be established for classical operators on bounded domains, such as the Bernstein polynomials. In the case of approximation operators on the whole real line, one-sided estimates can be achieved, e.g., for the Shannon sampling (cardinal) series, as well as for the so-called generalized sampling operators. At the end of the paper, the case of algebraic Lagrange approximation has been considered, showing the main open problems in order to derive two-sided error estimates in this noteworthy case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10723v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Danilo Costarelli, Donato Lavella</dc:creator>
    </item>
    <item>
      <title>Reduced-Order Time Splitting for Navier-Stokes with Open Boundaries</title>
      <link>https://arxiv.org/abs/2506.10763</link>
      <description>arXiv:2506.10763v1 Announce Type: new 
Abstract: In this work, we propose a Proper Orthogonal Decomposition-Reduced Order Model (POD-ROM) applied to time-splitting schemes for solving the Navier-Stokes equations with open boundary conditions. In this method, we combine three strategies to reduce the computing time to solve NSE: time splitting, reduction of the computational domain through non-standard treatment of open boundary conditions and reduced order modelling. To make the work self-contained, we first present the formulation of the time-splitting scheme applied to the Navier-Stokes equations with open boundary conditions, employing a first-order Euler time discretization and deriving the non-standard boundary condition for pressure. Then, we construct a Galerkin projection-based ROM using POD with two different treatments of the pressure boundary condition on the outlet. We propose a comparative performance analysis between the standard projection-based POD-ROM (fully intrusive) and a hybrid POD-ROM that combines a projection-based approach (intrusive) with a data-driven technique (non-intrusive) using Radial Basis Functions (RBF). We illustrate this comparison through two different numerical tests: the flow in a bifurcated tube and the benchmark numerical test of the flow past cylinder, numerically investigating the efficiency and accuracy of both ROMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10763v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mejdi Aza\"iez, Tom\'as Chac\'on Rebollo, Carlos N\'u\~nez Fern\'andez, Samuele Rubino</dc:creator>
    </item>
    <item>
      <title>A Combined Parallel-in-time Direct Inverse (ParaDIn)-Parareal Method for Nonlinear Differential Equations</title>
      <link>https://arxiv.org/abs/2506.10820</link>
      <description>arXiv:2506.10820v1 Announce Type: new 
Abstract: As has been shown in our previous work, the parallel-in-time direct inverse (ParaDIn) method introduced by Yamaleev and Paudel in (arXiv: 2406.00878v1, 2024) imposes some constraint on the maximum number of time levels, $N_t$, that can be integrated in parallel. To circumvent this problem and further increase the speedup, we combine the ParaDIn method with the Parareal algorithm to efficiently parallelize the first-order time derivative term in nonlinear partial differential equations discretized by the method of lines. The main idea of the proposed approach is to use a block-Jacobi preconditioner, so that each block is solved by using the ParaDIn method. To accelerate the convergence of Jacobi iterations, we use the Parareal method which can be interpreted as a two-level multigrid method in time. In contrast to the conventional Parareal algorithm whose coarse grid correction step is performed sequentially, both the coarse- and fine-grid propagators in the proposed approach are implemented in parallel by using the ParaDIn method, thus significantly increasing the parallel performance of the combined algorithm. Numerical results show that the new combined ParaDIn-Parareal method provides the speedup of up to 124 on 480 computing cores as compared with the sequential first-order implicit backward difference (BDF1) scheme for the 2-D nonlinear heat and Burgers equations with both smooth and discontinuous solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10820v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Subhash Paudel, Nail K. Yamaleev</dc:creator>
    </item>
    <item>
      <title>Numerical approximation of a PDE-constrained Optimization problem that appears in Data-Driven Computational Mechanics</title>
      <link>https://arxiv.org/abs/2506.10894</link>
      <description>arXiv:2506.10894v1 Announce Type: new 
Abstract: We investigate an optimization problem that arises when working within the paradigm of Data-Driven Computational Mechanics. In the context of the diffusion-reaction problem, such an optimization problem seeks for the continuous primal fields (gradient and flux) that are closest to some predefined discrete fields taken from a material data set. The optimization is performed over primal fields that satisfy the physical conservation law and the geometrical compatibility. We consider a reaction term in the conservation law, which has the effect of coupling all the optimality conditions. We first establish the well-posedness in the continuous setting. Then, we propose stable finite element discretizations that consistently approximate the continuous formulation, preserving its saddle-point structure and allowing for equal-order interpolation of all fields. Finally, we demonstrate the effectiveness of the proposed methods through a set of numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10894v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pedro B. Bazon, Cristian G. Gebhardt, Gustavo C. Buscaglia, Roberto F. Ausas</dc:creator>
    </item>
    <item>
      <title>Accelerating Newton-Schulz Iteration for Orthogonalization via Chebyshev-type Polynomials</title>
      <link>https://arxiv.org/abs/2506.10935</link>
      <description>arXiv:2506.10935v1 Announce Type: new 
Abstract: The problem of computing optimal orthogonal approximation to a given matrix has attracted growing interest in machine learning. Notable applications include the recent Muon optimizer or Riemannian optimization on the Stiefel manifold. Among existing approaches, the Newton-Schulz iteration has emerged as a particularly effective solution, as it relies solely on matrix multiplications and thus achieves high computational efficiency on GPU hardware. Despite its efficiency, the method has inherent limitations - its coefficients are fixed and thus not optimized for a given matrix. In this paper we address this issue by proposing a Chebyshev-optimized version of Newton-Schulz (CANS). Based on the Chebyshev's alternance theorem, we theoretically derive optimal coefficients for the 3-rd order Newton-Schulz iteration and apply a Remez algorithm to compute optimal higher-degree polynomials. We leverage these polynomials to construct controlled approximate orthogonalization schemes, which is of interest in deep learning applications. Practically, we demonstrate the method's effectiveness in two key applications: orthogonalization in the Muon optimizer, and providing an efficient retraction alternative for Riemannian optimization on the Stiefel manifold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10935v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ekaterina Grishina, Matvey Smirnov, Maxim Rakhuba</dc:creator>
    </item>
    <item>
      <title>Interpretable and flexible non-intrusive reduced-order models using reproducing kernel Hilbert spaces</title>
      <link>https://arxiv.org/abs/2506.10224</link>
      <description>arXiv:2506.10224v1 Announce Type: cross 
Abstract: This paper develops an interpretable, non-intrusive reduced-order modeling technique using regularized kernel interpolation. Existing non-intrusive approaches approximate the dynamics of a reduced-order model (ROM) by solving a data-driven least-squares regression problem for low-dimensional matrix operators. Our approach instead leverages regularized kernel interpolation, which yields an optimal approximation of the ROM dynamics from a user-defined reproducing kernel Hilbert space. We show that our kernel-based approach can produce interpretable ROMs whose structure mirrors full-order model structure by embedding judiciously chosen feature maps into the kernel. The approach is flexible and allows a combination of informed structure through feature maps and closure terms via more general nonlinear terms in the kernel. We also derive a computable a posteriori error bound that combines standard error estimates for intrusive projection-based ROMs and kernel interpolants. The approach is demonstrated in several numerical experiments that include comparisons to operator inference using both proper orthogonal decomposition and quadratic manifold dimension reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10224v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro N Diaz, Shane A McQuarrie, John T Tencer, Patrick J Blonigan</dc:creator>
    </item>
    <item>
      <title>Fast Ramanujan--type Series for Logarithms. Part II</title>
      <link>https://arxiv.org/abs/2506.10321</link>
      <description>arXiv:2506.10321v1 Announce Type: cross 
Abstract: This work extends the results of the preprint Ramanujan type Series for Logarithms, Part I, arXiv:2506.08245, which introduced single hypergeometric type identities for the efficient computing of $\log(p)$, where $p\in\mathbb{Z}_{&gt;1}$. We present novel formulas for arctangents and methods for a very fast multiseries evaluation of logarithms. Building upon a $\mathcal{O}((p-1)^{6})$ Ramanujan type series asymptotic approximation for $\log(p)$ as $p\rightarrow1$, formulas for computing $n$ simultaneous logarithms are developed. These formulas are derived by solving an integer programming problem to identify optimal variable values within a finite lattice $\mathbb{Z}^{n}$. This approach yields linear combinations of series that provide: (i) highly efficient formulas for single logarithms of natural numbers and (ii) the fastest known hypergeometric formulas for multivalued logarithms of $n$ selected integers in $\mathbb{Z}_{&gt;1}$. An application of these results was to extend the number of decimal places known for log(10) up to 2.0$\cdot$10$^{12}$ digits (June 06 2025).</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10321v1</guid>
      <category>math.NT</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jorge Zuniga</dc:creator>
    </item>
    <item>
      <title>On a mean-field Pontryagin minimum principle for stochastic optimal control</title>
      <link>https://arxiv.org/abs/2506.10506</link>
      <description>arXiv:2506.10506v1 Announce Type: cross 
Abstract: This papers outlines a novel extension of the classical Pontryagin minimum (maximum) principle to stochastic optimal control problems. Contrary to the well-known stochastic Pontryagin minimum principle involving forward-backward stochastic differential equations, the proposed formulation is deterministic and of mean-field type. The Hamiltonian structure of the proposed Pontryagin minimum principle is achieved via the introduction of an appropriate gauge variable. The gauge freedom can be used to decouple the forward and reverse time equations; hence simplifying the solution of the underlying boundary value problem. We also consider infinite horizon discounted cost optimal control problems. In this case, the mean-field formulation allows converting the computation of the desired optimal control law into solving a pair of forward mean-field ordinary differential equations. The proposed mean-field formulation of the Pontryagin minimum principle is tested numerically for a controlled inverted pendulum and a controlled Lorenz-63 system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10506v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manfred Opper, Sebastian Reich</dc:creator>
    </item>
    <item>
      <title>PDESpectralRefiner: Achieving More Accurate Long Rollouts with Spectral Adjustment</title>
      <link>https://arxiv.org/abs/2506.10711</link>
      <description>arXiv:2506.10711v1 Announce Type: cross 
Abstract: Generating accurate and stable long rollouts is a notorious challenge for time-dependent PDEs (Partial Differential Equations). Recently, motivated by the importance of high-frequency accuracy, a refiner model called PDERefiner utilizes diffusion models to refine outputs for every time step, since the denoising process could increase the correctness of modeling high frequency part. For 1-D Kuramoto-Sivashinsky equation, refiner models can degrade the amplitude of high frequency part better than not doing refinement process. However, for some other cases, the spectrum might be more complicated. For example, for a harder PDE like Navior-Stokes equation, diffusion models could over-degrade the higher frequency part. This motivates us to release the constraint that each frequency weighs the same. We enhance our refiner model with doing adjustments on spectral space, which recovers Blurring diffusion models. We developed a new v-prediction technique for Blurring diffusion models, recovering the MSE training objective on the first refinement step. We show that in this case, for different model backbones, such as U-Net and neural operators, the outputs of PDE-SpectralRefiner are more accurate for both one-step MSE loss and rollout loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10711v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Li Luo, Shangsong Liang</dc:creator>
    </item>
    <item>
      <title>Data-Driven Prediction of Dynamic Interactions Between Robot Appendage and Granular Material</title>
      <link>https://arxiv.org/abs/2506.10875</link>
      <description>arXiv:2506.10875v1 Announce Type: cross 
Abstract: An alternative data-driven modeling approach has been proposed and employed to gain fundamental insights into robot motion interaction with granular terrain at certain length scales. The approach is based on an integration of dimension reduction (Sequentially Truncated Higher-Order Singular Value Decomposition), surrogate modeling (Gaussian Process), and data assimilation techniques (Reduced Order Particle Filter). This approach can be used online and is based on offline data, obtained from the offline collection of high-fidelity simulation data and a set of sparse experimental data. The results have shown that orders of magnitude reduction in computational time can be obtained from the proposed data-driven modeling approach compared with physics-based high-fidelity simulations. With only simulation data as input, the data-driven prediction technique can generate predictions that have comparable accuracy as simulations. With both simulation data and sparse physical experimental measurement as input, the data-driven approach with its embedded data assimilation techniques has the potential in outperforming only high-fidelity simulations for the long-horizon predictions. In addition, it is demonstrated that the data-driven modeling approach can also reproduce the scaling relationship recovered by physics-based simulations for maximum resistive forces, which may indicate its general predictability beyond a case-by-case basis. The results are expected to help robot navigation and exploration in unknown and complex terrains during both online and offline phases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10875v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanjin Wang, Xiangxue Zhao, Shapour Azarm, Balakumar Balachandran</dc:creator>
    </item>
    <item>
      <title>Spectral Analysis of Discretized Boundary Integral Operators in 3D: a High-Frequency Perspective</title>
      <link>https://arxiv.org/abs/2506.10880</link>
      <description>arXiv:2506.10880v1 Announce Type: cross 
Abstract: When modeling propagation and scattering phenomena using integral equations discretized by the boundary element method, it is common practice to approximate the boundary of the scatterer with a mesh comprising elements of size approximately equal to a fraction of the wavelength $\lambda$ of the incident wave, e.g., $\lambda/10$. In this work, by analyzing the spectra of the operator matrices, we show a discrepancy with respect to the continuous operators which grows with the simulation frequency, challenging the common belief that the aforementioned widely used discretization approach is sufficient to maintain the accuracy of the solution constant when increasing the frequency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10880v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V. Giunzioni, A. Merlini, F. P. Andriulli</dc:creator>
    </item>
    <item>
      <title>A space-time interface-fitted method for moving-subdomain distributed control problems with energy regularization</title>
      <link>https://arxiv.org/abs/2506.10924</link>
      <description>arXiv:2506.10924v1 Announce Type: cross 
Abstract: This paper investigates a space-time interface-fitted approximation of a moving-interface optimal control problem with energy regularization. We reformulate the optimality conditions into a variational problem involving both the state and adjoint. This problem is shown to be equivalent to our optimal control problem. Based on fully unstructured, space-time interface-fitted meshes, we propose and analyze a Petrov-Galerkin approximation of the problem. An optimal error estimate with respect to a discrete norm is established under a specific regularity assumption on the state and adjoint. Several numerical results are presented to corroborate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10924v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Quang Huy Nguyen, Phuong Cuc Hoang, Van Chien Le, Thi Thanh Mai Ta</dc:creator>
    </item>
    <item>
      <title>Principled Approaches for Extending Neural Architectures to Function Spaces for Operator Learning</title>
      <link>https://arxiv.org/abs/2506.10973</link>
      <description>arXiv:2506.10973v1 Announce Type: cross 
Abstract: A wide range of scientific problems, such as those described by continuous-time dynamical systems and partial differential equations (PDEs), are naturally formulated on function spaces. While function spaces are typically infinite-dimensional, deep learning has predominantly advanced through applications in computer vision and natural language processing that focus on mappings between finite-dimensional spaces. Such fundamental disparities in the nature of the data have limited neural networks from achieving a comparable level of success in scientific applications as seen in other fields. Neural operators are a principled way to generalize neural networks to mappings between function spaces, offering a pathway to replicate deep learning's transformative impact on scientific problems. For instance, neural operators can learn solution operators for entire classes of PDEs, e.g., physical systems with different boundary conditions, coefficient functions, and geometries. A key factor in deep learning's success has been the careful engineering of neural architectures through extensive empirical testing. Translating these neural architectures into neural operators allows operator learning to enjoy these same empirical optimizations. However, prior neural operator architectures have often been introduced as standalone models, not directly derived as extensions of existing neural network architectures. In this paper, we identify and distill the key principles for constructing practical implementations of mappings between infinite-dimensional function spaces. Using these principles, we propose a recipe for converting several popular neural architectures into neural operators with minimal modifications. This paper aims to guide practitioners through this process and details the steps to make neural operators work in practice. Our code can be found at https://github.com/neuraloperator/NNs-to-NOs</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10973v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julius Berner, Miguel Liu-Schiaffini, Jean Kossaifi, Valentin Duruisseaux, Boris Bonev, Kamyar Azizzadenesheli, Anima Anandkumar</dc:creator>
    </item>
    <item>
      <title>Coarse spaces for non-symmetric two-level preconditioners based on local extended generalized eigenproblems</title>
      <link>https://arxiv.org/abs/2404.02758</link>
      <description>arXiv:2404.02758v2 Announce Type: replace 
Abstract: Domain decomposition (DD) methods are a natural way to take advantage of parallel computers when solving large scale linear systems. Their scalability depends on the design of the coarse space used in the two-level method. The analysis of adaptive coarse spaces we present here is quite general since it applies to symmetric and non-symmetric problems, to symmetric preconditioners such as the additive Schwarz method (ASM) and to the non-symmetric preconditioner restricted additive Schwarz (RAS), as well as to exact or inexact subdomain solves. The coarse space is built by solving generalized eigenproblems in the subdomains and applying a well-chosen operator to the selected eigenvectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02758v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fr\'ed\'eric Nataf, Emile Parolin</dc:creator>
    </item>
    <item>
      <title>An adaptive Newton-based free-boundary Grad-Shafranov solver</title>
      <link>https://arxiv.org/abs/2407.03499</link>
      <description>arXiv:2407.03499v2 Announce Type: replace 
Abstract: Equilibria in magnetic confinement devices result from force balancing between the Lorentz force and the plasma pressure gradient. In an axisymmetric configuration like a tokamak, such an equilibrium is described by an elliptic equation for the poloidal magnetic flux, commonly known as the Grad--Shafranov equation. It is challenging to develop a scalable and accurate free-boundary Grad--Shafranov solver, since it is a fully nonlinear optimization problem that simultaneously solves for the magnetic field coil current outside the plasma to control the plasma shape. In this work, we develop a Newton-based free-boundary Grad--Shafranov solver using adaptive finite elements and preconditioning strategies. The free-boundary interaction leads to the evaluation of a domain-dependent nonlinear form of which its contribution to the Jacobian matrix is achieved through shape calculus. The optimization problem aims to minimize the distance between the plasma boundary and specified control points while satisfying two non-trivial constraints, which correspond to the nonlinear finite element discretization of the Grad--Shafranov equation and a constraint on the total plasma current involving a nonlocal coupling term. The linear system is solved by a block factorization, and AMG is called for subblock elliptic operators. The unique contributions of this work include the treatment of a global constraint, preconditioning strategies, nonlocal reformulation, and the implementation of adaptive finite elements. It is found that the resulting Newton solver is robust, successfully reducing the nonlinear residual to 1e-6 and lower in a small handful of iterations while addressing the challenging case to find a Taylor state equilibrium where conventional Picard-based solvers fail to converge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03499v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel A. Serino, Qi Tang, Xian-Zhu Tang, Tzanio V. Kolev, Konstantin Lipnikov</dc:creator>
    </item>
    <item>
      <title>Deflation Techniques for Finding Multiple Local Minima of a Nonlinear Least Squares Problem</title>
      <link>https://arxiv.org/abs/2409.14438</link>
      <description>arXiv:2409.14438v3 Announce Type: replace 
Abstract: In this paper we generalize the technique of deflation to define two new methods to systematically find many local minima of a nonlinear least squares problem. The methods are based on the Gauss-Newton algorithm, and as such do not require the calculation of a Hessian matrix. They also require fewer deflations than for applying the deflated Newton method on the first order optimality conditions, as the latter finds all stationary points, not just local minima. One application of interest covered in this paper is the inverse eigenvalue problem (IEP) associated with the modelling of spectroscopic data of relevance to the physical and chemical sciences. Open source MATLAB code is provided at https://github.com/AlbanBloorRiley/DeflatedGaussNewton.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14438v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alban Bloor Riley, Marcus Webb, Michael L Baker</dc:creator>
    </item>
    <item>
      <title>BDF schemes for accelerated gradient flows in projection-free approximation of nonconvex constrained variational minimization</title>
      <link>https://arxiv.org/abs/2409.14670</link>
      <description>arXiv:2409.14670v2 Announce Type: replace 
Abstract: We propose novel algorithms combining accelerated gradient flows with linearized projection-free treatments of non-convex constraints and BDF pseudo-temporal discretization for quadratic energy minimization. A general framework is developed to analyze constraint violations in such projection-free techniques for quadratic constraints. This analysis proves to be universal to all projection-free iterative methods, and constraint error bounds depend solely on iterate regularity. For BDF-k(k=1,2,3,4), we derive both unconditional and conditional high-order constraint violation estimates for accelerated gradient flows using our framework. We further discover a new family of BDF-k accelerated gradient methods achieving modified energy stability for arbitrary positive integer k. Numerical experiments validate our theoretical results and demonstrate superior efficiency and accuracy compared to existing gradient flow approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14670v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guozhi Dong, Zikang Gong, Ziqing Xie, Shuo Yang</dc:creator>
    </item>
    <item>
      <title>Exact Integration for singular Zienkiewicz and Guzman-Neilan Finite Elements with Implementation</title>
      <link>https://arxiv.org/abs/2411.09485</link>
      <description>arXiv:2411.09485v2 Announce Type: replace 
Abstract: We develop a recursive integration formula for a class of rational polynomials in 2D. Based on this, we present implementations of finite elements that have rational basis functions. Specifically, we provide simple Matlab implementations of the singular Zienkiewicz and the lowest-order Guzman-Neilan finite element in 2D.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09485v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lars Diening, Johannes Storn, Tabea Tscherpel</dc:creator>
    </item>
    <item>
      <title>Guaranteed upper bounds for iteration errors and modified Kacanov schemes via discrete duality</title>
      <link>https://arxiv.org/abs/2501.16850</link>
      <description>arXiv:2501.16850v2 Announce Type: replace 
Abstract: We apply duality theory to discretized convex minimization problems to obtain computable guaranteed upper bounds for the distance of given discrete functions and the exact discrete minimizer. Furthermore, we show that the discrete duality framework extends convergence results for the Kacanov scheme to a broader class of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16850v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lars Diening, Johannes Storn</dc:creator>
    </item>
    <item>
      <title>On the approximation of the von Neumann equation in the semi-classical limit. Part II : numerical analysis</title>
      <link>https://arxiv.org/abs/2504.18177</link>
      <description>arXiv:2504.18177v2 Announce Type: replace 
Abstract: This paper is devoted to the numerical analysis of the Hermite spectral method proposed in [14], which provides, in the semi-classical limit, an asymptotic preserving approximation of the von Neumann equation. More precisely, it relies on the use of so-called Weyl's variables to effectively address the stiffness associated to the equation. Then by employing a truncated Hermite expansion of the density operator, we successfully manage this stiffness and provide error estimates by leveraging the propagation of regularity in the exact solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18177v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Golse (X), Francis Filbet (IMT)</dc:creator>
    </item>
    <item>
      <title>Equilibrium-distribution-function based mesoscopic finite-difference methods for partial differential equations: Modeling and Analysis</title>
      <link>https://arxiv.org/abs/2505.17057</link>
      <description>arXiv:2505.17057v2 Announce Type: replace 
Abstract: In this paper, based on the idea of direct discrete modeling (DDM) with equilibrium distribution functions (EDFs), we develop a general framework of the mesoscopic numerical method (MesoNM) for macroscopic partial differential equations (PDEs), including but not limited to the nonlinear convection-diffusion equation (NCDE) and the Navier-Stokes equations (NSEs). Unlike the mesoscopic lattice Boltzmann method, this kind of MesoNM is an EDF-based mesoscopic finite-difference (MesoFD) method, and by taking the moments of the MesoFD scheme, its macroscopic version, called MMFD method, can be derived directly. Both MesoFD scheme and MMFD schemes are multi-level FD methods, MesoFD scheme being mesoscopic, and MMFD scheme being its macroscopic form which has the form of the central FD scheme. They are unified FD schemes for PDEs and can be in implicit or explicit forms as needed. The macroscopic moment equations (MEs) can be derived from the MesoFD or MMFD scheme through the Taylor expansion method, and the common PDEs can be recovered from the MEs by using the direct Taylor expansion method. Moreover, the stability of the MMFD scheme is analyzed for linear CDE and liner wave equation with anisotropic diffusion, and the stability conditions of a two-level explicit MMFD scheme, a two-level $\theta$-MMFD scheme (hybrid explicit and implicit MMFD scheme), and a three-level MMFD scheme are obtained, respectively. Finally, we note that some existing lattice Boltzmann (LB) based macroscopic FD models for the NSEs and NCDE are the special cases of present MMFD, which can be considered as a unified framework of FD schemes for PDEs, from this point of view.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17057v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baochang shi, Rui Du, Zhenhua Chai</dc:creator>
    </item>
    <item>
      <title>Improved error bounds for Koopman operator and reconstructed trajectories approximations with kernel-based methods</title>
      <link>https://arxiv.org/abs/2506.09266</link>
      <description>arXiv:2506.09266v2 Announce Type: replace 
Abstract: In this article, we propose a new error bound for Koopman operator approximation using Kernel Extended Dynamic Mode Decomposition. The new estimate is $O(N^{-1/2})$, with a constant related to the probability of success of the bound, given by Hoeffding's inequality, similar to other methodologies, such as Philipp et al. Furthermore, we propose a \textit{lifting back} operator to obtain trajectories generated by embedding the initial state and iterating a linear system in a higher dimension. This naturally yields an $O(N^{-1/2})$ error bound for mean trajectories. Finally, we show numerical results including an example of nonlinear system, exhibiting successful approximation with exponential decay faster than $-1/2$, as suggested by the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09266v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diego Olgu\'in, Axel Osses, H\'ector Ram\'irez</dc:creator>
    </item>
    <item>
      <title>A Unified Framework to Enforce, Discover, and Promote Symmetry in Machine Learning</title>
      <link>https://arxiv.org/abs/2311.00212</link>
      <description>arXiv:2311.00212v3 Announce Type: replace-cross 
Abstract: Symmetry is present throughout nature and continues to play an increasingly central role in physics and machine learning. Fundamental symmetries, such as Poincar\'{e} invariance, allow physical laws discovered in laboratories on Earth to be extrapolated to the farthest reaches of the universe. Symmetry is essential to achieving this extrapolatory power in machine learning applications. For example, translation invariance in image classification allows models with fewer parameters, such as convolutional neural networks, to be trained on smaller data sets and achieve state-of-the-art performance. In this paper, we provide a unifying theoretical and methodological framework for incorporating symmetry into machine learning models in three ways: 1. enforcing known symmetry when training a model; 2. discovering unknown symmetries of a given model or data set; and 3. promoting symmetry during training by learning a model that breaks symmetries within a user-specified group of candidates when there is sufficient evidence in the data. We show that these tasks can be cast within a common mathematical framework whose central object is the Lie derivative associated with fiber-linear Lie group actions on vector bundles. We extend and unify several existing results by showing that enforcing and discovering symmetry are linear-algebraic tasks that are dual with respect to the bilinear structure of the Lie derivative. We also propose a novel way to promote symmetry by introducing a class of convex regularization functions based on the Lie derivative and nuclear norm relaxation to penalize symmetry breaking during training of machine learning models. We explain how these ideas can be applied to a wide range of machine learning models including basis function regression, dynamical systems discovery, neural networks, and neural operators acting on fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00212v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Samuel E. Otto, Nicholas Zolman, J. Nathan Kutz, Steven L. Brunton</dc:creator>
    </item>
    <item>
      <title>Differentially private and decentralized randomized power method</title>
      <link>https://arxiv.org/abs/2411.01931</link>
      <description>arXiv:2411.01931v3 Announce Type: replace-cross 
Abstract: The randomized power method has gained significant interest due to its simplicity and efficient handling of large-scale spectral analysis and recommendation tasks. However, its application to large datasets containing personal information (e.g., web interactions, search history, personal tastes) raises critical privacy problems. This paper addresses these issues by proposing enhanced privacy-preserving variants of the method. First, we propose a variant that reduces the amount of the noise required in current techniques to achieve Differential Privacy (DP). More precisely, we refine the privacy analysis so that the Gaussian noise variance no longer grows linearly with the target rank, achieving the same DP guarantees with strictly less noise. Second, we adapt our method to a decentralized framework in which data is distributed among multiple users. The decentralized protocol strengthens privacy guarantees with no accuracy penalty and a low computational and communication overhead. Our results include the provision of tighter convergence bounds for both the centralized and decentralized versions, and an empirical comparison with previous work using real recommendation datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01931v3</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julien Nicolas, C\'esar Sabater, Mohamed Maouche, Sonia Ben Mokhtar, Mark Coates</dc:creator>
    </item>
    <item>
      <title>Worth Their Weight: Randomized and Regularized Block Kaczmarz Algorithms without Preprocessing</title>
      <link>https://arxiv.org/abs/2502.00882</link>
      <description>arXiv:2502.00882v2 Announce Type: replace-cross 
Abstract: Due to the ever growing amounts of data leveraged for machine learning and scientific computing, it is increasingly important to develop algorithms that sample only a small portion of the data at a time. In the case of linear least-squares, the randomized block Kaczmarz method (RBK) is an appealing example of such an algorithm, but its convergence is only understood under sampling distributions that require potentially prohibitively expensive preprocessing steps. To address this limitation, we analyze RBK when the data is sampled uniformly, showing that its iterates converge in a Monte Carlo sense to a $\textit{weighted}$ least-squares solution. Unfortunately, for general problems the condition number of the weight matrix and the variance of the iterates can become arbitrarily large. We control these issues by incorporating regularization into the RBK iterations, yielding the regularized algorithm ReBlocK. Numerical experiments including examples arising from natural gradient optimization demonstrate that ReBlocK can outperform both RBK and minibatch stochastic gradient descent for inconsistent problems with rapidly decaying singular values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00882v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gil Goldshlager, Jiang Hu, Lin Lin</dc:creator>
    </item>
    <item>
      <title>A Generating Polynomial Based Two-Stage Optimization Method for Tensor Rank Decomposition</title>
      <link>https://arxiv.org/abs/2504.00313</link>
      <description>arXiv:2504.00313v2 Announce Type: replace-cross 
Abstract: The rank decomposition, also known as canonical polyadic (CP) or simply tensor decomposition, has a long-standing history in multilinear algebra. However, computing a CP decomposition becomes particularly challenging when the tensor's rank lies between its largest and second-largest dimensions. Moreover, a common approach to address high-order tensor decompositions is to first flatten them into an order-3 tensor, where a significant gap often exists between the largest and the second-largest dimension, also making this case crucial in practice. In such a case, traditional optimization methods, such as nonlinear least squares or alternative least squares methods, often fail to produce accurate tensor decompositions. There are also direct methods, such as the normal form algorithm and the method by Domanov and De Lathauwer, that solve tensor decompositions algebraically. However, these methods can be computationally expensive and demand substantial memory, especially when the tensor rank is high. This paper introduces a novel generating polynomial (GP) based two-stage algorithm for the order-3 nonsymmetric tensor decomposition problem, assuming the rank does not exceed the largest dimension. The proposed method reformulates the tensor decomposition problem into two sequential optimization problems. Notably, if the first-stage optimization yields only a partial solution, it will be effectively utilized in the second stage. We establish the theoretical equivalence between the CP decomposition and the global minimizers of those two-stage optimization problems. Numerical experiments demonstrate that our approach is both efficient and robust, capable of finding tensor decompositions in scenarios where the current state-of-the-art methods often fail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00313v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zequn Zheng, Hongchao Zhang, Guangming Zhou</dc:creator>
    </item>
    <item>
      <title>Solving Power System Problems using Adiabatic Quantum Computing</title>
      <link>https://arxiv.org/abs/2504.06458</link>
      <description>arXiv:2504.06458v2 Announce Type: replace-cross 
Abstract: This paper proposes a novel combinatorial optimization framework that reformulates existing power system problems into a format executable on quantum annealers. The proposed framework accommodates both normal and complex numbers and enables efficient handling of large-scale problems, thus ensuring broad applicability across power system problems. As a proof of concept, we demonstrate its applicability in two classical problems: (i) power system parameter identification, where we estimate the admittance matrix given voltage and current measurements, and (ii) power flow analysis, where we reformulate the nonlinear equations governing active and reactive power balance. The results show that the proposed framework effectively and efficiently solves both linear and nonlinear power system problems, and thus offers significant advantages in scenarios where traditional solvers face challenges, such as ill-conditioned systems and fault conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06458v2</guid>
      <category>cs.ET</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zeynab Kaseb, Matthias Moller, Peter Palensky, Pedro P. Vergara</dc:creator>
    </item>
    <item>
      <title>Centrality Change Proneness: an Early Indicator of Microservice Architectural Degradation</title>
      <link>https://arxiv.org/abs/2506.07690</link>
      <description>arXiv:2506.07690v2 Announce Type: replace-cross 
Abstract: Over the past decade, the wide adoption of Microservice Architecture has required the identification of various patterns and anti-patterns to prevent Microservice Architectural Degradation. Frequently, the systems are modelled as a network of connected services. Recently, the study of temporal networks has emerged as a way to describe and analyze evolving networks. Previous research has explored how software metrics such as size, complexity, and quality are related to microservice centrality in the architectural network. This study investigates whether temporal centrality metrics can provide insight into the early detection of architectural degradation by correlating or affecting software metrics. We reconstructed the architecture of 7 releases of an OSS microservice project with 42 services. For every service in every release, we computed the software and centrality metrics. From one of the latter, we derived a new metric, Centrality Change Proneness. We then explored the correlation between the metrics. We identified 7 size and 5 complexity metrics that have a consistent correlation with centrality, while Centrality Change Proneness did not affect the software metrics, thus providing yet another perspective and an early indicator of microservice architectural degradation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07690v2</guid>
      <category>cs.SE</category>
      <category>cs.DM</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Bakhtin, Matteo Esposito, Valentina Lenarduzzi, Davide Taibi</dc:creator>
    </item>
    <item>
      <title>mLaSDI: Multi-stage latent space dynamics identification</title>
      <link>https://arxiv.org/abs/2506.09207</link>
      <description>arXiv:2506.09207v2 Announce Type: replace-cross 
Abstract: Determining accurate numerical solutions of partial differential equations (PDEs) is an important task in many scientific disciplines. However, solvers can be computationally expensive, leading to the development of reduced-order models (ROMs). Recently, Latent Space Dynamics Identification (LaSDI) was proposed as a data-driven, non-intrusive ROM framework. LaSDI compresses the training data using an autoencoder and learns a system of user-chosen ordinary differential equations (ODEs), which govern the latent space dynamics. This allows for rapid predictions by interpolating and evolving the low-dimensional ODEs in the latent space. While LaSDI has produced effective ROMs for numerous problems, the autoencoder can have difficulty accurately reconstructing training data while also satisfying the imposed dynamics in the latent space, particularly in complex or high-frequency regimes. To address this, we propose multi-stage Latent Space Dynamics Identification (mLaSDI). With mLaSDI, several autoencoders are trained sequentially in stages, where each autoencoder learns to correct the error of the previous stages. We find that applying mLaSDI with small autoencoders results in lower prediction and reconstruction errors, while also reducing training time compared to LaSDI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09207v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Anderson, Seung Whan Chung, Youngsoo Choi</dc:creator>
    </item>
  </channel>
</rss>
