<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Aug 2025 04:01:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Score-based Diffusion Model Approach for Adaptive Learning of Stochastic Partial Differential Equation Solutions</title>
      <link>https://arxiv.org/abs/2508.06834</link>
      <description>arXiv:2508.06834v1 Announce Type: new 
Abstract: We propose a novel framework for adaptively learning the time-evolving solutions of stochastic partial differential equations (SPDEs) using score-based diffusion models within a recursive Bayesian inference setting. SPDEs play a central role in modeling complex physical systems under uncertainty, but their numerical solutions often suffer from model errors and reduced accuracy due to incomplete physical knowledge and environmental variability. To address these challenges, we encode the governing physics into the score function of a diffusion model using simulation data and incorporate observational information via a likelihood-based correction in a reverse-time stochastic differential equation. This enables adaptive learning through iterative refinement of the solution as new data becomes available. To improve computational efficiency in high-dimensional settings, we introduce the ensemble score filter, a training-free approximation of the score function designed for real-time inference. Numerical experiments on benchmark SPDEs demonstrate the accuracy and robustness of the proposed method under sparse and noisy observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06834v1</guid>
      <category>stat.CO</category>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Toan Huynh, Ruth Lopez Fajardo, Guannan Zhang, Lili Ju, Feng Bao</dc:creator>
    </item>
    <item>
      <title>An Approximate Maximum Likelihood Estimator for Discretely Observed Linear Birth-and-Death Processes</title>
      <link>https://arxiv.org/abs/2508.07527</link>
      <description>arXiv:2508.07527v1 Announce Type: new 
Abstract: Linear birth-and-death processes (LBDPs) are foundational stochastic models in population dynamics, evolutionary biology, and hematopoiesis. Estimating parameters from discretely observed data is computationally demanding due to irregular sampling, noise, and missing values. We propose a novel approximate maximum likelihood estimator (MLE) for LBDPs based on a Gaussian approximation to transition probabilities. The approach transforms estimation into a univariate optimization problem, achieving substantial computational gains without sacrificing accuracy.
  Through simulations, we show that the approximate MLE outperforms Gaussian and saddlepoint-based estimators in speed and precision under realistic noise and sparsity. Applied to longitudinal clonal hematopoiesis data, the method produces biologically meaningful growth estimates even with noisy, compositional input. Unlike Gaussian and saddlepoint approximations, our estimator is invariant to data scaling, making it ideal for real-world applications such as variant allele frequency analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07527v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaochen Long, Marek Kimmel</dc:creator>
    </item>
    <item>
      <title>Adaptive sequential Monte Carlo for structured cross validation in Bayesian hierarchical models</title>
      <link>https://arxiv.org/abs/2501.07685</link>
      <description>arXiv:2501.07685v2 Announce Type: replace 
Abstract: Importance sampling (IS) is commonly used for cross validation (CV) in Bayesian models, because it only involves reweighting existing posterior draws without needing to re-estimate the model by re-running Markov chain Monte Carlo (MCMC). For hierarchical models, standard IS can be unreliable; the out-of-sample generalization hypothesis may involve structured case-deletion schemes which significantly alter the posterior geometry. This can force costly MCMC re-runs and make CV impractical. As a principled alternative, we tailor adaptive sequential Monte Carlo to sample along a path of posteriors that leads to the case-deleted posterior. The sampler is designed to support various hypotheses by accommodating diverse CV designs, and to streamline the workflow by automating path construction and systematically minimizing MCMC intervention. We demonstrate its utility with three types of predictive model assessment: longitudinal leave-group-out CV, group $K$-fold CV, and sequential one-step-ahead validation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07685v2</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Geonhee Han, Andrew Gelman</dc:creator>
    </item>
    <item>
      <title>Fast and Accurate Emulation of Complex Dynamic Simulators</title>
      <link>https://arxiv.org/abs/2503.20250</link>
      <description>arXiv:2503.20250v2 Announce Type: replace 
Abstract: Dynamic simulators are computational models governed by differential equations that evolve over time. They are essential for scientific and engineering applications but remain challenging to emulate because of the unpredictable behavior of complex systems. To address this challenge, this paper introduces a fast and accurate Gaussian Process (GP)-based emulation method for complex dynamic simulators. By integrating linked GPs into the one-step-ahead emulation framework, the proposed algorithm provides exact and tractable computation of the posterior mean and variance, solving a problem previously considered computationally intractable and eliminating the need for expensive Monte Carlo approximations. This approach substantially reduces computation time while maintaining or improving predictive accuracy. Furthermore, the method naturally extends to systems with forcing inputs by incorporating them as additional variables within the GP framework. Numerical experiments on multiple dynamic systems demonstrate the efficiency and computational advantages of the proposed approach. An R package, dynemu, which implements the one-step-ahead emulation approach, is available on CRAN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20250v2</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junoh Heo</dc:creator>
    </item>
    <item>
      <title>Disclosure Avoidance for the 2020 Census Demographic and Housing Characteristics File</title>
      <link>https://arxiv.org/abs/2312.10863</link>
      <description>arXiv:2312.10863v2 Announce Type: replace-cross 
Abstract: In "The 2020 Census Disclosure Avoidance System TopDown Algorithm," Abowd et al. (2022) describe the concepts and methods used by the Disclosure Avoidance System (DAS) to produce formally private output in support of the 2020 Census statistical data product releases, with a particular focus on the DAS implementation that was used to create the 2020 Census Redistricting Data (P.L. 94-171) Summary File. In this paper we describe the updates to the DAS that were required to release the Demographic and Housing Characteristics (DHC) File, which provides more granular tables than other statistical data products, such as the Redistricting Data Summary File. We also describe the final configuration parameters used for the 2020 production DHC DAS implementation, error metrics for these production statistical data products, and plans for future experimental data products that provide confidence intervals for confidential 2020 Census tabulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.10863v2</guid>
      <category>cs.CR</category>
      <category>stat.CO</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Cumings-Menon, Robert Ashmead, Daniel Kifer, Philip Leclerc, Matthew Spence, Pavel Zhuravlev, John M. Abowd</dc:creator>
    </item>
    <item>
      <title>Tensor Decomposition with Unaligned Observations</title>
      <link>https://arxiv.org/abs/2410.14046</link>
      <description>arXiv:2410.14046v2 Announce Type: replace-cross 
Abstract: This paper presents a canonical polyadic (CP) tensor decomposition that addresses unaligned observations. The mode with unaligned observations is represented using functions in a reproducing kernel Hilbert space (RKHS). We introduce a versatile loss function that effectively accounts for various types of data, including binary, integer-valued, and positive-valued types. Additionally, we propose an optimization algorithm for computing tensor decompositions with unaligned observations, along with a stochastic gradient method to enhance computational efficiency. A sketching algorithm is also introduced to further improve efficiency when using the $\ell_2$ loss function. To demonstrate the efficacy of our methods, we provide illustrative examples using both synthetic data and an early childhood human microbiome dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14046v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Runshi Tang, Tamara Kolda, Anru R. Zhang</dc:creator>
    </item>
    <item>
      <title>Decision Theory For Large Scale Outlier Detection Using Aleatoric Uncertainty: With a Note on Bayesian FDR</title>
      <link>https://arxiv.org/abs/2508.01988</link>
      <description>arXiv:2508.01988v2 Announce Type: replace-cross 
Abstract: Aleatoric and Epistemic uncertainty have achieved recent attention in the literature as different sources from which uncertainty can emerge in stochastic modeling. Epistemic being intrinsic or model based notions of uncertainty, and aleatoric being the uncertainty inherent in the data. We propose a novel decision theoretic framework for outlier detection in the context of aleatoric uncertainty; in the context of Bayesian modeling. The model incorporates bayesian false discovery rate control for multiplicty adjustment, and a new generalization of Bayesian FDR is introduced. The model is applied to simulations based on temporally fluctuating outlier detection where fixing thresholds often results in poor performance due to nonstationarity, and a case study is outlined on on a novel cybersecurity detection. Cyberthreat signals are highly nonstationary; giving a credible stress test of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01988v2</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ryan Warnick</dc:creator>
    </item>
  </channel>
</rss>
