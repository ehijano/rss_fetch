<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 24 Dec 2025 02:30:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Characterising Behavioural Families and Dynamics of Promotional Twitter Bots via Sequence-Based Modelling</title>
      <link>https://arxiv.org/abs/2512.18077</link>
      <description>arXiv:2512.18077v1 Announce Type: new 
Abstract: This paper asks whether promotional Twitter/X bots form behavioural families and whether members evolve similarly. We analyse 2,798,672 tweets from 2,615 ground-truth promotional bot accounts (2006-2021), focusing on complete years 2009 to 2020. Each bot is encoded as a sequence of symbolic blocks (``digital DNA'') from seven categorical post-level behavioural features (posting action, URL, media, text duplication, hashtags, emojis, sentiment), preserving temporal order only. Using non-overlapping blocks (k=7), cosine similarity over block-frequency vectors, and hierarchical clustering, we obtain four coherent families: Unique Tweeters, Duplicators with URLs, Content Multipliers, and Informed Contributors. Families share behavioural cores but differ systematically in engagement strategies and life-cycle dynamics (beginning/middle/end). We then model behavioural change as mutations. Within each family we align sequences via multiple sequence alignment (MSA) and label events as insertions, deletions, substitutions, alterations, and identity. This quantifies mutation rates, change-prone blocks/features, and mutation hotspots. Deletions and substitutions dominate, insertions are rare, and mutation profiles differ by family, with hotspots early for some families and dispersed for others. Finally, we test predictive value: bots within the same family share mutations more often than bots across families; closer bots share and propagate mutations more than distant ones; and responses to external triggers (e.g., Christmas, Halloween) follow family-specific, partly predictable patterns. Overall, sequence-based family modelling plus mutation analysis provides a fine-grained account of how promotional bot behaviour adapts over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18077v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ohoud Alzahrani, Russell Beale, Robert J. Hendley</dc:creator>
    </item>
    <item>
      <title>Network Analysis of Cyberbullying Interactions on Instagram</title>
      <link>https://arxiv.org/abs/2512.18116</link>
      <description>arXiv:2512.18116v1 Announce Type: new 
Abstract: Cyberbullying continues to grow in prevalence and its impact is felt by thousands worldwide. This study seeks a network science perspective on cyberbullying interaction patterns on the popular photo and video-sharing platform, Instagram. Using an annotated cyberbullying dataset containing over 400 Instagram posts, we outline a set of heuristics for building Session Graphs, where nodes represent users and their cyberbullying role, and edges represent their exchanged communications via comments. Over these graphs, we compute the Bully Score, a measure of the net malice introduced by bullies as they attack victims (attacks minus pushback), and the Victim Score, a measure of the net support victims receive from their defenders (support minus attacks). Utilizing small subgraph (motif) enumeration, our analysis uncovers the most common interaction patterns over all cyberbullying sessions. We also explore the prevalence of specific motif patterns across different ranges of Bully and Victim Scores. We find that a majority of cyberbullying sessions have negative Victim Scores (attacks outweighing support), while the Bully Score distribution has a slight positive skew (attacks outweighing pushback). We also observe that while bullies are the most common role in motifs, defenders are also consistently present. This suggests that bullying mitigation is a recurring structural feature of many interactions. To the best of our knowledge, this is the first study to explore this granular scale of network interactions using human annotations at the session and comment levels on Instagram.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18116v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Satyaki Sikdar, Manuel Sandoval, Taylor Hales, Chloe Kilroy, Maddie Juarez, Tyler Rosario, Juan J. Rosendo, Deborah L. Hall, Yasin N. Silva</dc:creator>
    </item>
    <item>
      <title>Analyzing Crime Discourse in U.S. Metropolitan Communities on Reddit: Trends, Influences, and Insights</title>
      <link>https://arxiv.org/abs/2512.18227</link>
      <description>arXiv:2512.18227v1 Announce Type: new 
Abstract: The relationship between crime and the media has long been a focal point of academic research, with traditional media playing a significant role in shaping public perceptions of safety and community well-being. However, the advent of social media has introduced a new dimension to this discourse, offering unique platforms for user-driven discussions. Despite the prominence of social media, research examining its impact on crime-related discourse remains limited. This paper investigates crime-related discussions across Reddit communities representing 384 Metropolitan Areas in the United States. By analyzing user submissions, we identify key trends in crime discourse, including the higher prevalence of such discussions in larger metropolitan areas and communities with more liberal political leanings. Interestingly, we find that reported crime rates do not strongly influence the frequency or intensity of these discussions. These findings provide novel insights into how social media platforms, like Reddit, shape public narratives around crime, highlighting the growing need to examine digital spaces as influential mediators of public perception.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18227v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Deepit Sapru</dc:creator>
    </item>
    <item>
      <title>Needles in a haystack: using forensic network science to uncover insider trading</title>
      <link>https://arxiv.org/abs/2512.18918</link>
      <description>arXiv:2512.18918v1 Announce Type: new 
Abstract: Although the automation and digitisation of anti-financial crime investigation has made significant progress in recent years, detecting insider trading remains a unique challenge, partly due to the limited availability of labelled data. To address this challenge, we propose using a data-driven networks approach that flags groups of corporate insiders who report coordinated transactions that are indicative of insider trading. Specifically, we leverage data on 2.9 million trades reported to the U.S. Securities and Exchange Commission (SEC) by company insiders (C-suite executives, board members and major shareholders) between 2014 and 2024. Our proposed algorithm constructs weighted edges between insiders based on the temporal similarity of their trades over the 10-year timeframe. Within this network we then uncover trends that indicate insider trading by focusing on central nodes and anomalous subgraphs. To highlight the validity of our approach we evaluate our findings with reference to two null models, generated by running our algorithm on synthetic empirically calibrated and shuffled datasets. The results indicate that our approach can be used to detect pairs or clusters of insiders whose behaviour suggests insider trading and/or market manipulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18918v1</guid>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gian Jaeger, Wang Ngai Yeung, Renaud Lambiotte</dc:creator>
    </item>
    <item>
      <title>A Reverse Reachable Set Based Approach for Motif Oriented Profit maximization in Social Networks</title>
      <link>https://arxiv.org/abs/2512.19237</link>
      <description>arXiv:2512.19237v1 Announce Type: new 
Abstract: Profit Maximization is one of the key objectives for social media marketing, where the task is to choose a limited number of highly influential nodes such that their initial activation leads to maximum profit. In this paper, we introduce a variant of the Profit Maximization Problem where we consider that instead of nodes, benefits are assigned to some of the motifs of the graph, and these benefit values can be earned once a given threshold count of nodes from the motifs is influenced. The goal here is to choose a limited number of nodes for initial activation called seed nodes such that the motif-oriented profit gets maximized. Formally, we call our problem the Motif Oriented Profit Maximization Problem. We show that the problem is NP-hard to solve optimally. We propose a Reverse Reachable Set-based framework to solve our problem. The proposed methodology broadly divides into three steps: KPT Estimation and RR Set generation, Seed Set Selection, and Motif Oriented Profit Estimation. The proposed methodology has been analyzed to understand its time and space requirements. It has been implemented with real-world social network datasets, and the results are reported. We observe that the seed set selected by the proposed solution approaches leads to more profit compared to the seed sets selected by the existing methods. The whole implementation and data are available at: https://github.com/PoonamSharma-PY/MotifProfit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19237v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Poonam Sharma, Suman Banerjee</dc:creator>
    </item>
    <item>
      <title>Laplacian Network Optimization via Information Functions</title>
      <link>https://arxiv.org/abs/2512.19279</link>
      <description>arXiv:2512.19279v1 Announce Type: new 
Abstract: Designing networks to optimize robustness and other performance metrics is a well-established problem with applications ranging from electrical engineering to communication networks. Many such performance measures rely on the Laplacian spectrum; notable examples include total effective resistance, the number of spanning trees, and algebraic connectivity. This paper advances the study of Laplacian-based network optimization by drawing on ideas from experimental design in statistics. We present a theoretical framework for analyzing performance measures by introducing the notion of information functions, which captures a set of their desirable properties. Then, we formulate a new parametric family of information functions, Kiefer's measures, which encompasses the three most common spectral objectives. We provide a regular reformulation of the Laplacian optimization problem, and we use this reformulation to compute directional derivatives of Kiefer's measures. The directional derivatives provide a unified treatment of quantities recurring in Laplacian optimization, such as gradients and subgradients, and we show that they are connected to Laplacian-based measures of node distance, which we call node dissimilarities. We apply the node dissimilarities to derive efficient rank-one update formulas for Kiefer's criteria, and to devise a new edge-exchange method for network optimization. These update formulas enable greedy and exchange algorithms with reduced asymptotic time complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19279v1</guid>
      <category>cs.SI</category>
      <category>cs.DM</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Rosa, Radoslav Harman</dc:creator>
    </item>
    <item>
      <title>A Computationally Efficient Framework for Overlapping Community Detection in Large Bipartite Graphs</title>
      <link>https://arxiv.org/abs/2512.19426</link>
      <description>arXiv:2512.19426v1 Announce Type: new 
Abstract: Community detection, which uncovers closely connected vertex groups in networks, is vital for applications in social networks, recommendation systems, and beyond. Real-world networks often have bipartite structures (vertices in two disjoint sets with inter-set connections), creating unique challenges on specialized community detection methods. Biclique percolation community (BCPC) is widely used to detect cohesive structures in bipartite graphs. A biclique is a complete bipartite subgraph, and a BCPC forms when maximal bicliques connect via adjacency (sharing an (alpha, beta)-biclique). Yet, existing methods for BCPC detection suffer from high time complexity due to the potentially massive maximal biclique adjacency graph (MBAG). To tackle this, we propose a novel partial-BCPC based solution, whose key idea is to use partial-BCPC to reduce the size of the MBAG. A partial-BCPC is a subset of BCPC. Maximal bicliques belonging to the same partial-BCPC must also belong to the same BCPC. Therefore, these maximal bicliques can be grouped as a single vertex in the MBAG, significantly reducing the size of the MBAG. Furthermore, we move beyond the limitations of MBAG and propose a novel BCPC detection approach based on (alpha, beta)-biclique enumeration. This approach detects BCPC by enumerating all (alpha, beta)-bicliques and connecting maximal bicliques sharing the same (alpha, beta)-biclique, which is the condition for maximal bicliques to be adjacent. It also leverages partial-BCPC to significantly prune the enumeration space of (alpha, beta)-biclique. Experiments show that our methods outperform existing methods by nearly three orders of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19426v1</guid>
      <category>cs.SI</category>
      <category>cs.DB</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yue Zeng, Rong-Hua Li, Qiangqiang Dai, Guoren Wang</dc:creator>
    </item>
    <item>
      <title>Detecting Coordinated Activities Through Temporal, Multiplex, and Collaborative Analysis</title>
      <link>https://arxiv.org/abs/2512.19677</link>
      <description>arXiv:2512.19677v1 Announce Type: new 
Abstract: In the era of widespread online content consumption, effective detection of coordinated efforts is crucial for mitigating potential threats arising from information manipulation. Despite advances in isolating inauthentic and automated actors, the actions of individual accounts involved in influence campaigns may not stand out as anomalous if analyzed independently of the coordinated group. Given the collaborative nature of information operations, coordinated campaigns are better characterized by evidence of similar temporal behavioral patterns that extend beyond coincidental synchronicity across a group of accounts. We propose a framework to model complex coordination patterns across multiple online modalities. This framework utilizes multiplex networks to first decompose online activities into different interaction layers, and subsequently aggregate evidence of online coordination across the layers. In addition, we propose a time-aware collaboration model to capture patterns of online coordination for each modality. The proposed time-aware model builds upon the node-normalized collaboration model and accounts for repetitions of coordinated actions over different time intervals by employing an exponential decay temporal kernel. We validate our approach on multiple datasets featuring different coordinated activities. Our results demonstrate that a multiplex time-aware model excels in the identification of coordinating groups, outperforming previously proposed methods in coordinated activity detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19677v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Letizia Iannucci, Elisa Muratore, Antonis Matakos, Mikko Kivel\"a</dc:creator>
    </item>
    <item>
      <title>CoPE: A Small Language Model for Steerable and Scalable Content Labeling</title>
      <link>https://arxiv.org/abs/2512.18027</link>
      <description>arXiv:2512.18027v1 Announce Type: cross 
Abstract: This paper details the methodology behind CoPE, a policy-steerable small language model capable of fast and accurate content labeling. We present a novel training curricula called Contradictory Example Training that enables the model to learn policy interpretation rather than mere policy memorization. We also present a novel method for generating content policies, called Binocular Labeling, which enables rapid construction of unambiguous training datasets. When evaluated across seven different harm areas, CoPE exhibits equal or superior accuracy to frontier models at only 1% of their size. We openly release a 9 billion parameter version of the model that can be run on a single consumer-grade GPU. Models like CoPE represent a paradigm shift for classifier systems. By turning an ML task into a policy writing task, CoPE opens up new design possibilities for the governance of online platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18027v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Samidh Chakrabarti, David Willner, Kevin Klyman, Tiffany Saade, Emily Capstick, Sabina Nong</dc:creator>
    </item>
    <item>
      <title>Probabilistic Digital Twins of Users: Latent Representation Learning with Statistically Validated Semantics</title>
      <link>https://arxiv.org/abs/2512.18056</link>
      <description>arXiv:2512.18056v1 Announce Type: cross 
Abstract: Understanding user identity and behavior is central to applications such as personalization, recommendation, and decision support. Most existing approaches rely on deterministic embeddings or black-box predictive models, offering limited uncertainty quantification and little insight into what latent representations encode. We propose a probabilistic digital twin framework in which each user is modeled as a latent stochastic state that generates observed behavioral data. The digital twin is learned via amortized variational inference, enabling scalable posterior estimation while retaining a fully probabilistic interpretation. We instantiate this framework using a variational autoencoder (VAE) applied to a user-response dataset designed to capture stable aspects of user identity. Beyond standard reconstruction-based evaluation, we introduce a statistically grounded interpretation pipeline that links latent dimensions to observable behavioral patterns. By analyzing users at the extremes of each latent dimension and validating differences using nonparametric hypothesis tests and effect sizes, we demonstrate that specific dimensions correspond to interpretable traits such as opinion strength and decisiveness. Empirically, we find that user structure is predominantly continuous rather than discretely clustered, with weak but meaningful structure emerging along a small number of dominant latent axes. These results suggest that probabilistic digital twins can provide interpretable, uncertainty-aware representations that go beyond deterministic user embeddings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18056v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Daniel David</dc:creator>
    </item>
    <item>
      <title>GeoSense-AI: Fast Location Inference from Crisis Microblogs</title>
      <link>https://arxiv.org/abs/2512.18225</link>
      <description>arXiv:2512.18225v1 Announce Type: cross 
Abstract: This paper presents an applied AI pipeline for realtime geolocation from noisy microblog streams, unifying statistical hashtag segmentation, part-of-speech-driven proper-noun detection, dependency parsing around disaster lexicons, lightweight named-entity recognition, and gazetteer-grounded disambiguation to infer locations directly from text rather than sparse geotags. The approach operationalizes information extraction under streaming constraints, emphasizing low-latency NLP components and efficient validation against geographic knowledge bases to support situational awareness during emergencies. In head to head comparisons with widely used NER toolkits, the system attains strong F1 while being engineered for orders-of-magnitude faster throughput, enabling deployment in live crisis informatics settings. A production map interface demonstrates end-to-end AI functionality ingest, inference, and visualization--surfacing locational signals at scale for floods, outbreaks, and other fastmoving events. By prioritizing robustness to informal text and streaming efficiency, GeoSense-AI illustrates how domain-tuned NLP and knowledge grounding can elevate emergency response beyond conventional geo-tag reliance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18225v1</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Deepit Sapru</dc:creator>
    </item>
    <item>
      <title>Evolutionary Cooperation with Game Transitions via Markov Decision Chain in Networked Population</title>
      <link>https://arxiv.org/abs/2512.18972</link>
      <description>arXiv:2512.18972v1 Announce Type: cross 
Abstract: Individual cooperative strategy influences the surrounding dynamic population, which in turn affects cooperative strategy. To better model this phenomenon, we develop a Markov decision chain based game transitions model and examine the dynamic transitions in game states of individuals within a network and their impact on the strategy's evolution. Additionally, we extend single-round strategy imitation to multiple rounds to better capture players' potential non-rational behavior. Using intensive simulations, we explore the effects of transition probabilities and game parameters on game transitions and cooperation. Our study finds that strategy-driven game transitions promote cooperation, and increasing the transition rates of Markov decision chains can significantly accelerate this process. By designing different Markov decision chains, these results provide simulation based guidance for practical applications in swarm intelligence, such as strategic collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18972v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.apm.2025.116710</arxiv:DOI>
      <arxiv:journal_reference>Applied Mathematical Modelling,2025,116710</arxiv:journal_reference>
      <dc:creator>Chaoyang Luo, Yuji Zhang, Minyu Feng, Attila Szolnoki</dc:creator>
    </item>
    <item>
      <title>Normalized mutual information is a biased measure for classification and community detection</title>
      <link>https://arxiv.org/abs/2307.01282</link>
      <description>arXiv:2307.01282v3 Announce Type: replace 
Abstract: Normalized mutual information is widely used as a similarity measure for evaluating the performance of clustering and classification algorithms. In this paper, we argue that results returned by the normalized mutual information are biased for two reasons: first, because they ignore the information content of the contingency table and, second, because their symmetric normalization introduces spurious dependence on algorithm output. We introduce a modified version of the mutual information that remedies both of these shortcomings. As a practical demonstration of the importance of using an unbiased measure, we perform extensive numerical tests on a basket of popular algorithms for network community detection and show that one's conclusions about which algorithm is best are significantly affected by the biases in the traditional mutual information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.01282v3</guid>
      <category>cs.SI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1038/s41467-025-66150-8</arxiv:DOI>
      <arxiv:journal_reference>Nature Communications 16, 11268 (2025)</arxiv:journal_reference>
      <dc:creator>Maximilian Jerdee, Alec Kirkley, M. E. J. Newman</dc:creator>
    </item>
    <item>
      <title>DyGSSM: Multi-view Dynamic Graph Embeddings with State Space Model Gradient Update</title>
      <link>https://arxiv.org/abs/2505.09017</link>
      <description>arXiv:2505.09017v2 Announce Type: replace-cross 
Abstract: Most of the dynamic graph representation learning methods involve dividing a dynamic graph into discrete snapshots to capture the evolving behavior of nodes over time. Existing methods primarily capture only local or global structures of each node within a snapshot using message-passing and random walk-based methods. Then, they utilize sequence-based models (e.g., transformers) to encode the temporal evolution of node embeddings, and meta-learning techniques to update the model parameters. However, these approaches have two limitations. First, they neglect the extraction of global and local information simultaneously in each snapshot. Second, they fail to consider the model's performance in the current snapshot during parameter updates, resulting in a lack of temporal dependency management. Recently, HiPPO (High-order Polynomial Projection Operators) algorithm has gained attention for their ability to optimize and preserve sequence history in State Space Model (SSM). To address the aforementioned limitations in dynamic graph representation learning, we propose a novel method called Multi-view Dynamic Graph Embeddings with State Space Model Gradient Update (DyGSSM). Our approach combines Graph Convolution Networks (GCN) for local feature extraction and random walk with Gated Recurrent Unit (GRU) for global feature extraction in each snapshot. We then integrate the local and global features using a cross-attention mechanism. Additionally, we incorporate an SSM based on HiPPO algorithm to account for long-term dependencies when updating model parameters, ensuring that model performance in each snapshot informs subsequent updates. Experiments on five public datasets show that our method outperforms existing baseline and state-of-the-art (SOTA) methods in 17 out of 20 cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09017v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bizhan Alipour Pijan, Serdar Bozdag</dc:creator>
    </item>
  </channel>
</rss>
