<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Sep 2024 04:03:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>RRD-Bio: Building An Integrated Research Resource Database for Biomedicine</title>
      <link>https://arxiv.org/abs/2409.14010</link>
      <description>arXiv:2409.14010v1 Announce Type: new 
Abstract: Research resources (RRs) such as data, software, and tools are essential pillars of scientific research. The field of biomedicine, a critical scientific discipline, is witnessing a surge in research publications resulting in the accumulation of a substantial number of RRs. However, these resources are dispersed among various biomedical articles and can be challenging to locate and reuse due to their transient nature. In this paper, we report our recent progress in biomedical data curation - building a large research resource database for biomedicine (RRD-Bio), based on a collection of 40 million papers from two large biomedical literature databases, PubMed and PubMed Central. The database contains 2,555,116 RRs, each identified by a location on the Internet (URL) and descriptive information (Context). We made the RRD-Bio database publicly available (\url{https://zenodo.org/records/10526493}) to enhance the visibility of biomedical research resources, the ability to preserve important resources and the reproducibility of biomedical research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14010v1</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Li Zhang, Mengting Sun, Chong Jiang, Haihua Chen</dc:creator>
    </item>
    <item>
      <title>An Instance-based Plus Ensemble Learning Method for Classification of Scientific Papers</title>
      <link>https://arxiv.org/abs/2409.14237</link>
      <description>arXiv:2409.14237v1 Announce Type: new 
Abstract: The exponential growth of scientific publications in recent years has posed a significant challenge in effective and efficient categorization. This paper introduces a novel approach that combines instance-based learning and ensemble learning techniques for classifying scientific papers into relevant research fields. Working with a classification system with a group of research fields, first a number of typical seed papers are allocated to each of the fields manually. Then for each paper that needs to be classified, we compare it with all the seed papers in every field. Contents and citations are considered separately. An ensemble-based method is then employed to make the final decision. Experimenting with the datasets from DBLP, our experimental results demonstrate that the proposed classification method is effective and efficient in categorizing papers into various research areas. We also find that both content and citation features are useful for the classification of scientific papers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14237v1</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fang Zhang, Shengli Wu</dc:creator>
    </item>
    <item>
      <title>tabulapdf: An R Package to Extract Tables from PDF Documents</title>
      <link>https://arxiv.org/abs/2409.14524</link>
      <description>arXiv:2409.14524v1 Announce Type: cross 
Abstract: tabulapdf is an R package that utilizes the Tabula Java library to import tables from PDF files directly into R. This tool can reduce time and effort in data extraction processes in fields like investigative journalism. It allows for automatic and manual table extraction, the latter facilitated through a Shiny interface, enabling manual areas selection with a computer mouse for data retrieval.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14524v1</guid>
      <category>cs.IR</category>
      <category>cs.DL</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mauricio Vargas Sep\'ulveda, Thomas J. Leeper, Tom Paskhalis, Manuel Aristar\'an, Jeremy B. Merrill, Mike Tigas</dc:creator>
    </item>
    <item>
      <title>Representing provenance and track changes of cultural heritage metadata in RDF: a survey of existing approaches</title>
      <link>https://arxiv.org/abs/2305.08477</link>
      <description>arXiv:2305.08477v2 Announce Type: replace 
Abstract: In the realm of Digital Humanities, the management of cultural heritage metadata is pivotal for ensuring data trustworthiness. Provenance information - contextual metadata detailing the origin and history of data - plays a crucial role in this process. However, tracking provenance and changes in metadata using the Resource Description Framework (RDF) presents significant challenges due to the limitations of foundational Semantic Web technologies. This article offers a comprehensive review of existing models and approaches for representing provenance and tracking changes in RDF, with a specific focus on cultural heritage metadata. It examines W3C standard proposals such as RDF Reification and n-ary relations, along with various alternative systems. Through an in-depth analysis, the study identifies Named Graphs, RDF*, the Provenance Ontology (PROV-O), Dublin Core (DC), Conjectural Graphs, and the OpenCitations Data Model (OCDM) as the most effective solutions. These models are evaluated based on their compliance with RDF standards, scalability, and applicability across different domains. The findings underscore the importance of selecting the appropriate model to ensure robust and reliable management of provenance in RDF datasets, thereby contributing to the ongoing discourse on provenance representation in the Digital Humanities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.08477v2</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arcangelo Massari (Research Centre for Open Scholarly Metadata, Department of Classical Philology and Italian Studies, University of Bologna, Bologna, Italy, Digital Humanities Advanced Research Centre), Silvio Peroni (Research Centre for Open Scholarly Metadata, Department of Classical Philology and Italian Studies, University of Bologna, Bologna, Italy, Digital Humanities Advanced Research Centre), Francesca Tomasi (Digital Humanities Advanced Research Centre), Ivan Heibi (Research Centre for Open Scholarly Metadata, Department of Classical Philology and Italian Studies, University of Bologna, Bologna, Italy, Digital Humanities Advanced Research Centre)</dc:creator>
    </item>
    <item>
      <title>Requirements for Urban Dataset Metadata</title>
      <link>https://arxiv.org/abs/2402.05211</link>
      <description>arXiv:2402.05211v4 Announce Type: replace 
Abstract: In the current environment of data generation and publication, there is an ever-growing number of datasets available for download. This growth precipitates an existing challenge: sourcing and integrating relevant datasets for analysis is becoming more complex. Despite efforts by open data platforms, obstacles remain, predominantly rooted in inadequate metadata, unsuitable data presentation, complications in pinpointing desired data, and data integration. This paper delves into the intricacies of dataset retrieval, emphasizing the pivotal role of metadata in aligning datasets with user queries. Through an exploration of existing literature, it underscores prevailing issues such as the identification of valuable metadata and the development of tools to maintain and annotate them effectively. The central contribution of this research is the proposition of the Urban Dataset Metadata Requirements. Deriving inspiration from software engineering maturity models, this framework delineates a progression from rudimentary metadata documentation to advanced levels, aiding dataset creators in their documentation efforts. The requirements encompass seven pivotal dimensions, spanning content to quality information, each stratified across six levels to guide the optimal documentation of datasets, ensuring ease of discovery, relevance assessment, and comprehensive dataset understanding. This paper also incorporates the metadata properties into a data cataloguing tool called CKAN through a custom plugin, CKANext-udc. The plugin introduces custom fields based on different metadata levels, allows for user interface customisation, and integrates with a graph database, converting catalogue data into a knowledge graph based on the Urban Data Metadata Requirements ontology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05211v4</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark S. Fox, Bart Gajderowicz, Dishu Lyu</dc:creator>
    </item>
    <item>
      <title>Pennsieve: A Collaborative Platform for Translational Neuroscience and Beyond</title>
      <link>https://arxiv.org/abs/2409.10509</link>
      <description>arXiv:2409.10509v2 Announce Type: replace-cross 
Abstract: The exponential growth of neuroscientific data necessitates platforms that facilitate data management and multidisciplinary collaboration. In this paper, we introduce Pennsieve - an open-source, cloud-based scientific data management platform built to meet these needs. Pennsieve supports complex multimodal datasets and provides tools for data visualization and analyses. It takes a comprehensive approach to data integration, enabling researchers to define custom metadata schemas and utilize advanced tools to filter and query their data. Pennsieve's modular architecture allows external applications to extend its capabilities, and collaborative workspaces with peer-reviewed data publishing mechanisms promote high-quality datasets optimized for downstream analysis, both in the cloud and on-premises.
  Pennsieve forms the core for major neuroscience research programs including NIH SPARC Initiative, NIH HEAL Initiative's PRECISION Human Pain Network, and NIH HEAL RE-JOIN Initiative. It serves more than 80 research groups worldwide, along with several large-scale, inter-institutional projects at clinical sites through the University of Pennsylvania. Underpinning the SPARC.Science, Epilepsy.Science, and Pennsieve Discover portals, Pennsieve stores over 125 TB of scientific data, with 35 TB of data publicly available across more than 350 high-impact datasets. It adheres to the findable, accessible, interoperable, and reusable (FAIR) principles of data sharing and is recognized as one of the NIH-approved Data Repositories. By facilitating scientific data management, discovery, and analysis, Pennsieve fosters a robust and collaborative research ecosystem for neuroscience and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10509v2</guid>
      <category>cs.CY</category>
      <category>cs.DB</category>
      <category>cs.DL</category>
      <category>cs.ET</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zack Goldblum, Zhongchuan Xu, Haoer Shi, Patryk Orzechowski, Jamaal Spence, Kathryn A Davis, Brian Litt, Nishant Sinha, Joost Wagenaar</dc:creator>
    </item>
  </channel>
</rss>
