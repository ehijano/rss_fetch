<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 30 Sep 2024 04:06:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Synchronous Team Semantics for Temporal Logics</title>
      <link>https://arxiv.org/abs/2409.18667</link>
      <description>arXiv:2409.18667v1 Announce Type: new 
Abstract: We present team semantics for two of the most important linear and branching time specification languages, Linear Temporal Logic (LTL) and Computation Tree Logic (CTL).
  With team semantics, LTL is able to express hyperproperties, which have in the last decade been identified as a key concept in the verification of information flow properties. We study basic properties of the logic and classify the computational complexity of its satisfiability, path, and model checking problem. Further, we examine how extensions of the basic logic react to adding additional atomic operators. Finally, we compare its expressivity to the one of HyperLTL, another recently introduced logic for hyperproperties. Our results show that LTL with team semantics is a viable alternative to HyperLTL, which complements the expressivity of HyperLTL and has partially better algorithmic properties.
  For CTL with team semantics, we investigate the computational complexity of the satisfiability and model checking problem. The satisfiability problem is shown to be EXPTIME-complete while we show that model checking is PSPACE-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18667v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Krebs, Arne Meier, Jonni Virtema, Martin Zimmermann</dc:creator>
    </item>
    <item>
      <title>Beyond Decisiveness of Infinite Markov Chains</title>
      <link>https://arxiv.org/abs/2409.18670</link>
      <description>arXiv:2409.18670v1 Announce Type: new 
Abstract: Verification of infinite-state Markov chains is still a challenge despite several fruitful numerical or statistical approaches. For decisive Markov chains, there is a simple numerical algorithm that frames the reachability probability as accurately as required (however with an unknown complexity). On the other hand when applicable, statistical model checking is in most of the cases very efficient. Here we study the relation between these two approaches showing first that decisiveness is a necessary and sufficient condition for almost sure termination of statistical model checking. Afterwards we develop an approach with application to both methods that substitutes to a non decisive Markov chain a decisive Markov chain with the same reachability probability. This approach combines two key ingredients: abstraction and importance sampling (a technique that was formerly used for efficiency). We develop this approach on a generic formalism called layered Markov chain (LMC). Afterwards we perform an empirical study on probabilistic pushdown automata (an instance of LMC) to understand the complexity factors of the statistical and numerical algorithms. To the best of our knowledge, this prototype is the first implementation of the deterministic algorithm for decisive Markov chains and required us to solve several qualitative and numerical issues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18670v1</guid>
      <category>cs.LO</category>
      <category>cs.FL</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Beno\^it Barbot, Patricia Bouyer, Serge Haddad</dc:creator>
    </item>
    <item>
      <title>Interaction Equivalence</title>
      <link>https://arxiv.org/abs/2409.18709</link>
      <description>arXiv:2409.18709v1 Announce Type: new 
Abstract: Contextual equivalence is the de facto standard notion of program equivalence. A key theorem is that contextual equivalence is an equational theory. Making contextual equivalence more intensional, for example taking into account the time cost of the computation, seems a natural refinement. Such a change, however, does not induce an equational theory, for an apparently essential reason: cost is not invariant under reduction.
  In the paradigmatic case of the untyped $\lambda$-calculus, we introduce interaction equivalence. Inspired by game semantics, we observe the number of interaction steps between terms and contexts but -- crucially -- ignore their own internal steps. We prove that interaction equivalence is an equational theory and we characterize it as $B$, the well-known theory induced by B\"ohm tree equality. Ours is the first observational characterization of $B$ obtained without enriching the discriminating power of contexts with extra features such as non-determinism. To prove our results, we develop interaction-based refinements of the B\"ohm-out technique and of intersection types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18709v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Beniamino Accattoli, Adrienne Lancelot, Giulio Manzonetto, Gabriele Vanoni</dc:creator>
    </item>
    <item>
      <title>Fairness and promptness in Muller formulas</title>
      <link>https://arxiv.org/abs/2204.13215</link>
      <description>arXiv:2204.13215v5 Announce Type: replace 
Abstract: In this paper we consider two different views of the model checking problems for the Linear Temporal Logic (LTL). On the one hand, we consider the universal model checking problem for LTL, where one asks that for a given system and a given formula all the runs of the system satisfy the formula. On the other hand, the fair model checking problem for LTL asks that for a given system and a given formula almost all the runs of the system satisfy the formula. It was shown that these two problems have the same theoretical complexity i.e. PSPACE-complete. The question arises whether one can find a fragment of LTL for which the complexity of these two problems differs. One such fragment was identified in a previous work, namely the Muller fragment. We address a similar comparison for the prompt fragment of LTL (pLTL). pLTL extends LTL with an additional operator, i.e. the prompt-eventually. This operator ensures the existence of a bound such that liveness properties are satisfied within this bound. We show that the corresponding Muller fragment for pLTL does not enjoy the same algorithmic properties with respect to the comparison considered. We also identify a new expressive fragment for which the fair model checking is faster than the universal one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.13215v5</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Damien Busatto-Gaston, Youssouf Oualhadj, L\'eo Tible, Daniele Varacca</dc:creator>
    </item>
    <item>
      <title>Probabilistic unifying relations for modelling epistemic and aleatoric uncertainty: semantics and automated reasoning with theorem proving</title>
      <link>https://arxiv.org/abs/2303.09692</link>
      <description>arXiv:2303.09692v3 Announce Type: replace 
Abstract: Probabilistic programming combines general computer programming, statistical inference, and formal semantics to help systems make decisions when facing uncertainty. Probabilistic programs are ubiquitous, including having a significant impact on machine intelligence. While many probabilistic algorithms have been used in practice in different domains, their automated verification based on formal semantics is still a relatively new research area. In the last two decades, it has attracted much interest. Many challenges, however, remain. The work presented in this paper, probabilistic unifying relations (ProbURel), takes a step towards our vision to tackle these challenges.
  Our work is based on Hehner's predicative probabilistic programming, but there are several obstacles to the broader adoption of his work. Our contributions here include (1) the formalisation of its syntax and semantics by introducing an Iverson bracket notation to separate relations from arithmetic; (2) the formalisation of relations using Unifying Theories of Programming (UTP) and probabilities outside the brackets using summation over the topological space of the real numbers; (3) the constructive semantics for probabilistic loops using Kleene's fixed-point theorem; (4) the enrichment of its semantics from distributions to subdistributions and superdistributions to deal with the constructive semantics; (5) the unique fixed-point theorem to simplify the reasoning about probabilistic loops; and (6) the mechanisation of our theory in Isabelle/UTP, an implementation of UTP in Isabelle/HOL, for automated reasoning using theorem proving.
  We demonstrate our work with six examples, including problems in robot localisation, classification in machine learning, and the termination of probabilistic loops.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.09692v3</guid>
      <category>cs.LO</category>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.tcs.2024.114876</arxiv:DOI>
      <arxiv:journal_reference>Theoretical Computer Science Volume 1021, 21 December 2024, 114876</arxiv:journal_reference>
      <dc:creator>Kangfeng Ye, Jim Woodcock, Simon Foster</dc:creator>
    </item>
    <item>
      <title>How to play the Accordion. Uniformity and the (non-)conservativity of the linear approximation of the {\lambda}-calculus</title>
      <link>https://arxiv.org/abs/2305.02785</link>
      <description>arXiv:2305.02785v3 Announce Type: replace 
Abstract: Twenty years after its introduction by Ehrhard and Regnier, differentiation in {\lambda}-calculus and in linear logic is now a celebrated tool. In particular, it allows to write the Taylor formula in various {\lambda}-calculi, hence providing a theory of linear approximations for these calculi. In the standard {\lambda}-calculus, this linear approximation is expressed by results stating that the (possibly) infinitary {\beta}-reduction of {\lambda}-terms is simulated by the reduction of their Taylor expansion: in terms of rewriting systems, the resource reduction (operating on Taylor approximants) is an extension of the {\beta}-reduction.
  In this paper, we address the converse property, conservativity: are there reductions of the Taylor approximants that do not arise from an actual {\beta}-reduction of the approximated term? We show that if we restrict the setting to finite terms and {\beta}-reduction sequences, then the linear approximation is conservative. However, as soon as one allows infinitary reduction sequences this property is broken. We design a counter-example, the Accordion. Then we show how restricting the reduction of the Taylor approximants allows to build a conservative extension of the {\beta}-reduction preserving good simulation properties. This restriction relies on uniformity, a property that was already at the core of Ehrhard and Regnier's pioneering work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.02785v3</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>R\'emy Cerda, Lionel Vaux Auclair</dc:creator>
    </item>
    <item>
      <title>Containment for Guarded Monotone Strict NP</title>
      <link>https://arxiv.org/abs/2310.01254</link>
      <description>arXiv:2310.01254v3 Announce Type: replace 
Abstract: Guarded Monotone Strict NP (GMSNP) extends Monotone Monadic Strict NP (MMSNP) by guarded existentially quantified predicates of arbitrary arities. We prove that the containment problem for GMSNP is decidable, hereby settling an open question of Bienvenu, ten Cate, Lutz, and Wolter, later restated by Bourhis and Lutz. Our proof of decidability also comes with a 2NEXPTIME upper bound on the complexity of the problem, which matches the lower bound for containment of MMSNP previously obtained by Bourhis and Lutz. In order to obtain these results, we significantly improve the state of knowledge of the model-theoretic properties of GMSNP. Bodirsky, Kn\"auer, and Starke previously showed that every GMSNP sentence defines a finite union of CSPs of $\omega$-categorical structures. We refine their construction by adding a restricted form of homogeneity to the properties of these structures, making the logic amenable to future complexity classifications for query evaluation using techniques developed for infinite-domain CSPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01254v3</guid>
      <category>cs.LO</category>
      <category>cs.DB</category>
      <category>math.LO</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexey Barsukov, Michael Pinsker, Jakub Rydval</dc:creator>
    </item>
    <item>
      <title>Dense Integer-Complete Synthesis for Bounded Parametric Timed Automata</title>
      <link>https://arxiv.org/abs/2310.09109</link>
      <description>arXiv:2310.09109v2 Announce Type: replace 
Abstract: Ensuring the correctness of critical real-time systems, involving concurrent behaviors and timing requirements, is crucial. Timed automata extend finite-state automata with clocks, compared in guards and invariants with integer constants. Parametric timed automata (PTAs) extend timed automata with timing parameters. Parameter synthesis aims at computing dense sets of valuations for the timing parameters, guaranteeing a good behavior. However, in most cases, the emptiness problem for reachability (i.e., the emptiness of the parameter valuations set for which some location is reachable) is undecidable for PTAs and, as a consequence, synthesis procedures do not terminate in general, even for bounded parameters. In this paper, we introduce a parametric extrapolation, that allows us to derive an underapproximation in the form of symbolic sets of valuations containing not only all the integer points ensuring reachability, but also all the (non-necessarily integer) convex combinations of these integer points, for general PTAs with a bounded parameter domain. We also propose two further algorithms synthesizing parameter valuations guaranteeing unavoidability, and preservation of the untimed behavior w.r.t. a reference parameter valuation, respectively. Our algorithms terminate and can output sets of valuations arbitrarily close to the complete result. We demonstrate their applicability and efficiency using the tools Rom\'eo and IMITATOR on several benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09109v2</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\'Etienne Andr\'e, Didier Lime, Olivier H. Roux</dc:creator>
    </item>
    <item>
      <title>The Bright Side of Timed Opacity</title>
      <link>https://arxiv.org/abs/2408.12240</link>
      <description>arXiv:2408.12240v3 Announce Type: replace 
Abstract: In 2009, Franck Cassez showed that the timed opacity problem, where an attacker can observe some actions with their timestamps and attempts to deduce information, is undecidable for timed automata (TAs). Moreover, he showed that the undecidability holds even for subclasses such as event-recording automata. In this article, we consider the same definition of opacity for several other subclasses of TAs: with restrictions on the number of clocks, of actions, on the nature of time, or on a new subclass called observable event-recording automata. We show that opacity can mostly be retrieved, except for one-action TAs and for one-clock TAs with $\epsilon$-transitions, for which undecidability remains. We then exhibit a new decidable subclass in which the number of observations made by the attacker is limited.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12240v3</guid>
      <category>cs.LO</category>
      <category>cs.CR</category>
      <category>cs.FL</category>
      <pubDate>Mon, 30 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\'Etienne Andr\'e, Sarah D\'epernet, Engel Lefaucheux</dc:creator>
    </item>
  </channel>
</rss>
