<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Aug 2025 04:01:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Reinitializing weights vs units for maintaining plasticity in neural networks</title>
      <link>https://arxiv.org/abs/2508.00212</link>
      <description>arXiv:2508.00212v1 Announce Type: new 
Abstract: Loss of plasticity is a phenomenon in which a neural network loses its ability to learn when trained for an extended time on non-stationary data. It is a crucial problem to overcome when designing systems that learn continually. An effective technique for preventing loss of plasticity is reinitializing parts of the network. In this paper, we compare two different reinitialization schemes: reinitializing units vs reinitializing weights. We propose a new algorithm, which we name \textit{selective weight reinitialization}, for reinitializing the least useful weights in a network. We compare our algorithm to continual backpropagation and ReDo, two previously proposed algorithms that reinitialize units in the network. Through our experiments in continual supervised learning problems, we identify two settings when reinitializing weights is more effective at maintaining plasticity than reinitializing units: (1) when the network has a small number of units and (2) when the network includes layer normalization. Conversely, reinitializing weights and units are equally effective at maintaining plasticity when the network is of sufficient size and does not include layer normalization. We found that reinitializing weights maintains plasticity in a wider variety of settings than reinitializing units.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00212v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>J. Fernando Hernandez-Garcia, Shibhansh Dohare, Jun Luo, Rich S. Sutton</dc:creator>
    </item>
    <item>
      <title>Sequential, Parallel and Consecutive Hybrid Evolutionary-Swarm Optimization Metaheuristics</title>
      <link>https://arxiv.org/abs/2508.00229</link>
      <description>arXiv:2508.00229v1 Announce Type: new 
Abstract: The goal of this paper is twofold. First, it explores hybrid evolutionary-swarm metaheuristics that combine the features of PSO and GA in a sequential, parallel and consecutive manner in comparison with their standard basic form: Genetic Algorithm and Particle Swarm Optimization. The algorithms were tested on a set of benchmark functions, including Ackley, Griewank, Levy, Michalewicz, Rastrigin, Schwefel, and Shifted Rotated Weierstrass, across multiple dimensions. The experimental results demonstrate that the hybrid approaches achieve superior convergence and consistency, especially in higher-dimensional search spaces. The second goal of this paper is to introduce a novel consecutive hybrid PSO-GA evolutionary algorithm that ensures continuity between PSO and GA steps through explicit information transfer mechanisms, specifically by modifying GA's variation operators to inherit velocity and personal best information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00229v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-97554-7_15</arxiv:DOI>
      <arxiv:journal_reference>Computational Science - ICCS 2025 Workshops, Lecture Notes in Computer Science, 15907, 203-218</arxiv:journal_reference>
      <dc:creator>Piotr Urba\'nczyk, Aleksandra Urba\'nczyk, Magdalena Kr\'ol, Leszek Rutkowski, Marek Kisiel-Dorohinicki</dc:creator>
    </item>
    <item>
      <title>Evolutionary Generative Optimization: Towards Fully Data-Driven Evolutionary Optimization via Generative Learning</title>
      <link>https://arxiv.org/abs/2508.00380</link>
      <description>arXiv:2508.00380v1 Announce Type: new 
Abstract: Recent advances in data-driven evolutionary algorithms (EAs) have demonstrated the potential of leveraging data to improve optimization accuracy and adaptability. Nevertheless, most existing approaches remain dependent on handcrafted heuristics, which limits their generality and automation. To address this challenge, we propose Evolutionary Generative Optimization (EvoGO), a fully data-driven framework empowered by generative learning. EvoGO streamlines the evolutionary optimization process into three stages: data preparation, model training, and population generation. The data preparation stage constructs a pairwise dataset to enrich training diversity without incurring additional evaluation costs. During model training, a tailored generative model learns to transform inferior solutions into superior ones. In the population generation stage, EvoGO replaces traditional reproduction operators with a scalable and parallelizable generative mechanism. Extensive experiments on numerical benchmarks, classical control problems, and high-dimensional robotic tasks demonstrate that EvoGO consistently converges within merely 10 generations and significantly outperforms a wide spectrum of optimization approaches, including traditional EAs, Bayesian optimization, and reinforcement learning based methods. Source code will be made publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00380v1</guid>
      <category>cs.NE</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kebin Sun, Tao Jiang, Ran Cheng, Yaochu Jin, Kay Chen Tan</dc:creator>
    </item>
    <item>
      <title>STF: Shallow-Level Temporal Feedback to Enhance Spiking Transformers</title>
      <link>https://arxiv.org/abs/2508.00387</link>
      <description>arXiv:2508.00387v1 Announce Type: new 
Abstract: Transformer-based Spiking Neural Networks (SNNs) suffer from a great performance gap compared to floating-point Artificial Neural Networks (ANNs) due to the binary nature of spike trains. Recent efforts have introduced deep-level feedback loops to transmit high-level semantic information to narrow this gap. However, these designs often span multiple deep layers, resulting in costly feature transformations, higher parameter overhead, increased energy consumption, and longer inference latency. To address this issue, we propose Shallow-level Temporal Feedback (STF), a lightweight plug-and-play module for the encoding layer, which consists of Temporal-Spatial Position Embedding (TSPE) and Temporal Feedback (TF).Extensive experiments show that STF consistently improves performance across various Transformer-based SNN backbones on static datasets, including CIFAR-10, CIFAR-100, and ImageNet-1K, under different spike timestep settings. Further analysis reveals that STF enhances the diversity of the spike patterns, which is key to performance gain. Moreover, evaluations on adversarial robustness and temporal sensitivity confirm that STF outperforms direct coding and its variants, highlighting its potential as a new spike encoding scheme for static scenarios. Our code will be released upon acceptance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00387v1</guid>
      <category>cs.NE</category>
      <category>cs.CV</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeqi Zheng, Zizheng Zhu, Yingchao Yu, Yanchen Huang, Changze Lv, Junfeng Tang, Zhaofei Yu, Yaochu Jin</dc:creator>
    </item>
    <item>
      <title>Anomaly detection with spiking neural networks for LHC physics</title>
      <link>https://arxiv.org/abs/2508.00063</link>
      <description>arXiv:2508.00063v1 Announce Type: cross 
Abstract: Anomaly detection offers a promising strategy for discovering new physics at the Large Hadron Collider (LHC). This paper investigates AutoEncoders built using neuromorphic Spiking Neural Networks (SNNs) for this purpose. One key application is at the trigger level, where anomaly detection tools could capture signals that would otherwise be discarded by conventional selection cuts. These systems must operate under strict latency and computational constraints. SNNs are inherently well-suited for low-latency, low-memory, real-time inference, particularly on Field-Programmable Gate Arrays (FPGAs). Further gains are expected with the rapid progress in dedicated neuromorphic hardware development. Using the CMS ADC2021 dataset, we design and evaluate a simple SNN AutoEncoder architecture. Our results show that the SNN AutoEncoders are competitive with conventional AutoEncoders for LHC anomaly detection across all signal models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00063v1</guid>
      <category>hep-ph</category>
      <category>cs.NE</category>
      <category>hep-ex</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Barry M. Dillon, Jim Harkin, Aqib Javed</dc:creator>
    </item>
    <item>
      <title>E2ATST: A Temporal-Spatial Optimized Energy-Efficient Architecture for Training Spiking Transformer</title>
      <link>https://arxiv.org/abs/2508.00475</link>
      <description>arXiv:2508.00475v1 Announce Type: cross 
Abstract: (1) Pengcheng Laboratory, (2) Southern University of Science and Technology, (3) Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, (4) University of Chinese Academy of Sciences</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00475v1</guid>
      <category>cs.AR</category>
      <category>cs.NE</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunhao Ma, Yanyu Lin, Mingjing Li, Puli Quan, Chenlin Zhou, Wenyue Zhang, Zhiwei Zhong, Wanyi Jia, Xueke Zhu, Qingyan Meng, Huihui Zhou, Fengwei An</dc:creator>
    </item>
    <item>
      <title>Foundations of Interpretable Models</title>
      <link>https://arxiv.org/abs/2508.00545</link>
      <description>arXiv:2508.00545v1 Announce Type: cross 
Abstract: We argue that existing definitions of interpretability are not actionable in that they fail to inform users about general, sound, and robust interpretable model design. This makes current interpretability research fundamentally ill-posed. To address this issue, we propose a definition of interpretability that is general, simple, and subsumes existing informal notions within the interpretable AI community. We show that our definition is actionable, as it directly reveals the foundational properties, underlying assumptions, principles, data structures, and architectural features necessary for designing interpretable models. Building on this, we propose a general blueprint for designing interpretable models and introduce the first open-sourced library with native support for interpretable data structures and processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00545v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>stat.ML</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pietro Barbiero, Mateo Espinosa Zarlenga, Alberto Termine, Mateja Jamnik, Giuseppe Marra</dc:creator>
    </item>
    <item>
      <title>Synthetic Biology meets Neuromorphic Computing: Towards a bio-inspired Olfactory Perception System</title>
      <link>https://arxiv.org/abs/2504.10053</link>
      <description>arXiv:2504.10053v2 Announce Type: replace 
Abstract: In this study, we explore how the combination of synthetic biology, neuroscience modeling, and neuromorphic electronic systems offers a new approach to creating an artificial system that mimics the natural sense of smell. We argue that a co-design approach offers significant advantages in replicating the complex dynamics of odor sensing and processing. We propose a hybrid system of synthetic sensory neurons that provides three key features: (a) receptor-gated ion channels, (b) interface between synthetic biology and semiconductors and (c) event-based encoding and computing based on spiking networks. Our approach is validated using simulation-based modeling of the complete sensing and processing pipeline. This research seeks to develop a platform for ultra-sensitive, specific, and energy-efficient odor detection, with potential implications for environmental monitoring, medical diagnostics, and security.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10053v2</guid>
      <category>cs.NE</category>
      <category>cs.ET</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 04 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1088/2634-4386/aded2d</arxiv:DOI>
      <arxiv:journal_reference>Neuromorphic Computing and Engineering, 2025, Volume 5, Number 3</arxiv:journal_reference>
      <dc:creator>Kevin Max, Larissa Sames, Shimeng Ye, Jan Steink\"uhler, Federico Corradi</dc:creator>
    </item>
  </channel>
</rss>
