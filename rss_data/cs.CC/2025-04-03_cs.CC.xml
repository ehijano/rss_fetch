<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Apr 2025 01:45:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Dichotomies for \#CSP on graphs that forbid a clique as a minor</title>
      <link>https://arxiv.org/abs/2504.01354</link>
      <description>arXiv:2504.01354v1 Announce Type: new 
Abstract: We prove complexity dichotomies for \#CSP problems (not necessarily symmetric) with Boolean domain and complex range on several typical minor-closed graph classes. These dichotomies give a complete characterization of the complexity of \#CSP on graph classes that forbid a complete graph as a minor. In particular, we also demonstrate that, whether the maximum degree of vertices is bounded may influence the complexity on specific minor-closed graph classes, and this phenomenon has never been observed in the previous related studies. Furthermore, our proofs integrate the properties of each graph class with the techniques from counting complexity, and develop a systematic approach for analyzing the complexity of \#CSP on these graph classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01354v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boning Meng, Yicheng Pan</dc:creator>
    </item>
    <item>
      <title>Lower Bounds for Leader Election and Collective Coin Flipping, Revisited</title>
      <link>https://arxiv.org/abs/2504.01856</link>
      <description>arXiv:2504.01856v1 Announce Type: new 
Abstract: We study the tasks of collective coin flipping and leader election in the full-information model.
  We prove new lower bounds for coin flipping protocols, implying lower bounds for leader election protocols. We show that any $k$-round coin flipping protocol, where each of $\ell$ players sends 1 bit per round, can be biased by $O(\ell/\log^{(k)}(\ell))$ bad players. For all $k&gt;1$ this strengthens previous lower bounds [RSZ, SICOMP 2002], which ruled out protocols resilient to adversaries controlling $O(\ell/\log^{(2k-1)}(\ell))$ players. Consequently, we establish that any protocol tolerating a linear fraction of corrupt players, with only 1 bit per round, must run for at least $\log^*\ell-O(1)$ rounds, improving on the prior best lower bound of $\frac12 \log^*\ell-\log^*\log^*\ell$. This lower bound matches the number of rounds, $\log^*\ell$, taken by the current best coin flipping protocols from [RZ, JCSS 2001], [F, FOCS 1999] that can handle a linear sized coalition of bad players, but with players sending unlimited bits per round. We also derive lower bounds for protocols allowing multi-bit messages per round. Our results show that the protocols from [RZ, JCSS 2001], [F, FOCS 1999] that handle a linear number of corrupt players are almost optimal in terms of round complexity and communication per player in a round.
  A key technical ingredient in proving our lower bounds is a new result regarding biasing most functions from a family of functions using a common set of bad players and a small specialized set of bad players specific to each function that is biased.
  We give improved constant-round coin flipping protocols in the setting that each player can send 1 bit per round. For two rounds, our protocol can handle $O(\ell/(\log\ell)(\log\log\ell)^2)$ sized coalition of bad players; better than the best one-round protocol by [AL, Combinatorica 1993] in this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01856v1</guid>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eshan Chattopadhyay, Mohit Gurumukhani, Noam Ringach, Rocco Servedio</dc:creator>
    </item>
    <item>
      <title>Recovery Reductions in the Random Noise Model via Group Theory: Insights into NP-Complete and Fine-Grained Problems</title>
      <link>https://arxiv.org/abs/2504.01899</link>
      <description>arXiv:2504.01899v1 Announce Type: new 
Abstract: We introduce and initiate the study of a new model of reductions called the random noise model. In this model, the truth table $T_f$ of the function $f$ is corrupted on a randomly chosen $\delta$-fraction of instances. A randomized algorithm $A$ is a $\left(t, \delta, 1-\varepsilon\right)$-recovery reduction for $f$ if:
  1. With probability $1-\varepsilon$ over the choice of $\delta$-fraction corruptions, given access to the corrupted truth table, the algorithm $A$ computes $f(\phi)$ correctly with probability at least $2/3$ on every input $\phi$.
  2. The algorithm $A$ runs in time $O(t)$.
  We believe this model, which is a natural relaxation of average-case complexity, both has practical motivations and is mathematically interesting.
  Pointing towards this, we show the existence of robust deterministic polynomial-time recovery reductions with the highest tolerable noise level for many of the canonical NP-complete problems - SAT, kSAT, kCSP, CLIQUE and more. Our recovery reductions are optimal for non-adaptive algorithms under complexity-theoretic assumptions. Notably, all our recovery reductions follow as corollaries of one black box algorithm based on group theory and permutation group algorithms. This suggests that recovery reductions in the random noise model are important to the study of the structure of NP-completeness.
  Furthermore, we establish recovery reductions with optimal parameters for Orthogonal Vectors and Parity $k$-Clique problems. These problems exhibit structural similarities to NP-complete problems, with Orthogonal Vectors admitting a $2^{0.5n}$-time reduction from kSAT on $n$ variables and Parity $k$-Clique, a subexponential-time reduction from 3SAT. This further highlights the relevance of our model to the study of NP-completeness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01899v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tejas Nareddy, Abhishek Mishra</dc:creator>
    </item>
    <item>
      <title>Epistemic Skills: Reasoning about Knowledge and Oblivion</title>
      <link>https://arxiv.org/abs/2504.01733</link>
      <description>arXiv:2504.01733v1 Announce Type: cross 
Abstract: This paper presents a class of epistemic logics that captures the dynamics of acquiring knowledge and descending into oblivion, while incorporating concepts of group knowledge. The approach is grounded in a system of weighted models, introducing an ``epistemic skills'' metric to represent the epistemic capacities tied to knowledge updates. Within this framework, knowledge acquisition is modeled as a process of upskilling, whereas oblivion is represented as a consequence of downskilling. The framework further enables exploration of ``knowability'' and ``forgettability,'' defined as the potential to gain knowledge through upskilling and to lapse into oblivion through downskilling, respectively. Additionally, it supports a detailed analysis of the distinctions between epistemic de re and de dicto expressions. The computational complexity of the model checking and satisfiability problems is examined, offering insights into their theoretical foundations and practical implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01733v1</guid>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaolong Liang, Y\`i N. W\'ang</dc:creator>
    </item>
    <item>
      <title>Distributed Triangle Detection is Hard in Few Rounds</title>
      <link>https://arxiv.org/abs/2504.01802</link>
      <description>arXiv:2504.01802v1 Announce Type: cross 
Abstract: In the distributed triangle detection problem, we have an $n$-vertex network $G=(V,E)$ with one player for each vertex of the graph who sees the edges incident on the vertex. The players communicate in synchronous rounds using the edges of this network and have a limited bandwidth of $O(\log{n})$ bits over each edge. The goal is to detect whether or not $G$ contains a triangle as a subgraph in a minimal number of rounds.
  We prove that any protocol (deterministic or randomized) for distributed triangle detection requires $\Omega(\log\log{n})$ rounds of communication. Prior to our work, only one-round lower bounds were known for this problem.
  The primary technique for proving these types of distributed lower bounds is via reductions from two-party communication complexity. However, it has been known for a while that this approach is provably incapable of establishing any meaningful lower bounds for distributed triangle detection. Our main technical contribution is a new information theoretic argument which combines recent advances on multi-pass graph streaming lower bounds with the point-to-point communication aspects of distributed models, and can be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01802v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DC</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sepehr Assadi, Janani Sundaresan</dc:creator>
    </item>
    <item>
      <title>The $\text{FP}^\text{NP}$ versus \#P dichotomy for \#EO</title>
      <link>https://arxiv.org/abs/2502.02012</link>
      <description>arXiv:2502.02012v2 Announce Type: replace 
Abstract: The complexity classification of the Holant problem has remained unresolved for the past fifteen years. Counting complex-weighted Eulerian orientation problems, denoted as \#EO, is regarded as one of the most significant challenges to the comprehensive complexity classification of the Holant problem. This article presents an $\text{FP}^\text{NP}$ vs. \#P dichotomy for \#EO, demonstrating that \#EO defined by a signature set is either \#P-hard or polynomial-time computable with a specific NP oracle. This result provides a comprehensive complexity classification for \#EO, and potentially leads to a dichotomy for the Holant problem. Furthermore, we derive three additional dichotomies related to the Holant problem from the dichotomy for \#EO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02012v2</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boning Meng, Juqiu Wang, Mingji Xia</dc:creator>
    </item>
    <item>
      <title>Fundamental computational limits of weak learnability in high-dimensional multi-index models</title>
      <link>https://arxiv.org/abs/2405.15480</link>
      <description>arXiv:2405.15480v4 Announce Type: replace-cross 
Abstract: Multi-index models - functions which only depend on the covariates through a non-linear transformation of their projection on a subspace - are a useful benchmark for investigating feature learning with neural nets. This paper examines the theoretical boundaries of efficient learnability in this hypothesis class, focusing on the minimum sample complexity required for weakly recovering their low-dimensional structure with first-order iterative algorithms, in the high-dimensional regime where the number of samples $n\!=\!\alpha d$ is proportional to the covariate dimension $d$. Our findings unfold in three parts: (i) we identify under which conditions a trivial subspace can be learned with a single step of a first-order algorithm for any $\alpha\!&gt;\!0$; (ii) if the trivial subspace is empty, we provide necessary and sufficient conditions for the existence of an easy subspace where directions that can be learned only above a certain sample complexity $\alpha\!&gt;\!\alpha_c$, where $\alpha_{c}$ marks a computational phase transition. In a limited but interesting set of really hard directions -- akin to the parity problem -- $\alpha_c$ is found to diverge. Finally, (iii) we show that interactions between different directions can result in an intricate hierarchical learning phenomenon, where directions can be learned sequentially when coupled to easier ones. We discuss in detail the grand staircase picture associated to these functions (and contrast it with the original staircase one). Our theory builds on the optimality of approximate message-passing among first-order iterative methods, delineating the fundamental learnability limit across a broad spectrum of algorithms, including neural networks trained with gradient descent, which we discuss in this context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15480v4</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.CC</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emanuele Troiani, Yatin Dandi, Leonardo Defilippis, Lenka Zdeborov\'a, Bruno Loureiro, Florent Krzakala</dc:creator>
    </item>
    <item>
      <title>Deriving differential approximation results for $k\,$CSPs from combinatorial designs</title>
      <link>https://arxiv.org/abs/2409.03903</link>
      <description>arXiv:2409.03903v2 Announce Type: replace-cross 
Abstract: Inapproximability results for $\mathsf{Max\,k\,CSP\!-\!q}$ have been traditionally established using balanced $t$-wise independent distributions, which are closely related to orthogonal arrays, a famous family of combinatorial designs. In this work, we investigate the role of these combinatorial structures in the context of the differential approximability of $\mathsf{k\,CSP\!-\!q}$, providing new structural insights and approximation bounds. We first establish a direct connection between the average differential ratio on $\mathsf{k\,CSP\!-\!q}$ instances and orthogonal arrays. This allows us to derive the new differential approximability bounds of $1/q^k$ for $(k +1)$-partite instances, $\Omega(1/n^{\lfloor k/2\rfloor})$ for Boolean instances, $\Omega(1/n)$ when $k =2$, and $\Omega(1/n^{k -\lceil\log_{\Theta(q)}k\rceil})$ when $k, q\geq 3$. We then introduce families of array pairs, called {\em alphabet reduction pairs of arrays}, that are still related to balanced $k$-wise independence. Using these pairs of arrays, we establish a reduction from $\mathsf{k\,CSP\!-\!q}$ to $\mathsf{k\,CSP\!-\!k}$ (where $q &gt;k$), with an expansion factor of $1/(q -k/2)^k$ on the differential approximation guarantee. Combining this with a 1998 result by Yuri Nesterov, we conclude that $\mathsf{2\,CSP\!-\!q}$ is approximable within a differential factor of $0.429/(q -1)^2$. Finally, using similar Boolean array pairs, {\em called cover pairs of arrays}, we prove that every Hamming ball of radius $k$ provides a $\Omega(1/n^k)$-approximation of the instance diameter. Thus, our work highlights the relevance of combinatorial designs for establishing structural differential approximation guarantees for CSPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03903v2</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jean-Fran\c{c}ois Culus, Sophie Toulouse</dc:creator>
    </item>
    <item>
      <title>An Exponential Separation Between Quantum and Quantum-Inspired Classical Algorithms for Linear Systems</title>
      <link>https://arxiv.org/abs/2411.02087</link>
      <description>arXiv:2411.02087v4 Announce Type: replace-cross 
Abstract: Achieving a provable exponential quantum speedup for an important machine learning task has been a central research goal since the seminal HHL quantum algorithm for solving linear systems and the subsequent quantum recommender systems algorithm by Kerenidis and Prakash. These algorithms were initially believed to be strong candidates for exponential speedups, but a lower bound ruling out similar classical improvements remained absent. In breakthrough work by Tang, it was demonstrated that this lack of progress in classical lower bounds was for good reasons. Concretely, she gave a classical counterpart of the quantum recommender systems algorithm, reducing the quantum advantage to a mere polynomial. Her approach is quite general and was named quantum-inspired classical algorithms. Since then, almost all the initially exponential quantum machine learning speedups have been reduced to polynomial via new quantum-inspired classical algorithms. From the current state-of-affairs, it is unclear whether we can hope for exponential quantum speedups for any natural machine learning task.
  In this work, we present the first such provable exponential separation between quantum and quantum-inspired classical algorithms for the basic problem of solving a linear system when the input matrix is well-conditioned and has sparse rows and columns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02087v4</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Allan Gr{\o}nlund, Kasper Green Larsen</dc:creator>
    </item>
    <item>
      <title>Vanishing of Schubert Coefficients</title>
      <link>https://arxiv.org/abs/2412.02064</link>
      <description>arXiv:2412.02064v3 Announce Type: replace-cross 
Abstract: Schubert coefficients are nonnegative integers $c^w_{u,v}$ that arise in Algebraic Geometry and play a central role in Algebraic Combinatorics. It is a major open problem whether they have a combinatorial interpretation, i.e, whether $c^w_{u,v} \in \#{\sf P}$. We study the closely related vanishing problem of Schubert coefficients: $\{c^w_{u,v}=^? 0\}$. Until this work it was open whether this problem is in the polynomial hierarchy ${\sf PH}$. We prove that $\{c^w_{u,v}=^? 0\}$ in ${\sf coAM}$ assuming the GRH. In particular, the vanishing problem is in ${\Sigma_2^{{\text{p}}}}$. Our approach is based on constructions lifted formulations, which give polynomial systems of equations for the problem. The result follows from a reduction to Parametric Hilbert's Nullstellensatz, recently studied in arXiv:2408.13027. We extend our results to all classical types. Type $D$ is resolved in the appendix (joint with David Speyer).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02064v3</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.AG</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Igor Pak, Colleen Robichaux</dc:creator>
    </item>
  </channel>
</rss>
