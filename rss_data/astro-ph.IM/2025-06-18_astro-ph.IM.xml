<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>astro-ph.IM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/astro-ph.IM</link>
    <description>astro-ph.IM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/astro-ph.IM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Jun 2025 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The ASAS-SN Low Surface Brightness Survey I: Proof-of-Concept and Potential Applications</title>
      <link>https://arxiv.org/abs/2506.14873</link>
      <description>arXiv:2506.14873v1 Announce Type: new 
Abstract: The ASAS-SN Low Surface Brightness Survey utilizes the $\sim7$ years of g-band CCD data from ASAS-SN (The All-Sky Automated Survey for Supernovae) to create stacked images of the entire sky. It is significantly deeper than previous photographic surveys. Our median/95th percentile cumulative exposure time per field is 58.1/86.8 hours, and our median $3{\sigma}$ g-band surface brightness limit off the Galactic plane ($|b| &gt; 20{\deg}$) is 26.1 mag arcsec$^{-2}$. We image large-scale diffuse structures within the Milky Way, such as multiple degree-spanning supernova remnants and star-forming nebulae, and tidal features of nearby galaxies. To quantify how effective our deep images are, we compare with a catalog of known ultra-diffuse galaxies and find a recovery rate of 82$\%$. In the future, we intend to use this data set to perform an all-sky search for new nearby dwarf galaxies, create an all-sky Galactic cirrus map, create an all-sky low surface brightness mosaic for public use, and more.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14873v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.GA</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evan Jennerjahn, Michael A. Tucker, Benjamin J. Shappee, Christopher S. Kochanek, Subo Dong, Annika H. G. Peter, Jose L. Prieto, K. Z. Stanek, Todd A. Thompson</dc:creator>
    </item>
    <item>
      <title>GalaxyGenius: A Mock Galaxy Image Generator for Various Telescopes from Hydrodynamical Simulations</title>
      <link>https://arxiv.org/abs/2506.15060</link>
      <description>arXiv:2506.15060v1 Announce Type: new 
Abstract: To advance research on galaxies in the era of large-scale sky surveys, we introduce GalaxyGenius, a Python package designed to produce synthetic galaxy images tailored to different telescopes based on hydrodynamical simulations. The package comprises three main modules: data preprocessing, ideal data cube generation, and mock observation. Specifically, the preprocessing module extracts necessary properties of star and gas particles for a selected subhalo from hydrodynamical simulations and creates the execution file for the following radiative transfer procedure. Subsequently, building on the above information, the ideal data cube generation module executes a widely-used radiative transfer project, specifically the SKIRT, to perform the SED assignment for each particle and the radiative transfer procedure to produce an IFU-like ideal data cube. Lastly, the mock observation module takes the ideal data cube and applies the throughputs of aiming telescopes while also incorporating the relevant instrumental effects, point spread functions (PSFs), and background noise to generate desired mock observational images of galaxies. To showcase the outcomes of GalaxyGenius, We create a series of mock images of galaxies based on the IllustrisTNG and EAGLE simulations for both space and ground-based surveys spanning from the ultraviolet to infrared wavelength coverages, including CSST, Euclid, HST, JWST, Roman, and HSC. GalaxyGenius offers a flexible framework developed to generate mock galaxy images with customizable recipes. These generated images can serve as valuable references for verifying and validating new approaches in astronomical research, and they can also act as training sets for deep learning relevant studies where real observational data are insufficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15060v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.GA</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Xingchen Zhou, Hang Yang, Nan Li, Qi Xiong, Furen Deng, Xian-Min Meng, Renhao Ye, Shiyin Shen, Peng Wei, Qifan Cui, Zizhao He, Ayodeji Ibitoye, Chengliang Wei, Yuedong Fang</dc:creator>
    </item>
    <item>
      <title>Procedures for Constraining Robotic Fiber Positioning for Highly Multiplexed Spectroscopic Surveys: The Case of FPS for SDSS-V</title>
      <link>https://arxiv.org/abs/2506.15475</link>
      <description>arXiv:2506.15475v1 Announce Type: new 
Abstract: One crucial aspect of planning any large scale astronomical survey is constructing an observing strategy that maximizes reduced data quality. This is especially important for surveys that are rather heterogeneous and broad-ranging in their science goals. The Sloan Digital Sky Survey V (SDSS-V), which now utilizes the Focal Plane System (FPS) to robotically place fibers that feed the spectrographs, certainly meets these criteria. The addition of the FPS facilities an increase in survey efficiency, number of targets and target diversity, but also means the positions of fibers must be constrained to allow for simultaneous observations of sometimes competing programs. The constraints on the positions of the fibers are clearly driven by properties of the science targets e.g., the type of target, brightness of the target, position of the target relative to others in the field, etc. The parameters used to describe these constraints will also depend on the intended science goal of the observation, which will vary with the types of objects requested for the particular observation and the planned sky conditions for the observation. In this work, we detail the SDSS-V data collection scenarios, which consist of sets of parameters that serve as the framework for constraining fiber placements. The numerical values of these parameters were set based on either past experiences or from a series of new tests, which we describe in detail here. These parameters allow a survey like SDSS-V to be algorithmically planned to maximize the science output, while guaranteeing data quality throughout its operation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15475v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ilija Medan, Tom Dwelly, Kevin R. Covey, Eleonora Zari, Michael R. Blanton, Joleen K. Carlberg, S. Drew Chojnowski, Alexander Ji, Yue Shen, John Donor, Jos\'e S\'anchez-Gallego, Sean Morrison, H\'ector J. Ibarra-Medel, Conor Sayres, Keivan G. Stassun</dc:creator>
    </item>
    <item>
      <title>EMUSE: Evolutionary Map of the Universe Search Engine</title>
      <link>https://arxiv.org/abs/2506.15090</link>
      <description>arXiv:2506.15090v1 Announce Type: cross 
Abstract: We present EMUSE (Evolutionary Map of the Universe Search Engine), a tool designed for searching specific radio sources within the extensive datasets of the EMU (Evolutionary Map of the Universe) survey, with potential applications to other Big Data challenges in astronomy. Built on a multimodal approach to radio source classification and retrieval, EMUSE fine-tunes the OpenCLIP model on curated radio galaxy datasets. Leveraging the power of foundation models, our work integrates visual and textual embeddings to enable efficient and flexible searches within large radio astronomical datasets. We fine-tune OpenCLIP using a dataset of 2,900 radio galaxies, encompassing various morphological classes, including FR-I, FR-II, FR-x, R-type, and other rare and peculiar sources. The model is optimized using adapter-based fine-tuning, ensuring computational efficiency while capturing the unique characteristics of radio sources. The fine-tuned model is then deployed in EMUSE, allowing for seamless image- and text-based queries over the EMU survey dataset. Our results demonstrate the model's effectiveness in retrieving and classifying radio sources, particularly in recognizing distinct morphological features. However, challenges remain in identifying rare or previously unseen radio sources, highlighting the need for expanded datasets and continuous refinement. This study showcases the potential of multimodal machine learning in radio astronomy, paving the way for more scalable and accurate search tools in the field. The search engine is accessible at https://askap-emuse.streamlit.app/ and can be used locally by cloning the repository at https://github.com/Nikhel1/EMUSE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15090v1</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhel Gupta, Zeeshan Hayder, Minh Huynh, Ray P. Norris, Lars Petersson, Andrew M. Hopkins, Simone Riggi, B\"arbel S. Koribalski, Miroslav D. Filipovi\'c</dc:creator>
    </item>
    <item>
      <title>Evolutionary models for the Very Massive Stars in the R136 cluster of 30 Doradus in the Large Magellanic Cloud</title>
      <link>https://arxiv.org/abs/2506.15230</link>
      <description>arXiv:2506.15230v1 Announce Type: cross 
Abstract: The cluster R136 in the LMC contains a population of stars in excess of 100 M$_\odot$, including R136a1, the most massive star known. Very Massive Stars (VMSs) play an influential role in feedback processes and may potentially produce exotic supernova types and black holes of tens of solar masses. The evolutionary history and final fate of the three most luminous stars, R136a1, R136a2, and R136a3, has been a puzzling issue. We aim to resolve this by rotating single-star MESA models. We produce interpolated model grids and apply a Markov-Chain Monte Carlo analysis to compare our models with observations. The nature of supernova progenitors strongly depends on mass loss and the AM coupling schemes. We predict no pair-instability and no GRB progenitors from our fiducial model grid at LMC metallicity. The onset of Wolf-Rayet-type mass-loss rates on the main sequence leads to a rapid decrease in stellar mass and luminosity. The mass turnover implies that the evolutionary history can only be inferred if additional constraints are available. We utilise the surface helium abundance, which poses a conundrum: R136a1, the most luminous star, is less enriched in helium than R136a2 and R136a3. We propose that this can be explained if both R136a2 and R136a3 were initially more massive than R136a1. From a rigorous confrontation of our models to spectroscopically-derived observables, we estimate an initial mass of 346$\pm41$ M$_\odot$ for R136a1, and $\gtrsim$500 M$_\odot$ for R136a2 and R136a3. Even though VMSs are only present in the youngest clusters below 2 Myr of age, our study strengthens their role in local and galaxy evolution. At LMC metallicity, they will be observable as helium-enriched massive stars after their drastic mass loss, produced via single-star evolution. If the core collapse leads to a supernova, it will be of Type Ib/c. [abridged]</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15230v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Z. Keszthelyi, S. A. Brands, A. de Koter, N. Langer, J. Puls</dc:creator>
    </item>
    <item>
      <title>Cosmic curl -- Features and convergence of the vorticity power spectrum in $N$-body simulations</title>
      <link>https://arxiv.org/abs/2506.15486</link>
      <description>arXiv:2506.15486v1 Announce Type: cross 
Abstract: Observations of the cosmic velocity field could become an important cosmological probe in the near future. To take advantage of future velocity-flow surveys we must however have the theoretical predictions under control. In many respects, the velocity field is easier to simulate than the density field because it is less severely affected by small-scale clustering. Therefore, as we also show in this paper, a particle-mesh (PM) based simulation approach is usually sufficient, yielding results within a few percent of a corresponding P$^3$M simulation in which short-range forces are properly accounted for, but which also carry a much larger computational cost.
  However, in other respects the velocity field is much more challenging to deal with than the density field: Interpolating the velocity field onto a grid is significantly more complicated, and the vorticity field (the curl-part of the velocity field) is severely affected by both sample variance and discretisation effects. While the former can be dealt with using fixed amplitude initial conditions, the former makes it infeasible to run fully converged simulations in a cosmological volume. However, using the $N$-body code CONCEPT we show that one can robustly extrapolate the cosmic vorticity power spectrum from just 4 simulations with different number of particles. We expect our extrapolated vorticity power spectra to be correct within 5\% of the fully converged result across three orders of magnitude in $k$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15486v1</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Camilla T. G. S{\o}rensen, Steen Hannestad, Thomas Tram</dc:creator>
    </item>
    <item>
      <title>Regularizing the Pulsar Timing Array likelihood: A path towards Fourier Space</title>
      <link>https://arxiv.org/abs/2412.11894</link>
      <description>arXiv:2412.11894v3 Announce Type: replace 
Abstract: The recent announcement of evidence for a stochastic background of gravitational waves (GWB) in pulsar timing array (PTA) data has piqued interest across the scientific community. A combined analysis of all currently available data holds the promise of confirming the announced evidence as a solid detection of a GWB. However, the complexity of individual pulsar noise models and the variety of modeling tools used for different types of pulsars present significant challenges for a truly unified analysis. In this work we propose a novel approach to the analysis of PTA data: first a posterior distribution over Fourier modes is produced for each pulsar individually. Then, in a global analysis of all pulsars these posterior distributions can be re-used for a GWB search, which retains all information regarding the signals of interest without the added complexity of the underlying noise models or implementation differences. This approach facilitates combining radio and gamma-ray pulsar data, while reducing the complexity of the model and of its implementations when carrying out a GWB search with PTA data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11894v3</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <category>gr-qc</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Serena Valtolina, Rutger van Haasteren</dc:creator>
    </item>
    <item>
      <title>Differentiable and accelerated spherical harmonic and Wigner transforms</title>
      <link>https://arxiv.org/abs/2311.14670</link>
      <description>arXiv:2311.14670v3 Announce Type: replace-cross 
Abstract: Many areas of science and engineering encounter data defined on spherical manifolds. Modelling and analysis of spherical data often necessitates spherical harmonic transforms, at high degrees, and increasingly requires efficient computation of gradients for machine learning or other differentiable programming tasks. We develop novel algorithmic structures for accelerated and differentiable computation of generalised Fourier transforms on the sphere $\mathbb{S}^2$ and rotation group $\text{SO}(3)$, i.e. spherical harmonic and Wigner transforms, respectively. We present a recursive algorithm for the calculation of Wigner $d$-functions that is both stable to high harmonic degrees and extremely parallelisable. By tightly coupling this with separable spherical transforms, we obtain algorithms that exhibit an extremely parallelisable structure that is well-suited for the high throughput computing of modern hardware accelerators (e.g. GPUs). We also develop a hybrid automatic and manual differentiation approach so that gradients can be computed efficiently. Our algorithms are implemented within the JAX differentiable programming framework in the S2FFT software code. Numerous samplings of the sphere are supported, including equiangular and HEALPix sampling. Computational errors are at the order of machine precision for spherical samplings that admit a sampling theorem. When benchmarked against alternative C codes we observe up to a 400-fold acceleration. Furthermore, when distributing over multiple GPUs we achieve very close to optimal linear scaling with increasing number of GPUs due to the highly parallelised and balanced nature of our algorithms. Provided access to sufficiently many GPUs our transforms thus exhibit an unprecedented effective linear time complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14670v3</guid>
      <category>physics.comp-ph</category>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jcp.2024.113109</arxiv:DOI>
      <dc:creator>Matthew A. Price, Jason D. McEwen</dc:creator>
    </item>
    <item>
      <title>Quantum Limits of Exoplanet Detection and Localization</title>
      <link>https://arxiv.org/abs/2403.17988</link>
      <description>arXiv:2403.17988v3 Announce Type: replace-cross 
Abstract: Discovering exoplanets in orbit around distant stars via direct imaging is fundamentally impeded by the combined effect of optical diffraction and photon shot noise under extreme star-planet contrast. Coronagraphs strive to increase the signal-to-noise ratio of exoplanet signatures by optically suppressing light from the host star while preserving light from the exoplanet. However, it is unclear whether direct imaging coronagraphs constitute an optimal strategy for attaining fundamental limits relevant to exoplanet discovery. In this work, we first review the quantum information limits of exoplanet detection and localization characterized by (1) the quantum Chernoff exponent for symmetric hypothesis testing, (2) the quantum relative entropy for asymmetric hypothesis testing, and (3) the quantum Fisher information matrix for multiparameter estimation. We demonstrate that coronagraphs designed to completely suppress light in the fundamental mode of the telescope - while perfectly transmitting higher-order orthogonal modes - indeed achieve these limits in the regime of high star-planet contrasts. Furthermore, we formulate coronagraphs as quantum channels, thus generalizing the classical framework of coronography to the quantum setting. Using this framework, we compare the information-theoretic performance of leading coronagraph designs against the quantum limits. Our analysis indicates that quantum-optimal coronagraphs offer enhanced information efficiency in the sub-diffraction regime compared to leading coronagraph designs and may significantly expand the domain of accessible exoplanets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17988v3</guid>
      <category>quant-ph</category>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nico Deshler, Sebastiaan Haffert, Amit Ashok</dc:creator>
    </item>
    <item>
      <title>Assessing the Impact of Unequal Noises and Foreground Modeling on SGWB Reconstruction with LISA</title>
      <link>https://arxiv.org/abs/2410.10342</link>
      <description>arXiv:2410.10342v2 Announce Type: replace-cross 
Abstract: In the search for stochastic gravitational wave backgrounds (SGWB) of cosmological origin with LISA, it is crucial to account for realistic complications in the noise and astrophysical foreground modeling that may impact the signal reconstruction. To address these challenges, we updated the $\texttt{SGWBinner}$ code to incorporate both variable noise levels across LISA arms and more complex foreground spectral shapes. Our findings suggest that, while moderate variations of the noise amplitudes have a minimal impact, poor foreground modeling (i.e., templates requiring many free parameters) significantly degrades the reconstruction of cosmological signals. This underlines the importance of accurate modeling and subtraction of the astrophysical foregrounds to characterize possible cosmological components. To perform this more challenging analysis, we have integrated the $\texttt{JAX}$ framework, which significantly improves the computational efficiency of the code, in the $\texttt{SGWBinner}$ code, enabling faster Bayesian likelihood sampling and more effective exploration of complex SGWB signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10342v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1475-7516/2025/06/030</arxiv:DOI>
      <arxiv:journal_reference>JCAP 06 (2025) 030</arxiv:journal_reference>
      <dc:creator>Jun'ya Kume, Marco Peloso, Mauro Pieroni, Angelo Ricciardone</dc:creator>
    </item>
  </channel>
</rss>
