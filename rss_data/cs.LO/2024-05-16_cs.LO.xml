<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 May 2024 04:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 17 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the logical structure of some maximality and well-foundedness principles equivalent to choice principles</title>
      <link>https://arxiv.org/abs/2405.09946</link>
      <description>arXiv:2405.09946v1 Announce Type: new 
Abstract: We study the logical structure of Teichm{\"u}ller-Tukey lemma, a maximality principle equivalent to the axiom of choice and show that it corresponds to the generalisation to arbitrary cardinals of update induction, a well-foundedness principle from constructive mathematics classically equivalent to the axiom of dependent choice.From there, we state general forms of maximality and well-foundedness principles equivalent to the axiom of choice, including a variant of Zorn's lemma. A comparison with the general class of choice and bar induction principles given by Brede and the first author is initiated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09946v1</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo Herbelin (PICUBE, IRIF)</dc:creator>
    </item>
    <item>
      <title>Decidability of Quasi-Dense Modal Logics</title>
      <link>https://arxiv.org/abs/2405.10094</link>
      <description>arXiv:2405.10094v1 Announce Type: new 
Abstract: The decidability of axiomatic extensions of the modal logic K with modal reduction principles, i.e. axioms of the form $\Diamond^{k} p \rightarrow \Diamond^{n} p$, has remained a long-standing open problem. In this paper, we make significant progress toward solving this problem and show that decidability holds for a large subclass of these logics, namely, for 'quasi-dense logics.' Such logics are extensions of K with with modal reduction axioms such that $0 &lt; k &lt; n$ (dubbed 'quasi-density axioms'). To prove decidability, we define novel proof systems for quasi-dense logics consisting of disjunctive existential rules, which are first-order formulae typically used to specify ontologies in the context of database theory. We show that such proof systems can be used to generate proofs and models of modal formulae, and provide an intricate model-theoretic argument showing that such generated models can be encoded as finite objects called 'templates.' By enumerating templates of bound size, we obtain an EXPSPACE decision procedure as a consequence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10094v1</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Piotr Ostropolski-Nalewaja, Tim S. Lyon</dc:creator>
    </item>
    <item>
      <title>Compositional Value Iteration with Pareto Caching</title>
      <link>https://arxiv.org/abs/2405.10099</link>
      <description>arXiv:2405.10099v1 Announce Type: new 
Abstract: The de-facto standard approach in MDP verification is based on value iteration (VI). We propose compositional VI, a framework for model checking compositional MDPs, that addresses efficiency while maintaining soundness. Concretely, compositional MDPs naturally arise from the combination of individual components, and their structure can be expressed using, e.g., string diagrams. Towards efficiency, we observe that compositional VI repeatedly verifies individual components. We propose a technique called Pareto caching that allows to reuse verification results, even for previously unseen queries. Towards soundness, we present two stopping criteria: one generalizes the optimistic value iteration paradigm and the other uses Pareto caches in conjunction with recent baseline algorithms. Our experimental evaluations shows the promise of the novel algorithm and its variations, and identifies challenges for future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10099v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kazuki Watanabe, Marck van der Vegt, Sebastian Junges, Ichiro Hasuo</dc:creator>
    </item>
    <item>
      <title>Delooping cyclic groups with lens spaces in homotopy type theory</title>
      <link>https://arxiv.org/abs/2405.10149</link>
      <description>arXiv:2405.10149v1 Announce Type: new 
Abstract: In the setting of homotopy type theory, each type can be interpreted as a space. Moreover, given an element of a type, i.e. a point in the corresponding space, one can define another type which encodes the space of loops based at this point. In particular, when the type we started with is a groupoid, this loop space is always a group. Conversely, to every group we can associate a type (more precisely, a pointed connected groupoid) whose loop space is this group: this operation is called delooping. The generic procedures for constructing such deloopings of groups (based on torsors, or on descriptions of Eilenberg-MacLane spaces as higher inductive types) are unfortunately equipped with elimination principles which do not directly allow eliminating to untruncated types, and are thus difficult to work with in practice. Here, we construct deloopings of the cyclic groups $\mathbb{Z}_m$ which are cellular, and thus do not suffer from this shortcoming. In order to do so, we provide type-theoretic implementations of lens spaces, which constitute an important family of spaces in algebraic topology. Our definition is based on the computation of an iterative join of suitable maps from the circle to an arbitrary delooping of $\mathbb{Z}_m$. In some sense, this work generalizes the construction of real projective spaces by Buchholtz and Rijke, which handles the case m=2, although the general setting requires more involved tools. Finally, we use this construction to also provide cellular descriptions of dihedral groups, and explain how we can hope to use those to compute the cohomology and higher actions of such groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10149v1</guid>
      <category>cs.LO</category>
      <category>math.AT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Samuel Mimram, \'Emile Oleon</dc:creator>
    </item>
    <item>
      <title>Braids, twists, trace and duality in combinatory algebras</title>
      <link>https://arxiv.org/abs/2405.10152</link>
      <description>arXiv:2405.10152v1 Announce Type: new 
Abstract: We investigate a class of combinatory algebras, called ribbon combinatory algebras, in which we can interpret both the braided untyped linear lambda calculus and framed oriented tangles. Any reflexive object in a ribbon category gives rise to a ribbon combinatory algebra. Conversely, From a ribbon combinatory algebra, we can construct a ribbon category with a reflexive object, from which the combinatory algebra can be recovered. To show this, and also to give the equational characterisation of ribbon combinatory algebras, we make use of the internal PRO construction developed in Hasegawa's recent work. Interestingly, we can characterise ribbon combinatory algebras in two different ways: as balanced combinatory algebras with a trace combinator, and as balanced combinatory algebras with duality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10152v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3661814.3662098</arxiv:DOI>
      <dc:creator>Masahito Hasegawa, Serge Lechenne</dc:creator>
    </item>
    <item>
      <title>Efficient Implementation of an Abstract Domain of Quantified First-Order Formulas</title>
      <link>https://arxiv.org/abs/2405.10308</link>
      <description>arXiv:2405.10308v1 Announce Type: new 
Abstract: This paper lays a practical foundation for using abstract interpretation with an abstract domain that consists of sets of quantified first-order logic formulas. This abstract domain seems infeasible at first sight due to the complexity of the formulas involved and the enormous size of sets of formulas (abstract elements). We introduce an efficient representation of abstract elements, which eliminates redundancies based on a novel syntactic subsumption relation that under-approximates semantic entailment. We develop algorithms and data-structures to efficiently compute the join of an abstract element with the abstraction of a concrete state, operating on the representation of abstract elements. To demonstrate feasibility of the domain, we use our data structures and algorithms to implement a symbolic abstraction algorithm that computes the least fixpoint of the best abstract transformer of a transition system, which corresponds to the strongest inductive invariant. We succeed at finding, for example, the least fixpoint for Paxos (which in our representation has 1,438 formulas with forall-exists-forall quantification) in time comparable to state-of-the-art property-directed approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10308v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eden Frenkel, Tej Chaged, Oded Padon, Sharon Shoham</dc:creator>
    </item>
    <item>
      <title>Cut Elimination of Intuitionistic Tense Logic</title>
      <link>https://arxiv.org/abs/2405.09970</link>
      <description>arXiv:2405.09970v1 Announce Type: cross 
Abstract: In this paper, we use a new method to prove cut-elimination of intuitionistic tense logic. This method focuses on splitting the contraction rule and cut rules. Further general theories and applications of this method shall be developed in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09970v1</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiheng Wang, Yu Peng, Zhe Lin</dc:creator>
    </item>
    <item>
      <title>Global Benchmark Database</title>
      <link>https://arxiv.org/abs/2405.10045</link>
      <description>arXiv:2405.10045v1 Announce Type: cross 
Abstract: This paper presents Global Benchmark Database (GBD), a comprehensive suite of tools for provisioning and sustainably maintaining benchmark instances and their metadata. The availability of benchmark metadata is essential for many tasks in empirical research, e.g., for the data-driven compilation of benchmarks, the domain-specific analysis of runtime experiments, or the instance-specific selection of solvers. In this paper, we introduce the data model of GBD as well as its interfaces and provide examples of how to interact with them. We also demonstrate the integration of custom data sources and explain how to extend GBD with additional problem domains, instance formats and feature extractors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10045v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Markus Iser, Christoph Jabs</dc:creator>
    </item>
    <item>
      <title>What are kets?</title>
      <link>https://arxiv.org/abs/2405.10055</link>
      <description>arXiv:2405.10055v1 Announce Type: cross 
Abstract: According to Dirac's bra-ket notation, in an inner-product space, the inner product $\langle x\,|\,y\rangle$ of vectors $x,y$ can be viewed as an application of the bra $\langle x|$ to the ket $|y\rangle$. Here $\langle x|$ is the linear functional $|y\rangle \mapsto \langle x\,|\,y\rangle$ and $|y\rangle$ is the vector $y$. But often -- though not always -- there are advantages in seeing $|y\rangle$ as the function $a \mapsto a\cdot y$ where $a$ ranges over the scalars. For example, the outer product $|y\rangle\langle x|$ becomes simply the composition $|y\rangle \circ \langle x|$. It would be most convenient to view kets sometimes as vectors and sometimes as functions, depending on the context. This turns out to be possible. While the bra-ket notation arose in quantum mechanics, this note presupposes no familiarity with quantum mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10055v1</guid>
      <category>quant-ph</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuri Gurevich, Andreas Blass</dc:creator>
    </item>
    <item>
      <title>SMLP: Symbolic Machine Learning Prover (User Manual)</title>
      <link>https://arxiv.org/abs/2405.10215</link>
      <description>arXiv:2405.10215v1 Announce Type: cross 
Abstract: SMLP: Symbolic Machine Learning Prover an open source tool for exploration and optimization of systems represented by machine learning models. SMLP uses symbolic reasoning for ML model exploration and optimization under verification and stability constraints, based on SMT, constraint and NN solvers. In addition its exploration methods are guided by probabilistic and statistical methods. SMLP is a general purpose tool that requires only data suitable for ML modelling in the csv format (usually samples of the system's input/output). SMLP has been applied at Intel for analyzing and optimizing hardware designs at the analog level. Currently SMLP supports NNs, polynomial and tree models, and uses SMT solvers for reasoning and optimization at the backend, integration of specialized NN solvers is in progress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10215v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>cs.SC</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Franz Brau{\ss}e, Zurab Khasidashvili, Konstantin Korovin</dc:creator>
    </item>
    <item>
      <title>The Pebble-Relation Comonad in Finite Model Theory</title>
      <link>https://arxiv.org/abs/2110.08196</link>
      <description>arXiv:2110.08196v5 Announce Type: replace 
Abstract: The pebbling comonad, introduced by Abramsky, Dawar and Wang, provides a categorical interpretation for the k-pebble games from finite model theory. The coKleisli category of the pebbling comonad specifies equivalences under different fragments and extensions of infinitary k-variable logic. Moreover, the coalgebras over this pebbling comonad characterise treewidth and correspond to tree decompositions. In this paper we introduce the pebble-relation comonad, which characterises pathwidth and whose coalgebras correspond to path decompositions. We further show that the existence of a coKleisli morphism in this comonad is equivalent to truth preservation in the restricted conjunction fragment of k-variable infinitary logic. We do this using Dalmau's pebble-relation game and an equivalent all-in-one pebble game. We then provide a similar treatment to the corresponding coKleisli isomorphisms via a bijective version of the all-in-one pebble game. Finally, we show as a consequence a new Lov\'asz-type theorem relating pathwidth to the restricted conjunction fragment of k-variable infinitary logic with counting quantifiers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.08196v5</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yo\`av Montacute, Nihil Shah</dc:creator>
    </item>
    <item>
      <title>Bialgebraic Reasoning on Higher-Order Program Equivalence</title>
      <link>https://arxiv.org/abs/2402.00625</link>
      <description>arXiv:2402.00625v2 Announce Type: replace 
Abstract: Logical relations constitute a key method for reasoning about contextual equivalence of programs in higher-order languages. They are usually developed on a per-case basis, with a new theory required for each variation of the language or of the desired notion of equivalence. In the present paper we introduce a general construction of (step-indexed) logical relations at the level of Higher-Order Mathematical Operational Semantics, a highly parametric categorical framework for modeling the operational semantics of higher-order languages. Our main result asserts that for languages whose weak operational model forms a lax bialgebra, the logical relation is automatically sound for contextual equivalence. Our abstract theory is shown to instantiate to combinatory logics and $\lambda$-calculi with recursive types, and to different flavours of contextual equivalence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00625v2</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3661814.3662099</arxiv:DOI>
      <dc:creator>Sergey Goncharov, Stefan Milius, Stelios Tsampas, Henning Urbat</dc:creator>
    </item>
    <item>
      <title>Permissible Knowledge Pooling</title>
      <link>https://arxiv.org/abs/2404.03418</link>
      <description>arXiv:2404.03418v3 Announce Type: replace 
Abstract: Information pooling has been extensively formalised across various logical frameworks in distributed systems, characterized by diverse information-sharing patterns. These approaches generally adopt an intersection perspective, aggregating all possible information, regardless of whether it is known or unknown to the agents. In contrast, this work adopts a unique stance, emphasising that sharing knowledge means distributing what is known, rather than what remains uncertain. This paper introduces new modal logics for knowledge pooling and sharing, ranging from a novel language of knowledge pooling to a dynamic mechanism for knowledge sharing. It also outlines their axiomatizations and discusses a potential framework for permissible knowledge pooling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03418v3</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huimin Dong</dc:creator>
    </item>
    <item>
      <title>Equational Theories and Validity for Logically Constrained Term Rewriting (Full Version)</title>
      <link>https://arxiv.org/abs/2405.01174</link>
      <description>arXiv:2405.01174v2 Announce Type: replace 
Abstract: Logically constrained term rewriting is a relatively new formalism where rules are equipped with constraints over some arbitrary theory. Although there are many recent advances with respect to rewriting induction, completion, complexity analysis and confluence analysis for logically constrained term rewriting, these works solely focus on the syntactic side of the formalism lacking detailed investigations on semantics. In this paper, we investigate a semantic side of logically constrained term rewriting. To this end, we first define constrained equations, constrained equational theories and validity of the former based on the latter. After presenting the relationship of validity and conversion of rewriting, we then construct a sound inference system to prove validity of constrained equations in constrained equational theories. Finally, we give an algebraic semantics, which enables one to establish invalidity of constrained equations in constrained equational theories. This algebraic semantics derive a new notion of consistency for constrained equational theories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01174v2</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takahito Aoto, Naoki Nishida, Jonas Sch\"opf</dc:creator>
    </item>
    <item>
      <title>Scaling the weight parameters in Markov logic networks and relational logistic regression models</title>
      <link>https://arxiv.org/abs/2103.15140</link>
      <description>arXiv:2103.15140v3 Announce Type: replace-cross 
Abstract: We consider Markov logic networks and relational logistic regression as two fundamental representation formalisms in statistical relational artificial intelligence that use weighted formulas in their specification. However, Markov logic networks are based on undirected graphs, while relational logistic regression is based on directed acyclic graphs. We show that when scaling the weight parameters with the domain size, the asymptotic behaviour of a relational logistic regression model is transparently controlled by the parameters, and we supply an algorithm to compute asymptotic probabilities. We also show using two examples that this is not true for Markov logic networks. We also discuss using several examples, mainly from the literature, how the application context can help the user to decide when such scaling is appropriate and when using the raw unscaled parameters might be preferable. We highlight random sampling as a particularly promising area of application for scaled models and expound possible avenues for further research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.15140v3</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix Weitk\"amper</dc:creator>
    </item>
    <item>
      <title>Probabilities of the third type: Statistical Relational Learning and Reasoning with Relative Frequencies</title>
      <link>https://arxiv.org/abs/2202.10367</link>
      <description>arXiv:2202.10367v3 Announce Type: replace-cross 
Abstract: Dependencies on the relative frequency of a state in the domain are common when modelling probabilistic dependencies on relational data. For instance, the likelihood of a school closure during an epidemic might depend on the proportion of infected pupils exceeding a threshold. Often, rather than depending on discrete thresholds, dependencies are continuous: for instance, the likelihood of any one mosquito bite transmitting an illness depends on the proportion of carrier mosquitoes. Current approaches usually only consider probabilities over possible worlds rather than over domain elements themselves. An exception are the recently introduced Lifted Bayesian Networks for Conditional Probability Logic, which express discrete dependencies on probabilistic data. We introduce functional lifted Bayesian networks, a formalism that explicitly incorporates continuous dependencies on relative frequencies into statistical relational artificial intelligence. and compare and contrast them with ifted Bayesian Networks for Conditional Probability Logic. Incorporating relative frequencies is not only beneficial to modelling; it also provides a more rigorous approach to learning problems where training and test or application domains have different sizes. To this end, we provide a representation of the asymptotic probability distributions induced by functional lifted Bayesian networks on domains of increasing sizes. Since that representation has well-understood scaling behaviour across domain sizes, it can be used to estimate parameters for a large domain consistently from randomly sampled subpopulations. Furthermore, we show that in parametric families of FLBN, convergence is uniform in the parameters, which ensures a meaningful dependence of the asymptotic probabilities on the parameters of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.10367v3</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix Weitk\"amper</dc:creator>
    </item>
    <item>
      <title>Strict universes for Grothendieck topoi</title>
      <link>https://arxiv.org/abs/2202.12012</link>
      <description>arXiv:2202.12012v3 Announce Type: replace-cross 
Abstract: Hofmann and Streicher famously showed how to lift Grothendieck universes into presheaf topoi, and Streicher has extended their result to the case of sheaf topoi by sheafification. In parallel, van den Berg and Moerdijk have shown in the context of algebraic set theory that similar constructions continue to apply even in weaker metatheories. Unfortunately, sheafification seems not to preserve an important realignment property enjoyed by the presheaf universes that plays a critical role in models of univalent type theory as well as synthetic Tait computability, a recent technique to establish syntactic properties of type theories and programming languages. In the context of multiple universes, the realignment property also implies a coherent choice of codes for connectives at each universe level, thereby interpreting the cumulativity laws present in popular formulations of Martin-L\"of type theory.
  We observe that a slight adjustment to an argument of Shulman constructs a cumulative universe hierarchy satisfying the realignment property at every level in any Grothendieck topos. Hence one has direct-style interpretations of Martin-L\"of type theory with cumulative universes into all Grothendieck topoi. A further implication is to extend the reach of recent synthetic methods in the semantics of cubical type theory and the syntactic metatheory of type theory and programming languages to all Grothendieck topoi.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.12012v3</guid>
      <category>math.CT</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Gratzer, Michael Shulman, Jonathan Sterling</dc:creator>
    </item>
    <item>
      <title>How should I compute my candidates? A taxonomy and classification of diagnosis computation algorithms</title>
      <link>https://arxiv.org/abs/2207.12583</link>
      <description>arXiv:2207.12583v2 Announce Type: replace-cross 
Abstract: This work proposes a taxonomy for diagnosis computation methods which allows their standardized assessment, classification and comparison. The aim is to (i) give researchers and practitioners an impression of the diverse landscape of available diagnostic techniques, (ii) allow them to easily retrieve the main features as well as pros and cons of the approaches, (iii) enable an easy and clear comparison of the techniques based on their characteristics wrt. a list of important and well-defined properties, and (iv) facilitate the selection of the "right" algorithm to adopt for a particular problem case, e.g., in practical diagnostic settings, for comparison in experimental evaluations, or for reuse, modification, extension, or improvement in the course of research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.12583v2</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.3233/FAIA230490</arxiv:DOI>
      <arxiv:journal_reference>ECAI 2023: 1986-1993</arxiv:journal_reference>
      <dc:creator>Patrick Rodler</dc:creator>
    </item>
    <item>
      <title>Neurosymbolic AI for Reasoning over Knowledge Graphs: A Survey</title>
      <link>https://arxiv.org/abs/2302.07200</link>
      <description>arXiv:2302.07200v3 Announce Type: replace-cross 
Abstract: Neurosymbolic AI is an increasingly active area of research that combines symbolic reasoning methods with deep learning to leverage their complementary benefits. As knowledge graphs are becoming a popular way to represent heterogeneous and multi-relational data, methods for reasoning on graph structures have attempted to follow this neurosymbolic paradigm. Traditionally, such approaches have utilized either rule-based inference or generated representative numerical embeddings from which patterns could be extracted. However, several recent studies have attempted to bridge this dichotomy to generate models that facilitate interpretability, maintain competitive performance, and integrate expert knowledge. Therefore, we survey methods that perform neurosymbolic reasoning tasks on knowledge graphs and propose a novel taxonomy by which we can classify them. Specifically, we propose three major categories: (1) logically-informed embedding approaches, (2) embedding approaches with logical constraints, and (3) rule learning approaches. Alongside the taxonomy, we provide a tabular overview of the approaches and links to their source code, if available, for more direct comparison. Finally, we discuss the unique characteristics and limitations of these methods, then propose several prospective directions toward which this field of research could evolve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.07200v3</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lauren Nicole DeLong (The University of Edinburgh School of Informatics, Artificial Intelligence,its Applications Institute), Ramon Fern\'andez Mir (The University of Edinburgh School of Informatics, Artificial Intelligence,its Applications Institute), Jacques D. Fleuriot (The University of Edinburgh School of Informatics, Artificial Intelligence,its Applications Institute)</dc:creator>
    </item>
  </channel>
</rss>
