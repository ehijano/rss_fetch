<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Jun 2025 04:01:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Robust predicate and function computation in continuous chemical reaction networks</title>
      <link>https://arxiv.org/abs/2506.06590</link>
      <description>arXiv:2506.06590v1 Announce Type: new 
Abstract: We initiate the study of rate-constant-independent computation of Boolean predicates and numerical functions in the continuous model of chemical reaction networks (CRNs), which model the amount of a chemical species as a nonnegative, real-valued *concentration*. Real-valued numerical functions have previously been studied, finding that exactly the continuous, piecewise rational linear functions $f: \mathbb{R}_{&gt; 0}^k \to \mathbb{R}_{&gt; 0}$ can be computed *stably*, a.k.a., *rate-independently*, meaning that the CRN gets the answer correct no matter the rate at which reactions occur.
  We show that, contrary to functions, continuous CRNs are severely limited in the Boolean predicates they can stably decide, reporting an answer based only on which inputs are 0 or positive.
  This limitation motivates a slightly relaxed notion of rate-independent computation in CRNs that we call *robust computation*. The standard mass-action rate model is used, in which each reaction is assigned a rate equal to the product of its reactant concentrations and its rate constant. The computation is correct in this model if it converges to the correct output for any positive choice of rate constants. This adversary is weaker than the stable computation adversary, the latter being able to run reactions at non-mass-action rates.
  We show that CRNs can robustly decide every finite Boolean combination of *threshold predicates*: those predicates defined by taking a rational weighted sum of the inputs $\mathbf{x} \in \mathbb{R}^k_{\ge 0}$ and comparing to a constant, answering the question ``Is $\sum_{i=1}^k w_i \cdot \mathbf{x}(i) &gt; h$?'', for rational weights $w_i$ and real threshold $h$. Turning to function computation, we show that CRNs can robustly compute any piecewise affine function with rational coefficients, where threshold predicates determine which affine piece to evaluate for a given input.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06590v1</guid>
      <category>cs.CC</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kim Calabrese, David Doty, Mina Latifi</dc:creator>
    </item>
    <item>
      <title>#P is Sandwiched by One and Two #2DNF Calls: Is Subtraction Stronger Than We Thought?</title>
      <link>https://arxiv.org/abs/2506.06716</link>
      <description>arXiv:2506.06716v1 Announce Type: new 
Abstract: The canonical class in the realm of counting complexity is #P. It is well known that the problem of counting the models of a propositional formula in disjunctive normal form (#DNF) is complete for #P under Turing reductions. On the other hand, #DNF $\in$ spanL and spanL $\not\subseteq$ #P unless NL = NP. Hence, the class of functions logspace-reducible to #DNF is a strict subset of #P under plausible complexity-theoretic assumptions. By contrast, we show that two calls to a (restricted) #2DNF oracle suffice to capture gapP, namely, that the logspace many-one closure of the subtraction between the results of two #2DNF calls is gapP. Because #P $\not\subseteq$ gapP, #P is strictly contained between one and two #2DNF oracle calls.
  Surprisingly, the propositional formulas needed in both calls are linear-time computable, and the reduction preserves interesting structural as well as symmetry properties, leading to algorithmic applications. We show that a single subtraction suffices to compensate for the absence of negation while still capturing gapP, i.e., our results carry over to the monotone fragments of #2SAT and #2DNF. Since our reduction is linear-time, it preserves sparsity and, as a consequence we obtain a sparsification lemma for both #2SAT and #2DNF. This has only been known for kSAT with k $\geq$ 3 and respective counting versions. We further show that both #2DNF calls can be combined into a single call if we allow a little postprocessing (computable by AC0- or TC0-circuits). Consequently, we derive refined versions of Toda's Theorem: PH $\subseteq$ [#MON2SAT]$^{log}_{TC0}$ = [#MON2DNF]$^{log}_{TC0}$ and PH $\subseteq$ [#IMPL2SAT]$^{log}_{AC0}$. Our route to these results is via structure-aware reductions that preserve parameters like treewidth up to an additive overhead. The absence of multiplicative overhead indeed yields parameterized SETH-tight lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06716v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <category>math.CO</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Max Bannach, Erik D. Demaine, Timothy Gomez, Markus Hecher</dc:creator>
    </item>
    <item>
      <title>Quantum SAT Problems with Finite Sets of Projectors are Complete for a Plethora of Classes</title>
      <link>https://arxiv.org/abs/2506.07244</link>
      <description>arXiv:2506.07244v1 Announce Type: cross 
Abstract: Previously, all known variants of the Quantum Satisfiability (QSAT) problem, i.e. deciding whether a $k$-local ($k$-body) Hamiltonian is frustration-free, could be classified as being either in $\mathsf{P}$; or complete for $\mathsf{NP}$, $\mathsf{MA}$, or $\mathsf{QMA_1}$. Here, we demonstrate new qubit variants of this problem that are complete for $\mathsf{BQP_1}$, $\mathsf{coRP}$, $\mathsf{QCMA}$, $\mathsf{PI(coRP,NP)}$, $\mathsf{PI(BQP_1,NP)}$, $\mathsf{PI(BQP_1,MA)}$, $\mathsf{SoPU(coRP,NP)}$, $\mathsf{SoPU(BQP_1,NP)}$, and $\mathsf{SoPU(BQP_1,MA)}$. Our result implies that a complete classification of quantum constraint satisfaction problems (QCSPs), analogous to Schaefer's dichotomy theorem for classical CSPs, must either include these 13 classes, or otherwise show that some are equal. Additionally, our result showcases two new types of QSAT problems that can be decided efficiently, as well as the first nontrivial $\mathsf{BQP_1}$-complete problem. We first prove there are qudit QSAT problems that are complete for $\mathsf{BQP_1}$, $\mathsf{coRP}$, and $\mathsf{QCMA}$ by re-defining elements of the circuit-to-Hamiltonian transformation. We then show that any QCSP can be reduced to a problem in qubits while maintaining the same complexity - something believed not to be possible classically. The remaining six problems are obtained by considering "sums" and "products" of the first seven QSAT problems. Before this work, the QSAT problems generated in this way resulted in complete problems for $\mathsf{PI}$ and $\mathsf{SoPU}$ classes that were trivially equal to other known classes. We thus commence the study of these new and seemingly nontrivial classes. While [Meiburg, 2021] first sought to prove completeness for the first three classes, we note that his constructions are flawed. Here, we rework them and obtain improvements on the required qudit dimensionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07244v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ricardo Rivera Cardoso, Alex Meiburg, Daniel Nagaj</dc:creator>
    </item>
    <item>
      <title>New Limits on Distributed Quantum Advantage: Dequantizing Linear Programs</title>
      <link>https://arxiv.org/abs/2506.07574</link>
      <description>arXiv:2506.07574v1 Announce Type: cross 
Abstract: In this work, we give two results that put new limits on distributed quantum advantage in the context of the LOCAL model of distributed computing. First, we show that there is no distributed quantum advantage for any linear program. Put otherwise, if there is a quantum-LOCAL algorithm $\mathcal{A}$ that finds an $\alpha$-approximation of some linear optimization problem $\Pi$ in $T$ communication rounds, we can construct a classical, deterministic LOCAL algorithm $\mathcal{A}'$ that finds an $\alpha$-approximation of $\Pi$ in $T$ rounds. As a corollary, all classical lower bounds for linear programs, including the KMW bound, hold verbatim in quantum-LOCAL. Second, using the above result, we show that there exists a locally checkable labeling problem (LCL) for which quantum-LOCAL is strictly weaker than the classical deterministic SLOCAL model. Our results extend from quantum-LOCAL also to finitely dependent and non-signaling distributions, and one of the corollaries of our work is that the non-signaling model and the SLOCAL model are incomparable in the context of LCL problems: By prior work, there exists an LCL problem for which SLOCAL is strictly weaker than the non-signaling model, and our work provides a separation in the opposite direction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07574v1</guid>
      <category>cs.DC</category>
      <category>cs.CC</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alkida Balliu, Corinna Coupette, Antonio Cruciani, Francesco d'Amore, Massimo Equi, Henrik Lievonen, Augusto Modanese, Dennis Olivetti, Jukka Suomela</dc:creator>
    </item>
    <item>
      <title>Refuting Perfect Matchings in Spectral Expanders is Hard</title>
      <link>https://arxiv.org/abs/2506.07700</link>
      <description>arXiv:2506.07700v1 Announce Type: cross 
Abstract: This work studies the complexity of refuting the existence of a perfect matching in spectral expanders with an odd number of vertices, in the Polynomial Calculus (PC) and Sum of Squares (SoS) proof system. Austrin and Risse [SODA, 2021] showed that refuting perfect matchings in sparse $d$-regular \emph{random} graphs, in the above proof systems, with high probability requires proofs with degree $\Omega(n/\log n)$. We extend their result by showing the same lower bound holds for \emph{all} $d$-regular graphs with a mild spectral gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07700v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ari Biswas, Rajko Nenadov</dc:creator>
    </item>
    <item>
      <title>On Approximability of Satisfiable k-CSPs: V</title>
      <link>https://arxiv.org/abs/2408.15377</link>
      <description>arXiv:2408.15377v2 Announce Type: replace 
Abstract: We propose a framework of algorithm vs. hardness for all Max-CSPs and demonstrate it for a large class of predicates. This framework extends the work of Raghavendra [STOC, 2008], who showed a similar result for almost satisfiable Max-CSPs.
  Our framework is based on a new hybrid approximation algorithm, which uses a combination of the Gaussian elimination technique (i.e., solving a system of linear equations over an Abelian group) and the semidefinite programming relaxation. We complement our algorithm with a matching dictator vs. quasirandom test that has perfect completeness.
  The analysis of our dictator vs. quasirandom test is based on a novel invariance principle, which we call the mixed invariance principle. Our mixed invariance principle is an extension of the invariance principle of Mossel, O'Donnell and Oleszkiewicz [Annals of Mathematics, 2010] which plays a crucial role in Raghavendra's work. The mixed invariance principle allows one to relate 3-wise correlations over discrete probability spaces with expectations over spaces that are a mixture of Guassian spaces and Abelian groups, and may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15377v2</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amey Bhangale, Subhash Khot, Dor Minzer</dc:creator>
    </item>
    <item>
      <title>Parameterized Complexity of the Star Decomposition Problem</title>
      <link>https://arxiv.org/abs/2411.13348</link>
      <description>arXiv:2411.13348v2 Announce Type: replace 
Abstract: A star of length $ \ell $ is defined as the complete bipartite graph $ K_{1,\ell } $. In this paper we deal with the problem of edge decomposition of graphs into stars of varying lengths.
  Given a graph $ G $ and a list of integers $S=(s_1,\ldots, s_t) $, an $S$-star decomposition of $ G $ is an edge decomposition of $ G $ into graphs $G_1 ,G_2 ,\ldots,G_t $ such that $G_i$ is isomorphic to an star of length $s_i$, for each $i \in\{1,2,\ldots,t\}$. Given a graph $G$ and a list of integers $S$, the \sdp problem asks if $G$ admits an $ S $-star decomposition. The problem is known to be NP-complete even when all stars are of length three. In this paper, we investigate parametrized complexity of the problem with respect to the structural parameters of the input graph such as minimum vertex cover, treewidth, tree-depth and neighborhood diversity as well as some intrinsic parameters of the problem such as the number of distinct star lengths, the maximum size of stars and the maximum degree of the input graph, giving a roughly complete picture of the parameterized complexity landscape of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13348v2</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sahab Hajebi, Ramin Javadi</dc:creator>
    </item>
    <item>
      <title>Maximum Separation of Quantum Communication Complexity With and Without Shared Entanglement</title>
      <link>https://arxiv.org/abs/2505.16457</link>
      <description>arXiv:2505.16457v2 Announce Type: replace-cross 
Abstract: We present relation problems whose input size is $n$ such that they can be solved with no communication for entanglement-assisted quantum communication models, but require $\Omega(n)$ qubit communication for $2$-way quantum communication models without prior shared entanglement. This is the maximum separation of quantum communication complexity with and without shared entanglement. To our knowledge, our result even shows the first lower bound on quantum communication complexity without shared entanglement when the upper bound of entanglement-assisted quantum communication models is zero. The problem we consider is parallel repetition of any non-local game which has a perfect quantum strategy and no perfect classical strategy, and for which a parallel repetition theorem holds with exponential decay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16457v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atsuya Hasegawa, Fran\c{c}ois Le Gall, Augusto Modanese</dc:creator>
    </item>
  </channel>
</rss>
