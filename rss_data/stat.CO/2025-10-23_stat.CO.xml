<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Oct 2025 04:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Approximating evidence via bounded harmonic means</title>
      <link>https://arxiv.org/abs/2510.20617</link>
      <description>arXiv:2510.20617v1 Announce Type: new 
Abstract: Efficient Bayesian model selection relies on the model evidence or marginal likelihood, whose computation often requires evaluating an intractable integral. The harmonic mean estimator (HME) has long been a standard method of approximating the evidence. While computationally simple, the version introduced by Newton and Raftery (1994) potentially suffers from infinite variance. To overcome this issue, Gelfand and Dey (1994) defined a standardized representation of the estimator based on an instrumental function and Robert and Wraith (2009) later proposed to use higher posterior density (HPD) indicators as instrumental functions. Following this approach, a practical method is proposed, based on an elliptical covering of the HPD region with non-overlapping ellipsoids. The resulting estimator (ECMLE) not only eliminates the infinite-variance issue of the original HME and allows exact volume computations, but is also able to be used in multi-modal settings. Through several examples, we illustrate that ECMLE outperforms other recent methods such as THAMES and Mixture THAMES (Metodiev et al., 2025). Moreover, ECMLE demonstrates lower variance, a key challenge that subsequent HME variants have sought to address, and provides more stable evidence approximations, even in challenging settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20617v1</guid>
      <category>stat.CO</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dana Naderi, Christian P Robert, Kaniav Kamary, Darren Wraith{\S}</dc:creator>
    </item>
    <item>
      <title>Asynchronous Distributed ECME Algorithm for Matrix Variate Non-Gaussian Responses</title>
      <link>https://arxiv.org/abs/2510.20147</link>
      <description>arXiv:2510.20147v1 Announce Type: cross 
Abstract: We propose a regression model with matrix-variate skew-t response (REGMVST) for analyzing irregular longitudinal data with skewness, symmetry, or heavy tails. REGMVST models matrix-variate responses and predictors, with rows indexing longitudinal measurements per subject. It uses the matrix-variate skew-t (MVST) distribution to handle skewness and heavy tails, a damped exponential correlation (DEC) structure for row-wise dependencies across irregular time profiles, and leaves the column covariance unstructured. For estimation, we initially develop an ECME algorithm for parameter estimation and further mitigate its computational bottleneck via an asynchronous and distributed ECME (ADECME) extension. ADECME accelerates the E-step through parallelization, and retains the simplicity of the conditional M-step, enabling scalable inference. Simulations using synthetic data and a case study exploring matrix-variate periodontal disease endpoints derived from electronic health records demonstrate ADECME's superiority in efficiency and convergence, over the alternatives. We also provide theoretical support for our empirical observations and identify regularity assumptions for ADECME's optimal performance. An accompanying R package is available at https://github.com/rh8liuqy/STMATREG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20147v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qingyang Liu, Sanvesh Srivastava, Dipankar Bandyopadhyay</dc:creator>
    </item>
    <item>
      <title>Sampling from multi-modal distributions with polynomial query complexity in fixed dimension via reverse diffusion</title>
      <link>https://arxiv.org/abs/2501.00565</link>
      <description>arXiv:2501.00565v3 Announce Type: replace 
Abstract: Even in low dimensions, sampling from multi-modal distributions is challenging. We provide the first sampling algorithm for a broad class of distributions -- including all Gaussian mixtures -- with a query complexity that is polynomial in the parameters governing multi-modality, assuming fixed dimension. Our sampling algorithm simulates a time-reversed diffusion process, using a self-normalized Monte Carlo estimator of the intermediate score functions. Unlike previous works, it avoids metastability, requires no prior knowledge of the mode locations, and relaxes the well-known log-smoothness assumption which excluded general Gaussian mixtures so far.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00565v3</guid>
      <category>stat.CO</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Adrien Vacher, Omar Chehab, Anna Korba</dc:creator>
    </item>
    <item>
      <title>SMRS: advocating a unified reporting standard for surrogate models in the artificial intelligence era</title>
      <link>https://arxiv.org/abs/2502.06753</link>
      <description>arXiv:2502.06753v3 Announce Type: replace 
Abstract: Surrogate models are widely used to approximate complex systems across science and engineering to reduce computational costs. Despite their widespread adoption, the field lacks standardisation across key stages of the modelling pipeline, including data sampling, model selection, evaluation, and downstream analysis. This fragmentation limits reproducibility and cross-domain utility -- a challenge further exacerbated by the rapid proliferation of AI-driven surrogate models. We argue for the urgent need to establish a structured reporting standard, the Surrogate Model Reporting Standard (SMRS), that systematically captures essential design and evaluation choices while remaining agnostic to implementation specifics. By promoting a standardised yet flexible framework, we aim to improve the reliability of surrogate modelling, foster interdisciplinary knowledge transfer, and, as a result, accelerate scientific progress in the AI era.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06753v3</guid>
      <category>stat.CO</category>
      <category>cs.LG</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Elizaveta Semenova, Alisa Sheinkman, Timothy James Hitge, Siobhan Mackenzie Hall, Jon Cockayne</dc:creator>
    </item>
    <item>
      <title>Asymptotically exact variational flows via involutive MCMC kernels</title>
      <link>https://arxiv.org/abs/2506.02162</link>
      <description>arXiv:2506.02162v2 Announce Type: replace 
Abstract: Most expressive variational families -- such as normalizing flows -- lack practical convergence guarantees, as their theoretical assurances typically hold only at the intractable global optimum. In this work, we present a general recipe for constructing tuning-free, asymptotically exact variational flows on arbitrary state spaces from involutive MCMC kernels. The core methodological component is a novel representation of general involutive MCMC kernels as invertible, measurepreserving iterated random function systems, which act as the flow maps of our variational flows. This leads to three new variational families with provable total variation convergence. Our framework resolves key practical limitations of existing variational families with similar guarantees (e.g., MixFlows), while requiring substantially weaker theoretical assumptions. Finally, we demonstrate the competitive performance of our flows across tasks including posterior approximation, Monte Carlo estimates, and normalization constant estimation, outperforming or matching No-U-Turn sampler (NUTS) and black-box normalizing flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02162v2</guid>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zuheng Xu, Trevor Campbell</dc:creator>
    </item>
    <item>
      <title>Quantum speedup of non-linear Monte Carlo problems</title>
      <link>https://arxiv.org/abs/2502.05094</link>
      <description>arXiv:2502.05094v2 Announce Type: replace-cross 
Abstract: The mean of a random variable can be understood as a linear functional on the space of probability distributions. Quantum computing is known to provide a quadratic speedup over classical Monte Carlo methods for mean estimation. In this paper, we investigate whether a similar quadratic speedup is achievable for estimating non-linear functionals of probability distributions. We propose a quantum-inside-quantum Monte Carlo algorithm that achieves such a speedup for a broad class of non-linear estimation problems, including nested conditional expectations and stochastic optimization. Our algorithm improves upon the direct application of the quantum multilevel Monte Carlo algorithm introduced by An et al. (2021). The existing lower bound indicates that our algorithm is optimal up polylogarithmic factors. A key innovation of our approach is a new sequence of multilevel Monte Carlo approximations specifically designed for quantum computing, which is central to the algorithm's improved performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05094v2</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of the 39th Conference on Neural Information Processing Systems (NeurIPS), 2025</arxiv:journal_reference>
      <dc:creator>Jose Blanchet, Yassine Hamoudi, Mario Szegedy, Guanyang Wang</dc:creator>
    </item>
  </channel>
</rss>
