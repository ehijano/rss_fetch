<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.EC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.EC</link>
    <description>q-fin.EC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.EC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 Jan 2026 05:01:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Mobility-as-a-service (MaaS) system as a multi-leader-multi-follower game: A single-level variational inequality (VI) formulation</title>
      <link>https://arxiv.org/abs/2601.19880</link>
      <description>arXiv:2601.19880v1 Announce Type: new 
Abstract: This study models a Mobility-as-a-Service (MaaS) system as a multi-leader-multi-follower game that captures the complex interactions among the MaaS platform, service operators, and travelers. We consider a coopetitive setting where the MaaS platform purchases service capacity from service operators and sells multi-modal trips to travelers following an origin-destination-based pricing scheme; meanwhile, service operators use their remaining capacities to serve single-modal trips. As followers, travelers make both mode choices, including whether to use MaaS, and route choices in the multi-modal transportation network, subject to prices and congestion. Inspired by the dual formulation for traffic assignment problems, we propose a novel single-level variational inequality (VI) formulation by introducing a virtual traffic operator, along with the MaaS platform and multiple service operators. A key advantage of the proposed VI formulation is that it supports parallel solution procedures and thus enables large-scale applications. We prove that an equilibrium solution always exists given the negotiated wholesale price of service capacity. Numerical experiments on a small network further demonstrate that the wholesale price can be tailored to align with varying system-wide objectives. The proposed MaaS system demonstrates potential for creating a "win-win-win" outcome -- service operators and travelers are better off compared to the "without MaaS" scenario, meanwhile the MaaS platform remains profitable. Such a Pareto-improving regime can be explicitly specified with the wholesale capacity price. Similar conclusions are drawn from the experiment of an extended multi-modal Sioux Falls network, which also validates the scalability of the proposed model and solution algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19880v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Yao, Xinyu Ma, Kenan Zhang</dc:creator>
    </item>
    <item>
      <title>AI Cap-and-Trade: Efficiency Incentives for Accessibility and Sustainability</title>
      <link>https://arxiv.org/abs/2601.19886</link>
      <description>arXiv:2601.19886v1 Announce Type: new 
Abstract: The race for artificial intelligence (AI) dominance often prioritizes scale over efficiency. Hyper-scaling is the common industry approach: larger models, more data, and as many computational resources as possible. Using more resources is a simpler path to improved AI performance. Thus, efficiency has been de-emphasized. Consequently, the need for costly computational resources has marginalized academics and smaller companies. Simultaneously, increased energy expenditure, due to growing AI use, has led to mounting environmental costs. In response to accessibility and sustainability concerns, we argue for research into, and implementation of, market-based methods that incentivize AI efficiency. We believe that incentivizing efficient operations and approaches will reduce emissions while opening new opportunities for academics and smaller companies. As a call to action, we propose a cap-and-trade system for AI. Our system provably reduces computations for AI deployment, thereby lowering emissions and monetizing efficiency to the benefit of of academics and smaller companies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19886v1</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Bornstein, Amrit Singh Bedi</dc:creator>
    </item>
    <item>
      <title>Design-Robust Event-Study Estimation under Staggered Adoption Diagnostics, Sensitivity, and Orthogonalisation</title>
      <link>https://arxiv.org/abs/2601.18801</link>
      <description>arXiv:2601.18801v1 Announce Type: cross 
Abstract: This paper develops a design-first econometric framework for event-study and difference-in-differences estimands under staggered adoption with heterogeneous effects, emphasising (i) exact probability limits for conventional two-way fixed effects event-study regressions, (ii) computable design diagnostics that quantify contamination and negative-weight risk, and (iii) sensitivity-robust inference that remains uniformly valid under restricted violations of parallel trends. The approach is accompanied by orthogonal score constructions that reduce bias from high-dimensional nuisance estimation when conditioning on covariates. Theoretical results and Monte Carlo experiments jointly deliver a self-contained methodology paper suitable for finance and econometrics applications where timing variation is intrinsic to policy, regulation, and market-structure changes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18801v1</guid>
      <category>econ.EM</category>
      <category>econ.GN</category>
      <category>q-fin.CP</category>
      <category>q-fin.EC</category>
      <category>q-fin.GN</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Craig S Wright</dc:creator>
    </item>
    <item>
      <title>Who Restores the Peg? A Mean-Field Game Approach to Model Stablecoin Market Dynamics</title>
      <link>https://arxiv.org/abs/2601.18991</link>
      <description>arXiv:2601.18991v1 Announce Type: cross 
Abstract: USDC and USDT are the dominant stablecoins pegged to \$1 with a total market capitalization of over \$300B and rising. Stablecoins make dollar value globally accessible with secure transfer and settlement. Yet in practice, these stablecoins experience periods of stress and de-pegging from their \$1 target, posing significant systemic risks. The behavior of market participants during these stress events and the collective actions that either restore or break the peg are not well understood. This paper addresses the question: who restores the peg? We develop a dynamic, agent-based mean-field game framework for fiat-collateralized stablecoins, in which a large population of arbitrageurs and retail traders strategically interacts across explicit primary (mint/redeem) and secondary (exchange) markets during a de-peg episode. The key advantage of this equilibrium formulation is that it endogenously maps market frictions into a market-clearing price path and implied net order flows, allowing us to attribute peg-reverting pressure by channel and to stress-test when a given mechanism becomes insufficient for recovery. Using three historical de-peg events, we show that the calibrated equilibrium reproduces observed recovery half-lives and yields an order flow decomposition in which system-wide stress is predominantly stabilized by primary-market arbitrage, whereas episodes with impaired primary redemption require a joint recovery via both primary and secondary markets. Finally, a quantitative sensitivity analysis of primary-rail frictions identifies a non-linear breakdown threshold. Beyond this point, secondary-market liquidity acts mainly as a second-order amplifier around this primary-market bottleneck.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18991v1</guid>
      <category>q-fin.TR</category>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hardhik Mohanty, Bhaskar Krishnamachari</dc:creator>
    </item>
    <item>
      <title>Hedonic Prices and Quality Adjusted Price Indices Powered by AI</title>
      <link>https://arxiv.org/abs/2305.00044</link>
      <description>arXiv:2305.00044v4 Announce Type: replace 
Abstract: We develop empirical models that efficiently process large amounts of unstructured product data (text, images, prices, quantities) to produce accurate hedonic price estimates and derived indices. To achieve this, we generate abstract product attributes (or ``features'') from descriptions and images using deep neural networks. These attributes are then used to estimate the hedonic price function. To demonstrate the effectiveness of this approach, we apply the models to Amazon's data for first-party apparel sales, and estimate hedonic prices. The resulting models have a very high out-of-sample predictive accuracy, with $R^2$ ranging from $80\%$ to $90\%$. Finally, we construct the AI-based hedonic Fisher price index, chained at the year-over-year frequency, and contrast it with the CPI and other electronic indices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00044v4</guid>
      <category>econ.GN</category>
      <category>cs.LG</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jeconom.2025.106052</arxiv:DOI>
      <arxiv:journal_reference>Journal of Econometrics, Volume 251, 2025</arxiv:journal_reference>
      <dc:creator>Patrick Bajari, Zhihao Cen, Victor Chernozhukov, Manoj Manukonda, Suhas Vijaykumar, Jin Wang, Ramon Huerta, Junbo Li, Ling Leng, George Monokroussos, Shan Wang</dc:creator>
    </item>
    <item>
      <title>Consumption and capital growth</title>
      <link>https://arxiv.org/abs/2505.01527</link>
      <description>arXiv:2505.01527v2 Announce Type: replace 
Abstract: Capital growth, at large scales only, arrives with no help from net saving, and consequently with no help from consumption constraint. Net saving, at large scales, is sacrifice of consumption with nothing in return.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01527v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gordon Getty, Nikita Tkachenko</dc:creator>
    </item>
    <item>
      <title>Navigating the Lobbying Landscape: Insights from Opinion Dynamics Models</title>
      <link>https://arxiv.org/abs/2507.13767</link>
      <description>arXiv:2507.13767v3 Announce Type: replace 
Abstract: While lobbying has been demonstrated to have an important effect on public opinion and policy making, existing models of opinion formation do not specifically include its effect. In this work we introduce a new model of lobbying-driven opinion influence within opinion dynamics, where lobbyists can implement complex strategies and are characterised by a finite budget. Individuals update their opinions through a learning process resembling Bayes-rule updating but using signals generated by the other agents (a form of social learning), modulated by under-reaction and confirmation bias. We study the model numerically and demonstrate rich dynamics both with and without lobbyists. In the presence of lobbying, we observe two regimes: one in which lobbyists can have full influence on the agent network, and another where the peer-effect generates polarisation. When lobbyists are symmetric, the lobbyist-influence regime is characterised by prolonged opinion oscillations. If lobbyists temporally differentiate their strategies, frontloading is advantageous in the peer-effect regime, whereas backloading is advantageous in the lobbyist-influence regime. These rich dynamics pave the way for studying real lobbying strategies to validate the model in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13767v3</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniele Giachini, Leonardo Ciambezi, Verdiana Del Rosso, Fabrizio Fornari, Valentina Pansanella, Lilit Popoyan, Alina S\^irbu</dc:creator>
    </item>
    <item>
      <title>Specialization, Complexity &amp; Resilience in Supply Chains</title>
      <link>https://arxiv.org/abs/2509.08981</link>
      <description>arXiv:2509.08981v2 Announce Type: replace 
Abstract: We study how product specialization choices affect supply chain resilience. We propose a theory of supply chain formation in which only compatible inputs can be used in final production. Intermediate producers choose how much to specialize their goods, trading off higher value added against a smaller pool of compatible final producers. Final producers operate complex supply chains, requiring multiple complementary inputs. Specialization choices determine how quickly final producers can replace suppliers after disruptions, and thus supply chain resilience. In equilibrium, production inputs are over-specialized due to a novel network externality. Intermediate producers fail to internalize how their specialization choices affect the likelihood that final producers source all required inputs, and therefore the lost value added from complementary inputs if production halts. As a result, supply chains are more productive in normal times but less resilient than socially desirable. We characterize the optimal transfer that restores the efficient allocation and show that non-fiscal interventions, such as compatibility standards, are generally welfare-enhancing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08981v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Ferrari, Lorenzo Pesaresi</dc:creator>
    </item>
    <item>
      <title>Cloud and AI Infrastructure Cost Optimization: A Comprehensive Review of Strategies and Case Studies</title>
      <link>https://arxiv.org/abs/2307.12479</link>
      <description>arXiv:2307.12479v2 Announce Type: replace-cross 
Abstract: Cloud computing has revolutionized the way organizations manage their IT infrastructure, but it has also introduced new challenges, such as managing cloud costs. The rapid adoption of artificial intelligence (AI) and machine learning (ML) workloads has further amplified these challenges, with GPU compute now representing 40-60\% of technical budgets for AI-focused organizations. This paper provides a comprehensive review of cloud and AI infrastructure cost optimization techniques, covering traditional cloud pricing models, resource allocation strategies, and emerging approaches for managing AI/ML workloads. We examine the dramatic cost reductions in large language model (LLM) inference which has decreased by approximately 10x annually since 2021 and explore techniques such as model quantization, GPU instance selection, and inference optimization. Real-world case studies from Amazon Prime Video, Pinterest, Cloudflare, and Netflix showcase practical application of these techniques. Our analysis reveals that organizations can achieve 50-90% cost savings through strategic optimization approaches. Future research directions in automated optimization, sustainability, and AI-specific cost management are proposed to advance the state of the art in this rapidly evolving field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.12479v2</guid>
      <category>cs.DC</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>econ.GN</category>
      <category>eess.SY</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Saurabh Deochake</dc:creator>
    </item>
    <item>
      <title>Conservation priority mapping to prevent zoonotic spillovers</title>
      <link>https://arxiv.org/abs/2601.13349</link>
      <description>arXiv:2601.13349v2 Announce Type: replace-cross 
Abstract: Diseases originating from wildlife pose a significant threat to global health, causing human and economic losses each year. The transmission of disease from animals to humans occurs at the interface between humans, livestock, and wildlife reservoirs, influenced by abiotic factors and ecological mechanisms. Although evidence suggests that intact ecosystems can reduce transmission, disease prevention has largely been neglected in conservation efforts and remains underfunded compared to mitigation. A major constraint is the lack of reliable, spatially explicit information to guide efforts effectively. Given the increasing rate of new disease emergence, accelerated by climate change and biodiversity loss, identifying priority areas for mitigating the risk of disease transmission is more crucial than ever. We present new high-resolution (1 km) maps of priority areas for targeted ecological countermeasures aimed at reducing the likelihood of zoonotic spillover, along with a methodology adaptable to local contexts. Our study compiles data on well-documented risk factors, protection status, forest restoration potential, and opportunity cost of the land to map areas with high potential for cost-effective interventions. We identify low-cost priority areas across 50 countries, including 277,000 km2 where environmental restoration could mitigate the risk of zoonotic spillover and 198,000 km2 where preventing deforestation could do the same, 95% of which are not currently under protection. The resulting layers, covering tropical regions globally, are freely available alongside an interactive no-code platform that allows users to adjust parameters and identify priority areas at multiple scales. Ecological countermeasures can be a cost-effective strategy for reducing the emergence of new pathogens; however, our study highlights the extent to which current conservation efforts fall short of this goal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.13349v2</guid>
      <category>q-bio.PE</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 28 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Leonardo Viotti, Luis Diego Herrera, Garo Batmanian, Franck Berthe, Rachael Kramp</dc:creator>
    </item>
  </channel>
</rss>
