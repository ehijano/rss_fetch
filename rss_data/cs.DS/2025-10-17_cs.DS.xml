<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Oct 2025 04:01:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Levelset Algorithm for 3D-Tarksi</title>
      <link>https://arxiv.org/abs/2510.14777</link>
      <description>arXiv:2510.14777v1 Announce Type: new 
Abstract: We present a simple new algorithm for finding a Tarski fixed point of a monotone function $F : [N]^3 \rightarrow [N]^3$. Our algorithm runs in $O(\log^2 N)$ time and makes $O(\log^2 N)$ queries to $F$, matching the $\Omega(\log^2 N)$ query lower bound due to Etessami et al.\ as well as the existing state-of-the-art algorithm due to Fearnley et al.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14777v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Haslebacher, Jonas Lill</dc:creator>
    </item>
    <item>
      <title>Prediction-Specific Design of Learning-Augmented Algorithms</title>
      <link>https://arxiv.org/abs/2510.14887</link>
      <description>arXiv:2510.14887v1 Announce Type: new 
Abstract: Algorithms with predictions} has emerged as a powerful framework to combine the robustness of traditional online algorithms with the data-driven performance benefits of machine-learned (ML) predictions. However, most existing approaches in this paradigm are overly conservative, {as they do not leverage problem structure to optimize performance in a prediction-specific manner}. In this paper, we show that such prediction-specific performance criteria can enable significant performance improvements over the coarser notions of consistency and robustness considered in prior work. Specifically, we propose a notion of \emph{strongly-optimal} algorithms with predictions, which obtain Pareto optimality not just in the worst-case tradeoff between robustness and consistency, but also in the prediction-specific tradeoff between these metrics. We develop a general bi-level optimization framework that enables systematically designing strongly-optimal algorithms in a wide variety of problem settings, and we propose explicit strongly-optimal algorithms for several classic online problems: deterministic and randomized ski rental, and one-max search. Our analysis reveals new structural insights into how predictions can be optimally integrated into online algorithms by leveraging a prediction-specific design. To validate the benefits of our proposed framework, we empirically evaluate our algorithms in case studies on problems including dynamic power management and volatility-based index trading. Our results demonstrate that prediction-specific, strongly-optimal algorithms can significantly improve performance across a variety of online decision-making settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14887v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sizhe Li, Nicolas Christianson, Tongxin Li</dc:creator>
    </item>
    <item>
      <title>Tree-Like Shortcuttings of Trees</title>
      <link>https://arxiv.org/abs/2510.14918</link>
      <description>arXiv:2510.14918v1 Announce Type: new 
Abstract: Sparse shortcuttings of trees -- equivalently, sparse 1-spanners for tree metrics with bounded hop-diameter -- have been studied extensively (under different names and settings), since the pioneering works of [Yao82, Cha87, AS87, BTS94], initially motivated by applications to range queries, online tree product, and MST verification, to name a few. These constructions were also lifted from trees to other graph families using known low-distortion embedding results. The works of [Yao82, Cha87, AS87, BTS94] establish a tight tradeoff between hop-diameter and sparsity (or average degree) for tree shortcuttings and imply constant-hop shortcuttings for $n$-node trees with sparsity $O(\log^* n)$. Despite their small sparsity, all known constant-hop shortcuttings contain dense subgraphs (of sparsity $\Omega(\log n)$), which is a significant drawback for many applications.
  We initiate a systematic study of constant-hop tree shortcuttings that are ``tree-like''. We focus on two well-studied graph parameters that measure how far a graph is from a tree: arboricity and treewidth. Our contribution is twofold.
  * New upper and lower bounds for tree-like shortcuttings of trees, including an optimal tradeoff between hop-diameter and treewidth for all hop-diameter up to $O(\log\log n)$. We also provide a lower bound for larger values of $k$, which together yield $\text{hop-diameter}\times \text{treewidth} = \Omega((\log\log n)^2)$ for all values of hop-diameter, resolving an open question of [FL22, Le23]. [...]</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14918v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hung Le, Lazar Milenkovi\'c, Shay Solomon, Cuong Than</dc:creator>
    </item>
    <item>
      <title>Distributed-Memory Parallel Algorithms for Fixed-Radius Near Neighbor Graph Construction</title>
      <link>https://arxiv.org/abs/2510.14147</link>
      <description>arXiv:2510.14147v1 Announce Type: cross 
Abstract: Computing fixed-radius near-neighbor graphs is an important first step for many data analysis algorithms. Near-neighbor graphs connect points that are close under some metric, endowing point clouds with a combinatorial structure. As computing power and data acquisition methods advance, diverse sources of large scientific datasets would greatly benefit from scalable solutions to this common subroutine for downstream analysis. Prior work on parallel nearest neighbors has made great progress in problems like k-nearest and approximate nearest neighbor search problems, with particular attention on Euclidean spaces. Yet many applications need exact solutions and non-Euclidean metrics. This paper presents a scalable sparsity-aware distributed memory algorithm using cover trees to compute near-neighbor graphs in general metric spaces. We provide a shared-memory algorithm for cover tree construction and demonstrate its competitiveness with state-of-the-art fixed-radius search data structures. We then introduce two distributed-memory algorithms for the near-neighbor graph problem, a simple point-partitioning strategy and a spatial-partitioning strategy, which leverage the cover tree algorithm on each node. Our algorithms exhibit parallel scaling across a variety of real and synthetic datasets for both traditional and non-traditional metrics. On real world high dimensional datasets with one million points, we achieve speedups up to 678.34x over the state-of-the-art using 1024 cores for graphs with 70 neighbors per vertex (on average), and up to 1590.99x using 4096 cores for graphs with 500 neighbors per vertex (on average).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14147v1</guid>
      <category>cs.DC</category>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Raulet, Dmitriy Morozov, Aydin Buluc, Katherine Yelick</dc:creator>
    </item>
    <item>
      <title>An efficient algorithm for \textsc{$\mathcal{F}$-subgraph-free Edge Deletion} on graphs having a product structure</title>
      <link>https://arxiv.org/abs/2510.14674</link>
      <description>arXiv:2510.14674v1 Announce Type: cross 
Abstract: Given a family $\mathcal{F}$ of graphs, a graph is \emph{$\mathcal{F}$-subgraph-free} if it has no subgraph isomorphic to a member of $\mathcal{F}$. We present a fixed-parameter linear-time algorithm that decides whether a planar graph can be made $\mathcal{F}$-subgraph-free by deleting at most $k$ vertices or $k$ edges, where the parameters are $k$, $\lvert \mathcal{F} \rvert$, and the maximum number of vertices in a member of $\mathcal{F}$. The running time of our algorithm is double-exponential in the parameters, which is faster than the algorithm obtained by applying the first-order model checking result for graphs of bounded twin-width.
  To obtain this result, we develop a unified framework for designing algorithms for this problem on graphs with a ``product structure.'' Using this framework, we also design algorithms for other graph classes that generalize planar graphs. Specifically, the problem admits a fixed-parameter linear time algorithm on disk graphs of bounded local radius, and a fixed-parameter almost-linear time algorithm on graphs of bounded genus.
  Finally, we show that our result gives a tight fixed-parameter algorithm in the following sense: Even when $\mathcal{F}$ consists of a single graph $F$ and the input is restricted to planar graphs, it is unlikely to drop any parameters $k$ and $\lvert V(F) \rvert$ while preserving fixed-parameter tractability, unless the Exponential-Time Hypothesis fails.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14674v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shinwoo An, Seonghyuk Im, Seokbeom Kim, Myounghwan Lee</dc:creator>
    </item>
    <item>
      <title>Online Proportional Apportionment</title>
      <link>https://arxiv.org/abs/2510.14752</link>
      <description>arXiv:2510.14752v1 Announce Type: cross 
Abstract: Traditionally, the problem of apportioning the seats of a legislative body has been viewed as a one-shot process with no dynamic considerations. While this approach is reasonable for some settings, dynamic aspects play an important role in many others. We initiate the study of apportionment problems in an online setting. Specifically, we introduce a framework for proportional apportionment with no information about the future. In this model, time is discrete and there are $n$ parties that receive a certain share of the votes at each time step. An online algorithm needs to irrevocably assign a prescribed number of seats at each time, ensuring that each party receives its fractional share rounded up or down, and that the cumulative number of seats allocated to each party remains close to its cumulative share up to that time.
  We study deterministic and randomized online apportionment methods. For deterministic methods, we construct a family of adversarial instances that yield a lower bound, linear in $n$, on the worst-case deviation between the seats allocated to a party and its cumulative share. We show that this bound is best possible and is matched by a natural greedy method. As a consequence, a method guaranteeing that the cumulative number of seats assigned to each party up to any step equals its cumulative share rounded up or down (global quota) exists if and only if $n\leq 3$. Then, we turn to randomized allocations and show that, for $n\leq 3$, we can randomize over methods satisfying global quota with the additional guarantee that each party receives, in expectation, its proportional share in every step. Our proof is constructive: Any method satisfying these properties can be obtained from a flow on a recursively constructed network. We showcase the applicability of our results to obtain approximate solutions in the context of online dependent rounding procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14752v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javier Cembrano, Jose Correa, Svenja M. Griesbach, Victor Verdugo</dc:creator>
    </item>
    <item>
      <title>Balls and Bins and the Infinite Process with Random Deletions</title>
      <link>https://arxiv.org/abs/2510.14798</link>
      <description>arXiv:2510.14798v1 Announce Type: cross 
Abstract: We consider an infinite balls-into-bins process with deletions where in each discrete step $t$ a coin is tossed as to whether, with probability $\beta(t) \in (0,1)$, a new ball is allocated using the Greedy[2] strategy (which places the ball in the lower loaded of two bins sampled uniformly at random) or, with remaining probability $1-\beta(t)$, a ball is deleted from a non-empty bin chosen uniformly at random. Let $n$ be the number of bins and $m(t)$ the total load at time $t$. We are interested in bounding the discrepancy $x_{\max}(t) - m(t)/n$ (current maximum load relative to current average) and the overload $x_{\max}(t) - m_{\max}(t)/n$ (current maximum load relative to highest average observed so far).
  We prove that at an arbitrarily chosen time $t$ the total number of balls above the average is $O(n)$ and that the discrepancy is $ O(\log(n))$. For the discrepancy, we provide a matching lower bound. Furthermore we prove that at an arbitrarily chosen time $t$ the overload is $\log\log(n)+O(1)$. For "good" insertion probability sequences (in which the average load of time intervals with polynomial length increases in expectation) we show that even the discrepancy is bounded by $\log\log(n)+O(1)$.
  One of our main analytical tools is a layered induction, as per [ABKU99]. Since our model allows for rather more general scenarios than what was previously considered, the formal analysis requires some extra ingredients as well, in particular a detailed potential analysis. Furthermore, we simplify the setup by applying probabilistic couplings to obtain certain "recovery" properties, which eliminate much of the need for intricate and careful conditioning elsewhere in the analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14798v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Petra Berenbrink, Tom Friedetzky, Peter Kling, Lars Nagel</dc:creator>
    </item>
    <item>
      <title>Sensitivity Lower Bounds for Approximaiton Algorithms</title>
      <link>https://arxiv.org/abs/2411.02744</link>
      <description>arXiv:2411.02744v3 Announce Type: replace 
Abstract: Sensitivity measures how much the output of an algorithm changes, in terms of Hamming distance, when part of the input is modified. While approximation algorithms with low sensitivity have been developed for many problems, no sensitivity lower bounds were previously known for approximation algorithms. In this work, we establish the first polynomial lower bound on the sensitivity of (randomized) approximation algorithms for constraint satisfaction problems (CSPs) by adapting the probabilistically checkable proof (PCP) framework to preserve sensitivity lower bounds. From this, we derive polynomial sensitivity lower bounds for approximation algorithms for a variety of problems, including maximum clique, minimum vertex cover, and maximum cut.
  Leveraging the connection between sensitivity and locality in the non-signaling model, which subsumes the LOCAL, quantum-LOCAL, and bounded dependence models, we establish locality lower bounds for several graph problems in the non-signaling model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02744v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noah Fleming, Yuichi Yoshida</dc:creator>
    </item>
    <item>
      <title>Adaptivity Gaps for Stochastic Probing with Subadditive Functions</title>
      <link>https://arxiv.org/abs/2504.15547</link>
      <description>arXiv:2504.15547v2 Announce Type: replace 
Abstract: In this paper, we study the stochastic probing problem under a general monotone norm objective. Given a ground set $U = [n]$, each element $i \in U$ has an independent nonnegative random variable $X_i$ with known distribution. Probing an element reveals its value, and the sequence of probed elements must satisfy a prefix-closed feasibility constraint $\mathcal{F}$. A monotone norm $f: \mathbb{R}_{\geq 0}^n \to \mathbb{R}_{\geq 0}$ determines the reward $f(X_P)$, where $P$ is the set of probed elements and $X_P$ is the vector with $X_i$ for $i \in P$ and 0 otherwise. The goal is to design a probing strategy maximizing the expected reward $\mathbb{E}[f(X_P)]$. We focus on the adaptivity gap: the ratio between the expected rewards of optimal adaptive and optimal non-adaptive strategies. We resolve an open question posed in [GNS17, KMS24], showing that for general monotone norms, the adaptivity gap is $O(\log^2 n)$. A refined analysis yields an improved bound of $O(\log r \log n / \log\log n)$, where $r$ is the maximum size of a feasible probing sequence. As a by-product, we derive an asymptotically tight adaptivity gap $\Theta( \log n/\log\log n)$ for Bernoulli probing with binary-XOS objectives, matching the known lower bound. Additionally, we show an $O(\log^3 n)$ upper bound for Bernoulli probing with general subadditive objectives. For monotone symmetric norms, we prove the adaptivity gap is $O(1)$, improving the previous $O(\log n)$ bound from [PRS23].</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15547v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jian Li, Yinchen Liu, Yiran Zhang</dc:creator>
    </item>
    <item>
      <title>H-Planarity and Parametric Extensions: when Modulators Act Globally</title>
      <link>https://arxiv.org/abs/2507.08541</link>
      <description>arXiv:2507.08541v2 Announce Type: replace 
Abstract: We introduce a series of graph decompositions based on the modulator/target scheme of modification problems that enable several algorithmic applications that parametrically extend the algorithmic potential of planarity. In the core of our approach is a polynomial time algorithm for computing planar H-modulators. Given a graph class H, a planar H-modulator of a graph G is a set X \subseteq V(G) such that the ``torso'' of X is planar and all connected components of G - X belong to H. Here, the torso of X is obtained from G[X] if, for every connected component of G-X, we form a clique out of its neighborhood on G[X]. We introduce H-Planarity as the problem of deciding whether a graph G has a planar H-modulator. We prove that, if H is hereditary, CMSO-definable, and decidable in polynomial time, then H-Planarity is solvable in polynomial time. Further, we introduce two parametric extensions of H-Planarity by defining the notions of H-planar treedepth and H-planar treewidth, which generalize the concepts of elimination distance and tree decompositions to the class H. Combining this result with existing FPT algorithms for various H-modulator problems, we thereby obtain FPT algorithms parameterized by H-planar treedepth and H-planar treewidth for numerous graph classes H. By combining the well-known algorithmic properties of planar graphs and graphs of bounded treewidth, our methods for computing H-planar treedepth and H-planar treewidth lead to a variety of algorithmic applications. For instance, once we know that a given graph has bounded H-planar treedepth or bounded H-planar treewidth, we can derive additive approximation algorithms for graph coloring and polynomial-time algorithms for counting (weighted) perfect matchings. Furthermore, we design Efficient Polynomial-Time Approximation Schemes (EPTAS-es) for several problems, including Maximum Independent Set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08541v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fedor V. Fomin, Petr A. Golovach, Laure Morelle, Dimitrios M. Thilikos</dc:creator>
    </item>
    <item>
      <title>BlockFIFO &amp; MultiFIFO: Scalable Relaxed Queues</title>
      <link>https://arxiv.org/abs/2507.22764</link>
      <description>arXiv:2507.22764v2 Announce Type: replace 
Abstract: FIFO queues are a fundamental data structure used in a wide range of applications. Concurrent FIFO queues allow multiple execution threads to access the queue simultaneously. Maintaining strict FIFO semantics in concurrent queues leads to low throughput due to high contention at the head and tail of the queue. By relaxing the FIFO semantics to allow some reordering of elements, it becomes possible to achieve much higher scalability. This work presents two orthogonal designs for relaxed concurrent FIFO queues, one derived from the MultiQueue and the other based on ring buffers. We evaluate both designs extensively on various micro-benchmarks and a breadth-first search application on large graphs. Both designs outperform state-of-the-art relaxed and strict FIFO queues, achieving higher throughput and better scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22764v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan Koch, Peter Sanders, Marvin Williams</dc:creator>
    </item>
    <item>
      <title>Smoothed analysis for graph isomorphism</title>
      <link>https://arxiv.org/abs/2410.06095</link>
      <description>arXiv:2410.06095v3 Announce Type: replace-cross 
Abstract: There is no known polynomial-time algorithm for graph isomorphism testing, but elementary combinatorial "refinement" algorithms seem to be very efficient in practice. Some philosophical justification is provided by a classical theorem of Babai, Erd\H{o}s and Selkow: an extremely simple polynomial-time combinatorial algorithm (variously known as "na\"ive refinement", "na\"ive vertex classification", "colour refinement" or the "1-dimensional Weisfeiler-Leman algorithm") yields a so-called canonical labelling scheme for "almost all graphs". More precisely, for a typical outcome of a random graph $G(n,1/2)$, this simple combinatorial algorithm assigns labels to vertices in a way that easily permits isomorphism-testing against any other graph.
  We improve the Babai-Erd\H{o}s-Selkow theorem in two directions. First, we consider randomly perturbed graphs, in accordance with the smoothed analysis philosophy of Spielman and Teng: for any graph $G$, na\"ive refinement becomes effective after a tiny random perturbation to $G$ (specifically, the addition and removal of $O(n\log n)$ random edges). Actually, with a twist on na\"ive refinement, we show that $O(n)$ random additions and removals suffice. These results significantly improve on previous work of Gaudio-R\'acz-Sridhar, and are in certain senses best-possible.
  Second, we complete a long line of research on canonical labelling of random graphs: for any $p$ (possibly depending on $n$), we prove that a random graph $G(n,p)$ can typically be canonically labelled in polynomial time. This is most interesting in the extremely sparse regime where $p$ has order of magnitude $c/n$; denser regimes were previously handled by Bollob\'as, Czajka-Pandurangan, and Linial-Mosheiff. Our proof also provides a description of the automorphism group of a typical outcome of $G(n,p_n)$ (slightly correcting a prediction of Linial-Mosheiff).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06095v3</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Anastos, Matthew Kwan, Benjamin Moore</dc:creator>
    </item>
    <item>
      <title>Stochastic and incremental subgradient methods for convex optimization on Hadamard spaces</title>
      <link>https://arxiv.org/abs/2412.06730</link>
      <description>arXiv:2412.06730v3 Announce Type: replace-cross 
Abstract: As a foundation for optimization, convexity is useful beyond the classical settings of Euclidean and Hilbert space. The broader arena of nonpositively curved metric spaces, which includes manifolds like hyperbolic space, as well as metric trees and more general CAT(0) cubical complexes, supports primal tools like proximal operations for geodesically convex functions. However, the lack of linear structure in such spaces complicates dual constructions like subgradients. To address this hurdle, we introduce a new type of subgradient for functions on Hadamard spaces, based on Busemann functions. Our notion supports generalizations of classical stochastic and incremental subgradient methods, with guaranteed complexity bounds. We illustrate with subgradient algorithms for $p$-mean problems in general Hadamard spaces, in particular computing medians in BHV tree space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06730v3</guid>
      <category>math.OC</category>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Goodwin, Adrian S. Lewis, Genaro L\'opez-Acedo, Adriana Nicolae</dc:creator>
    </item>
  </channel>
</rss>
