<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.FL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.FL</link>
    <description>cs.FL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.FL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Aug 2025 04:03:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Active Automata Learning with Advice</title>
      <link>https://arxiv.org/abs/2508.10535</link>
      <description>arXiv:2508.10535v1 Announce Type: new 
Abstract: We present an extended automata learning framework that combines active automata learning with deductive inference. The learning algorithm asks membership and equivalence queries as in the original framework, but it is also given advice, which is used to infer answers to queries when possible and reduce the burden on the teacher. We consider advice given via string rewriting systems, which specify equivalence of words w.r.t. the target languages. The main motivation for the proposed framework is to reduce the number of queries. We show how to adapt Angluin-style learning algorithms to this framework with low overhead. Finally, we present empirical evaluation of our approach and observe substantial improvement in query complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10535v1</guid>
      <category>cs.FL</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micha{\l} Fica, Jan Otop</dc:creator>
    </item>
    <item>
      <title>Constrained Decoding of Diffusion LLMs with Context-Free Grammars</title>
      <link>https://arxiv.org/abs/2508.10111</link>
      <description>arXiv:2508.10111v1 Announce Type: cross 
Abstract: Large language models (LLMs) have shown promising performance across diverse domains. Many practical applications of LLMs, such as code completion and structured data extraction, require adherence to syntactic constraints specified by a formal language. Yet, due to their probabilistic nature, LLM output is not guaranteed to adhere to such formal languages. Prior work has proposed constrained decoding as a means to restrict LLM generation to particular formal languages. However, existing works are not applicable to the emerging paradigm of diffusion LLMs, when used in practical scenarios such as the generation of formally correct C++ or JSON output. In this paper we address this challenge and present the first constrained decoding method for diffusion models, one that can handle formal languages captured by context-free grammars. We begin by reducing constrained decoding to the more general additive infilling problem, which asks whether a partial output can be completed to a valid word in the target language. This problem also naturally subsumes the previously unaddressed multi-region infilling constrained decoding. We then reduce this problem to the task of deciding whether the intersection of the target language and a regular language is empty and present an efficient algorithm to solve it for context-free languages. Empirical results on various applications, such as C++ code infilling and structured data extraction in JSON, demonstrate that our method achieves near-perfect syntactic correctness while consistently preserving or improving functional correctness. Importantly, our efficiency optimizations ensure that the computational overhead remains practical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10111v1</guid>
      <category>cs.LG</category>
      <category>cs.FL</category>
      <category>cs.SE</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niels M\"undler, Jasper Dekoninck, Martin Vechev</dc:creator>
    </item>
    <item>
      <title>Rule-based Generation of de Bruijn Sequences: Memory and Learning</title>
      <link>https://arxiv.org/abs/2507.09764</link>
      <description>arXiv:2507.09764v2 Announce Type: replace 
Abstract: We investigate binary sequences generated by non-Markovian rules with memory length $\mu$, similar to those adopted in Elementary Cellular Automata. This generation procedure is equivalente to a shift register and certain rules produce sequences with maximal periods, known as de Bruijn sequences. We introduce a novel methodology for generating de Bruijn sequences that combines: (i) a set of derived properties that significantly reduce the space of feasible generating rules, and (ii) a neural network-based classifier that identifies which rules produce de Bruijn sequences. Experiments for large values of $\mu$ demonstrate the approach's effectiveness and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09764v2</guid>
      <category>cs.FL</category>
      <category>math.DS</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francisco J. Mu\~noz, Juan Carlos Nu\~no</dc:creator>
    </item>
  </channel>
</rss>
