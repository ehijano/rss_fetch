<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 27 Sep 2024 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>MODEL&amp;CO: Exoplanet detection in angular differential imaging by learning across multiple observations</title>
      <link>https://arxiv.org/abs/2409.17178</link>
      <description>arXiv:2409.17178v1 Announce Type: cross 
Abstract: Direct imaging of exoplanets is particularly challenging due to the high contrast between the planet and the star luminosities, and their small angular separation. In addition to tailored instrumental facilities implementing adaptive optics and coronagraphy, post-processing methods combining several images recorded in pupil tracking mode are needed to attenuate the nuisances corrupting the signals of interest. Most of these post-processing methods build a model of the nuisances from the target observations themselves, resulting in strongly limited detection sensitivity at short angular separations due to the lack of angular diversity. To address this issue, we propose to build the nuisance model from an archive of multiple observations by leveraging supervised deep learning techniques. The proposed approach casts the detection problem as a reconstruction task and captures the structure of the nuisance from two complementary representations of the data. Unlike methods inspired by reference differential imaging, the proposed model is highly non-linear and does not resort to explicit image-to-image similarity measurements and subtractions. The proposed approach also encompasses statistical modeling of learnable spatial features. The latter is beneficial to improve both the detection sensitivity and the robustness against heterogeneous data. We apply the proposed algorithm to several datasets from the VLT/SPHERE instrument, and demonstrate a superior precision-recall trade-off compared to the PACO algorithm. Interestingly, the gain is especially important when the diversity induced by ADI is the most limited, thus supporting the ability of the proposed approach to learn information across multiple observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17178v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.EP</category>
      <category>cs.CV</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Th\'eo Bodrito, Olivier Flasseur, Julien Mairal, Jean Ponce, Maud Langlois, Anne-Marie Lagrange</dc:creator>
    </item>
    <item>
      <title>N-dimensional maximum-entropy tomography via particle sampling</title>
      <link>https://arxiv.org/abs/2409.17915</link>
      <description>arXiv:2409.17915v1 Announce Type: cross 
Abstract: This paper proposes an alternative implementation of the MENT algorithm, an exact maximum-entropy algorithm used to infer a phase space distribution from its projections. A key step in the MENT algorithm is to compute the distribution's projections via numerical integration. In this approach, the run time scales quickly with the phase space dimension and measurement resolution. The proposed MENT implementation computes the projections via particle sampling, rather than numerical integration, eliminating the dependence on the measurement resolution. Furthermore, with the appropriate sampling algorithm, the particle-based approach scales to $N$-dimensions without computer memory limitations. Using synthetic data, we demonstrate MENT convergence in four dimensions using a grid-based sampling method and in six dimensions using Markov Chain Monte Carlo (MCMC) sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.17915v1</guid>
      <category>physics.acc-ph</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Austin Hoover</dc:creator>
    </item>
    <item>
      <title>Jet Tagging with More-Interaction Particle Transformer</title>
      <link>https://arxiv.org/abs/2407.08682</link>
      <description>arXiv:2407.08682v3 Announce Type: replace-cross 
Abstract: In this study, we introduce the More-Interaction Particle Transformer (MIParT), a novel deep learning neural network designed for jet tagging. This framework incorporates our own design, the More-Interaction Attention (MIA) mechanism, which increases the dimensionality of particle interaction embeddings. We tested MIParT using the top tagging and quark-gluon datasets. Our results show that MIParT not only matches the accuracy and AUC of LorentzNet and a series of Lorentz-equivariant methods, but also significantly outperforms the ParT model in background rejection. Specifically, it improves background rejection by approximately 25% at a 30% signal efficiency on the top tagging dataset and by 3% on the quark-gluon dataset. Additionally, MIParT requires only 30% of the parameters and 53% of the computational complexity needed by ParT, proving that high performance can be achieved with reduced model complexity. For very large datasets, we double the dimension of particle embeddings, referring to this variant as MIParT-Large (MIParT-L). We find that MIParT-L can further capitalize on the knowledge from large datasets. From a model pre-trained on the 100M JetClass dataset, the background rejection performance of the fine-tuned MIParT-L improved by 39% on the top tagging dataset and by 6% on the quark-gluon dataset, surpassing that of the fine-tuned ParT. Specifically, the background rejection of fine-tuned MIParT-L improved by an additional 2% compared to the fine-tuned ParT. The results suggest that MIParT has the potential to advance efficiency benchmarks for jet tagging and event identification in particle physics. The code is available at the following GitHub repository: https://github.com/USST-HEP/MIParT</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08682v3</guid>
      <category>hep-ph</category>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 27 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1674-1137/ad7f3d</arxiv:DOI>
      <dc:creator>Yifan Wu, Kun Wang, Congqiao Li, Huilin Qu, Jingya Zhu</dc:creator>
    </item>
  </channel>
</rss>
