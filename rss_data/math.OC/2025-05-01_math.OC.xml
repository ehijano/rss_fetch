<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 May 2025 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Strongly Convex Maximization via the Frank-Wolfe Algorithm with the Kurdyka-{\L}ojasiewicz Inequality</title>
      <link>https://arxiv.org/abs/2505.00221</link>
      <description>arXiv:2505.00221v1 Announce Type: new 
Abstract: We study the convergence properties of the 'greedy' Frank-Wolfe algorithm with a unit step size, for a convex maximization problem over a compact set. We assume the function satisfies smoothness and strong convexity. These assumptions together with the Kurdyka-{\L}ojasiewicz (KL) property, allow us to derive global asymptotic convergence for the sequence generated by the algorithm. Furthermore, we also derive a convergence rate that depends on the geometric properties of the problem. To illustrate the implications of the convergence result obtained, we prove a new convergence result for a sparse principal component analysis algorithm, propose a convergent reweighted $\ell_1$ minimization algorithm for compressed sensing, and design a new algorithm for the semidefinite relaxation of the Max-Cut problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00221v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fatih Selim Aktas, Christian Kroer</dc:creator>
    </item>
    <item>
      <title>Feature preserving data assimilation via feature alignment</title>
      <link>https://arxiv.org/abs/2505.00249</link>
      <description>arXiv:2505.00249v1 Announce Type: new 
Abstract: Data assimilation combines information from physical observations and numerical simulation results to obtain better estimates of the state and parameters of a physical system. A wide class of physical systems of interest have solutions that exhibit the formation of structures, called features, which have to be accurately captured by the assimilation framework. For example, fluids can develop features such as shockwaves and contact discontinuities that need to be tracked and preserved during data assimilation. State-of-the-art data assimilation techniques are agnostic of such features. Current ensemble-based methods construct state estimates by taking linear combinations of multiple ensemble states; repeated averaging tends to smear the features over multiple assimilation cycles, leading to nonphysical state estimates. A novel feature-preserving data assimilation methodology that combines sequence alignment with the ensemble transform particle filter is proposed to overcome this limitation of existing assimilation algorithms. Specifically, optimal transport of particles is performed along feature-aligned characteristics. The strength of the proposed feature-preserving filtering approach is demonstrated on multiple test problems described by the compressible Euler equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00249v1</guid>
      <category>math.OC</category>
      <category>physics.flu-dyn</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit N. Subrahmanya, Adrian Sandu</dc:creator>
    </item>
    <item>
      <title>PDCS: A Primal-Dual Large-Scale Conic Programming Solver with GPU Enhancements</title>
      <link>https://arxiv.org/abs/2505.00311</link>
      <description>arXiv:2505.00311v1 Announce Type: new 
Abstract: In this paper, we introduce the "Primal-Dual Conic Programming Solver" (PDCS), a large-scale conic programming solver with GPU enhancements. Problems that PDCS currently supports include linear programs, second-order cone programs, convex quadratic programs, and exponential cone programs. PDCS achieves scalability to large-scale problems by leveraging sparse matrix-vector multiplication as its core computational operation, which is both memory-efficient and well-suited for GPU acceleration. The solver is based on the restarted primal-dual hybrid gradient method but further incorporates several enhancements, including adaptive reflected Halpern restarts, adaptive step-size selection, adaptive weight adjustment, and diagonal rescaling. Additionally, PDCS employs a bijection-based method to compute projections onto rescaled cones. Furthermore, cuPDCS is a GPU implementation of PDCS and it implements customized computational schemes that utilize different levels of GPU architecture to handle cones of different types and sizes. Numerical experiments demonstrate that cuPDCS is generally more efficient than state-of-the-art commercial solvers and other first-order methods on large-scale conic program applications, including Fisher market equilibrium problems, Lasso regression, and multi-period portfolio optimization. Furthermore, cuPDCS also exhibits better scalability, efficiency, and robustness compared to other first-order methods on the conic program benchmark dataset CBLIB. These advantages are more pronounced in large-scale, lower-accuracy settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00311v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenwei Lin, Zikai Xiong, Dongdong Ge, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Burer-Monteiro factorizability of nuclear norm regularized optimization</title>
      <link>https://arxiv.org/abs/2505.00349</link>
      <description>arXiv:2505.00349v1 Announce Type: new 
Abstract: This paper studies the relationship between the nuclear norm-regularized minimization problem, which minimizes the sum of a $C^2$ function $h$ and a positive multiple of the nuclear norm, and its factorized problem obtained by the Burer-Monteiro technique. We first prove that every second-order stationary point of the factorized problem corresponds to an approximate stationary point of its non-factorized counterpart, and those rank-deficient ones correspond to global minimizers of the latter problem when $h$ is additionally convex, conforming with the observations in [2, 15]. Next, discarding the rank condition on the second-order stationary points but assuming the convexity and Lipschitz differentiability of $h$, we characterize, with respect to some natural problem parameters, when every second-order stationary point of the factorized problem is a global minimizer of the corresponding nuclear norm-regularized problem. More precisely, we subdivide the class of Lipschitz differentiable convex $C^2$ functions into subclasses according to those natural parameters and characterize when each subclass consists solely of functions $h$ such that every second-order stationary point of the associated factorized model is a global minimizer of the nuclear norm regularized model. In particular, explicit counterexamples are established when the characterizing condition on the said parameters is violated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00349v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenqing Ouyang, Ting Kei Pong, Man-Chung Yue</dc:creator>
    </item>
    <item>
      <title>Vintage-Based Formulations in Multi-Year Investment Modelling for Energy Systems</title>
      <link>https://arxiv.org/abs/2505.00379</link>
      <description>arXiv:2505.00379v1 Announce Type: new 
Abstract: This paper reviews two established formulations for modelling multi-year energy investments: the simple method, which aggregates all capacity regardless of commissioning year, and the vintage method, which explicitly tracks investments by year to capture differences in technical parameters over time. While the vintage method improves modelling fidelity, it significantly increases model size. To address this, we propose a novel compact formulation that maintains the ability to represent year-specific characteristics while reducing the dimensionality of the model. The proposed compact formulation is implemented in the open-source model TulipaEnergyModel.jl and offers a tractable alternative for detailed long-term energy system planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00379v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ni Wang, Germ\'an Morales-Espa\~na</dc:creator>
    </item>
    <item>
      <title>Proximal gradient-type method with generalized distance and convergence analysis without global descent lemma</title>
      <link>https://arxiv.org/abs/2505.00381</link>
      <description>arXiv:2505.00381v1 Announce Type: new 
Abstract: We consider solving nonconvex composite optimization problems in which the sum of a smooth function and a nonsmooth function is minimized. Many of convergence analyses of proximal gradient-type methods rely on global descent property between the smooth term and its proximal term. On the other hand, the ability to efficiently solve the subproblem depends on the compatibility between the nonsmooth term and the proximal term. Selecting an appropriate proximal term by considering both factors simultaneously is generally difficult. We overcome this issue by providing convergence analyses for proximal gradient-type methods with general proximal terms, without requiring global descent property of the smooth term. As a byproduct, new convergence results of the interior gradient methods for conic optimization are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00381v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shotaro Yagishita, Masaru Ito</dc:creator>
    </item>
    <item>
      <title>Revisiting the convergence rate of the Lasserre hierarchy for polynomial optimization over the hypercube</title>
      <link>https://arxiv.org/abs/2505.00544</link>
      <description>arXiv:2505.00544v1 Announce Type: new 
Abstract: We revisit the problem of minimizing a given polynomial $f$ on the hypercube $[-1,1]^n$. Lasserre's hierarchy (also known as the moment- or sum-of-squares hierarchy) provides a sequence of lower bounds $\{f_{(r)}\}_{r \in \mathbb N}$ on the minimum value $f^*$, where $r$ refers to the allowed degrees in the sum-of-squares hierarchy. A natural question is how fast the hierarchy converges as a function of the parameter $r$. The current state-of-the-art is due to Baldi and Slot [SIAM J. on Applied Algebraic Geometry, 2024] and roughly shows a convergence rate of order $1/r$. Here we obtain closely related results via a different approach: the polynomial kernel method. We also discuss limitations of the polynomial kernel method, suggesting a lower bound of order $1/r^2$ for our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00544v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sander Gribling, Etienne de Klerk, Juan Vera</dc:creator>
    </item>
    <item>
      <title>Learning to Borrow Features for Improved Detection of Small Objects in Single-Shot Detectors</title>
      <link>https://arxiv.org/abs/2505.00044</link>
      <description>arXiv:2505.00044v1 Announce Type: cross 
Abstract: Detecting small objects remains a significant challenge in single-shot object detectors due to the inherent trade-off between spatial resolution and semantic richness in convolutional feature maps. To address this issue, we propose a novel framework that enables small object representations to "borrow" discriminative features from larger, semantically richer instances within the same class. Our architecture introduces three key components: the Feature Matching Block (FMB) to identify semantically similar descriptors across layers, the Feature Representing Block (FRB) to generate enhanced shallow features through weighted aggregation, and the Feature Fusion Block (FFB) to refine feature maps by integrating original, borrowed, and context information. Built upon the SSD framework, our method improves the descriptive capacity of shallow layers while maintaining real-time detection performance. Experimental results demonstrate that our approach significantly boosts small object detection accuracy over baseline methods, offering a promising direction for robust object detection in complex visual environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00044v1</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard Schmit</dc:creator>
    </item>
    <item>
      <title>A New Hybrid Quantum-Classical Algorithm for Solving the Unit Commitment Problem</title>
      <link>https://arxiv.org/abs/2505.00145</link>
      <description>arXiv:2505.00145v1 Announce Type: cross 
Abstract: Solving problems related to planning and operations of large-scale power systems is challenging on classical computers due to their inherent nature as mixed-integer and nonlinear problems. Quantum computing provides new avenues to approach these problems. We develop a hybrid quantum-classical algorithm for the Unit Commitment (UC) problem in power systems which aims at minimizing the total cost while optimally allocating generating units to meet the hourly demand of the power loads. The hybrid algorithm combines a variational quantum algorithm (VQA) with a classical Bender's type heuristic. The resulting algorithm computes approximate solutions to UC in three stages: i) a collection of UC vectors capable meeting the power demand with lowest possible operating costs is generated based on VQA; ii) a classical sequential least squares programming (SLSQP) routine is leveraged to find the optimal power level corresponding to a predetermined number of candidate vectors; iii) in the last stage, the approximate solution of UC along with generating units power level combination is given. To demonstrate the effectiveness of the presented method, three different systems with 3 generating units, 10 generating units, and 26 generating units were tested for different time periods. In addition, convergence of the hybrid quantum-classical algorithm for select time periods is proven out on IonQ's Forte system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00145v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Willie Aboumrad, Phani R V Marthi, Suman Debnath, Martin Roetteler, Evgeny Epifanovsky</dc:creator>
    </item>
    <item>
      <title>Stochastic Subspace Descent Accelerated via Bi-fidelity Line Search</title>
      <link>https://arxiv.org/abs/2505.00162</link>
      <description>arXiv:2505.00162v1 Announce Type: cross 
Abstract: Efficient optimization remains a fundamental challenge across numerous scientific and engineering domains, especially when objective function and gradient evaluations are computationally expensive. While zeroth-order optimization methods offer effective approaches when gradients are inaccessible, their practical performance can be limited by the high cost associated with function queries. This work introduces the bi-fidelity stochastic subspace descent (BF-SSD) algorithm, a novel zeroth-order optimization method designed to reduce this computational burden. BF-SSD leverages a bi-fidelity framework, constructing a surrogate model from a combination of computationally inexpensive low-fidelity (LF) and accurate high-fidelity (HF) function evaluations. This surrogate model facilitates an efficient backtracking line search for step size selection, for which we provide theoretical convergence guarantees under standard assumptions. We perform a comprehensive empirical evaluation of BF-SSD across four distinct problems: a synthetic optimization benchmark, dual-form kernel ridge regression, black-box adversarial attacks on machine learning models, and transformer-based black-box language model fine-tuning. Numerical results demonstrate that BF-SSD consistently achieves superior optimization performance while requiring significantly fewer HF function evaluations compared to relevant baseline methods. This study highlights the efficacy of integrating bi-fidelity strategies within zeroth-order optimization, positioning BF-SSD as a promising and computationally efficient approach for tackling large-scale, high-dimensional problems encountered in various real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00162v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nuojin Cheng, Alireza Doostan, Stephen Becker</dc:creator>
    </item>
    <item>
      <title>Guidance and Control of Unmanned Surface Vehicles via HEOL</title>
      <link>https://arxiv.org/abs/2505.00168</link>
      <description>arXiv:2505.00168v1 Announce Type: cross 
Abstract: This work presents a new approach to the guidance and control of marine craft via HEOL, i.e., a new way of combining flatness-based and model-free controllers. Its goal is to develop a general regulator for Unmanned Surface Vehicles (USV). To do so, the well-known USV maneuvering model is simplified into a nominal Hovercraft model which is flat. A flatness-based controller is derived for the simplified USV model and the loop is closed via an intelligent proportional-derivative (iPD) regulator. We thus associate the well-documented natural robustness of flatness-based control and adaptivity of iPDs. The controller is applied in simulation to two surface vessels, one meeting the simplifying hypotheses, the other one being a generic USV of the literature. It is shown to stabilize both systems even in the presence of unmodeled environmental disturbances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00168v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lo\"ick Degorre, Emmanuel Delaleau, C\'edric Join, Michel Fliess</dc:creator>
    </item>
    <item>
      <title>PSN Game: Game-theoretic Planning via a Player Selection Network</title>
      <link>https://arxiv.org/abs/2505.00213</link>
      <description>arXiv:2505.00213v1 Announce Type: cross 
Abstract: While game-theoretic planning frameworks are effective at modeling multi-agent interactions, they require solving optimization problems with hundreds or thousands of variables, resulting in long computation times that limit their use in large-scale, real-time systems. To address this issue, we propose PSN Game: a novel game-theoretic planning framework that reduces runtime by learning a Player Selection Network (PSN). A PSN outputs a player selection mask that distinguishes influential players from less relevant ones, enabling the ego player to solve a smaller, masked game involving only selected players. By reducing the number of variables in the optimization problem, PSN directly lowers computation time. The PSN Game framework is more flexible than existing player selection methods as it i) relies solely on observations of players' past trajectories, without requiring full state, control, or other game-specific information; and ii) requires no online parameter tuning. We train PSNs in an unsupervised manner using a differentiable dynamic game solver, with reference trajectories from full-player games guiding the learning. Experiments in both simulated scenarios and human trajectory datasets demonstrate that i) PSNs outperform baseline selection methods in trajectory smoothness and length, while maintaining comparable safety and achieving a 10x speedup in runtime; and ii) PSNs generalize effectively to real-world scenarios without fine-tuning. By selecting only the most relevant players for decision-making, PSNs offer a general mechanism for reducing planning complexity that can be seamlessly integrated into existing multi-agent planning frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00213v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianyu Qiu, Eric Ouano, Fernando Palafox, Christian Ellis, David Fridovich-Keil</dc:creator>
    </item>
    <item>
      <title>Pinching-Antenna Systems (PASS): Power Radiation Model and Optimal Beamforming Design</title>
      <link>https://arxiv.org/abs/2505.00218</link>
      <description>arXiv:2505.00218v1 Announce Type: cross 
Abstract: Pinching-antenna systems (PASS) improve wireless links by configuring the locations of activated pinching antennas along dielectric waveguides, namely pinching beamforming. In this paper, a novel adjustable power radiation model is proposed for PASS, where power radiation ratios of pinching antennas can be flexibly controlled by tuning the spacing between pinching antennas and waveguides. A closed-form pinching antenna spacing arrangement strategy is derived to achieve the commonly assumed equal-power radiation. Based on this, a practical PASS framework relying on discrete activation is considered, where pinching antennas can only be activated among a set of predefined locations. A transmit power minimization problem is formulated, which jointly optimizes the transmit beamforming, pinching beamforming, and the numbers of activated pinching antennas, subject to each user's minimum rate requirement. (1) To solve the resulting highly coupled mixed-integer nonlinear programming (MINLP) problem, branch-and-bound (BnB)-based algorithms are proposed for both single-user and multi-user scenarios, which is guaranteed to converge to globally optimal solutions. (2) A low-complexity many-to-many matching algorithm is further developed. Combined with the Karush-Kuhn-Tucker (KKT) theory, locally optimal and pairwise-stable solutions are obtained within polynomial-time complexity. Simulation results demonstrate that: (i) PASS significantly outperforms conventional multi-antenna architectures, particularly when the number of users and the spatial range increase; and (ii) The proposed matching-based algorithm achieves near-optimal performance, resulting in only a slight performance loss while significantly reducing computational overheads. Code is available at https://github.com/xiaoxiaxusummer/PASS_Discrete</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00218v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoxia Xu, Xidong Mu, Zhaolin Wang, Yuanwei Liu, Arumugam Nallanathan</dc:creator>
    </item>
    <item>
      <title>Inference for max-linear Bayesian networks with noise</title>
      <link>https://arxiv.org/abs/2505.00229</link>
      <description>arXiv:2505.00229v1 Announce Type: cross 
Abstract: Max-Linear Bayesian Networks (MLBNs) provide a powerful framework for causal inference in extreme-value settings; we consider MLBNs with noise parameters with a given topology in terms of the max-plus algebra by taking its logarithm. Then, we show that an estimator of a parameter for each edge in a directed acyclic graph (DAG) is distributed normally. We end this paper with computational experiments with the expectation and maximization (EM) algorithm and quadratic optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00229v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark Adams, Kamillo Ferry, Ruriko Yoshida</dc:creator>
    </item>
    <item>
      <title>Beyond Quadratic Costs in LQR: Bregman Divergence Control</title>
      <link>https://arxiv.org/abs/2505.00317</link>
      <description>arXiv:2505.00317v1 Announce Type: cross 
Abstract: In the past couple of decades, the use of ``non-quadratic" convex cost functions has revolutionized signal processing, machine learning, and statistics, allowing one to customize solutions to have desired structures and properties. However, the situation is not the same in control where the use of quadratic costs still dominates, ostensibly because determining the ``value function", i.e., the optimal expected cost-to-go, which is critical to the construction of the optimal controller, becomes computationally intractable as soon as one considers general convex costs. As a result, practitioners often resort to heuristics and approximations, such as model predictive control that only looks a few steps into the future. In the quadratic case, the value function is easily determined by solving Riccati equations. In this work, we consider a special class of convex cost functions constructed from Bregman divergence and show how, with appropriate choices, they can be used to fully extend the framework developed for the quadratic case. The resulting optimal controllers are infinite horizon, come with stability guarantees, and have state-feedback, or estimated state-feedback, laws. They exhibit a much wider range of behavior than their quadratic counterparts since the feedback laws are nonlinear. The approach can be applied to several cases of interest, including safety control, sparse control, and bang-bang control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00317v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Babak Hassibi, Joudi Hajar, Reza Ghane</dc:creator>
    </item>
    <item>
      <title>Second-Order Adjoint Method for Quantum Optimal Control</title>
      <link>https://arxiv.org/abs/2505.00529</link>
      <description>arXiv:2505.00529v1 Announce Type: cross 
Abstract: We derive and implement a second-order adjoint method to compute exact gradients and Hessians for a prototypical quantum optimal control problem, that of solving for the minimal energy applied electric field that drives a molecule from a given initial state to a desired target state. For small to moderately sized systems, we demonstrate a vectorized GPU implementation of a second-order adjoint method that computes both Hessians and gradients with wall times only marginally more than those required to compute gradients via commonly used first-order adjoint methods. Pairing our second-order adjoint method with a trust region optimizer (a type of Newton method), we show that it outperforms a first-order method, requiring significantly fewer iterations and wall time to find optimal controls for four molecular systems. Our derivation of the second-order adjoint method allows for arbitrary parameterizations of the controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00529v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Harish S. Bhat</dc:creator>
    </item>
    <item>
      <title>Accelerated First-Order Optimization under Nonlinear Constraints</title>
      <link>https://arxiv.org/abs/2302.00316</link>
      <description>arXiv:2302.00316v3 Announce Type: replace 
Abstract: We exploit analogies between first-order algorithms for constrained optimization and non-smooth dynamical systems to design a new class of accelerated first-order algorithms for constrained optimization. Unlike Frank-Wolfe or projected gradients, these algorithms avoid optimization over the entire feasible set at each iteration. We prove convergence to stationary points even in a nonconvex setting and we derive accelerated rates for the convex setting both in continuous time, as well as in discrete time. An important property of these algorithms is that constraints are expressed in terms of velocities instead of positions, which naturally leads to sparse, local and convex approximations of the feasible set (even if the feasible set is nonconvex). Thus, the complexity tends to grow mildly in the number of decision variables and in the number of constraints, which makes the algorithms suitable for machine learning applications. We apply our algorithms to a compressed sensing and a sparse regression problem, showing that we can treat nonconvex $\ell^p$ constraints ($p&lt;1$) efficiently, while recovering state-of-the-art performance for $p=1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.00316v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Muehlebach, Michael I. Jordan</dc:creator>
    </item>
    <item>
      <title>A Near-Optimal Single-Loop Stochastic Algorithm for Convex Finite-Sum Coupled Compositional Optimization</title>
      <link>https://arxiv.org/abs/2312.02277</link>
      <description>arXiv:2312.02277v5 Announce Type: replace 
Abstract: This paper studies a class of convex Finite-sum Coupled Compositional Optimization (cFCCO) problems with applications including group distributionally robust optimization (GDRO) and learning with imbalanced data. To better address these problems, we introduce an efficient single-loop primal-dual block-coordinate stochastic algorithm called ALEXR. The algorithm employs block-coordinate stochastic mirror ascent with extrapolation for the dual variable and stochastic proximal gradient descent updates for the primal variable. We establish the convergence rates of ALEXR in both convex and strongly convex cases under smoothness and non-smoothness conditions of involved functions, which not only improve the best rates in previous works on smooth cFCCO problems but also expand the realm of cFCCO for solving more challenging non-smooth problems such as the dual form of GDRO. Finally, we derive lower complexity bounds, demonstrating the (near-)optimality of ALEXR within a broad class of stochastic algorithms for cFCCO. Experimental results on GDRO and partial Area Under the ROC Curve (pAUC) maximization demonstrate the promising performance of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02277v5</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bokun Wang, Tianbao Yang</dc:creator>
    </item>
    <item>
      <title>Heavy-ball Differential Equation Achieves $O(\varepsilon^{-7/4})$ Convergence for Nonconvex Functions</title>
      <link>https://arxiv.org/abs/2406.06100</link>
      <description>arXiv:2406.06100v2 Announce Type: replace 
Abstract: First-order optimization methods for nonconvex functions with Lipschitz continuous gradient and Hessian have been extensively studied. State-of-the-art methods for finding an $\varepsilon$-stationary point within $O(\varepsilon^{-{7/4}})$ or $\tilde{O}(\varepsilon^{-{7/4}})$ gradient evaluations are based on Nesterov's accelerated gradient descent (AGD) or Polyak's heavy-ball (HB) method. However, these algorithms employ additional mechanisms, such as restart schemes and negative curvature exploitation, which complicate their behavior and make it challenging to apply them to more advanced settings (e.g., stochastic optimization). As a first step in investigating whether a simple algorithm with $O(\varepsilon^{-{7/4}})$ complexity can be constructed without such additional mechanisms, we study the HB differential equation, a continuous-time analogue of the AGD and HB methods. We prove that its dynamics attain an $\varepsilon$-stationary point within $O(\varepsilon^{-{7/4}})$ time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06100v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaito Okamura, Naoki Marumo, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Benamou-Brenier Formulation of Optimal Transport for Nonlinear Control Systems on Rd</title>
      <link>https://arxiv.org/abs/2407.16088</link>
      <description>arXiv:2407.16088v4 Announce Type: replace 
Abstract: In this paper we consider the Benamou-Brenier formulation of optimal transport for nonlinear control affine systems on $\Rd$, removing the compactness assumption of the underlying manifold in previous work by the author. By using Bernard's Young measure based weak formulation of optimal transport, the results are established for cases not covered by previous treatments using the Monge problem. Particularly, no assumptions are made on the non-existence of singular minimizing controls or the cost function being Lipschitz. Therefore, the existence of solutions to dynamical formulation is established for general Sub-Riemmanian energy costs not covered by literature previously.
  The results also establish controllability of the continuity equation whenever the corresponding Kantorovich problem admits a feasible solution, leveraging the equivalence between the Kantorovich and Benamou-Brenier formulations. Furthermore, when the cost function does not admit singular minimizing curves, we demonstrate that the Benamou-Brenier problem is equivalent to its convexified formulation in momentum and measure coordinates. In this regular setting, we further show that the constructed transport solutions possess sufficient regularity: for the feedback control laws that achieve transport, the associated continuity equation admits a unique weak solution. These findings apply in particular to linear-quadratic costs for controllable linear time-invariant (LTI) systems, as well as to certain classes of driftless nonlinear systems. Thus, in these cases, controllability of the continuity equation is achieved with control laws regular enough to guarantee uniqueness of solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16088v4</guid>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthik Elamvazhuthi</dc:creator>
    </item>
    <item>
      <title>Data-driven topology design for conductor layout problem of electromagnetic interference filter</title>
      <link>https://arxiv.org/abs/2410.18459</link>
      <description>arXiv:2410.18459v2 Announce Type: replace 
Abstract: Electromagnetic interference (EMI) filters are used to reduce electromagnetic noise. It is well known that the performance of an EMI filter in reducing electromagnetic noise largely depends on its conductor layout. Therefore, if a conductor layout optimization method with a high degree of freedom is realized, a drastic performance improvement is expected. Although there are a few design methods based on topology optimization for this purpose, these methods have some difficulties originating from topology optimization. In this paper, we therefore propose a conductor layout design method for EMI filters on the basis of data-driven topology design (DDTD), which is a high degree of freedom structural design methodology incorporating a deep generative model and data-driven approach. DDTD was proposed to overcome the intrinsic difficulties of topology optimization, and we consider it suitable for the conductor layout design problem of EMI filters. One significant challenge in applying DDTD to the conductor layout design problem is maintaining the topology of the circuit diagram during the solution search. For this purpose, we propose a simple yet efficient constraint. We further provide numerical examples to confirm the usefulness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18459v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Duanyutian Zhou, Nomura Katsuya, Shintaro Yamasaki</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of nonmonotone proximal gradient methods under local Lipschitz continuity and Kurdyka--{\L}ojasiewicz property</title>
      <link>https://arxiv.org/abs/2411.19256</link>
      <description>arXiv:2411.19256v3 Announce Type: replace 
Abstract: The proximal gradient method is a standard approach for solving composite minimization problems in which the objective function is the sum of a continuously differentiable function and a lower semicontinuous, extended-valued function. The traditional convergence theory for both monotone and nonmonotone variants replies heavily on the assumption of global Lipschitz continuity of the gradient of the smooth part of the objective function. Recent work has shown that monotone proximal gradient methods converge globally only when the local (rather than global) Lipschitz continuity is assumed, provided that the Kurdyka--{\L}ojasiewicz (KL) property holds. However, these results have not been extended to nonmonotone proximal gradient (NPG) methods. In this manuscript, we consider two types of NPG methods: those combined with the average line search and the max line search, respectively. By partitioning indices into two subsets, one of which aims to achieve a sufficient decrease in the functional sequence, we establish global convergence and rate-of-convergence results using the local Lipschitz continuity and the KL property, without requiring boundedness of the iterates. While finalizing this work, we noticed that [18] presented analogous results for the NPG method with average line search, but with a different partitioning strategy. Together, we confidently conclude that the convergence theory of the NPG method is independent on index partitioning choices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19256v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoxi Jia, Kai Wang</dc:creator>
    </item>
    <item>
      <title>Introduction to Online Control</title>
      <link>https://arxiv.org/abs/2211.09619</link>
      <description>arXiv:2211.09619v5 Announce Type: replace-cross 
Abstract: This text presents an introduction to an emerging paradigm in control of dynamical systems and differentiable reinforcement learning called online nonstochastic control. The new approach applies techniques from online convex optimization and convex relaxations to obtain new methods with provable guarantees for classical settings in optimal and robust control.
  The primary distinction between online nonstochastic control and other frameworks is the objective. In optimal control, robust control, and other control methodologies that assume stochastic noise, the goal is to perform comparably to an offline optimal strategy. In online nonstochastic control, both the cost functions as well as the perturbations from the assumed dynamical model are chosen by an adversary. Thus the optimal policy is not defined a priori. Rather, the target is to attain low regret against the best policy in hindsight from a benchmark class of policies.
  This objective suggests the use of the decision making framework of online convex optimization as an algorithmic methodology. The resulting methods are based on iterative mathematical optimization algorithms, and are accompanied by finite-time regret and computational complexity guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.09619v5</guid>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Elad Hazan, Karan Singh</dc:creator>
    </item>
    <item>
      <title>Computational and Statistical Guarantees for Tensor-on-Tensor Regression with Tensor Train Decomposition</title>
      <link>https://arxiv.org/abs/2406.06002</link>
      <description>arXiv:2406.06002v2 Announce Type: replace-cross 
Abstract: Recently, a tensor-on-tensor (ToT) regression model has been proposed to generalize tensor recovery, encompassing scenarios like scalar-on-tensor regression and tensor-on-vector regression. However, the exponential growth in tensor complexity poses challenges for storage and computation in ToT regression. To overcome this hurdle, tensor decompositions have been introduced, with the tensor train (TT)-based ToT model proving efficient in practice due to reduced memory requirements, enhanced computational efficiency, and decreased sampling complexity. Despite these practical benefits, a disparity exists between theoretical analysis and real-world performance. In this paper, we delve into the theoretical and algorithmic aspects of the TT-based ToT regression model. Assuming the regression operator satisfies the restricted isometry property (RIP), we conduct an error analysis for the solution to a constrained least-squares optimization problem. This analysis includes upper error bound and minimax lower bound, revealing that such error bounds polynomially depend on the order $N+M$. To efficiently find solutions meeting such error bounds, we propose two optimization algorithms: the iterative hard thresholding (IHT) algorithm (employing gradient descent with TT-singular value decomposition (TT-SVD)) and the factorization approach using the Riemannian gradient descent (RGD) algorithm. When RIP is satisfied, spectral initialization facilitates proper initialization, and we establish the linear convergence rate of both IHT and RGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06002v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen Qin, Zhihui Zhu</dc:creator>
    </item>
    <item>
      <title>Robust dividend policy: Equivalence of Epstein-Zin and Maenhout preferences</title>
      <link>https://arxiv.org/abs/2406.12305</link>
      <description>arXiv:2406.12305v2 Announce Type: replace-cross 
Abstract: In a continuous-time economy, this paper formulates the Epstein-Zin (EZ) preference for discounted dividends received by an investor as an EZ singular control utility. We introduce a backward stochastic differential equation with a aggregator integrated with respect to a singular control, prove its well-posedness, and show that it coincides with the EZ singular control utility. We then establish that this formulation is equivalent to a robust dividend policy chosen by the firm's executive under the Maenhout's ambiguity-averse preference. In particular, the robust dividend policy takes the form of a threshold strategy on the firm's surplus process, where the threshold level is characterized as the free boundary of a Hamilton-Jacobi-Bellman variational inequality. Therefore, dividend-caring investors can choose firms that match their preferences by examining stock's dividend policies and financial statements, whereas executives can make use of dividend to signal their confidence, in the form of ambiguity aversion, on realizing the earnings implied by their financial statements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12305v2</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.GN</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kexin Chen, Kyunghyun Park, Hoi Ying Wong</dc:creator>
    </item>
    <item>
      <title>Steady-State Cascade Operators and their Role in Linear Control, Estimation, and Model Reduction Problems</title>
      <link>https://arxiv.org/abs/2408.07568</link>
      <description>arXiv:2408.07568v2 Announce Type: replace-cross 
Abstract: Certain linear matrix operators arise naturally in systems analysis and design problems involving cascade interconnections of linear time-invariant systems, including problems of stabilization, estimation, and model order reduction. We conduct here a comprehensive study of these operators and their relevant system-theoretic properties. The general theory is leveraged to delineate both known and new design methodologies for control and observation of cascades, and to characterize structural properties of reduced models. Several entirely new designs arise from this systematic categorization, including new recursive and low-gain design frameworks for observation of cascaded systems. The benefits of the results beyond the linear time-invariant setting are demonstrated through preliminary extensions for nonlinear systems, with an outlook towards the development of a similarly comprehensive nonlinear theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07568v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>John W. Simpson-Porco, Daniele Astolfi, Giordano Scarciotti</dc:creator>
    </item>
    <item>
      <title>Level-set shape optimization via polytopic discontinuous Galerkin methods</title>
      <link>https://arxiv.org/abs/2408.13206</link>
      <description>arXiv:2408.13206v2 Announce Type: replace-cross 
Abstract: We introduce a new level-set shape optimization approach based on polytopic (i.e., polygonal in two and polyhedral in three spatial dimensions) discontinuous Galerkin methods. The approach benefits from the geometric mesh flexibility of polytopic discontinuous Galerkin methods to resolve the zero-level set accurately and efficiently. Additionally, we employ suitable Runge-Kutta discontinuous Galerkin methods to update the level-set function on a fine underlying simplicial mesh. We discuss the construction and implementation of the approach, explaining how to modify shape derivate formulas to compute consistent shape gradient approximations using discontinuous Galerkin methods, and how to recover dG functions into smoother ones. Numerical experiments on unconstrained and PDE-constrained test cases evidence the good properties of the proposed methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13206v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raphael E. Fernandes, Emmanuil H. Georgoulis, Alberto Paganini</dc:creator>
    </item>
    <item>
      <title>Sample-Efficient Quantum State Tomography for Structured Quantum States in One Dimension</title>
      <link>https://arxiv.org/abs/2410.02583</link>
      <description>arXiv:2410.02583v3 Announce Type: replace-cross 
Abstract: While quantum state tomography (QST) remains the gold standard for benchmarking and verifying quantum devices, it requires an exponentially large number of measurements and classical computational resources for generic quantum many-body systems, making it impractical even for intermediate-size quantum devices. Fortunately, many physical quantum states often exhibit certain low-dimensional structures that enable the development of efficient QST. A notable example is the class of states represented by matrix product operators (MPOs) with a finite matrix/bond dimension, which include most physical states in one dimension and where the number of independent parameters describing the states only grows linearly with the number of qubits. Whether a sample efficient quantum state tomography protocol, where the number of required state copies scales only linearly as the number of parameters describing the state, exists for a generic MPO state still remains an important open question.
  In this paper, we answer this fundamental question affirmatively by using a class of informationally complete positive operator-valued measures (IC-POVMs) -- including symmetric IC-POVMs (SIC-POVMs) and spherical $t$-designs -- focusing on sample complexity while not accounting for the implementation complexity of the measurement settings. For SIC-POVMs and (approximate) spherical 2-designs, we show that the number of state copies to guarantee bounded recovery error of an MPO state with a constrained least-squares estimator depends on the probability distribution of the MPO under the POVM but scales only linearly with $n$ when the distribution is approximately uniform. For spherical $t$-designs with $t\geq 3$, we prove that only a number of state copies proportional to the number of independent parameters in the MPO is sufficient for a guaranteed recovery of any state represented by an MPO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02583v3</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen Qin, Casey Jameson, Alireza Goldar, Michael B. Wakin, Zhexuan Gong, Zhihui Zhu</dc:creator>
    </item>
    <item>
      <title>Well-Posedness and Long-Time Dynamics of a Water-Waves Model with Time-Varying Boundary Delay</title>
      <link>https://arxiv.org/abs/2411.05191</link>
      <description>arXiv:2411.05191v2 Announce Type: replace-cross 
Abstract: A higher-order nonlinear Boussinesq system with a time-dependent boundary delay is considered. Sufficient conditions are presented to ensure the well-posedness of the problem by utilizing Kato's variable norm technique and the Fixed-Point Theorem. More significantly, the energy decay for the linearized problem is demonstrated using the energy method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05191v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>G. Bautista, R. de A. Capistrano--Filho, B. Chentouf, O. Sierra Fonseca</dc:creator>
    </item>
    <item>
      <title>Improving the convergence of Markov chains via permutations and projections</title>
      <link>https://arxiv.org/abs/2411.08295</link>
      <description>arXiv:2411.08295v2 Announce Type: replace-cross 
Abstract: This paper aims at improving the convergence to equilibrium of finite ergodic Markov chains via permutations and projections. First, we prove that a specific mixture of permuted Markov chains arises naturally as a projection under the KL divergence or the squared-Frobenius norm. We then compare various mixing properties of the mixture with other competing Markov chain samplers and demonstrate that it enjoys improved convergence. This geometric perspective motivates us to propose samplers based on alternating projections to combine different permutations and to analyze their rate of convergence. We give necessary, and under some additional assumptions also sufficient, conditions for the projection to achieve stationarity in the limit in terms of the trace of the transition matrix. We proceed to discuss tuning strategies of the projection samplers when these permutations are viewed as parameters. Along the way, we reveal connections between the mixture and a Markov chain Sylvester's equation as well as assignment problems, and highlight how these can be used to understand and improve Markov chain mixing. We provide two examples as illustrations. In the first example, the projection sampler (with a suitable choice of the permutation) improves upon Metropolis-Hastings in a discrete bimodal distribution with a reduced relaxation time from exponential to polynomial in the system size, while in the second example, the mixture of permuted Markov chain yields a mixing time that is logarithmic in system size (with high probability under random permutation), compared to a linear mixing time in the Diaconis-Holmes-Neal sampler. Finally, we provide numerical experiments on statistical physics models to illustrate the improved mixing performance of the proposed projection samplers over standard Metropolis-Hastings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08295v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael C. H. Choi, Max Hird, Youjia Wang</dc:creator>
    </item>
  </channel>
</rss>
