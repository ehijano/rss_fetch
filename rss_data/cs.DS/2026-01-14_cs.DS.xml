<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 Jan 2026 05:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Derandomizing Matrix Concentration Inequalities from Free Probability</title>
      <link>https://arxiv.org/abs/2601.08111</link>
      <description>arXiv:2601.08111v1 Announce Type: new 
Abstract: Recently, sharp matrix concentration inequalities~\cite{BBvH23,BvH24} were developed using the theory of free probability. In this work, we design polynomial time deterministic algorithms to construct outcomes that satisfy the guarantees of these inequalities. As direct consequences, we obtain polynomial time deterministic algorithms for the matrix Spencer problem~\cite{BJM23} and for constructing near-Ramanujan graphs. Our proofs show that the concepts and techniques in free probability are useful not only for mathematical analyses but also for efficient computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08111v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Wang, Lap Chi Lau, Hong Zhou</dc:creator>
    </item>
    <item>
      <title>Protrusion Decompositions Revisited: Uniform Lossy Kernels for Reducing Treewidth and Linear Kernels for Hitting Disconnected Minors</title>
      <link>https://arxiv.org/abs/2601.08424</link>
      <description>arXiv:2601.08424v1 Announce Type: new 
Abstract: Let F be a finite family of graphs. In the F-Deletion problem, one is given a graph G and an integer k, and the goal is to find k vertices whose deletion results in a graph with no minor from the family F. This may be regarded as a far-reaching generalization of Vertex Cover and Feedback vertex Set. In their seminal work, Fomin, Lokshtanov, Misra &amp; Saurabh [FOCS 2012] gave a polynomial kernel for this problem when the family F contains a planar graph. As the size of their kernel is g(F) * k^{f(F)}, a natural follow-up question was whether the dependence on F in the exponent of k can be avoided. The answer turned out to be negative: Giannapoulou, Jansen, Lokshtanov &amp; Saurabh [TALG 2017] proved that this is already inevitable for the special case of the Treewidth-d-Deletion problem.
  In this work, we show that this non-uniformity can be avoided at the expense of a small loss. First, we present a simple 2-approximate kernelization algorithm for Treewidth-d-Deletion with kernel size g(d) * k^5. Next, we show that the approximation factor can be made arbitrarily close to 1, if we settle for a kernelization protocol with O(1) calls to an oracle that solves instances of size bounded by a uniform polynomial in k.
  We also obtain linear kernels on sparse graph classes when F contains a planar graph, whereas the previously known theorems required all graphs in F to be connected. Specifically, we generalize the kernelization algorithm by Kim, Langer, Paul, Reidl, Rossmanith, Sau &amp; Sikdar [TALG 2015] on graph classes that exclude a topological minor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08424v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.STACS.2026.31</arxiv:DOI>
      <dc:creator>Roohani Sharma, Micha{\l} W{\l}odarczyk</dc:creator>
    </item>
    <item>
      <title>FPT Approximations for Connected Maximum Coverage</title>
      <link>https://arxiv.org/abs/2601.08639</link>
      <description>arXiv:2601.08639v1 Announce Type: new 
Abstract: We revisit connectivity-constrained coverage through a unifying model, Partial Connected Red-Blue Dominating Set. Given a red-blue bipartite graph $G$ and an auxiliary connectivity graph $G_{conn}$ on red vertices, and integers $k, t$, the task is to find a $k$-sized subset of red vertices that dominates at least $t$ blue vertices, and that induces a connected subgraph in $G_{conn}$. This formulation captures connected variants of Max Coverage, Partial Dominating Set, and Partial Vertex Cover studied in prior literature.
  After identifying (parameterized) inapproximability results inherited from known problems, we first show that the problem is fixed-parameter tractable by $t$. Furthermore, when the bipartite graph excludes $K_{d,d}$ as a subgraph, we design (resp. efficient) parameterized approximation schemes for approximating $t$ (resp. $k$). Notably, these FPT approximations do not impose any restrictions on $G_{conn}$. Together, these results chart the boundary between hardness and FPT-approximability for connectivity-constrained coverage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08639v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tanmay Inamdar, Satyabrata Jana, Madhumita Kundu, Daniel Lokshtanov, Saket Saurabh, Meirav Zehavi</dc:creator>
    </item>
    <item>
      <title>Delaunay Triangulations with Predictions</title>
      <link>https://arxiv.org/abs/2601.08106</link>
      <description>arXiv:2601.08106v1 Announce Type: cross 
Abstract: We investigate algorithms with predictions in computational geometry, specifically focusing on the basic problem of computing 2D Delaunay triangulations. Given a set $P$ of $n$ points in the plane and a triangulation $G$ that serves as a "prediction" of the Delaunay triangulation, we would like to use $G$ to compute the correct Delaunay triangulation $\textit{DT}(P)$ more quickly when $G$ is "close" to $\textit{DT}(P)$. We obtain a variety of results of this type, under different deterministic and probabilistic settings, including the following: 1. Define $D$ to be the number of edges in $G$ that are not in $\textit{DT}(P)$. We present a deterministic algorithm to compute $\textit{DT}(P)$ from $G$ in $O(n + D\log^3 n)$ time, and a randomized algorithm in $O(n+D\log n)$ expected time, the latter of which is optimal in terms of $D$. 2. Let $R$ be a random subset of the edges of $\textit{DT}(P)$, where each edge is chosen independently with probability $\rho$. Suppose $G$ is any triangulation of $P$ that contains $R$. We present an algorithm to compute $\textit{DT}(P)$ from $G$ in $O(n\log\log n + n\log(1/\rho))$ time with high probability. 3. Define $d_{\mbox{\scriptsize\rm vio}}$ to be the maximum number of points of $P$ strictly inside the circumcircle of a triangle in $G$ (the number is 0 if $G$ is equal to $\textit{DT}(P)$). We present a deterministic algorithm to compute $\textit{DT}(P)$ from $G$ in $O(n\log^*n + n\log d_{\mbox{\scriptsize\rm vio}})$ time. We also obtain results in similar settings for related problems such as 2D Euclidean minimum spanning trees, and hope that our work will open up a fruitful line of future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08106v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergio Cabello, Timothy M. Chan, Panos Giannopoulos</dc:creator>
    </item>
    <item>
      <title>Symbolic Functional Decomposition: A Reconfiguration Approach</title>
      <link>https://arxiv.org/abs/2601.08354</link>
      <description>arXiv:2601.08354v1 Announce Type: cross 
Abstract: Functional decomposition is the process of breaking down a function $f$ into a composition $f=g(f_1,\dots,f_k)$ of simpler functions $f_1,\dots,f_k$ belonging to some class $\mathcal{F}$. This fundamental notion can be used to model applications arising in a wide variety of contexts, ranging from machine learning to formal language theory. In this work, we study functional decomposition by leveraging on the notion of functional reconfiguration. In this setting, constraints are imposed not only on the factor functions $f_1,\dots,f_k$ but also on the intermediate functions arising during the composition process.
  We introduce a symbolic framework to address functional reconfiguration and decomposition problems. In our framework, functions arising during the reconfiguration process are represented symbolically, using ordered binary decision diagrams (OBDDs). The function $g$ used to specify the reconfiguration process is represented by a Boolean circuit $C$. Finally, the function class $\mathcal{F}$ is represented by a second-order finite automaton $\mathcal{A}$. Our main result states that functional reconfiguration, and hence functional decomposition, can be solved in fixed-parameter linear time when parameterized by the width of the input OBDD, by structural parameters associated with the reconfiguration circuit $C$, and by the size of the second-order finite automaton $\mathcal{A}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08354v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mateus de Oliveira Oliveira, Wim Van den Broeck</dc:creator>
    </item>
    <item>
      <title>Kantorovich Distance via Spanning Trees: Properties and Algorithms</title>
      <link>https://arxiv.org/abs/2601.08396</link>
      <description>arXiv:2601.08396v1 Announce Type: cross 
Abstract: We study optimal transport between probability measures supported on the same finite metric space, where the ground cost is a distance induced by a weighted connected graph. Building on recent work showing that the resulting Kantorovich distance can be expressed as a minimization problem over the set of spanning trees of this underlying graph, we investigate the implications of this reformulation on the construction of an optimal transport plan and a dual potential based on the solution of such an optimization problem. In this setting, we derive an explicit formula for the Kantorovich potential in terms of the imbalanced cumulative mass (a generalization of the cumulative distribution in R) along an optimal spanning tree solving such a minimization problem, under a weak non-degeneracy condition on the pair of measures that guarantees the uniqueness of a dual potential. Our second contribution establishes the existence of an optimal transport plan that can be computed efficiently by a dynamic programming procedure once an optimal spanning tree is known. Finally, we propose a stochastic algorithm based on simulated annealing on the space of spanning trees to compute such an optimal spanning tree. Numerical experiments illustrate the theoretical results and demonstrate the practical relevance of the proposed approach for optimal transport on finite metric spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08396v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J\'er\'emie Bigot, Luis Fredes</dc:creator>
    </item>
    <item>
      <title>Lower Bounds for Dominating Set in Ball Graphs and for Weighted Dominating Set in Unit-Ball Graphs</title>
      <link>https://arxiv.org/abs/2601.08425</link>
      <description>arXiv:2601.08425v1 Announce Type: cross 
Abstract: Recently it was shown that many classic graph problems -- Independent Set, Dominating Set, Hamiltonian Cycle, and more -- can be solved in subexponential time on unit-ball graphs. More precisely, these problems can be solved in $2^{O(n^{1-1/d})}$ time on unit-ball graphs in $\mathbb R^d$, which is tight under ETH. The result can be generalized to intersection graphs of similarly-sized fat objects. For Independent Set the same running time can be achieved for non-similarly-sized fat objects, and for the weighted version of the problem. We show that such generalizations most likely are not possible for Dominating Set: assuming ETH, we prove that - there is no algorithm with running time $2^{o(n)}$ for Dominating Set on (non-unit) ball graphs in $\mathbb R^3$; - there is no algorithm with running time $2^{o(n)}$ for Weighted Dominating Set on unit-ball graphs in $\mathbb R^3$; - there is no algorithm with running time $2^{o(n)}$ for Dominating Set, Connected Dominating Set, or Steiner Tree on intersections graphs of arbitrary convex (but non-constant-complexity) objects in the plane.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08425v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-030-42071-0_5</arxiv:DOI>
      <arxiv:journal_reference>In: Fomin, F.V., Kratsch, S., van Leeuwen, E.J. (eds) Treewidth, Kernels, and Algorithms (2020). Lecture Notes in Computer Science, vol 12160. Springer, Cham</arxiv:journal_reference>
      <dc:creator>Mark de Berg, S\'andor Kisfaludi-Bak</dc:creator>
    </item>
    <item>
      <title>How Hard Is It to Rig a Tournament When Few Players Can Beat or Be Beaten by the Favorite?</title>
      <link>https://arxiv.org/abs/2601.08530</link>
      <description>arXiv:2601.08530v1 Announce Type: cross 
Abstract: In knockout tournaments, players compete in successive rounds, with losers eliminated and winners advancing until a single champion remains. Given a tournament digraph $D$, which encodes the outcomes of all possible matches, and a designated player $v^* \in V(D)$, the \textsc{Tournament Fixing} problem (TFP) asks whether the tournament can be scheduled in a way that guarantees $v^*$ emerges as the winner. TFP is known to be NP-hard, but is fixed-parameter tractable (FPT) when parameterized by structural measures such as the feedback arc set (fas) or feedback vertex set (fvs) number of the tournament digraph. In this paper, we introduce and study two new structural parameters: the number of players who can defeat $v^*$ (i.e., the in-degree of $v^*$, denoted by $k$) and the number of players that $v^*$ can defeat (i.e., the out-degree of $v^*$, denoted by $\ell$).
  A natural question is that: can TFP be efficiently solved when $k$ or $\ell$ is small? We answer this question affirmatively by showing that TFP is FPT when parameterized by either the in-degree or out-degree of $v^*$. Our algorithm for the in-degree parameterization is particularly involved and technically intricate. Notably, the in-degree $k$ can remain small even when other structural parameters, such as fas or fvs, are large. Hence, our results offer a new perspective and significantly broaden the parameterized algorithmic understanding of the \textsc{Tournament Fixing} problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08530v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhonghao Wang, Junqiang Peng, Yuxi Liu, Mingyu Xiao</dc:creator>
    </item>
    <item>
      <title>Optimal Extended Formulations from Optimal Dynamic Programming Algorithms</title>
      <link>https://arxiv.org/abs/2601.06947</link>
      <description>arXiv:2601.06947v2 Announce Type: replace 
Abstract: Vertex Subset Problems (VSPs) are a class of combinatorial optimization problems on graphs where the goal is to find a subset of vertices satisfying a predefined condition. Two prominent approaches for solving VSPs are dynamic programming over tree-like structures, such as tree decompositions or clique decompositions, and linear programming. In this work, we establish a sharp connection between both approaches by showing that if a vertex-subset problem $\Pi$ admits a solution-preserving dynamic programming algorithm that produces tables of size at most $\alpha(k,n)$ when processing a tree decomposition of width at most $k$ of an $n$-vertex graph $G$, then the polytope $P_{\Pi}(G)$ defined as the convex-hull of solutions of $\Pi$ in $G$ has extension complexity at most $O(\alpha(k,n)\cdot n)$. Additionally, this upper bound is optimal under the exponential time hypothesis (ETH).
  On the one hand, our results imply that ETH-optimal solution-preserving dynamic programming algorithms for combinatorial problems yield optimal-size parameterized extended formulations for the solution polytopes associated with instances of these problems. On the other hand, unconditional lower bounds obtained in the realm of the theory of extended formulations yield unconditional lower bounds on the table complexity of solution-preserving dynamic programming algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06947v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mateus de Oliveira Oliveira, Wim Van den Broeck</dc:creator>
    </item>
    <item>
      <title>A refined graph container lemma and applications to the hard-core model on bipartite expanders</title>
      <link>https://arxiv.org/abs/2411.03393</link>
      <description>arXiv:2411.03393v3 Announce Type: replace-cross 
Abstract: We establish a refined version of a graph container lemma due to Galvin and discuss several applications related to the hard-core model on bipartite expander graphs. Given a graph $G$ and $\lambda&gt;0$, the hard-core model on $G$ at activity $\lambda$ is the probability distribution $\mu_{G,\lambda}$ on independent sets in $G$ given by $\mu_{G,\lambda}(I)\propto \lambda^{|I|}$. As one of our main applications, we show that the hard-core model at activity $\lambda$ on the hypercube $Q_d$ exhibits a `structured phase' for $\lambda= \Omega( \log^2 d/d^{1/2})$ in the following sense: in a typical sample from $\mu_{Q_d,\lambda}$, most vertices are contained in one side of the bipartition of $Q_d$. This improves upon a result of Galvin which establishes the same for $\lambda=\Omega(\log d/ d^{1/3})$. As another application, we establish a fully polynomial-time approximation scheme (FPTAS) for the hard-core model on a $d$-regular bipartite $\alpha$-expander, with $\alpha&gt;0$ fixed, when $\lambda= \Omega( \log^2 d/d^{1/2})$. This improves upon the bound $\lambda=\Omega(\log d/ d^{1/4})$ due to the first author, Perkins and Potukuchi. We discuss similar improvements to results of Galvin-Tetali, Balogh-Garcia-Li and Kronenberg-Spinka.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03393v3</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1002/rsa.70041</arxiv:DOI>
      <arxiv:journal_reference>Random Structures &amp; Algorithms 68 (2026): e70041</arxiv:journal_reference>
      <dc:creator>Matthew Jenssen, Alexandru Malekshahian, Jinyoung Park</dc:creator>
    </item>
    <item>
      <title>The Conflict Graph Design: Estimating Causal Effects under Arbitrary Neighborhood Interference</title>
      <link>https://arxiv.org/abs/2411.10908</link>
      <description>arXiv:2411.10908v3 Announce Type: replace-cross 
Abstract: A fundamental problem in network experiments is selecting an appropriate experimental design in order to precisely estimate a given causal effect of interest. In this work, we propose the Conflict Graph Design, a general approach for constructing experiment designs under network interference with the goal of precisely estimating a pre-specified causal effect. A central aspect of our approach is the notion of a conflict graph, which captures the fundamental unobservability associated with the causal effect and the underlying network. In order to estimate effects, we propose a modified Horvitz--Thompson estimator. We show that its variance under the Conflict Graph Design is bounded as $O(\lambda(H) / n )$, where $\lambda(H)$ is the largest eigenvalue of the adjacency matrix of the conflict graph. These rates depend on both the underlying network and the particular causal effect under investigation. Not only does this yield the best known rates of estimation for several well-studied causal effects (e.g. the global and direct effects) but it also provides new methods for effects which have received less attention from the perspective of experiment design (e.g. spill-over effects). Finally, we construct conservative variance estimators which facilitate asymptotically valid confidence intervals for the causal effect of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10908v3</guid>
      <category>stat.ME</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vardis Kandiros, Charilaos Pipis, Constantinos Daskalakis, Christopher Harshaw</dc:creator>
    </item>
    <item>
      <title>Optimal Deterministic Rendezvous in Labeled Lines</title>
      <link>https://arxiv.org/abs/2505.04564</link>
      <description>arXiv:2505.04564v2 Announce Type: replace-cross 
Abstract: In a rendezvous task, some mobile agents dispersed in a network have to gather at an arbitrary common site. We consider the rendezvous problem on the infinite labeled line, with $2$ agents, without communication, and a synchronous notion of time. Each node on the line is labeled with a unique positive integer. The initial distance between the agents is denoted by $D$. Time is divided into rounds and measured from the moment an agent first wakes up. We denote by $\tau$ the delay between the two agents' wake up times. If awake in a given round $T$, an agent at a node $v$ has three options: stay at the node $v$, take port $0$, or take port $1$. If it decides to stay, the agent will still be at node $v$ in round $T+1$. Otherwise, it will be at one of the two neighbors of $v$ on the infinite line, depending on the port it chose. The agents achieve rendezvous in $T$ rounds if they are at the same node in round $T$. We aim for a deterministic algorithm for this problem.
  The problem was recently considered by Miller and Pelc [Distributed Computing 2025]. With $\ell_{\max}$ the largest label of the two starting nodes, they showed that no algorithm can guarantee rendezvous in $o(D \log^* \ell_{\max})$ rounds. The lower bound follows from a connection with the LOCAL model of distributed computing, and holds even if the agents are guaranteed simultaneous wake-up ($\tau = 0$) and are told their initial distance $D$. Miller and Pelc also gave an algorithm of optimal matching complexity $O(D \log^* \ell_{\max})$ when the agents know $D$, but only obtained the higher bound of $O(D^2 (\log^* \ell_{\max})^3)$ when $D$ is unknown to the agents.
  We improve this complexity to a tight $O(D \log^* \ell_{\max})$. In fact, our algorithm achieves rendezvous in $O(D \log^* \ell_{\min})$ rounds, where $\ell_{\min}$ is the smallest label within distance $O(D)$ of the two starting positions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04564v2</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.STACS.2026.62 10.1145/3732772.3733537</arxiv:DOI>
      <dc:creator>Yann Bourreau, Ananth Narayanan, Alexandre Nolin</dc:creator>
    </item>
    <item>
      <title>Subgraph Isomorphism: Prolog vs. Conventional</title>
      <link>https://arxiv.org/abs/2511.13600</link>
      <description>arXiv:2511.13600v2 Announce Type: replace-cross 
Abstract: Subgraph Isomorphism uses a small graph as a pattern to identify within a larger graph a set of vertices that have matching edges. This paper addresses a logic program written in Prolog for a specific relatively complex graph pattern for which multiple conventional implementations (including parallel) exist. The goal is to understand the complexity differences between programming logically and programming conventionally. Discussion includes the process of converting the graph pattern into logic statements in Prolog, and the resulting characteristics as the size of the graph increased. The analysis shows that using a logic paradigm is an efficient way to attack complex graph problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13600v2</guid>
      <category>cs.LO</category>
      <category>cs.DS</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Claire Y. Yin, Peter M. Kogge</dc:creator>
    </item>
    <item>
      <title>The Mixed Birth-death/death-Birth Moran Process</title>
      <link>https://arxiv.org/abs/2511.18252</link>
      <description>arXiv:2511.18252v3 Announce Type: replace-cross 
Abstract: We study evolutionary dynamics on graphs in which each step consists of one birth and one death, also known as the Moran processes. There are two types of individuals: residents with fitness $1$ and mutants with fitness $r$. Two standard update rules are used in the literature. In Birth-death (Bd), a vertex is chosen to reproduce proportional to fitness, and one of its neighbors is selected uniformly at random to be replaced by the offspring. In death-Birth (dB), a vertex is chosen uniformly to die, and then one of its neighbors is chosen, proportional to fitness, to place an offspring into the vacancy. We formalize and study a unified model, the $\lambda$-mixed Moran process, in which each step is independently a Bd step with probability $\lambda \in [0,1]$ and a dB step otherwise. We analyze this mixed process for undirected, connected graphs. As an interesting special case, we show at $\lambda=1/2$, for any graph that the fixation probability when $r=1$ with a single mutant initially on the graph is exactly $1/n$, and also at $\lambda=1/2$ that the absorption time for any $r$ is $O_r(n^4)$. We also show results for graphs that are "almost regular," in a manner defined in the paper. We use this to show that for suitable random graphs from $G \sim G(n,p)$ and fixed $r&gt;1$, with high probability over the choice of graph, the absorption time is $O_r(n^4)$, the fixation probability is $\Omega_r(n^{-2})$, and we can approximate the fixation probability in polynomial time. Another special case is when the graph has only two distinct degree values $\{d_1, d_2\}$ with $d_1 \leq d_2$. For those graphs, we give exact formulas for fixation probabilities when $r = 1$ and any $\lambda$, and establish an absorption time of $O_r(n^4 \alpha^4)$ for all $\lambda$, where $\alpha = d_2 / d_1$. We also provide explicit formulas for the star and cycle under any $r$ or $\lambda$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18252v3</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David A. Brewster, Yichen Huang, Michael Mitzenmacher, Martin A. Nowak</dc:creator>
    </item>
  </channel>
</rss>
