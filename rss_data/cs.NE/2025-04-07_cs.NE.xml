<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Apr 2025 03:06:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Improved Compact Genetic Algorithms with Efficient Caching</title>
      <link>https://arxiv.org/abs/2504.02972</link>
      <description>arXiv:2504.02972v1 Announce Type: new 
Abstract: Compact Genetic Algorithms (cGAs) are condensed variants of classical Genetic Algorithms (GAs) that use a probability vector representation of the population instead of the complete population. cGAs have been shown to significantly reduce the number of function evaluations required while producing outcomes similar to those of classical GAs. However, cGAs have a tendency to repeatedly generate the same chromosomes as they approach convergence, resulting in unnecessary evaluations of identical chromosomes. This article introduces the concept of caching in cGAs as a means of avoiding redundant evaluations of the same chromosomes. Our proposed approach operates equivalently to cGAs, but enhances the algorithm's time efficiency by reducing the number of function evaluations. We also present a data structure for efficient cache maintenance to ensure low overhead. The proposed caching approach has an asymptotically constant time complexity on average. The proposed method further generalizes the caching mechanism with higher selection pressure for elitism-based cGAs. We conduct a rigorous analysis based on experiments on benchmark optimization problems using two well-known cache replacement strategies. The results demonstrate that caching significantly reduces the number of function evaluations required while maintaining the same level of performance accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02972v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prasanta Dutta, Anirban Mukhopadhyay</dc:creator>
    </item>
    <item>
      <title>Low Rank Factorizations are Indirect Encodings for Deep Neuroevolution</title>
      <link>https://arxiv.org/abs/2504.03037</link>
      <description>arXiv:2504.03037v1 Announce Type: new 
Abstract: Deep neuroevolution is a highly scalable alternative to reinforcement learning due to its unique ability to encode network updates in a small number of bytes. Recent insights from traditional deep learning indicate high-dimensional models possess intrinsic, low-rank structure. In this work, we introduce low-rank, factorized neuroevolution: an indirect encoding through which we can search a small space of low-rank factors that enforce underlying structure across a network's weights. We compare our approach with non-factorized networks of similar and smaller size to understand how much performance can be attributed to the smaller search space. We evaluate our method on a language modeling task using transformers, as well as continuous and discrete vision-based reinforcement learning tasks. Our study shows that low-rank, factorized neuroevolution outperforms or is competitive with non-factorized neuroevolution, performing notably well on language modeling. Our results also suggest deleterious factorized mutations have a stronger negative impact on performance than deleterious non-factorized mutations, which significantly reduces the runtime on environments with early termination for bad performers. More broadly, these results show how we can use insights from backpropgation-based methods to enhance neuroevolution</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03037v1</guid>
      <category>cs.NE</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jack Garbus, Jordan Pollack</dc:creator>
    </item>
    <item>
      <title>Heterogeneous Resource Allocation for Ensuring End-to-End Quality of Service in Multi-hop Integrated Access and Backhaul Network</title>
      <link>https://arxiv.org/abs/2504.03576</link>
      <description>arXiv:2504.03576v1 Announce Type: new 
Abstract: Faced with increasing network traffic demands, cell dense deployment is one of significant means to utilize spectrum resources efficiently to improve network capacity. Multi-hop integrated access and backhaul (IAB) architectures have emerged as a cost-effective solution for network densification. Meanwhile, dynamic time division duplex (D-TDD) is a promising solution to adapt to highly dynamic scenarios with asymmetric uplink and downlink traffic. Thus, dynamic resource allocation between backhaul and access links and high spectral efficiency under ensuring reliable transmission are two key objectives of IAB research. However, due to huge solution space, there are some challenges in multi-hop IAB with D-TDD if only an integrated optimization problem (IOP) is considered. To handle these challenges, we decompose the IOP into sub-problems to reduce the solution space. To tackle these sub-problems, we formulate them separately as the non-cooperative games and design the corresponding utility functions to guarantee the existence of Nash equilibrium solutions. Also, to achieve the system-wide solution, we propose a single-leader heterogeneous multi-follower Stackelberg-game-based resource allocation scheme, which can combine the solving results of all the sub-problems to get the IOP approximate solution. Simulation results show that the proposed scheme can improve throughput performance while meeting spectrum energy efficiency constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03576v1</guid>
      <category>cs.NE</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuaifeng Zhang</dc:creator>
    </item>
    <item>
      <title>On-line Policy Improvement using Monte-Carlo Search</title>
      <link>https://arxiv.org/abs/2501.05407</link>
      <description>arXiv:2501.05407v1 Announce Type: cross 
Abstract: We present a Monte-Carlo simulation algorithm for real-time policy improvement of an adaptive controller. In the Monte-Carlo simulation, the long-term expected reward of each possible action is statistically measured, using the initial policy to make decisions in each step of the simulation. The action maximizing the measured expected reward is then taken, resulting in an improved policy. Our algorithm is easily parallelizable and has been implemented on the IBM SP1 and SP2 parallel-RISC supercomputers.
  We have obtained promising initial results in applying this algorithm to the domain of backgammon. Results are reported for a wide variety of initial policies, ranging from a random policy to TD-Gammon, an extremely strong multi-layer neural network. In each case, the Monte-Carlo algorithm gives a substantial reduction, by as much as a factor of 5 or more, in the error rate of the base players. The algorithm is also potentially useful in many other adaptive control applications in which it is possible to simulate the environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05407v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Advances in Neural Information Processing 9 (NIPS 1996 Proceedings published 1997)</arxiv:journal_reference>
      <dc:creator>Gerald Tesauro, Gregory R. Galperin</dc:creator>
    </item>
    <item>
      <title>Explainable Dual-Attention Tabular Transformer for Soil Electrical Resistivity Prediction: A Decision Support Framework for High-Voltage Substation Construction</title>
      <link>https://arxiv.org/abs/2504.02834</link>
      <description>arXiv:2504.02834v1 Announce Type: cross 
Abstract: This research introduces a novel dual-attention transformer architecture for predicting soil electrical resistivity, a critical parameter for high-voltage substation construction. Our model employs attention mechanisms operating across both features and data batches, enhanced by feature embedding layers that project inputs into higher-dimensional spaces. We implements Particle Swarm Optimization for hyperparameter tuning, systematically optimizing embedding dimensions, attention heads, and neural network architecture. The proposed architecture achieves superior predictive performance (Mean Absolute Percentage Error: 0.63%) compared to recent state of the art models for tabular data. Crucially, our model maintains explainability through SHapley Additive exPlanations value analysis, revealing that fine particle content and dry density are the most influential parameters affecting soil resistivity. We developes a web-based application implementing this model to provide engineers with an accessible decision support framework that bridges geotechnical and electrical engineering requirements for the Electricity Generating Authority of Thailand. This integrated approach satisfies both structural stability and electrical safety standards, improving construction efficiency and safety compliance in high-voltage infrastructure implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02834v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Warat Kongkitkul, Sompote Youwai, Warut Sakulpojworachai</dc:creator>
    </item>
    <item>
      <title>Building functional and mechanistic models of cortical computation based on canonical cell type connectivity</title>
      <link>https://arxiv.org/abs/2504.03031</link>
      <description>arXiv:2504.03031v1 Announce Type: cross 
Abstract: Neuronal circuits of the cerebral cortex are the structural basis of mammalian cognition. The same qualitative components and connectivity motifs are repeated across functionally specialized cortical areas and mammalian species, suggesting a single underlying algorithmic motif. Here, we propose a perspective on current knowledge of the cortical structure, from which we extract two core principles for computational modeling. The first principle is that cortical cell types fulfill distinct computational roles. The second principle is that cortical connectivity can be efficiently characterized by only a few canonical blueprints of connectivity between cell types. Starting with these two foundational principles, we outline a general framework for building functional and mechanistic models of cortical circuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03031v1</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arno Granier, Katharina A Wilmes, Mihai A Petrovici, Walter Senn</dc:creator>
    </item>
    <item>
      <title>Overcoming Deceptiveness in Fitness Optimization with Unsupervised Quality-Diversity</title>
      <link>https://arxiv.org/abs/2504.01915</link>
      <description>arXiv:2504.01915v2 Announce Type: replace 
Abstract: Policy optimization seeks the best solution to a control problem according to an objective or fitness function, serving as a fundamental field of engineering and research with applications in robotics. Traditional optimization methods like reinforcement learning and evolutionary algorithms struggle with deceptive fitness landscapes, where following immediate improvements leads to suboptimal solutions. Quality-diversity (QD) algorithms offer a promising approach by maintaining diverse intermediate solutions as stepping stones for escaping local optima. However, QD algorithms require domain expertise to define hand-crafted features, limiting their applicability where characterizing solution diversity remains unclear. In this paper, we show that unsupervised QD algorithms - specifically the AURORA framework, which learns features from sensory data - efficiently solve deceptive optimization problems without domain expertise. By enhancing AURORA with contrastive learning and periodic extinction events, we propose AURORA-XCon, which outperforms all traditional optimization baselines and matches, in some cases even improving by up to 34%, the best QD baseline with domain-specific hand-crafted features. This work establishes a novel application of unsupervised QD algorithms, shifting their focus from discovering novel solutions toward traditional optimization and expanding their potential to domains where defining feature spaces poses challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01915v2</guid>
      <category>cs.NE</category>
      <category>cs.RO</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3712256.3726314</arxiv:DOI>
      <dc:creator>Lisa Coiffard, Paul Templier, Antoine Cully</dc:creator>
    </item>
    <item>
      <title>EVOS: Efficient Implicit Neural Training via EVOlutionary Selector</title>
      <link>https://arxiv.org/abs/2412.10153</link>
      <description>arXiv:2412.10153v3 Announce Type: replace-cross 
Abstract: We propose EVOlutionary Selector (EVOS), an efficient training paradigm for accelerating Implicit Neural Representation (INR). Unlike conventional INR training that feeds all samples through the neural network in each iteration, our approach restricts training to strategically selected points, reducing computational overhead by eliminating redundant forward passes. Specifically, we treat each sample as an individual in an evolutionary process, where only those fittest ones survive and merit inclusion in training, adaptively evolving with the neural network dynamics. While this is conceptually similar to Evolutionary Algorithms, their distinct objectives (selection for acceleration vs. iterative solution optimization) require a fundamental redefinition of evolutionary mechanisms for our context. In response, we design sparse fitness evaluation, frequency-guided crossover, and augmented unbiased mutation to comprise EVOS. These components respectively guide sample selection with reduced computational cost, enhance performance through frequency-domain balance, and mitigate selection bias from cached evaluation. Extensive experiments demonstrate that our method achieves approximately 48%-66% reduction in training time while ensuring superior convergence without additional cost, establishing state-of-the-art acceleration among recent sampling-based strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10153v3</guid>
      <category>cs.CV</category>
      <category>cs.MM</category>
      <category>cs.NE</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weixiang Zhang, Shuzhao Xie, Chengwei Ren, Siyi Xie, Chen Tang, Shijia Ge, Mingzi Wang, Zhi Wang</dc:creator>
    </item>
    <item>
      <title>Evolution 6.0: Evolving Robotic Capabilities Through Generative Design</title>
      <link>https://arxiv.org/abs/2502.17034</link>
      <description>arXiv:2502.17034v4 Announce Type: replace-cross 
Abstract: We propose a new concept, Evolution 6.0, which represents the evolution of robotics driven by Generative AI. When a robot lacks the necessary tools to accomplish a task requested by a human, it autonomously designs the required instruments and learns how to use them to achieve the goal. Evolution 6.0 is an autonomous robotic system powered by Vision-Language Models (VLMs), Vision-Language Action (VLA) models, and Text-to-3D generative models for tool design and task execution. The system comprises two key modules: the Tool Generation Module, which fabricates task-specific tools from visual and textual data, and the Action Generation Module, which converts natural language instructions into robotic actions. It integrates QwenVLM for environmental understanding, OpenVLA for task execution, and Llama-Mesh for 3D tool generation. Evaluation results demonstrate a 90% success rate for tool generation with a 10-second inference time, and action generation achieving 83.5% in physical and visual generalization, 70% in motion generalization, and 37% in semantic generalization. Future improvements will focus on bimanual manipulation, expanded task capabilities, and enhanced environmental interpretation to improve real-world adaptability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17034v4</guid>
      <category>cs.RO</category>
      <category>cs.NE</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Muhammad Haris Khan, Artyom Myshlyaev, Artem Lykov, Miguel Altamirano Cabrera, Dzmitry Tsetserukou</dc:creator>
    </item>
  </channel>
</rss>
