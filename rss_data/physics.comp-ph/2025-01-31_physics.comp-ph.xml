<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Jan 2025 05:00:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Ultrafast Inverse Design of Electromagnetic Devices</title>
      <link>https://arxiv.org/abs/2501.18054</link>
      <description>arXiv:2501.18054v1 Announce Type: new 
Abstract: This paper introduces the Precomputed Numerical Green Function (PNGF) method, a new approach for rapid inverse design of electromagnetic devices. The static components of the design are incorporated into a numerical Green function obtained from a single fully parallelized precomputation step, reducing the cost of evaluating candidate designs during optimization to only being proportional to the size of the region under modification. When used with the direct binary search optimization algorithm, a low-rank update technique is leveraged to further decrease the iteration time to seconds without approximations or compromises in accuracy. The total runtime for an inverse design is reduced by several orders of magnitude compared to using conventional Maxwell solvers due to the linear time complexity of the method, attaining speedups of up to 700x for the design examples considered and lowering the process from multiple days to weeks down to less than an hour. The performance and flexibility of the approach are highlighted with design studies, including experimental results, on an ultrawideband 30GHz substrate antenna with 50% fractional bandwidth, a 6GHz switched beam antenna steerable between angles 90{\deg} apart, and a broadband, ultra-short-length microstrip to substrate-integrated waveguide transition. The approach stands to reshape inverse design in electromagnetics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18054v1</guid>
      <category>physics.comp-ph</category>
      <category>physics.app-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yifei Zheng, Mohamed Elsawaf, Jui-Hung Sun, Ho-Chun Lin, Chia-Wei Hsu, Constantine Sideris</dc:creator>
    </item>
    <item>
      <title>High order-accurate solution of scattering integral equations with unbounded solutions at corners</title>
      <link>https://arxiv.org/abs/2501.18065</link>
      <description>arXiv:2501.18065v1 Announce Type: cross 
Abstract: Although high-order Maxwell integral equation solvers provide significant advantages in terms of speed and accuracy over corresponding low-order integral methods, their performance significantly degrades in presence of non-smooth geometries--owing to field enhancement and singularities that arise at sharp edges and corners which, if left untreated, give rise to significant accuracy losses. The problem is particularly challenging in cases in which the "density" (i.e., the solution of the integral equation) tends to infinity at corners and edges--a difficulty that can be bypassed for 2D configurations, but which is unavoidable in 3D Maxwell integral formulations, wherein the component tangential to an edge of the electrical-current integral density vector tends to infinity at the edge. In order to tackle the problem this paper restricts attention to the simplest context in which the unbounded-density difficulty arises, namely, integral formulations in 2D space whose integral density blows up at corners; the strategies proposed, however, generalize directly to the 3D context. The novel methodologies presented in this paper yield high-order convergence for such challenging equations and achieve highly accurate solutions (even near edges and corners) without requiring a priori analysis of the geometry or use of singular bases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18065v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Constantine Sideris, Davit Aslanyan, Oscar P. Bruno</dc:creator>
    </item>
    <item>
      <title>A tomographic interpretation of structure-property relations for materials discovery</title>
      <link>https://arxiv.org/abs/2501.18163</link>
      <description>arXiv:2501.18163v1 Announce Type: cross 
Abstract: Recent advancements in machine learning (ML) for materials have demonstrated that "simple" materials representations (e.g., the chemical formula alone without structural information) can sometimes achieve competitive property prediction performance in common-tasks. Our physics-based intuition would suggest that such representations are "incomplete", which indicates a gap in our understanding. This work proposes a tomographic interpretation of structure-property relations of materials to bridge that gap by defining what is a material representation, material properties, the material and the relationships between these three concepts using ideas from information theory. We verify this framework performing an exhaustive comparison of property-augmented representations on a range of material's property prediction objectives, providing insight into how different properties can encode complementary information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18163v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raul Ortega-Ochoa, Al\'an Aspuru-Guzik, Tejs Vegge, Tonio Buonassisi</dc:creator>
    </item>
    <item>
      <title>A photonic integrated processor for multiple parallel computational tasks</title>
      <link>https://arxiv.org/abs/2501.18186</link>
      <description>arXiv:2501.18186v1 Announce Type: cross 
Abstract: Optical networks with parallel processing capabilities are significant in advancing high-speed data computing and large-scale data processing by providing ultra-width computational bandwidth. In this paper, we present a photonic integrated processor that can be segmented into multiple functional blocks, to enable compact and reconfigurable matrix operations for multiple parallel computational tasks. Fabricated on a silicon-on-insulator (SOI) platform, the photonic integrated processor supports fully reconfigurable optical matrix operations. By segmenting the chip into multiple functional blocks, it enables optical matrix operations of various sizes, offering great flexibility and scalability for parallel computational tasks. Specifically, we utilize this processor to perform optical convolution operations with various kernel sizes, including reconfigurable three-channel 1x1 convolution kernels and 2x2 real-valued convolution kernels, implemented within distinct segmented blocks of the chip. The multichannel optical 1x1 convolution operation is experimentally validated by using the deep residual U-Net, demonstrating precise segmentation of pneumonia lesion region in lung CT images. In addition, the capability of the 2x2 optical convolution operation is also experimentally validated by constructing an optical convolution layer and integrating an electrical fully connected layer, achieving ten-class classification of handwritten digit images. The photonic integrated processor features high scalability and robust parallel computational capability, positioning it a promising candidate for applications in optical neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18186v1</guid>
      <category>physics.optics</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sheng Dong, Ruiqi Zheng, Huan Rao, Junyi Zhang, Jingxu Chen, Chencheng Zeng, Yu Huang, Jiejun Zhang, Jianping Yao</dc:creator>
    </item>
    <item>
      <title>Neural Network Modeling of Microstructure Complexity Using Digital Libraries</title>
      <link>https://arxiv.org/abs/2501.18189</link>
      <description>arXiv:2501.18189v1 Announce Type: cross 
Abstract: Microstructure evolution in matter is often modeled numerically using field or level-set solvers, mirroring the dual representation of spatiotemporal complexity in terms of pixel or voxel data, and geometrical forms in vector graphics. Motivated by this analog, as well as the structural and event-driven nature of artificial and spiking neural networks, respectively, we evaluate their performance in learning and predicting fatigue crack growth and Turing pattern development. Predictions are made based on digital libraries constructed from computer simulations, which can be replaced by experimental data to lift the mathematical overconstraints of physics. Our assessment suggests that the leaky integrate-and-fire neuron model offers superior predictive accuracy with fewer parameters and less memory usage, alleviating the accuracy-cost tradeoff in contrast to the common practices in computer vision tasks. Examination of network architectures shows that these benefits arise from its reduced weight range and sparser connections. The study highlights the capability of event-driven models in tackling problems with evolutionary bulk-phase and interface behaviors using the digital library approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18189v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.CE</category>
      <category>nlin.PS</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingjie Zhao, Zhiping Xu</dc:creator>
    </item>
    <item>
      <title>Refining interface stress measurement in nanomultilayers through layer corrugation and interface roughness corrections</title>
      <link>https://arxiv.org/abs/2501.18247</link>
      <description>arXiv:2501.18247v1 Announce Type: cross 
Abstract: We introduce new models that incorporate layer corrugation and interface roughness into standard approaches for measuring interface stress in nanomultilayers (NMLs). Applied to Cu/W NMLs, these models show that ignoring such features can inflate measured interface stress by up to 0.4 J/m^2. However, corrugation and roughness alone cannot account for the extreme stresses reported, suggesting that atomic-scale phenomena (e.g., intermixing and metastable phase formation at the interfaces) dominate. These findings highlight the importance of balancing bilayer counts and thickness-to-roughness ratios for reliable stress quantification, providing a practical pathway to designing and characterizing advanced nanocomposite coatings with improved accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18247v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Hu, Aleksandr Druzhinin, Claudia Cancellieri, Vladyslav Turlo</dc:creator>
    </item>
    <item>
      <title>Tensor network state methods and quantum information theory for strongly correlated molecular systems</title>
      <link>https://arxiv.org/abs/2501.18263</link>
      <description>arXiv:2501.18263v1 Announce Type: cross 
Abstract: A brief pedagogical overview of recent advances in tensor network state methods are presented that have the potential to broaden their scope of application radically for strongly correlated molecular systems. These include global fermionic mode optimization, i.e., a general approach to find an optimal matrix product state (MPS) parametrization of a quantum many-body wave function with the minimum number of parameters for a given error margin, the restricted active space DMRG-RAS-X method, multi-orbital correlations and entanglement, developments on hybrid CPU-multiGPU parallelization, and an efficient treatment of non-Abelian symmetries on high-performance computing (HPC) infrastructures. Scaling analysis on NVIDIA DGX-A100 platform is also presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18263v1</guid>
      <category>cond-mat.str-el</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikl\'os Antal Werner, Andor Menczer, \"Ors Legeza</dc:creator>
    </item>
    <item>
      <title>Implications of the multi-minima character of molecular crystal phases onto the free energy</title>
      <link>https://arxiv.org/abs/2501.18372</link>
      <description>arXiv:2501.18372v1 Announce Type: cross 
Abstract: In recent years, significant advancements in computational methods have dramatically enhanced the precision in determining the energetic ranking of different phases of molecular crystals. The developments mainly focused on providing accurate dispersion corrected exchange correlation functionals and methods for describing the vibrational entropy contributions to the free energy at finite temperatures. Several molecular crystals phases were recently found to have of multi-minima character. For our investigations we highlight the multi-minima character in the example of the molecular crystal consisting of N-(4-Methylbenzylidene)-4-methylalanine. We explore its potential energy landscape on the full DFT level or with a machine learned potential that was fitted to DFT data. We calculate not only many local minima but also exact barriers along transformation pathways to demonstrate the multi-minima character of our system. Furthermore, we present a framework, based on the quantum superposition method, that includes both configurational and vibrational entropy. As an example, we show for our system that the transition temperature between two of its phases is afflicted by an error of about 200 K if the multi-minima character is not taken into account. This indicates that it is absolutely essential to consider configurational entropy to obtain reliable finite temperature free energy rankings for complex molecular crystals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18372v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Krummenacher, Martin Sommer-J\"orgensen, Moritz Gubler, Jonas A. Finkler, Ehsan Rahmatizad Khajehpasha, Giuseppe Fisicaro, Stefan Goedecker</dc:creator>
    </item>
    <item>
      <title>Nonequilibrium friction and free energy estimates for kinetic coarse-graining -- Driven particles in responsive media</title>
      <link>https://arxiv.org/abs/2501.18484</link>
      <description>arXiv:2501.18484v1 Announce Type: cross 
Abstract: Predicting the molecular friction and energy landscapes under nonequilibrium conditions is key to coarse-graining the dynamics of selective solute transport through complex, fluctuating and responsive media, e.g., polymeric materials such as hydrogels, cellular membranes or ion channels. The analysis of equilibrium ensembles already allows such a coarse-graining for very mild nonequilibrium conditions. Yet in the presence of stronger external driving and/or inhomogeneous setups, the transport process is governed apart from a potential of mean force also by a nontrivial position- and velocity-dependent friction. It is therefore important to find suitable and efficient methods to estimate the mean force and the friction landscape, which then can be used in a low-dimensional, coarse-grained Langevin framework to predict the system's transport properties and timescales. In this work, we evaluate different coarse-graining approaches based on constant-velocity constraint simulations for generating such estimates using two model systems, which are a 1D responsive barrier as a minimalistic model and a single tracer driven through a 3D bead-spring polymer membrane as a more sophisticated problem. Finally, we demonstrate that the estimates from 3D constant-velocity simulations yield the correct velocity-dependent friction, which can be directly utilized for coarse-grained (1D) Langevin simulations with constant external driving forces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18484v1</guid>
      <category>cond-mat.soft</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Milster, Joachim Dzubiella, Gerhard Stock, Steffen Wolf</dc:creator>
    </item>
    <item>
      <title>Digital Quantum Simulations of the Non-Resonant Open Tavis-Cummings Model</title>
      <link>https://arxiv.org/abs/2501.18522</link>
      <description>arXiv:2501.18522v1 Announce Type: cross 
Abstract: The open Tavis-Cummings model consists of $N$ quantum emitters interacting with a common cavity mode, accounts for losses and decoherence, and is frequently explored for quantum information processing and designing quantum devices. As $N$ increases, it becomes harder to simulate the open Tavis-Cummings model using traditional methods. To address this problem, we implement two quantum algorithms for simulating the dynamics of this model in the inhomogenous, non-resonant regime, with up to three excitations in the cavity. We show that the implemented algorithms have gate complexities that scale polynomially, as $O(N^2)$ and $O(N^3)$. One of these algorithms is the sampling-based wave matrix Lindbladization algorithm, for which we propose two protocols to implement its system-independent fixed interaction, resolving key open questions of [Patel and Wilde, Open Sys. &amp; Info. Dyn., 30:2350014 (2023)]. Furthermore, we benchmark our results against a classical differential equation solver and demonstrate the ability to simulate classically intractable systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18522v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>physics.comp-ph</category>
      <category>physics.optics</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aidan N. Sims, Dhrumil Patel, Aby Philip, Alex H. Rubin, Rahul Bandyopadhyay, Marina Radulaski, Mark M. Wilde</dc:creator>
    </item>
    <item>
      <title>Freeze-and-release direct optimization method for variational calculations of excited electronic states</title>
      <link>https://arxiv.org/abs/2501.18568</link>
      <description>arXiv:2501.18568v1 Announce Type: cross 
Abstract: Time-independent, orbital-optimized density functional approaches outperform time-dependent density functional theory (TDDFT) in calculations of excited electronic states involving a large rearrangement of the electron density, such as charge transfer excitations. However, optimizing orbitals for excited states remains challenging, as the latter typically correspond to saddle points on the electronic energy surface. A simple and robust strategy for variational orbital optimization of excited states is presented. The approach involves two steps: (1) a constrained energy minimization, where a subset of orbitals changed by the excitation are frozen, followed by (2) a fully unconstrained saddle point optimization. The constrained minimization step makes it possible to identify the electronic degrees of freedom along which the energy needs to be maximized, preventing variational collapse. Both steps of this freeze-and-release strategy are carried out using direct optimization algorithms with a computational scaling comparable to ground state calculations. Numerical tests using a semilocal functional are performed on intramolecular charge transfer states of organic molecules and intermolecular charge transfer states of molecular dimers. It is shown that the freeze-and-release direct optimization (FR-DO) approach can successfully converge challenging charge transfer states, overcoming limitations of conventional algorithms based on the maximum overlap method, which either collapse to lower energy, charge-delocalized solutions or fail to converge. While FR-DO requires more iterations on average, the overall increase in computational cost is small. For the NH3-F2 dimer, it is found that unlike TDDFT, orbital-optimized calculations reproduce the correct long-range dependency of the energy with respect to the donor-acceptor separation without the need to include exact exchange in the long range.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18568v1</guid>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yorick L. A. Schmerwitz, Elli Selenius, Gianluca Levi</dc:creator>
    </item>
    <item>
      <title>PyMoosh : a comprehensive numerical toolkit for computing the optical properties of multilayered structures</title>
      <link>https://arxiv.org/abs/2309.00654</link>
      <description>arXiv:2309.00654v3 Announce Type: replace 
Abstract: We present PyMoosh, a Python-based simulation library designed to provide a comprehensive set of numerical tools allowing to compute essentially all optical characteristics of multilayered structures, ranging from reflectance and transmittance to guided modes and photovoltaic efficiency. PyMoosh is designed not just for research purposes, but also for use-cases in education. To this end, we have invested significant effort in ensuring user-friendliness and simplicity of the interface. PyMoosh has been developed in line with the principles of Open Science and taking into account the fact that multilayered structures are increasingly being used as a testing ground for optimization and deep learning approaches. We provide in this paper the theoretical basis at the core of PyMoosh, an overview of its capabilities, as well as a comparison between the different numerical methods implemented in terms of speed and stability. We are convinced such a versatile tool will be useful for the community in many ways.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.00654v3</guid>
      <category>physics.comp-ph</category>
      <category>physics.optics</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1364/JOSAB.506175</arxiv:DOI>
      <arxiv:journal_reference>Journal of the Optical Society of America B Vol. 41, Issue 2, pp. A67-A78 (2024)</arxiv:journal_reference>
      <dc:creator>Denis Langevin, Pauline Bennet, Abdourahman Khaireh-Walieh, Peter Wiecha, Olivier Teytaud, Antoine Moreau</dc:creator>
    </item>
    <item>
      <title>Coupling Fluid Plasma and Kinetic Neutral Models using Correlated Monte Carlo Methods</title>
      <link>https://arxiv.org/abs/2407.10936</link>
      <description>arXiv:2407.10936v2 Announce Type: replace-cross 
Abstract: While boundary plasmas in present-day tokamaks generally fall in a fluid regime, neutral species near the boundary often require kinetic models due to long mean-free-paths compared to characteristic spatial scales in the region. Monte-Carlo (MC) methods provide a complete, high-fidelity approach to solving kinetic models, and must be coupled to fluid plasma models to simulate the full plasma-neutrals system. The statistical nature of MC methods, however, prevents the convergence of coupled fluid-kinetic simulations to an exact self-consistent steady-state. Moreover, this forces the use of explicit methods that can suffer from numerical errors and require huge computational resources. Correlated Monte-Carlo (CMC) methods are expected to alleviate these issues but have historically enjoyed only mixed success. Here, a fully implicit method for coupled plasma-neutral systems is demonstrated in 1D using the UEDGE plasma code and a homemade CMC code. In particular, it is shown that ensuring the CMC method is a differentiable function of the background plasma is sufficient to employ a Jacobian-Free Newton-Krylov solver for implicit time steps. The convergence of the implicit coupling method is explored and compared with explicit coupling and uncorrelated methods. It is shown that ensuring differentiability by controlling random seeds in the MC is sufficient to achieve convergence, and that the use of implicit time-stepping methods has the potential for improved stability and runtimes over explicit coupling methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10936v2</guid>
      <category>physics.plasm-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gregory J. Parker, Maxim V. Umansky, Benjamin D. Dudson</dc:creator>
    </item>
    <item>
      <title>Constructing multicomponent cluster expansions with machine-learning and chemical embedding</title>
      <link>https://arxiv.org/abs/2409.06071</link>
      <description>arXiv:2409.06071v2 Announce Type: replace-cross 
Abstract: Cluster expansions are commonly employed as surrogate models to link the electronic structure of an alloy to its finite-temperature properties. Using cluster expansions to model materials with several alloying elements is challenging due to a rapid increase in the number of fitting parameters and training set size. We introduce the embedded cluster expansion (eCE) formalism that enables the parameterization of accurate on-lattice surrogate models for alloys containing several chemical species. The eCE model simultaneously learns a low dimensional embedding of site basis functions along with the weights of an energy model. A prototypical senary alloy comprised of elements in groups 5 and 6 of the periodic table is used to demonstrate that eCE models can accurately reproduce ordering energetics of complex alloys without a significant increase in model complexity. Further, eCE models can leverage similarities between chemical elements to efficiently extrapolate into compositional spaces that are not explicitly included in the training dataset. The eCE formalism presented in this study unlocks the possibility of employing cluster expansion models to study multicomponent alloys containing several alloying elements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06071v2</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yann L. M\"uller, Anirudh Raju Natarajan</dc:creator>
    </item>
    <item>
      <title>An information-matching approach to optimal experimental design and active learning</title>
      <link>https://arxiv.org/abs/2411.02740</link>
      <description>arXiv:2411.02740v2 Announce Type: replace-cross 
Abstract: The efficacy of mathematical models heavily depends on the quality of the training data, yet collecting sufficient data is often expensive and challenging. Many modeling applications require inferring parameters only as a means to predict other quantities of interest (QoI). Because models often contain many unidentifiable (sloppy) parameters, QoIs often depend on a relatively small number of parameter combinations. Therefore, we introduce an information-matching criterion based on the Fisher Information Matrix to select the most informative training data from a candidate pool. This method ensures that the selected data contain sufficient information to learn only those parameters that are needed to constrain downstream QoIs. It is formulated as a convex optimization problem, making it scalable to large models and datasets. We demonstrate the effectiveness of this approach across various modeling problems in diverse scientific fields, including power systems and underwater acoustics. Finally, we use information-matching as a query function within an Active Learning loop for material science applications. In all these applications, we find that a relatively small set of optimal training data can provide the necessary information for achieving precise predictions. These results are encouraging for diverse future applications, particularly active learning in large machine learning models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02740v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yonatan Kurniawan (Brigham Young University, Provo, UT, USA), Tracianne B. Neilsen (Brigham Young University, Provo, UT, USA), Benjamin L. Francis (Achilles Heel Technologies, Orem, UT, USA), Alex M. Stankovic (SLAC National Accelerator Laboratory, Menlo Park, CA, USA), Mingjian Wen (University of Houston, Houston, TX, USA), Ilia Nikiforov (University of Minnesota, Minneapolis, MN, USA), Ellad B. Tadmor (University of Minnesota, Minneapolis, MN, USA), Vasily V. Bulatov (Lawrence Livermore National Laboratory), Vincenzo Lordi (Lawrence Livermore National Laboratory), Mark K. Transtrum (Brigham Young University, Provo, UT, USA, SLAC National Accelerator Laboratory, Menlo Park, CA, USA)</dc:creator>
    </item>
    <item>
      <title>Energy-based physics-informed neural network for frictionless contact problems under large deformation</title>
      <link>https://arxiv.org/abs/2411.03671</link>
      <description>arXiv:2411.03671v2 Announce Type: replace-cross 
Abstract: Numerical methods for contact mechanics are of great importance in engineering applications, enabling the prediction and analysis of complex surface interactions under various conditions. In this work, we propose an energy-based physics-informed neural network (PINNs) framework for solving frictionless contact problems under large deformation. Inspired by microscopic Lennard-Jones potential, a surface contact energy is used to describe the contact phenomena. To ensure the robustness of the proposed PINN framework, relaxation, gradual loading and output scaling techniques are introduced. In the numerical examples, the well-known Hertz contact benchmark problem is conducted, demonstrating the effectiveness and robustness of the proposed PINNs framework. Moreover, challenging contact problems with the consideration of geometrical and material nonlinearities are tested. It has been shown that the proposed PINNs framework provides a reliable and powerful tool for nonlinear contact mechanics. More importantly, the proposed PINNs framework exhibits competitive computational efficiency to the commercial FEM software when dealing with those complex contact problems. The codes used in this manuscript are available at https://github.com/JinshuaiBai/energy_PINN_Contact.(The code will be available after acceptance)</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03671v2</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinshuai Bai, Zhongya Lin, Yizheng Wang, Jiancong Wen, Yinghua Liu, Timon Rabczuk, YuanTong Gu, Xi-Qiao Feng</dc:creator>
    </item>
    <item>
      <title>Advancing Natural Orbital Functional Calculations Through Deep Learning-Inspired Techniques for Large-Scale Strongly Correlated Electron Systems</title>
      <link>https://arxiv.org/abs/2411.18493</link>
      <description>arXiv:2411.18493v2 Announce Type: replace-cross 
Abstract: Natural orbital functional (NOF) theory offers a promising approach for studying strongly correlated systems at an affordable computational cost, with an accuracy comparable to highly demanding wavefunction-based methods. However, its widespread adoption in cases involving a large number of correlated electrons has been limited by the extensive iterations required for convergence. In this work, we present a disruptive approach that embeds the techniques used for optimization in deep learning within the NOF calculation, constituting a substantial advance in the scale of accessible systems. The revamped procedure is based on the adaptive momentum technique for orbital optimization, alternated with the optimization of the occupation numbers, significantly improving the computational feasibility of challenging calculations. This work represents a complete change in the size scale of the systems that can be reached using NOF theory. We demonstrate this with three examples that involve a large number of electrons: (i) the symmetric dissociation of a large hydrogen cluster, (ii) an analysis of occupancies distribution in fullerenes, and (iii) a study of the singlet-triplet energy gap in linear acenes. Notably, the hydrogen cluster calculation, featuring 1000 electrons, represents the largest NOF calculation performed to date and one of the largest strongly correlated electron calculations ever reported. This system, which serves as an ideal model for a strongly correlated Mott insulator, illustrates a metal-to-insulator transition where all electrons participate in the correlation phenomenon, offering insight in a unique challenge. We anticipate that this work will enable the practical application of NOFs to increasingly complex and intriguing systems, leveraging the method's inherent scalability and accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18493v2</guid>
      <category>cond-mat.str-el</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Juan Felipe Huan Lew-Yee, Jorge M. del Campo, Mario Piris</dc:creator>
    </item>
    <item>
      <title>Machine learning-driven conservative-to-primitive conversion in hybrid piecewise polytropic and tabulated equations of state</title>
      <link>https://arxiv.org/abs/2412.07836</link>
      <description>arXiv:2412.07836v2 Announce Type: replace-cross 
Abstract: We present a novel machine learning (ML) method to accelerate conservative-to-primitive inversion, focusing on hybrid piecewise polytropic and tabulated equations of state. Traditional root-finding techniques are computationally expensive, particularly for large-scale relativistic hydrodynamics simulations. To address this, we employ feedforward neural networks (NNC2PS and NNC2PL), trained in PyTorch and optimized for GPU inference using NVIDIA TensorRT, achieving significant speedups with minimal accuracy loss. The NNC2PS model achieves $ L_1 $ and $ L_\infty $ errors of $ 4.54 \times 10^{-7} $ and $ 3.44 \times 10^{-6} $, respectively, while the NNC2PL model exhibits even lower error values. TensorRT optimization with mixed-precision deployment substantially accelerates performance compared to traditional root-finding methods. Specifically, the mixed-precision TensorRT engine for NNC2PS achieves inference speeds approximately 400 times faster than a traditional single-threaded CPU implementation for a dataset size of 1,000,000 points. Ideal parallelization across an entire compute node in the Delta supercomputer (Dual AMD 64 core 2.45 GHz Milan processors; and 8 NVIDIA A100 GPUs with 40 GB HBM2 RAM and NVLink) predicts a 25-fold speedup for TensorRT over an optimally-parallelized numerical method when processing 8 million data points. Moreover, the ML method exhibits sub-linear scaling with increasing dataset sizes. We release the scientific software developed, enabling further validation and extension of our findings. This work underscores the potential of ML, combined with GPU optimization and model quantization, to accelerate conservative-to-primitive inversion in relativistic hydrodynamics simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07836v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <category>cs.AI</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Semih Kacmaz, Roland Haas, E. A. Huerta</dc:creator>
    </item>
    <item>
      <title>CK-MPM: A Compact-Kernel Material Point Method</title>
      <link>https://arxiv.org/abs/2412.10399</link>
      <description>arXiv:2412.10399v2 Announce Type: replace-cross 
Abstract: The Material Point Method (MPM) has become a cornerstone of physics-based simulation, widely used in geomechanics and computer graphics for modeling phenomena such as granular flows, viscoelasticity, fracture mechanics, etc. Despite its versatility, the original MPM suffers from cell-crossing instabilities caused by discontinuities in particle-grid transfer kernels. Existing solutions mitigate these issues by adopting smoother shape functions, but at the cost of increased computational overhead due to larger kernel support. In this paper, we propose a novel $C^2$-continuous compact kernel for MPM that achieves a unique balance between stability and computational efficiency. Our method integrates seamlessly with Affine Particle-In-Cell (APIC) and Moving Least Squares (MLS) MPM, while only doubling the number of grid nodes associated with each particle compared to linear kernels. At its core is an innovative dual-grid framework, which associates particles with grid nodes exclusively within the cells they occupy on two staggered grids, ensuring consistent and stable force computations. To further accelerate performance, we present a GPU-optimized implementation inspired by state-of-the-art massively parallel MPM techniques, achieving an additional $2\times$ speedup in G2P2G transfers over quadratic B-spline MPM. Comprehensive validation through unit tests, comparative studies, and stress tests demonstrates the efficacy of our approach in conserving both linear and angular momentum, handling stiff materials, and scaling efficiently for large-scale simulations. Our results highlight the transformative potential of compact, high-order kernels in advancing MPM's capabilities for stable, high-performance simulations, paving the way for more computationally efficient applications in computer graphics and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10399v2</guid>
      <category>cs.GR</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Liu, Xinlei Wang, Minchen Li</dc:creator>
    </item>
    <item>
      <title>A projection method for particle resampling</title>
      <link>https://arxiv.org/abs/2501.13681</link>
      <description>arXiv:2501.13681v2 Announce Type: replace-cross 
Abstract: Particle discretizations of partial differential equations are advantageous for high-dimensional kinetic models in phase space due to their better scalability than continuum approaches with respect to dimension. Complex processes collectively referred to as \textit{particle noise} hamper long-time simulations with particle methods. One approach to address this problem is particle mesh adaptivity or remapping, known as \textit{particle resampling}. This paper introduces a resampling method that projects particles to and from a (finite element) function space. The method is simple; using standard sparse linear algebra and finite element techniques, it can adapt to almost any set of new particle locations and preserves all moments up to the order of polynomial represented exactly by the continuum function space.
  This work is motivated by the Vlasov-Maxwell-Landau model of magnetized plasmas with up to six dimensions, $3X$ in physical space and $3V$ in velocity space, and is developed in the context of a $1X$ + $1V$ Vlasov-Poisson model of Landau damping with logically regular particle and continuum phase space grids. The evaluation codes are publicly available, along with the data and reproducibility artifacts, and developed in the PETSc numerical library.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13681v2</guid>
      <category>physics.plasm-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark F. Adams, Matthew G. Knepley, Joseph V. Pusztay, Daniel S. Finn</dc:creator>
    </item>
  </channel>
</rss>
