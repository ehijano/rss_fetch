<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Jul 2025 04:00:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>StockSim: A Dual-Mode Order-Level Simulator for Evaluating Multi-Agent LLMs in Financial Markets</title>
      <link>https://arxiv.org/abs/2507.09255</link>
      <description>arXiv:2507.09255v1 Announce Type: new 
Abstract: We present StockSim, an open-source simulation platform for systematic evaluation of large language models (LLMs) in realistic financial decision-making scenarios. Unlike previous toolkits that offer limited scope, StockSim delivers a comprehensive system that fully models market dynamics and supports diverse simulation modes of varying granularity. It incorporates critical real-world factors, such as latency, slippage, and order-book microstructure, that were previously neglected, enabling more faithful and insightful assessment of LLM-based trading agents. An extensible, role-based agent framework supports heterogeneous trading strategies and multi-agent coordination, making StockSim a uniquely capable testbed for NLP research on reasoning under uncertainty and sequential decision-making. We open-source all our code at https: //github.com/harrypapa2002/StockSim.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09255v1</guid>
      <category>cs.CE</category>
      <category>cs.MA</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Charidimos Papadakis, Giorgos Filandrianos, Angeliki Dimitriou, Maria Lymperaiou, Konstantinos Thomas, Giorgos Stamou</dc:creator>
    </item>
    <item>
      <title>GeoWarp: An automatically differentiable and GPU-accelerated implicit MPM framework for geomechanics based on NVIDIA Warp</title>
      <link>https://arxiv.org/abs/2507.09435</link>
      <description>arXiv:2507.09435v1 Announce Type: new 
Abstract: The material point method (MPM), a hybrid Lagrangian-Eulerian particle method, is increasingly used to simulate large-deformation and history-dependent behavior of geomaterials. While explicit time integration dominates current MPM implementations due to its algorithmic simplicity, such schemes are unsuitable for quasi-static and long-term processes typical in geomechanics. Implicit MPM formulations are free of these limitations but remain less adopted, largely due to the difficulty of computing the Jacobian matrix required for Newton-type solvers, especially when consistent tangent operators should be derived for complex constitutive models. In this paper, we introduce GeoWarp -- an implicit MPM framework for geomechanics built on NVIDIA Warp -- that exploits GPU parallelism and reverse-mode automatic differentiation to compute Jacobians without manual derivation. To enhance efficiency, we develop a sparse Jacobian construction algorithm that leverages the localized particle-grid interactions intrinsic to MPM. The framework is verified through forward and inverse examples in large-deformation elastoplasticity and coupled poromechanics. Results demonstrate that GeoWarp provides a robust, scalable, and extensible platform for differentiable implicit MPM simulation in computational geomechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09435v1</guid>
      <category>cs.CE</category>
      <category>cs.MS</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yidong Zhao, Xuan Li, Chenfanfu Jiang, Jinhyun Choo</dc:creator>
    </item>
    <item>
      <title>EV-STLLM: Electric vehicle charging forecasting based on spatio-temporal large language models with multi-frequency and multi-scale information fusion</title>
      <link>https://arxiv.org/abs/2507.09527</link>
      <description>arXiv:2507.09527v1 Announce Type: new 
Abstract: With the proliferation of electric vehicles (EVs), accurate charging demand and station occupancy forecasting are critical for optimizing urban energy and the profit of EVs aggregator. Existing approaches in this field usually struggle to capture the complex spatio-temporal dependencies in EV charging behaviors, and their limited model parameters hinder their ability to learn complex data distribution representations from large datasets. To this end, we propose a novel EV spatio-temporal large language model (EV-STLLM) for accurate prediction. Our proposed framework is divided into two modules. In the data processing module, we utilize variational mode decomposition (VMD) for data denoising, and improved complete ensemble empirical mode decomposition with adaptive noise (ICEEMDAN) for data multi-frequency decomposition. Fuzzy information granulation (FIG) for extracting multi-scale information. Additionally, ReliefF is used for feature selection to mitigate redundancy. In the forecasting module, the EV-STLLM is used to directly achieve EV charging and occupancy forecasting. Firstly, we fully capture the intrinsic spatio-temporal characteristics of the data by integrating adjacency matrices derived from the regional stations network and spatio-temporal-frequency embedding information. Then, the partially frozen graph attention (PFGA) module is utilized to maintain the sequential feature modeling capabilities of the pre-trained large model while incorporating EV domain knowledge. Extensive experiments using real-world data from Shenzhen, China, demonstrate that our proposed framework can achieve superior accuracy and robustness compared to the state-of-the-art benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09527v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hang Fan, Yunze Chai, Chenxi Liu, Weican Liu, Zuhan Zhang, Wencai Run, Dunnan Liu</dc:creator>
    </item>
    <item>
      <title>Physics-informed machine learning surrogate for scalable simulation of thermal histories during wire-arc directed energy deposition</title>
      <link>https://arxiv.org/abs/2507.09591</link>
      <description>arXiv:2507.09591v1 Announce Type: new 
Abstract: Wire-arc directed energy deposition (DED) has emerged as a promising additive manufacturing (AM) technology for large-scale structural engineering applications. However, the complex thermal dynamics inherent to the process present challenges in ensuring structural integrity and mechanical properties of fabricated thick walls and plates. While finite element method (FEM) simulations have been conventionally employed to predict thermal history during deposition, their computational demand remains prohibitively high for actual large-scale applications. Given the necessity of multiple repetitive simulations for heat management and the determination of an optimal printing strategy, FEM simulation quickly becomes entirely infeasible. Instead, advancements have been made in using trained neural networks as surrogate models for rapid prediction. However, traditional data-driven approaches necessitate large amounts of relevant and verifiable external data, during the training and validation of the neural network. Regarding large-scale wire-arc DED, none of these data sources are readily available in quantities sufficient for an accurate surrogate. The introduction of physics-informed neural networks (PINNs) has opened up an alternative simulation strategy by leveraging the existing physical knowledge of the phenomena with advanced machine learning methods. Despite their theoretical advantages, PINNs have seen limited application in the context of large-scale wire-arc DED for structural engineering. This study investigates the scalability of PINNs, focusing on efficient collocation points sampling, a critical factor controlling both the training time and model performance. Results show PINNs can reduce computational time and effort by up to 98.6%, while maintaining the desired accuracy and offering "super-resolution". Future directions for enhancing PINN performance in metal AM are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09591v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Ryan, Mohammad Hassan Baqershahi, Hessamoddin Moshayedi, Elyas Ghafoori</dc:creator>
    </item>
    <item>
      <title>What Matters Most? A Quantitative Meta-Analysis of AI-Based Predictors for Startup Success</title>
      <link>https://arxiv.org/abs/2507.09675</link>
      <description>arXiv:2507.09675v1 Announce Type: new 
Abstract: Background: Predicting startup success with machine learning is a rapidly growing field, yet findings on key predictors are often fragmented and context-specific. This makes it difficult to discern robust patterns and highlights a need for a systematic synthesis of the evidence.
  Methods: This study conducts a quantitative meta-analysis to synthesize the literature on predictor importance in AI-based startup evaluation. We performed a systematic review to identify a final sample of 13 empirical studies that report rankable feature importance. From these papers, we extracted and categorized 58 unique predictors, synthesizing their importance using a Weighted Importance Score (WIS) that balances a feature's average rank with its frequency of appearance. We also conducted a moderator analysis to investigate how predictor importance changes with context (e.g., success definition).
  Results: Our aggregate analysis reveals that the most consistently powerful predictors are a quartet of foundational attributes: Firm Characteristics (e.g., age, location), Investor Structure (e.g., investor quality), Digital and Social Traction (e.g., online momentum), and Funding History. The moderator analysis further reveals that this hierarchy is highly context-dependent. For instance, predicting near-term funding milestones elevates the importance of the deal's immediate context, while predicting long-term exits prioritizes fundamental firm and investor characteristics.
  Conclusion: The factors that best predict startup success are not universal but are contingent on the startup's goals, stage, and the data used for evaluation. Our findings point to a potential "convenience bias" in the literature, where predictor importance may be tied to data accessibility. We conclude by underscoring the need for standardized reporting practices to enable more robust, cumulative knowledge building in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09675v1</guid>
      <category>cs.CE</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seyed Mohammad Ali Jafari, Ali Mobini Dehkordi, Ehsan Chitsaz, Yadollah Yaghoobzadeh</dc:creator>
    </item>
    <item>
      <title>Legendre Polynomials and Their Use for Karhunen-Lo\`eve Expansion</title>
      <link>https://arxiv.org/abs/2507.09825</link>
      <description>arXiv:2507.09825v1 Announce Type: new 
Abstract: This paper makes two main contributions. First, we present a pedagogical review of the derivation of the three-term recurrence relation for Legendre polynomials, without relying on the classical Legendre differential equation, Rodrigues' formula, or generating functions. This exposition is designed to be accessible to undergraduate students.
  Second, we develop a computational framework for Karhunen-Lo\`eve expansions of isotropic Gaussian random fields on hyper-rectangular domains. The framework leverages Legendre polynomials and their associated Gaussian quadrature, and it remains efficient even in higher spatial dimensions.
  A covariance kernel is first approximated by a non-negative mixture of squared-exponentials, obtained via a Newton-optimized fit with a theoretically informed initialization. The resulting separable kernel enables a Legendre-Galerkin discretization in the form of a Kronecker product over single dimensions, with submatrices that exhibit even/odd parity structure. For assembly, we introduce a Duffy-type transformation followed by quadrature. These structural properties significantly reduce both memory usage and arithmetic cost compared to naive approaches. All algorithms and numerical experiments are provided in an open-source repository that reproduces every figure and table in this work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09825v1</guid>
      <category>cs.CE</category>
      <category>math.PR</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michal B\'ere\v{s}</dc:creator>
    </item>
    <item>
      <title>Non-smooth optimization meets automated material model discovery</title>
      <link>https://arxiv.org/abs/2507.10196</link>
      <description>arXiv:2507.10196v1 Announce Type: new 
Abstract: Automated material model discovery disrupts the tedious and time-consuming cycle of iteratively calibrating and modifying manually designed models. Non-smooth L1-norm regularization is the backbone of automated model discovery; however, the current literature on automated material model discovery offers limited insights into the robust and efficient minimization of non-smooth objective functions. In this work, we examine the minimization of functions of the form f(w) + a ||w||_1, where w are the material model parameters, f is a metric that quantifies the mismatch between the material model and the observed data, and a is a regularization parameter that determines the sparsity of the solution. We investigate both the straightforward case where f is quadratic and the more complex scenario where it is non-quadratic or even non-convex. Importantly, we do not only focus on methods that solve the sparse regression problem for a given value of the regularization parameter a, but propose methods to efficiently compute the entire regularization path, facilitating the selection of a suitable a. Specifically, we present four algorithms and discuss their roles for automated material model discovery in mechanics: First, we recapitulate a well-known coordinate descent algorithm that solves the minimization problem assuming that f is quadratic for a given value of a, also known as the LASSO. Second, we discuss the algorithm LARS, which automatically determines the critical values of a, at which material parameters in w are set to zero. Third, we propose to use the proximal gradient method ISTA for automated material model discovery if f is not quadratic, and fourth, we suggest a pathwise extension of ISTA for computing the regularization path. We demonstrate the applicability of all algorithms for the discovery of hyperelastic material models from uniaxial tension and simple shear data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10196v1</guid>
      <category>cs.CE</category>
      <category>cond-mat.mtrl-sci</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moritz Flaschel, Trevor Hastie, Ellen Kuhl</dc:creator>
    </item>
    <item>
      <title>FinTeam: A Multi-Agent Collaborative Intelligence System for Comprehensive Financial Scenarios</title>
      <link>https://arxiv.org/abs/2507.10448</link>
      <description>arXiv:2507.10448v1 Announce Type: new 
Abstract: Financial report generation tasks range from macro- to micro-economics analysis, also requiring extensive data analysis. Existing LLM models are usually fine-tuned on simple QA tasks and cannot comprehensively analyze real financial scenarios. Given the complexity, financial companies often distribute tasks among departments. Inspired by this, we propose FinTeam, a financial multi-agent collaborative system, with a workflow with four LLM agents: document analyzer, analyst, accountant, and consultant. We train these agents with specific financial expertise using constructed datasets. We evaluate FinTeam on comprehensive financial tasks constructed from real online investment forums, including macroeconomic, industry, and company analysis. The human evaluation shows that by combining agents, the financial reports generate from FinTeam achieved a 62.00% acceptance rate, outperforming baseline models like GPT-4o and Xuanyuan. Additionally, FinTeam's agents demonstrate a 7.43% average improvement on FinCUGE and a 2.06% accuracy boost on FinEval. Project is available at https://github.com/FudanDISC/DISC-FinLLM/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10448v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingqian Wu, Qiushi Wang, Zefei Long, Rong Ye, Zhongtian Lu, Xianyin Zhang, Bingxuan Li, Wei Chen, Liwen Zhang, Zhongyu Wei</dc:creator>
    </item>
    <item>
      <title>Central Bank Digital Currencies: A Survey</title>
      <link>https://arxiv.org/abs/2507.08880</link>
      <description>arXiv:2507.08880v1 Announce Type: cross 
Abstract: With the advancement of digital payment technologies, central banks worldwide have increasingly begun to explore the implementation of Central Bank Digital Currencies (CBDCs). This paper presents a comprehensive review of the latest developments in CBDC system design and implementation. By analyzing 135 research papers published between 2018 and 2025, the study provides an in-depth examination of CBDC design taxonomy and ecosystem frameworks. Grounded in the CBDC Design Pyramid, the paper refines and expands key architectural elements by thoroughly investigating innovations in ledger technologies, the selection of consensus mechanisms, and challenges associated with offline payments and digital wallet integration. Furthermore, it conceptualizes a CBDC ecosystem. A detailed comparative analysis of 26 existing CBDC systems is conducted across four dimensions: system architecture, ledger technology, access model, and application domain. The findings reveal that the most common configuration consists of a two-tier architecture, distributed ledger technology (DLT), and a token-based access model. However, no dominant trend has emerged regarding application domains. Notably, recent research shows a growing focus on leveraging CBDCs for cross-border payments to resolve inefficiencies and structural delays in current systems. Finally, the paper offers several forward-looking recommendations for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08880v1</guid>
      <category>econ.GN</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qifeng Tang, Yain-Whar Si</dc:creator>
    </item>
    <item>
      <title>Toward Developing Machine-Learning-Aided Tools for the Thermomechanical Monitoring of Nuclear Reactor Components</title>
      <link>https://arxiv.org/abs/2507.09443</link>
      <description>arXiv:2507.09443v1 Announce Type: cross 
Abstract: Proactive maintenance strategies, such as Predictive Maintenance (PdM), play an important role in the operation of Nuclear Power Plants (NPPs), particularly due to their capacity to reduce offline time by preventing unexpected shutdowns caused by component failures.
  In this work, we explore the use of a Convolutional Neural Network (CNN) architecture combined with a computational thermomechanical model to calculate the temperature, stress, and strain of a Pressurized Water Reactor (PWR) fuel rod during operation. This estimation relies on a limited number of temperature measurements from the cladding's outer surface. This methodology can potentially aid in developing PdM tools for nuclear reactors by enabling real-time monitoring of such systems.
  The training, validation, and testing datasets were generated through coupled simulations involving BISON, a finite element-based nuclear fuel performance code, and the MOOSE Thermal-Hydraulics Module (MOOSE-THM). We conducted eleven simulations, varying the peak linear heat generation rates. Of these, eight were used for training, two for validation, and one for testing.
  The CNN was trained for over 1,000 epochs without signs of overfitting, achieving highly accurate temperature distribution predictions. These were then used in a thermomechanical model to determine the stress and strain distribution within the fuel rod.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09443v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luiz Aldeia Machado, Victor Coppo Leite, Elia Merzari, Arthur Motta, Roberto Ponciroli, Lander Ibarra, Lise Charlot</dc:creator>
    </item>
    <item>
      <title>When the Weak Becomes Strong: Effective Observables via Time-Symmetric Quantum Selection</title>
      <link>https://arxiv.org/abs/2507.09716</link>
      <description>arXiv:2507.09716v1 Announce Type: cross 
Abstract: We investigate the sequential composition of weak values in the framework of time-symmetric quantum mechanics. Specifically, we consider a forward'' weak measurement from a preselected state $\ket{\psi}$ to a post-selected state $\ket{\phi}$, followed by a reverse'' weak measurement. We show that the product of these two weak values corresponds to the normalized expectation value of a strong, state-conditioned observable $B = A P_\psi A$, where $P_\psi = \ket{\psi}\bra{\psi}$ is the projector onto the preselected state. Analyzing the structure of $B$, we demonstrate how it encodes interference information, particularly when $\ket{\psi}$ is a superposition rather than an eigenstate of $A$. This formulation extends naturally to mixed states by replacing $P_\psi$ with a generic density matrix $\rho$, linking the construction to the formalism of generalized quantum measurements. We illustrate practical applications in quantum information, including state-specific error witnessing in quantum computing, and show how the phase of a weak value can be inferred via strong measurements in the pure-state case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09716v1</guid>
      <category>quant-ph</category>
      <category>cs.CE</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mirco A. Mannucci</dc:creator>
    </item>
    <item>
      <title>A Coincidence of Wants Mechanism for Swap Trade Execution in Decentralized Exchanges</title>
      <link>https://arxiv.org/abs/2507.10149</link>
      <description>arXiv:2507.10149v1 Announce Type: cross 
Abstract: We propose a mathematically rigorous framework for identifying and completing Coincidence of Wants (CoW) cycles in decentralized exchange (DEX) aggregators. Unlike existing auction based systems such as CoWSwap, our approach introduces an asset matrix formulation that not only verifies feasibility using oracle prices and formal conservation laws but also completes partial CoW cycles of swap orders that are discovered using graph traversal and are settled using imbalance correction. We define bridging orders and show that the resulting execution is slippage free and capital preserving for LPs. Applied to real world Arbitrum swap data, our algorithm demonstrates efficient discovery of CoW cycles and supports the insertion of synthetic orders for atomic cycle closure. This work can be thought of as the detailing of a potential delta-neutral strategy by liquidity providing market makers: a structured CoW cycle execution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10149v1</guid>
      <category>cs.GT</category>
      <category>cs.CE</category>
      <category>q-fin.TR</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhimanyu Nag, Madhur Prabhakar, Tanuj Behl</dc:creator>
    </item>
    <item>
      <title>Foundation Model for Composite Microstructures: Reconstruction, Stiffness, and Nonlinear Behavior Prediction</title>
      <link>https://arxiv.org/abs/2411.06565</link>
      <description>arXiv:2411.06565v4 Announce Type: replace 
Abstract: We present the Material Masked Autoencoder (MMAE), a self-supervised Vision Transformer pretrained on a large corpus of short-fiber composite images via masked image reconstruction. The pretrained MMAE learns latent representations that capture essential microstructural features and are broadly transferable across tasks. We demonstrate two key applications: (i) predicting homogenized stiffness components through fine-tuning on limited data, and (ii) inferring physically interpretable parameters by coupling MMAE with an interaction-based material network (IMN), thereby enabling extrapolation of nonlinear stress-strain responses. These results highlight the promise of microstructure foundation models and lay the groundwork for future extensions to more complex systems, such as 3D composites and experimental datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06565v4</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ting-Ju Wei, Chuin-Shan Chen</dc:creator>
    </item>
    <item>
      <title>Multimodal Financial Foundation Models (MFFMs): Progress, Prospects, and Challenges</title>
      <link>https://arxiv.org/abs/2506.01973</link>
      <description>arXiv:2506.01973v2 Announce Type: replace 
Abstract: Financial Large Language Models (FinLLMs), such as open FinGPT and proprietary BloombergGPT, have demonstrated great potential in select areas of financial services. Beyond this earlier language-centric approach, Multimodal Financial Foundation Models (MFFMs) can digest interleaved multimodal financial data, including fundamental data, market data, data analytics, macroeconomic, and alternative data (e.g., natural language, audio, images, and video). In this position paper, presented at the MFFM Workshop joined with ACM International Conference on AI in Finance (ICAIF) 2024, we describe the progress, prospects, and challenges of MFFMs. This paper also highlights ongoing research on FinAgents in the \textbf{SecureFinAI Lab}\footnote{\https://openfin.engineering.columbia.edu/} at Columbia University. We believe that MFFMs will enable a deeper understanding of the underlying complexity associated with numerous financial tasks and data, streamlining the operation of financial services and investment processes. Github Repo https://github.com/Open-Finance-Lab/Awesome-MFFMs/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01973v2</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao-Yang Liu Yanglet, Yupeng Cao, Li Deng</dc:creator>
    </item>
    <item>
      <title>QPET: A Versatile and Portable Quantity-of-Interest-Preservation Framework for Error-Bounded Lossy Compression</title>
      <link>https://arxiv.org/abs/2412.02799</link>
      <description>arXiv:2412.02799v4 Announce Type: replace-cross 
Abstract: Error-bounded lossy compression has been widely adopted in many scientific domains because it can address the challenges in storing, transferring, and analyzing unprecedented amounts of scientific data. Although error-bounded lossy compression offers general data distortion control by enforcing strict error bounds on raw data, it may fail to meet the quality requirements on the results of downstream analysis, a.k.a. Quantities of Interest (QoIs), derived from raw data. This may lead to uncertainties and even misinterpretations in scientific discoveries, significantly limiting the use of lossy compression in practice. In this paper, we propose QPET, a novel, versatile, and portable framework for QoI-preserving error-bounded lossy compression, which overcomes the challenges of modeling diverse QoIs by leveraging numerical strategies. QPET features (1) high portability to multiple existing lossy compressors, (2) versatile preservation to most differentiable univariate and multivariate QoIs, and (3) significant compression improvements in QoI-preservation tasks. Experiments with six real-world datasets demonstrate that integrating QPET into state-of-the-art error-bounded lossy compressors can gain 2x to 10x compression speedups of existing QoI-preserving error-bounded lossy compression solutions, up to 1000% compression ratio improvements to general-purpose compressors, and up to 133% compression ratio improvements to existing QoI-integrated scientific compressors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02799v4</guid>
      <category>cs.DB</category>
      <category>cs.CE</category>
      <category>cs.DC</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jinyang Liu, Pu Jiao, Kai Zhao, Xin Liang, Sheng Di, Franck Cappello</dc:creator>
    </item>
    <item>
      <title>Noise-robust multi-fidelity surrogate modelling for parametric partial differential equations</title>
      <link>https://arxiv.org/abs/2507.03691</link>
      <description>arXiv:2507.03691v2 Announce Type: replace-cross 
Abstract: We address the challenge of constructing noise-robust surrogate models for quantities of interest (QoIs) arising from parametric partial differential equations (PDEs), using multi-fidelity collocation techniques; specifically, the Multi-Index Stochastic Collocation (MISC). In practical scenarios, the PDE evaluations used to build a response surface are often corrupted by numerical noise, especially for the low-fidelity models. This noise, which may originate from loose solver tolerances, coarse discretisations, or transient effects, can lead to overfitting in MISC, degrading surrogate quality through nonphysical oscillations and loss of convergence, thereby limiting its utility in downstream tasks like uncertainty quantification, optimisation, and control. To correct this behaviour, we propose an improved version of MISC that can automatically detect the presence of solver noise during the surrogate model construction and then ignore the exhausted fidelities. Our approach monitors the spectral decay of the surrogate at each iteration, identifying stagnation in the coefficient spectrum that signals the onset of noise. Once detected, the algorithm selectively halts the use of noisy fidelities, focusing computational resources on those fidelities that still provide meaningful information. The effectiveness of this approach is numerically validated on two challenging test cases: a parabolic advection--diffusion PDE with uncertain coefficients, and a parametric turbulent incompressible Navier--Stokes problem. The results showcase the accuracy and robustness of the resulting multi-fidelity surrogate and its capability to extract relevant information, even from under-resolved meshes not suitable for reliable single-fidelity computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03691v2</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin M. Kent, Lorenzo Tamellini, Matteo Giacomini, Antonio Huerta</dc:creator>
    </item>
  </channel>
</rss>
