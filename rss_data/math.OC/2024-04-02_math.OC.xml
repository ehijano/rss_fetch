<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Apr 2024 19:07:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Minimum $L_2$-Distance Projection onto the Canonical Simplex: A Simple Algorithm</title>
      <link>https://arxiv.org/abs/2404.00002</link>
      <description>arXiv:2404.00002v1 Announce Type: new 
Abstract: We consider the minimum distance projection in the $L_2$-norm from an arbitrary point in an $n$-dimensional, Euclidian space onto the canonical simplex. It is shown that this problem reduces to a univariate problem that can be solved by a simple algorithm. This optimization problem occurs in the setting of credit risk, where one has stochastic matrices that describe transition probabilities between different credit ratings, and one wants to determine the roots of these matrices, or close approximations to them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00002v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Algo Research Quarterly, 4(4):53-55, December 2001</arxiv:journal_reference>
      <dc:creator>Hans J. H. Tuenter</dc:creator>
    </item>
    <item>
      <title>Algorithms for constrained optimal transport</title>
      <link>https://arxiv.org/abs/2404.00003</link>
      <description>arXiv:2404.00003v1 Announce Type: new 
Abstract: We derive iterative scaling algorithms of the Sinkhorn-Knopp (SK) type for constrained optimal transport. The constraints are in the form of prior-imposed zeroes in the transport plan. Based on classical Bregman arguments, we prove asymptotic convergence of our algorithms to a unique optimal solution. New insights obtained from the convergence proof are highlighted. An example from electrical vehicle charging in a smart city context is outlined, in which the prior zero-constraints prevent energy from being transported from some providers to some vehicles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00003v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Corless, Anthony Quinn, Sarah Boufelja, Robert Shorten</dc:creator>
    </item>
    <item>
      <title>Introduction: Swarm-based gradient descent for non convex optimization</title>
      <link>https://arxiv.org/abs/2404.00005</link>
      <description>arXiv:2404.00005v1 Announce Type: new 
Abstract: The field of optimization has the goal to find an optimal solution to a target function, i.e. to minimize (or maximize) the target function. When trying to find such a global minimum, one often encounters local minima due to unfavorable procedures and starting regions. The swarm-based gradient descent method of Prof. Eitan Tadmor offers an alternative method for solving global minimization problems. By using a swarm of agents, local minima will not be taken account and the global minimum will be found. Furthermore leads the communication between the agent to a further expansion of the search region. Under the supervision of Prof. Angela Kunoth, I give an introduction to this swarm-based method in my bachelor thesis. Therefore I used my own program in Julia to give a more visual understanding of how the new method works and which influence certain parameters such as the number of agents or "q" have.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00005v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Janina Tikko</dc:creator>
    </item>
    <item>
      <title>Best free knot linear spline approximation and its application to neural networks</title>
      <link>https://arxiv.org/abs/2404.00008</link>
      <description>arXiv:2404.00008v1 Announce Type: new 
Abstract: The problem of fixed knot approximation is convex and there are several efficient approaches to solve this problem, yet, when the knots joining the affine parts are also variable, finding conditions for a best Chebyshev approximation remains an open problem. It was noticed before that piecewise linear approximation with free knots is equivalent to neural network approximation with piecewise linear activation functions (for example ReLU). In this paper, we demonstrate that in the case of one internal free knot, the problem of linear spline approximation can be reformulated as a mixed-integer linear programming problem and solved efficiently using, for example, a branch and bound type method. We also present a new sufficient optimality condition for a one free knot piecewise linear approximation. The results of numerical experiments are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00008v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vinesha Peiris, Duy Khoa Pham, Nadezda Sukhorukova</dc:creator>
    </item>
    <item>
      <title>Technical Report: Pose Graph Optimization over Planar Unit Dual Quaternions: Improved Accuracy with Provably Convergent Riemannian Optimization</title>
      <link>https://arxiv.org/abs/2404.00010</link>
      <description>arXiv:2404.00010v1 Announce Type: new 
Abstract: It is common in pose graph optimization (PGO) algorithms to assume that noise in the translations and rotations of relative pose measurements is uncorrelated. However, existing work shows that in practice these measurements can be highly correlated, which leads to degradation in the accuracy of PGO solutions that rely on this assumption. Therefore, in this paper we develop a novel algorithm derived from a realistic, correlated model of relative pose uncertainty, and we quantify the resulting improvement in the accuracy of the solutions we obtain relative to state-of-the-art PGO algorithms. Our approach utilizes Riemannian optimization on the planar unit dual quaternion (PUDQ) manifold, and we prove that it converges to first-order stationary points of a Lie-theoretic maximum likelihood objective. Then we show experimentally that, compared to state-of-the-art PGO algorithms, this algorithm produces estimation errors that are lower by 10% to 25% across several orders of magnitude of noise levels and graph sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00010v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William D. Warke, J. Humberto Ramos, Prashant Ganesh, Kevin M. Brink, Matthew T. Hale</dc:creator>
    </item>
    <item>
      <title>Strong convergence towards the minimum norm solution via temporal scaling and Tikhonov approximation of a first-order dynamical system</title>
      <link>https://arxiv.org/abs/2404.00038</link>
      <description>arXiv:2404.00038v1 Announce Type: new 
Abstract: Given a proper convex lower semicontinuous function defined on a Hilbert space and whose solution set is supposed nonempty. For attaining a global minimizer when this convex function is continuously differentiable, we approach it by a first-order continuous dynamical system with a time rescaling parameter and a Tikhonov regularization term. We show, along the generated trajectories, fast convergence of values, fast convergence of gradients towards origin and strong convergence towards the minimum norm element of the solution set. These convergence rates now depend on the time rescaling parameter, and thus improve existing results by choosing this parameter appropriately. The obtained results illustrate, via particular cases on the choice of the time rescaling parameter, good performances of the proposed continuous method and the wide range of applications they can address. Numerical illustrations for continuous example are provided to confirm the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00038v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. C. Bagy, Z. Chbani, H. Riahi</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimization with Constraints: A Non-asymptotic Instance-Dependent Analysis</title>
      <link>https://arxiv.org/abs/2404.00042</link>
      <description>arXiv:2404.00042v1 Announce Type: new 
Abstract: We consider the problem of stochastic convex optimization under convex constraints. We analyze the behavior of a natural variance reduced proximal gradient (VRPG) algorithm for this problem. Our main result is a non-asymptotic guarantee for VRPG algorithm. Contrary to minimax worst case guarantees, our result is instance-dependent in nature. This means that our guarantee captures the complexity of the loss function, the variability of the noise, and the geometry of the constraint set. We show that the non-asymptotic performance of the VRPG algorithm is governed by the scaled distance (scaled by $\sqrt{N}$) between the solutions of the given problem and that of a certain small perturbation of the given problem -- both solved under the given convex constraints; here, $N$ denotes the number of samples. Leveraging a well-established connection between local minimax lower bounds and solutions to perturbed problems, we show that as $N \rightarrow \infty$, the VRPG algorithm achieves the renowned local minimax lower bound by H\`{a}jek and Le Cam up to universal constants and a logarithmic factor of the sample size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00042v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Koulik Khamaru</dc:creator>
    </item>
    <item>
      <title>Partial Backorder Inventory System: Asymptotic Optimality and Demand Learning</title>
      <link>https://arxiv.org/abs/2404.00046</link>
      <description>arXiv:2404.00046v1 Announce Type: new 
Abstract: We develop a stochastic inventory system which accounts for the limited patience of backlogged customers. While limited patience is a feature that is closer to the nature of unmet demand, our model also unifies the classic backlogging and lost-sales inventory systems which are special cases of the one we propose. We establish the uniform (asymptotic) optimality of the base-stock policy when both demand and patience distributions are known. When the backlogged demands become unobservable, we introduce a novel policy family that operates without backlogged demands information, and prove that it can approach the cost efficiency of the optimal policy in the system when the demand and patience distributions are known. Finally, we consider an online inventory control problem in which backlogged demand is unobservable and demand and patience distributions are also not known, and develop a UCB-type algorithm that yields a near-optimal policy. The regret bounds given by the algorithm are provably tight within the planning horizon, and are comparable to the state-of-the-art results in the literature, even in the face of partial and biased observations and weaker system ergodicity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00046v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew E. B. Lim, Zhao-Xuan Wei, Hanqin Zhang</dc:creator>
    </item>
    <item>
      <title>Adaptive Computing for Scale-up Problems</title>
      <link>https://arxiv.org/abs/2404.00053</link>
      <description>arXiv:2404.00053v1 Announce Type: new 
Abstract: Adaptive Computing is an application-agnostic outer loop framework to strategically deploy simulations and experiments to guide decision making for scale-up analysis. Resources are allocated over successive batches, which makes the allocation adaptive to some objective such as optimization or model training. The framework enables the characterization and management of uncertainties associated with predictive models of complex systems when scale-up questions lead to significant model extrapolation. A key feature of this framework is the ability to explicitly utilize user-specified uncertainty priors, which we call model-specific local trust estimates, that are provided directly together with the problem specification and exploited in adaptive sampling strategies. A multi-fidelity model hierarchy is supported to allow trade-offs in accuracy and data acquisition cost while exploring the search space given a specified budget of potentially distributed, heterogeneous resources. We discuss application of this framework to problems in the renewable energy space, including biofuels production, material synthesis, perovskite crystal growth, and building electrical loads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00053v1</guid>
      <category>math.OC</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hilary Egan, Kevin Patrick Griffin, Marc T. Henry de Frahan, Juliane Mueller, Deepthi Vaidhynatha, Dylan Wald, Rohit Chintala, Olga A. Doronina, Ryan King, Jibonananda Sanyal, Marc Day</dc:creator>
    </item>
    <item>
      <title>Efficient Global Algorithms for Transmit Beamforming Design in ISAC Systems</title>
      <link>https://arxiv.org/abs/2404.00055</link>
      <description>arXiv:2404.00055v1 Announce Type: new 
Abstract: In this paper, we propose a multi-input multi-output transmit beamforming optimization model for joint radar sensing and multi-user communications, where the design of the beamformers is formulated as an optimization problem whose objective is a weighted combination of the sum rate and the Cram\'{e}r-Rao bound, subject to the transmit power budget. Obtaining the global solution for the formulated nonconvex problem is a challenging task, since the sum-rate maximization problem itself (even without considering the sensing metric) is known to be NP-hard. The main contributions of this paper are threefold. Firstly, we derive an optimal closed-form solution to the formulated problem in the single-user case and the multi-user case where the channel vectors of different users are orthogonal. Secondly, for the general multi-user case, we propose a novel branch and bound (B\&amp;B) algorithm based on the McCormick envelope relaxation. The proposed algorithm is guaranteed to find the globally optimal solution to the formulated problem. Thirdly, we design a graph neural network (GNN) based pruning policy to determine irrelevant nodes that can be directly pruned in the proposed B\&amp;B algorithm, thereby significantly reducing the number of unnecessary enumerations therein and improving its computational efficiency. Simulation results show the efficiency of the proposed vanilla and GNN-based accelerated B\&amp;B algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00055v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiageng Wu, Zhiguo Wang, Ya-Feng Liu, Fan Liu</dc:creator>
    </item>
    <item>
      <title>An SVD-like Decomposition of Bounded-Input Bounded-Output Functions</title>
      <link>https://arxiv.org/abs/2404.00112</link>
      <description>arXiv:2404.00112v1 Announce Type: new 
Abstract: The Singular Value Decomposition (SVD) of linear functions facilitates the calculation of their 2-induced norm and row and null spaces, hallmarks of linear control theory. In this work, we present a function representation that, similar to SVD, provides an upper bound on the 2-induced norm of bounded-input bounded-output functions, as well as facilitates the computation of generalizations of the notions of row and null spaces. Borrowing from the notion of "lifting" in Koopman operator theory, we construct a finite-dimensional lifting of inputs that relaxes the unitary property of the right-most matrix in traditional SVD, $V^*$, to be an injective, norm-preserving mapping to a slightly higher-dimensional space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00112v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian Charles Brown, Michael King, Sean Warnick, Enoch Yeung, David Grimsman</dc:creator>
    </item>
    <item>
      <title>Fully Zeroth-Order Bilevel Programming via Gaussian Smoothing</title>
      <link>https://arxiv.org/abs/2404.00158</link>
      <description>arXiv:2404.00158v1 Announce Type: new 
Abstract: In this paper, we study and analyze zeroth-order stochastic approximation algorithms for solving bilvel problems, when neither the upper/lower objective values, nor their unbiased gradient estimates are available. In particular, exploiting Stein's identity, we first use Gaussian smoothing to estimate first- and second-order partial derivatives of functions with two independent block of variables. We then used these estimates in the framework of a stochastic approximation algorithm for solving bilevel optimization problems and establish its non-asymptotic convergence analysis. To the best of our knowledge, this is the first time that sample complexity bounds are established for a fully stochastic zeroth-order bilevel optimization algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00158v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alireza Aghasi, Saeed Ghadimi</dc:creator>
    </item>
    <item>
      <title>Dynamic Pedestrian Traffic Assignment with Link Transmission Model for Bidirectional Sidewalk Networks</title>
      <link>https://arxiv.org/abs/2404.00170</link>
      <description>arXiv:2404.00170v1 Announce Type: new 
Abstract: Planning assessment of the urban walking infrastructure requires appropriate methodologies that can capture the time-dependent and unique microscopic characteristics of bidirectional pedestrian flow. In this paper, we develop a simulation-based dynamic pedestrian traffic assignment (DPTA) model specifically formulated for walking networks (e.g. sidewalks) with bidirectional links. The model consists of a dynamic user equilibrium (DUE) based route choice and a link transmission model (LTM) for network loading. The formulated DUE adopts a pedestrian volume delay function (pVDF) taking into account the properties of bidirectional pedestrian streams such as self-organization. The adopted LTM uses a three-dimensional triangular bidirectional fundamental diagram as well as a generalized first-order node model. The applicability and validity of the model is demonstrated in hypothetical small networks as well as a real-world large-scale network of sidewalks in Sydney. The model successfully replicates formation and propagation of shockwaves in walking corridors and networks due to bidirectional effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00170v1</guid>
      <category>math.OC</category>
      <category>cond-mat.stat-mech</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.trc.2022.103930</arxiv:DOI>
      <dc:creator>Tanapon Lilasathapornkit, Meead Saberi</dc:creator>
    </item>
    <item>
      <title>Beyond Suspension: A Two-phase Methodology for Concluding Sports Leagues</title>
      <link>https://arxiv.org/abs/2404.00178</link>
      <description>arXiv:2404.00178v1 Announce Type: new 
Abstract: Problem definition: Professional sports leagues may be suspended due to various reasons such as the recent COVID-19 pandemic. A critical question the league must address when re-opening is how to appropriately select a subset of the remaining games to conclude the season in a shortened time frame. Academic/practical relevance: Despite the rich literature on scheduling an entire season starting from a blank slate, concluding an existing season is quite different. Our approach attempts to achieve team rankings similar to that which would have resulted had the season been played out in full. Methodology: We propose a data-driven model which exploits predictive and prescriptive analytics to produce a schedule for the remainder of the season comprised of a subset of originally-scheduled games. Our model introduces novel rankings-based objectives within a stochastic optimization model, whose parameters are first estimated using a predictive model. We introduce a deterministic equivalent reformulation along with a tailored Frank-Wolfe algorithm to efficiently solve our problem, as well as a robust counterpart based on min-max regret. Results: We present simulation-based numerical experiments from previous National Basketball Association (NBA) seasons 2004--2019, and show that our models are computationally efficient, outperform a greedy benchmark that approximates a non-rankings-based scheduling policy, and produce interpretable results. Managerial implications: Our data-driven decision-making framework may be used to produce a shortened season with 25-50\% fewer games while still producing an end-of-season ranking similar to that of the full season, had it been played.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00178v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ali Hassanzadeh, Mojtaba Hosseini, John G. Turner</dc:creator>
    </item>
    <item>
      <title>An Efficient Sparse Identification Algorithm For Stochastic Systems With General Observation Sequences</title>
      <link>https://arxiv.org/abs/2404.00199</link>
      <description>arXiv:2404.00199v1 Announce Type: new 
Abstract: This paper studies the sparse identification problem of unknown sparse parameter vectors in stochastic dynamic systems. Firstly, a novel sparse identification algorithm is proposed, which can generate sparse estimates based on least squares estimation by adaptively adjusting the threshold. Secondly, under a possibly weakest non-persistent excited condition, we prove that the proposed algorithm can correctly identify the zero and nonzero elements of the sparse parameter vector using a finite number of observations, and further estimates of the nonzero elements almost surely converge to the true values. Compared with the related works, e.g., LASSO, our method only requires the weakest assumptions and does not require solving additional optimization problems. Besides, our theoretical results do not require any statistical assumptions on the regression signals, including independence or stationarity, which makes our results promising for application to stochastic feedback systems. Thirdly, the number of finite observations that guarantee the convergence of the zero-element set of unknown sparse parameters of the Hammerstein system is derived for the first time. Finally, numerical simulations are provided, demonstrating the effectiveness of the proposed method. Since there is no additional optimization problem, i.e., no additional numerical error, the proposed algorithm performs much better than other related algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00199v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziming Wang, Xinghua Zhu</dc:creator>
    </item>
    <item>
      <title>Non-homogeneous stochastic linear-quadratic optimal control problems with multi-dimensional state and regime switching</title>
      <link>https://arxiv.org/abs/2404.00382</link>
      <description>arXiv:2404.00382v1 Announce Type: new 
Abstract: In this paper, we study non-homogeneous stochastic linear-quadratic (LQ) optimal control problems with multi-dimensional state and regime switching. We focus on the corresponding stochastic Riccati equation, which is the same as that one in homogeneous stochastic LQ optimal control problem, and the adjoint backward stochastic differential equation (BSDE), which arises from the non-homogeneous terms in the state equation and cost functional. Both stochastic Riccati equation and adjoint BSDE are solved by the contraction mapping method, and are used to represent the closed-loop optimal control and the optimal value of our problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00382v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuyang Chen, Peng Luo</dc:creator>
    </item>
    <item>
      <title>Learning truly monotone operators with applications to nonlinear inverse problems</title>
      <link>https://arxiv.org/abs/2404.00390</link>
      <description>arXiv:2404.00390v1 Announce Type: new 
Abstract: This article introduces a novel approach to learning monotone neural networks through a newly defined penalization loss. The proposed method is particularly effective in solving classes of variational problems, specifically monotone inclusion problems, commonly encountered in image processing tasks. The Forward-Backward-Forward (FBF) algorithm is employed to address these problems, offering a solution even when the Lipschitz constant of the neural network is unknown. Notably, the FBF algorithm provides convergence guarantees under the condition that the learned operator is monotone. Building on plug-and-play methodologies, our objective is to apply these newly learned operators to solving non-linear inverse problems. To achieve this, we initially formulate the problem as a variational inclusion problem. Subsequently, we train a monotone neural network to approximate an operator that may not inherently be monotone. Leveraging the FBF algorithm, we then show simulation examples where the non-linear inverse problem is successfully solved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00390v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Younes Belkouchi, Jean-Christophe Pesquet, Audrey Repetti, Hugues Talbot</dc:creator>
    </item>
    <item>
      <title>Dynamic Transfer Policies for Parallel Queues</title>
      <link>https://arxiv.org/abs/2404.00543</link>
      <description>arXiv:2404.00543v1 Announce Type: new 
Abstract: We consider the problem of load balancing in parallel queues by transferring customers between them at discrete points in time. Holding costs accrue as customers wait in the queue, while transfer decisions incur both fixed (setup) and variable costs proportional to the number and direction of transfers. Our work is primarily motivated by inter-facility patient transfers between hospitals during a surge in demand for hospitalization (e.g., during a pandemic). By analyzing an associated fluid control problem, we show that under fairly general assumptions including time-varying arrivals and convex increasing holding costs, the optimal policy in each period partitions the state-space into a well-defined $\textit{no-transfer region}$ and its complement, such that transferring is optimal if and only if the system is sufficiently imbalanced. In the absence of fixed transfer costs, an optimal policy moves the state to the no-transfer region's boundary; in contrast, with fixed costs, the state is moved to the no-transfer region's relative interior. We further leverage the fluid control problem to provide insights on the trade-off between holding and transfer costs, emphasizing the importance of preventing excessive idleness when transfers are not feasible in continuous-time. Using simulation experiments, we investigate the performance and robustness of the fluid policy for the stochastic system. In particular, our case study calibrated using data during the pandemic in the Greater Toronto Area demonstrates that transferring patients between hospitals could result in up to 27.7% reduction in total cost with relatively few transfers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00543v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Timothy C. Y. Chan, Jangwon Park, Vahid Sarhangian</dc:creator>
    </item>
    <item>
      <title>Stochastic-Robust Planning of Networked Hydrogen-Electrical Microgrids: A Study on Induced Refueling Demand</title>
      <link>https://arxiv.org/abs/2404.00568</link>
      <description>arXiv:2404.00568v1 Announce Type: new 
Abstract: Hydrogen-electrical (HE) microgrids are increasingly assuming an important role on the pathway toward decarbonization of energy and transportation systems. This paper studies networked HE microgrids planning (NHEMP), considering a critical but often-overlooked issue, i.e., the demand-inducing effect (DIE) associated with infrastructure development decisions. Specifically, higher refueling capacities will attract more refueling demand of hydrogen-powered vehicles (HVs). To capture such interactions between investment decisions and induced refueling demand, we introduce a decision-dependent uncertainty (DDU) set and build a trilevel stochastic-robust formulation. The upper-level determines optimal investment strategies for HE microgrids, the lower-level optimizes the risk-aware operation schedules across a series of stochastic scenarios, and, for each scenario, the middle-level identifies the "worst" situation of refueling demand within an individual DDU set to ensure economic feasibility. Then, an adaptive and exact decomposition algorithm, based on Parametric Column-and-Constraint Generation (PC&amp;CG), is customized and developed to address the computational challenge and to quantitatively analyze the impact of DIE. Case studies on an IEEE exemplary system validate the effectiveness of the proposed NHEMP model and the PC&amp;CG algorithm. It is worth highlighting that DIE can make an important contribution to the economic benefits of NHEMP, yet its significance will gradually decrease when the main bottleneck transits to other system restrictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00568v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xunhang Sun, Xiaoyu Cao, Bo Zeng, Qiaozhu Zhai, Tamer Ba\c{s}ar, Xiaohong Guan</dc:creator>
    </item>
    <item>
      <title>Sparse Extended Mean-Variance-CVaR Portfolios with Short-selling</title>
      <link>https://arxiv.org/abs/2404.00605</link>
      <description>arXiv:2404.00605v1 Announce Type: new 
Abstract: This paper introduces a novel penalty decomposition algorithm customized for addressing the non-differentiable and nonconvex problem of extended mean-variance-CVaR portfolio optimization with short-selling and cardinality constraints. The proposed algorithm solves a sequence of penalty subproblems using a block coordinate descent (BCD) method while striving to fully exploit each component of the objective function or constraints. Through rigorous analysis, the well-posed nature of each subproblem of the BCD method is established, and closed-form solutions are derived where possible. A comprehensive theoretical convergence analysis is provided to confirm the efficacy of the introduced algorithm in reaching a local minimizer of this intractable optimization problem in finance, whereas generic optimization techniques either only capture a partial minimum or are not efficient. Numerical experiments conducted on real-world datasets validate the practical applicability, effectiveness, and robustness of the introduced algorithm across various criteria. Notably, the existence of closed-form solutions within the BCD subproblems prominently underscores the efficiency of our algorithm when compared to state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00605v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmad Mousavi, Maziar Salahi, Zois Boukouvalas</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Chance Constrained Optimization in Dynamic Environment</title>
      <link>https://arxiv.org/abs/2404.00608</link>
      <description>arXiv:2404.00608v1 Announce Type: new 
Abstract: We study the scenario approach for solving chance-constrained optimization in time-coupled dynamic environments. Scenario generation methods approximate the true feasible region from scenarios generated independently and identically from the actual distribution. In this paper, we consider this problem in a dynamic environment, where the scenarios are assumed to be drawn sequentially from an unknown and time-varying distribution. Such dynamic environments are driven by changing environmental conditions that could be found in many real-world applications such as energy systems. We couple the time-varying distributions using the Wasserstein metric between the sequence of scenario-generating distributions and the actual chance-constrained distribution. Our main results are bounds on the number of samples essential for ensuring the ex-post risk in chance-constrained optimization problems when the underlying feasible set is convex or non-convex. Finally, our results are illustrated on multiple numerical experiments for both types of feasible sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00608v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Apurv Shukla, Qian Zhang, Le Xie</dc:creator>
    </item>
    <item>
      <title>Popov Mirror-Prox for solving Variational Inequalities</title>
      <link>https://arxiv.org/abs/2404.00635</link>
      <description>arXiv:2404.00635v1 Announce Type: new 
Abstract: We consider the mirror-prox algorithm for solving monotone Variational Inequality (VI) problems. As the mirror-prox algorithm is not practically implementable, except in special instances of VIs (such as affine VIs), we consider its implementation with Popov method updates. We provide convergence rate analysis of our proposed method for a monotone VI with a Lipschitz continuous mapping. We establish a convergence rate of $O(1/t)$, in terms of the number $t$ of iterations, for the dual gap function. Simulations on a two player matrix game corroborate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00635v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhishek Chakraborty, Angelia Nedi\'c</dc:creator>
    </item>
    <item>
      <title>A Lane Usage Strategy for General Traffic Access on Bus Lanes under Mixed Traffic Environment</title>
      <link>https://arxiv.org/abs/2404.00697</link>
      <description>arXiv:2404.00697v1 Announce Type: new 
Abstract: The strategy of permitting general traffic to use the bus lane for improved utilization while ensuring bus priority has gained increasingly attention, particularly with the support of vehicle-to-everything technology. In this study, we propose a novel lane usage strategy called Dynamic Spatial-Temporal Priority (DSTP) to ensure bus priority and optimize bus lane usage in a mixed traffic environment. DSTP leverages dynamic methods to identify available spatial-temporal resources in the lane, utilizing signal timing, road information, and vehicle data. A Right-of-Way assignment optimization model is then developed based on these resources to determine which vehicles can enter the bus lane. The model is dynamically enacted using a rolling horizon scheme to accommodate time-varying traffic conditions. Numerical studies have validated the advantages of DSTP, showing maintained bus priority, improved traffic efficiency, reduced fuel consumption, and lower CO2 emissions, especially during periods of high traffic demand and concentrated bus arrivals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00697v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoran Li, Zhenzhou Yuan, Rui Yue, Guangchuan Yang, Chuang Zhu, Siyuan Chen</dc:creator>
    </item>
    <item>
      <title>Computing Proximity Operators of Scale and Signed Permutation Invariant Functions</title>
      <link>https://arxiv.org/abs/2404.00713</link>
      <description>arXiv:2404.00713v1 Announce Type: new 
Abstract: This paper investigates the computation of proximity operators for scale and signed permutation invariant functions. A scale-invariant function remains unchanged under uniform scaling, while a signed permutation invariant function retains its structure despite permutations and sign changes applied to its input variables. Noteworthy examples include the $\ell_0$ function and the ratios of $\ell_1/\ell_2$ and its square, with their proximity operators being particularly crucial in sparse signal recovery. We delve into the properties of scale and signed permutation invariant functions, delineating the computation of their proximity operators into three sequential steps: the $\mathbf{w}$-step, $r$-step, and $d$-step. These steps collectively form a procedure termed as WRD, with the $\mathbf{w}$-step being of utmost importance and requiring careful treatment. Leveraging this procedure, we present a method for explicitly computing the proximity operator of $(\ell_1/\ell_2)^2$ and introduce an efficient algorithm for the proximity operator of $\ell_1/\ell_2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00713v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jianqing Jia, Ashley Prater-Bennette, Lixin Shen</dc:creator>
    </item>
    <item>
      <title>Sparse Recovery: The Square of $\ell_1/\ell_2$ Norms</title>
      <link>https://arxiv.org/abs/2404.00764</link>
      <description>arXiv:2404.00764v1 Announce Type: new 
Abstract: This paper introduces a nonconvex approach to the problem of recovering sparse signals. We propose a novel model, termed the $\tau_2$-model, which utilizes the square of $\ell_1/\ell_2$ norms for sparse recovery. This model is an advancement over the $\ell_0$ norm, which is often computationally intractable and less effective in handling practical scenarios. Our approach is grounded in the concept of effective sparsity, which robustly measures the number of effective coordinates in a signal. We demonstrate that our model is a powerful alternative for sparse signal estimation, with the $\tau_2$-model offering computational advantages and practical applicability. The model's formulation and the accompanying algorithm, based on Dinkelbach's procedure combined with a difference of convex functions strategy, are detailed. We further explore the properties of our model, including the existence of solutions under certain conditions, and discuss the algorithm's convergence properties. Numerical experiments with various sensing matrices are conducted to validate the effectiveness of our model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00764v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianqing Jia, Ashley Prater-Bennette, Lixin Shen, Erin E. Tripp</dc:creator>
    </item>
    <item>
      <title>Convex Network Flows</title>
      <link>https://arxiv.org/abs/2404.00765</link>
      <description>arXiv:2404.00765v1 Announce Type: new 
Abstract: We introduce a general framework for flow problems over hypergraphs. In our problem formulation, which we call the convex flow problem, we have a concave utility function for the net flow at every node and a concave utility function for each edge flow. The objective is to minimize the sum of these utilities, subject to constraints on the flows allowed at each edge, which we only assume to be a convex set. This framework not only includes many classic problems in network optimization, such as max flow, min-cost flow, and multi-commodity flows, but also generalizes these problems to allow, for example, concave edge gain functions. In addition, our framework includes applications spanning a number of fields: optimal power flow over lossy networks, routing and resource allocation in ad-hoc wireless networks, Arrow-Debreu Nash bargaining, and order routing through financial exchanges, among others. We show that the convex flow problem has a dual with a number of interesting interpretations, and that this dual decomposes over the edges of the hypergraph. Using this decomposition, we propose a fast solution algorithm that parallelizes over the edges and admits a clean problem interface. We provide an open source implementation of this algorithm in the Julia programming language, which we show is significantly faster than the state-of-the-art commercial convex solver Mosek.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00765v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Theo Diamandis, Guillermo Angeris, Alan Edelman</dc:creator>
    </item>
    <item>
      <title>An OpenStreetMaps based tool to study the energy demand and emissions impact of electrification of medium and heavy-duty freight trucks</title>
      <link>https://arxiv.org/abs/2404.00805</link>
      <description>arXiv:2404.00805v1 Announce Type: new 
Abstract: In this paper, we present the mathematical formulation of an OpenStreetMaps (OSM) based tool that compares the costs and emissions of long-haul medium and heavy-duty (M&amp;HD) electric and diesel freight trucks, and determines the spatial distribution of added energy demand due to M&amp;HD EVs. The optimization utilizes a combination of information on routes from OSM, utility rate design data across the United States, and freight volume data, to determine these values. In order to deal with the computational complexity of this problem, we formulate the problem as a convex optimization problem that is scalable to a large geographic area. In our analysis, we further evaluate various scenarios of utility rate design (energy charges) and EV penetration rate across different geographic regions and their impact on the operating cost and emissions of the freight trucks. Our approach determines the net emissions reduction benefits of freight electrification by considering the primary energy source in different regions. Such analysis will provide insights to policy makers in designing utility rates for electric vehicle supply equipment (EVSE) operators depending upon the specific geographic region and to electric utilities in deciding infrastructure upgrades based on the spatial distribution of the added energy demand of M&amp;HD EVs. To showcase the results, a case study for the U.S. state of Texas is conducted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00805v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nawaf Nazir, Bowen Huang, Shant Mahserejian</dc:creator>
    </item>
    <item>
      <title>Identifying a piecewise affine signal from its nonlinear observation -- application to DNA replication analysis</title>
      <link>https://arxiv.org/abs/2404.00824</link>
      <description>arXiv:2404.00824v1 Announce Type: new 
Abstract: DNA replication stands as one of the fundamental biological processes crucial for cellular functioning. Recent experimental developments enable the study of replication dynamics at the single-molecule level for complete genomes, facilitating a deeper understanding of its main parameters. In these new data, replication dynamics is reported by the incorporation of an exogenous chemical, whose intra-cellular concentration follows a nonlinear function. The analysis of replication traces thus gives rise to a nonlinear inverse problem, presenting a nonconvex optimization challenge. We demonstrate that under noiseless conditions, the replication dynamics can be uniquely identified by the proposed model. Computing a global solution to this optimization problem is specially challenging because of its multiple local minima. We present the DNA-inverse optimization method that is capable of finding this global solution even in the presence of noise. Comparative analysis against state-of-the-art optimization methods highlights the superior computational efficiency of our approach. DNA-inverse enables the automatic recovery of all configurations of the replication dynamics, which was not possible with previous methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00824v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lage Clara, Pustelnik Nelly, Audit Benjamin, Arbona Jean-Michel, Gribonval R\'emi</dc:creator>
    </item>
    <item>
      <title>Auxiliary-Variable Adaptive Control Lyapunov Barrier Functions for Spatio-Temporally Constrained Safety-Critical Applications</title>
      <link>https://arxiv.org/abs/2404.00881</link>
      <description>arXiv:2404.00881v1 Announce Type: new 
Abstract: Recent work has shown that stabilizing an affine control system while optimizing a quadratic cost subject to state and control constraints can be mapped to a sequence of Quadratic Programs (QPs) using Control Barrier Functions (CBFs) and Control Lyapunov Functions (CLFs). One of the main challenges in this method is that the QPs could easily become infeasible under safety and spatio-temporal constraints with tight control bounds. In our own recent work, we defined Auxiliary-Variable Adaptive CBFs (AVCBFs) to improve the feasibility of the CBF-based QP, while avoiding extensive parameter tuning. In this paper, we consider spatio-temporal constraints as finite-time reachability requirements. In order to satisfy these requirements, we generalize AVCBFs to Auxiliary-Variable Adaptive Control Lyapunov Barrier Functions (AVCLBFs) that work for systems and constraints with arbitrary relative degrees. We show that our method has fewer conflicts with safety and input constraints, and outperforms the state of the art in term of adaptivity and feasibility in solving the QP. We illustrate our approach on an optimal control problem for a unicycle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00881v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Liu, Wei Xiao, Calin A. Belta</dc:creator>
    </item>
    <item>
      <title>Sequential Decision-Making under Uncertainty: A Robust MDPs review</title>
      <link>https://arxiv.org/abs/2404.00940</link>
      <description>arXiv:2404.00940v1 Announce Type: new 
Abstract: This review paper provides an in-depth overview of the evolution and advancements in Robust Markov Decision Processes (RMDPs), a field of paramount importance for its role in sequential decision-making amidst uncertainty. Fueled by advances in robust optimization theory and the increasing applications of reinforcement learning techniques, RMDPs literature has been enriched extensively. The review focuses on the formulation of RMDPs, particularly ambiguity sets modeling, which is central to hedging uncertainty. The review systematically classifies the extant methodologies for RMDP formulation into three principal categories: parametric, moment-based, and discrepancy-based approaches, and comprehensively dissects them. The review further delves into the rectangular assumption, which is essential for the computational tractability of RMDPs yet noted for its potential to engender overly conservative policy outcomes. The review summarizes three popular rectangular forms and presents new proof attesting to the NP-hardness of non-rectangular RMDPs. Out of traditional RMDPs scope, the review also surveys recent efforts without conventional rectangular assumptions and burgeoning research trends within the RMDP community. These studies foster the development of more flexible and practical modeling frameworks and enhance the adaptability and performance of RMDPs in the face of uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00940v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenfan Ou, Sheng Bi</dc:creator>
    </item>
    <item>
      <title>Accelerate Solving Expensive Scheduling by Leveraging Economical Auxiliary Tasks</title>
      <link>https://arxiv.org/abs/2404.01018</link>
      <description>arXiv:2404.01018v1 Announce Type: new 
Abstract: To fully leverage the multi-task optimization paradigm for accelerating the solution of expensive scheduling problems, this study has effectively tackled three vital concerns. The primary issue is identifying auxiliary tasks that closely resemble the original expensive task. We suggested a sampling strategy based on job importance, creating a compact matrix by extracting crucial rows from the entire problem specification matrix of the expensive task. This matrix serves as an economical auxiliary task. Mathematically, we proved that this economical auxiliary task bears similarity to its corresponding expensive task. The subsequent concern revolves around making auxiliary tasks more cost-effective. We determined the sampling proportions for the entire problem specification matrix through factorial design experiments, resulting in a more compact auxiliary task. With a reduced search space and shorter function evaluation time, it can rapidly furnish high-quality transferable information for the primary task. The last aspect involves designing transferable deep information from auxiliary tasks. We regarded the job priorities in the (sub-) optimal solutions to the economical auxiliary task as transferable invariants. By adopting a partial solution patching strategy, we augmented specificity knowledge onto the common knowledge to adapt to the target expensive task. The strategies devised for constructing task pairs and facilitating knowledge transfer, when incorporated into various evolutionary multitasking algorithms, were utilized to address expensive instances of permutation flow shop scheduling. Extensive experiments and statistical comparisons have validated that, with the collaborative synergy of these strategies, the performance of evolutionary multitasking algorithms is significantly enhanced in handling expensive scheduling tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01018v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Minshuo Li, Bo Liu, Bin Xin, Liang Feng, Peng Li</dc:creator>
    </item>
    <item>
      <title>Multiple Joint Chance Constraints Approximation for Uncertainty Modeling in Dispatch Problems</title>
      <link>https://arxiv.org/abs/2404.01167</link>
      <description>arXiv:2404.01167v1 Announce Type: new 
Abstract: Uncertainty modeling has become increasingly important in power system decision-making. The widely-used tractable uncertainty modeling method-chance constraints with Conditional Value at Risk (CVaR) approximation, can be overconservative and even turn an originally feasible problem into an infeasible one. This paper proposes a new approximation method for multiple joint chance constraints (JCCs) to model the uncertainty in dispatch problems, which solves the conservativeness and potential infeasibility concerns of CVaR. The proposed method is also convenient for controlling the risk levels of different JCCs, which is necessary for power system applications since different resources may be affected by varying degrees of uncertainty or have different importance to the system. We then formulate a data-driven distributionally robust chance-constrained programming model for the power system multiperiod dispatch problem and leverage the proposed approximation method to solve it. In the numerical simulations, two small general examples clearly demonstrate the superiority of the proposed method, and the results of the multiperiod dispatch problem on IEEE test cases verify its practicality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01167v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilin Wen, Yi Guo, Zechun Hu, Gabriela Hug</dc:creator>
    </item>
    <item>
      <title>Hundreds of grocery outlets needed across the United States to achieve walkable cities</title>
      <link>https://arxiv.org/abs/2404.01209</link>
      <description>arXiv:2404.01209v1 Announce Type: new 
Abstract: The notion of the $x$-minute city is again popular in urban planning, but the practical implications of developing walkable neighborhoods have not been rigorously explored. What is the scale of the challenge that cities needing to retrofit face? Where should new stores or amenities be located? For 500 cities in the United States, we explored how many additional supermarkets would be required to achieve various levels of $x$-minute access and where new stores should be located so that this access is equally-distributed. Our method is unique because it combines a novel measure of equality with a new model that optimally locates amenities for inequality-minimizing community access. We found that 25% of the studied cities could reach 15-minute access by adding five or fewer stores, while only 10% of the cities could even achieve 5-minute average access when using neighborhood centroids as potential sites; the cities that could, on average, required more than 100 stores each. This work provides a tool for cities to use evidenced-based planning to efficiently retrofit in order to enable active transport, benefiting both the climate and their residents' health. It also highlights the major challenge facing our cities due to the existing and ongoing car-dependent urban design that renders these goals unfeasible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01209v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Drew Horton, Tom Logan, Daphne Skipper, Emily Speakman</dc:creator>
    </item>
    <item>
      <title>Gradient Methods for Scalable Multi-value Electricity Network Expansion Planning</title>
      <link>https://arxiv.org/abs/2404.01255</link>
      <description>arXiv:2404.01255v1 Announce Type: new 
Abstract: We consider multi-value expansion planning (MEP), a general bilevel optimization model in which a planner optimizes arbitrary functions of the dispatch outcome in the presence of a partially controllable, competitive electricity market. The MEP problem can be used to jointly plan various grid assets, such as transmission, generation, and battery storage capacities; examples include identifying grid investments that minimize emissions in the absence of a carbon tax, maximizing the profit of a portfolio of renewable investments and long-term energy contracts, or reducing price inequities between different grid stakeholders. The MEP problem, however, is in general nonconvex, making it difficult to solve exactly for large real-world systems. Therefore, we propose a fast stochastic implicit gradient-based heuristic method that scales well to large networks with many scenarios. We use a strong duality reformulation and the McCormick envelope to provide a lower bound on the performance of our algorithm via convex relaxation. We test the performance of our method on a large model of the U.S. Western Interconnect and demonstrate that it scales linearly with network size and number of scenarios and can be efficiently parallelized on large machines. We find that for medium-sized 16 hour cases, gradient descent on average finds a 5.3x lower objective value in 16.5x less time compared to a traditional reformulation-based approach solved with an interior point method. We conclude with a large example in which we jointly plan transmission, generation, and storage for a 768 hour case on 100 node system, showing that emissions penalization leads to additional 40.0% reduction in carbon intensity at an additional cost of $17.1/MWh.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01255v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anthony Degleris, Abbas El Gamal, Ram Rajagopal</dc:creator>
    </item>
    <item>
      <title>Dynamics and Optimization in Spatially Distributed Electrical Vehicle Charging</title>
      <link>https://arxiv.org/abs/2404.01259</link>
      <description>arXiv:2404.01259v1 Announce Type: new 
Abstract: We consider a spatially distributed demand for electrical vehicle recharging, that must be covered by a fixed set of charging stations. Arriving EVs receive feedback on transport times to each station, and waiting times at congested ones, based on which they make a selfish selection. This selection determines total arrival rates in station queues, which are represented by a fluid state; departure rates are modeled under the assumption that clients have a given sojourn time in the system. The resulting differential equation system is analyzed with tools of optimization. We characterize the equilibrium as the solution to a specific convex program, which has connections to optimal transport problems, and also with road traffic theory. In particular a price of anarchy appears with respect to a social planner's allocation. From a dynamical perspective, global convergence to equilibrium is established, with tools of Lagrange duality and Lyapunov theory. An extension of the model that makes customer demand elastic to observed delays is also presented, and analyzed with extensions of the optimization machinery. Simulations to illustrate the global behavior are presented, which also help validate the model beyond the fluid approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01259v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fernando Paganini, Andres Ferragut</dc:creator>
    </item>
    <item>
      <title>Non-asymptotic Global Convergence Rates of BFGS with Exact Line Search</title>
      <link>https://arxiv.org/abs/2404.01267</link>
      <description>arXiv:2404.01267v1 Announce Type: new 
Abstract: In this paper, we explore the non-asymptotic global convergence rates of the Broyden-Fletcher-Goldfarb-Shanno (BFGS) method implemented with exact line search. Notably, due to Dixon's equivalence result, our findings are also applicable to other quasi-Newton methods in the convex Broyden class employing exact line search, such as the Davidon-Fletcher-Powell (DFP) method. Specifically, we focus on problems where the objective function is strongly convex with Lipschitz continuous gradient and Hessian. Our results hold for any initial point and any symmetric positive definite initial Hessian approximation matrix. The analysis unveils a detailed three-phase convergence process, characterized by distinct linear and superlinear rates, contingent on the iteration progress. Additionally, our theoretical findings demonstrate the trade-offs between linear and superlinear convergence rates for BFGS when we modify the initial Hessian approximation matrix, a phenomenon further corroborated by our numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01267v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiujiang Jin, Ruichen Jiang, Aryan Mokhtari</dc:creator>
    </item>
    <item>
      <title>MicroHD: An Accuracy-Driven Optimization of Hyperdimensional Computing Algorithms for TinyML systems</title>
      <link>https://arxiv.org/abs/2404.00039</link>
      <description>arXiv:2404.00039v1 Announce Type: cross 
Abstract: Hyperdimensional computing (HDC) is emerging as a promising AI approach that can effectively target TinyML applications thanks to its lightweight computing and memory requirements. Previous works on HDC showed that limiting the standard 10k dimensions of the hyperdimensional space to much lower values is possible, reducing even more HDC resource requirements. Similarly, other studies demonstrated that binary values can be used as elements of the generated hypervectors, leading to significant efficiency gains at the cost of some degree of accuracy degradation. Nevertheless, current optimization attempts do not concurrently co-optimize HDC hyper-parameters, and accuracy degradation is not directly controlled, resulting in sub-optimal HDC models providing several applications with unacceptable output qualities. In this work, we propose MicroHD, a novel accuracy-driven HDC optimization approach that iteratively tunes HDC hyper-parameters, reducing memory and computing requirements while ensuring user-defined accuracy levels. The proposed method can be applied to HDC implementations using different encoding functions, demonstrates good scalability for larger HDC workloads, and achieves compression and efficiency gains up to 200x when compared to baseline implementations for accuracy degradations lower than 1%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00039v1</guid>
      <category>cs.PF</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Flavio Ponzina, Tajana Rosing</dc:creator>
    </item>
    <item>
      <title>On contention resolution for the hypergraph matching, knapsack, and $k$-column sparse packing problems</title>
      <link>https://arxiv.org/abs/2404.00041</link>
      <description>arXiv:2404.00041v1 Announce Type: cross 
Abstract: The contention resolution framework is a versatile rounding technique used as a part of the relaxation and rounding approach for solving constrained submodular function maximization problems. We apply this framework to the hypergraph matching, knapsack, and $k$-column sparse packing problems. In the hypergraph matching setting, we adapt the technique of Guruganesh, Lee (2018) to non-constructively prove that the correlation gap is at least $\frac{1-e^{-k}}{k}$ and provide a monotone $\left(b,\frac{1-e^{-bk}}{bk}\right)$-balanced contention resolution scheme, generalizing the results of Bruggmann, Zenklusen (2019). For the knapsack problem, we prove that the correlation gap of instances where exactly $k$ copies of each item fit into the knapsack is at least $\frac{1-e^{-2}}{2}$ and provide several monotone contention resolution schemes: a $\frac{1-e^{-2}}{2}$-balanced scheme for instances where all item sizes are strictly bigger than $\frac{1}{2}$, a $\frac{4}{9}$-balanced scheme for instances where all item sizes are at most $\frac{1}{2}$, and a $0.279$-balanced scheme for instances with arbitrary item sizes. For $k$-column sparse packing integer programs, we slightly modify the $\left(2k+o\left(k\right)\right)$-approximation algorithm for $k$-CS-PIP based on the strengthened LP relaxation presented in Brubach et al. (2019) to obtain a $\frac{1}{4k+o\left(k\right)}$-balanced contention resolution scheme and hence a $\left(4k+o\left(k\right)\right)$-approximation algorithm for $k$-CS-PIP based on the natural LP relaxation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00041v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ivan Sergeev</dc:creator>
    </item>
    <item>
      <title>A short introduction to geometric control theory</title>
      <link>https://arxiv.org/abs/2404.00059</link>
      <description>arXiv:2404.00059v1 Announce Type: cross 
Abstract: The goal of this expository paper is to present the basics of geometric control theory suitable for advanced undergraduate or beginning graduate students with a solid background in advanced calculus and ordinary differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00059v1</guid>
      <category>math.HO</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Slobodan N. Simi\'c</dc:creator>
    </item>
    <item>
      <title>Fast OMP for Exact Recovery and Sparse Approximation</title>
      <link>https://arxiv.org/abs/2404.00146</link>
      <description>arXiv:2404.00146v1 Announce Type: cross 
Abstract: Orthogonal Matching Pursuit (OMP) has been a powerful method in sparse signal recovery and approximation. However OMP suffers computational issue when the signal has large number of non-zeros. This paper advances OMP in two fronts: it offers a fast algorithm for the orthogonal projection of the input signal at each iteration, and a new selection criterion for making the greedy choice, which reduces the number of iterations it takes to recover the signal. The proposed modifications to OMP directly reduce the computational complexity. Experiment results show significant improvement over the classical OMP in computation time. The paper also provided a sufficient condition for exact recovery under the new greedy choice criterion. For general signals that may not have sparse representations, the paper provides a bound for the approximation error. The approximation error is at the same order as OMP but is obtained within fewer iterations and less time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00146v1</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huiyuan Yu, Jia He, Maggie Cheng</dc:creator>
    </item>
    <item>
      <title>Precision game engineering through reshaping strategic payoffs</title>
      <link>https://arxiv.org/abs/2404.00153</link>
      <description>arXiv:2404.00153v1 Announce Type: cross 
Abstract: Nash equilibrium is a key concept in game theory fundamental for elucidating the equilibrium state of strategic interactions, finding applications in diverse fields such as economics, political science, and biology. However, the Nash equilibrium may not always align with the optimal or desired outcomes within a system. This article introduces a novel game engineering framework that tweaks strategic payoffs within a game to achieve a desired Nash equilibrium while averting undesired ones. Leveraging mixed-integer linear programming, this framework identifies intricate combinations of players and strategies and optimal perturbations to their payoffs that enable the shift from undesirable Nash equilibria to more favorable ones. We demonstrate the effectiveness and scalability of our approach on games of varying complexity, ranging from simple prototype games such as the Prisoner's Dilemma and Snowdrift games with two or more players to complex game configurations with as high as $10^6$ entries in the payoff matrix. These studies showcase the capability of this framework in efficiently identifying the alternative ways of reshaping strategic payoffs to secure desired Nash equilibria and preclude the undesired equilibrium states. Our game engineering framework offers a versatile toolkit for precision strategic decision-making with far-reaching implications across diverse domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00153v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elie Eshoa (Computer Science Department, Harvard John A. Paulson School of Engineering and Applied Sciences, Boston, MA, USA, Harvard Medical School, Boston, MA, USA), Ali R. Zomorrodi (Mucosal Immunology and Biology Research Center, Pediatrics Department, Massachusetts General Hospital, Boston, MA, USA, Harvard Medical School, Boston, MA, USA)</dc:creator>
    </item>
    <item>
      <title>Managing power balance and reserve feasibility in the AC unit commitment problem</title>
      <link>https://arxiv.org/abs/2404.00200</link>
      <description>arXiv:2404.00200v1 Announce Type: cross 
Abstract: Incorporating the AC power flow equations into unit commitment models has the potential to avoid costly corrective actions required by less accurate power flow approximations. However, research on unit commitment with AC power flow constraints has been limited to a few relatively small test networks. This work investigates large-scale AC unit commitment problems for the day-ahead market and develops decomposition algorithms capable of obtaining high-quality solutions at industry-relevant scales. The results illustrate that a simple algorithm that only seeks to satisfy unit commitment, reserve, and AC power balance constraints can obtain surprisingly high-quality solutions to this AC unit commitment problem. However, a naive strategy that prioritizes reserve feasibility leads to AC infeasibility, motivating the need to design heuristics that can effectively balance reserve and AC feasibility. Finally, this work explores a parallel decomposition strategy that allows the proposed algorithm to obtain feasible solutions on large cases within the two hour time limit required by typical day-ahead market operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00200v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Parker, Carleton Coffrin</dc:creator>
    </item>
    <item>
      <title>Discrete Natural Evolution Strategies</title>
      <link>https://arxiv.org/abs/2404.00208</link>
      <description>arXiv:2404.00208v1 Announce Type: cross 
Abstract: Natural evolution strategies are a class of approximate-gradient black-box optimizers that have been successfully used for continuous parameter spaces. In this paper, we derive NES algorithms for discrete parameter spaces and demonstrate their effectiveness in tasks involving discrete parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00208v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmad Ayaz Amin</dc:creator>
    </item>
    <item>
      <title>Inverse Optimal Cardano-Lyapunov Feedback for PDEs with Convection</title>
      <link>https://arxiv.org/abs/2404.00370</link>
      <description>arXiv:2404.00370v1 Announce Type: cross 
Abstract: We consider the problem of inverse optimal control design for systems that are not affine in the control. In particular, we consider some classes of partial differential equations (PDEs) with quadratic convection and counter-convection, for which the L2 norm is a control Lyapunov function (CLF) whose derivative has either a depressed cubic or a quadratic dependence in the boundary control input. We also consider diffusive PDEs with or without linear convection, for which a weighted L2 norm is a CLF whose derivative has a quadratic dependence in the control input. For each structure on the derivative of the CLF, we achieve inverse optimality with respect to a meaningful cost functional. For the case where the derivative of the CLF has a depressed cubic dependence in the control, we construct a cost functional for which the unique minimizer is the unique real root of a cubic polynomial: the Cardano-Lyapunov controller. When the derivative of the CLF is quadratic in the control, we construct a cost functional that is minimized by two distinct feedback laws, that correspond to the two distinct real roots of a quadratic equation. We show how to switch from one root to the other to reduce the control effort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00370v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamed Camil Belhadjoudja, Miroslav Krstic, Mohamed Maghenem, Emmanuel Witrant</dc:creator>
    </item>
    <item>
      <title>Communication Efficient Distributed Training with Distributed Lion</title>
      <link>https://arxiv.org/abs/2404.00438</link>
      <description>arXiv:2404.00438v1 Announce Type: cross 
Abstract: The Lion optimizer has been a promising competitor with the AdamW for training large AI models, with advantages on memory, computation, and sample efficiency. In this paper, we introduce Distributed Lion, an innovative adaptation of Lion for distributed training environments. Leveraging the sign operator in Lion, our Distributed Lion only requires communicating binary or lower-precision vectors between workers to the center server, significantly reducing the communication cost. Our theoretical analysis confirms Distributed Lion's convergence properties. Empirical results demonstrate its robustness across a range of tasks, worker counts, and batch sizes, on both vision and language problems. Notably, Distributed Lion attains comparable performance to standard Lion or AdamW optimizers applied on aggregated gradients, but with significantly reduced communication bandwidth. This feature is particularly advantageous for training large models. In addition, we also demonstrate that Distributed Lion presents a more favorable performance-bandwidth balance compared to existing efficient distributed methods such as deep gradient compression and ternary gradients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00438v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bo Liu, Lemeng Wu, Lizhang Chen, Kaizhao Liang, Jiaxu Zhu, Chen Liang, Raghuraman Krishnamoorthi, Qiang Liu</dc:creator>
    </item>
    <item>
      <title>Competition-Aware Decision-Making Approach for Mobile Robots in Racing Scenarios</title>
      <link>https://arxiv.org/abs/2404.00520</link>
      <description>arXiv:2404.00520v1 Announce Type: cross 
Abstract: This paper presents a game-theoretic strategy for racing, where the autonomous ego agent seeks to block a racing opponent that aims to overtake the ego agent. After a library of trajectory candidates and an associated reward matrix are constructed, the optimal trajectory in terms of maximizing the cumulative reward over the planning horizon is determined based on the level-K reasoning framework. In particular, the level of the opponent is estimated online according to its behavior over a past window and is then used to determine the trajectory for the ego agent. Taking into account that the opponent may change its level and strategy during the decision process of the ego agent, we introduce a trajectory mixing strategy that blends the level-K optimal trajectory with a fail-safe trajectory. The overall algorithm was tested and evaluated in various simulated racing scenarios, which also includes human-in-the-loop experiments. Comparative analysis against the conventional level-K framework demonstrates the superiority of our proposed approach in terms of overtake-blocking success rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00520v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyoungtae Ji, Sangjae Bae, Nan Li, Kyoungseok Han</dc:creator>
    </item>
    <item>
      <title>Accelerated Parameter-Free Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2404.00666</link>
      <description>arXiv:2404.00666v1 Announce Type: cross 
Abstract: We propose a method that achieves near-optimal rates for smooth stochastic convex optimization and requires essentially no prior knowledge of problem parameters. This improves on prior work which requires knowing at least the initial distance to optimality d0. Our method, U-DoG, combines UniXGrad (Kavis et al., 2019) and DoG (Ivgi et al., 2023) with novel iterate stabilization techniques. It requires only loose bounds on d0 and the noise magnitude, provides high probability guarantees under sub-Gaussian noise, and is also near-optimal in the non-smooth case. Our experiments show consistent, strong performance on convex problems and mixed results on neural network training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00666v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Itai Kreisler, Maor Ivgi, Oliver Hinder, Yair Carmon</dc:creator>
    </item>
    <item>
      <title>Designing robust trajectories by lobe dynamics in low-dimensional Hamiltonian systems</title>
      <link>https://arxiv.org/abs/2404.00721</link>
      <description>arXiv:2404.00721v1 Announce Type: cross 
Abstract: Modern space missions with uncrewed spacecraft require robust trajectory design to connect multiple chaotic orbits by small controls. To address this issue, we propose a novel control scheme to design robust trajectories by leveraging a geometrical structure in chaotic zones, known as {\it lobe}. Our scheme shows that appropriately selected lobes reveal possible paths to traverse chaotic zones in a short time. The effectiveness of our method is demonstrated through trajectory design in both the standard map and Hill's equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00721v1</guid>
      <category>nlin.CD</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>physics.class-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Naoki Hiraiwa, Mai Bando, Isaia Nisoli, Yuzuru Sato</dc:creator>
    </item>
    <item>
      <title>Off-the-grid regularisation for Poisson inverse problems</title>
      <link>https://arxiv.org/abs/2404.00810</link>
      <description>arXiv:2404.00810v1 Announce Type: cross 
Abstract: Off-the-grid regularisation has been extensively employed over the last decade in the context of ill-posed inverse problems formulated in the continuous setting of the space of Radon measures $\mathcal{M}(\mathcal{X})$. These approaches enjoy convexity and counteract the discretisation biases as well the numerical instabilities typical of their discrete counterparts. In the framework of sparse reconstruction of discrete point measures (sum of weighted Diracs), a Total Variation regularisation norm in $\mathcal{M}(\mathcal{X})$ is typically combined with an $L^2$ data term modelling additive Gaussian noise. To asses the framework of off-the-grid regularisation in the presence of signal-dependent Poisson noise, we consider in this work a variational model coupling the Total Variation regularisation with a Kullback-Leibler data term under a non-negativity constraint. Analytically, we study the optimality conditions of the composite functional and analyse its dual problem. Then, we consider an homotopy strategy to select an optimal regularisation parameter and use it within a Sliding Frank-Wolfe algorithm. Several numerical experiments on both 1D/2D simulated and real 3D fluorescent microscopy data are reported.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00810v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marta Lazzaretti, Claudio Estatico, Alejandro Melero Carrillo, Luca Calatroni</dc:creator>
    </item>
    <item>
      <title>Designing gradient coils with the shape derivative and the closed B-spline curves</title>
      <link>https://arxiv.org/abs/2404.00967</link>
      <description>arXiv:2404.00967v1 Announce Type: cross 
Abstract: This study proposes a versatile and efficient optimisation method for discrete coils that induce a magnetic field by their steady currents. The prime target is gradient coils for MRI (Magnetic Resonance Imaging). The derivative (gradient) of the $z$-component the magnetic field, which is calculated by the Biot--Savart's law, with respect to the $z$-coordinate in the Cartesian $xyz$ coordinate system is considered as the objective function. Then, the derivative of the objective function with respect to a change of coils in shape is formulated according to the concept of shape optimisation. The resulting shape derivative (as well as the Biot--Savart's law) is smoothly discretised with the closed B-spline curves. In this case, the control points (CPs) of the curves are naturally selected as the design variables. As a consequence, the shape derivative is discretised to the sensitivities of the objective function with respect to the CPs. Those sensitivities are available to solve the present shape-optimisation problem with a certain gradient-based nonlinear-programming solver. The numerical examples exhibit the mathematical reliability, computational efficiency, and engineering applicability of the proposed methodology based on the shape derivative/sensitivities and the closed B-spline curves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00967v1</guid>
      <category>physics.med-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Toru Takahashi</dc:creator>
    </item>
    <item>
      <title>Mitigating Transient Bullwhip Effects Under Imperfect Demand Forecasts</title>
      <link>https://arxiv.org/abs/2404.01090</link>
      <description>arXiv:2404.01090v1 Announce Type: cross 
Abstract: Motivated by how forecast errors exacerbate order fluctuations in supply chains, we use tools from robust control theory to characterize and compute the worst-case order fluctuation experienced by an individual supply chain vendor under bounded forecast errors and demand fluctuations. Building on existing discrete time, linear time-invariant (LTI) models of supply chains, we separately model forecast error and demand fluctuations as inputs to the inventory dynamics. We then define a transient Bullwhip measure to evaluate the vendor's worst-case order fluctuation and show that for bounded forecast errors and demand fluctuations, this measure is equivalent to the disturbance to control peak gain. To compute the controller that minimizes the worst-case peak gain, we formulate an optimization problem with bilinear matrix inequalities and show that solving this problem is equivalent to minimizing a quasi-convex function on a bounded domain. In contrast to the existing Bullwhip measure in literature, the transient Bullwhip measure has an explicit dependency on the forecast error and does not need the forecast to be a deterministic function of the demand history. This explicit dependency enables us to separately quantify the transient Bullwhip measure's sensitivity to forecast error and demand fluctuations. We empirically verify our model for vendors with non-zero perishable rates and order backlogging rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01090v1</guid>
      <category>cs.ET</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah H. Q. Li, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Finite Sample Frequency Domain Identification</title>
      <link>https://arxiv.org/abs/2404.01100</link>
      <description>arXiv:2404.01100v1 Announce Type: cross 
Abstract: We study non-parametric frequency-domain system identification from a finite-sample perspective. We assume an open loop scenario where the excitation input is periodic and consider the Empirical Transfer Function Estimate (ETFE), where the goal is to estimate the frequency response at certain desired (evenly-spaced) frequencies, given input-output samples. We show that under sub-Gaussian colored noise (in time-domain) and stability assumptions, the ETFE estimates are concentrated around the true values. The error rate is of the order of $\mathcal{O}((d_{\mathrm{u}}+\sqrt{d_{\mathrm{u}}d_{\mathrm{y}}})\sqrt{M/N_{\mathrm{tot}}})$, where $N_{\mathrm{tot}}$ is the total number of samples, $M$ is the number of desired frequencies, and $d_{\mathrm{u}},\,d_{\mathrm{y}}$ are the dimensions of the input and output signals respectively. This rate remains valid for general irrational transfer functions and does not require a finite order state-space representation. By tuning $M$, we obtain a $N_{\mathrm{tot}}^{-1/3}$ finite-sample rate for learning the frequency response over all frequencies in the $ \mathcal{H}_{\infty}$ norm. Our result draws upon an extension of the Hanson-Wright inequality to semi-infinite matrices. We study the finite-sample behavior of ETFE in simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01100v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anastasios Tsiamis, Mohamed Abdalmoaty, Roy S. Smith, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Collaborative Pareto Set Learning in Multiple Multi-Objective Optimization Problems</title>
      <link>https://arxiv.org/abs/2404.01224</link>
      <description>arXiv:2404.01224v1 Announce Type: cross 
Abstract: Pareto Set Learning (PSL) is an emerging research area in multi-objective optimization, focusing on training neural networks to learn the mapping from preference vectors to Pareto optimal solutions. However, existing PSL methods are limited to addressing a single Multi-objective Optimization Problem (MOP) at a time. When faced with multiple MOPs, this limitation not only leads to significant inefficiencies but also fails to exploit the potential synergies across varying MOPs. In this paper, we propose a Collaborative Pareto Set Learning (CoPSL) framework, which simultaneously learns the Pareto sets of multiple MOPs in a collaborative manner. CoPSL employs an architecture consisting of shared and MOP-specific layers, where shared layers aim to capture common relationships among MOPs collaboratively, and MOP-specific layers process these relationships to generate solution sets for each MOP. This collaborative approach enables CoPSL to efficiently learn the Pareto sets of multiple MOPs in a single run while leveraging the relationships among various MOPs. To further understand these relationships, we experimentally demonstrate that there exist shareable representations among MOPs. Leveraging these collaboratively shared representations can effectively improve the capability to approximate Pareto sets. Extensive experiments underscore the superior efficiency and robustness of CoPSL in approximating Pareto sets compared to state-of-the-art approaches on a variety of synthetic and real-world MOPs. Code is available at https://github.com/ckshang/CoPSL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01224v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chikai Shang, Rongguang Ye, Jiaqi Jiang, Fangqing Gu</dc:creator>
    </item>
    <item>
      <title>New logarithmic step size for stochastic gradient descent</title>
      <link>https://arxiv.org/abs/2404.01257</link>
      <description>arXiv:2404.01257v1 Announce Type: cross 
Abstract: In this paper, we propose a novel warm restart technique using a new logarithmic step size for the stochastic gradient descent (SGD) approach. For smooth and non-convex functions, we establish an $O(\frac{1}{\sqrt{T}})$ convergence rate for the SGD. We conduct a comprehensive implementation to demonstrate the efficiency of the newly proposed step size on the ~FashionMinst,~ CIFAR10, and CIFAR100 datasets. Moreover, we compare our results with nine other existing approaches and demonstrate that the new logarithmic step size improves test accuracy by $0.9\%$ for the CIFAR100 dataset when we utilize a convolutional neural network (CNN) model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01257v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s11704-023-3245-z</arxiv:DOI>
      <arxiv:journal_reference>Frontiers of Computer Science, 2025</arxiv:journal_reference>
      <dc:creator>M. Soheil Shamaee, S. Fathi Hafshejani, Z. Saeidian</dc:creator>
    </item>
    <item>
      <title>Markovian Foundations for Quasi-Stochastic Approximation with Applications to Extremum Seeking Control</title>
      <link>https://arxiv.org/abs/2207.06371</link>
      <description>arXiv:2207.06371v4 Announce Type: replace 
Abstract: This paper concerns quasi-stochastic approximation (QSA) to solve root finding problems commonly found in applications to optimization and reinforcement learning. The general constant gain algorithm may be expressed as the time-inhomogeneous ODE $ \frac{d}{dt}\Theta_t=\alpha f_t (\Theta_t)$, with state process $\Theta$ evolving on $\mathbb{R}^d$. Theory is based on an almost periodic vector field, so that in particular the time average of $f_t(\theta)$ defines the time-homogeneous mean vector field $\bar{f} \colon \mathbb{R}^d \to \mathbb{R}^d$ with $\bar{f}(\theta^*)=0$. Under smoothness assumptions on the functions involved, the following exact representation is obtained: \[\frac{d}{dt}\Theta_t=\alpha[\bar{f}(\Theta_t)-\alpha\bar\Upsilon_t+\alpha^2\mathcal{W}_t^0+\alpha\frac{d}{dt}\mathcal{W}_t^1+\frac{d^2}{dt^2}\mathcal{W}_t^2]\] along with formulae for the smooth signals $\{\bar \Upsilon_t , \mathcal{W}_t^i : i=0, 1, 2\}$. This new representation, combined with new conditions for ultimate boundedness, has many applications for furthering the theory of QSA and its applications, including the following implications that are developed in this paper:
  (i) A proof that the estimation error $\|\Theta_t-\theta^*\|$ is of order $O(\alpha)$, but can be reduced to $O(\alpha^2)$ using a second order linear filter.
  (ii) In application to extremum seeking control, it is found that the results do not apply because the standard algorithms are not Lipschitz continuous. A new approach is presented to ensure that the required Lipschitz bounds hold, and from this we obtain stability, transient bounds, and asymptotic bias of order $O(\alpha^2)$, and asymptotic variance of order $O(\alpha^4)$.
  (iii) It is in general possible to obtain better than $O(\alpha)$ bounds on error in traditional stochastic approximation when there is Markovian noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.06371v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caio Kalil Lauand, Sean Meyn</dc:creator>
    </item>
    <item>
      <title>Approximating Hessian matrices using Bayesian inference: a new approach for quasi-Newton methods in stochastic optimization</title>
      <link>https://arxiv.org/abs/2208.00441</link>
      <description>arXiv:2208.00441v2 Announce Type: replace 
Abstract: Using quasi-Newton methods in stochastic optimization is not a trivial task given the difficulty of extracting curvature information from the noisy gradients. Moreover, pre-conditioning noisy gradient observations tend to amplify the noise. We propose a Bayesian approach to obtain a Hessian matrix approximation for stochastic optimization that minimizes the secant equations residue while retaining the extreme eigenvalues between a specified range. Thus, the proposed approach assists stochastic gradient descent to converge to local minima without augmenting gradient noise. We propose maximizing the log posterior using the Newton-CG method. Numerical results on a stochastic quadratic function and an $\ell_2$-regularized logistic regression problem are presented. In all the cases tested, our approach improves the convergence of stochastic gradient descent, compensating for the overhead of solving the log posterior maximization. In particular, pre-conditioning the stochastic gradient with the inverse of our Hessian approximation becomes more advantageous the larger the condition number of the problem is.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.00441v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andre Carlon, Luis Espath, Raul Tempone</dc:creator>
    </item>
    <item>
      <title>Machine Learning-Augmented Optimization of Large Bilevel and Two-stage Stochastic Programs: Application to Cycling Network Design</title>
      <link>https://arxiv.org/abs/2209.09404</link>
      <description>arXiv:2209.09404v3 Announce Type: replace 
Abstract: Motivated by a cycling infrastructure planning application, we present a machine learning approach to solving bilevel programs with a large number of independent followers, which as a special case includes two-stage stochastic programming. We propose an optimization model that explicitly considers a sampled subset of followers and exploits a machine learning model to estimate the objective values of unsampled followers. Unlike existing approaches, we embed machine learning model training into the optimization problem, which allows us to employ follower features that cannot be represented using leader decisions. We prove bounds on the optimality gap of the generated leader decision as measured by the original objective that considers the full follower set. We develop follower sampling algorithms to tighten the bounds and a representation learning approach to learn follower features, which are used as inputs to our machine learning model. Through numerical studies, we show that our approach generates leader decisions of higher quality compared to baselines. Finally, we perform a real-world case study in Toronto, Canada, where we solve a cycling network design problem with over one million followers. Compared to the current practice, our approach improves a transportation metric by 19.2% and can lead to a potential cost saving of $18M.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.09404v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timothy C. Y. Chan, Bo Lin, Shoshanna Saxe</dc:creator>
    </item>
    <item>
      <title>Towards a Multimodal Charging Network: Joint Planning of Charging Stations and Battery Swapping Stations for Electrified Ride-Hailing Fleets</title>
      <link>https://arxiv.org/abs/2212.12677</link>
      <description>arXiv:2212.12677v3 Announce Type: replace 
Abstract: This paper considers a multimodal charging network in which charging stations and battery swapping stations are jointly built to support an electric ride-hailing fleet synergistically. Our argument is based on the observation that charging an EV is a time-consuming burden, and battery swapping faces scaling issues due to its deployment costs. However, charging stations are cost-effective, making them ideal for scaling up EV fleets, while battery swapping stations offer quick turnaround and can be deployed in tandem with charging stations to improve fleet utilization and reduce operational costs. To fulfill this vision, we consider a ride-hailing platform that jointly builds charging and battery swapping stations to support an EV fleet. An optimization model is proposed to capture the platform's planning and operational decisions. In particular, the model incorporates essential components such as elastic passenger demand, spatial charging equilibrium, charging and swapping congestion, etc. The overall problem is formulated as a nonconcave program. Instead of pursuing the globally optimal solution, we establish a tight upper bound through relaxation and decomposition, allowing us to evaluate the solution optimality even in the absence of concavity. Through case studies for Manhattan, New York City, we find that joint planning of charging and battery swapping stations outperforms deploying only one of them, yielding a total profit that is 11.7% higher than swapping-only deployment under a limited budget, and 17.5% higher than charging-only deployment under a sufficient budget. These results underscore the complementary benefit between charging and battery swapping facilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.12677v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhijie Lai, Sen Li</dc:creator>
    </item>
    <item>
      <title>Similarity, Compression and Local Steps: Three Pillars of Efficient Communications for Distributed Variational Inequalities</title>
      <link>https://arxiv.org/abs/2302.07615</link>
      <description>arXiv:2302.07615v2 Announce Type: replace 
Abstract: Variational inequalities are a broad and flexible class of problems that includes minimization, saddle point, and fixed point problems as special cases. Therefore, variational inequalities are used in various applications ranging from equilibrium search to adversarial learning. With the increasing size of data and models, today's instances demand parallel and distributed computing for real-world machine learning problems, most of which can be represented as variational inequalities. Meanwhile, most distributed approaches have a significant bottleneck - the cost of communications. The three main techniques to reduce the total number of communication rounds and the cost of one such round are the similarity of local functions, compression of transmitted information, and local updates. In this paper, we combine all these approaches. Such a triple synergy did not exist before for variational inequalities and saddle problems, nor even for minimization problems. The methods presented in this paper have the best theoretical guarantees of communication complexity and are significantly ahead of other methods for distributed variational inequalities. The theoretical results are confirmed by adversarial learning experiments on synthetic and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.07615v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Beznosikov, Martin Tak\'a\v{c}, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Gauss-Newton Temporal Difference Learning with Nonlinear Function Approximation</title>
      <link>https://arxiv.org/abs/2302.13087</link>
      <description>arXiv:2302.13087v2 Announce Type: replace 
Abstract: In this paper, a Gauss-Newton Temporal Difference (GNTD) learning method is proposed to solve the Q-learning problem with nonlinear function approximation. In each iteration, our method takes one Gauss-Newton (GN) step to optimize a variant of Mean-Squared Bellman Error (MSBE), where target networks are adopted to avoid double sampling. Inexact GN steps are analyzed so that one can safely and efficiently compute the GN updates by cheap matrix iterations. Under mild conditions, non-asymptotic finite-sample convergence to the globally optimal Q function is derived for various nonlinear function approximations. In particular, for neural network parameterization with relu activation, GNTD achieves an improved sample complexity of $\tilde{\mathcal{O}}(\varepsilon^{-1})$, as opposed to the $\mathcal{\mathcal{O}}(\varepsilon^{-2})$ sample complexity of the existing neural TD methods. An $\tilde{\mathcal{O}}(\varepsilon^{-1.5})$ sample complexity of GNTD is also established for general smooth function approximations. We validate our method via extensive experiments in several RL benchmarks, where GNTD exhibits both higher rewards and faster convergence than TD-type methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.13087v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhifa Ke, Junyu Zhang, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>First Order Methods with Markovian Noise: from Acceleration to Variational Inequalities</title>
      <link>https://arxiv.org/abs/2305.15938</link>
      <description>arXiv:2305.15938v2 Announce Type: replace 
Abstract: This paper delves into stochastic optimization problems that involve Markovian noise. We present a unified approach for the theoretical analysis of first-order gradient methods for stochastic optimization and variational inequalities. Our approach covers scenarios for both non-convex and strongly convex minimization problems. To achieve an optimal (linear) dependence on the mixing time of the underlying noise sequence, we use the randomized batching scheme, which is based on the multilevel Monte Carlo method. Moreover, our technique allows us to eliminate the limiting assumptions of previous research on Markov noise, such as the need for a bounded domain and uniformly bounded stochastic gradients. Our extension to variational inequalities under Markovian noise is original. Additionally, we provide lower bounds that match the oracle complexity of our method in the case of strongly convex optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.15938v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>https://proceedings.neurips.cc/paper_files/paper/2023/hash/8c3e38ce55a0fa44bc325bc6fdb7f4e5-Abstract-Conference.html</arxiv:journal_reference>
      <dc:creator>Aleksandr Beznosikov, Sergey Samsonov, Marina Sheshukova, Alexander Gasnikov, Alexey Naumov, Eric Moulines</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimization Algorithms for Problems with Controllable Biased Oracles</title>
      <link>https://arxiv.org/abs/2306.07810</link>
      <description>arXiv:2306.07810v3 Announce Type: replace 
Abstract: Motivated by multiple emerging applications in machine learning, we consider an optimization problem in a general form where the gradient of the objective function is available through a biased stochastic oracle. We assume a bias-control parameter can reduce the bias magnitude, however, a lower bias requires more computation/samples. For instance, for two applications on stochastic composition optimization and policy optimization for infinite-horizon Markov decision processes, we show that the bias follows a power law and exponential decay, respectively, as functions of their corresponding bias control parameters. For problems with such gradient oracles, the paper proposes stochastic algorithms that adjust the bias-control parameter throughout the iterations. We analyze the nonasymptotic performance of the proposed algorithms in the nonconvex regime and establish their sample or bias-control computation complexities to obtain a stationary point. Finally, we numerically evaluate the performance of the proposed algorithms over three applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.07810v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yin Liu, Sam Davanloo Tajbakhsh</dc:creator>
    </item>
    <item>
      <title>Hyperspectral super-resolution via low rank tensor triple decomposition</title>
      <link>https://arxiv.org/abs/2306.10489</link>
      <description>arXiv:2306.10489v2 Announce Type: replace 
Abstract: Hyperspectral image (HSI) and multispectral image (MSI) fusion aims at producing a super-resolution image (SRI). In this paper, we establish a nonconvex optimization model for image fusion problems through low-rank tensor triple decomposition. Using the L-BFGS approach, we develop a first-order optimization algorithm for obtaining the desired super-resolution image (TTDSR). Furthermore, two detailed methods are provided for calculating the gradient of the objective function. With the aid of the Kurdyka-Lojasiewicz property, the iterative sequence is proved to converge to a stationary point. Finally, experimental results on different datasets show the effectiveness of our proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10489v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaofei Cui, Jingya Chang</dc:creator>
    </item>
    <item>
      <title>Feasibility-Guaranteed Safety-Critical Control with Applications to Heterogeneous Platoons</title>
      <link>https://arxiv.org/abs/2310.00238</link>
      <description>arXiv:2310.00238v4 Announce Type: replace 
Abstract: This paper studies safety and feasibility guarantees for systems with tight control bounds. It has been shown that stabilizing an affine control system while optimizing a quadratic cost and satisfying state and control constraints can be mapped to a sequence of Quadratic Programs (QPs) using Control Barrier Functions (CBF) and Control Lyapunov Functions (CLF). One of the main challenges in this method is that the QP could easily become infeasible under safety constraints of high relative degree, especially under tight control bounds. Recent work focused on deriving sufficient conditions for guaranteeing feasibility. The existing results are case-dependent. In this paper, we consider the general case. We define a feasibility constraint and propose a new type of CBF to enforce it. Our method guarantees the feasibility of the above mentioned QPs, while satisfying safety requirements. We demonstrate the proposed method on an Adaptive Cruise Control (ACC) problem for a heterogeneous platoon with tight control bounds, and compare our method to existing CBF-CLF approaches. The results show that our proposed approach can generate gradually transitioned control (without abrupt changes) with guaranteed feasibility and safety.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00238v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Liu, Wei Xiao, Calin A. Belta</dc:creator>
    </item>
    <item>
      <title>Prescribed Robustness in Optimal Power Flow</title>
      <link>https://arxiv.org/abs/2310.02957</link>
      <description>arXiv:2310.02957v2 Announce Type: replace 
Abstract: For a timely decarbonization of our economy, power systems need to accommodate increasing numbers of clean but stochastic resources. This requires new operational methods that internalize this stochasticity to ensure safety and efficiency. This paper proposes a novel approach to compute adaptive safety intervals for each stochastic resource that internalize power flow physics and optimize the expected cost of system operations, making them ``prescriptive''. The resulting intervals are interpretable and can be used in a tractable robust optimal power flow problem as uncertainty sets. We use stochastic gradient descent with differentiable optimization layers to compute a mapping that obtains these intervals from a given vector of context parameters that captures the expected system state. We demonstrate and discuss the proposed approach on two case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02957v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Mieth, H. Vincent Poor</dc:creator>
    </item>
    <item>
      <title>Ito Diffusion Approximation of Universal Ito Chains for Sampling, Optimization and Boosting</title>
      <link>https://arxiv.org/abs/2310.06081</link>
      <description>arXiv:2310.06081v2 Announce Type: replace 
Abstract: In this work, we consider rather general and broad class of Markov chains, Ito chains, that look like Euler-Maryama discretization of some Stochastic Differential Equation. The chain we study is a unified framework for theoretical analysis. It comes with almost arbitrary isotropic and state-dependent noise instead of normal and state-independent one as in most related papers. Moreover, in our chain the drift and diffusion coefficient can be inexact in order to cover wide range of applications as Stochastic Gradient Langevin Dynamics, sampling, Stochastic Gradient Descent or Stochastic Gradient Boosting. We prove the bound in $W_{2}$-distance between the laws of our Ito chain and corresponding differential equation. These results improve or cover most of the known estimates. And for some particular cases, our analysis is the first.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06081v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksei Ustimenko, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>A minimax optimal control approach for robust neural ODEs</title>
      <link>https://arxiv.org/abs/2310.17584</link>
      <description>arXiv:2310.17584v3 Announce Type: replace 
Abstract: In this paper, we address the adversarial training of neural ODEs from a robust control perspective. This is an alternative to the classical training via empirical risk minimization, and it is widely used to enforce reliable outcomes for input perturbations. Neural ODEs allow the interpretation of deep neural networks as discretizations of control systems, unlocking powerful tools from control theory for the development and the understanding of machine learning. In this specific case, we formulate the adversarial training with perturbed data as a minimax optimal control problem, for which we derive first order optimality conditions in the form of Pontryagin's Maximum Principle. We provide a novel interpretation of robust training leading to an alternative weighted technique, which we test on a low-dimensional classification task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17584v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cristina Cipriani, Alessandro Scagliotti, Tobias W\"ohrer</dc:creator>
    </item>
    <item>
      <title>Bound Tightening using Rolling-Horizon Decomposition for Neural Network Verification</title>
      <link>https://arxiv.org/abs/2401.05280</link>
      <description>arXiv:2401.05280v3 Announce Type: replace 
Abstract: Neural network verification aims at providing formal guarantees on the output of trained neural networks, to ensure their robustness against adversarial examples and enable their deployment in safety-critical applications. This paper introduces a new approach to neural network verification using a novel mixed-integer programming rolling-horizon decomposition method. The algorithm leverages the layered structure of neural networks, by employing optimization-based bound-tightening on smaller sub-graphs of the original network in a rolling-horizon fashion. This strategy strikes a balance between achieving tighter bounds and ensuring the tractability of the underlying mixed-integer programs. Extensive numerical experiments, conducted on instances from the VNN-COMP benchmark library, demonstrate that the proposed approach yields significantly improved bounds compared to existing effective bound propagation methods. Notably, the parallelizable nature of the proposed method proves effective in solving open verification problems. Our code is built and released as part of the open-source mathematical modeling tool Gravity (https://github.com/coin-or/Gravity), which is extended to support generic neural network models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05280v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoruo Zhao, Hassan Hijazi, Haydn Jones, Juston Moore, Mathieu Tanneau, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>A Deep Learning Method for Optimal Investment Under Relative Performance Criteria Among Heterogeneous Agents</title>
      <link>https://arxiv.org/abs/2402.07365</link>
      <description>arXiv:2402.07365v2 Announce Type: replace 
Abstract: Graphon games have been introduced to study games with many players who interact through a weighted graph of interaction. By passing to the limit, a game with a continuum of players is obtained, in which the interactions are through a graphon. In this paper, we focus on a graphon game for optimal investment under relative performance criteria, and we propose a deep learning method. The method builds upon two key ingredients: first, a characterization of Nash equilibria by forward-backward stochastic differential equations and, second, recent advances of machine learning algorithms for stochastic differential games. We provide numerical experiments on two different financial models. In each model, we compare the effect of several graphons, which correspond to different structures of interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07365v2</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathieu Lauri\`ere, Ludovic Tangpi, Xuchen Zhou</dc:creator>
    </item>
    <item>
      <title>A robust optimization approach model for a multi-vaccine multi-echelon supply chain</title>
      <link>https://arxiv.org/abs/2403.16173</link>
      <description>arXiv:2403.16173v3 Announce Type: replace 
Abstract: This research investigates a multi-product, multi-echelon, and multi-period vaccine supply chain network model under uncertainty and quality inspection errors. The objective function seeks optimizing the total cost of the supply chain. Moreover, the proposed model is formulated as a mixed integer linear programming problem under multiple sources of uncertain parameters including demand, inspection errors, vaccine waste generated in healthcare centers, and defective treatment rate of vaccine waste. To provide meaningful solutions that are robust against future fluctuation of parameters, the robust optimization approach is utilized to incorporate the decision maker risk attitude under different type of uncertainty sets. Namely, box, polyhedral and combination of interval polyhedral. The performance of the proposed model is demonstrated through an illustrative example. The results show the effect of different types of uncertainties on the overall objective function. Managerial insights and research implications in terms of vaccine supply chain is advised and future research directions are proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16173v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Abderrahmen Bouchenine, Ismail Almaraj</dc:creator>
    </item>
    <item>
      <title>Chattering Phenomena in Time-Optimal Control for High-Order Chain-of-Integrators Systems with Full State Constraints</title>
      <link>https://arxiv.org/abs/2403.17675</link>
      <description>arXiv:2403.17675v3 Announce Type: replace 
Abstract: Time-optimal control for high-order chain-of-integrators systems with full state constraints remains an open and challenging problem in the optimal control theory domain. The behaviors of optimal control in high-order problems lack precision characterization, even where the existence of the chattering phenomenon remains unknown and overlooked. This paper establishes a theoretical framework for chattering phenomena in the considered problem, providing novel findings on the uniqueness of state constraints inducing chattering, the upper bound on switching times in an unconstrained arc during chattering, and the convergence of states and costates to the chattering limit point. For the first time, this paper proves the existence of the chattering phenomenon in the considered problem. The chattering optimal control for 4th order problems with velocity constraints is precisely solved, providing an approach to plan strictly time-optimal snap-limited trajectories. Other cases of order $n\leq4$ are proved not to allow chattering. The conclusions correct the longstanding misconception in the industry regarding the time-optimality of S-shaped trajectories with minimal switching times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17675v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunan Wang, Chuxiong Hu, Zeyang Li, Yujie Lin, Shize Lin, Suqin He</dc:creator>
    </item>
    <item>
      <title>Provably Efficient Exploration in Policy Optimization</title>
      <link>https://arxiv.org/abs/1912.05830</link>
      <description>arXiv:1912.05830v4 Announce Type: replace-cross 
Abstract: While policy-based reinforcement learning (RL) achieves tremendous successes in practice, it is significantly less understood in theory, especially compared with value-based RL. In particular, it remains elusive how to design a provably efficient policy optimization algorithm that incorporates exploration. To bridge such a gap, this paper proposes an Optimistic variant of the Proximal Policy Optimization algorithm (OPPO), which follows an ``optimistic version'' of the policy gradient direction. This paper proves that, in the problem of episodic Markov decision process with linear function approximation, unknown transition, and adversarial reward with full-information feedback, OPPO achieves $\tilde{O}(\sqrt{d^2 H^3 T} )$ regret. Here $d$ is the feature dimension, $H$ is the episode horizon, and $T$ is the total number of steps. To the best of our knowledge, OPPO is the first provably efficient policy optimization algorithm that explores.</description>
      <guid isPermaLink="false">oai:arXiv.org:1912.05830v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Cai, Zhuoran Yang, Chi Jin, Zhaoran Wang</dc:creator>
    </item>
    <item>
      <title>Can Temporal-Difference and Q-Learning Learn Representation? A Mean-Field Theory</title>
      <link>https://arxiv.org/abs/2006.04761</link>
      <description>arXiv:2006.04761v2 Announce Type: replace-cross 
Abstract: Temporal-difference and Q-learning play a key role in deep reinforcement learning, where they are empowered by expressive nonlinear function approximators such as neural networks. At the core of their empirical successes is the learned feature representation, which embeds rich observations, e.g., images and texts, into the latent space that encodes semantic structures. Meanwhile, the evolution of such a feature representation is crucial to the convergence of temporal-difference and Q-learning.
  In particular, temporal-difference learning converges when the function approximator is linear in a feature representation, which is fixed throughout learning, and possibly diverges otherwise. We aim to answer the following questions: When the function approximator is a neural network, how does the associated feature representation evolve? If it converges, does it converge to the optimal one?
  We prove that, utilizing an overparameterized two-layer neural network, temporal-difference and Q-learning globally minimize the mean-squared projected Bellman error at a sublinear rate. Moreover, the associated feature representation converges to the optimal one, generalizing the previous analysis of Cai et al. (2019) in the neural tangent kernel regime, where the associated feature representation stabilizes at the initial one. The key to our analysis is a mean-field perspective, which connects the evolution of a finite-dimensional parameter to its limiting counterpart over an infinite-dimensional Wasserstein space. Our analysis generalizes to soft Q-learning, which is further connected to policy gradient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2006.04761v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yufeng Zhang, Qi Cai, Zhuoran Yang, Yongxin Chen, Zhaoran Wang</dc:creator>
    </item>
    <item>
      <title>Variational Transport: A Convergent Particle-BasedAlgorithm for Distributional Optimization</title>
      <link>https://arxiv.org/abs/2012.11554</link>
      <description>arXiv:2012.11554v2 Announce Type: replace-cross 
Abstract: We consider the optimization problem of minimizing a functional defined over a family of probability distributions, where the objective functional is assumed to possess a variational form. Such a distributional optimization problem arises widely in machine learning and statistics, with Monte-Carlo sampling, variational inference, policy optimization, and generative adversarial network as examples. For this problem, we propose a novel particle-based algorithm, dubbed as variational transport, which approximately performs Wasserstein gradient descent over the manifold of probability distributions via iteratively pushing a set of particles. Specifically, we prove that moving along the geodesic in the direction of functional gradient with respect to the second-order Wasserstein distance is equivalent to applying a pushforward mapping to a probability distribution, which can be approximated accurately by pushing a set of particles. Specifically, in each iteration of variational transport, we first solve the variational problem associated with the objective functional using the particles, whose solution yields the Wasserstein gradient direction. Then we update the current distribution by pushing each particle along the direction specified by such a solution. By characterizing both the statistical error incurred in estimating the Wasserstein gradient and the progress of the optimization algorithm, we prove that when the objective function satisfies a functional version of the Polyak-\L{}ojasiewicz (PL) (Polyak, 1963) and smoothness conditions, variational transport converges linearly to the global minimum of the objective functional up to a certain statistical error, which decays to zero sublinearly as the number of particles goes to infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.11554v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuoran Yang, Yufeng Zhang, Yongxin Chen, Zhaoran Wang</dc:creator>
    </item>
    <item>
      <title>Wasserstein Flow Meets Replicator Dynamics: A Mean-Field Analysis of Representation Learning in Actor-Critic</title>
      <link>https://arxiv.org/abs/2112.13530</link>
      <description>arXiv:2112.13530v2 Announce Type: replace-cross 
Abstract: Actor-critic (AC) algorithms, empowered by neural networks, have had significant empirical success in recent years. However, most of the existing theoretical support for AC algorithms focuses on the case of linear function approximations, or linearized neural networks, where the feature representation is fixed throughout training. Such a limitation fails to capture the key aspect of representation learning in neural AC, which is pivotal in practical problems. In this work, we take a mean-field perspective on the evolution and convergence of feature-based neural AC. Specifically, we consider a version of AC where the actor and critic are represented by overparameterized two-layer neural networks and are updated with two-timescale learning rates. The critic is updated by temporal-difference (TD) learning with a larger stepsize while the actor is updated via proximal policy optimization (PPO) with a smaller stepsize. In the continuous-time and infinite-width limiting regime, when the timescales are properly separated, we prove that neural AC finds the globally optimal policy at a sublinear rate. Additionally, we prove that the feature representation induced by the critic network is allowed to evolve within a neighborhood of the initial one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.13530v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yufeng Zhang, Siyu Chen, Zhuoran Yang, Michael I. Jordan, Zhaoran Wang</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning from Partial Observation: Linear Function Approximation with Provable Sample Efficiency</title>
      <link>https://arxiv.org/abs/2204.09787</link>
      <description>arXiv:2204.09787v3 Announce Type: replace-cross 
Abstract: We study reinforcement learning for partially observed Markov decision processes (POMDPs) with infinite observation and state spaces, which remains less investigated theoretically. To this end, we make the first attempt at bridging partial observability and function approximation for a class of POMDPs with a linear structure. In detail, we propose a reinforcement learning algorithm (Optimistic Exploration via Adversarial Integral Equation or OP-TENET) that attains an $\epsilon$-optimal policy within $O(1/\epsilon^2)$ episodes. In particular, the sample complexity scales polynomially in the intrinsic dimension of the linear structure and is independent of the size of the observation and state spaces.
  The sample efficiency of OP-TENET is enabled by a sequence of ingredients: (i) a Bellman operator with finite memory, which represents the value function in a recursive manner, (ii) the identification and estimation of such an operator via an adversarial integral equation, which features a smoothed discriminator tailored to the linear structure, and (iii) the exploration of the observation and state spaces via optimism, which is based on quantifying the uncertainty in the adversarial integral equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.09787v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Cai, Zhuoran Yang, Zhaoran Wang</dc:creator>
    </item>
    <item>
      <title>Online Convex Optimization with Unbounded Memory</title>
      <link>https://arxiv.org/abs/2210.09903</link>
      <description>arXiv:2210.09903v5 Announce Type: replace-cross 
Abstract: Online convex optimization (OCO) is a widely used framework in online learning. In each round, the learner chooses a decision in a convex set and an adversary chooses a convex loss function, and then the learner suffers the loss associated with their current decision. However, in many applications the learner's loss depends not only on the current decision but on the entire history of decisions until that point. The OCO framework and its existing generalizations do not capture this, and they can only be applied to many settings of interest after a long series of approximation arguments. They also leave open the question of whether the dependence on memory is tight because there are no non-trivial lower bounds. In this work we introduce a generalization of the OCO framework, "Online Convex Optimization with Unbounded Memory", that captures long-term dependence on past decisions. We introduce the notion of $p$-effective memory capacity, $H_p$, that quantifies the maximum influence of past decisions on present losses. We prove an $O(\sqrt{H_p T})$ upper bound on the policy regret and a matching (worst-case) lower bound. As a special case, we prove the first non-trivial lower bound for OCO with finite memory \citep{anavaHM2015online}, which could be of independent interest, and also improve existing upper bounds. We demonstrate the broad applicability of our framework by using it to derive regret bounds, and to improve and simplify existing regret bound derivations, for a variety of online learning problems including online linear control and an online variant of performative prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.09903v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raunak Kumar, Sarah Dean, Robert Kleinberg</dc:creator>
    </item>
    <item>
      <title>Dynamic Regularized Sharpness Aware Minimization in Federated Learning: Approaching Global Consistency and Smooth Landscape</title>
      <link>https://arxiv.org/abs/2305.11584</link>
      <description>arXiv:2305.11584v2 Announce Type: replace-cross 
Abstract: In federated learning (FL), a cluster of local clients are chaired under the coordination of the global server and cooperatively train one model with privacy protection. Due to the multiple local updates and the isolated non-iid dataset, clients are prone to overfit into their own optima, which extremely deviates from the global objective and significantly undermines the performance. Most previous works only focus on enhancing the consistency between the local and global objectives to alleviate this prejudicial client drifts from the perspective of the optimization view, whose performance would be prominently deteriorated on the high heterogeneity. In this work, we propose a novel and general algorithm {\ttfamily FedSMOO} by jointly considering the optimization and generalization targets to efficiently improve the performance in FL. Concretely, {\ttfamily FedSMOO} adopts a dynamic regularizer to guarantee the local optima towards the global objective, which is meanwhile revised by the global Sharpness Aware Minimization (SAM) optimizer to search for the consistent flat minima. Our theoretical analysis indicates that {\ttfamily FedSMOO} achieves fast $\mathcal{O}(1/T)$ convergence rate with low generalization bound. Extensive numerical studies are conducted on the real-world dataset to verify its peerless efficiency and excellent generality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.11584v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>PMLR 202:32991-33013, 2023</arxiv:journal_reference>
      <dc:creator>Yan Sun, Li Shen, Shixiang Chen, Liang Ding, Dacheng Tao</dc:creator>
    </item>
    <item>
      <title>Information Theoretically Optimal Sample Complexity of Learning Dynamical Directed Acyclic Graphs</title>
      <link>https://arxiv.org/abs/2308.16859</link>
      <description>arXiv:2308.16859v2 Announce Type: replace-cross 
Abstract: In this article, the optimal sample complexity of learning the underlying interactions or dependencies of a Linear Dynamical System (LDS) over a Directed Acyclic Graph (DAG) is studied. We call such a DAG underlying an LDS as dynamical DAG (DDAG). In particular, we consider a DDAG where the nodal dynamics are driven by unobserved exogenous noise sources that are wide-sense stationary (WSS) in time but are mutually uncorrelated, and have the same {power spectral density (PSD)}. Inspired by the static DAG setting, a metric and an algorithm based on the PSD matrix of the observed time series are proposed to reconstruct the DDAG. It is shown that the optimal sample complexity (or length of state trajectory) needed to learn the DDAG is $n=\Theta(q\log(p/q))$, where $p$ is the number of nodes and $q$ is the maximum number of parents per node. To prove the sample complexity upper bound, a concentration bound for the PSD estimation is derived, under two different sampling strategies. A matching min-max lower bound using generalized Fano's inequality also is provided, thus showing the order optimality of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.16859v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mishfad Shaikh Veedu, Deepjyoti Deka, Murti V. Salapaka</dc:creator>
    </item>
    <item>
      <title>A Comparison between Markov Chain and Koopman Operator Based Data-Driven Modeling of Dynamical Systems</title>
      <link>https://arxiv.org/abs/2310.05508</link>
      <description>arXiv:2310.05508v2 Announce Type: replace-cross 
Abstract: Markov chain-based modeling and Koopman operator-based modeling are two popular frameworks for data-driven modeling of dynamical systems. They share notable similarities from a computational and practitioner's perspective, especially for modeling autonomous systems. The first part of this paper aims to elucidate these similarities. For modeling systems with control inputs, the models produced by the two approaches differ. The second part of this paper introduces these models and their corresponding control design methods. We illustrate the two approaches and compare them in terms of model accuracy and computational efficiency for both autonomous and controlled systems in numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05508v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saeid Tafazzol, Nan Li, Ilya Kolmanovsky, Dimitar Filev</dc:creator>
    </item>
    <item>
      <title>Fun with Flags: Robust Principal Directions via Flag Manifolds</title>
      <link>https://arxiv.org/abs/2401.04071</link>
      <description>arXiv:2401.04071v2 Announce Type: replace-cross 
Abstract: Principal component analysis (PCA), along with its extensions to manifolds and outlier contaminated data, have been indispensable in computer vision and machine learning. In this work, we present a unifying formalism for PCA and its variants, and introduce a framework based on the flags of linear subspaces, ie a hierarchy of nested linear subspaces of increasing dimension, which not only allows for a common implementation but also yields novel variants, not explored previously. We begin by generalizing traditional PCA methods that either maximize variance or minimize reconstruction error. We expand these interpretations to develop a wide array of new dimensionality reduction algorithms by accounting for outliers and the data manifold. To devise a common computational approach, we recast robust and dual forms of PCA as optimization problems on flag manifolds. We then integrate tangent space approximations of principal geodesic analysis (tangent-PCA) into this flag-based framework, creating novel robust and dual geodesic PCA variations. The remarkable flexibility offered by the 'flagification' introduced here enables even more algorithmic variants identified by specific flag types. Last but not least, we propose an effective convergent solver for these flag-formulations employing the Stiefel manifold. Our empirical results on both real-world and synthetic scenarios, demonstrate the superiority of our novel algorithms, especially in terms of robustness to outliers on manifolds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04071v2</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan Mankovich, Gustau Camps-Valls, Tolga Birdal</dc:creator>
    </item>
  </channel>
</rss>
