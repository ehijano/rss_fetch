<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Oct 2024 01:56:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Distributed Asynchronous Mixed-Integer Linear Programming with Feasibility Guarantees</title>
      <link>https://arxiv.org/abs/2410.10828</link>
      <description>arXiv:2410.10828v1 Announce Type: new 
Abstract: In this paper we solve mixed-integer linear programs (MILPs) via distributed asynchronous saddle point computation. This work is motivated by the MILPs being able to model problems in multi-agent autonomy, such as task assignment problems and trajectory planning with collision avoidance constraints in multi-robot systems. To solve a MILP, we relax it with a linear program approximation. We first show that if the linear program relaxation satisfies Slater's condition, then relaxing the problem, solving it, and rounding the relaxed solution produces a point that is guaranteed to satisfy the constraints of the original MILP. Next, we form a Lagrangian saddle point problem that is equivalent to the linear program relaxation, and then we regularize the Lagrangian in both the primal and dual spaces. Doing so gives a regularized Lagrangian that is strongly convex-strongly concave. We then develop a parallelized algorithm to compute saddle points of the regularized Lagrangian, and we show that it is tolerant to asynchrony in the computations and communications of primal and dual variables. Suboptimality bounds and convergence rates are presented for convergence to a saddle point. The suboptimality bound accounts for (i) the error induced by regularizing the Lagrangian and (ii) the suboptimality gap between the solution to the original MILP and the solution to its relaxed form. Simulation results illustrate these theoretical developments in practice, and show that relaxation and regularization combined typically have only a mild impact on the suboptimality of the solution obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10828v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luke Fina, Christopher Petersen, Matthew Hale</dc:creator>
    </item>
    <item>
      <title>Complexity and numerical experiments of a new adaptive generic proximal bundle method</title>
      <link>https://arxiv.org/abs/2410.11066</link>
      <description>arXiv:2410.11066v1 Announce Type: new 
Abstract: This paper develops an adaptive generic proximal bundle method, shows its complexity, and presents numerical experiments comparing this method with two bundle methods on a set of optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11066v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Guigues, Renato Monteiro, Benoit Tran</dc:creator>
    </item>
    <item>
      <title>Recursively Feasible Stochastic Model Predictive Control for Time-Varying Linear Systems Subject to Unbounded Disturbances</title>
      <link>https://arxiv.org/abs/2410.11107</link>
      <description>arXiv:2410.11107v1 Announce Type: new 
Abstract: Model predictive control solves a constrained optimization problem online in order to compute an implicit closed-loop control policy. Recursive feasibility -- guaranteeing that the optimal control problem will have a solution at every time step -- is an important property to guarantee the success of any model predictive control approach. However, recursive feasibility is difficult to establish in a stochastic setting and, in particular, in the presence of disturbances having unbounded support (e.g., Gaussian noise). The problem is further exacerbated for time-varying systems, in which case recursive feasibility must be established also in a robust sense, over all possible future time-varying parameter values, as well as in a stochastic sense, over all potential disturbance realizations. This work presents a method for ensuring the recursive feasibility of a convex, affine-feedback stochastic model predictive control problem formulation for systems with time-varying system matrices and unbounded disturbances using ideas from covariance steering stochastic model predictive control. It is additionally shown that the proposed approach ensures the closed-loop operation of the system will satisfy the desired chance constraints in practice, and that the stochastic model predictive control problem may be formulated as a convex program so that it may be efficiently solved in real-time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11107v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob W. Knaup, Panagiotis Tsiotras</dc:creator>
    </item>
    <item>
      <title>Analysis of Wind Power Integration in Electricity Markets LMP Pricing</title>
      <link>https://arxiv.org/abs/2410.11139</link>
      <description>arXiv:2410.11139v1 Announce Type: new 
Abstract: Wind energy has emerged as one of the most vital and economically viable forms of renewable energy. The integration of wind energy sources into power grids across the globe has been increasing substantially, largely due to the higher levels of uncertainty associated with wind energy compared to other renewable energy sources. This study focuses on analyzing the Locational Marginal Pricing (LMP) market model, with particular emphasis on the integration of wind power plants into substations. Furthermore, it examines a two-stage stochastic model for electricity markets employing LMP pricing, utilizing the Optimal Power Flow (OPF) method for the analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11139v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Narin Nemati, Amin Ahmadi Kasani</dc:creator>
    </item>
    <item>
      <title>RPCBF: Constructing Safety Filters Robust to Model Error and Disturbances via Policy Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2410.11157</link>
      <description>arXiv:2410.11157v1 Announce Type: new 
Abstract: Control Barrier Functions (CBFs) have proven to be an effective tool for performing safe control synthesis for nonlinear systems. However, guaranteeing safety in the presence of disturbances and input constraints for high relative degree systems is a difficult problem. In this work, we propose the Robust Policy CBF (RPCBF), a practical method of constructing CBF approximations that is easy to implement and robust to disturbances via the estimation of a value function. We demonstrate the effectiveness of our method in simulation on a variety of high relative degree input-constrained systems. Finally, we demonstrate the benefits of RPCBF in compensating for model errors on a hardware quadcopter platform by treating the model errors as disturbances. The project page can be found at https://oswinso.xyz/rpcbf.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11157v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Luzia Knoedler, Oswin So, Ji Yin, Mitchell Black, Zachary Serlin, Panagiotis Tsiotras, Javier Alonso-Mora, Chuchu Fan</dc:creator>
    </item>
    <item>
      <title>Subdifferential Calculus for Ordered Set-Valued Mappings between Infinite-Dimensional Spaces</title>
      <link>https://arxiv.org/abs/2410.11362</link>
      <description>arXiv:2410.11362v1 Announce Type: new 
Abstract: The paper is devoted to developing subdifferential theory for set-valued mappings taking values in ordered infinite-dimensional spaces. This study is motivated by applications to problems of vector and set optimization with various constraints in infinite dimensions. The main results establish new sum and chain rules for major subdifferential constructions associated with ordered set-valued mappings under appropriate qualification and sequentially normal compactness conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11362v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boris S. Mordukhovich, Oanh Nguyen</dc:creator>
    </item>
    <item>
      <title>Markov-Nash equilibria in mean-field games under model uncertainty</title>
      <link>https://arxiv.org/abs/2410.11652</link>
      <description>arXiv:2410.11652v1 Announce Type: new 
Abstract: We propose and analyze a framework for mean-field Markov games under model uncertainty. In this framework, a state-measure flow describing the collective behavior of a population affects the given reward function as well as the unknown transition kernel of the representative agent. The agent's objective is to choose an optimal Markov policy in order to maximize her worst-case expected reward, where worst-case refers to the most adverse scenario among all transition kernels considered to be feasible to describe the unknown true law of the environment. We prove the existence of a mean-field equilibrium under model uncertainty, where the agent chooses the optimal policy that maximizes the worst-case expected reward, and the state-measure flow aligns with the agent's state distribution under the optimal policy and the worst-case transition kernel. Moreover, we prove that for suitable multi-agent Markov games under model uncertainty the optimal policy from the mean-field equilibrium forms an approximate Markov-Nash equilibrium whenever the number of agents is large enough.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11652v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Langner, Ariel Neufeld, Kyunghyun Park</dc:creator>
    </item>
    <item>
      <title>Global non-asymptotic super-linear convergence rates of regularized proximal quasi-Newton methods on non-smooth composite problems</title>
      <link>https://arxiv.org/abs/2410.11676</link>
      <description>arXiv:2410.11676v1 Announce Type: new 
Abstract: In this paper, we propose two regularized proximal quasi-Newton methods with symmetric rank-1 update of the metric (SR1 quasi-Newton) to solve non-smooth convex additive composite problems. Both algorithms avoid using line search or other trust region strategies. For each of them, we prove a super-linear convergence rate that is independent of the initialization of the algorithm. The cubic regularized method achieves a rate of order $\left(\frac{C}{N^{1/2}}\right)^{N/2}$, where $N$ is the number of iterations and $C$ is some constant, and the other gradient regularized method shows a rate of the order $\left(\frac{C}{N^{1/4}}\right)^{N/2}$. To the best of our knowledge, these are the first global non-asymptotic super-linear convergence rates for regularized quasi-Newton methods and regularized proximal quasi-Newton methods. The theoretical properties are also demonstrated in two applications from machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11676v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shida Wang, Jalal Fadili, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Improving the Accuracy of DC Optimal Power Flow Formulations via Parameter Optimization</title>
      <link>https://arxiv.org/abs/2410.11725</link>
      <description>arXiv:2410.11725v1 Announce Type: new 
Abstract: DC Optimal Power Flow (DC-OPF) problems optimize the generators' active power setpoints while satisfying constraints based on the DC power flow linearization. The computational tractability advantages of DC-OPF problems come at the expense of inaccuracies relative to AC Optimal Power Flow (AC-OPF) problems which accurately model the nonlinear steady-state behavior of power grids. This paper proposes an algorithm that significantly improves the accuracy of the generators' active power setpoints from DC-OPF problems with respect to the corresponding AC-OPF problems over a specified range of operating conditions. Using sensitivity information in a machine learning-inspired methodology, this algorithm tunes coefficient and bias parameters in the DC power flow approximation to improve the accuracy of the resulting DC-OPF solutions. Employing the Truncated Newton Conjugate-Gradient (TNC) method -- a Quasi-Newton optimization technique -- this parameter tuning occurs during an offline training phase, with the resulting parameters then used in online computations. Numerical results underscore the algorithm's efficacy with accuracy improvements in squared two-norm and $\infty$-norm losses of up to $90\%$ and $79\%$, respectively, relative to traditional DC-OPF formulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11725v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Babak Taheri, Daniel K. Molzahn</dc:creator>
    </item>
    <item>
      <title>Analysis of a toy model for optimal crop protection</title>
      <link>https://arxiv.org/abs/2410.11733</link>
      <description>arXiv:2410.11733v1 Announce Type: new 
Abstract: In this paper we investigate an optimal control problem involving a toy model for the protection on a crop field. Precisely, we consider a protection on a crop field and we want to place intervention zones represented by a control, in order to maximise the protection on the field during a given period. Using a relaxation method, we prove that there exists a control which maximises the protection and, moreover, it must be a bang-bang control. Furthermore, with additional assumptions on the crop field geometry, some results on the shape of the optimal intervention are proved using comparison results for elliptic equations via Schwarz and Steiner symmetrizations. Finally, some numerical simulations are performed in order to illustrate those results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11733v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis Almeida, Aymeric Jacob de Cordemoy, Ayman Moussa, Nicolas Vauchelet</dc:creator>
    </item>
    <item>
      <title>Shape optimization for variational inequalities: the scalar Tresca friction problem</title>
      <link>https://arxiv.org/abs/2410.11750</link>
      <description>arXiv:2410.11750v1 Announce Type: new 
Abstract: This paper investigates, without any regularization or penalization procedure, a shape optimization problem involving a simplified friction phenomena modeled by a scalar Tresca friction law. Precisely, using tools from convex and variational analysis such as proximal operators and the notion of twice epi-differentiability, we prove that the solution to a scalar Tresca friction problem admits a directional derivative with respect to the shape which moreover coincides with the solution to a boundary value problem involving Signorini-type unilateral conditions. Then we explicitly characterize the shape gradient of the corresponding energy functional and we exhibit a descent direction. Finally numerical simulations are performed to solve the corresponding energy minimization problem under a volume constraint which shows the applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11750v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samir Adly, Lo\"ic Bourdin, Fabien Caubet, Aymeric Jacob de Cordemoy</dc:creator>
    </item>
    <item>
      <title>Sensitivity analysis of a scalar mechanical contact problem with perturbation of the Tresca's friction law</title>
      <link>https://arxiv.org/abs/2410.11760</link>
      <description>arXiv:2410.11760v1 Announce Type: new 
Abstract: This paper investigates the sensitivity analysis of a scalar mechanical contact problem described by a boundary value problem involving the Tresca's friction law. The sensitivity analysis is performed with respect to right-hand source and boundary terms perturbations. In particular the friction threshold involved in the Tresca's friction law is perturbed, which constitutes the main novelty of the present work with respect to the existing literature. Hence we introduce a parameterized Tresca friction problem and its solution is characterized by using the proximal operator associated with the corresponding perturbed nonsmooth convex Tresca friction functional. Then, by invoking the extended notion of twice epi-differentiability depending on a parameter, we prove the differentiability of the solution to the parameterized Tresca friction problem, characterizing its derivative as the solution to a boundary value problem involving Signorini unilateral conditions. Finally numerical simulations are provided in order to illustrate our main result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11760v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lo\"ic Bourdin, Fabien Caubet, Aymeric Jacob de Cordemoy</dc:creator>
    </item>
    <item>
      <title>Action Gaps and Advantages in Continuous-Time Distributional Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2410.11022</link>
      <description>arXiv:2410.11022v1 Announce Type: cross 
Abstract: When decisions are made at high frequency, traditional reinforcement learning (RL) methods struggle to accurately estimate action values. In turn, their performance is inconsistent and often poor. Whether the performance of distributional RL (DRL) agents suffers similarly, however, is unknown. In this work, we establish that DRL agents are sensitive to the decision frequency. We prove that action-conditioned return distributions collapse to their underlying policy's return distribution as the decision frequency increases. We quantify the rate of collapse of these return distributions and exhibit that their statistics collapse at different rates. Moreover, we define distributional perspectives on action gaps and advantages. In particular, we introduce the superiority as a probabilistic generalization of the advantage -- the core object of approaches to mitigating performance issues in high-frequency value-based RL. In addition, we build a superiority-based DRL algorithm. Through simulations in an option-trading domain, we validate that proper modeling of the superiority distribution produces improved controllers at high decision frequencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11022v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harley Wiltzer, Marc G. Bellemare, David Meger, Patrick Shafto, Yash Jhaveri</dc:creator>
    </item>
    <item>
      <title>Learning to Optimize for Mixed-Integer Non-linear Programming</title>
      <link>https://arxiv.org/abs/2410.11061</link>
      <description>arXiv:2410.11061v1 Announce Type: cross 
Abstract: Mixed-integer non-linear programs (MINLPs) arise in various domains, such as energy systems and transportation, but are notoriously difficult to solve. Recent advances in machine learning have led to remarkable successes in optimization tasks, an area broadly known as learning to optimize. This approach includes using predictive models to generate solutions for optimization problems with continuous decision variables, thereby avoiding the need for computationally expensive optimization algorithms. However, applying learning to MINLPs remains challenging primarily due to the presence of integer decision variables, which complicate gradient-based learning. To address this limitation, we propose two differentiable correction layers that generate integer outputs while preserving gradient information. Combined with a soft penalty for constraint violation, our framework can tackle both the integrality and non-linear constraints in a MINLP. Experiments on three problem classes with convex/non-convex objective/constraints and integer/mixed-integer variables show that the proposed learning-based approach consistently produces high-quality solutions for parametric MINLPs extremely quickly. As problem size increases, traditional exact solvers and heuristic methods struggle to find feasible solutions, whereas our approach continues to deliver reliable results. Our work extends the scope of learning-to-optimize to MINLP, paving the way for integrating integer constraints into deep learning models. Our code is available at https://github.com/pnnl/L2O-pMINLP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11061v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Tang, Elias B. Khalil, J\'an Drgo\v{n}a</dc:creator>
    </item>
    <item>
      <title>A Bilevel Optimization Framework for Imbalanced Data Classification</title>
      <link>https://arxiv.org/abs/2410.11171</link>
      <description>arXiv:2410.11171v1 Announce Type: cross 
Abstract: Data rebalancing techniques, including oversampling and undersampling, are a common approach to addressing the challenges of imbalanced data. To tackle unresolved problems related to both oversampling and undersampling, we propose a new undersampling approach that: (i) avoids the pitfalls of noise and overlap caused by synthetic data and (ii) avoids the pitfall of under-fitting caused by random undersampling. Instead of undersampling majority data randomly, our method undersamples datapoints based on their ability to improve model loss. Using improved model loss as a proxy measurement for classification performance, our technique assesses a datapoint's impact on loss and rejects those unable to improve it. In so doing, our approach rejects majority datapoints redundant to datapoints already accepted and, thereby, finds an optimal subset of majority training data for classification. The accept/reject component of our algorithm is motivated by a bilevel optimization problem uniquely formulated to identify the optimal training set we seek. Experimental results show our proposed technique with F1 scores up to 10% higher than state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11171v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Karen Medlin, Sven Leyffer, Krishnan Raghavan</dc:creator>
    </item>
    <item>
      <title>Subspace Optimization for Large Language Models with Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2410.11289</link>
      <description>arXiv:2410.11289v1 Announce Type: cross 
Abstract: Subspace optimization algorithms, with GaLore (Zhao et al., 2024) as a representative method, have gained popularity for pre-training or fine-tuning large language models (LLMs) due to their memory efficiency. However, their convergence guarantees remain unclear, particularly in stochastic settings. In this paper, we unexpectedly discover that GaLore does not always converge to the optimal solution and substantiate this finding with an explicit counterexample. We then investigate the conditions under which GaLore can achieve convergence, demonstrating that it does so either in deterministic scenarios or when using a sufficiently large mini-batch size. More significantly, we introduce GoLore (Gradient random Low-rank projection), a novel variant of GaLore that provably converges in stochastic settings, even with standard batch sizes. Our convergence analysis can be readily extended to other sparse subspace optimization algorithms. Finally, we conduct numerical experiments to validate our theoretical results and empirically explore the proposed mechanisms. Codes are available at https://github.com/pkumelon/Golore.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11289v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yutong He, Pengrui Li, Yipeng Hu, Chuyan Chen, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>Evolutionary Retrofitting</title>
      <link>https://arxiv.org/abs/2410.11330</link>
      <description>arXiv:2410.11330v1 Announce Type: cross 
Abstract: AfterLearnER (After Learning Evolutionary Retrofitting) consists in applying non-differentiable optimization, including evolutionary methods, to refine fully-trained machine learning models by optimizing a set of carefully chosen parameters or hyperparameters of the model, with respect to some actual, exact, and hence possibly non-differentiable error signal, performed on a subset of the standard validation set. The efficiency of AfterLearnER is demonstrated by tackling non-differentiable signals such as threshold-based criteria in depth sensing, the word error rate in speech re-synthesis, image quality in 3D generative adversarial networks (GANs), image generation via Latent Diffusion Models (LDM), the number of kills per life at Doom, computational accuracy or BLEU in code translation, and human appreciations in image synthesis. In some cases, this retrofitting is performed dynamically at inference time by taking into account user inputs. The advantages of AfterLearnER are its versatility (no gradient is needed), the possibility to use non-differentiable feedback including human evaluations, the limited overfitting, supported by a theoretical study and its anytime behavior. Last but not least, AfterLearnER requires only a minimal amount of feedback, i.e., a few dozens to a few hundreds of scalars, rather than the tens of thousands needed in most related published works. Compared to fine-tuning (typically using the same loss, and gradient-based optimization on a smaller but still big dataset at a fine grain), AfterLearnER uses a minimum amount of data on the real objective function without requiring differentiability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11330v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathurin Videau (TAU), Mariia Zameshina (LIGM), Alessandro Leite (TAU), Laurent Najman (LIGM), Marc Schoenauer (TAU), Olivier Teytaud (TAU)</dc:creator>
    </item>
    <item>
      <title>pycvxset: A Python package for convex set manipulation</title>
      <link>https://arxiv.org/abs/2410.11430</link>
      <description>arXiv:2410.11430v1 Announce Type: cross 
Abstract: This paper introduces pycvxset, a new Python package to manipulate and visualize convex sets. We support polytopes and ellipsoids, and provide user-friendly methods to perform a variety of set operations. For polytopes, pycvxset supports the standard halfspace/vertex representation as well as the constrained zonotope representation. The main advantage of constrained zonotope representations over standard halfspace/vertex representations is that constrained zonotopes admit closed-form expressions for several set operations. pycvxset uses CVXPY to solve various convex programs arising in set operations, and uses pycddlib to perform vertex-halfspace enumeration. We demonstrate the use of pycvxset in analyzing and controlling dynamical systems in Python. pycvxset is available at https://github.com/merlresearch/pycvxset under the AGPL-3.0-or-later license, along with documentation and examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11430v1</guid>
      <category>eess.SY</category>
      <category>cs.CG</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abraham P. Vinod</dc:creator>
    </item>
    <item>
      <title>Numerical computation of generalized Wasserstein distances with applications to traffic model analysis</title>
      <link>https://arxiv.org/abs/2410.11441</link>
      <description>arXiv:2410.11441v1 Announce Type: cross 
Abstract: Generalized Wasserstein distances allow to quantitatively compare two continuous or atomic mass distributions with equal or different total mass. In this paper, we propose four numerical methods for the approximation of three different generalized Wasserstein distances introduced in the last years, giving some insights about their physical meaning. After that, we explore their usage in the context of the sensitivity analysis of differential models for traffic flow. The quantification of models sensitivity is obtained by computing the generalized Wasserstein distances between two (numerical) solutions corresponding to different inputs, including different boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11441v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maya Briani, Emiliano Cristiani, Giovanni Franzina, Francesca L. Ignoto</dc:creator>
    </item>
    <item>
      <title>How Transformers Implement Induction Heads: Approximation and Optimization Analysis</title>
      <link>https://arxiv.org/abs/2410.11474</link>
      <description>arXiv:2410.11474v2 Announce Type: cross 
Abstract: Transformers have demonstrated exceptional in-context learning capabilities, yet the theoretical understanding of the underlying mechanisms remain limited. A recent work (Elhage et al., 2021) identified a "rich" in-context mechanism known as induction head, contrasting with "lazy" $n$-gram models that overlook long-range dependencies. In this work, we provide both approximation and optimization analyses of how transformers implement induction heads. In the approximation analysis, we formalize both standard and generalized induction head mechanisms, and examine how transformers can efficiently implement them, with an emphasis on the distinct role of each transformer submodule. For the optimization analysis, we study the training dynamics on a synthetic mixed target, composed of a 4-gram and an in-context 2-gram component. This setting enables us to precisely characterize the entire training process and uncover an {\em abrupt transition} from lazy (4-gram) to rich (induction head) mechanisms as training progresses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11474v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingze Wang, Ruoxi Yu, Weinan E, Lei Wu</dc:creator>
    </item>
    <item>
      <title>Generalizable Spacecraft Trajectory Generation via Multimodal Learning with Transformers</title>
      <link>https://arxiv.org/abs/2410.11723</link>
      <description>arXiv:2410.11723v1 Announce Type: cross 
Abstract: Effective trajectory generation is essential for reliable on-board spacecraft autonomy. Among other approaches, learning-based warm-starting represents an appealing paradigm for solving the trajectory generation problem, effectively combining the benefits of optimization- and data-driven methods. Current approaches for learning-based trajectory generation often focus on fixed, single-scenario environments, where key scene characteristics, such as obstacle positions or final-time requirements, remain constant across problem instances. However, practical trajectory generation requires the scenario to be frequently reconfigured, making the single-scenario approach a potentially impractical solution. To address this challenge, we present a novel trajectory generation framework that generalizes across diverse problem configurations, by leveraging high-capacity transformer neural networks capable of learning from multimodal data sources. Specifically, our approach integrates transformer-based neural network models into the trajectory optimization process, encoding both scene-level information (e.g., obstacle locations, initial and goal states) and trajectory-level constraints (e.g., time bounds, fuel consumption targets) via multimodal representations. The transformer network then generates near-optimal initial guesses for non-convex optimization problems, significantly enhancing convergence speed and performance. The framework is validated through extensive simulations and real-world experiments on a free-flyer platform, achieving up to 30% cost improvement and 80% reduction in infeasible cases with respect to traditional approaches, and demonstrating robust generalization across diverse scenario variations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11723v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Celestini, Amirhossein Afsharrad, Daniele Gammelli, Tommaso Guffanti, Gioele Zardini, Sanjay Lall, Elisa Capello, Simone D'Amico, Marco Pavone</dc:creator>
    </item>
    <item>
      <title>Solving The Dynamic Volatility Fitting Problem: A Deep Reinforcement Learning Approach</title>
      <link>https://arxiv.org/abs/2410.11789</link>
      <description>arXiv:2410.11789v1 Announce Type: cross 
Abstract: The volatility fitting is one of the core problems in the equity derivatives business. Through a set of deterministic rules, the degrees of freedom in the implied volatility surface encoding (parametrization, density, diffusion) are defined. Whilst very effective, this approach widespread in the industry is not natively tailored to learn from shifts in market regimes and discover unsuspected optimal behaviors. In this paper, we change the classical paradigm and apply the latest advances in Deep Reinforcement Learning(DRL) to solve the fitting problem. In particular, we show that variants of Deep Deterministic Policy Gradient (DDPG) and Soft Actor Critic (SAC) can achieve at least as good as standard fitting algorithms. Furthermore, we explain why the reinforcement learning framework is appropriate to handle complex objective functions and is natively adapted for online learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11789v1</guid>
      <category>q-fin.CP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.RM</category>
      <category>stat.ML</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Emmanuel Gnabeyeu, Omar Karkar, Imad Idboufous</dc:creator>
    </item>
    <item>
      <title>Machine Learning for K-adaptability in Two-stage Robust Optimization</title>
      <link>https://arxiv.org/abs/2210.11152</link>
      <description>arXiv:2210.11152v3 Announce Type: replace 
Abstract: Two-stage robust optimization problems constitute one of the hardest optimization problem classes. One of the solution approaches to this class of problems is K-adaptability. This approach simultaneously seeks the best partitioning of the uncertainty set of scenarios into K subsets, and optimizes decisions corresponding to each of these subsets. In general case, it is solved using the K-adaptability branch-and-bound algorithm, which requires exploration of exponentially-growing solution trees. To accelerate finding high-quality solutions in such trees, we propose a machine learning-based node selection strategy. In particular, we construct a feature engineering scheme based on general two-stage robust optimization insights that allows us to train our machine learning tool on a database of resolved B&amp;B trees, and to apply it as-is to problems of different sizes and/or types. We experimentally show that using our learned node selection strategy outperforms a vanilla, random node selection strategy when tested on problems of the same type as the training problems, also in case the K-value or the problem size differs from the training ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.11152v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Esther Julien, Krzysztof Postek, \c{S}. \.Ilker Birbil</dc:creator>
    </item>
    <item>
      <title>A stochastic use of the Kurdyka-Lojasiewicz property: Investigation of optimization algorithms behaviours in a non-convex differentiable framework</title>
      <link>https://arxiv.org/abs/2302.06447</link>
      <description>arXiv:2302.06447v4 Announce Type: replace 
Abstract: Stochastic differentiable approximation schemes are widely used for solving high dimensional problems. Most of existing methods satisfy some desirable properties, including conditional descent inequalities, and almost sure (a.s.) convergence guarantees on the objective function, or on the involved gradient. However, for non-convex objective functions, a.s. convergence of the iterates, i.e., the stochastic process, to a critical point is usually not guaranteed, and remains an important challenge. In this article, we develop a framework to bridge the gap between descent-type inequalities and a.s. convergence of the associated stochastic process. Leveraging a novel Kurdyka-Lojasiewicz property, we show convergence guarantees of stochastic processes under mild assumptions on the objective function. We also provide examples of stochastic algorithms benefiting from the proposed framework and derive a.s. convergence guarantees on the iterates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.06447v4</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean-Baptiste Fest, Audrey Repetti, Emilie Chouzenoux</dc:creator>
    </item>
    <item>
      <title>Random Function Descent</title>
      <link>https://arxiv.org/abs/2305.01377</link>
      <description>arXiv:2305.01377v3 Announce Type: replace 
Abstract: Classical worst-case optimization theory neither explains the success of optimization in machine learning, nor does it help with step size selection. In this paper we demonstrate the viability and advantages of replacing the classical 'convex function' framework with a 'random function' framework. With complexity $\mathcal{O}(n^3d^3)$, where $n$ is the number of steps and $d$ the number of dimensions, Bayesian optimization with gradients has not been viable in large dimension so far. By bridging the gap between Bayesian optimization (i.e. random function optimization theory) and classical optimization we establish viability. Specifically, we use a 'stochastic Taylor approximation' to rediscover gradient descent, which is scalable in high dimension due to $\mathcal{O}(nd)$ complexity. This rediscovery yields a specific step size schedule we call Random Function Descent (RFD). The advantage of this random function framework is that RFD is scale invariant and that it provides a theoretical foundation for common step size heuristics such as gradient clipping and gradual learning rate warmup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.01377v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:journal_reference>Advances in Neural Information Processing Systems, Vol. 37. Vancouver, Canada: Curran Associates, Inc., 2024</arxiv:journal_reference>
      <dc:creator>Felix Benning, Leif D\"oring</dc:creator>
    </item>
    <item>
      <title>Environmental management and restoration under unified risk and uncertainty using robustified dynamic Orlicz risk</title>
      <link>https://arxiv.org/abs/2306.01998</link>
      <description>arXiv:2306.01998v2 Announce Type: replace 
Abstract: Environmental management and restoration should be designed such that the risk and uncertainty owing to nonlinear stochastic systems can be successfully addressed. We apply the robustified dynamic Orlicz risk to the modeling and analysis of environmental management and restoration to consider both the risk and uncertainty within a unified theory. We focus on the control of a jump-driven hybrid stochastic system that represents macrophyte dynamics. The dynamic programming equation based on the Orlicz risk is first obtained heuristically, from which the associated Hamilton-Jacobi-Bellman (HJB) equation is derived. In the proposed Orlicz risk, the risk aversion of the decision-maker is represented by a power coefficient that resembles a certainty equivalence, whereas the uncertainty aversion is represented by the Kullback-Leibler divergence, in which the risk and uncertainty are handled consistently and separately. The HJB equation includes a new state-dependent discount factor that arises from the uncertainty aversion, which leads to a unique, nonlinear, and nonlocal term. The link between the proposed and classical stochastic control problems is discussed with a focus on control-dependent discount rates. We propose a finite difference method for computing the HJB equation. Finally, the proposed model is applied to an optimal harvesting problem for macrophytes in a brackish lake that contains both growing and drifting populations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.01998v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.PR</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hidekazu Yoshioka, Motoh Tsujimura, Futoshi Aranishi, Tomomi Tanaka</dc:creator>
    </item>
    <item>
      <title>An accelerated first-order regularized momentum descent ascent algorithm for stochastic nonconvex-concave minimax problems</title>
      <link>https://arxiv.org/abs/2310.15448</link>
      <description>arXiv:2310.15448v2 Announce Type: replace 
Abstract: Stochastic nonconvex minimax problems have attracted wide attention in machine learning, signal processing and many other fields in recent years. In this paper, we propose an accelerated first-order regularized momentum descent ascent algorithm (FORMDA) for solving stochastic nonconvex-concave minimax problems. The iteration complexity of the algorithm is proved to be $\tilde{\mathcal{O}}(\varepsilon ^{-6.5})$ to obtain an $\varepsilon$-stationary point, which achieves the best-known complexity bound for single-loop algorithms to solve the stochastic nonconvex-concave minimax problems under the stationarity of the objective function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.15448v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huiling Zhang, Zi Xu</dc:creator>
    </item>
    <item>
      <title>Addressing Unboundedness in Quadratically-Constrained Mixed-Integer Problems</title>
      <link>https://arxiv.org/abs/2405.05978</link>
      <description>arXiv:2405.05978v2 Announce Type: replace 
Abstract: Mixed-integer (MI) quadratic models subject to quadratic constraints, known as All-Quadratic MI Programs, constitute a challenging class of NP-complete optimization problems. The particular scenario of unbounded integers defines a subclass that holds the distinction of being even undecidable [Jeroslow, 1973]. This complexity suggests a possible soft-spot for Mathematical Programming (MP) techniques, which otherwise constitute a good choice to treat MI problems. We consider the task of minimizing MI convex quadratic objective and constraint functions with unbounded decision variables. Given the theoretical weakness of white-box MP solvers to handle such models, we turn to black-box meta-heuristics of the Evolution Strategies (ESs) family, and question their capacity to solve this challenge. Through an empirical assessment of all-quadratic test-cases, across varying Hessian forms and condition numbers, we compare the performance of the CPLEX solver to modern MI ESs, which handle constraints by penalty. Our systematic investigation begins where the CPLEX solver encounters difficulties (timeouts as the search-space dimensionality increases, D&gt;=30), and we report in detail on the D=64 case. Overall, the empirical observations confirm that black-box and white-box solvers can be competitive, where CPLEX is evidently outperformed on 13% of the cases. This trend is flipped when unboundedness is amplified by a significant translation of the optima, leading to a totally inferior performance of CPLEX at 83% of the cases. We also conclude that conditioning and separability are not intuitive factors in determining the hardness degree of this class of MI problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05978v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guy Zepko, Ofer M. Shir</dc:creator>
    </item>
    <item>
      <title>Greedy Learning to Optimize with Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2406.00260</link>
      <description>arXiv:2406.00260v2 Announce Type: replace 
Abstract: Learning to optimize is an approach that leverages training data to accelerate the solution of optimization problems. Many approaches use unrolling to parametrize the update step and learn optimal parameters. Although L2O has shown empirical advantages over classical optimization algorithms, memory restrictions often greatly limit the unroll length and learned algorithms usually do not provide convergence guarantees. In contrast, we introduce a novel method employing a greedy strategy that learns iteration-specific parameters by minimizing the function value at the next iteration. This enables training over significantly more iterations while maintaining constant memory usage. We parameterize the update such that parameter learning corresponds to solving a convex optimization problem at each iteration. In particular, we explore preconditioned gradient descent with multiple parametrizations including a novel convolutional preconditioner. With our learned algorithm, convergence in the training set is proven even when the preconditioner is neither symmetric nor positive definite. Convergence on a class of unseen functions is also obtained, ensuring robust performance and generalization beyond the training data. We test our learned algorithms on two inverse problems, image deblurring and Computed Tomography, on which learned convolutional preconditioner demonstrates improved empirical performance over classical optimization algorithms such as Nesterov's Accelerated Gradient Method and the quasi-Newton method L-BFGS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00260v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Fahy, Mohammad Golbabaee, Matthias J. Ehrhardt</dc:creator>
    </item>
    <item>
      <title>Problem of Locating and Allocating Charging Equipment for Battery Electric Buses under Stochastic Charging Demand</title>
      <link>https://arxiv.org/abs/2408.05278</link>
      <description>arXiv:2408.05278v2 Announce Type: replace 
Abstract: Bus electrification plays a crucial role in advancing urban transportation sustainability. Battery Electric Buses (BEBs), however, often need recharging, making the Problem of Locating and Allocating Charging Equipment for BEBs (PLACE-BEB) essential for efficient operations. This study proposes an optimization framework to solve the PLACE-BEB by determining the optimal placement of charger types at potential locations under the stochastic charging demand. Leveraging the existing stochastic location literature, we develop a Mixed-Integer Non-Linear Program (MINLP) to model the problem. To solve this problem, we develop an exact solution method that minimizes the costs related to building charging stations, charger allocation, travel to stations, and average queueing and charging times. Queueing dynamics are modeled using an M/M/s queue, with the number of servers at each location treated as a decision variable. To improve scalability, we implement a Simulated Annealing (SA) and a Genetic Algorithm (GA) allowing for efficient solutions to large-scale problems. The computational performance of the methods was thoroughly evaluated, revealing that SA was effective for small-scale problems, while GA outperformed others for large-scale instances. A case study comparing garage-only, other-only, and mixed scenarios, along with joint deployment, highlighted the cost benefits of a collaborative and a comprehensive approach. Sensitivity analyses showed that the waiting time is a key factor to consider in the decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05278v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sadjad Bazarnovi, Taner Cokyasar, Omer Verbas, Abolfazl Kouros Mohammadian</dc:creator>
    </item>
    <item>
      <title>Exactness Conditions for Semidefinite Relaxations of the Quadratic Assignment Problem</title>
      <link>https://arxiv.org/abs/2409.08802</link>
      <description>arXiv:2409.08802v2 Announce Type: replace 
Abstract: The Quadratic Assignment Problem (QAP) is an important discrete optimization instance that encompasses many well-known combinatorial optimization problems, and has applications in a wide range of areas such as logistics and computer vision. The QAP, unfortunately, is NP-hard to solve. To address this difficulty, a number of semidefinite relaxations of the QAP have been developed. These techniques are known to be powerful in that they compute globally optimal solutions in many instances, and are often deployed as sub-routines within enumerative procedures for solving QAPs. In this paper, we investigate the strength of these semidefinite relaxations. Our main result is a deterministic set of conditions on the input matrices -- specified via linear inequalities -- under which these semidefinite relaxations are exact. Our result is simple to state, in the hope that it serves as a foundation for subsequent studies on semidefinite relaxations of the QAP as well as other related combinatorial optimization problems. As a corollary, we show that the semidefinite relaxation is exact under a perturbation model whereby the input matrices differ by a suitably small perturbation term. One technical difficulty we encounter is that the set of dual feasible solutions is not closed. To circumvent these difficulties, our analysis constructs a sequence of dual feasible solutions whose objective value approaches the primal objective, but never attains it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08802v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyu Chen, Yong Sheng Soh</dc:creator>
    </item>
    <item>
      <title>$\gamma$-Competitiveness: An Approach to Multi-Objective Optimization with High Computation Costs in Lipschitz Functions</title>
      <link>https://arxiv.org/abs/2410.03023</link>
      <description>arXiv:2410.03023v2 Announce Type: replace 
Abstract: In practical engineering and optimization, solving multi-objective optimization (MOO) problems typically involves scalarization methods that convert a multi-objective problem into a single-objective one. While effective, these methods often incur significant computational costs due to iterative calculations and are further complicated by the need for hyperparameter tuning. In this paper, we introduce an extension of the concept of competitive solutions and propose the Scalarization With Competitiveness Method (SWCM) for multi-criteria problems. This method is highly interpretable and eliminates the need for hyperparameter tuning. Additionally, we offer a solution for cases where the objective functions are Lipschitz continuous and can only be computed once, termed Competitiveness Approximation on Lipschitz Functions (CAoLF). This approach is particularly useful when computational resources are limited or re-computation is not feasible. Through computational experiments on the minimum-cost concurrent flow problem, we demonstrate the efficiency and scalability of the proposed method, underscoring its potential for addressing computational challenges in MOO across various applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03023v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ilgam Latypov, Yuriy Dorn</dc:creator>
    </item>
    <item>
      <title>Anderson Acceleration in Nonsmooth Problems: Local Convergence via Active Manifold Identification</title>
      <link>https://arxiv.org/abs/2410.09420</link>
      <description>arXiv:2410.09420v2 Announce Type: replace 
Abstract: Anderson acceleration is an effective technique for enhancing the efficiency of fixed-point iterations; however, analyzing its convergence in nonsmooth settings presents significant challenges. In this paper, we investigate a class of nonsmooth optimization algorithms characterized by the active manifold identification property. This class includes a diverse array of methods such as the proximal point method, proximal gradient method, proximal linear method, proximal coordinate descent method, Douglas-Rachford splitting (or the alternating direction method of multipliers), and the iteratively reweighted $\ell_1$ method, among others. Under the assumption that the optimization problem possesses an active manifold at a stationary point, we establish a local R-linear convergence rate for the Anderson-accelerated algorithm. Our extensive numerical experiments further highlight the robust performance of the proposed Anderson-accelerated methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09420v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kexin Li, Luwei Bai, Xiao Wang, Hao Wang</dc:creator>
    </item>
    <item>
      <title>Comparison of viscosity solutions for a class of second order PDEs on the Wasserstein space</title>
      <link>https://arxiv.org/abs/2309.05040</link>
      <description>arXiv:2309.05040v3 Announce Type: replace-cross 
Abstract: We prove a comparison result for viscosity solutions of second order parabolic partial differential equations in the Wasserstein space. The comparison is valid for semisolutions that are Lipschitz continuous in the measure in a Fourier-Wasserstein metric and uniformly continuous in time. The class of equations we consider is motivated by Mckean-Vlasov control problems with common noise and filtering problems. The proof of comparison relies on a novel version of Ishii's lemma, which is tailor-made for the class of equations we consider.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05040v3</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Ibrahim Ekren, Xin Zhang</dc:creator>
    </item>
    <item>
      <title>Variance-Aware Regret Bounds for Stochastic Contextual Dueling Bandits</title>
      <link>https://arxiv.org/abs/2310.00968</link>
      <description>arXiv:2310.00968v2 Announce Type: replace-cross 
Abstract: Dueling bandits is a prominent framework for decision-making involving preferential feedback, a valuable feature that fits various applications involving human interaction, such as ranking, information retrieval, and recommendation systems. While substantial efforts have been made to minimize the cumulative regret in dueling bandits, a notable gap in the current research is the absence of regret bounds that account for the inherent uncertainty in pairwise comparisons between the dueling arms. Intuitively, greater uncertainty suggests a higher level of difficulty in the problem. To bridge this gap, this paper studies the problem of contextual dueling bandits, where the binary comparison of dueling arms is generated from a generalized linear model (GLM). We propose a new SupLinUCB-type algorithm that enjoys computational efficiency and a variance-aware regret bound $\tilde O\big(d\sqrt{\sum_{t=1}^T\sigma_t^2} + d\big)$, where $\sigma_t$ is the variance of the pairwise comparison in round $t$, $d$ is the dimension of the context vectors, and $T$ is the time horizon. Our regret bound naturally aligns with the intuitive expectation in scenarios where the comparison is deterministic, the algorithm only suffers from an $\tilde O(d)$ regret. We perform empirical experiments on synthetic data to confirm the advantage of our method over previous variance-agnostic algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00968v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiwei Di, Tao Jin, Yue Wu, Heyang Zhao, Farzad Farnoud, Quanquan Gu</dc:creator>
    </item>
    <item>
      <title>GSE: Group-wise Sparse and Explainable Adversarial Attacks</title>
      <link>https://arxiv.org/abs/2311.17434</link>
      <description>arXiv:2311.17434v2 Announce Type: replace-cross 
Abstract: Sparse adversarial attacks fool deep neural networks (DNNs) through minimal pixel perturbations, often regularized by the $\ell_0$ norm. Recent efforts have replaced this norm with a structural sparsity regularizer, such as the nuclear group norm, to craft group-wise sparse adversarial attacks. The resulting perturbations are thus explainable and hold significant practical relevance, shedding light on an even greater vulnerability of DNNs. However, crafting such attacks poses an optimization challenge, as it involves computing norms for groups of pixels within a non-convex objective. We address this by presenting a two-phase algorithm that generates group-wise sparse attacks within semantically meaningful areas of an image. Initially, we optimize a quasinorm adversarial loss using the $1/2-$quasinorm proximal operator tailored for non-convex programming. Subsequently, the algorithm transitions to a projected Nesterov's accelerated gradient descent with $2-$norm regularization applied to perturbation magnitudes. Rigorous evaluations on CIFAR-10 and ImageNet datasets demonstrate a remarkable increase in group-wise sparsity, e.g., $50.9\%$ on CIFAR-10 and $38.4\%$ on ImageNet (average case, targeted attack). This performance improvement is accompanied by significantly faster computation times, improved explainability, and a $100\%$ attack success rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17434v2</guid>
      <category>cs.CV</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shpresim Sadiku, Moritz Wagner, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Optimistic Safety for Online Convex Optimization with Unknown Linear Constraints</title>
      <link>https://arxiv.org/abs/2403.05786</link>
      <description>arXiv:2403.05786v3 Announce Type: replace-cross 
Abstract: We study the problem of online convex optimization (OCO) under unknown linear constraints that are either static, or stochastically time-varying. For this problem, we introduce an algorithm that we term Optimistically Safe OCO (OSOCO) and show that it enjoys $\tilde{O}(\sqrt{T})$ regret and no constraint violation. In the case of static linear constraints, this improves on the previous best known $\tilde{O}(T^{2/3})$ regret under the same assumptions. In the case of stochastic time-varying constraints, our work supplements existing results that show $O(\sqrt{T})$ regret and $O(\sqrt{T})$ cumulative violation under more general convex constraints and a different set of assumptions. In addition to our theoretical guarantees, we also give numerical results that further validate the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05786v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Spencer Hutchinson, Tianyi Chen, Mahnoosh Alizadeh</dc:creator>
    </item>
    <item>
      <title>Few for Many: Tchebycheff Set Scalarization for Many-Objective Optimization</title>
      <link>https://arxiv.org/abs/2405.19650</link>
      <description>arXiv:2405.19650v2 Announce Type: replace-cross 
Abstract: Multi-objective optimization can be found in many real-world applications where some conflicting objectives can not be optimized by a single solution. Existing optimization methods often focus on finding a set of Pareto solutions with different optimal trade-offs among the objectives. However, the required number of solutions to well approximate the whole Pareto optimal set could be exponentially large with respect to the number of objectives, which makes these methods unsuitable for handling many optimization objectives. In this work, instead of finding a dense set of Pareto solutions, we propose a novel Tchebycheff set scalarization method to find a few representative solutions (e.g., 5) to cover a large number of objectives (e.g., $&gt;100$) in a collaborative and complementary manner. In this way, each objective can be well addressed by at least one solution in the small solution set. In addition, we further develop a smooth Tchebycheff set scalarization approach for efficient optimization with good theoretical guarantees. Experimental studies on different problems with many optimization objectives demonstrate the effectiveness of our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19650v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Lin, Yilu Liu, Xiaoyuan Zhang, Fei Liu, Zhenkun Wang, Qingfu Zhang</dc:creator>
    </item>
    <item>
      <title>Fast Revenue Maximization</title>
      <link>https://arxiv.org/abs/2407.07316</link>
      <description>arXiv:2407.07316v2 Announce Type: replace-cross 
Abstract: Problem definition: We study a data-driven pricing problem in which a seller offers a price for a single item based on demand observed at a small number of historical prices. Our goal is to derive precise evaluation procedures of the value of the historical information gathered by the seller, along with prescriptions for more efficient price experimentation. Methodology/results: Our main methodological result is an exact characterization of the maximin ratio (defined as the worst-case revenue garnered by a seller who only relies on past data divided by the optimal revenue achievable with full knowledge of the distribution of values). This result allows to measure the value of any historical data consisting of prices and corresponding conversion rates. We leverage this central reduction to provide new insights about price experimentation. Managerial implications: Motivated by practical constraints that impede the seller from changing prices abruptly, we first illustrate our framework by evaluating the value of local information and show that the mere sign of the gradient of the revenue curve at a single point can provide significant information to the seller. We then showcase how our framework can be used to run efficient price experiments. On the one hand, we develop a method to select the next price experiment that the seller should use to maximize the future robust performance. On the other hand, we demonstrate that our result allows to considerably reduce the number of price experiments needed to reach preset revenue guarantees through dynamic pricing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07316v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Achraf Bahamou, Omar Besbes, Omar Mouchtaki</dc:creator>
    </item>
    <item>
      <title>Exploiting Exogenous Structure for Sample-Efficient Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2409.14557</link>
      <description>arXiv:2409.14557v2 Announce Type: replace-cross 
Abstract: We study a class of structured Markov Decision Processes (MDPs) known as Exo-MDPs. They are characterized by a partition of the state space into two components: the exogenous states evolve stochastically in a manner not affected by the agent's actions, whereas the endogenous states can be affected by actions, and evolve according to deterministic dynamics involving both the endogenous and exogenous states. Exo-MDPs provide a natural model for various applications, including inventory control, portfolio management, power systems, and ride-sharing, among others. While seemingly restrictive on the surface, our first result establishes that any discrete MDP can be represented as an Exo-MDP. The underlying argument reveals how transition and reward dynamics can be written as linear functions of the exogenous state distribution, showing how Exo-MDPs are instances of linear mixture MDPs, thereby showing a representational equivalence between discrete MDPs, Exo-MDPs, and linear mixture MDPs. The connection between Exo-MDPs and linear mixture MDPs leads to algorithms that are near sample-optimal, with regret guarantees scaling with the (effective) size of the exogenous state space $d$, independent of the sizes of the endogenous state and action spaces, even when the exogenous state is {\em unobserved}. When the exogenous state is unobserved, we establish a regret upper bound of $O(H^{3/2}d\sqrt{K})$ with $K$ trajectories of horizon $H$ and unobserved exogenous state of dimension $d$. We also establish a matching regret lower bound of $\Omega(H^{3/2}d\sqrt{K})$ for non-stationary Exo-MDPs and a lower bound of $\Omega(Hd\sqrt{K})$ for stationary Exo-MDPs. We complement our theoretical findings with an experimental study on inventory control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14557v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jia Wan, Sean R. Sinclair, Devavrat Shah, Martin J. Wainwright</dc:creator>
    </item>
    <item>
      <title>Active Learning of Deep Neural Networks via Gradient-Free Cutting Planes</title>
      <link>https://arxiv.org/abs/2410.02145</link>
      <description>arXiv:2410.02145v3 Announce Type: replace-cross 
Abstract: Active learning methods aim to improve sample complexity in machine learning. In this work, we investigate an active learning scheme via a novel gradient-free cutting-plane training method for ReLU networks of arbitrary depth. We demonstrate, for the first time, that cutting-plane algorithms, traditionally used in linear models, can be extended to deep neural networks despite their nonconvexity and nonlinear decision boundaries. Our results demonstrate that these methods provide a promising alternative to the commonly employed gradient-based optimization techniques in large-scale neural networks. Moreover, this training method induces the first deep active learning scheme known to achieve convergence guarantees. We exemplify the effectiveness of our proposed active learning method against popular deep active learning baselines via both synthetic data experiments and sentimental classification task on real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02145v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erica Zhang, Fangzhao Zhang, Mert Pilanci</dc:creator>
    </item>
  </channel>
</rss>
