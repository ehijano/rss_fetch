<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>astro-ph.IM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/astro-ph.IM</link>
    <description>astro-ph.IM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/astro-ph.IM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 May 2024 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 07 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Noise Models in the LISA Mission</title>
      <link>https://arxiv.org/abs/2405.02339</link>
      <description>arXiv:2405.02339v1 Announce Type: new 
Abstract: This document briefly describes the noise models and shapes used for the synthesis of the Drag-Free and Attitude Control System in the LISA space mission. LISA (Laser Interferometer Space Antenna) is one of the next large-class missions from the European Space Agency (ESA), expected to be launched in 2034. The main goal of the mission is to detect the gravitational waves, which are undulatory perturbations of the space-time fabric, extremely important to collect experimental proofs for the General Relativity Theory. In the 90s, different international collaborations of institutes laid the foundations for the first ground-based interferometers (see, e.g., LIGO and Virgo). However, ground-based interferometers have a limited bandwidth due to the Earth's environmental noises and short arm-length of few kilometers. Therefore, they cannot observe gravitational waves belonging to the portion of the spectrum below 1 Hz. This issue can be overcome by means of space-based interferometers, that can have arm-lengths up to millions of kilometers and exploit a quieter environment than the Earth's surface. The LISA system is affected by actuation, sensing and environmental disturbances and noises. Among the actuation noises we have those given by the Micro Propulsion System (MPS), the Gravitational Reference Sensor (GRS) and the Optical Assembly (OA) motor. Among the sensing noises we consider the interferometer, the Differential Wavefront Sensor (DWS) and the GRS. The environmental disturbances are given by the solar radiation pressure, the test-mass stiffness and self-gravity, and the environmental noises acting directly on the test-mass.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02339v1</guid>
      <category>astro-ph.IM</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michele Pagone, Carlo Novara</dc:creator>
    </item>
    <item>
      <title>Bayesian and Convolutional Networks for Hierarchical Morphological Classification of Galaxies</title>
      <link>https://arxiv.org/abs/2405.02366</link>
      <description>arXiv:2405.02366v1 Announce Type: new 
Abstract: This work is focused on the morphological classification of galaxies following the Hubble sequence in which the different classes are arranged in a hierarchy. The proposed method, BCNN, is composed of two main modules. First, a convolutional neural network (CNN) is trained with images of the different classes of galaxies (image augmentation is carried out to balance some classes); the CNN outputs the probability for each class of the hierarchy, and its outputs/predictions feed the second module. The second module consists of a Bayesian network that represents the hierarchy and helps to improve the prediction accuracy by combining the predictions of the first phase while maintaining the hierarchical constraint (in a hierarchy, an instance associated with a node must be associated to all its ancestors), through probabilistic inference over the Bayesian network so that a consistent prediction is obtained. Different images from the Hubble telescope have been collected and labeled by experts, which are used to perform the experiments. The results show that BCNN performed better than several CNNs in multiple evaluation measures, reaching the next scores: 67% in exact match, 78% in accuracy, and 83% in hierarchical F-measure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02366v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.GA</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jonathan Serrano-P\'erez, Raquel D\'iaz Hern\'andez, L. Enrique Sucar</dc:creator>
    </item>
    <item>
      <title>The Stagger Code for Accurate and Efficient, Radiation-Coupled MHD Simulations</title>
      <link>https://arxiv.org/abs/2405.02483</link>
      <description>arXiv:2405.02483v1 Announce Type: new 
Abstract: We describe the Stagger Code for simulations of magneto-hydrodynamic (MHD) systems. This is a modular code with a variety of physics modules that will let the user run simulations of deep stellar atmospheres, sunspot formation, stellar chromospheres and coronae, proto-stellar disks, star formation from giant molecular clouds and even galaxy formation. The Stagger Code is efficiently and highly parallelizable, enabling such simulations with large ranges of both spatial and temporal scales. We, describe the methodology of the code, and present the most important of the physics modules, as well as its input and output variables. We show results of a number of standard MHD tests to enable comparison with other, similar codes. In addition, we provide an overview of tests that have been carried out against solar observations, ranging from spectral line shapes, spectral flux distribution, limb darkening, intensity and velocity distributions of granulation, to seismic power-spectra and the excitation of p modes. The Stagger Code has proven to be a high fidelity code with a large range of uses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02483v1</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert F. Stein, {\AA}ke Nordlund, Remo Collet, Regner Trampedach</dc:creator>
    </item>
    <item>
      <title>ATAT: Astronomical Transformer for time series And Tabular data</title>
      <link>https://arxiv.org/abs/2405.03078</link>
      <description>arXiv:2405.03078v1 Announce Type: new 
Abstract: The advent of next-generation survey instruments, such as the Vera C. Rubin Observatory and its Legacy Survey of Space and Time (LSST), is opening a window for new research in time-domain astronomy. The Extended LSST Astronomical Time-Series Classification Challenge (ELAsTiCC) was created to test the capacity of brokers to deal with a simulated LSST stream. We describe ATAT, the Astronomical Transformer for time series And Tabular data, a classification model conceived by the ALeRCE alert broker to classify light-curves from next-generation alert streams. ATAT was tested in production during the first round of the ELAsTiCC campaigns. ATAT consists of two Transformer models that encode light curves and features using novel time modulation and quantile feature tokenizer mechanisms, respectively. ATAT was trained on different combinations of light curves, metadata, and features calculated over the light curves. We compare ATAT against the current ALeRCE classifier, a Balanced Hierarchical Random Forest (BHRF) trained on human-engineered features derived from light curves and metadata. When trained on light curves and metadata, ATAT achieves a macro F1-score of 82.9 +- 0.4 in 20 classes, outperforming the BHRF model trained on 429 features, which achieves a macro F1-score of 79.4 +- 0.1. The use of Transformer multimodal architectures, combining light curves and tabular data, opens new possibilities for classifying alerts from a new generation of large etendue telescopes, such as the Vera C. Rubin Observatory, in real-world brokering scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03078v1</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G. Cabrera-Vives, D. Moreno-Cartagena, N. Astorga, I. Reyes-Jainaga, F. F\"orster, P. Huijse, J. Arredondo, A. M. Mu\~noz Arancibia, A. Bayo, M. Catelan, P. A. Est\'evez, P. S\'anchez-S\'aez, A. \'Alvarez, P. Castellanos, P. Gallardo, A. Moya, D. Rodriguez-Mancini</dc:creator>
    </item>
    <item>
      <title>LURAD: Design Study of a Comprehensive Radiation Monitor Package for the Gateway and the Lunar Surface</title>
      <link>https://arxiv.org/abs/2405.03187</link>
      <description>arXiv:2405.03187v1 Announce Type: new 
Abstract: Moon is an auspicious environment for the study of Galactic cosmic rays (GCR) and Solar particle events (SEP) due to the absence of magnetic field and atmosphere. The same characteristics raise the radiation risk for human presence in orbit around it or at the lunar surface. The secondary (albedo) radiation resulting from the interaction of the primary radiation with the lunar soil adds an extra risk factor, because neutrons are produced, but also it can be exploited to study the soil composition. In this paper, the design of a comprehensive radiation monitor package tailored to the lunar environment is presented. The detector, named LURAD, will perform spectroscopic measurements of protons, electrons, heavy ions, as well as gamma-rays, and neutrons. A microdosimetry monitor subsystem is foreseen which can provide measurements of LET(Si) spectra in a wide dynamic range of LET(Si) and flux for SPE and GCR, detection of neutrons and biological dose for radiation protection of astronauts. The LURAD design leverages on the following key enabling technologies: (a) Fully depleted Si monolithic active pixel sensors; (b) Scintillators read by silicon photomultipliers (SiPM); (c) Silicon on Insulator (SOI) microdosimetry sensors; These technologies promise miniaturization and mass reduction with state-of-the-art performance. The instrument's design is presented, and the Monte Carlo study of the feasibility of particle identification and kinetic energy determination is discussed</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03187v1</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C. Potiriadis, K. Karafasoulis, C. Papadimitropoulos, E. Papadomanolaki, A. Papangelis, I. Kazas, J. Vourvoulakis, G. Theodoratos, A. Kok, L. T. Tran, M. Povoli, J. Vohradsky, G. Dimitropoulos, A. Rosenfeld, C. P. Lambropoulos</dc:creator>
    </item>
    <item>
      <title>Deep Learning and genetic algorithms for cosmological Bayesian inference speed-up</title>
      <link>https://arxiv.org/abs/2405.03293</link>
      <description>arXiv:2405.03293v1 Announce Type: new 
Abstract: In this paper, we present a novel approach to accelerate the Bayesian inference process, focusing specifically on the nested sampling algorithms. Bayesian inference plays a crucial role in cosmological parameter estimation, providing a robust framework for extracting theoretical insights from observational data. However, its computational demands can be substantial, primarily due to the need for numerous likelihood function evaluations. Our proposed method utilizes the power of deep learning, employing feedforward neural networks to approximate the likelihood function dynamically during the Bayesian inference process. Unlike traditional approaches, our method trains neural networks on-the-fly using the current set of live points as training data, without the need for pre-training. This flexibility enables adaptation to various theoretical models and datasets. We perform simple hyperparameter optimization using genetic algorithms to suggest initial neural network architectures for learning each likelihood function. Once sufficient accuracy is achieved, the neural network replaces the original likelihood function. The implementation integrates with nested sampling algorithms and has been thoroughly evaluated using both simple cosmological dark energy models and diverse observational datasets. Additionally, we explore the potential of genetic algorithms for generating initial live points within nested sampling inference, opening up new avenues for enhancing the efficiency and effectiveness of Bayesian inference methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03293v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.CO</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isidro G\'omez-Vargas, J. Alberto V\'azquez</dc:creator>
    </item>
    <item>
      <title>Swarm intelligence for full Stokes dynamic imaging reconstruction of interferometric data</title>
      <link>https://arxiv.org/abs/2405.03330</link>
      <description>arXiv:2405.03330v1 Announce Type: new 
Abstract: In very long baseline interferometry (VLBI) the combination of multiple antennas permits the synthesis of a virtual telescope with a larger diameter and consequently higher resolution than the individual antennae. Yet, due to the sparse nature of the array, recovering an image from the observed data is a challenging ill-posed inverse problem. The VLBI community is interested in not only recovering an image in total intensity from interferometric data, but also to obtain results in the polarimetric and the temporal domain. Only a few algorithms are able to work in all these domains simultaneously. In particular, the algorithms based on optimization that consider various penalty terms specific to static total intensity imaging, time-variability and polarimetry are restricted to grids the domain of the objective function. In this work we present a novel algorithm, multiobjective particle swarm optimization, that is able to recover the optimal weights without any space-gridding, and to obtain the marginal contribution of each the playing terms. To this end, we utilize multiobjective optimization together with particle swarm metaheuristics. We let the swarm of weights to converge together to the best position. We evaluate our algorithm with representative synthetic data sets focused on the instrumental configuration of the Event Horizon Telescope Collaboration and its planned successors. We successfully recover the polarimetric, static and time-dynamic signature of the ground truth movie, even with relative sparsity, and a set of realistic data corruptions. This is a novel, fast, weighting space gridding-free algorithm that successfully recovers static and dynamic polarimetric reconstructions. Compared to Regularized Maximum Likelihood methods, it avoids the need for parameter surveys, and it is not limited to the number of pixels such as recently proposed multiobjective imaging algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03330v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.GA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro Mus, Hendrik M\"uller, Andrei Lobanov</dc:creator>
    </item>
    <item>
      <title>An Image Quality Evaluation and Masking Algorithm Based On Pre-trained Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2405.03408</link>
      <description>arXiv:2405.03408v1 Announce Type: new 
Abstract: With the growing amount of astronomical data, there is an increasing need for automated data processing pipelines, which can extract scientific information from observation data without human interventions. A critical aspect of these pipelines is the image quality evaluation and masking algorithm, which evaluates image qualities based on various factors such as cloud coverage, sky brightness, scattering light from the optical system, point spread function size and shape, and read-out noise. Occasionally, the algorithm requires masking of areas severely affected by noise. However, the algorithm often necessitates significant human interventions, reducing data processing efficiency. In this study, we present a deep learning based image quality evaluation algorithm that uses an autoencoder to learn features of high quality astronomical images. The trained autoencoder enables automatic evaluation of image quality and masking of noise affected areas. We have evaluated the performance of our algorithm using two test cases: images with point spread functions of varying full width half magnitude, and images with complex backgrounds. In the first scenario, our algorithm could effectively identify variations of the point spread functions, which can provide valuable reference information for photometry. In the second scenario, our method could successfully mask regions affected by complex regions, which could significantly increase the photometry accuracy. Our algorithm can be employed to automatically evaluate image quality obtained by different sky surveying projects, further increasing the speed and robustness of data processing pipelines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03408v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <category>cs.CV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peng Jia, Yu Song, Jiameng Lv, Runyu Ning</dc:creator>
    </item>
    <item>
      <title>Exomoons &amp; Exorings with the Habitable Worlds Observatory I: On the Detection of Earth-Moon Analog Shadows &amp; Eclipses</title>
      <link>https://arxiv.org/abs/2405.02408</link>
      <description>arXiv:2405.02408v1 Announce Type: cross 
Abstract: The highest priority recommendation of the Astro2020 Decadal Survey for space-based astronomy was the construction of an observatory capable of characterizing habitable worlds. In this paper series we explore the detectability of and interference from exomoons and exorings serendipitously observed with the proposed Habitable Worlds Observatory (HWO) as it seeks to characterize exoplanets, starting in this manuscript with Earth-Moon analog mutual events. Unlike transits, which only occur in systems viewed near edge-on, shadow (i.e., solar eclipse) and lunar eclipse mutual events occur in almost every star-planet-moon system. The cadence of these events can vary widely from ~yearly to multiple events per day, as was the case in our younger Earth-Moon system. Leveraging previous space-based (EPOXI) lightcurves of a Moon transit and performance predictions from the LUVOIR-B concept, we derive the detectability of Moon analogs with HWO. We determine that Earth-Moon analogs are detectable with observation of ~2-20 mutual events for systems within 10pc, and larger moons should remain detectable out to 20pc. We explore the extent to which exomoon mutual events can mimic planet features and weather. We find that HWO wavelength coverage in the near-IR, specifically in the 1.4 micron water band where large moons can outshine their host planet, will aid in differentiating exomoon signals from exoplanet variability. Finally, we predict that exomoons formed through collision processes akin to our Moon are more likely to be detected in younger systems, where shorter orbital periods and favorable geometry enhance the probability and frequency of mutual events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02408v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mary Anne Limbach, Jacob Lustig-Yaeger, Andrew Vanderburg, Johanna M. Vos, Rene Heller, Tyler D. Robinson</dc:creator>
    </item>
    <item>
      <title>Information content of JWST spectra of WASP-39b</title>
      <link>https://arxiv.org/abs/2405.02656</link>
      <description>arXiv:2405.02656v1 Announce Type: cross 
Abstract: WASP-39b was observed using several different JWST instrument modes and the spectra were published in a series of papers by the ERS team. The current study examines the information content of these spectra measured using the different instrument modes, focusing on the complexity of the temperature-pressure profiles and number of chemical species warranted by the data. We examine if H2O, CO, CO2, K, H2S, CH4, and SO2 are detected in each of the instrument modes. Two Bayesian inference methods are used to perform atmospheric retrievals: standard nested sampling and supervised machine learning of the random forest (trained on a model grid). For nested sampling, Bayesian model comparison is used as a guide to identify the set of models with the required complexity to explain the data. Generally, non-isothermal transit chords are needed to fit the transmission spectra of WASP-39b, although the complexity of the Tp-profile required is mode-dependent. The minimal set of chemical species needed to fit a spectrum is mode-dependent as well, and also depends on whether grey or non-grey clouds are assumed. When a non-grey cloud model is used to fit the G395H spectrum, it generates a spectral continuum that compensates for the H2O opacity. The same compensation is absent when fitting the non-grey cloud model to the PRISM spectrum (which has broader wavelength coverage), suggesting that it is spurious. The interplay between the cloud spectral continuum and the H2O opacity determines if SO2 is needed to fit either spectrum. The inferred elemental abundances of carbon and oxygen and the carbon-to-oxygen (C/O) ratios are all mode- and model-dependent, and should be interpreted with caution. Bayesian model comparison does not always offer a clear path forward for favouring specific retrieval models (e.g. grey versus non-grey clouds) and thus for enabling unambiguous interpretations of exoplanet spectra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02656v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Lueber, Aline Novais, Chloe Fisher, Kevin Heng</dc:creator>
    </item>
    <item>
      <title>MACE: A Machine learning Approach to Chemistry Emulation</title>
      <link>https://arxiv.org/abs/2405.03274</link>
      <description>arXiv:2405.03274v1 Announce Type: cross 
Abstract: The chemistry of an astrophysical environment is closely coupled to its dynamics, the latter often found to be complex. Hence, to properly model these environments a 3D context is necessary. However, solving chemical kinetics within a 3D hydro simulation is computationally infeasible for a even a modest parameter study. In order to develop a feasible 3D hydro-chemical simulation, the classical chemical approach needs to be replaced by a faster alternative. We present mace, a Machine learning Approach to Chemistry Emulation, as a proof-of-concept work on emulating chemistry in a dynamical environment. Using the context of AGB outflows, we have developed an architecture that combines the use of an autoencoder (to reduce the dimensionality of the chemical network) and a set of latent ordinary differential equations (that are solved to perform the temporal evolution of the reduced features). Training this architecture with an integrated scheme makes it possible to successfully reproduce a full chemical pathway in a dynamical environment. mace outperforms its classical analogue on average by a factor 26. Furthermore, its efficient implementation in PyTorch results in a sub-linear scaling with respect to the number of hydrodynamical simulation particles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03274v1</guid>
      <category>physics.comp-ph</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>S. Maes, F. De Ceuster, M. Van de Sande, L. Decin</dc:creator>
    </item>
    <item>
      <title>Three-temperature radiation hydrodynamics with PLUTO: Thermal and kinematic signatures of accreting protoplanets</title>
      <link>https://arxiv.org/abs/2405.03375</link>
      <description>arXiv:2405.03375v1 Announce Type: cross 
Abstract: In circumstellar disks around young stars, the gravitational influence of nascent planets produces telltale patterns in density, temperature, and kinematics. To better understand these signatures, we first performed 3D hydrodynamical simulations of a 0.012 $M_{\odot}$ disk, with a Saturn-mass planet orbiting circularly in-plane at 40 au. We tested four different disk thermodynamic prescriptions (in increasing order of complexity, local isothermality, $\beta$-cooling, two-temperature radiation hydrodynamics, and three-temperature radiation hydrodynamics), finding that $\beta$-cooling offers a reasonable approximation for the three-temperature approach when the planet is not massive or luminous enough to substantially alter the background temperature and density structure. Thereafter, using the three-temperature scheme, we relaxed this assumption, simulating a range of different planet masses (Neptune-mass, Saturn-mass, Jupiter-mass) and accretion luminosities (0, $10^{-3} L_{\odot}$) in the same disk. Our investigation revealed that signatures of disk-planet interaction strengthen with increasing planet mass, with circumplanetary flows becoming prominent in the high-planet-mass regime. Accretion luminosity, which adds pressure support around the planet, was found to weaken the midplane Doppler-flip, potentially visible in optically thin tracers like C$^{18}$O, while strengthening the spiral signature, particularly in upper disk layers sensitive to thicker lines, like those of $^{12}$CO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03375v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dhruv Muley, Julio David Melon Fuksman, Hubert Klahr</dc:creator>
    </item>
    <item>
      <title>Calibration of Uncertainties of the Gaia DR3 Catalog Based on Data on Wide Binary Stars of the Galaxy Field</title>
      <link>https://arxiv.org/abs/2405.03457</link>
      <description>arXiv:2405.03457v1 Announce Type: cross 
Abstract: The catalog of wide binary stars by El-Badry et al. (2021) [arXiv:2101.05282], created on the basis of Gaia EDR3 data and including more than a million pairs, was used to analyze Gaia DR3 data obtained independently for their components. By comparison with the model distribution, it is shown that the catalog contains approximately 2.5 times fewer binary stars than would be expected in the absence of spatial incompleteness. It is confirmed that the radius of spatial completeness of the catalog is on average close to 200 pc and depends on the absolute magnitude of the main component. The spatial density of binary stars in the catalog depends weakly on the difference in the magnitudes of the components, and significantly depends on the physical distance between the components. A high correlation between the degree of agreement between the characteristics and the reliability of the pair was found for radial velocities. Qualitative agreement is observed for metallicity [Fe/H] estimates and, to a lesser extent, for absorption A_G estimates. No agreement was found for the ages of the stars, which indicates their great uncertainty in the ensemble, consisting mainly of main sequence stars. Age estimates for pairs with evolved components show significantly better agreement than for the dataset as a whole. Using the parameters of the components of the pairs from Gaia DR3, an independent estimate of the uncertainties in the radial velocities and metallicities depending on the apparent magnitude of the sources was performed. Estimates of the probable median values of errors in the radial velocities and metallicities of Gaia DR3 sources are proposed. Depending on the apparent magnitude, they exceed the median error values given in the catalog: for radial velocities by 1.5-3 times, for metallicities [Fe/H] by 7-25 times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03457v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1134/S106377292309007X</arxiv:DOI>
      <arxiv:journal_reference>Astronomy Reports, 2023, Volume 67, Issue 9, p.938-950</arxiv:journal_reference>
      <dc:creator>Dana A. Kovaleva</dc:creator>
    </item>
    <item>
      <title>Gravitational Wave Polarization Detection with Pyramid Constellation of Gravitational Wave Observatory</title>
      <link>https://arxiv.org/abs/2405.03492</link>
      <description>arXiv:2405.03492v1 Announce Type: cross 
Abstract: In general relativity (GR), gravitational wave (GW) polarization modes are tensor named as plus and cross modes, which have been detected from the LIGO, Virgo, and KAGRA collaborations. The other GW modes beyond GR, called as two scalar polarization modes and two vector modes, have being probed especially with an expected network of Advanced LIGO, Advanced Virgo, and KAGRA. For the space-based GW detection, the LISA - Taiji networks can perform the detection of GW polarizations. For the first time, we have come up with the pyramid constellation of gravitational wave observatory(PCGO) for GW polarization detection. The configuration of PCGO can be simultaneously sensitive to the six polarization modes of GWs. The response intensity of six detector arms changes with the detector positions on orbit in one year period. The newly added three arms have a different response of GWs from the triangle arms, comparing to LISA, Taiji and Tianqin. That indicates that there are more freedoms for the polarization component extraction from the total polarization signals of GWs. Comparing to LISA, Taiji and Tianqin configuration, PCGO has more combinations of optical paths of time delay interferometer (TDI) to suppress the frequency noise. The unequal arm Michelson TDI configuration and the Sagnac TDI configuration are equally effective for elimination of the laser frequency noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03492v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hong-Bo Jin, Cong-Feng Qiao</dc:creator>
    </item>
    <item>
      <title>A Full Model of the Response of Surface Detectors to Extensive Air Showers Based on Shower Universality</title>
      <link>https://arxiv.org/abs/2405.03494</link>
      <description>arXiv:2405.03494v1 Announce Type: cross 
Abstract: We present a full model of surface-detector responses to extensive air showers. The model is motivated by the principles of air-shower universality and can be applied to different types of surface detectors. Here we describe a parametrization for both water-Cerenkov detectors and scintillator surface detectors, as for instance employed by the upgraded detector array of the Pierre Auger Observatory. Using surface detector data, the model can be used to reconstruct with reasonable precision shower observables such as the depth of the shower maximum $X_\text{max}$ and the number of muons $R_\mu$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03494v1</guid>
      <category>hep-ph</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <category>hep-ex</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Stadelmaier, Ralph Engel, Markus Roth, David Schmidt, Darko Veberic</dc:creator>
    </item>
    <item>
      <title>The Basic Iterative Deconvolution: A fast instrumental point-spread function deconvolution method that corrects for light that is scattered out of the field of view of a detector</title>
      <link>https://arxiv.org/abs/2312.11784</link>
      <description>arXiv:2312.11784v3 Announce Type: replace 
Abstract: A point-spread function describes the optics of an imaging system and can be used to correct collected images for instrumental effects. The state of the art for deconvolving images with the point-spread function is the Richardson-Lucy algorithm; however, despite its high fidelity, it is slow and cannot account for light scattered out of the field of view of the detector. We reinstate the Basic Iterative Deconvolution (BID) algorithm, a deconvolution algorithm that considers photons scattered out of the field of view of the detector, and extend it for image subregion deconvolutions. Its runtime is 1.8 to 7.1 faster than the Richardson-Lucy algorithm for 4096 x 4096 pixels images and up to an additional factor of 150 for subregions of 250 x 250 pixels. We test the extended BID algorithm for solar images taken by the Atmospheric Imaging Assembly (AIA), and find that the deviations between the reconstructed intensities of BID and the Richardson-Lucy algorithm are smaller than 1%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11784v3</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.EP</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.SR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefan Johann Hofmeister</dc:creator>
    </item>
    <item>
      <title>Expected Impact of Glints from Space Debris in the LSST</title>
      <link>https://arxiv.org/abs/2403.04942</link>
      <description>arXiv:2403.04942v2 Announce Type: replace 
Abstract: We examine the simple model put forth in a recent note by Loeb regarding the brightness of space debris in the size range of 1-10 cm and their impact on the Rubin Observatory Legacy Survey of Space and Time (LSST) transient object searches. Their main conclusion was that "image contamination by untracked space debris might pose a bigger challenge [than large commercial satellite constellations in LEO]". Following corrections and improvements to this model, we calculate the apparent brightness of tumbling low-Earth orbit (LEO) debris of various sizes, and we briefly discuss the likely impact and potential mitigations of glints from space debris in LSST. We find the majority of the difference in predicted signal-to-noise ratio (S/N), about a factor of 6, arises from the defocus of LEO objects due to the large Simonyi Survey Telescope primary mirror and finite range of the debris. The largest change from the Loeb estimates is that 1-10 cm debris in LEO pose no threat to LSST transient object alert generation because their S/N for detection will be much lower than estimated by Loeb due to defocus. We find that only tumbling LEO debris larger than 10 cm or with significantly greater reflectivity, which give 1 ms glints, might be detected with high confidence (S/N &gt; 5). We estimate that only one in five LSST exposures low on the sky during twilight might be affected. More slowly tumbling objects of larger size can give flares in brightness that are easily detected; however, these will not be cataloged by the LSST Science Pipelines because of the resulting long streak.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04942v2</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. Anthony Tyson, Adam Snyder, Daniel Polin, Meredith L. Rawls, Zeljko Ivezic</dc:creator>
    </item>
    <item>
      <title>First Results from a Broadband Search for Dark Photon Dark Matter in the $44$ to $52\,\mu$eV range with a coaxial dish antenna</title>
      <link>https://arxiv.org/abs/2310.13891</link>
      <description>arXiv:2310.13891v2 Announce Type: replace-cross 
Abstract: We present first results from a dark photon dark matter search in the mass range from 44 to 52 $\mu{\rm eV}$ ($10.7 - 12.5\,{\rm GHz}$) using a room-temperature dish antenna setup called GigaBREAD. Dark photon dark matter converts to ordinary photons on a cylindrical metallic emission surface with area $0.5\,{\rm m}^2$ and is focused by a novel parabolic reflector onto a horn antenna. Signals are read out with a low-noise receiver system. A first data taking run with 24 days of data does not show evidence for dark photon dark matter in this mass range, excluding dark photon - photon mixing parameters $\chi \gtrsim 10^{-12}$ in this range at 90% confidence level. This surpasses existing constraints by about two orders of magnitude and is the most stringent bound on dark photons in this range below 49 $\mu$eV.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13891v2</guid>
      <category>hep-ex</category>
      <category>astro-ph.IM</category>
      <category>hep-ph</category>
      <category>physics.ins-det</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevLett.132.131004</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Lett. 132, 131004 (2024)</arxiv:journal_reference>
      <dc:creator>Stefan Knirck, Gabe Hoshino, Mohamed H. Awida, Gustavo I. Cancelo, Martin Di Federico, Benjamin Knepper, Alex Lapuente, Mira Littmann, David W. Miller, Donald V. Mitchell, Derrick Rodriguez, Mark K. Ruschman, Matthew A. Sawtell, Leandro Stefanazzi, Andrew Sonnenschein, Gary W. Teafoe, Daniel Bowring, G. Carosi, Aaron Chou, Clarence L. Chang, Kristin Dona, Rakshya Khatiwada, Noah A. Kurinsky, Jesse Liu, Cristi\'an Pena, Chiara P. Salemi, Christina W. Wang, Jialin Yu</dc:creator>
    </item>
    <item>
      <title>New binary black hole mergers in the LIGO-Virgo O3b data</title>
      <link>https://arxiv.org/abs/2311.06061</link>
      <description>arXiv:2311.06061v2 Announce Type: replace-cross 
Abstract: We report the detection of 6 new candidate binary black hole (BBH) merger signals in the publicly released data from the second half of the third observing run (O3b) of advanced LIGO and advanced Virgo. The LIGO-Virgo-KAGRA (LVK) collaboration reported 35 compact binary coalescences (CBCs) in their analysis of the O3b data [1], with 30 BBH mergers having coincidence in the Hanford and Livingston detectors. We confirm 17 of these for a total of 23 detections in our analysis of the Hanford-Livingston coincident O3b data. We identify candidates using a search pipeline employing aligned-spin quadrupole-only waveforms. Our pipeline is similar to the one used in our O3a coincident analysis [2], except for a few improvements in the veto procedure and the ranking statistic, and we continue to use an astrophysical probability of one half as our detection threshold, following the approach of the LVK catalogs. Most of the new candidates reported in this work are placed in the upper and lower-mass gap of the black hole (BH) mass distribution. We also identify a possible neutron star-black hole (NSBH) merger. We expect these events to help inform the black hole mass and spin distributions inferred in a full population analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06061v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajit Kumar Mehta, Seth Olsen, Digvijay Wadekar, Javier Roulet, Tejaswi Venumadhav, Jonathan Mushkin, Barak Zackay, Matias Zaldarriaga</dc:creator>
    </item>
    <item>
      <title>Ephemeris Matching Reveals False Positive Validated and Candidate Planets from the K2 Mission</title>
      <link>https://arxiv.org/abs/2402.07903</link>
      <description>arXiv:2402.07903v2 Announce Type: replace-cross 
Abstract: Data from the Kepler space telescope have led to the discovery of thousands of planet candidates. Most of these candidates are likely to be real exoplanets, but a significant number of false positives still contaminate the sample, especially in candidate lists from the K2 mission. Identifying and rejecting the false positives lurking in the planet candidates sample is important for prioritizing follow-up resources and measuring the most accurate population statistics. Here, we identify false positives in the K2 planet candidate sample using a technique called "ephemeris matching," in which we compare the period and transit time of different signals. When signals from different stars show the same period and time of transit, we can conclude that at least one of the two signals is contamination. We identify 43 false positives among published K2 planet candidates (nearly 2% of the complete list), one of which (K2-256 b) was previously validated as genuine exoplanet. This work increases the reliability of the K2 planet sample and helps boost confidence in the surviving planet candidates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07903v2</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Drake A. Lehmann, Andrew Vanderburg</dc:creator>
    </item>
  </channel>
</rss>
