<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Oct 2024 04:00:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A method to estimate well flowing gas-oil ratio and composition using pressure and temperature measurements across a production choke, a seed composition of oil and gas, and a thermodynamic simulator</title>
      <link>https://arxiv.org/abs/2410.01371</link>
      <description>arXiv:2410.01371v1 Announce Type: new 
Abstract: In this work we propose and demonstrate a method to estimate the flowing gas-oil ratio and composition of a hydrocarbon well stream using measurements of pressure and temperature across a production choke. The method consists of using a numerical solver on a thermodynamic simulator to recombine a seed oil and gas until the simulated temperature drop across the choke is equal to the measured value. This method is meant for cases where it is not possible to measure periodically individual well composition. A study case and reference solution were generated using the reservoir model presented in the SPE (Society of Petroleum Engineers) comparative case Nr. 5 linked with a process simulator. Time profiles of well producing gas-oil ratio, wellstream compositions, compositions of surface conditions oil and gas, and temperature drop across the choke were generated with the models. The method proposed was then employed to estimate the flowing gas-oil ratio of the reference solution. Results show that the proposed method predicts with reasonable accuracy (maximum 12% percent error) the well gas-oil ratio and compositions during the life of the field when using compositions of surface oil and gas from initial time. When using compositions of surface oil and gas from later times, the prediction accuracy of the gas-oil ratio improves at those times but worsens for times before and after. A measurement error for the temperature drop across the choke of at least 0.01 {\deg}C is required to achieve convergence of the method. The mean percent error between the predicted and real mole fractions has an upper bound in time of 21% when using initial surface oil and gas as seed compositions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01371v1</guid>
      <category>cs.CE</category>
      <category>physics.app-ph</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seok Ki Moon, Milan Stanko</dc:creator>
    </item>
    <item>
      <title>Hexahedral mesh of anatomical atlas for construction of computational human brain models: Applications to modeling biomechanics and bioelectric field propagation</title>
      <link>https://arxiv.org/abs/2410.01409</link>
      <description>arXiv:2410.01409v1 Announce Type: new 
Abstract: Numerical simulations rely on constructing accurate and detailed models to produce reliable results - a task that is often challenging. This task becomes notably more difficult when the model is of the human brain, the most complex organ of the human body. We create an anatomically comprehensive hexahedral mesh of the human brain using an open-source digital brain atlas from the Open Anatomy Project. This atlas currently includes over three hundred labelled anatomical structures of the brain and represents over two decades of development. It is a valuable tool currently used by medical professionals, medical students, and researchers for gathering, presenting, and discovering knowledge about the human brain. We demonstrate that this atlas can be used to efficiently create a detailed hexahedral finite element mesh of the brain for scientific computing. The two-way correspondence between the mesh and the atlas facilitates the construction of computational models and the communication and analysis of results. We present two case studies. The first case study constructs a biomechanical model of the brain to compute brain deformations and predict traumatic brain injury risk due to violent impact. In the second case study, we construct a bioelectric model of the brain to solve the electroencephalography (EEG) forward problem, a frequent simulation process used in electrophysiology to study electromagnetic fields generated by the nervous system. These techniques are often used to help understand the behavior and functionality of the brain or for treating neurological disorders such as epilepsy. We demonstrate efficient and accurate model construction using the meshed anatomical brain atlas, as well as emphasize the importance of effective communication and contextual analysis of results for enabling multi-disciplinary scientific computing research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01409v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andy Huynh, Benjamin Zwick, Mostafa Jamshidian, Michael Halle, Adam Wittek, Karol Miller</dc:creator>
    </item>
    <item>
      <title>DrivAerNet: A Parametric Car Dataset for Data-Driven Aerodynamic Design and Graph-Based Drag Prediction</title>
      <link>https://arxiv.org/abs/2403.08055</link>
      <description>arXiv:2403.08055v1 Announce Type: cross 
Abstract: This study introduces DrivAerNet, a large-scale high-fidelity CFD dataset of 3D industry-standard car shapes, and RegDGCNN, a dynamic graph convolutional neural network model, both aimed at aerodynamic car design through machine learning. DrivAerNet, with its 4000 detailed 3D car meshes using 0.5 million surface mesh faces and comprehensive aerodynamic performance data comprising of full 3D pressure, velocity fields, and wall-shear stresses, addresses the critical need for extensive datasets to train deep learning models in engineering applications. It is 60\% larger than the previously available largest public dataset of cars, and is the only open-source dataset that also models wheels and underbody. RegDGCNN leverages this large-scale dataset to provide high-precision drag estimates directly from 3D meshes, bypassing traditional limitations such as the need for 2D image rendering or Signed Distance Fields (SDF). By enabling fast drag estimation in seconds, RegDGCNN facilitates rapid aerodynamic assessments, offering a substantial leap towards integrating data-driven methods in automotive design. Together, DrivAerNet and RegDGCNN promise to accelerate the car design process and contribute to the development of more efficient vehicles. To lay the groundwork for future innovations in the field, the dataset and code used in our study are publicly accessible at \url{https://github.com/Mohamedelrefaie/DrivAerNet}</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08055v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>physics.flu-dyn</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamed Elrefaie, Angela Dai, Faez Ahmed</dc:creator>
    </item>
    <item>
      <title>Structure-Preserving Operator Learning</title>
      <link>https://arxiv.org/abs/2410.01065</link>
      <description>arXiv:2410.01065v1 Announce Type: cross 
Abstract: Learning complex dynamics driven by partial differential equations directly from data holds great promise for fast and accurate simulations of complex physical systems. In most cases, this problem can be formulated as an operator learning task, where one aims to learn the operator representing the physics of interest, which entails discretization of the continuous system. However, preserving key continuous properties at the discrete level, such as boundary conditions, and addressing physical systems with complex geometries is challenging for most existing approaches. We introduce a family of operator learning architectures, structure-preserving operator networks (SPONs), that allows to preserve key mathematical and physical properties of the continuous system by leveraging finite element (FE) discretizations of the input-output spaces. SPONs are encode-process-decode architectures that are end-to-end differentiable, where the encoder and decoder follows from the discretizations of the input-output spaces. SPONs can operate on complex geometries, enforce certain boundary conditions exactly, and offer theoretical guarantees. Our framework provides a flexible way of devising structure-preserving architectures tailored to specific applications, and offers an explicit trade-off between performance and efficiency, all thanks to the FE discretization of the input-output spaces. Additionally, we introduce a multigrid-inspired SPON architecture that yields improved performance at higher efficiency. Finally, we release a software to automate the design and training of SPON architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01065v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nacime Bouziani, Nicolas Boull\'e</dc:creator>
    </item>
    <item>
      <title>Mixing It Up: The Cocktail Effect of Multi-Task Fine-Tuning on LLM Performance -- A Case Study in Finance</title>
      <link>https://arxiv.org/abs/2410.01109</link>
      <description>arXiv:2410.01109v1 Announce Type: cross 
Abstract: The application of large language models (LLMs) in domain-specific contexts, including finance, has expanded rapidly. Domain-specific LLMs are typically evaluated based on their performance in various downstream tasks relevant to the domain. In this work, we present a detailed analysis of fine-tuning LLMs for such tasks. Somewhat counterintuitively, we find that in domain-specific cases, fine-tuning exclusively on the target task is not always the most effective strategy. Instead, multi-task fine-tuning - where models are trained on a cocktail of related tasks - can significantly enhance performance. We demonstrate how this approach enables a small model, such as Phi-3-Mini, to achieve state-of-the-art results, even surpassing the much larger GPT-4-o model on financial benchmarks. Our study involves a large-scale experiment, training over 200 models using several widely adopted LLMs as baselines, and empirically confirms the benefits of multi-task fine-tuning. Additionally, we explore the use of general instruction data as a form of regularization, suggesting that it helps minimize performance degradation. We also investigate the inclusion of mathematical data, finding improvements in numerical reasoning that transfer effectively to financial tasks. Finally, we note that while fine-tuning for downstream tasks leads to targeted improvements in task performance, it does not necessarily result in broader gains in domain knowledge or complex domain reasoning abilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01109v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Meni Brief, Oded Ovadia, Gil Shenderovitz, Noga Ben Yoash, Rachel Lemberg, Eitam Sheetrit</dc:creator>
    </item>
    <item>
      <title>PhyMPGN: Physics-encoded Message Passing Graph Network for spatiotemporal PDE systems</title>
      <link>https://arxiv.org/abs/2410.01337</link>
      <description>arXiv:2410.01337v1 Announce Type: cross 
Abstract: Solving partial differential equations (PDEs) serves as a cornerstone for modeling complex dynamical systems. Recent progresses have demonstrated grand benefits of data-driven neural-based models for predicting spatiotemporal dynamics (e.g., tremendous speedup gain compared with classical numerical methods). However, most existing neural models rely on rich training data, have limited extrapolation and generalization abilities, and suffer to produce precise or reliable physical prediction under intricate conditions (e.g., irregular mesh or geometry, complex boundary conditions, diverse PDE parameters, etc.). To this end, we propose a new graph learning approach, namely, Physics-encoded Message Passing Graph Network (PhyMPGN), to model spatiotemporal PDE systems on irregular meshes given small training datasets. Specifically, we incorporate a GNN into a numerical integrator to approximate the temporal marching of spatiotemporal dynamics for a given PDE system. Considering that many physical phenomena are governed by diffusion processes, we further design a learnable Laplace block, which encodes the discrete Laplace-Beltrami operator, to aid and guide the GNN learning in a physically feasible solution space. A boundary condition padding strategy is also designed to improve the model convergence and accuracy. Extensive experiments demonstrate that PhyMPGN is capable of accurately predicting various types of spatiotemporal dynamics on coarse unstructured meshes, consistently achieves the state-of-the-art results, and outperforms other baselines with considerable gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01337v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bocheng Zeng, Qi Wang, Mengtao Yan, Yang Liu, Ruizhi Chengze, Yi Zhang, Hongsheng Liu, Zidong Wang, Hao Sun</dc:creator>
    </item>
    <item>
      <title>Adversarial Latent Autoencoder with Self-Attention for Structural Image Synthesis</title>
      <link>https://arxiv.org/abs/2307.10166</link>
      <description>arXiv:2307.10166v2 Announce Type: replace-cross 
Abstract: Generative Engineering Design approaches driven by Deep Generative Models (DGM) have been proposed to facilitate industrial engineering processes. In such processes, designs often come in the form of images, such as blueprints, engineering drawings, and CAD models depending on the level of detail. DGMs have been successfully employed for synthesis of natural images, e.g., displaying animals, human faces and landscapes. However, industrial design images are fundamentally different from natural scenes in that they contain rich structural patterns and long-range dependencies, which are challenging for convolution-based DGMs to generate. Moreover, DGM-driven generation process is typically triggered based on random noisy inputs, which outputs unpredictable samples and thus cannot perform an efficient industrial design exploration. We tackle these challenges by proposing a novel model Self-Attention Adversarial Latent Autoencoder (SA-ALAE), which allows generating feasible design images of complex engineering parts. With SA-ALAE, users can not only explore novel variants of an existing design, but also control the generation process by operating in latent space. The potential of SA-ALAE is shown by generating engineering blueprints in a real automotive design task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.10166v2</guid>
      <category>cs.CV</category>
      <category>cs.CE</category>
      <category>eess.IV</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/CAI59869.2024.00030</arxiv:DOI>
      <arxiv:journal_reference>2024 IEEE Conference on Artificial Intelligence (CAI)</arxiv:journal_reference>
      <dc:creator>Jiajie Fan, Laure Vuaille, Hao Wang, Thomas B\"ack</dc:creator>
    </item>
    <item>
      <title>GAL{\AE}XI: Solving complex compressible flows with high-order discontinuous Galerkin methods on accelerator-based systems</title>
      <link>https://arxiv.org/abs/2404.12703</link>
      <description>arXiv:2404.12703v2 Announce Type: replace-cross 
Abstract: This work presents GALAEXI as a novel, energy-efficient flow solver for the simulation of compressible flows on unstructured meshes leveraging the parallel computing power of modern Graphics Processing Units (GPUs). GALAEXI implements the high-order Discontinuous Galerkin Spectral Element Method (DGSEM) using shock capturing with a finite-volume subcell approach to ensure the stability of the high-order scheme near shocks. This work provides details on the general code design, the parallelization strategy, and the implementation approach for the compute kernels with a focus on the element local mappings between volume and surface data due to the unstructured mesh. GALAEXI exhibits excellent strong scaling properties up to 1024 GPUs if each GPU is assigned a minimum of one million degrees of freedom degrees of freedom. To verify its implementation, a convergence study is performed that recovers the theoretical order of convergence of the implemented numerical schemes. Moreover, the solver is validated using both the incompressible and compressible formulation of the Taylor-Green-Vortex at a Mach number of 0.1 and 1.25, respectively. A mesh convergence study shows that the results converge to the high-fidelity reference solution and that the results match the original CPU implementation. Finally, GALAEXI is applied to a large-scale wall-resolved large eddy simulation of a linear cascade of the NASA Rotor 37. Here, the supersonic region and shocks at the leading edge are captured accurately and robustly by the implemented shock-capturing approach. It is demonstrated that GALAEXI requires less than half of the energy to carry out this simulation in comparison to the reference CPU implementation. This renders GALAEXI as a potent tool for accurate and efficient simulations of compressible flows in the realm of exascale computing and the associated new HPC architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12703v2</guid>
      <category>cs.MS</category>
      <category>cs.CE</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cpc.2024.109388</arxiv:DOI>
      <arxiv:journal_reference>Computer Physics Communications (2024) 109388</arxiv:journal_reference>
      <dc:creator>Daniel Kempf, Marius Kurz, Marcel Blind, Patrick Kopper, Philipp Offenh\"auser, Anna Schwarz, Spencer Starr, Jens Keim, Andrea Beck</dc:creator>
    </item>
  </channel>
</rss>
