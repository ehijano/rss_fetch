<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CG updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CG</link>
    <description>cs.CG updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CG" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Jan 2026 05:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Granular Grassmannian Clustering Framework via the Schubert Variety of Best Fit</title>
      <link>https://arxiv.org/abs/2512.23766</link>
      <description>arXiv:2512.23766v1 Announce Type: cross 
Abstract: In many classification and clustering tasks, it is useful to compute a geometric representative for a dataset or a cluster, such as a mean or median. When datasets are represented by subspaces, these representatives become points on the Grassmann or flag manifold, with distances induced by their geometry, often via principal angles. We introduce a subspace clustering algorithm that replaces subspace means with a trainable prototype defined as a Schubert Variety of Best Fit (SVBF) - a subspace that comes as close as possible to intersecting each cluster member in at least one fixed direction. Integrated in the Linde-Buzo-Grey (LBG) pipeline, this SVBF-LBG scheme yields improved cluster purity on synthetic, image, spectral, and video action data, while retaining the mathematical structure required for downstream analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23766v1</guid>
      <category>cs.LG</category>
      <category>cs.CG</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karim Salta, Michael Kirby, Chris Peterson</dc:creator>
    </item>
    <item>
      <title>Notes on the 33-point Erd\H{o}s--Szekeres problem</title>
      <link>https://arxiv.org/abs/2512.24061</link>
      <description>arXiv:2512.24061v1 Announce Type: cross 
Abstract: The determination of $ES(7)$ is the first open case of the planar Erd\H{o}s--Szekeres problem, where the general conjecture predicts $ES(7)=33$. We present a SAT encoding for the 33-point case based on triple-orientation variables and a 4-set convexity criterion for excluding convex 7-gons, together with convex-layer anchoring constraints. The framework yields UNSAT certificates for a collection of anchored subfamilies. We also report pronounced runtime variability across configurations, including heavy-tailed behavior that currently dominates the computational effort and motivates further encoding refinements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24061v1</guid>
      <category>math.CO</category>
      <category>cs.CG</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bogdan Dumitru</dc:creator>
    </item>
    <item>
      <title>High-dimensional Regret Minimization</title>
      <link>https://arxiv.org/abs/2512.24078</link>
      <description>arXiv:2512.24078v1 Announce Type: cross 
Abstract: Multi-criteria decision making in large databases is very important in real world applications. Recently, an interactive query has been studied extensively in the database literature with the advantage of both the top-k query (with limited output size) and the skyline query (which does not require users to explicitly specify their preference function). This approach iteratively asks the user to select the one preferred within a set of options. Based on rounds of feedback, the query learns the implicit preference and returns the most favorable as a recommendation.
  However, many modern applications in areas like housing or financial product markets feature datasets with hundreds of attributes. Existing interactive algorithms either fail to scale or require excessive user interactions (often exceeding 1000 rounds). Motivated by this, we propose FHDR (Fast High-Dimensional Reduction), a novel framework that takes less than 0.01s with fewer than 30 rounds of interaction. It is considered a breakthrough in the field of interactive queries since most, if not all, existing studies are not scalable to high-dimensional datasets.
  Extensive experiments demonstrate that FHDR outperforms the best-known algorithms by at least an order of magnitude in execution time and up to several orders of magnitude in terms of the number of interactions required, establishing a new state of the art for scalable interactive regret minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24078v1</guid>
      <category>cs.DB</category>
      <category>cs.CG</category>
      <category>cs.IR</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junyu Liao, Ashwin Lall, Mitsunori Ogihara, Raymond Wong</dc:creator>
    </item>
    <item>
      <title>Topological Spatial Graph Coarsening</title>
      <link>https://arxiv.org/abs/2512.24327</link>
      <description>arXiv:2512.24327v1 Announce Type: cross 
Abstract: Spatial graphs are particular graphs for which the nodes are localized in space (e.g., public transport network, molecules, branching biological structures). In this work, we consider the problem of spatial graph reduction, that aims to find a smaller spatial graph (i.e., with less nodes) with the same overall structure as the initial one. In this context, performing the graph reduction while preserving the main topological features of the initial graph is particularly relevant, due to the additional spatial information. Thus, we propose a topological spatial graph coarsening approach based on a new framework that finds a trade-off between the graph reduction and the preservation of the topological characteristics. The coarsening is realized by collapsing short edges. In order to capture the topological information required to calibrate the reduction level, we adapt the construction of classical topological descriptors made for point clouds (the so-called persistent diagrams) to spatial graphs. This construction relies on the introduction of a new filtration called triangle-aware graph filtration. Our coarsening approach is parameter-free and we prove that it is equivariant under rotations, translations and scaling of the initial spatial graph. We evaluate the performances of our method on synthetic and real spatial graphs, and show that it significantly reduces the graph sizes while preserving the relevant topological information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24327v1</guid>
      <category>stat.ML</category>
      <category>cs.CG</category>
      <category>cs.LG</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Calissano, Etienne Lasalle</dc:creator>
    </item>
    <item>
      <title>Pointwise Distance Distributions for detecting near-duplicates in large materials databases</title>
      <link>https://arxiv.org/abs/2108.04798</link>
      <description>arXiv:2108.04798v4 Announce Type: replace 
Abstract: Many real objects are modeled as discrete sets of points, such as corners or other salient features. For our main applications in chemistry, points represent atomic centers in a molecule or a solid material. We study the problem of classifying discrete (finite and periodic) sets of unordered points under isometry, which is any transformation preserving distances in a metric space.
  Experimental noise motivates the new practical requirement to make such invariants Lipschitz continuous so that perturbing every point in its epsilon-neighborhood changes the invariant up to a constant multiple of epsilon in a suitable distance satisfying all metric axioms. Since the given points are unordered, the key challenge is to compute all invariants and metrics in a near-linear time of the input size.
  We define the Pointwise Distance Distribution (PDD) for any discrete set and prove, in addition to the properties above, the completeness of PDD for all periodic sets in general position. The PDD can compare nearly 2 million crystals from the world's five largest databases within 2 hours on a modest desktop computer. The impact is upholding data integrity in crystallography because the PDD will not allow anyone to claim a `new' material as a noisy disguise of a known crystal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2108.04798v4</guid>
      <category>cs.CG</category>
      <category>math.MG</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1137/25M1736657</arxiv:DOI>
      <dc:creator>Daniel Widdowson, Vitaliy Kurlin</dc:creator>
    </item>
    <item>
      <title>The Fr\'echet Distance Unleashed: Approximating a Dog with a Frog</title>
      <link>https://arxiv.org/abs/2407.03101</link>
      <description>arXiv:2407.03101v4 Announce Type: replace 
Abstract: We show that a variant of the continuous Frechet distance between polygonal curves can be computed using essentially the same algorithm used to solve the discrete version. The new variant is not necessarily monotone, but this shortcoming can be easily handled via refinement.
  Combined with a Dijkstra/Prim type algorithm, this leads to a realization of the Frechet distance (i.e., a morphing) that is locally optimal (aka locally correct), that is both easy to compute, and in practice, takes near linear time on many inputs. The new morphing has the property that the leash is always as short as possible. These matchings/morphings are more natural and are better than the ones computed by standard algorithms -- in particular, they handle noise more graciously. This approach should make the Frechet distance more useful for real-world applications.
  We implemented the new algorithm and various strategies to obtain reasonably fast practical performance. We performed extensive experiments on our new algorithm, and released publicly available (and easily installable and usable) Julia and Python packages. Our algorithms can be used to compute the almost-exact Frechet distance between polygonal curves.
  Implementations and numerous examples are available here: https://frechet.xyz.
  We emphasize, however, that the existing state-of-the-art algorithm/implementation in C++ is faster, by several orders of magnitude, than our current algorithm/implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03101v4</guid>
      <category>cs.CG</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sariel Har-Peled, Benjamin Raichel, Eliot W. Robson</dc:creator>
    </item>
    <item>
      <title>Computing the bridge length: the key ingredient in a continuous isometry classification of periodic point sets</title>
      <link>https://arxiv.org/abs/2410.23288</link>
      <description>arXiv:2410.23288v2 Announce Type: replace 
Abstract: The fundamental model of any periodic crystal is a periodic set of points at all atomic centres. Since crystal structures are determined in a rigid form, their strongest equivalence is rigid motion (composition of translations and rotations) or isometry (also including reflections). The recent classification of periodic point sets under rigid motion used a complete invariant isoset whose size essentially depends on the bridge length, defined as the minimum `jump' that suffices to connect any points in the given set.
  We propose a practical algorithm to compute the bridge length of any periodic point set given by a motif of points in a periodically translated unit cell. The algorithm has been tested on a large crystal dataset and is required for an efficient continuous classification of all periodic crystals. The exact computation of the bridge length is a key step to realising the inverse design of materials from new invariant values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23288v2</guid>
      <category>cs.CG</category>
      <category>cond-mat.mtrl-sci</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1107/S2053273325008253</arxiv:DOI>
      <dc:creator>Jonathan McManus, Vitaliy Kurlin</dc:creator>
    </item>
    <item>
      <title>Compressed data structures for Heegaard splittings</title>
      <link>https://arxiv.org/abs/2507.11406</link>
      <description>arXiv:2507.11406v2 Announce Type: replace 
Abstract: Heegaard splittings provide a natural representation of closed 3-manifolds by gluing two handlebodies along a common surface. These splittings can be equivalently given by two finite sets of meridians lying on the surface, which define a Heegaard diagram. We present a data structure to effectively represent Heegaard diagrams as normal curves with respect to triangulations of a surface, where the complexity is measured by the space required to express the normal coordinates' vectors in binary. This structure can be significantly more compact than triangulations of 3-manifolds, yielding exponential gains for certain families. Even with this succinct definition of complexity, we establish polynomial-time algorithms for comparing and manipulating diagrams, performing stabilizations, detecting trivial stabilizations and reductions, and computing topological invariants of the underlying manifolds, such as their fundamental and homology groups. We also contrast early implementations of our techniques with standard software programs for 3-manifolds, achieving faster algorithms for the average cases and exponential gains in speed for some particular presentations of the inputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11406v2</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <category>math.GT</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henrique Ennes, Cl\'ement Maria</dc:creator>
    </item>
    <item>
      <title>The Complexity of One or Many Faces in the Overlay of Many Arrangements</title>
      <link>https://arxiv.org/abs/2512.11445</link>
      <description>arXiv:2512.11445v2 Announce Type: replace 
Abstract: We present an extension of the Combination Lemma of [GSS89] that expresses the complexity of one or several faces in the overlay of many arrangements, as a function of the number of arrangements, the number of faces, and the complexities of these faces in the separate arrangements. Several applications of the new Combination Lemma are presented: We first show that the complexity of a single face in an arrangement of $k$ simple polygons with a total of $n$ sides is $\Theta(n \alpha(k) )$, where $\alpha(\cdot)$ is the inverse of Ackermann's function. We also give a new and simpler proof of the bound $O \left( \sqrt{m} \lambda_{s+2}( n ) \right)$ on the total number of edges of $m$ faces in an arrangement of $n$ Jordan arcs, each pair of which intersect in at most $s$ points, where $\lambda_{s}(n)$ is the maximum length of a Davenport-Schinzel sequence of order $s$ with $n$ symbols. We extend this result, showing that the total number of edges of $m$ faces in a sparse arrangement of $n$ Jordan arcs is $O \left( (n + \sqrt{m}\sqrt{w}) \frac{\lambda_{s+2}(n)}{n} \right)$, where $w$ is the total complexity of the arrangement. Several other applications and variants of the Combination Lemma are also presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11445v2</guid>
      <category>cs.CG</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/S0925-7721(98)00042-X</arxiv:DOI>
      <dc:creator>Sariel Har-Peled</dc:creator>
    </item>
    <item>
      <title>Passage-traversing optimal path planning with sampling-based algorithms</title>
      <link>https://arxiv.org/abs/2506.23614</link>
      <description>arXiv:2506.23614v2 Announce Type: replace-cross 
Abstract: This paper introduces a new paradigm of optimal path planning, i.e., passage-traversing optimal path planning (PTOPP), that optimizes paths' traversed passages for specified optimization objectives. In particular, PTOPP is utilized to find the path with optimal accessible free space along its entire length, which represents a basic requirement for paths in robotics. As passages are places where free space shrinks and becomes constrained, the core idea is to leverage the path's passage traversal status to characterize its accessible free space comprehensively. To this end, a novel passage detection and free space decomposition method using proximity graphs is proposed, enabling fast detection of sparse but informative passages and environment decompositions. Based on this preprocessing, optimal path planning with accessible free space objectives or constraints is formulated as PTOPP problems compatible with sampling-based optimal planners. Then, sampling-based algorithms for PTOPP, including their dependent primitive procedures, are developed leveraging partitioned environments for fast passage traversal check. All these methods are implemented and thoroughly tested for effectiveness and efficiency validation. Compared to existing approaches, such as clearance-based methods, PTOPP demonstrates significant advantages in configurability, solution optimality, and efficiency, addressing prior limitations and incapabilities. It is believed to provide an efficient and versatile solution to accessible free space optimization over conventional avenues and more generally, to a broad class of path planning problems that can be formulated as PTOPP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23614v2</guid>
      <category>cs.RO</category>
      <category>cs.CG</category>
      <pubDate>Thu, 01 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Huang, Hao Su, Kwok Wai Samuel Au</dc:creator>
    </item>
  </channel>
</rss>
