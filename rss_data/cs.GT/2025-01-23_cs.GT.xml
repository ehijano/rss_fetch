<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Jan 2025 05:01:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Mechanism Design for Blockchain Order Books against Selfish Miners</title>
      <link>https://arxiv.org/abs/2501.12576</link>
      <description>arXiv:2501.12576v1 Announce Type: new 
Abstract: In blockchain-based order book systems, buyers and sellers trade assets, while it is miners to match them and include their transactions in the blockchain. It is found that many miners behave selfishly and myopically, prioritizing transactions with high fees and ignoring many desirable matches that could enhance social welfare. Existing blockchain mechanisms fail to address this issue by overlooking miners' selfish behaviors. To our best knowledge, this work presents the first analytical study to quantify and understand buyer and seller transaction fee choices and selfish miners' transaction matching strategies, proving an infinitely large price of anarchy (PoA) for social welfare loss. To mitigate this, we propose an adjustable block size mechanism that is easy to implement without altering the existing decentralized protocols and still allows buyers and sellers to freely decide transaction fees and miners to selfishly match. The analysis is challenging, as pure strategy Nash equilibria do not always exist, requiring the analysis of many buyers' or sellers' interactive mixed-strategy distributions. Moreover, the system designer may even lack information about each buyer's or seller's bid/ask prices and trading quantities. Nevertheless, our mechanism achieves a well-bounded PoA, and under the homogeneous-quantity trading for non-fungible tokens (NFT), it attains a PoA of 1 with no social welfare loss. We implement our mechanism on a local instance of Ethereum to demonstrate the feasibility of our approach. Experiments based on the realistic dataset demonstrate that our mechanism achieves social optimum for homogeneous-quantity trading like NFT. It can enhance social welfare up to 3.7 times compared to the existing order book benchmarks for heterogeneous-quantity trading of Bitcoin tokens. It exhibits robustness against random variations in buyers and sellers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12576v1</guid>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <category>cs.NI</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yunshu Liu, Lingjie Duan</dc:creator>
    </item>
    <item>
      <title>Does multi-block MEV exist? Analysis of 2 years of MEV Data</title>
      <link>https://arxiv.org/abs/2501.12827</link>
      <description>arXiv:2501.12827v1 Announce Type: new 
Abstract: This study analyzes proposer-builder data and MEV-Boost payment data following the Ethereum merge in September 2022 to identify patterns of multi-block MEV. Our findings reveal fewer multi-slot sequences of builders than predicted by a random Monte Carlo simulation, with the longest observed sequence spanning 25 slots. Additionally, we observe that average MEV-Boost payments increase with the length of consecutive sequences, from approximately 0.05 ETH for single slots to 0.08 ETH for nine consecutive slots. Within longer sequences, payments per slot show a slight increase, suggesting that builders bid higher for longer sequences or the first slot after a longer sequence. A weak positive autocorrelation is found between subsequent MEV-Boost payments, challenging the hypothesis of alternating periods of low and high MEV. Finally, our comparison of builders during periods of low and high base fee volatility reveals minimal correlation, indicating the absence of builder specialization based on base fee volatility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12827v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Pascal Stichler</dc:creator>
    </item>
    <item>
      <title>Probabilistic Analysis of Stable Matching in Large Markets with Siblings</title>
      <link>https://arxiv.org/abs/2501.13043</link>
      <description>arXiv:2501.13043v1 Announce Type: new 
Abstract: We study a practical centralized matching problem which assigns children to daycare centers. The collective preferences of siblings from the same family introduce complementarities, which can lead to the absence of stable matchings, as observed in the hospital-doctor matching problems involving couples. Intriguingly, stable matchings are consistently observed in real-world daycare markets, despite the prevalence of sibling applicants.
  We conduct a probabilistic analysis of large random markets to examine the existence of stable matchings in such markets. Specifically, we examine scenarios where daycare centers have similar priorities over children, a common characteristic in real-world markets. Our analysis reveals that as the market size approaches infinity, the likelihood of stable matchings existing converges to 1.
  To facilitate our exploration, we refine an existing heuristic algorithm to address a more rigorous stability concept, as the original one may fail to meet this criterion. Through extensive experiments on both real-world and synthetic datasets, we demonstrate the effectiveness of our revised algorithm in identifying stable matchings, particularly when daycare priorities exhibit high similarity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13043v1</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhaohong Sun, Tomohiko Yokoyama, Makoto Yokoo</dc:creator>
    </item>
    <item>
      <title>Stable Matching with Interviews</title>
      <link>https://arxiv.org/abs/2501.12503</link>
      <description>arXiv:2501.12503v1 Announce Type: cross 
Abstract: In several two-sided markets, including labor and dating, agents typically have limited information about their preferences prior to mutual interactions. This issue can result in matching frictions, as arising in the labor market for medical residencies, where high application rates are followed by a large number of interviews. Yet, the extensive literature on two-sided matching primarily focuses on models where agents know their preferences, leaving the interactions necessary for preference discovery largely overlooked. This paper studies this problem using an algorithmic approach, extending Gale-Shapley's deferred acceptance to this context.
  Two algorithms are proposed. The first is an adaptive algorithm that expands upon Gale-Shapley's deferred acceptance by incorporating interviews between applicants and positions. Similar to deferred acceptance, one side sequentially proposes to the other. However, the order of proposals is carefully chosen to ensure an interim stable matching is found. Furthermore, with high probability, the number of interviews conducted by each applicant or position is limited to $O(\log^2 n)$.
  In many seasonal markets, interactions occur more simultaneously, consisting of an initial interview phase followed by a clearing stage. We present a non-adaptive algorithm for generating a single stage set of in tiered random markets. The algorithm finds an interim stable matching in such markets while assigning no more than $O(\log^3 n)$ interviews to each applicant or position.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12503v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Itai Ashlagi, Jiale Chen, Mohammad Roghani, Amin Saberi</dc:creator>
    </item>
    <item>
      <title>Information Design for Adaptive Organizations</title>
      <link>https://arxiv.org/abs/2501.12669</link>
      <description>arXiv:2501.12669v1 Announce Type: cross 
Abstract: This paper examines the optimal design of information sharing in organizations. Organizational performance depends on agents adapting to uncertain external environments while coordinating their actions, where coordination incentives and synergies are modeled as graphs (networks). The equilibrium strategies and the principal's objective function are summarized using Laplacian matrices of these graphs. I formulate a Bayesian persuasion problem to determine the optimal public signal and show that it comprises a set of statistics on local states, necessarily including their average, which serves as the organizational goal. When the principal benefits equally from the coordination of any two agents, the choice of disclosed statistics is based on the Laplacian eigenvectors and eigenvalues of the incentive graph. The algebraic connectivity (the second smallest Laplacian eigenvalue) determines the condition for full revelation, while the Laplacian spectral radius (the largest Laplacian eigenvalue) establishes the condition for minimum transparency, where only the average state is disclosed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12669v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.SI</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wataru Tamura</dc:creator>
    </item>
    <item>
      <title>Paper Quality Assessment based on Individual Wisdom Metrics from Open Peer Review</title>
      <link>https://arxiv.org/abs/2501.13014</link>
      <description>arXiv:2501.13014v1 Announce Type: cross 
Abstract: This study proposes a data-driven framework for enhancing the accuracy and efficiency of scientific peer review through an open, bottom-up process that estimates reviewer quality. Traditional closed peer review systems, while essential for quality control, are often slow, costly, and subject to biases that can impede scientific progress. Here, we introduce a method that evaluates individual reviewer reliability by quantifying agreement with community consensus scores and applying Bayesian weighting to refine paper quality assessments. We analyze open peer review data from two major scientific conferences, and demonstrate that reviewer-specific quality scores significantly improve the reliability of paper quality estimation. Perhaps surprisingly, we find that reviewer quality scores are unrelated to authorship quality. Our model incorporates incentive structures to recognize high-quality reviewers and encourage broader coverage of submitted papers, thereby mitigating the common "rich-get-richer" pitfall of social media. These findings suggest that open peer review, with mechanisms for estimating and incentivizing reviewer quality, offers a scalable and equitable alternative for scientific publishing, with potential to enhance the speed, fairness, and transparency of the peer review process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13014v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrii Zahorodnii, Jasper J. F. van den Bosch, Ian Charest, Christopher Summerfield, Ila R. Fiete</dc:creator>
    </item>
    <item>
      <title>Group fairness in dynamic refugee assignment</title>
      <link>https://arxiv.org/abs/2301.10642</link>
      <description>arXiv:2301.10642v3 Announce Type: replace 
Abstract: Ensuring that refugees and asylum seekers thrive (e.g., find employment) in their host countries is a profound humanitarian goal, and a primary driver of employment is the geographic location within a host country to which the refugee or asylum seeker is assigned. Recent research has proposed and implemented algorithms that assign refugees and asylum seekers to geographic locations in a manner that maximizes the average employment across all arriving refugees. While these algorithms can have substantial overall positive impact, using data from two industry collaborators we show that the impact of these algorithms can vary widely across key subgroups based on country of origin, age, or educational background. Thus motivated, we develop a simple and interpretable framework for incorporating group fairness into the dynamic refugee assignment problem. In particular, the framework can flexibly incorporate many existing and future definitions of group fairness from the literature (e.g., Random, Proportionally Optimized within-group, and MaxMin). Equipped with our framework, we propose two bid-price algorithms that maximize overall employment while simultaneously yielding provable group fairness guarantees. Through extensive numerical experiments using various definitions of group fairness and real-world data from the U.S. and the Netherlands, we show that our algorithms can yield substantial improvements in group fairness compared to an offline benchmark fairness constraints, with only small relative decreases ($\approx$ 1%-5%) in global performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.10642v3</guid>
      <category>cs.GT</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Freund, Thodoris Lykouris, Elisabeth Paulson, Bradley Sturt, Wentao Weng</dc:creator>
    </item>
    <item>
      <title>CHG Shapley: Efficient Data Valuation and Selection towards Trustworthy Machine Learning</title>
      <link>https://arxiv.org/abs/2406.11730</link>
      <description>arXiv:2406.11730v3 Announce Type: replace 
Abstract: Understanding the decision-making process of machine learning models is crucial for ensuring trustworthy machine learning. Data Shapley, a landmark study on data valuation, advances this understanding by assessing the contribution of each datum to model performance. However, the resource-intensive and time-consuming nature of multiple model retraining poses challenges for applying Data Shapley to large datasets. To address this, we propose the CHG (compound of Hardness and Gradient) utility function, which approximates the utility of each data subset on model performance in every training epoch. By deriving the closed-form Shapley value for each data point using the CHG utility function, we reduce the computational complexity to that of a single model retraining, achieving a quadratic improvement over existing marginal contribution-based methods. We further leverage CHG Shapley for real-time data selection, conducting experiments across three settings: standard datasets, label noise datasets, and class imbalance datasets. These experiments demonstrate its effectiveness in identifying high-value and noisy data. By enabling efficient data valuation, CHG Shapley promotes trustworthy model training through a novel data-centric perspective. Our codes are available at https://github.com/caihuaiguang/CHG-Shapley-for-Data-Valuation and https://github.com/caihuaiguang/CHG-Shapley-for-Data-Selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11730v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Huaiguang Cai</dc:creator>
    </item>
    <item>
      <title>You Can't Always Get What You Want: Games of Ordered Preference</title>
      <link>https://arxiv.org/abs/2410.21447</link>
      <description>arXiv:2410.21447v2 Announce Type: replace 
Abstract: We study noncooperative games, in which each player's objective is composed of a sequence of ordered- and potentially conflicting-preferences. Problems of this type naturally model a wide variety of scenarios: for example, drivers at a busy intersection must balance the desire to make forward progress with the risk of collision. Mathematically, these problems possess a nested structure, and to behave properly players must prioritize their most important preference, and only consider less important preferences to the extent that they do not compromise performance on more important ones. We consider multi-agent, noncooperative variants of these problems, and seek generalized Nash equilibria in which each player's decision reflects both its hierarchy of preferences and other players' actions. We make two key contributions. First, we develop a recursive approach for deriving the first-order optimality conditions of each player's nested problem. Second, we propose a sequence of increasingly tight relaxations, each of which can be transcribed as a mixed complementarity problem and solved via existing methods. Experimental results demonstrate that our approach reliably converges to equilibrium solutions that strictly reflect players' individual ordered preferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21447v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dong Ho Lee, Lasse Peters, David Fridovich-Keil</dc:creator>
    </item>
    <item>
      <title>Computing Threshold Budgets in Discrete-Bidding Games</title>
      <link>https://arxiv.org/abs/2210.02773</link>
      <description>arXiv:2210.02773v4 Announce Type: replace-cross 
Abstract: In a two-player zero-sum graph game, the players move a token throughout a graph to produce an infinite play, which determines the winner of the game. Bidding games are graph games in which in each turn, an auction (bidding) determines which player moves the token: the players have budgets, and in each turn, both players simultaneously submit bids that do not exceed their available budgets, the higher bidder moves the token, and pays the bid to the lower bidder (called Richman bidding). We focus on discrete-bidding games, in which, motivated by practical applications, the granularity of the players' bids is restricted, e.g., bids must be given in cents.
  A central quantity in bidding games is threshold budgets: a necessary and sufficient initial budget for winning the game. Previously, thresholds were shown to exist in parity games, but their structure was only understood for reachability games. Moreover, the previously-known algorithms have a worst-case exponential running time for both reachability and parity objectives, and output strategies that use exponential memory. We describe two algorithms for finding threshold budgets in parity discrete-bidding games. The first is a fixed-point algorithm. It reveals, for the first time, the structure of threshold budgets in parity discrete-bidding games. Based on this structure, we develop a second algorithm that shows that the problem of finding threshold budgets is in NP and coNP for both reachability and parity objectives. Moreover, our algorithm constructs strategies that use only linear memory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.02773v4</guid>
      <category>cs.FL</category>
      <category>cs.GT</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46298/theoretics.25.5</arxiv:DOI>
      <arxiv:journal_reference>TheoretiCS, Volume 4 (2025), Article 5, 1-45</arxiv:journal_reference>
      <dc:creator>Guy Avni, Suman Sadhukhan</dc:creator>
    </item>
    <item>
      <title>Continuous Social Networks</title>
      <link>https://arxiv.org/abs/2407.11710</link>
      <description>arXiv:2407.11710v2 Announce Type: replace-cross 
Abstract: We develop an extension of the classical model of DeGroot (1974) to a continuum of agents when they interact among them according to a DiKernel. We show that, under some regularity assumptions, the continuous model is the limit case of the discrete one. Additionally, we establish sufficient conditions for the emergence of consensus. We provide some applications of these results. First, we establish a canonical way to reduce the dimensionality of matrices by comparing matrices of different dimensions in the space of DiKernels. Then, we develop a model of Lobby Competition where two lobbies compete to bias the opinion of a continuum of agents. We give sufficient conditions for the existence of a Nash Equilibrium and study their relation with the equilibria of discretizations of the game. Finally, we characterize the equilibrium for a particular case of DiKernels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11710v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juli\'an Chitiva, Xavier Venel</dc:creator>
    </item>
  </channel>
</rss>
