<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Sep 2025 04:00:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Multi-population Ensemble Genetic Programming via Cooperative Coevolution and Multi-view Learning for Classification</title>
      <link>https://arxiv.org/abs/2509.19339</link>
      <description>arXiv:2509.19339v1 Announce Type: new 
Abstract: This paper introduces Multi-population Ensemble Genetic Programming (MEGP), a computational intelligence framework that integrates cooperative coevolution and the multiview learning paradigm to address classification challenges in high-dimensional and heterogeneous feature spaces. MEGP decomposes the input space into conditionally independent feature subsets, enabling multiple subpopulations to evolve in parallel while interacting through a dynamic ensemble-based fitness mechanism. Each individual encodes multiple genes whose outputs are aggregated via a differentiable softmax-based weighting layer, enhancing both model interpretability and adaptive decision fusion. A hybrid selection mechanism incorporating both isolated and ensemble-level fitness promotes inter-population cooperation while preserving intra-population diversity. This dual-level evolutionary dynamic facilitates structured search exploration and reduces premature convergence. Experimental evaluations across eight benchmark datasets demonstrate that MEGP consistently outperforms a baseline GP model in terms of convergence behavior and generalization performance. Comprehensive statistical analyses validate significant improvements in Log-Loss, Precision, Recall, F1 score, and AUC. MEGP also exhibits robust diversity retention and accelerated fitness gains throughout evolution, highlighting its effectiveness for scalable, ensemble-driven evolutionary learning. By unifying population-based optimization, multi-view representation learning, and cooperative coevolution, MEGP contributes a structurally adaptive and interpretable framework that advances emerging directions in evolutionary machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19339v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Sadegh Khorshidi, Navid Yazdanjue, Hassan Gharoun, Mohammad Reza Nikoo, Fang Chen, Amir H. Gandomi</dc:creator>
    </item>
    <item>
      <title>Fully Tensorized GPU-accelerated Multi-population Evolutionary Algorithm for Constrained Multiobjective Optimization Problems</title>
      <link>https://arxiv.org/abs/2509.19821</link>
      <description>arXiv:2509.19821v1 Announce Type: new 
Abstract: Real world constrained multiobjective optimization problems (CMOPs) are prevalent and often come with stringent time-sensitive requirements. However, most contemporary constrained multiobjective evolutionary algorithms (CMOEAs) suffer from a number of drawbacks, including complex designs, low computational efficiency, and long convergence times, which are particularly pronounced when addressing time-sensitive CMOPs. Although research on accelerating evolutionary algorithms using GPU parallelism has advanced, existing CMOEAs still face significant limitations within GPU frameworks. To overcome these challenges, this paper proposes a GPU-accelerated multi-population evolutionary algorithm, termed GMPEA. We first systematically analyze the performance bottlenecks of representative CMOEAs when implemented in a GPU environment. To address the trade-off between computational speed and solution performance, GMPEA introduces a decomposition-based multi-population approach that is fully parallelized across its entire workflow. We conducted comparative experiments on various benchmark tests and real world applications: the Weapon Target Assignment Problems. The results demonstrate that GMPEA achieves competitive performance even without time constraints, while its computational speed significantly surpasses that of the compared algorithms. More critically, under a strict time limit, the performance of GMPEA drastically outperforms its counterparts. This work provides compelling evidence of GMPEA's superiority in solving time-sensitive CMOPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19821v1</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weixiong Huang, Rui Wang, Wenhua Li, Sheng Qi, Tianyu Luo, Delong Chen, Tao Zhang, Ling Wang</dc:creator>
    </item>
    <item>
      <title>Projective Kolmogorov Arnold Neural Networks (P-KANs): Entropy-Driven Functional Space Discovery for Interpretable Machine Learning</title>
      <link>https://arxiv.org/abs/2509.20049</link>
      <description>arXiv:2509.20049v1 Announce Type: new 
Abstract: Kolmogorov-Arnold Networks (KANs) relocate learnable nonlinearities from nodes to edges, demonstrating remarkable capabilities in scientific machine learning and interpretable modeling. However, current KAN implementations suffer from fundamental inefficiencies due to redundancy in high-dimensional spline parameter spaces, where numerous distinct parameterisations yield functionally equivalent behaviors. This redundancy manifests as a "nuisance space" in the model's Jacobian, leading to susceptibility to overfitting and poor generalization. We introduce Projective Kolmogorov-Arnold Networks (P-KANs), a novel training framework that guides edge function discovery towards interpretable functional representations through entropy-minimisation techniques from signal analysis and sparse dictionary learning. Rather than constraining functions to predetermined spaces, our approach maintains spline space flexibility while introducing "gravitational" terms that encourage convergence towards optimal functional representations. Our key insight recognizes that optimal representations can be identified through entropy analysis of projection coefficients, compressing edge functions to lower-parameter projective spaces (Fourier, Chebyshev, Bessel). P-KANs demonstrate superior performance across multiple domains, achieving up to 80% parameter reduction while maintaining representational capacity, significantly improved robustness to noise compared to standard KANs, and successful application to industrial automated fiber placement prediction. Our approach enables automatic discovery of mixed functional representations where different edges converge to different optimal spaces, providing both compression benefits and enhanced interpretability for scientific machine learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20049v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alastair Poole, Stig McArthur, Saravan Kumar</dc:creator>
    </item>
    <item>
      <title>Biologically Plausible Learning via Bidirectional Spike-Based Distillation</title>
      <link>https://arxiv.org/abs/2509.20284</link>
      <description>arXiv:2509.20284v1 Announce Type: new 
Abstract: Developing biologically plausible learning algorithms that can achieve performance comparable to error backpropagation remains a longstanding challenge. Existing approaches often compromise biological plausibility by entirely avoiding the use of spikes for error propagation or relying on both positive and negative learning signals, while the question of how spikes can represent negative values remains unresolved. To address these limitations, we introduce Bidirectional Spike-based Distillation (BSD), a novel learning algorithm that jointly trains a feedforward and a backward spiking network. We formulate learning as a transformation between two spiking representations (i.e., stimulus encoding and concept encoding) so that the feedforward network implements perception and decision-making by mapping stimuli to actions, while the backward network supports memory recall by reconstructing stimuli from concept representations. Extensive experiments on diverse benchmarks, including image recognition, image generation, and sequential regression, show that BSD achieves performance comparable to networks trained with classical error backpropagation. These findings represent a significant step toward biologically grounded, spike-driven learning in neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20284v1</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Changze Lv, Yifei Wang, Yanxun Zhang, Yiyang Lu, Jingwen Xu, Di Yu, Xin Du, Xuanjing Huang, Xiaoqing Zheng</dc:creator>
    </item>
    <item>
      <title>The Impact of Structural Changes on Learning Capacity in the Fly Olfactory Neural Circuit</title>
      <link>https://arxiv.org/abs/2509.19351</link>
      <description>arXiv:2509.19351v1 Announce Type: cross 
Abstract: The Drosophila mushroom body (MB) is known to be involved in olfactory learning and memory; the synaptic plasticity of the Kenyon cell (KC) to mushroom body output neuron (MBON) synapses plays a key role in the learning process. Previous research has focused on projection neuron (PN) to Kenyon cell (KC) connectivity within the MB; we examine how perturbations to the mushroom body circuit structure and changes in connectivity, specifically within the KC to mushroom body output neuron (MBON) neural circuit, affect the MBONs' ability to distinguish between odor classes. We constructed a neural network that incorporates the connectivity between PNs, KCs, and MBONs. To train our model, we generated ten artificial input classes, which represent the projection neuron activity in response to different odors. We collected data on the number of KC-to-MBON connections, MBON error rates, and KC-to-MBON synaptic weights, among other metrics. We observed that MBONs with very few presynaptic KCs consistently performed worse than others in the odor classification task. The developmental types of KCs also played a significant role in each MBON's output. We performed random and targeted KC ablation and observed that ablating developmentally mature KCs had a greater negative impact on MBONs' learning capacity than ablating immature KCs. Random and targeted pruning of KC-MBON synaptic connections yielded results largely consistent with the ablation experiments. To further explore the various types of KCs, we also performed rewiring experiments in the PN to KC circuit. Our study furthers our understanding of olfactory neuroplasticity and provides important clues to understanding learning and memory in general. Understanding how the olfactory circuits process and learn can also have potential applications in artificial intelligence and treatments for neurodegenerative diseases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.19351v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Katherine Xie, Gabriel Koch Ocker</dc:creator>
    </item>
    <item>
      <title>Predictive Coding-based Deep Neural Network Fine-tuning for Computationally Efficient Domain Adaptation</title>
      <link>https://arxiv.org/abs/2509.20269</link>
      <description>arXiv:2509.20269v1 Announce Type: cross 
Abstract: As deep neural networks are increasingly deployed in dynamic, real-world environments, relying on a single static model is often insufficient. Changes in input data distributions caused by sensor drift or lighting variations necessitate continual model adaptation. In this paper, we propose a hybrid training methodology that enables efficient on-device domain adaptation by combining the strengths of Backpropagation and Predictive Coding. The method begins with a deep neural network trained offline using Backpropagation to achieve high initial performance. Subsequently, Predictive Coding is employed for online adaptation, allowing the model to recover accuracy lost due to shifts in the input data distribution. This approach leverages the robustness of Backpropagation for initial representation learning and the computational efficiency of Predictive Coding for continual learning, making it particularly well-suited for resource-constrained edge devices or future neuromorphic accelerators. Experimental results on the MNIST and CIFAR-10 datasets demonstrate that this hybrid strategy enables effective adaptation with a reduced computational overhead, offering a promising solution for maintaining model performance in dynamic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20269v1</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.NE</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Cardoni, Sam Leroux</dc:creator>
    </item>
    <item>
      <title>Runtime Analysis of Competitive co-Evolutionary Algorithms for Maximin Optimisation of a Bilinear Function</title>
      <link>https://arxiv.org/abs/2206.15238</link>
      <description>arXiv:2206.15238v3 Announce Type: replace 
Abstract: Co-evolutionary algorithms have a wide range of applications, such as in hardware design, evolution of strategies for board games, and patching software bugs. However, these algorithms are poorly understood and applications are often limited by pathological behaviour, such as loss of gradient, relative over-generalisation, and mediocre objective stasis. It is an open challenge to develop a theory that can predict when co-evolutionary algorithms find solutions efficiently and reliable.
  This paper provides a first step in developing runtime analysis for population-based competitive co-evolutionary algorithms. We provide a mathematical framework for describing and reasoning about the performance of co-evolutionary processes. To illustrate the framework, we introduce a population-based co-evolutionary algorithm called \pdcoea, and prove that it obtains a solution to a bilinear maximin optimisation problem in expected polynomial time. Finally, we describe settings where \pdcoea needs exponential time with overwhelmingly high probability to obtain a solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.15238v3</guid>
      <category>cs.NE</category>
      <category>q-bio.PE</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00453-024-01218-3</arxiv:DOI>
      <dc:creator>Per Kristian Lehre</dc:creator>
    </item>
    <item>
      <title>A Detection Region Method-Based Evolutionary Algorithm for Binary Constrained Multiobjective Optimization</title>
      <link>https://arxiv.org/abs/2411.08437</link>
      <description>arXiv:2411.08437v2 Announce Type: replace 
Abstract: Solving constrained multi-objective optimization problems (CMOPs) is a challenging task. While many practical algorithms have been developed to tackle CMOPs, real-world scenarios often present cases where the constraint functions are unknown or unquantifiable, resulting in only binary outcomes (feasible or infeasible). This limitation reduces the effectiveness of constraint violation guidance, which can negatively impact the performance of existing algorithms that rely on this approach. Such challenges are particularly detrimental for algorithms employing the epsilon-based method, as they hinder effective relaxation of the feasible region. To address these challenges, this paper proposes a novel algorithm called DRMCMO based on the detection region method. In DRMCMO, detection regions dynamic monitor feasible solutions to enhance convergence, helping the population escape local optima. Additionally, these regions collaborate with the neighbor pairing strategy to improve population diversity within narrow feasible areas. We have modified three existing test suites to serve as benchmark test problems for CMOPs with binary constraints(CMOP/BC) and conducted comprehensive comparative experiments with state-of-the-art algorithms on these test suites and real-world problems. The results demonstrate the strong competitiveness of DRMCMO against state-of-the-art algorithms. Given the limited research on CMOP/BC, our study offers a new perspective for advancing this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08437v2</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weixiong Huang, Rui Wang, Tao Zhang, Sheng Qi, Ling Wang</dc:creator>
    </item>
    <item>
      <title>Language Model Evolutionary Algorithms for Recommender Systems: Benchmarks and Algorithm Comparisons</title>
      <link>https://arxiv.org/abs/2411.10697</link>
      <description>arXiv:2411.10697v3 Announce Type: replace 
Abstract: In the evolutionary computing community, the remarkable language-handling capabilities and reasoning power of large language models (LLMs) have significantly enhanced the functionality of evolutionary algorithms (EAs), enabling them to tackle optimization problems involving structured language or program code. Although this field is still in its early stages, its impressive potential has led to the development of various LLM-based EAs. To effectively evaluate the performance and practical applicability of these LLM-based EAs, benchmarks with real-world relevance are essential. In this paper, we focus on LLM-based recommender systems (RSs) and introduce a benchmark problem set, named RSBench, specifically designed to assess the performance of LLM-based EAs in recommendation prompt optimization. RSBench emphasizes session-based recommendations, aiming to discover a set of Pareto optimal prompts that guide the recommendation process, providing accurate, diverse, and fair recommendations. We develop three LLM-based EAs based on established EA frameworks and experimentally evaluate their performance using RSBench. Our study offers valuable insights into the application of EAs in LLM-based RSs. Additionally, we explore key components that may influence the overall performance of the RS, providing meaningful guidance for future research on the development of LLM-based EAs in RSs. The source code of the proposed RSBench can be found at https://github.com/LiuJ-2023/RSBench/tree/main.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10697v3</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiao Liu, Zhu Sun, Shanshan Feng, Caishun Chen, Yew-Soon Ong</dc:creator>
    </item>
    <item>
      <title>The Iterative Chainlet Partitioning Algorithm for the Traveling Salesman Problem with Drone and Neural Acceleration</title>
      <link>https://arxiv.org/abs/2504.15147</link>
      <description>arXiv:2504.15147v2 Announce Type: replace 
Abstract: This study introduces the Iterative Chainlet Partitioning (ICP) algorithm and its neural acceleration for solving the Traveling Salesman Problem with Drone (TSP-D). The proposed ICP algorithm decomposes a TSP-D solution into smaller segments called chainlets, each optimized individually by a dynamic programming subroutine. The chainlet with the highest improvement is updated, and the procedure is repeated until no further improvement is possible. We show that the subroutine runs in quadratic time and the number of subroutine calls is bounded linearly in problem size for the first iteration and remains constant in subsequent iterations, ensuring algorithmic scalability. Empirical results show that ICP outperforms existing algorithms in both solution quality and computational time. Tested over 1,249 benchmark instances, ICP yields an average improvement of 2.6\% in solution quality over the previous state-of-the-art algorithm while reducing computational time by 91.3\%. The procedure is deterministic, ensuring reliability without requiring multiple runs. The subroutine is the computational bottleneck in the already efficient ICP algorithm. To reduce the necessity of subroutine calls, we integrate a graph neural network (GNN) to predict incremental improvements. We demonstrate that the resulting Neuro ICP (NICP) achieves substantial acceleration while maintaining solution quality. Compared to ICP, NICP reduces the total computational time by 28.6\%, while the objective function value increase is limited to 0.14\%. A transfer learning framework enables efficient extension to various operational constraints, making this a valuable foundation for developing efficient algorithms for truck-drone synchronized routing problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15147v2</guid>
      <category>cs.NE</category>
      <pubDate>Thu, 25 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jae Hyeok Lee, Minwoo Kim, Minjun Kim, Jinkyoo Park, Changhyun Kwon</dc:creator>
    </item>
  </channel>
</rss>
