<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 26 Jan 2026 05:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Gen-DBA: Generative Database Agents (Towards a Move 37 for Databases)</title>
      <link>https://arxiv.org/abs/2601.16409</link>
      <description>arXiv:2601.16409v1 Announce Type: new 
Abstract: Move\,37 marks one of the major breakthroughs in AI in terms of its ability to surpass human expertise and discover novel strategies beyond the traditional game play in the strategic two-player board game of Go. The domains of Natural Language Processing, Computer Vision, and Robotics have also undergone a similar phenomenon through the advent of large foundational models in the form of Large Language Models (LLMs), Vision Language Models (VLMs) and Vision Language Action models (VLAs), respectively. In this paper, we investigate the current state of Artificial Intelligence for Database Systems research (AI4DB), and assess how far AI4DB systems are from achieving their own Move\,37 moment. We envision a Generative Database Agent (Gen-DBA, for short) as the pathway to achieving Move\,37 for database systems that will bring generative reasoning and creativity into the realm of database learning tasks. This vision paper explores this direction by presenting the recipe for building Gen-DBA that encompasses but is not limited to a Transformer backbone, a hardware-grounded tokenization mechanism, a two-stage Goal-Directed Next Token Prediction training paradigm, and a generative inference process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16409v1</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yeasir Rayhan, Walid G. Aref</dc:creator>
    </item>
    <item>
      <title>iPDB -- Optimizing SQL Queries with ML and LLM Predicates</title>
      <link>https://arxiv.org/abs/2601.16432</link>
      <description>arXiv:2601.16432v1 Announce Type: new 
Abstract: Structured Query Language (SQL) has remained the standard query language for databases. SQL is highly optimized for processing structured data laid out in relations. Meanwhile, in the present application development landscape, it is highly desirable to utilize the power of learned models to perform complex tasks. Large language models (LLMs) have been shown to understand and extract information from unstructured textual data. However, SQL as a query language and accompanying relational database systems are either incompatible or inefficient for workloads that require leveraging learned models. This results in complex engineering and multiple data migration operations that move data between the data sources and the model inference platform. In this paper, we present iPDB, a relational system that supports in-database machine learning (ML) and large language model (LLM) inferencing using extended SQL syntax. In iPDB, LLMs and ML calls can function as semantic projects, as predicates to perform semantic selects and semantic joins, or for semantic grouping in group-by clauses. iPDB has a novel relational predict operator and semantic query optimizations that enable users to write and efficiently execute semantic SQL queries, outperforming the state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16432v1</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Udesh Kumarasinghe, Tyler Liu, Chunwei Liu, Walid G. Aref</dc:creator>
    </item>
    <item>
      <title>A Scalable Transaction Management Framework for Consistent Document-Oriented NoSQL Databases</title>
      <link>https://arxiv.org/abs/2601.16490</link>
      <description>arXiv:2601.16490v1 Announce Type: new 
Abstract: NoSQL databases are widely used in modern applications due to their scalability and schema flexibility, yet they often rely on eventual consistency models that limit reliable transaction processing. This study proposes a four-stage transaction management framework for document-oriented NoSQL databases, with MongoDB as the reference platform. The framework combines transaction lifecycle management, operation classification, pre-execution conflict detection, and an adaptive locking strategy with timeout-based deadlock prevention. Formal correctness analysis shows that the proposed approach guarantees conflict serializability under defined conditions. An experimental evaluation using the Yahoo Cloud Serving Benchmark (YCSB) workloads A, B, and F, with concurrency levels ranging from 1 to 100 clients, demonstrates a reduction in transaction abort rates from 8.3% to 4.7%, the elimination of observed deadlocks, and a 34.2% decrease in latency variance. Throughput improvements ranging from 6.3% to 18.4% are observed under high concurrency, particularly for read-modify-write workloads. Distributed experiments on clusters of up to 9 nodes confirm scalability, achieving 15.2% higher throughput and 53% lower abort rates than baseline systems. Comparisons with MongoDB's native transactions, CockroachDB, and TiDB indicate that the proposed framework strikes a good balance between consistency guarantees and performance overhead. Sensitivity analysis identifies optimal parameter settings, including a lock timeout of 100 ms, an initial backoff of 10 ms, and a maximum backoff of 500 ms. These results show that carefully designed consistency mechanisms can significantly improve data integrity in NoSQL systems without undermining scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16490v1</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adam A. E. Alflahi, Mohammed A. Y. Mohammed, Abdallah Alsammani</dc:creator>
    </item>
    <item>
      <title>A Categorical Approach to Semantic Interoperability across Building Lifecycle</title>
      <link>https://arxiv.org/abs/2601.16663</link>
      <description>arXiv:2601.16663v1 Announce Type: new 
Abstract: Buildings generate heterogeneous data across their lifecycle, yet integrating these data remains a critical unsolved challenge. Despite three decades of standardization efforts, over 40 metadata schemas now span the building lifecycle, with fragmentation accelerating rather than resolving. Current approaches rely on point-to-point mappings that scale quadratically with the number of schemas, or universal ontologies that become unwieldy monoliths. The fundamental gap is the absence of mathematical foundations for structure-preserving transformations across heterogeneous building data. Here we show that category theory provides these foundations, enabling systematic data integration with $O(n)$ specification complexity for $n$ ontologies. We formalize building ontologies as first-order theories and demonstrate two proof-of-concept implementations in Categorical Query Language (CQL): 1) generating BRICK models from IFC design data at commissioning, and 2) three-way integration of IFC, BRICK, and RealEstateCore where only two explicit mappings yield the third automatically through categorical composition. Our correct-by-construction approach treats property sets as first-class schema entities and provides automated bidirectional migrations, and enables cross-ontology queries. These results establish feasibility of categorical methods for building data integration and suggest a path toward an app ecosystem for buildings, where mathematical foundations enable reliable component integration analogous to smartphone platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16663v1</guid>
      <category>cs.DB</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zoltan Nagy, Ryan Wisnesky, Kevin Carlson, Eswaran Subrahmanian, Gioele Zardini</dc:creator>
    </item>
    <item>
      <title>Integrating Meteorological and Operational Data: A Novel Approach to Understanding Railway Delays in Finland</title>
      <link>https://arxiv.org/abs/2601.16592</link>
      <description>arXiv:2601.16592v1 Announce Type: cross 
Abstract: Train delays result from complex interactions between operational, technical, and environmental factors. While weather impacts railway reliability, particularly in Nordic regions, existing datasets rarely integrate meteorological information with operational train data. This study presents the first publicly available dataset combining Finnish railway operations with synchronized meteorological observations from 2018-2024. The dataset integrates operational metrics from Finland Digitraffic Railway Traffic Service with weather measurements from 209 environmental monitoring stations, using spatial-temporal alignment via Haversine distance. It encompasses 28 engineered features across operational variables and meteorological measurements, covering approximately 38.5 million observations from Finland's 5,915-kilometer rail network. Preprocessing includes strategic missing data handling through spatial fallback algorithms, cyclical encoding of temporal features, and robust scaling of weather data to address sensor outliers. Analysis reveals distinct seasonal patterns, with winter months exhibiting delay rates exceeding 25\% and geographic clustering of high-delay corridors in central and northern Finland. Furthermore, the work demonstrates applications of the data set in analysing the reliability of railway traffic in Finland. A baseline experiment using XGBoost regression achieved a Mean Absolute Error of 2.73 minutes for predicting station-specific delays, demonstrating the dataset's utility for machine learning applications. The dataset enables diverse applications, including train delay prediction, weather impact assessment, and infrastructure vulnerability mapping, providing researchers with a flexible resource for machine learning applications in railway operations research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16592v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vinicius Pozzobon Borin, Jean Michel de Souza Sant'Ana, Usama Raheel, Nurul Huda Mahmood</dc:creator>
    </item>
    <item>
      <title>HapticMatch: An Exploration for Generative Material Haptic Simulation and Interaction</title>
      <link>https://arxiv.org/abs/2601.16639</link>
      <description>arXiv:2601.16639v1 Announce Type: cross 
Abstract: High-fidelity haptic feedback is essential for immersive virtual environments, yet authoring realistic tactile textures remains a significant bottleneck for designers. We introduce HapticMatch, a visual-to-tactile generation framework designed to democratize haptic content creation. We present a novel dataset containing precisely aligned pairs of micro-scale optical images, surface height maps, and friction-induced vibrations for 100 diverse materials. Leveraging this data, we explore and demonstrate that conditional generative models like diffusion and flow-matching can synthesize high-fidelity, renderable surface geometries directly from standard RGB photos. By enabling a "Scan-to-Touch" workflow, HapticMatch allows interaction designers to rapidly prototype multimodal surface sensations without specialized recording equipment, bridging the gap between visual and tactile immersion in VR/AR interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16639v1</guid>
      <category>cs.HC</category>
      <category>cs.DB</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingxin Zhang, Yu Yao, Yasutoshi Makino, Hiroyuki Shinoda, Masashi Sugiyama</dc:creator>
    </item>
    <item>
      <title>Translating database mathematical schemes into relational database software applications with MatBase</title>
      <link>https://arxiv.org/abs/2601.10604</link>
      <description>arXiv:2601.10604v3 Announce Type: replace 
Abstract: We present a pseudocode algorithm for translating our (Elementary) Mathematical Data Model schemes into relational ones and associated sets of non-relational constraints, used by MatBase, our intelligent data and knowledge base management system prototype. We prove that this algorithm is very fast, solid, complete, and optimal. We apply it to a mathematical scheme modeling the genealogical trees subuniverse. We also provide examples of SQL and VBA code for enforcing some of its non-relational constraints, as well as guidelines to develop code for enforcing such constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10604v3</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 26 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Mancas, Diana Christina Mancas</dc:creator>
    </item>
  </channel>
</rss>
