<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 Jan 2026 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An Almost-Optimal Upper Bound on the Push Number of the Torus Puzzle</title>
      <link>https://arxiv.org/abs/2601.08989</link>
      <description>arXiv:2601.08989v1 Announce Type: new 
Abstract: We study the Torus Puzzle, a solitaire game in which the elements of an input $m \times n$ matrix need to be rearranged into a target configuration via a sequence of unit rotations (i.e., circular shifts) of rows and/or columns. Amano et al.\ proposed a more permissive variant of the above puzzle, where each row and column rotation can shift the involved elements by any amount of positions. The number of rotations needed to solve the puzzle in the original and in the permissive variants of the puzzle are respectively known as the \emph{push number} and the \emph{drag number}, where the latter is always smaller than or equal to the former and admits an existential lower bound of $\Omega(mn)$. While this lower bound is matched by an $O(mn)$ upper bound, the push number is not so well understood. Indeed, to the best of our knowledge, only an $O(mn \cdot \max\{ m, n \})$ upper bound is currently known. In this paper, we provide an algorithm that solves the Torus Puzzle using $O(mn \cdot \log \max \{m, n\})$ unit rotations in a model that is more restricted than that of the original puzzle. This implies a corresponding upper bound on the push number and reduces the gap between the known upper and lower bounds from $\Theta(\max\{m,n\})$ to $\Theta(\log \max\{m, n\})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08989v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Caporrella, Stefano Leucci</dc:creator>
    </item>
    <item>
      <title>A Grouped Sorting Queue Supporting Dynamic Updates for Timer Management in High-Speed Network Interface Cards</title>
      <link>https://arxiv.org/abs/2601.09081</link>
      <description>arXiv:2601.09081v1 Announce Type: new 
Abstract: With the hardware offloading of network functions, network interface cards (NICs) undertake massive stateful, high-precision, and high-throughput tasks, where timers serve as a critical enabling component. However, existing timer management schemes suffer from heavy software load, low precision, lack of hardware update support, and overflow. This paper proposes two novel operations for priority queues--update and group sorting--to enable hardware timer management. To the best of our knowledge, this work presents the first hardware priority queue to support an update operation through the composition and propagation of basic operations to modify the priorities of elements within the queue. The group sorting mechanism ensures correct timing behavior post-overflow by establishing a group boundary priority to alter the sorting process and element insertion positions. Implemented with a hybrid architecture of a one-dimension (1D) systolic array and shift registers, our design is validated through packet-level simulations for flow table timeout management. Results demonstrate that a 4K-depth, 16-bit timer queue achieves over 500 MHz (175 Mpps, 12 ns precision) in a 28nm process and over 300 MHz (116 Mpps) on an FPGA. Critically, it reduces LUTs and FFs usage by 31% and 25%, respectively, compared to existing designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09081v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zekun Wang, Binghao Yue, Weitao Pan, Jianyi Shi, Yue Hao</dc:creator>
    </item>
    <item>
      <title>Dynamic Hierarchical $j$-Tree Decomposition and Its Applications</title>
      <link>https://arxiv.org/abs/2601.09139</link>
      <description>arXiv:2601.09139v1 Announce Type: new 
Abstract: We develop a new algorithmic framework for designing approximation algorithms for cut-based optimization problems on capacitated undirected graphs that undergo edge insertions and deletions. Specifically, our framework dynamically maintains a variant of the hierarchical $j$-tree decomposition of [Madry FOCS'10], achieving a poly-logarithmic approximation factor to the graph's cut structure and supporting edge updates in $O(n^{\epsilon})$ amortized update time, for any arbitrarily small constant $\epsilon \in (0,1)$.
  Consequently, we obtain new trade-offs between approximation and update/query time for fundamental cut-based optimization problems in the fully dynamic setting, including all-pairs minimum cuts, sparsest cut, multi-way cut, and multi-cut. For the last three problems, these trade-offs give the first fully-dynamic algorithms achieving poly-logarithmic approximation in sub-linear time per operation.
  The main technical ingredient behind our dynamic hierarchy is a dynamic cut-sparsifier algorithm that can handle vertex splits with low recourse. This is achieved by white-boxing the dynamic cut sparsifier construction of [Abraham et al. FOCS'16], based on forest packing, together with new structural insights about the maintenance of these forests under vertex splits. Given the versatility of cut sparsification in both the static and dynamic graph algorithms literature, we believe this construction may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09139v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gramoz Goranci, Monika Henzinger, Peter Kiss, Ali Momeni, Gernot Z\"ocklein</dc:creator>
    </item>
    <item>
      <title>Computational Complexity of Swish</title>
      <link>https://arxiv.org/abs/2601.09289</link>
      <description>arXiv:2601.09289v1 Announce Type: new 
Abstract: Swish is a card game in which players are given cards having symbols (hoops and balls), and find a valid superposition of cards, called a "swish." Dailly, Lafourcade, and Marcadet (FUN 2024) studied a generalized version of Swish and showed that the problem is solvable in polynomial time with one symbol per card, while it is NP-complete with three or more symbols per card. In this paper, we resolve the previously open case of two symbols per card, which corresponds to the original game. We show that Swish is NP-complete for this case. Specifically, we prove the NP-hardness when the allowed transformations of cards are restricted to a single (horizontal or vertical) flip or 180-degree rotation, and extend the results to the original setting allowing all three transformations. In contrast, when neither transformation is allowed, we present a polynomial-time algorithm. Combining known and our results, we establish a complete characterization of the computational complexity of Swish with respect to both the number of symbols per card and the allowed transformations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09289v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takashi Horiyama, Takehiro Ito, Jun Kawahara, Shin-ichi Minato, Akira Suzuki, Ryuhei Uehara, Yutaro Yamaguchi</dc:creator>
    </item>
    <item>
      <title>Engineering Compressed Matrix Multiplication with the Fast Walsh-Hadamard Transform</title>
      <link>https://arxiv.org/abs/2601.09477</link>
      <description>arXiv:2601.09477v1 Announce Type: new 
Abstract: We present an implementation of Pagh's compressed matrix multiplication algorithm, a randomized algorithm that constructs sketches of matrices to compute an unbiased estimate of their product. By leveraging fast polynomial multiplication via the FFT, the algorithm achieves high performance when the product matrix is sparse or contains only a small number of entries with magnitudes significantly larger than the rest. We show empirically that the algorithm is practical and can outperform state-of-the-art DGEMM implementations when the product matrix has few nonzero entries or is otherwise dominated by a small subset of elements with large magnitude. As a minor theoretical contribution, we replace the FFT with the Fast Walsh-Hadamard Transform (FWHT) in sketched multiplication, preserving all correctness and variance guarantees of the original algorithm.
  Experiments with our carefully engineered multithreaded CPU implementation for dense double-precision matrices on 64-core CPU nodes across a range of synthetic benchmarks, exhibiting variable sparsity patterns, show that the FWHT variant is up to 4 times faster than the FFT-based version. Under favorable sparsity and magnitude patterns in the product matrix, our FWHT-based implementation achieves a speedup of up to 40 over DGEMM from Intel MKL, with low probability of error in the estimates. Our implementation is released as free software and comes with NumPy-compatible Python bindings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09477v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joel Andersson, Matti Karppa</dc:creator>
    </item>
    <item>
      <title>How many users have been here for a long time? Efficient solutions for counting long aggregated visits</title>
      <link>https://arxiv.org/abs/2601.09489</link>
      <description>arXiv:2601.09489v1 Announce Type: new 
Abstract: This paper addresses the Counting Long Aggregated Visits problem, which is defined as follows. We are given $n$ users and $m$ regions, where each user spends some time visiting some regions. For a parameter $k$ and a query consisting of a subset of $r$ regions, the task is to count the number of distinct users whose aggregate time spent visiting the query regions is at least $k$. This problem is motivated by queries arising in the analysis of large-scale mobility datasets. We present several exact and approximate data structures for supporting counting long aggregated visits, as well as conditional and unconditional lower bounds. First, we describe an exact data structure that exhibits a space-time tradeoff, as well as efficient approximate solutions based on sampling and sketching techniques. We then study the problem in geometric settings where regions are points in $\mathbb{R}^d$ and queries are hyperrectangles, and derive exact data structures that achieve improved performance in these structured spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09489v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peyman Afshani, Rezaul Chowdhury, Inge Li G{\o}rtz, Mayank Goswami, Francesco Silvestri, Mariafiore Tognon</dc:creator>
    </item>
    <item>
      <title>Permutation Matching Under Parikh Budgets: Linear-Time Detection, Packing, and Disjoint Selection</title>
      <link>https://arxiv.org/abs/2601.09577</link>
      <description>arXiv:2601.09577v1 Announce Type: new 
Abstract: We study permutation (jumbled/Abelian) pattern matching over a general alphabet $\Sigma$. Given a pattern P of length m and a text T of length n, the classical task is to decide whether T contains a length-m substring whose Parikh vector equals that of P . While this existence problem admits a linear-time sliding-window solution, many practical applications require optimization and packing variants beyond mere detection. We present a unified sliding-window framework based on maintaining the Parikh-vector difference between P and the current window of T , enabling permutation matching in O(n + {\sigma}) time and O({\sigma}) space, where {\sigma} = |{\Sigma}|. Building on this foundation, we introduce a combinatorial-optimization variant that we call Maximum Feasible Substring under Pattern Supply (MFSP): find the longest substring S of T whose symbol counts are component-wise bounded by those of P . We show that MFSP can also be solved in O(n + {\sigma}) time via a two-pointer feasibility maintenance algorithm, providing an exact packing interpretation of P as a resource budget. Finally, we address non-overlapping occurrence selection by modeling each permutation match as an equal-length interval and proving that a greedy earliest-finishing strategy yields a maximum-cardinality set of disjoint matches, computable in linear time once all matches are enumerated. Our results provide concise, provably correct algorithms with tight bounds, and connect frequency-based string matching to packing-style optimization primitives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09577v1</guid>
      <category>cs.DS</category>
      <category>cs.CL</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>MD Nazmul Alam Shanto, Md. Tanzeem Rahat, Md. Manzurul Hasan</dc:creator>
    </item>
    <item>
      <title>Continuous Fairness On Data Streams</title>
      <link>https://arxiv.org/abs/2601.08976</link>
      <description>arXiv:2601.08976v1 Announce Type: cross 
Abstract: We study the problem of enforcing continuous group fairness over windows in data streams. We propose a novel fairness model that ensures group fairness at a finer granularity level (referred to as block) within each sliding window. This formulation is particularly useful when the window size is large, making it desirable to enforce fairness at a finer granularity. Within this framework, we address two key challenges: efficiently monitoring whether each sliding window satisfies block-level group fairness, and reordering the current window as effectively as possible when fairness is violated. To enable real-time monitoring, we design sketch-based data structures that maintain attribute distributions with minimal overhead. We also develop optimal, efficient algorithms for the reordering task, supported by rigorous theoretical guarantees. Our evaluation on four real-world streaming scenarios demonstrates the practical effectiveness of our approach. We achieve millisecond-level processing and a throughput of approximately 30,000 queries per second on average, depending on system parameters. The stream reordering algorithm improves block-level group fairness by up to 95% in certain cases, and by 50-60% on average across datasets. A qualitative study further highlights the advantages of block-level fairness compared to window-level fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08976v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>cs.DS</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Subhodeep Ghosh, Zhihui Du, Angela Bonifati, Manish Kumar, David Bader, Senjuti Basu Roy</dc:creator>
    </item>
    <item>
      <title>SCaLE: Switching Cost aware Learning and Exploration</title>
      <link>https://arxiv.org/abs/2601.09042</link>
      <description>arXiv:2601.09042v1 Announce Type: cross 
Abstract: This work addresses the fundamental problem of unbounded metric movement costs in bandit online convex optimization, by considering high-dimensional dynamic quadratic hitting costs and $\ell_2$-norm switching costs in a noisy bandit feedback model. For a general class of stochastic environments, we provide the first algorithm SCaLE that provably achieves a distribution-agnostic sub-linear dynamic regret, without the knowledge of hitting cost structure. En-route, we present a novel spectral regret analysis that separately quantifies eigenvalue-error driven regret and eigenbasis-perturbation driven regret. Extensive numerical experiments, against online-learning baselines, corroborate our claims, and highlight statistical consistency of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09042v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Neelkamal Bhuyan, Debankur Mukherjee, Adam Wierman</dc:creator>
    </item>
    <item>
      <title>On the complexity of global Roman domination problem in graphs</title>
      <link>https://arxiv.org/abs/2601.09167</link>
      <description>arXiv:2601.09167v1 Announce Type: cross 
Abstract: A Roman dominating function of a graph $G=(V,E)$ is a labeling $f: V \rightarrow{} \{0 ,1, 2\}$ such that for each vertex $u \in V$ with $f(u) = 0$, there exists a vertex $v \in N(u)$ with $f(v) =2$. A Roman dominating function $f$ is a global Roman dominating function if it is a Roman dominating function for both $G$ and its complement $\overline{G}$. The weight of $f$ is the sum of $f(u)$ over all the vertices $u \in V$. The objective of Global Roman Domination problem is to find a global Roman dominating function with minimum weight. The objective of Global Roman Domination is to compute a global Roman dominating function of minimum weight.
  In this paper, we study the algorithmic aspects of Global Roman Domination problem on various graph classes and obtain the following results.
  1. We prove that Roman domination and Global Roman Domination problems are not computationally equivalent by identifying graph classes on which one is linear-time solvable, while the other is NP-complete.
 2. We show that Global Roman Domination problem is NP-complete on split graphs, thereby resolving an open question posed by Panda and Goyal [Discrete Applied Mathematics, 2023].
  3. We prove that Global Roman Domination problem is NP-complete on chordal bipartite graphs, planar bipartite graphs with maximum degree five and circle graphs.
  4. On the positive side, we present a linear-time algorithm for Global Roman domination problem on cographs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09167v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sangam Balchandar Reddy, Arun Kumar Das, Anjeneya Swami Kare, I. Vinod Reddy</dc:creator>
    </item>
    <item>
      <title>On Numbers of Simplicial Walks and Equivalent Canonizations for Graph Recognition</title>
      <link>https://arxiv.org/abs/2601.09506</link>
      <description>arXiv:2601.09506v1 Announce Type: cross 
Abstract: Two graphs are isomorphic exactly when they admit the same number of homomorphisms from every graph. Hence, a graph is recognized up to isomorphism by homomorphism counts over the class of all graphs. Restricting to a specific graph class yields some natural isomorphism relaxations and modulates recognition to particular graph properties. A notable restriction is to the classes of bounded treewidth, yielding the isomorphism relaxation of Weisfeiler--Leman refinement (WL), as shown by Dvo\v{r}\'{a}k [JGT 2010]. The properties recognized by WL are exactly those definable in fragments of first-order logic with counting quantifiers, as shown by Cai, F\"{u}rer, and Immerman [Comb. 1992].
  We characterize the restriction to the classes of bounded pathwidth by numbers of simplicial walks, and formalize it into a refinement procedure (SW). The properties recognized by SW are exactly those definable in fragments of restricted-conjunction first-order logic with counting quantifiers, introduced by Montacute and Shah [LMCS 2024].
  Unlike WL, computing SW directly is not polynomial-time in general. We address this by representing SW in terms of multiplicity automata. We equip these automata with an involution, simplifying the canonization to standard forward reduction and omitting the backward one. The resulting canonical form is computable in time $O(kn^{3k})$ for any graph on $n$ vertices and the restriction to pathwidth at most $k$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09506v1</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marek \v{C}ern\'y</dc:creator>
    </item>
    <item>
      <title>Boltzmann Sampling for Powersets without an Oracle</title>
      <link>https://arxiv.org/abs/2601.09508</link>
      <description>arXiv:2601.09508v1 Announce Type: cross 
Abstract: We show that powersets over structures with a bounded counting sequence can be sampled efficiently without evaluating the generating function. An algorithm is provided, implemented, and tested. Runtimes are comparable to existing Boltzmann samplers reported in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09508v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean Peyen</dc:creator>
    </item>
    <item>
      <title>Parameterized Complexity of Biclique Contraction and Balanced Biclique Contraction</title>
      <link>https://arxiv.org/abs/2307.10607</link>
      <description>arXiv:2307.10607v2 Announce Type: replace 
Abstract: In this work, we initiate the complexity study of Biclique Contraction and Balanced Biclique Contraction. In these problems, given as input a graph G and an integer k, the objective is to determine whether one can contract at most k edges in G to obtain a biclique and a balanced biclique, respectively. We first prove that these problems are NP-complete even when the input graph is bipartite. Next, we study the parameterized complexity of these problems and show that they admit single exponential-time FPT algorithms when parameterized by the number k of edge contractions. Then, we show that Balanced Biclique Contraction admits a quadratic vertex kernel while Biclique Contraction does not admit any polynomial compression (or kernel) under standard complexity-theoretic assumptions. We also give faster FPT algorithms for contraction to restricted bicliques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.10607v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. Krithika, V. K. Kutty Malu, Roohani Sharma, Prafullkumar Tale</dc:creator>
    </item>
    <item>
      <title>The Longest Common Bitonic Subsequence: A Match-Sensitive Dynamic Programming Approach</title>
      <link>https://arxiv.org/abs/2511.08958</link>
      <description>arXiv:2511.08958v2 Announce Type: replace 
Abstract: Given two sequences $A[1..n]$ and $B[1..m]$ over a totally ordered alphabet, the \emph{Longest Common Bitonic Subsequence} (LCBS) problem asks for a longest common subsequence that is strictly increasing up to a single peak element and strictly decreasing thereafter (allowing either phase to be empty). The only explicitly documented approach evaluates a quadratic dynamic program over the full $n\times m$ grid, which is prohibitive on large inputs. We present two exact algorithms. First, we give a simple $\Theta(nm)$-time baseline that computes LCBS by combining a longest common increasing subsequence (LCIS) computation on $(A,B)$ with a second LCIS computation on the reversed inputs, and then maximizing $INC(i,j)+DEC(i,j)-1$ over all common peaks. The method is constructive via parent pointers. Second, we develop an \emph{instance-sensitive} algorithm whose running time depends on the number $\mathcal{M}$ of matching pairs $(i,j)$ with $A[i]=B[j]$. We view matches as vertices of a dominance-ordered poset and compute the increasing and decreasing halves by two 2D dominance DP passes supported by orthogonal range-maximum data structures, followed by a linear peak scan. With a standard 2D range tree (or equivalent), this yields $O(\mathcal{M}\log^{2}\mathcal{M} + \mathcal{M} + (n+m)\log(n+m))$ time and $O(\mathcal{M}\log \mathcal{M})$ space, and it improves over the dense baseline whenever $M\log^2 M\ll nm$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08958v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md. Tanzeem Rahat, Md. Manzurul Hasan</dc:creator>
    </item>
    <item>
      <title>Merging RLBWTs adaptively</title>
      <link>https://arxiv.org/abs/2511.16953</link>
      <description>arXiv:2511.16953v5 Announce Type: replace 
Abstract: We show how to merge two run-length compressed Burrows-Wheeler Transforms (RLBWTs) into a run-length compressed extended Burrows-Wheeler Transform (eBWT) in $O (r)$ space and $O ((r + L) \log (m + n))$ time, where $m$ and $n$ are the lengths of the uncompressed strings, $r$ is the number of runs in the final eBWT and $L$ is the sum of its irreducible LCP values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16953v5</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Travis Gagie</dc:creator>
    </item>
    <item>
      <title>Hamiltonian Property Testing</title>
      <link>https://arxiv.org/abs/2403.02968</link>
      <description>arXiv:2403.02968v4 Announce Type: replace-cross 
Abstract: Locality is a fundamental feature of many physical time evolutions. Assumptions on locality and related structural properties also underlie recently proposed procedures for learning an unknown Hamiltonian from access to the induced time evolution. However, no protocols to rigorously test whether an unknown Hamiltonian is local were known. We investigate Hamiltonian locality testing as a property testing problem, where the task is to determine whether an unknown $n$-qubit Hamiltonian $H$ is $k$-local or $\varepsilon$-far from all $k$-local Hamiltonians, given access to the time evolution along $H$. First, we emphasize the importance of the chosen distance measure: With respect to the operator norm, a worst-case distance measure, incoherent quantum locality testers require $\tilde{\Omega}(2^n)$ many time evolution queries and an expected total evolution time of $\tilde{\Omega}(2^n / \varepsilon)$, and even coherent testers need $\Omega(2^{n/2})$ many queries and $\Omega(2^{n/2}/\varepsilon)$ total evolution time. In contrast, when distances are measured according to the normalized Frobenius norm, corresponding to an average-case distance, we give a sample-, time-, and computationally efficient incoherent Hamiltonian locality testing algorithm based on randomized measurements. In fact, our procedure can be used to simultaneously test a wide class of Hamiltonian properties beyond locality. Finally, we prove that learning a general Hamiltonian remains exponentially hard with this average-case distance, thereby establishing an exponential separation between Hamiltonian testing and learning. Our work initiates the study of property testing for quantum Hamiltonians, demonstrating that a broad class of Hamiltonian properties is efficiently testable even with limited quantum capabilities, and positioning Hamiltonian testing as an independent area of research alongside Hamiltonian learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02968v4</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Bluhm, Matthias C. Caro, Aadil Oufkir</dc:creator>
    </item>
    <item>
      <title>The PRODSAT phase of random quantum satisfiability</title>
      <link>https://arxiv.org/abs/2404.18447</link>
      <description>arXiv:2404.18447v2 Announce Type: replace-cross 
Abstract: The $k$-QSAT problem is a quantum analog of the famous $k$-SAT constraint satisfaction problem. We must determine the zero energy ground states of a Hamiltonian of $N$ qubits consisting of a sum of $M$ random $k$-local rank-one projectors. It is known that product states of zero energy exist with high probability if and only if the underlying factor graph has a clause-covering dimer configuration. This means that the threshold of the PRODSAT phase is a purely geometric quantity equal to the dimer covering threshold. We revisit and fully prove this result through a combination of complex analysis and algebraic methods based on Buchberger's algorithm for complex polynomial equations with random coefficients. We also discuss numerical experiments investigating the presence of entanglement in the PRODSAT phase in the sense that product states do not span the whole zero energy ground state space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18447v2</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joon Lee, Nicolas Macris, Jean Bernoulli Ravelomanana, Perrine Vantalon</dc:creator>
    </item>
    <item>
      <title>The Polymatroid Representation of a Greedoid, and Associated Galois Connections</title>
      <link>https://arxiv.org/abs/2411.15363</link>
      <description>arXiv:2411.15363v3 Announce Type: replace-cross 
Abstract: A greedoid is a generalization of a matroid allowing for more flexible analyses and modeling of combinatorial optimization problems. However, these structures decimate many matroid properties contributing to their pervasive nature. A polymatroid greedoid [KL85a] presents an interesting middle ground, so we further develop this class. First we prove every local poset greedoid for which the greedy algorithm correctly solves linear optimizations over its basic words must have a polymatroid representation. For this, we use relationships between the lattices of greedoid flats and closed sets of a polymatroid to generalize concepts in [KL85a]. Then, we show our generalization induces a Galois injection between the greedoid flats and closed sets of a representation. Finally, we apply this duality to identify a subclass of polymatroid greedoids with a maximum representation, giving a partial answer to an open problem of [KL85a]. As technical tools for our analyses, we introduce optimism and the Forking Lemma for interval greedoids. Both are pervasive in our work, and are of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15363v3</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Streit, Vijay K. Garg</dc:creator>
    </item>
  </channel>
</rss>
