<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 15 Oct 2025 01:45:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Towards Automated and Predictive Network-Level Energy Profiling in Reconfigurable IoT Systems</title>
      <link>https://arxiv.org/abs/2510.09842</link>
      <description>arXiv:2510.09842v1 Announce Type: new 
Abstract: Energy efficiency has emerged as a defining constraint in the evolution of sustainable Internet of Things (IoT) networks. This work moves beyond simulation-based or device-centric studies to deliver measurement-driven, network-level smart energy analysis. The proposed system enables end-to-end visibility of energy flows across distributed IoT infrastructures, uniting Bluetooth Low Energy (BLE) and Visible Light Communication (VLC) modes with environmental sensing and E-ink display subsystems under a unified profiling and prediction platform. Through automated, time-synchronized instrumentation, the framework captures fine-grained energy dynamics across both node and gateway layers. We developed a suite of tools that generate energy datasets for IoT ecosystems, addressing the scarcity of such data and enabling AI-based predictive and adaptive energy optimization. Validated within a network-level IoT testbed, the approach demonstrates robust performance under real operating conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09842v1</guid>
      <category>cs.NI</category>
      <category>cs.AR</category>
      <category>cs.PF</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammud J. Bocus, Senhui Qiu, Robert J. Piechocki, Kerstin Eder</dc:creator>
    </item>
    <item>
      <title>Fine-grained CDN Delegation</title>
      <link>https://arxiv.org/abs/2510.09983</link>
      <description>arXiv:2510.09983v1 Announce Type: new 
Abstract: The use of Content Delivery Networks (CDNs) has significantly increased over the past decade, with approximately 55 million websites currently relying on CDN services. Emerging solutions, such as Delegated Credentials (RFC 9345), lack fine-grained definitions of many critical aspects of delegation, such as the length of delegation chains, revocation mechanism, permitted operations, and a well-defined scope for said delegation. We present Delegation Certificates (DeCerts), which modify X.509 certificate standard and add new extensions to enable fine-grained CDN delegation. DeCerts allow domain owners to specify delegated and non-delegated subdomains, and control the depth of delegation extended by CDNs, which provides flexibility in delegation management. But more importantly, DeCerts are built on a new principle which provides full autonomy to domain owners-domain owners can issue DeCerts fully independent of Certificate Authorities (CAs), and thus have greater flexibility in policy control, including revocation methods. Such level of flexibility would be hard to match if CAs where to issue such certificates. Revoking a DeCert revokes delegation. We discuss multiple revocation mechanisms for a DeCerts balancing security, performance, and delegator control. We modify Firefox to support DeCert (i.e., proper validation) as a proof-of-concept, and test it to demonstrate the feasibility, compatibility of DeCerts with browsers and TLS/HTTPS protocols. DeCerts enhance the security, scalability, and manageability of CDN delegation, offering a practical solution for Internet services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09983v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ethan Thompson, Ali Sadeghi Jahromi, AbdelRahman Abdou</dc:creator>
    </item>
    <item>
      <title>Pushing the Boundaries in CBRS Band: Robust Radar Detection within High 5G Interference</title>
      <link>https://arxiv.org/abs/2510.10040</link>
      <description>arXiv:2510.10040v1 Announce Type: new 
Abstract: Spectrum sharing is a critical strategy for meeting escalating user demands via commercial wireless services, yet its effective regulation and technological enablement, particularly concerning coexistence with incumbent systems, remain significant challenges. Federal organizations have established regulatory frameworks to manage shared commercial use alongside mission-critical operations, such as military communications. This paper investigates the potential of machine learning (ML)-based approaches to enhance spectrum sharing capabilities within the Citizens Broadband Radio Service (CBRS) band, specifically focusing on the coexistence of commercial signals (e.g., 5G) and military radar systems. We demonstrate that ML techniques can potentially extend the Federal Communications Commission (FCC)-recommended signal-to-interference-plus-noise ratio (SINR) boundaries by improving radar detection and waveform identification in high-interference environments. Through rigorous evaluation using both synthetic and real-world signals, our findings indicate that proposed ML models, utilizing In-phase/Quadrature (IQ) data and spectrograms, can achieve the FCC-recommended $99\%$ radar detection accuracy even when subjected to high interference from 5G signals upto -5dB SINR, exceeding the required limits of $20$ SINR. Our experimental studies distinguish this work from the state-of-the-art by significantly extending the SINR limit for $99\%$ radar detection accuracy from approximately $12$ dB down to $-5$ dB. Subsequent to detection, we further apply ML to analyze and identify radar waveforms. The proposed models also demonstrate the capability to classify six distinct radar waveform types with $93\%$ accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10040v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shafi Ullah Khan, Michel Kulhandjian, Debashri Roy</dc:creator>
    </item>
    <item>
      <title>Waves of Imagination: Unconditional Spectrogram Generation using Diffusion Architectures</title>
      <link>https://arxiv.org/abs/2510.10044</link>
      <description>arXiv:2510.10044v1 Announce Type: new 
Abstract: The growing demand for effective spectrum management and interference mitigation in shared bands, such as the Citizens Broadband Radio Service (CBRS), requires robust radar detection algorithms to protect the military transmission from interference due to commercial wireless transmission. These algorithms, in turn, depend on large, diverse, and carefully labeled spectrogram datasets. However, collecting and annotating real-world radio frequency (RF) spectrogram data remains a significant challenge, as radar signals are rare, and their occurrences are infrequent. This challenge makes the creation of balanced datasets difficult, limiting the performance and generalizability of AI models in this domain.
  To address this critical issue, we propose a diffusion-based generative model for synthesizing realistic and diverse spectrograms of five distinct categories that integrate LTE, 5G, and radar signals within the CBRS band. We conduct a structural and statistical fidelity analysis of the generated spectrograms using widely accepted evaluation metrics Structural Similarity Index Measure (SSIM) and Peak Signal-to-Noise Ratio (PSNR), to quantify their divergence from the training data. Furthermore, we demonstrate that pre-training on the generated spectrograms significantly improves training efficiency on a real-world radar detection task by enabling $51.5\%$ faster convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10044v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rahul Vanukuri, Shafi Ullah Khan, Talip Tolga Sar{\i}, Gokhan Secinti, Diego Pati\~no, Debashri Roy</dc:creator>
    </item>
    <item>
      <title>Multi-Scale Diffusion Transformer for Jointly Simulating User Mobility and Mobile Traffic Pattern</title>
      <link>https://arxiv.org/abs/2510.10158</link>
      <description>arXiv:2510.10158v1 Announce Type: new 
Abstract: User mobility trajectory and mobile traffic data are essential for a wide spectrum of applications including urban planning, network optimization, and emergency management. However, large-scale and fine-grained mobility data remains difficult to obtain due to privacy concerns and collection costs, making it essential to simulate realistic mobility and traffic patterns. User trajectories and mobile traffic are fundamentally coupled, reflecting both physical mobility and cyber behavior in urban environments. Despite this strong interdependence, existing studies often model them separately, limiting the ability to capture cross-modal dynamics. Therefore, a unified framework is crucial. In this paper, we propose MSTDiff, a Multi-Scale Diffusion Transformer for joint simulation of mobile traffic and user trajectories. First, MSTDiff applies discrete wavelet transforms for multi-resolution traffic decomposition. Second, it uses a hybrid denoising network to process continuous traffic volumes and discrete location sequences. A transition mechanism based on urban knowledge graph embedding similarity is designed to guide semantically informed trajectory generation. Finally, a multi-scale Transformer with cross-attention captures dependencies between trajectories and traffic. Experiments show that MSTDiff surpasses state-of-the-art baselines in traffic and trajectory generation tasks, reducing Jensen-Shannon divergence (JSD) across key statistical metrics by up to 17.38% for traffic generation, and by an average of 39.53% for trajectory generation. The source code is available at: https://github.com/tsinghua-fib-lab/MSTDiff .</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10158v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyi Liu, Qingyue Long, Zhiwen Xue, Huandong Wang, Yong Li</dc:creator>
    </item>
    <item>
      <title>Hybrid MAC Protocol with Integrated Multi-Layered Security for Resource-Constrained UAV Swarm Communications</title>
      <link>https://arxiv.org/abs/2510.10236</link>
      <description>arXiv:2510.10236v1 Announce Type: new 
Abstract: Flying Ad Hoc Networks (FANETs) present unique challenges due to high node mobility, dynamic topologies, and strict resource constraints. Existing routing protocols often optimize for a single metric, such as path length or energy, while neglecting the complex dependencies between network performance, security, and MAC layer efficiency. This paper introduces a novel hardware software co design framework for secure and adaptive UAV swarm communications, featuring an energy aware protocol stack. The architecture employs a multicast, clustered organization where routing decisions integrate dynamic trust scores, historical link quality, and internodal distance. A hybrid MAC protocol combines contention based and scheduled channel access for optimized throughput. Security is ensured through a zero trust model that fuses cryptographic authentication with a behavioral reputation system, alongside hardware accelerated AES GCM encryption. Comparative analysis in an NS 3 simulation environment demonstrates the framework's superiority in packet delivery ratio, latency, resilience, and overhead, providing a scalable foundation for high performance swarm operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10236v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dhrumil Bhatt, Siddharth Penumatsa, Vidushi Kumar</dc:creator>
    </item>
    <item>
      <title>A Framework for AI-Native Semantic-Based Dynamic Slicing for 6G Networks</title>
      <link>https://arxiv.org/abs/2510.10756</link>
      <description>arXiv:2510.10756v1 Announce Type: new 
Abstract: In the ensuing ultra-dense and diverse environment in future \ac{6G} communication networks, it will be critical to optimize network resources via mechanisms that recognize and cater to the diversity, density, and dynamicity of system changes. However, coping with such environments cannot be done through the current network approach of compartmentalizing data as distinct from network operations. Instead, we envision a computing continuum where the content of the transmitted data is considered as an essential element in the transmission of that data, with data sources and streams analyzed and distilled to their essential elements, based on their semantic context, and then processed and transmitted over dedicated slices of network resources. By exploiting the rich content and semantics within data for dynamic and autonomous optimization of the computing continuum, this article opens the door to integrating communication, computing, cyber-physical systems, data flow, and AI, presenting new and exciting opportunities for cross-layer design. We propose semantic slicing, a two-pronged approach that builds multiple virtual divisions within a single physical and data infrastructure, each with its own distinct characteristics and needs. We view semantic slicing as a novel shift from current static slicing techniques, extending existing slicing approaches such that it can be applied dynamically at different levels and categories of resources in the computing continuum. Further it propels the advancement of semantic communication via the proposed architectural framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10756v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mayukh Roy Chowdhury, Eman Hammad, Lauri Loven, Susanna Pirttikangas, Aloizio P da Silva, Walid Saad</dc:creator>
    </item>
    <item>
      <title>Zephyrus: Scaling Gateways Beyond the Petabit-Era with DPU-Augmented Hierarchical Co-Offloading</title>
      <link>https://arxiv.org/abs/2510.11043</link>
      <description>arXiv:2510.11043v1 Announce Type: new 
Abstract: Operating at petabit-scale, ByteDance's cloud gateways are deployed at critical aggregation points to orchestrate a wide array of business traffic. However, this massive scale imposes significant resource pressure on our previous-generation cloud gateways, rendering them unsustainable in the face of ever-growing cloud-network traffic. As the DPU market rapidly expands, we see a promising path to meet our escalating business traffic demands by integrating DPUs with our established Tofino-based gateways. DPUs augment these gateways with substantially larger table capacities and richer programmability without compromising previously low-latency and high-throughput forwarding. Despite compelling advantages, the practical integration of DPUs into cloud gateways remains unexplored, primarily due to underlying challenges. In this paper, we present Zephyrus, a production-scale gateway built upon a unified P4 pipeline spanning high-performance Tofino and feature-rich DPUs, which successfully overcomes these challenges. We further introduce a hierarchical co-offloading architecture (HLCO) to orchestrate traffic flow within this heterogeneous gateway, achieving &gt; 99% hardware offloading while retaining software fallback paths for complex operations. Zephyrus outperforms LuoShen (NSDI '24) with 33% higher throughput and our evaluation further indicates 21% lower power consumption and 14% lower hardware cost. Against FPGA-based systems, Albatross (SIGCOMM '25), it doubles the throughput at a substantially lower Total Cost of Ownership (TCO), showcasing its superior performance-per-dollar. Beyond these performance gains, we also share key lessons from several years of developing and operating Zephyrus at production scale. We believe these insights provide valuable references for researchers and practitioners designing performant cloud gateways.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11043v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuemeng Xu, Haoran Chen, Jiarui Guo, Mingwei Cui, Qiuheng Yin, Cheng Dong, Daxiang Kang, Xian Wu, Chenmin Sun, Peng He, Yang Gao, Lirong Lai, Kai Wang, Hongyu Wu, Tong Yang, Xiyun Xu</dc:creator>
    </item>
    <item>
      <title>Graph Neural Network-Based Multicast Routing for On-Demand Streaming Services in 6G Networks</title>
      <link>https://arxiv.org/abs/2510.11109</link>
      <description>arXiv:2510.11109v1 Announce Type: new 
Abstract: The increase of bandwidth-intensive applications in sixth-generation (6G) wireless networks, such as real-time volumetric streaming and multi-sensory extended reality, demands intelligent multicast routing solutions capable of delivering differentiated quality-of-service (QoS) at scale. Traditional shortest-path and multicast routing algorithms are either computationally prohibitive or structurally rigid, and they often fail to support heterogeneous user demands, leading to suboptimal resource utilization. Neural network-based approaches, while offering improved inference speed, typically lack topological generalization and scalability. To address these limitations, this paper presents a graph neural network (GNN)-based multicast routing framework that jointly minimizes total transmission cost and supports user-specific video quality requirements. The routing problem is formulated as a constrained minimum-flow optimization task, and a reinforcement learning algorithm is developed to sequentially construct efficient multicast trees by reusing paths and adapting to network dynamics. A graph attention network (GAT) is employed as the encoder to extract context-aware node embeddings, while a long short-term memory (LSTM) module models the sequential dependencies in routing decisions. Extensive simulations demonstrate that the proposed method closely approximates optimal dynamic programming-based solutions while significantly reducing computational complexity. The results also confirm strong generalization to large-scale and dynamic network topologies, highlighting the method's potential for real-time deployment in 6G multimedia delivery scenarios. Code is available at https://github.com/UNIC-Lab/GNN-Routing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11109v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiucheng Wang, Zien Wang, Nan Cheng, Wenchao Xu, Wei Quan, Xuemin Shen</dc:creator>
    </item>
    <item>
      <title>Visible Light Communication for Vehicular Networks: A Tutorial</title>
      <link>https://arxiv.org/abs/2510.11123</link>
      <description>arXiv:2510.11123v1 Announce Type: new 
Abstract: The advent of the fifth-generation technology promises to bring about more vertical applications and emerging services that include vehicular networks and intelligent transportation systems (ITSs). To achieve their vision of real-time and safetyapplications, vehicular networks rely on short-range to medium-range communications. One emerging technology that aims to provide reliability and high-data rate in short-range communications is the visible light communications (VLC). Due to its remarkable advantages, some studies have recently investigated the integration of VLC in vehicular networks and ITSs. Despite their attractive features, such networks also face several implementation issues. This paper provides an extended tutorial on the implementation of VLC-based vehicular networks. To begin with, we present the implementation characteristics of these systems and discuss some related issues. The underlying system considers a general structure with transmitters, channels, and receivers based on photodetectors and cameras, as well as standardization efforts and types of topologies. In addition, we discuss the impact of the sun and artificial light sources, flickering, dimming, throughput enhancement, uplink security, and mobility on practical implementation. Finally, we highlight some key challenges and potential solutions and provide some directions for future research investigations that could constitute an advancement toward the development of commercial VLC-based vehicular systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11123v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pedro E. G\'oria Silva, Eduardo S. Lima, Jules M. Moualeu, Mohamed Korium, Pedro H. J. Nardelli</dc:creator>
    </item>
    <item>
      <title>Age of Information-Aware Cognitive Shared Access Networks with Energy Harvesting</title>
      <link>https://arxiv.org/abs/2510.11198</link>
      <description>arXiv:2510.11198v1 Announce Type: new 
Abstract: This study investigates a cognitive shared access network with energy harvesting capabilities operating under Age of Information (AoI) constraints for the primary user. Secondary transmitters are spatially distributed according to a homogeneous Poisson Point Process (PPP), while the primary user is located at a fixed position. The primary transmitter handles bursty packet arrivals, whereas secondary users operate under saturated traffic conditions. To manage interference and energy, two distinct zones are introduced: an energy harvesting zone around the primary transmitter and a guard zone around the primary receiver, within which secondary transmissions are prohibited. Secondary users access the channel probabilistically, with access decisions depending on their current battery state (charged or empty) and their location relative to the guard zone. Our objective is to analyze the primary user's AoI performance under three distinct packet management policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11198v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georgios Smpokos, Dionysis Xenakis, Marios Kountouris, Nikolaos Pappas</dc:creator>
    </item>
    <item>
      <title>From Prompts to Packets: A View from the Network on ChatGPT, Copilot, and Gemini</title>
      <link>https://arxiv.org/abs/2510.11269</link>
      <description>arXiv:2510.11269v1 Announce Type: new 
Abstract: Generative AI (GenAI) chatbots are now pervasive in digital ecosystems, yet their network traffic remains largely underexplored. This study presents an in-depth investigation of traffic generated by three leading chatbots (ChatGPT, Copilot, and Gemini) when accessed via Android mobile apps for both text and image generation. Using a dedicated capture architecture, we collect and label two complementary workloads: a 60-hour generic dataset with unconstrained prompts, and a controlled dataset built from identical prompts across GenAI apps and replicated via conventional messaging apps to enable one-to-one comparisons. This dual design allows us to address practical research questions on the distinctiveness of GenAI traffic, its differences from widely deployed traffic categories, and its novel implications for network usage. To this end, we provide fine-grained traffic characterization at trace, flow, and protocol levels, and model packet-sequence dynamics with Multimodal Markov Chains. Our analyses reveal app- and content-specific traffic patterns, particularly in volume, uplink/downlink profiles, and protocol adoption. We highlight the predominance of TLS, with Gemini extensively leveraging QUIC, ChatGPT exclusively using TLS 1.3, and app- and content-specific Server Name Indication (SNI) values. A payload-based occlusion analysis quantifies SNI's contribution to classification: masking it reduces F1-score by up to 20 percentage points in GenAI app traffic classification. Finally, compared with conventional messaging apps when carrying the same content, GenAI chatbots exhibit unique traffic characteristics, highlighting new stress factors for mobile networks, such as sustained upstream activity, with direct implications for network monitoring and management. We publicly release the datasets to support reproducibility and foster extensions to other use cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11269v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Antonio Montieri, Alfredo Nascita, Antonio Pescap\`e</dc:creator>
    </item>
    <item>
      <title>Network-Optimised Spiking Neural Network (NOS) Scheduling for 6G O-RAN: Spectral Margin and Delay-Tail Control</title>
      <link>https://arxiv.org/abs/2510.11291</link>
      <description>arXiv:2510.11291v1 Announce Type: new 
Abstract: This work presents a Network-Optimised Spiking (NOS) delay-aware scheduler for 6G radio access. The scheme couples a bounded two-state kernel to a clique-feasible proportional-fair (PF) grant head: the excitability state acts as a finite-buffer proxy, the recovery state suppresses repeated grants, and neighbour pressure is injected along the interference graph via delayed spikes. A small-signal analysis yields a delay-dependent threshold $k_\star(\Delta)$ and a spectral margin $\delta = k_\star(\Delta) - gH\rho(W)$ that compress topology, controller gain, and delay into a single design parameter. Under light assumptions on arrivals, we prove geometric ergodicity for $\delta&gt;0$ and derive sub-Gaussian backlog and delay tail bounds with exponents proportional to $\delta$. A numerical study, aligned with the analysis and a DU compute budget, compares NOS with PF and delayed backpressure (BP) across interference topologies over a $5$--$20$\,ms delay sweep. With a single gain fixed at the worst spectral radius, NOS sustains higher utilisation and a smaller 99.9th-percentile delay while remaining clique-feasible on integer PRBs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11291v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Bilal, Xiaolong Xu</dc:creator>
    </item>
    <item>
      <title>A protocol to reduce worst-case latency in deflection-based on-chip networks</title>
      <link>https://arxiv.org/abs/2510.11361</link>
      <description>arXiv:2510.11361v1 Announce Type: new 
Abstract: We present a novel protocol that reduces worst-case packet latency in deflection-based on-chip interconnect networks. It enforces the deflection of the header of a packet but not its payload, resulting in a reduction in overall network traffic and, more importantly, worst-case packet latency due to decreased pre-injection latency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11361v1</guid>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leandro Soares Indrusiak</dc:creator>
    </item>
    <item>
      <title>A Flexible Multi-Agent Deep Reinforcement Learning Framework for Dynamic Routing and Scheduling of Latency-Critical Services</title>
      <link>https://arxiv.org/abs/2510.11535</link>
      <description>arXiv:2510.11535v1 Announce Type: new 
Abstract: Timely delivery of delay-sensitive information over dynamic, heterogeneous networks is increasingly essential for a range of interactive applications, such as industrial automation, self-driving vehicles, and augmented reality. However, most existing network control solutions target only average delay performance, falling short of providing strict End-to-End (E2E) peak latency guarantees. This paper addresses the challenge of reliably delivering packets within application-imposed deadlines by leveraging recent advancements in Multi-Agent Deep Reinforcement Learning (MA-DRL). After introducing the Delay-Constrained Maximum-Throughput (DCMT) dynamic network control problem, and highlighting the limitations of current solutions, we present a novel MA-DRL network control framework that leverages a centralized routing and distributed scheduling architecture. The proposed framework leverages critical networking domain knowledge for the design of effective MA-DRL strategies based on the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) technique, where centralized routing and distributed scheduling agents dynamically assign paths and schedule packet transmissions according to packet lifetimes, thereby maximizing on-time packet delivery. The generality of the proposed framework allows integrating both data-driven \blue{Deep Reinforcement Learning (DRL)} agents and traditional rule-based policies in order to strike the right balance between performance and learning complexity. Our results confirm the superiority of the proposed framework with respect to traditional stochastic optimization-based approaches and provide key insights into the role and interplay between data-driven DRL agents and new rule-based policies for both efficient and high-performance control of latency-critical services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11535v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vincenzo Norman Vitale, Antonia Maria Tulino, Andreas F. Molisch, Jaime Llorca</dc:creator>
    </item>
    <item>
      <title>Pingmark: A Textual Protocol for Universal Spatial Mentions</title>
      <link>https://arxiv.org/abs/2510.09672</link>
      <description>arXiv:2510.09672v1 Announce Type: cross 
Abstract: Pingmark defines a universal textual protocol for expressing spatial context through a minimal symbol: !@. Rather than embedding coordinates or using proprietary map links, Pingmark introduces a semantic trigger that compliant client applications interpret to generate a standardized resolver link of the form https://pingmark.me/lat/lon/[timestamp]. This allows location expression to function like existing textual conventions - @ for identity or # for topics - but for physical space. The protocol requires no user registration, relies on open mapping technologies, and protects privacy by generating location data ephemerally and locally. This paper presents the motivation, syntax, and design of the Pingmark Protocol Specification (PPS v0.1), its reference resolver implementation, and the long-term goal of establishing Pingmark as an open Internet standard for spatial mentions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09672v1</guid>
      <category>cs.CR</category>
      <category>cs.HC</category>
      <category>cs.NI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kalin Dimitrov (Independent Researcher, M.Sc. Student, Veliko Tarnovo University)</dc:creator>
    </item>
    <item>
      <title>A Scalable, Privacy-Preserving Decentralized Identity and Verifiable Data Sharing Framework based on Zero-Knowledge Proofs</title>
      <link>https://arxiv.org/abs/2510.09715</link>
      <description>arXiv:2510.09715v1 Announce Type: cross 
Abstract: With the proliferation of decentralized applications (DApps), the conflict between the transparency of blockchain technology and user data privacy has become increasingly prominent. While Decentralized Identity (DID) and Verifiable Credentials (VCs) provide a standardized framework for user data sovereignty, achieving trusted identity verification and data sharing without compromising privacy remains a significant challenge. This paper proposes a novel, comprehensive framework that integrates DIDs and VCs with efficient Zero-Knowledge Proof (ZKP) schemes to address this core issue. The key contributions of this framework are threefold: first, it constructs a set of strong privacy-preserving protocols based on zk-STARKs, allowing users to prove that their credentials satisfy specific conditions (e.g., "age is over 18") without revealing any underlying sensitive data. Second, it designs a scalable, privacy-preserving credential revocation mechanism based on cryptographic accumulators, effectively solving credential management challenges in large-scale scenarios. Finally, it integrates a practical social key recovery scheme, significantly enhancing system usability and security. Through a prototype implementation and performance evaluation, this paper quantitatively analyzes the framework's performance in terms of proof generation time, verification overhead, and on-chain costs. Compared to existing state-of-the-art systems based on zk-SNARKs, our framework, at the cost of a larger proof size, significantly improves prover efficiency for complex computations and provides stronger security guarantees, including no trusted setup and post-quantum security. Finally, a case study in the decentralized finance (DeFi) credit scoring scenario demonstrates the framework's immense potential for unlocking capital efficiency and fostering a trusted data economy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09715v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hui Yuan</dc:creator>
    </item>
    <item>
      <title>CIRSense: Rethinking WiFi Sensing with Channel Impulse Response</title>
      <link>https://arxiv.org/abs/2510.11374</link>
      <description>arXiv:2510.11374v1 Announce Type: cross 
Abstract: WiFi sensing based on channel state information (CSI) collected from commodity WiFi devices has shown great potential across a wide range of applications, including vital sign monitoring and indoor localization. Existing WiFi sensing approaches typically estimate motion information directly from CSI. However, they often overlook the inherent advantages of channel impulse response (CIR), a delay-domain representation that enables more intuitive and principled motion sensing by naturally concentrating motion energy and separating multipath components. Motivated by this, we revisit WiFi sensing and introduce CIRSense, a new framework that enhances the performance and interpretability of WiFi sensing with CIR. CIRSense is built upon a new motion model that characterizes fractional delay effects, a fundamental challenge in CIR-based sensing. This theoretical model underpins technical advances for the three challenges in WiFi sensing: hardware distortion compensation, high-resolution distance estimation, and subcarrier aggregation for extended range sensing. CIRSense, operating with a 160 MHz channel bandwidth, demonstrates versatile sensing capabilities through its dual-mode design, achieving a mean error of approximately 0.25 bpm in respiration monitoring and 0.09 m in distance estimation. Comprehensive evaluations across residential spaces, far-range scenarios, and multi-target settings demonstrate CIRSense's superior performance over state-of-the-art CSI-based baselines. Notably, at a challenging sensing distance of 20 m, CIRSense achieves at least 3x higher average accuracy with more than 4.5x higher computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11374v1</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiqi Kong, He Chen</dc:creator>
    </item>
    <item>
      <title>Open Wireless Digital Twin: End-to-End 5G Mobility Emulation with OpenAirInterface and Ray Tracing</title>
      <link>https://arxiv.org/abs/2503.12177</link>
      <description>arXiv:2503.12177v4 Announce Type: replace 
Abstract: This study presents an end-to-end wireless digital twin platform constructed using open-source software and open data to enhance the evaluation of mobile communication systems. The proposed open wireless digital twin (OWDT) integrates OpenAirInterface (OAI) for Fifth-Generation New Radio (5G NR) protocol stack emulation and NVIDIA Sionna RT for high-resolution ray-tracing-based radio propagation modeling. This integration enables the realistic emulation of 5G wireless communication in mobility scenarios on a CPU-based Linux system, leveraging real-world building data to bridge the gap between theoretical simulations and real-world deployments. The platform also incorporates OAI FlexRIC, which is an implementation aligned with the O-RAN near-real-time RAN Intelligent Controller (near-RT RIC), to dynamically monitor key performance indicators (KPIs). Through extensive evaluation in urban environments, this study demonstrated the validity of the emulation framework, revealing its capability to replicate real-world communication dynamics with high fidelity. The results underscore the potential of the OWDT to accelerate wireless system development, reduce experimental costs, and optimize network configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12177v4</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ACCESS.2025.3619105</arxiv:DOI>
      <dc:creator>Tetsuya Iye, Masaya Sakamoto, Shohei Takaya, Eisaku Sato, Yuki Susukida, Yu Nagaoka, Kazuki Maruta, Jin Nakazato</dc:creator>
    </item>
    <item>
      <title>PartialLoading: User Scheduling and Bandwidth Allocation for Parameter-sharing Edge Inference</title>
      <link>https://arxiv.org/abs/2503.22982</link>
      <description>arXiv:2503.22982v2 Announce Type: replace 
Abstract: By provisioning inference offloading services, edge inference drives the rapid growth of AI applications at network edge. However, how to reduce the inference latency remains a significant challenge. To address this issue, we develop a parameter-sharing AI model loading (PartialLoading) framework for multi-user edge inference, which exploits two key insights: 1) the majority of latency arises from loading AI models into server GPU memory, and 2) different AI models can share a significant number of parameters, for which redundant loading should be avoided. Towards this end, we formulate a joint multi-user scheduling and spectrum bandwidth allocation problem to maximize task throughput by exploiting shared parameter blocks across models. The intuition is to judiciously schedule user requests to reuse the shared parameter blocks between consecutively loaded models, thereby reducing model loading time substantially. To facilitate solution finding, we decouple the problem into two sub-problems, i.e., user scheduling and bandwidth allocation, showing that solving them sequentially leads to the solution to the original problem. Due to the NP-hardness of the problem, we first study an important special case called the "backbone-sharing" case, and design a dynamic programming-based algorithm to obtain the optimal solution in polynomial time. For the general case, we propose a greedy heuristic to obtain the sub-optimal solution efficiently. Simulation results demonstrate that the proposed framework significantly improves task throughput under deadline constraints compared with user scheduling without exploiting parameter sharing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22982v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanqiao Qu, Qian Chen, Xianhao Chen, Kaibin Huang, Yuguang Fang</dc:creator>
    </item>
    <item>
      <title>Editable-DeepSC: Reliable Cross-Modal Semantic Communications for Facial Editing</title>
      <link>https://arxiv.org/abs/2411.15702</link>
      <description>arXiv:2411.15702v3 Announce Type: replace-cross 
Abstract: Real-time computer vision (CV) plays a crucial role in various real-world applications, whose performance is highly dependent on communication networks. Nonetheless, the data-oriented characteristics of conventional communications often do not align with the special needs of real-time CV tasks. To alleviate this issue, the recently emerged semantic communications only transmit task-related semantic information and exhibit a promising landscape to address this problem. However, the communication challenges associated with Semantic Facial Editing, one of the most important real-time CV applications on social media, still remain largely unexplored. In this paper, we fill this gap by proposing Editable-DeepSC, a novel cross-modal semantic communication approach for facial editing. Firstly, we theoretically discuss different transmission schemes that separately handle communications and editings, and emphasize the necessity of Joint Editing-Channel Coding (JECC) via iterative attributes matching, which integrates editings into the communication chain to preserve more semantic mutual information. To compactly represent the high-dimensional data, we leverage inversion methods via pre-trained StyleGAN priors for semantic coding. To tackle the dynamic channel noise conditions, we propose SNR-aware channel coding via model fine-tuning. Extensive experiments indicate that Editable-DeepSC can achieve superior editings while significantly saving the transmission bandwidth, even under high-resolution and out-of-distribution (OOD) settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15702v3</guid>
      <category>cs.IT</category>
      <category>cs.CV</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Chen, Wenbo Yu, Qinshan Zhang, Tianqu Zhuang, Yong Jiang, Shu-Tao Xia</dc:creator>
    </item>
  </channel>
</rss>
