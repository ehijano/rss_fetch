<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Feb 2026 05:00:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Structural shifts in institutional participation and collaboration within the AI arXiv preprint research ecosystem</title>
      <link>https://arxiv.org/abs/2602.03969</link>
      <description>arXiv:2602.03969v1 Announce Type: new 
Abstract: The emergence of large language models (LLMs) represents a significant technological shift within the scientific ecosystem, particularly within the field of artificial intelligence (AI). This paper examines structural changes in the AI research landscape using a dataset of arXiv preprints (cs.AI) from 2021 through 2025. Given the rapid pace of AI development, the preprint ecosystem has become a critical barometer for real-time scientific shifts, often preceding formal peer-reviewed publication by months or years. By employing a multi-stage data collection and enrichment pipeline in conjunction with LLM-based institution classification, we analyze the evolution of publication volumes, author team sizes, and academic--industry collaboration patterns. Our results reveal an unprecedented surge in publication output following the introduction of ChatGPT, with academic institutions continuing to provide the largest volume of research. However, we observe that academic--industry collaboration is still suppressed, as measured by a Normalized Collaboration Index (NCI) that remains significantly below the random-mixing baseline across all major subfields. These findings highlight a continuing institutional divide and suggest that the capital-intensive nature of generative AI research may be reshaping the boundaries of scientific collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03969v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shama Magnur, Mayank Kejriwal</dc:creator>
    </item>
    <item>
      <title>Unmasking Superspreaders: Data-Driven Approaches for Identifying and Comparing Key Influencers of Conspiracy Theories on X.com</title>
      <link>https://arxiv.org/abs/2602.04546</link>
      <description>arXiv:2602.04546v1 Announce Type: new 
Abstract: Conspiracy theories can threaten society by spreading misinformation, deepening polarization, and eroding trust in democratic institutions. Social media often fuels the spread of conspiracies, primarily driven by two key actors: Superspreaders -- influential individuals disseminating conspiracy content at disproportionately high rates, and Bots -- automated accounts designed to amplify conspiracies strategically. To counter the spread of conspiracy theories, it is critical to both identify these actors and to better understand their behavior. However, a systematic analysis of these actors as well as real-world-applicable identification methods are still lacking. In this study, we leverage over seven million tweets from the COVID-19 pandemic to analyze key differences between Human Superspreaders and Bots across dimensions such as linguistic complexity, toxicity, and hashtag usage. Our analysis reveals distinct communication strategies: Superspreaders tend to use more complex language and substantive content while relying less on structural elements like hashtags and emojis, likely to enhance credibility and authority. By contrast, Bots favor simpler language and strategic cross-usage of hashtags, likely to increase accessibility, facilitate infiltration into trending discussions, and amplify reach. To counter both Human Superspreaders and Bots, we propose and evaluate 27 novel metrics for quantifying the severity of conspiracy theory spread. Our findings highlight the effectiveness of an adapted H-Index for computationally feasible identification of Human Superspreaders. By identifying behavioral patterns unique to Human Superspreaders and Bots as well as providing suitable identification methods, this study provides a foundation for mitigation strategies, including platform moderation policies, temporary and permanent account suspensions, and public awareness campaigns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04546v1</guid>
      <category>cs.SI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.IR</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Kramer, Henrich R. Greve, Moritz von Zahn, Hayagreeva Rao</dc:creator>
    </item>
    <item>
      <title>Overstating Attitudes, Ignoring Networks: LLM Biases in Simulating Misinformation Susceptibility</title>
      <link>https://arxiv.org/abs/2602.04674</link>
      <description>arXiv:2602.04674v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly used as proxies for human judgment in computational social science, yet their ability to reproduce patterns of susceptibility to misinformation remains unclear. We test whether LLM-simulated survey respondents, prompted with participant profiles drawn from social survey data measuring network, demographic, attitudinal and behavioral features, can reproduce human patterns of misinformation belief and sharing. Using three online surveys as baselines, we evaluate whether LLM outputs match observed response distributions and recover feature-outcome associations present in the original survey data. LLM-generated responses capture broad distributional tendencies and show modest correlation with human responses, but consistently overstate the association between belief and sharing. Linear models fit to simulated responses exhibit substantially higher explained variance and place disproportionate weight on attitudinal and behavioral features, while largely ignoring personal network characteristics, relative to models fit to human responses. Analyses of model-generated reasoning and LLM training data suggest that these distortions reflect systematic biases in how misinformation-related concepts are represented. Our findings suggest that LLM-based survey simulations are better suited for diagnosing systematic divergences from human judgment than for substituting it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04674v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eun Cheol Choi, Lindsay E. Young, Emilio Ferrara</dc:creator>
    </item>
    <item>
      <title>The Needle is a Thread: Finding Planted Paths in Noisy Process Trees</title>
      <link>https://arxiv.org/abs/2602.04694</link>
      <description>arXiv:2602.04694v1 Announce Type: new 
Abstract: Motivated by applications in cybersecurity such as finding meaningful sequences of malware-related events buried inside large amounts of computer log data, we introduce the "planted path" problem and propose an algorithm to find fuzzy matchings between two trees. This algorithm can be used as a "building block" for more complicated workflows. We demonstrate usefulness of a few of such workflows in mining synthetically generated data as well as real-world ACME cybersecurity datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04694v1</guid>
      <category>cs.SI</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maya Le, Pawe{\l} Pra{\l}at, Aaron Smith, Fran\c{c}ois Th\'eberge</dc:creator>
    </item>
    <item>
      <title>Privacy utility trade offs for parameter estimation in degree heterogeneous higher order networks</title>
      <link>https://arxiv.org/abs/2602.03948</link>
      <description>arXiv:2602.03948v1 Announce Type: cross 
Abstract: In sensitive applications involving relational datasets, protecting information about individual links from adversarial queries is of paramount importance. In many such settings, the available data are summarized solely through the degrees of the nodes in the network. We adopt the $\beta$ model, which is the prototypical statistical model adopted for this form of aggregated relational information, and study the problem of minimax-optimal parameter estimation under both local and central differential privacy constraints. We establish finite sample minimax lower bounds that characterize the precise dependence of the estimation risk on the network size and the privacy parameters, and we propose simple estimators that achieve these bounds up to constants and logarithmic factors under both local and central differential privacy frameworks. Our results provide the first comprehensive finite sample characterization of privacy utility trade offs for parameter estimation in $\beta$ models, addressing the classical graph case and extending the analysis to higher order hypergraph models. We further demonstrate the effectiveness of our methods through experiments on synthetic data and a real world communication network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03948v1</guid>
      <category>stat.ML</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bibhabasu Mandal, Sagnik Nandy</dc:creator>
    </item>
    <item>
      <title>Coalition Structure and Polarization in Parliamentary Voting Networks: Evidence from the Italian Parliament</title>
      <link>https://arxiv.org/abs/2602.04088</link>
      <description>arXiv:2602.04088v1 Announce Type: cross 
Abstract: Ensuring legislative accountability in multi-party systems requires quantitative tools that reveal actual voting behavior beyond formal party affiliations. We present a network-based framework for analyzing parliamentary dynamics at multiple scales, capturing coalition structure, group coherence, and individual influence. Applied to over 4 million vote expressions from the Italian Parliament across three government formations (2018-2021), the methodology combines network modularity, voting distance metrics, and betweenness centrality to map the structure of collective decision-making. Using this framework, we show that system-level polarization, as captured by network modularity, varies systematically with coalition structure rather than coalition size. Technical governments display paradoxically lower global polarization despite broader formal support, reflecting structurally mixed voting patterns rather than unified blocs. On polarizing issues such as immigration, network polarization depends strongly on the fragmentation or cohesion of the opposition, even when the governing coalition votes cohesively. Betweenness analysis reveals that mediator roles are highly concentrated, with only about 2% of parliamentarians acting as structural bridges between communities. Community detection further uncovers implicit coalitions that are not apparent from declared alliances. The framework relies exclusively on public roll-call data, enabling reproducible analysis and direct applicability to any legislature with transparent voting records. By linking individual voting behavior to emergent system-level structure, the methodology provides quantitative infrastructure for comparative analysis of legislative voting networks and coalition monitoring, enabling systematic assessment of legislative behaviour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04088v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesca Collu, Antonio Scala, Emilia La Nave</dc:creator>
    </item>
    <item>
      <title>Toward Effective Multimodal Graph Foundation Model: A Divide-and-Conquer Based Approach</title>
      <link>https://arxiv.org/abs/2602.04116</link>
      <description>arXiv:2602.04116v1 Announce Type: cross 
Abstract: Graph Foundation Models (GFMs) have achieved remarkable success in generalizing across diverse domains. However, they mainly focus on Text-Attributed Graphs (TAGs), leaving Multimodal-Attributed Graphs (MAGs) largely untapped. Developing Multimodal Graph Foundation Models (MGFMs) allows for leveraging the rich multimodal information in MAGs, and extends applicability to broader types of downstream tasks. While recent MGFMs integrate diverse modality information, our empirical investigation reveals two fundamental limitations of existing MGFMs: (1)they fail to explicitly model modality interaction, essential for capturing intricate cross-modal semantics beyond simple aggregation, and (2)they exhibit sub-optimal modality alignment, which is critical for bridging the significant semantic disparity between distinct modal spaces. To address these challenges, we propose PLANET (graPh topoLogy-aware modAlity iNteraction and alignmEnT), a novel framework employing a Divide-and-Conquer strategy to decouple modality interaction and alignment across distinct granularities. At the embedding granularity, (1)Embedding-wise Domain Gating (EDG) performs local semantic enrichment by adaptively infusing topology-aware cross-modal context, achieving modality interaction. At the node granularity, (2)Node-wise Discretization Retrieval (NDR) ensures global modality alignment by constructing a Discretized Semantic Representation Space (DSRS) to bridge modality gaps. Extensive experiments demonstrate that PLANET significantly outperforms state-of-the-art baselines across diverse graph-centric and multimodal generative tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04116v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sicheng Liu, Xunkai Li, Daohan Su, Ru Zhang, Hongchao Qin, Ronghua Li, Guoren Wang</dc:creator>
    </item>
    <item>
      <title>Opinion dynamics under electoral shocks in competitive campaigns</title>
      <link>https://arxiv.org/abs/2602.04829</link>
      <description>arXiv:2602.04829v1 Announce Type: cross 
Abstract: We propose a computational framework for modeling opinion dynamics in electoral competitions that combines two realistic features: voter memory and exogenous shocks. The population is represented by a fully-connected network of agents, each holding a binary opinion that reflects support for one of two candidates. First, inspired by the classical voter model, we introduce a memory-dependent opinion update: each agent's probability of adopting a neighbor's stance depends on how many times they agreed with that neighbor in the agent's past $m$ states, promoting inertia and resistance to change. Second, we define an electoral shock as an abrupt external influence acting uniformly over all agents during a finite interval $[t_0, t_0+\Delta t]$, favoring one candidate by switching opinions with probability $p_s$, representing the impact of extraordinary events such as political scandals, impactful speeches, or sudden news. We explore how the strength and duration of the shock, in conjunction with memory length, influence the transient and stationary properties of the model, as well as the candidates' advantage. Our findings reveal a rich dynamical behavior: memory slows down convergence and enhances system resilience, whereas shocks of sufficient intensity and duration can abruptly realign collective preferences, particularly when occurring close to the election date. Conversely, for long memory lengths or large election horizons, shock effects are dampened or delayed, depending on their timing. These results offer insights into why some sudden political events reshape electoral outcomes while others fade under strong individual inertia. Finally, a qualitative comparison with real electoral shocks reported in opinion polls illustrates how the model captures the competition between voter inertia and abrupt external events observed in actual elections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04829v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.1142/S0129183127500549</arxiv:DOI>
      <dc:creator>Jaime L. C. da C. Filho, Nuno Crokidakis</dc:creator>
    </item>
    <item>
      <title>Steering the Herd: A Framework for LLM-based Control of Social Learning</title>
      <link>https://arxiv.org/abs/2504.02648</link>
      <description>arXiv:2504.02648v4 Announce Type: replace-cross 
Abstract: Algorithms increasingly serve as information mediators--from social media feeds and targeted advertising to the increasing ubiquity of LLMs. This engenders a joint process where agents combine private, algorithmically-mediated signals with learning from peers to arrive at decisions. To study such settings, we introduce a model of controlled sequential social learning in which an information-mediating planner (e.g. an LLM) controls the information structure of agents while they also learn from the decisions of earlier agents. The planner may seek to improve social welfare (altruistic planner) or to induce a specific action the planner prefers (biased planner). Our framework presents a new optimization problem for social learning that combines dynamic programming with decentralized action choices and Bayesian belief updates. We prove the convexity of the value function and characterize the optimal policies of altruistic and biased planners, which attain desired tradeoffs between the costs they incur and the payoffs they earn from induced agent choices. Notably, in some regimes the biased planner intentionally obfuscates the agents' signals. Even under stringent transparency constraints--information parity with individuals, no lying or cherry-picking, and full observability--we show that information mediation can substantially shift social welfare in either direction. We complement our theory with simulations in which LLMs act as both planner and agents. Notably, the LLM planner in our simulations exhibits emergent strategic behavior in steering public opinion that broadly mirrors the trends predicted, though key deviations suggest the influence of non-Bayesian reasoning consistent with the cognitive patterns of both humans and LLMs trained on human-like data. Together, we establish our framework as a tractable basis for studying the impact and regulation of LLM information mediators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02648v4</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raghu Arghal, Kevin He, Shirin Saeedi Bidokhti, Saswati Sarkar</dc:creator>
    </item>
    <item>
      <title>Modeling individual attention dynamics on online social media</title>
      <link>https://arxiv.org/abs/2507.01511</link>
      <description>arXiv:2507.01511v2 Announce Type: replace-cross 
Abstract: In the attention economy, understanding how individuals manage limited attention is critical. We introduce a simple model describing the decay of a user's engagement when facing multiple inputs. We analytically show that individual attention decay is determined by the overall duration of interactions, not their number or user activity. Our model is validated using data from Reddit's Change My View subreddit, where the user's attention dynamics is explicitly traceable. Despite its simplicity, our model offers a crucial microscopic perspective complementing macroscopic studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01511v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaume Ojer, Filippo Radicchi, Santo Fortunato, Michele Starnini, Romualdo Pastor-Satorras</dc:creator>
    </item>
    <item>
      <title>ToxiTwitch: Toward Emote-Aware Hybrid Moderation for Live Streaming Platforms</title>
      <link>https://arxiv.org/abs/2601.15605</link>
      <description>arXiv:2601.15605v2 Announce Type: replace-cross 
Abstract: The rapid growth of live-streaming platforms such as Twitch has introduced complex challenges in moderating toxic behavior. Traditional moderation approaches, such as human annotation and keyword-based filtering, have demonstrated utility, but human moderators on Twitch constantly struggle to scale effectively in the fast-paced, high-volume, and context-rich chat environment of the platform while also facing harassment themselves. Recent advances in large language models (LLMs), such as DeepSeek-R1-Distill and Llama-3-8B-Instruct, offer new opportunities for toxicity detection, especially in understanding nuanced, multimodal communication involving emotes. In this work, we present an exploratory comparison of toxicity detection approaches tailored to Twitch. Our analysis reveals that incorporating emotes improves the detection of toxic behavior. To this end, we introduce ToxiTwitch, a hybrid model that combines LLM-generated embeddings of text and emotes with traditional machine learning classifiers, including Random Forest and SVM. In our case study, the proposed hybrid approach reaches up to 80 percent accuracy under channel-specific training (with 13 percent improvement over BERT and F1-score of 76 percent). This work is an exploratory study intended to surface challenges and limits of emote-aware toxicity detection on Twitch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15605v2</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Thu, 05 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baktash Ansari, Elias Martin, Afra Mashhadi</dc:creator>
    </item>
  </channel>
</rss>
