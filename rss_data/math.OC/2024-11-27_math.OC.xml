<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 28 Nov 2024 02:53:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Accelerated Bregman gradient methods for relatively smooth and relatively Lipschitz continuous minimization problems</title>
      <link>https://arxiv.org/abs/2411.16743</link>
      <description>arXiv:2411.16743v1 Announce Type: new 
Abstract: In this paper, we propose some accelerated methods for solving optimization problems under the condition of relatively smooth and relatively Lipschitz continuous functions with an inexact oracle. We consider the problem of minimizing the convex differentiable and relatively smooth function concerning a reference convex function. The first proposed method is based on a similar triangles method with an inexact oracle, which uses a special triangular scaling property for the used Bregman divergence. The other proposed methods are non-adaptive and adaptive (tuning to the relative smoothness parameter) accelerated Bregman proximal gradient methods with an inexact oracle. These methods are universal in the sense that they are applicable not only to relatively smooth but also to relatively Lipschitz continuous optimization problems. We also introduced an adaptive intermediate Bregman method which interpolates between slower but more robust algorithms non-accelerated and faster, but less robust accelerated algorithms. We conclude the paper with the results of numerical experiments demonstrating the advantages of the proposed algorithms for the Poisson inverse problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16743v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>O. S. Savchuk, M. S. Alkousa, A. S. Shushko, A. A. Vyguzov, F. S. Stonyakin, D. A. Pasechnyuk, A. V. Gasnikov</dc:creator>
    </item>
    <item>
      <title>On quasi-convex smooth optimization problems by a comparison oracle</title>
      <link>https://arxiv.org/abs/2411.16745</link>
      <description>arXiv:2411.16745v1 Announce Type: new 
Abstract: Frequently, when dealing with many machine learning models, optimization problems appear to be challenging due to a limited understanding of the constructions and characterizations of the objective functions in these problems. Therefore, major complications arise when dealing with first-order algorithms, in which gradient computations are challenging or even impossible in various scenarios. For this reason, we resort to derivative-free methods (zeroth-order methods). This paper is devoted to an approach to minimizing quasi-convex functions using a recently proposed comparison oracle only. This oracle compares function values at two points and tells which is larger, thus by the proposed approach, the comparisons are all we need to solve the optimization problem under consideration. The proposed algorithm to solve the considered problem is based on the technique of comparison-based gradient direction estimation and the comparison-based approximation normalized gradient descent. The normalized gradient descent algorithm is an adaptation of gradient descent, which updates according to the direction of the gradients, rather than the gradients themselves. We proved the convergence rate of the proposed algorithm when the objective function is smooth and strictly quasi-convex in $\mathbb{R}^n$, this algorithm needs $\mathcal{O}\left( \left(n D^2/\varepsilon^2 \right) \log\left(n D / \varepsilon\right)\right)$ comparison queries to find an $\varepsilon$-approximate of the optimal solution, where $D$ is an upper bound of the distance between all generated iteration points and an optimal solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16745v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. V. Gasnikov, M. S. Alkousa, A. V. Lobanov, Y. V. Dorn, F. S. Stonyakin, I. A. Kuruzov, S. R. Singh</dc:creator>
    </item>
    <item>
      <title>Modelling to Generate Continuous Alternatives: Enabling Real-Time Feasible Portfolio Generation in Convex Planning Models</title>
      <link>https://arxiv.org/abs/2411.16887</link>
      <description>arXiv:2411.16887v1 Announce Type: new 
Abstract: Decarbonization provides new opportunities to plan energy systems for improved health, resilience, equity, and environmental outcomes, but challenges in siting and social acceptance of transition goals and targets threaten progress. Modelling to Generate Alternatives (MGA) provides an optimization method for capturing many near-cost-optimal system configurations, and can provide insights into the tradeoffs between objectives and flexibility available in the system. However, MGA is currently limited in interactive applicability to these problems due to a lack of methods for allowing users to explore near-optimal feasible spaces. In this work we describe Modelling to Generate Continuous Alternatives (MGCA), a novel post-processing algorithm for convex planning problems which enables users to rapidly generate new interior solutions, incorporate new constraints, and solve within the space with convex objectives. MGCA begins with a dimensionality reduction to capacity decisions and metric values. We then take advantage of convex combinations to generate interior points by allowing user weight specification and encoding convex combinations in an optimization problem with user-defined additional constraints and objective. Dimensionality reduction enables this problem to solve in tenths of a second, suitable for analysis in interactive settings. We discuss the interpolation of capacity and operational metric values, finding capacity metrics can be perfectly interpolated while operational metrics remain within the feasible range of the points used to create them. We demonstrate interpolated solutions can be exported and re-solved with an economic dispatch model to provide operational metric values consistent with least-cost decision-making and show interpolated metric values are generally within 10% of the optimal value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16887v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.5281/zenodo.13958746</arxiv:DOI>
      <dc:creator>Michael Lau, Xin Wang, Neha Patankar, Jesse D. Jenkins</dc:creator>
    </item>
    <item>
      <title>Strong convergence and fast rates for systems with Tikhonov regularization</title>
      <link>https://arxiv.org/abs/2411.17329</link>
      <description>arXiv:2411.17329v1 Announce Type: new 
Abstract: We introduce and investigate the asymptotic behaviour of the trajectories of a second order dynamical system with Tikhonov regularization for solving a monotone equation with single valued, monotone and continuous operator acting on a real Hilbert space. We consider a vanishing damping which is correlated with the Tikhonov parameter and which is in line with recent developments in the literature on this topic. A correction term which involves the time derivative of the operator along the trajectory is also involved in the system and makes the link with Newton and Levenberg-Marquardt type methods. We obtain strong convergence of the trajectory to the minimal norm solution and fast convergence rates for the velocity and a quantity involving the operator along the trajectory. The rates are very closed to the known fast convergence results for systems without Tikhonov regularization, the novelty with respect to this is that we also obtain strong convergence of the trajectory to the minimal norm solution. As an application we introduce a primal-dual dynamical system for solving linearly constrained convex optimization problems, where the strong convergence of the trajectories is highlighted together with fast convergence rates for the feasibility measure and function values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17329v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>math.FA</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ern\"o Robert Csetnek, Szil\'ard Csaba L\'aszl\'o</dc:creator>
    </item>
    <item>
      <title>Scaled Relative Graphs for Nonmonotone Operators with Applications in Circuit Theory</title>
      <link>https://arxiv.org/abs/2411.17419</link>
      <description>arXiv:2411.17419v1 Announce Type: new 
Abstract: The scaled relative graph (SRG) is a powerful graphical tool for analyzing the properties of operators, by mapping their graph onto the complex plane. In this work, we study the SRG of two classes of nonmonotone operators, namely the general class of semimonotone operators and a class of angle-bounded operators. In particular, we provide an analytical description of the SRG of these classes and show that membership of an operator to these classes can be verified through geometric containment of its SRG. To illustrate the importance of these results, we provide several examples in the context of electrical circuits. Most notably, we show that the Ebers-Moll transistor belongs to the class of angle-bounded operators and use this result to compute the response of a common-emitter amplifier using Chambolle-Pock, despite the underlying nonsmoothness and multi-valuedness, leveraging recent convergence results for this algorithm in the nonmonotone setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17419v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Quan, Brecht Evens, Rodolphe Sepulchre, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>How long is long enough? Finite-horizon approximation of energy storage scheduling problems</title>
      <link>https://arxiv.org/abs/2411.17463</link>
      <description>arXiv:2411.17463v1 Announce Type: new 
Abstract: Energy storage scheduling problems, where a storage is operated to maximize its profit in response to a price signal, are essentially infinite-horizon optimization problems as storage systems operate continuously, without a foreseen end to their operation. Such problems can be solved to optimality with a rolling-horizon approach, provided that the planning horizon over which the problem is solved is long enough. Such a horizon is termed a forecast horizon. However, the length of the planning horizon is usually chosen arbitrarily for such applications. We introduce an easy-to-check condition that confirms whether a planning horizon is a forecast horizon, and which can be used to derive a bound on suboptimality when it is not the case. By way of an example, we demonstrate that the existence of forecast horizons is not guaranteed for this problem. We also derive a lower bound on the length of the minimum forecast horizon. We show how the condition introduced can be used as part of an algorithm to determine the minimum forecast horizon of the problem, which ensures the determination of optimal solutions at the lowest computational and forecasting costs. Finally, we provide insights into the implications of different planning horizons for a range of storage system characteristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17463v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>El\'ea Prat, Richard M. Lusby, Juan Miguel Morales, Salvador Pineda, Pierre Pinson</dc:creator>
    </item>
    <item>
      <title>Tight MIP Formulations for Optimal Operation and Investment of Storage Including Reserves</title>
      <link>https://arxiv.org/abs/2411.17484</link>
      <description>arXiv:2411.17484v1 Announce Type: new 
Abstract: Fast and accurate large-scale energy system models are needed to investigate the potential of storage to complement the fluctuating energy production of renewable energy systems. However, the standard Mixed-Integer Programming (MIP) models that describe optimal investment and operation of these storage units, including the optional capacity to provide up/down reserves, do not scale well. To improve scalability, the integrality constraints are often relaxed, resulting in Linear Programming (LP) relaxations that allow simultaneous charging and discharging, while this is not feasible in practice. To address this, we derive the convex hull of the solutions for the optimal operation of storage for one time period, as well as for problems including investments and reserves, guaranteeing that no tighter MIP formulation or better LP approximation exists for one time period. When included in multi-period large-scale energy system models, these improved LP relaxations can better prevent simultaneous charging and discharging. We demonstrate this with illustrative case studies of a unit commitment problem and a transmission expansion planning problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17484v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maaike B. Elgersma, Germ\'an Morales-Espa\~na, Karen I. Aardal, Niina Helist\"o, Juha Kiviluoma, Mathijs M. de Weerdt</dc:creator>
    </item>
    <item>
      <title>Exact and Heuristic Approaches for the Covering Tour Location Routing Problem</title>
      <link>https://arxiv.org/abs/2411.17510</link>
      <description>arXiv:2411.17510v1 Announce Type: new 
Abstract: The Covering Tour Location Routing Problem (CTLRP) unites the well-known location routing problem with the possibility of covering customers through intermediary facilities. The objective is to select a subset of greenfield or brownfield depots and a subset of facilities, assign customers to suitable facilities, and design routes for a fleet of vehicles such that each customer's demand of a homogenous good can be satisfied and a given objective function is minimized. We focus particularly on the case when customers can not be directly visited, i.e. they have to pick up their orders from intermediary facilities, and the objective function consists of the strategic and operational costs, i.e. total routing costs plus costs for establishing or operating the selected depots and facilities. We introduce a mixed-integer programming model derived from a 2-commodity flow formulation, which can be seen as a baseline model for various applications. As such models are often impractical to solve for realistically-sized scenarios, a local search-based matheuristic to solve the problem at hand is developed. Furthermore, we construct benchmark instances for the CTLRP by expanding existing LRP instances to include information on facilities and customers. Extensive computational experiments on said instances with the aim of analyzing different heuristic configurations show that the proposed heuristic, if designed carefully, is able to produce very good results within a short period of time, while exact solving methods using the proposed MIP formulation frequently return highly suboptimal solutions and exhibit slow convergence speeds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17510v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Hagn, Jan Krause, Lorenza Moreno, Moritz Stargalla</dc:creator>
    </item>
    <item>
      <title>A Network Flow Approach to Optimal Scheduling in Supply Chain Logistics</title>
      <link>https://arxiv.org/abs/2411.17544</link>
      <description>arXiv:2411.17544v1 Announce Type: new 
Abstract: In the evolving digital landscape, network flow models have transcended traditional applications to become integral in diverse sectors, including supply chain management. This research develops a robust network flow model for semiconductor wafer supply chains, optimizing resource allocation and addressing maximum flow challenges in production and logistics. The model incorporates the stochastic nature of wafer batch transfers and employs a dual-layer optimization framework to reduce variability and exceedance probabilities in finished goods. Empirical comparisons reveal significant enhancements in cost efficiency, productivity, and resource utilization, with a 20% reduction in time and production costs, and a 10% increase in transportation and storage capacities. The model's efficacy is underscored by a 15% decrease in transportation time and a 6700 kg increase in total capacity, demonstrating its capability to resolve logistical bottlenecks in semiconductor manufacturing. This study concludes that network flow models are a potent tool for optimizing supply chain logistics, offering a 23% improvement in resource utilization and a 13% boost in accuracy. The findings provide valuable insights for supply chain logistics optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17544v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yichen Wang, Qianjin Wang, Haowen Lei</dc:creator>
    </item>
    <item>
      <title>Dual Sourcing of Green Hydrogen: Balancing Local Production with Stochastic Capacity and Import with Random Yield</title>
      <link>https://arxiv.org/abs/2411.17583</link>
      <description>arXiv:2411.17583v1 Announce Type: new 
Abstract: Green hydrogen is a critical component for achieving the European Union's 2050 net-zero emissions goal. However, ensuring a reliable and stable supply is challenging, particularly when local production of green hydrogen is subject to high variability due to fluctuating renewable energy output. Although importing from regions with stable renewable resources may offer greater reliability, they introduce longer lead times and potential energy losses during transportation and conversion. To address this issue, we develop optimal dual sourcing policies for green hydrogen through modeling and solving a Markov Decision Process that integrates general lead times, stochastic local supply capacity, and random yield from import. Alongside optimal dual sourcing policies, we propose heuristic policies that offer both flexibility and stability, enabling practical implementation while achieving near-optimal performance. We test our framework on a case study for the Netherlands and obtain the following insights: (i) based on the results across different countries and cost settings, our dual sourcing model demonstrates an average cost benefit of 8 percent compared to models that ignore stochastic supply capacity and random yield, (ii) the proposed heuristic policies can perform comparably to optimal policies under varying country-specific conditions and cost settings, offering insights for shaping hydrogen trade agreements between importing and exporting countries, (iii) sensitivity analyses on production and storage costs, as well as variability in supply capacity, demand, and random yield, reveal the conditions needed to achieve specific local production levels. These results thereby support feasibility of the Netherlands' climate scenarios and ambitions while guiding green hydrogen investment planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17583v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sezen Ece Kayacik, Albert H. Schrotenboer, Iris F. A. Vis, Beste Basciftci, Evrim Ursavas</dc:creator>
    </item>
    <item>
      <title>Asymptotic behavior of the Arrow-Hurwicz differential system with Tikhonov regularization</title>
      <link>https://arxiv.org/abs/2411.17656</link>
      <description>arXiv:2411.17656v1 Announce Type: new 
Abstract: In a real Hilbert space setting, we investigate the asymptotic behavior of the solutions of the classical Arrow-Hurwicz differential system combined with Tikhonov regularizing terms. Under some newly proposed conditions on the Tikhonov terms involved, we show that the solutions of the regularized Arrow-Hurwicz differential system strongly converge toward the element of least norm within its set of zeros. Moreover, we provide fast asymptotic decay rate estimates for the so-called ``primal-dual gap function'' and the norm of the solutions' velocity. If, in addition, the Tikhonov regularizing terms are decreasing, we provide some refined estimates in the sense of an exponentially weighted moving average. Under the additional assumption that the governing operator of the Arrow-Hurwicz differential system satisfies a reverse Lipschitz condition, we further provide a fast rate of strong convergence of the solutions toward the unique zero. We conclude our study by deriving the corresponding decay rate estimates with respect to the so-called ``viscosity curve''. Numerical experiments illustrate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17656v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fouad Battahi, Zaki Chbani, Simon K. Niederl\"ander, Hassan Riahi</dc:creator>
    </item>
    <item>
      <title>Decision Making under the Exponential Family: Distributionally Robust Optimisation with Bayesian Ambiguity Sets</title>
      <link>https://arxiv.org/abs/2411.16829</link>
      <description>arXiv:2411.16829v1 Announce Type: cross 
Abstract: Decision making under uncertainty is challenging as the data-generating process (DGP) is often unknown. Bayesian inference proceeds by estimating the DGP through posterior beliefs on the model's parameters. However, minimising the expected risk under these beliefs can lead to suboptimal decisions due to model uncertainty or limited, noisy observations. To address this, we introduce Distributionally Robust Optimisation with Bayesian Ambiguity Sets (DRO-BAS) which hedges against model uncertainty by optimising the worst-case risk over a posterior-informed ambiguity set. We provide two such sets, based on posterior expectations (DRO-BAS(PE)) or posterior predictives (DRO-BAS(PP)) and prove that both admit, under conditions, strong dual formulations leading to efficient single-stage stochastic programs which are solved with a sample average approximation. For DRO-BAS(PE) this covers all conjugate exponential family members while for DRO-BAS(PP) this is shown under conditions on the predictive's moment generating function. Our DRO-BAS formulations Pareto dominate existing Bayesian DRO on the Newsvendor problem and achieve faster solve times with comparable robustness on the Portfolio problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16829v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charita Dellaporta, Patrick O'Hara, Theodoros Damoulas</dc:creator>
    </item>
    <item>
      <title>The Exploration of Neural Collapse under Imbalanced Data</title>
      <link>https://arxiv.org/abs/2411.17278</link>
      <description>arXiv:2411.17278v1 Announce Type: cross 
Abstract: Neural collapse, a newly identified characteristic, describes a property of solutions during model training. In this paper, we explore neural collapse in the context of imbalanced data. We consider the $L$-extended unconstrained feature model with a bias term and provide a theoretical analysis of global minimizer.
  Our findings include: (1) Features within the same class converge to their class mean, similar to both the balanced case and the imbalanced case without bias. (2) The geometric structure is mainly on the left orthonormal transformation of the product of $L$ linear classifiers and the right transformation of the class-mean matrix. (3) Some rows of the left orthonormal transformation of the product of $L$ linear classifiers collapse to zeros and others are orthogonal, which relies on the singular values of $\hat Y=(I_K-1/N\mathbf{n}1^\top_K)D$, where $K$ is class size, $\mathbf{n}$ is the vector of sample size for each class, $D$ is the diagonal matrix whose diagonal entries are given by $\sqrt{\mathbf{n}}$. Similar results are for the columns of the right orthonormal transformation of the product of class-mean matrix and $D$. (4) The $i$-th row of the left orthonormal transformation of the product of $L$ linear classifiers aligns with the $i$-th column of the right orthonormal transformation of the product of class-mean matrix and $D$. (5) We provide the estimation of singular values about $\hat Y$. Our numerical experiments support these theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17278v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haixia Liu</dc:creator>
    </item>
    <item>
      <title>A "Breathing" Mobile Communication Network</title>
      <link>https://arxiv.org/abs/2411.17290</link>
      <description>arXiv:2411.17290v1 Announce Type: cross 
Abstract: The frequent migration of large-scale users leads to the load imbalance of mobile communication networks, which causes resource waste and decreases user experience. To address the load balancing problem, this paper proposes a dynamic optimization framework for mobile communication networks inspired by the average consensus in multi-agent systems. In this framework, all antennas cooperatively optimize their CPICH (Common Pilot Channel) transmit power in real-time to balance their busy-degrees. Then, the coverage area of each antenna would change accordingly, and we call this framework a ``breathing'' mobile communication network. To solve this optimization problem, two algorithms named BDBA (Busy-degree Dynamic Balancing Algorithm) and BFDBA (Busy-degree Fast Dynamic Balancing Algorithm) are proposed. Moreover, a fast network coverage calculation method is introduced, by which each antenna's minimum CPICH transmit power is determined under the premise of meeting the network coverage requirements. Besides, we present the theoretical analysis of the two proposed algorithms' performance, which prove that all antennas' busy-degrees will reach consensus under certain assumptions. Furthermore, simulations carried out on three large datasets demonstrate that our cooperative optimization can significantly reduce the unbalance among antennas as well as the proportion of over-busy antennas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17290v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TMC.2024.3487213.</arxiv:DOI>
      <dc:creator>Chao Ge, Ge Chen, Zhipeng Jiang</dc:creator>
    </item>
    <item>
      <title>Decision making in stochastic extensive form II: Stochastic extensive forms and games</title>
      <link>https://arxiv.org/abs/2411.17587</link>
      <description>arXiv:2411.17587v1 Announce Type: cross 
Abstract: A general theory of stochastic extensive forms is developed to bridge two concepts of information flow: decision trees and refined partitions on the one side, filtrations from probability theory on the other. Instead of the traditional "nature" agent, this framework uses a single lottery draw to select a tree of a given decision forest. Each "personal" agent receives dynamic updates from an own oracle on the lottery outcome and makes partition-refining choices adapted to this information. This theory addresses a key limitation of existing approaches in extensive form theory, which struggle to model continuous-time stochastic processes, such as Brownian motion, as outcomes of "nature" decision making. Additionally, a class of stochastic extensive forms based on time-indexed action paths is constructed, encompassing a wide range of models from the literature and laying the groundwork for an approximation theory for stochastic differential games in extensive form.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17587v1</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>E. Emanuel Rapsch</dc:creator>
    </item>
    <item>
      <title>Anytime Acceleration of Gradient Descent</title>
      <link>https://arxiv.org/abs/2411.17668</link>
      <description>arXiv:2411.17668v1 Announce Type: cross 
Abstract: This work investigates stepsize-based acceleration of gradient descent with {\em anytime} convergence guarantees. For smooth (non-strongly) convex optimization, we propose a stepsize schedule that allows gradient descent to achieve convergence guarantees of $O(T^{-1.03})$ for any stopping time $T$, where the stepsize schedule is predetermined without prior knowledge of the stopping time. This result provides an affirmative answer to a COLT open problem \citep{kornowski2024open} regarding whether stepsize-based acceleration can yield anytime convergence rates of $o(T^{-1})$. We further extend our theory to yield anytime convergence guarantees of $\exp(-\Omega(T/\kappa^{0.97}))$ for smooth and strongly convex optimization, with $\kappa$ being the condition number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17668v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zihan Zhang, Jason D. Lee, Simon S. Du, Yuxin Chen</dc:creator>
    </item>
    <item>
      <title>Controllability and Vector Potential</title>
      <link>https://arxiv.org/abs/1911.01238</link>
      <description>arXiv:1911.01238v3 Announce Type: replace 
Abstract: Kalman's fundamental notion of a controllable state space system \cite{k} has been generalised to higher order systems by Willems \cite{w}, and further to distributed systems defined by partial differential equations \cite{ps}. It turns out, that for systems defined in several important spaces of distributions, controllability is now identical to the notion of vector potential in physics, or of vanishing homology in mathematics. These notes will explain this relationship, and a few of its consequences. It will also pose an important question: does a controllable system, in any space of distributions, always admit a vector potential? In other words, is Kalman's notion of a controllable system, suitably generalised, nothing more -- nor less -- than the possibility of describing the dynamics of the system by means of a vector potential?
  Furthermore, it also turns out that the category of distributed systems bears many formal similarities to the category of affine algebraic sets. This raises a second important question: what is the category for which these distributed systems are `local models', just as affine algebraic sets are local models for the category of algebraic varieties? It would then be possible to extend the theory of control described in these notes to this larger category of systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:1911.01238v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiva Shankar</dc:creator>
    </item>
    <item>
      <title>A Riemannian ADMM</title>
      <link>https://arxiv.org/abs/2211.02163</link>
      <description>arXiv:2211.02163v3 Announce Type: replace 
Abstract: We consider a class of Riemannian optimization problems where the objective is the sum of a smooth function and a nonsmooth function, considered in the ambient space. This class of problems finds important applications in machine learning and statistics such as the sparse principal component analysis, sparse spectral clustering, and orthogonal dictionary learning. We propose a Riemannian alternating direction method of multipliers (ADMM) to solve this class of problems. Our algorithm adopts easily computable steps in each iteration. The iteration complexity of the proposed algorithm for obtaining an $\epsilon$-stationary point is analyzed under mild assumptions. Existing ADMM for solving nonconvex problems either does not allow nonconvex constraint set, or does not allow nonsmooth objective function. Our algorithm is the first ADMM type algorithm that minimizes a nonsmooth objective over manifold -- a particular nonconvex set. Numerical experiments are conducted to demonstrate the advantage of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.02163v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaxiang Li, Shiqian Ma, Tejes Srivastava</dc:creator>
    </item>
    <item>
      <title>Second-order conditions for spatio-temporally sparse optimal control via second subderivatives</title>
      <link>https://arxiv.org/abs/2311.14538</link>
      <description>arXiv:2311.14538v2 Announce Type: replace 
Abstract: We address second-order optimality conditions for optimal control problems involving sparsity functionals which induce spatio-temporal sparsity patterns. We employ the notion of (weak) second subderivatives. With this approach, we are able to reproduce the results from Casas, Herzog, and Wachsmuth (ESAIM COCV, 23, 2017, p. 263-295). Our analysis yields a slight improvement of one of these results and also opens the door for the sensitivity analysis of this class of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14538v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nicolas Borchard, Gerd Wachsmuth</dc:creator>
    </item>
    <item>
      <title>Optimization meets Machine Learning: An Exact Algorithm for Semi-Supervised Support Vector Machines</title>
      <link>https://arxiv.org/abs/2312.09789</link>
      <description>arXiv:2312.09789v2 Announce Type: replace 
Abstract: Support vector machines (SVMs) are well-studied supervised learning models for binary classification. In many applications, large amounts of samples can be cheaply and easily obtained. What is often a costly and error-prone process is to manually label these instances. Semi-supervised support vector machines (S3VMs) extend the well-known SVM classifiers to the semi-supervised approach, aiming at maximizing the margin between samples in the presence of unlabeled data. By leveraging both labeled and unlabeled data, S3VMs attempt to achieve better accuracy and robustness compared to traditional SVMs. Unfortunately, the resulting optimization problem is non-convex and hence difficult to solve exactly. In this paper, we present a new branch-and-cut approach for S3VMs using semidefinite programming (SDP) relaxations. We apply optimality-based bound tightening to bound the feasible set. Box constraints allow us to include valid inequalities, strengthening the lower bound. The resulting SDP relaxation provides bounds significantly stronger than the ones available in the literature. For the upper bound, instead, we define a local search exploiting the solution of the SDP relaxation. Computational results highlight the efficiency of the algorithm, showing its capability to solve instances with a number of data points 10 times larger than the ones solved in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09789v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Veronica Piccialli, Jan Schwiddessen, Antonio M. Sudoso</dc:creator>
    </item>
    <item>
      <title>Finite-Time Decoupled Convergence in Nonlinear Two-Time-Scale Stochastic Approximation</title>
      <link>https://arxiv.org/abs/2401.03893</link>
      <description>arXiv:2401.03893v3 Announce Type: replace 
Abstract: In two-time-scale stochastic approximation (SA), two iterates are updated at varying speeds using different step sizes, with each update influencing the other. Previous studies on linear two-time-scale SA have shown that the convergence rates of the mean-square errors for these updates depend solely on their respective step sizes, a phenomenon termed decoupled convergence. However, achieving decoupled convergence in nonlinear SA remains less understood. Our research investigates the potential for finite-time decoupled convergence in nonlinear two-time-scale SA. We demonstrate that, under a nested local linearity assumption, finite-time decoupled convergence rates can be achieved with suitable step size selection. To derive this result, we conduct a convergence analysis of the matrix cross term between the iterates and leverage fourth-order moment convergence rates to control the higher-order error terms induced by local linearity. Additionally, a numerical example is provided to explore the possible necessity of local linearity for decoupled convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03893v3</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuze Han, Xiang Li, Zhihua Zhang</dc:creator>
    </item>
    <item>
      <title>Real-time Hosting Capacity Assessment for Electric Vehicles: A Sequential Forecast-then-Optimize Method</title>
      <link>https://arxiv.org/abs/2408.11269</link>
      <description>arXiv:2408.11269v3 Announce Type: replace 
Abstract: Hosting capacity (HC) assessment for electric vehicles (EVs) is crucial for EV secure integration and reliable power system operation. Existing methods primarily focus on a long-term perspective (e.g., system planning), and consider the EV charging demands as scalar values, which introduces inaccuracies in real-time operations due to the inherently stochastic nature of EVs. In this regard, this paper proposes a real-time HC assessment method for EVs through a three-step process, involving real-time probabilistic forecasting, risk analysis and probabilistic optimization. Specifically, we conduct real-time probabilistic forecasting to capture the stochastic nature of EV charging demands across multiple charging stations by performing deterministic forecasting and fitting the distribution of forecasting errors. The deterministic forecasting is conducted using an adaptive spatio-temporal graph convolutional network (ASTGCN). ASTGCN leverages adaptive spatial feature extraction, attention-based temporal feature extraction, and second-order graph representation to improve the forecasting performance. Subsequently, based on the probabilistic forecasting of EV charging demands, we conduct real-time risk analysis and operational boundary identification by utilizing probabilistic power flow calculations to assess potential violations of secure operation constraints. Furthermore, we present the formulation of real-time HC of EVs considering expected satisfaction of stochastic EV charging demands, and propose an optimization model for real-time HC assessment of EVs. Numerical experiments on a real-world dataset demonstrate that the proposed ASTGCN model outperforms state-of-the-art forecasting models by achieving the lowest root mean square error of 0.0442, and the real-time HC is improved by 64% compared to long-term HC assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11269v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingrui Zhuang, Lin Cheng, Ning Qi, Xinyi Wang, Yue Chen</dc:creator>
    </item>
    <item>
      <title>Envisioning an Optimal Network of Space-Based Lasers for Orbital Debris Remediation</title>
      <link>https://arxiv.org/abs/2409.03146</link>
      <description>arXiv:2409.03146v2 Announce Type: replace 
Abstract: The significant expansion of the orbital debris population poses a serious threat to the safety and sustainability of space operations. This paper investigates orbital debris remediation through a network of collaborative space-based lasers, leveraging the principle of momentum transfer onto debris via laser ablation. A novel delta-v vector analysis framework quantifies the cumulative effects of multiple concurrent laser-to-debris (L2D) engagements, utilizing the vector composition of the imparted delta-v vectors. The paper formulates the Concurrent Location-Scheduling Problem (CLSP) to optimize the placement of laser platforms and the scheduling of L2D engagements, aiming to maximize debris remediation capacity. Given the computational intractability of the CLSP, a decomposition strategy is employed, yielding two sequential subproblems: (1) determining optimal laser platform locations via the Maximal Covering Location Problem, and (2) scheduling L2D engagements using a novel integer linear programming approach to maximize debris remediation capacity. Computational experiments evaluate the efficacy of the proposed framework across diverse mission scenarios, demonstrating critical network functions such as collaborative and controlled nudging, deorbiting, and just-in-time collision avoidance. A sensitivity analysis further explores the impact of varying the number and distribution of laser platforms on debris remediation capacity, offering insights into optimizing the performance of space-based laser networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03146v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David O. Williams Rogers, Matthew C. Fox, Paul R. Stysley, Hang Woon Lee</dc:creator>
    </item>
    <item>
      <title>Optimality of Motion Camouflage Under Escape Uncertainty</title>
      <link>https://arxiv.org/abs/2409.09890</link>
      <description>arXiv:2409.09890v2 Announce Type: replace 
Abstract: This letter proposes a novel continuous-time dynamic programming framework to determine when it is optimal for a pursuer to use MC amidst uncertainty in the evader's escape attempt time. We motivate this framework through the model problem of an energy-optimizing male hover fly pursuing a female hover fly for mating. The time at which the female fly initiates an escape is modeled to occur as the result of a non-homogeneous Poisson point process with a biologically informed rate function, and we obtain and solve two Hamilton-Jacobi-Bellman (HJB) PDEs which encode the pursuer's optimal trajectories. Our numerical experiments and statistics illustrate when it is optimal to use MC pursuit tactics amidst uncertainty and how MC optimality is affected by certain properties of the evader's sensing abilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09890v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mallory E. Gaspard</dc:creator>
    </item>
    <item>
      <title>Fair Mixed Effects Support Vector Machine</title>
      <link>https://arxiv.org/abs/2405.06433</link>
      <description>arXiv:2405.06433v5 Announce Type: replace-cross 
Abstract: To ensure unbiased and ethical automated predictions, fairness must be a core principle in machine learning applications. Fairness in machine learning aims to mitigate biases present in the training data and model imperfections that could lead to discriminatory outcomes. This is achieved by preventing the model from making decisions based on sensitive characteristics like ethnicity or sexual orientation. A fundamental assumption in machine learning is the independence of observations. However, this assumption often does not hold true for data describing social phenomena, where data points are often clustered based. Hence, if the machine learning models do not account for the cluster correlations, the results may be biased. Especially high is the bias in cases where the cluster assignment is correlated to the variable of interest. We present a fair mixed effects support vector machine algorithm that can handle both problems simultaneously. With a reproducible simulation study we demonstrate the impact of clustered data on the quality of fair machine learning predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06433v5</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jo\~ao Vitor Pamplona, Jan Pablo Burgard</dc:creator>
    </item>
    <item>
      <title>S-CFE: Simple Counterfactual Explanations</title>
      <link>https://arxiv.org/abs/2410.15723</link>
      <description>arXiv:2410.15723v3 Announce Type: replace-cross 
Abstract: We study the problem of finding optimal sparse, manifold-aligned counterfactual explanations for classifiers. Canonically, this can be formulated as an optimization problem with multiple non-convex components, including classifier loss functions and manifold alignment (or \emph{plausibility}) metrics. The added complexity of enforcing \emph{sparsity}, or shorter explanations, complicates the problem further. Existing methods often focus on specific models and plausibility measures, relying on convex $\ell_1$ regularizers to enforce sparsity. In this paper, we tackle the canonical formulation using the accelerated proximal gradient (APG) method, a simple yet efficient first-order procedure capable of handling smooth non-convex objectives and non-smooth $\ell_p$ (where $0 \leq p &lt; 1$) regularizers. This enables our approach to seamlessly incorporate various classifiers and plausibility measures while producing sparser solutions. Our algorithm only requires differentiable data-manifold regularizers and supports box constraints for bounded feature ranges, ensuring the generated counterfactuals remain \emph{actionable}. Finally, experiments on real-world datasets demonstrate that our approach effectively produces sparse, manifold-aligned counterfactual explanations while maintaining proximity to the factual data and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15723v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shpresim Sadiku, Moritz Wagner, Sai Ganesh Nagarajan, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Towards safe Bayesian optimization with Wiener kernel regression</title>
      <link>https://arxiv.org/abs/2411.02253</link>
      <description>arXiv:2411.02253v2 Announce Type: replace-cross 
Abstract: Bayesian Optimization (BO) is a data-driven strategy for minimizing/maximizing black-box functions based on probabilistic surrogate models. In the presence of safety constraints, the performance of BO crucially relies on tight probabilistic error bounds related to the uncertainty surrounding the surrogate model. For the case of Gaussian Process surrogates and Gaussian measurement noise, we present a novel error bound based on the recently proposed Wiener kernel regression. We prove that under rather mild assumptions, the proposed error bound is tighter than bounds previously documented in the literature which leads to enlarged safety regions. We draw upon a numerical example to demonstrate the efficacy of the proposed error bound in safe BO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02253v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 27 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oleksii Molodchyk, Johannes Teutsch, Timm Faulwasser</dc:creator>
    </item>
  </channel>
</rss>
