<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Jul 2024 02:47:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Mathematical modelling and uncertainty quantification for analysis of biphasic coral reef recovery patterns</title>
      <link>https://arxiv.org/abs/2406.19591</link>
      <description>arXiv:2406.19591v1 Announce Type: new 
Abstract: Coral reefs are increasingly subjected to major disturbances threatening the health of marine ecosystems. Substantial research underway to develop intervention strategies that assist reefs in recovery from, and resistance to, inevitable future climate and weather extremes. To assess potential benefits of interventions, mechanistic understanding of coral reef recovery and resistance patterns is essential. Recent evidence suggests that more than half of the reefs surveyed across the Great Barrier Reef (GBR) exhibit deviations from standard recovery modelling assumptions when the initial coral cover is low ($\leq 10$\%). New modelling is necessary to account for these observed patterns to better inform management strategies. We consider a new model for reef recovery at the coral cover scale that accounts for biphasic recovery patterns. The model is based on a multispecies Richards' growth model that includes a change point in the recovery patterns. Bayesian inference is applied for uncertainty quantification of key parameters for assessing reef health and recovery patterns. This analysis is applied to benthic survey data from the Australian Institute of Marine Sciences (AIMS). We demonstrate agreement between model predictions and data across every recorded recovery trajectory with at least two years of observations following disturbance events occurring between 1992--2020. This new approach will enable new insights into the biological, ecological and environmental factors that contribute to the duration and severity of biphasic coral recovery patterns across the GBR. These new insights will help to inform managements and monitoring practice to mitigate the impacts of climate change on coral reefs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19591v1</guid>
      <category>stat.AP</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David J. Warne, Kerryn Crossman, Grace E. M. Heron, Jesse A. Sharp, Wang Jin, Paul Pao-Yen Wu, Matthew J. Simpson, Kerrie Mengersen, Juan-Carlos Ortiz</dc:creator>
    </item>
    <item>
      <title>Surrogate model for Bayesian optimal experimental design in chromatography</title>
      <link>https://arxiv.org/abs/2406.19835</link>
      <description>arXiv:2406.19835v1 Announce Type: new 
Abstract: We applied Bayesian Optimal Experimental Design (OED) in the estimation of parameters involved in the Equilibrium Dispersive Model for chromatography with two components with the Langmuir adsorption isotherm. The coefficients estimated were Henry's coefficients, the total absorption capacity and the number of theoretical plates, while the design variables were the injection time and the initial concentration. The Bayesian OED algorithm is based on nested Monte Carlo estimation, which becomes computationally challenging due to the simulation time of the PDE involved in the dispersive model. This complication was relaxed by introducing a surrogate model based on Piecewise Sparse Linear Interpolation. Using the surrogate model instead the original reduces significantly the simulation time and it approximates the solution of the PDE with high degree of accuracy. The estimation of the parameters over strategical design points provided by OED reduces the uncertainty in the estimation of parameters. Additionally, the Bayesian OED methodology indicates no improvements when increasing the number of measurements in temporal nodes above a threshold value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19835v1</guid>
      <category>stat.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jose Rodrigo Rojo-Garcia, Heikki Haario, Tapio Helin, Tuomo Sainio</dc:creator>
    </item>
    <item>
      <title>Stock Volume Forecasting with Advanced Information by Conditional Variational Auto-Encoder</title>
      <link>https://arxiv.org/abs/2406.19414</link>
      <description>arXiv:2406.19414v1 Announce Type: cross 
Abstract: We demonstrate the use of Conditional Variational Encoder (CVAE) to improve the forecasts of daily stock volume time series in both short and long term forecasting tasks, with the use of advanced information of input variables such as rebalancing dates. CVAE generates non-linear time series as out-of-sample forecasts, which have better accuracy and closer fit of correlation to the actual data, compared to traditional linear models. These generative forecasts can also be used for scenario generation, which aids interpretation. We further discuss correlations in non-stationary time series and other potential extensions from the CVAE forecasts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19414v1</guid>
      <category>q-fin.ST</category>
      <category>cs.LG</category>
      <category>q-fin.PR</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <category>stat.OT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parley R Yang, Alexander Y Shestopaloff</dc:creator>
    </item>
    <item>
      <title>Bayesian calibration of stochastic agent based model via random forest</title>
      <link>https://arxiv.org/abs/2406.19524</link>
      <description>arXiv:2406.19524v1 Announce Type: cross 
Abstract: Agent-based models (ABM) provide an excellent framework for modeling outbreaks and interventions in epidemiology by explicitly accounting for diverse individual interactions and environments. However, these models are usually stochastic and highly parametrized, requiring precise calibration for predictive performance. When considering realistic numbers of agents and properly accounting for stochasticity, this high dimensional calibration can be computationally prohibitive. This paper presents a random forest based surrogate modeling technique to accelerate the evaluation of ABMs and demonstrates its use to calibrate an epidemiological ABM named CityCOVID via Markov chain Monte Carlo (MCMC). The technique is first outlined in the context of CityCOVID's quantities of interest, namely hospitalizations and deaths, by exploring dimensionality reduction via temporal decomposition with principal component analysis (PCA) and via sensitivity analysis. The calibration problem is then presented and samples are generated to best match COVID-19 hospitalization and death numbers in Chicago from March to June in 2020. These results are compared with previous approximate Bayesian calibration (IMABC) results and their predictive performance is analyzed showing improved performance with a reduction in computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19524v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Connor Robertson, Cosmin Safta, Nicholson Collier, Jonathan Ozik, Jaideep Ray</dc:creator>
    </item>
    <item>
      <title>Bayesian Rank-Clustering</title>
      <link>https://arxiv.org/abs/2406.19563</link>
      <description>arXiv:2406.19563v1 Announce Type: cross 
Abstract: In a traditional analysis of ordinal comparison data, the goal is to infer an overall ranking of objects from best to worst with each object having a unique rank. However, the ranks of some objects may not be statistically distinguishable. This could happen due to insufficient data or to the true underlying abilities or qualities being equal for some objects. In such cases, practitioners may prefer an overall ranking where groups of objects are allowed to have equal ranks or to be $\textit{rank-clustered}$. Existing models related to rank-clustering are limited by their inability to handle a variety of ordinal data types, to quantify uncertainty, or by the need to pre-specify the number and size of potential rank-clusters. We solve these limitations through the proposed Bayesian $\textit{Rank-Clustered Bradley-Terry-Luce}$ model. We allow for rank-clustering via parameter fusion by imposing a novel spike-and-slab prior on object-specific worth parameters in Bradley-Terry-Luce family of distributions for ordinal comparisons. We demonstrate the model on simulated and real datasets in survey analysis, elections, and sports.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19563v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Michael Pearce, Elena A. Erosheva</dc:creator>
    </item>
    <item>
      <title>Predictability of climate tipping focusing on the internal variability of the Earth system</title>
      <link>https://arxiv.org/abs/2406.19639</link>
      <description>arXiv:2406.19639v1 Announce Type: cross 
Abstract: Prediction of climate tipping is challenging due to the lack of recent observation of actual climate tipping. Despite many previous efforts to accurately predict the existence and timing of climate tippings under specific climate scenarios, the predictability of climate tipping, the necessary conditions under which climate tipping can be predicted, has yet to be explored. In this study, the predictability of climate tipping is analyzed by Observation System Simulation Experiment (OSSE), in which the value of observation for prediction is assessed through the idealized experiment of data assimilation, using a simplified dynamic vegetation model and an Atlantic Meridional Overturning Circulation (AMOC) two box model. We find that the ratio of internal variability to observation error, or signal-to-noise ratio, should be large enough to accurately predict climate tippings. When observation can accurately resolve the internal variability of the system, assimilating these observations into process-based models can effectively improve the skill of predicting climate tippings. Our quantitative estimation of required observation accuracy to predict climate tipping implies that the existing observation network is not always sufficient to accurately project climate tipping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19639v1</guid>
      <category>physics.ao-ph</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amane Kubo, Yohei Sawada</dc:creator>
    </item>
    <item>
      <title>Functional Time Transformation Model with Applications to Digital Health</title>
      <link>https://arxiv.org/abs/2406.19716</link>
      <description>arXiv:2406.19716v1 Announce Type: cross 
Abstract: The advent of wearable and sensor technologies now leads to functional predictors which are intrinsically infinite dimensional. While the existing approaches for functional data and survival outcomes lean on the well-established Cox model, the proportional hazard (PH) assumption might not always be suitable in real-world applications. Motivated by physiological signals encountered in digital medicine, we develop a more general and flexible functional time-transformation model for estimating the conditional survival function with both functional and scalar covariates. A partially functional regression model is used to directly model the survival time on the covariates through an unknown monotone transformation and a known error distribution. We use Bernstein polynomials to model the monotone transformation function and the smooth functional coefficients. A sieve method of maximum likelihood is employed for estimation. Numerical simulations illustrate a satisfactory performance of the proposed method in estimation and inference. We demonstrate the application of the proposed model through two case studies involving wearable data i) Understanding the association between diurnal physical activity pattern and all-cause mortality based on accelerometer data from the National Health and Nutrition Examination Survey (NHANES) 2011-2014 and ii) Modelling Time-to-Hypoglycemia events in a cohort of diabetic patients based on distributional representation of continuous glucose monitoring (CGM) data. The results provide important epidemiological insights into the direct association between survival times and the physiological signals and also exhibit superior predictive performance compared to traditional summary based biomarkers in the CGM study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19716v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rahul Ghosal, Marcos Matabuena, Sujit K. Ghosh</dc:creator>
    </item>
    <item>
      <title>Futility analyses for the MCP-Mod methodology based on longitudinal models</title>
      <link>https://arxiv.org/abs/2406.19965</link>
      <description>arXiv:2406.19965v1 Announce Type: cross 
Abstract: This article discusses futility analyses for the MCP-Mod methodology. Formulas are derived for calculating predictive and conditional power for MCP-Mod, which also cover the case when longitudinal models are used allowing to utilize incomplete data from patients at interim. A simulation study is conducted to evaluate the repeated sampling properties of the proposed decision rules and to assess the benefit of using a longitudinal versus a completer only model for decision making at interim. The results suggest that the proposed methods perform adequately and a longitudinal analysis outperforms a completer only analysis, particularly when the recruitment speed is higher and the correlation over time is larger. The proposed methodology is illustrated using real data from a dose-finding study for severe uncontrolled asthma.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19965v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bj\"orn Bornkamp, Jie Zhou, Dong Xi, Weihua Cao</dc:creator>
    </item>
    <item>
      <title>A Statistical Model of Bipartite Networks: Application to Cosponsorship in the United States Senate</title>
      <link>https://arxiv.org/abs/2305.05833</link>
      <description>arXiv:2305.05833v2 Announce Type: replace 
Abstract: Many networks in political and social research are bipartite, with edges connecting exclusively across two distinct types of nodes. A common example includes cosponsorship networks, in which legislators are connected indirectly through the bills they support. Yet most existing network models are designed for unipartite networks, where edges can arise between any pair of nodes. However, using a unipartite network model to analyze bipartite networks, as often done in practice, can result in aggregation bias and artificially high-clustering -- a particularly insidious problem when studying the role groups play in network formation. To address these methodological problems, we develop a statistical model of bipartite networks theorized to be generated through group interactions by extending the popular mixed-membership stochastic blockmodel. Our model allows researchers to identify the groups of nodes, within each node type in the bipartite structure, that share common patterns of edge formation. The model also incorporates both node and dyad-level covariates as the predictors of group membership and of observed dyadic relations. We develop an efficient computational algorithm for fitting the model, and apply it to cosponsorship data from the United States Senate. We show that legislators in a Senate that was perfectly split along party lines were able to remain productive and pass major legislation by forming non-partisan, power-brokering coalitions that found common ground through their collaboration on low-stakes bills. We also find evidence for norms of reciprocity, and uncover the substantial role played by policy expertise in the formation of cosponsorships between senators and legislation. We make an open-source software package available that makes it possible for other researchers to uncover similar insights from bipartite networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.05833v2</guid>
      <category>stat.AP</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Adeline Lo, Santiago Olivella, Kosuke Imai</dc:creator>
    </item>
    <item>
      <title>Hypothesis-driven mediation analysis for compositional data: an application to gut microbiome</title>
      <link>https://arxiv.org/abs/2308.16000</link>
      <description>arXiv:2308.16000v2 Announce Type: replace 
Abstract: Biological sequencing data consist of read counts, e.g. of specified taxa and often exhibit sparsity (zero-count inflation) and overdispersion (extra-Poisson variability). As most sequencing techniques provide an arbitrary total count, taxon-specific counts should ideally be treated as proportions under the compositional data-analytic framework. There is increasing interest in the role of the gut microbiome composition in mediating the effects of different exposures on health outcomes. Most previous approaches to compositional mediation have addressed the problem of identifying potentially mediating taxa among a large number of candidates. We here consider causal inference in compositional mediation when a priori knowledge is available about the hierarchy for a restricted number of taxa, building on a single hypothesis structured in terms of contrasts between appropriate sub-compositions. Based on the theory on multiple contemporaneous mediators and the assumed causal graph, we define non-parametric estimands for overall and coordinate-wise mediation effects, and show how these indirect effects can be estimated from empirical data based on simple parametric linear models. The mediators have straightforward and coherent interpretations, related to specific causal questions about the interrelationships between the sub-compositions. We perform a simulation study focusing on the impact of sparsity and overdispersion on estimation of mediation. While unbiased, the precision of the estimators depends, for any given magnitude of indirect effect, on sparsity and the relative magnitudes of exposure-to-mediator and mediator-to-outcome effects in a complex manner. We demonstrate the approach on empirical data, finding an inverse association of fibre intake on insulin level, mainly attributable to direct rather than indirect effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.16000v2</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/24709360.2024.2360375</arxiv:DOI>
      <dc:creator>Noora Kartiosuo, Jaakko Nevalainen, Olli Raitakari, Katja Pahkala, Kari Auranen</dc:creator>
    </item>
    <item>
      <title>A Spatial-statistical model to analyse historical rutting data</title>
      <link>https://arxiv.org/abs/2401.03633</link>
      <description>arXiv:2401.03633v3 Announce Type: replace 
Abstract: Pavement rutting poses a significant challenge in flexible pavements, necessitating costly asphalt resurfacing. To address this issue comprehensively, we propose an advanced Bayesian hierarchical framework of latent Gaussian models with spatial components. Our model provides a thorough diagnostic analysis, pinpointing areas exhibiting unexpectedly high rutting rates. Incorporating spatial and random components, and important explanatory variables like annual average daily traffic (traffic intensity), asphalt type, rut depth and lane width, our proposed models account for and estimate the influence of these variables on rutting. This approach not only quantifies uncertainties and discerns locations at the highest risk of requiring maintenance, but also uncover spatial dependencies in rutting (millimetre/year). We apply our models to a data set spanning eleven years (2010-2020). Our findings emphasise the systematic unexplained spatial rutting effect, where some of the rutting variability is accounted for by spatial components, asphalt type, in conjunction with traffic intensity, is also found to be the primary driver of rutting. Furthermore, the spatial dependencies uncovered reveal road sections experiencing more than 1 millimeter of rutting beyond annual expectations. This leads to a halving of the expected pavement lifespan in these areas. Our study offers valuable insights, presenting maps indicating expected rutting, and identifying locations with accelerated rutting rates, resulting in a reduction in pavement life expectancy of at least 10 years.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03633v3</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Natoya O. A. S. Jourdain, Ingelin Steinsland, Mamoona Birkhez-Shami, Emil Vedvik, William Olsen, Dagfin Gryteselv, Doreen Siebert, Alex Klein-Paste</dc:creator>
    </item>
    <item>
      <title>A comprehensive survey of the home advantage in American football</title>
      <link>https://arxiv.org/abs/2401.16392</link>
      <description>arXiv:2401.16392v3 Announce Type: replace 
Abstract: The existence and justification to the home advantage -- the benefit a sports team receives when playing at home -- has been studied across sport. The majority of research on this topic is limited to individual leagues in short time frames, which hinders extrapolation and a deeper understanding of possible causes. Using nearly two decades of data from the National Football League (NFL), the National Collegiate Athletic Association (NCAA), and high schools from across the United States, we provide a uniform approach to understanding the home advantage in American football. Our findings suggest home advantage is declining in the NFL and the highest levels of collegiate football, but not in amateur football. This increases the possibility that characteristics of the NCAA and NFL, such as travel improvements and instant replay, have helped level the playing field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16392v3</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke S. Benz, Thompson J. Bliss, Michael J. Lopez</dc:creator>
    </item>
    <item>
      <title>Bayesian analysis of biomarker levels can predict time of recurrence of prostate cancer with strictly positive apparent Shannon information against an exponential attrition prior</title>
      <link>https://arxiv.org/abs/2404.17857</link>
      <description>arXiv:2404.17857v2 Announce Type: replace 
Abstract: Shariat et al previously investigated the possibility of predicting from clinical data (including Gleason grade and stage) and preoperative biomarkers, which of any pair of patients would suffer recurrence of prostate cancer first. We wished to establish the extent to which predictions of time of relapse from such a model could be improved upon using Bayesian methods.
  The same dataset was reanalysed with a Bayesian skew-Student mixture model. Predictions were made of which of any pair of patients would relapse first and of the time of relapse. The benefit of using these biomarkers relative to predictions made without them was measured by the apparent Shannon information, using as prior an exponential attrition model of relapse time independent of input variables.
  Using half the dataset for training and the other half for testing, predictions of relapse time from the strict Cox model gave $-\infty$ nepers of apparent Shannon information (it predicts that relapse can only occur at times when patients in the training set relapsed). Deliberately smoothed predictions from the Cox model gave -0.001 (-0.131 to +0.120) nepers, while the Bayesian model gave +0.109 (+0.021 to +0.192) nepers (mean, 2.5 to 97.5 centiles), being positive with posterior probability 0.993 and beating the blurred Cox model with posterior probability 0.927.
  These predictions from the Bayesian model thus outperform those of the Cox model, but the overall yield of predictive information leaves scope for improvement of the range of biomarkers in use. The Bayesian model presented here is the first such model for prostate cancer to consider the variation of relapse hazard with biomarker concentrations to be smooth, as is intuitive. It is also the first to be shown to provide more apparent Shannon information than the Cox model or to be shown to provide positive apparent information relative to an exponential prior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17857v2</guid>
      <category>stat.AP</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Roger Sewell, Elisabeth Crowe, Sharokh F. Shariat</dc:creator>
    </item>
    <item>
      <title>Trade-off between predictive performance and FDR control for high-dimensional Gaussian model selection</title>
      <link>https://arxiv.org/abs/2302.01831</link>
      <description>arXiv:2302.01831v4 Announce Type: replace-cross 
Abstract: In the context of high-dimensional Gaussian linear regression for ordered variables, we study the variable selection procedure via the minimization of the penalized least-squares criterion. We focus on model selection where the penalty function depends on an unknown multiplicative constant commonly calibrated for prediction. We propose a new proper calibration of this hyperparameter to simultaneously control predictive risk and false discovery rate. We obtain non-asymptotic bounds on the False Discovery Rate with respect to the hyperparameter and we provide an algorithm to calibrate it. This algorithm is based on quantities that can typically be observed in real data applications. The algorithm is validated in an extensive simulation study and is compared with several existing variable selection procedures. Finally, we study an extension of our approach to the case in which an ordering of the variables is not available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.01831v4</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Perrine Lacroix, Marie-Laure Martin</dc:creator>
    </item>
  </channel>
</rss>
