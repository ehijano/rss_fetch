<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Nov 2025 05:00:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Understanding the Complexities of Responsibly Sharing NSFW Content Online</title>
      <link>https://arxiv.org/abs/2511.15726</link>
      <description>arXiv:2511.15726v1 Announce Type: new 
Abstract: Reddit is in the minority of mainstream social platforms that permit posting content that may be considered to be at the edge of what is permissible, including so-called Not Safe For Work (NSFW) content. However, NSFW is becoming more common on mainstream platforms, with X now allowing such material. We examine the top 15 NSFW-restricted subreddits by size to explore the complexities of responsibly sharing adult content, aiming to balance ethical and legal considerations with monetization opportunities. We find that users often use NSFW subreddits as a social springboard, redirecting readers to private or specialized adult social platforms such as Telegram, Kik or OnlyFans for further interactions. They also directly negotiate image "trades" through credit cards or payment platforms such as PayPal, Bitcoin or Venmo. Disturbingly, we also find linguistic cues linked to non-consensual content sharing. To help platforms moderate such behavior, we trained a RoBERTa-based classification model, which outperforms GPT-4 and traditional classifiers such as logistic regression and random forest in identifying non-consensual content sharing, demonstrating superior performance in this specific task. The source code and trained model weights are publicly available at https://github.com/socsys/15NSFW Subreddits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15726v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shalini Jangra, Zaid Almahmoud, Suparna De, Gareth Tyson, Ehsan Ul Haq, Nishanth Sastry</dc:creator>
    </item>
    <item>
      <title>Disagreement is Disappearing on U.S. Cable Debate Shows</title>
      <link>https://arxiv.org/abs/2511.15774</link>
      <description>arXiv:2511.15774v1 Announce Type: new 
Abstract: Prime-time cable news programs are a highly influential part of the American media landscape, with top-rated opinion shows attracting millions of politically attentive viewers each night. In an era of intense political polarization, a critical question is whether these widely-watched "debate" shows foster genuine discussion or have devolved into partisan echo chambers that deepen societal divides. While these programs claim to air competing viewpoints, no large-scale evidence exists to quantify how often hosts and guests actually disagree. Measuring these exchanges is a significant challenge, as live broadcasts contain overlapping speakers, sarcasm, and billions of words of text. To address this gap, we construct the first speaker-resolved map of agreement and disagreement across U.S. cable opinion programming. Our study assembles over 21,000 episodes from 24 flagship shows on Fox News, MSNBC, and CNN from 2010-2024, segmenting them into host-guest turns and labeling 2.13 million turn-pairs using a high-fidelity large-language-model classifier. We present three findings: (1) the proportion of disagreement/debate on prime time shows a consistent downward trend, dropping by roughly one-third between 2017 and 2024; (2) on-air challenge is partisan and asymmetric--conservatives seldom face push-back on Fox, liberals seldom on MSNBC, with CNN declining toward the midpoint; and (3) polarizing issues such as abortion, gun rights, and immigration attract the least disagreement. The work contributes a public corpus, an open-source stance pipeline, and the first longitudinal evidence that televised "debate" is retreating from genuine discussion. By transforming into platforms for partisan affirmation, these shows erode the cross-cutting cleavages essential for a pluralistic society, thereby intensifying affective polarization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15774v1</guid>
      <category>cs.SI</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S M Mehedi Zaman, Kiran Garimella</dc:creator>
    </item>
    <item>
      <title>Time-Critical Adversarial Influence Blocking Maximization</title>
      <link>https://arxiv.org/abs/2511.16068</link>
      <description>arXiv:2511.16068v1 Announce Type: new 
Abstract: Adversarial Influence Blocking Maximization (AIBM) aims to select a set of positive seed nodes that propagate synchronously with the known negative seed nodes on the graph to counteract their negative influence. Currently, most AIBM studies are based on the classical Independent Cascade (IC) model, which omits the time factor and thus hinders their applications to time-critical scenarios like political campaigns or public emergencies. More importantly, existing AIBM studies have not investigated in-depth the submodularity of the objective function, resulting in their failure to provide a theoretical lower bound for the problem. To address these challenges, firstly, this paper proposes the Time-Critical Independent Cascade (TC-IC) model, which incorporates time constraints into the classical IC model. Secondly, the Time-Critical Adversarial Influence Blocking Maximization (TC-AIBM) is established to better handle time-critical scenarios. A detailed formulation of the problem is then presented, along with a theoretical proof of its submodularity under three different tie-breaking rules. Finally, a Bidirectional Influence Sampling (BIS) algorithm is proposed to solve the TC-AIBM problem. The submodularity of the objective function guarantees that the BIS can provide an approximation guarantee of
  to the optimal solution. Comprehensive experiments on four real-world datasets demonstrated that the proposed BIS algorithm exhibits excellent stability with various negative seeds, time constraints, and tie-breaking rules, outperforming state-of-the-art baselines. In addition, BIS improves efficiency by up to three orders of magnitude compared to the Greedy algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16068v1</guid>
      <category>cs.SI</category>
      <category>cs.GR</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jilong Shi, Qiuyan Yan, Xiaobin Rui, Zhixiao Wang</dc:creator>
    </item>
    <item>
      <title>CausalMamba: Interpretable State Space Modeling for Temporal Rumor Causality</title>
      <link>https://arxiv.org/abs/2511.16191</link>
      <description>arXiv:2511.16191v1 Announce Type: cross 
Abstract: Rumor detection on social media remains a challenging task due to the complex propagation dynamics and the limited interpretability of existing models. While recent neural architectures capture content and structural features, they often fail to reveal the underlying causal mechanisms of misinformation spread. We propose CausalMamba, a novel framework that integrates Mamba-based sequence modeling, graph convolutional networks (GCNs), and differentiable causal discovery via NOTEARS. CausalMamba learns joint representations of temporal tweet sequences and reply structures, while uncovering latent causal graphs to identify influential nodes within each propagation chain. Experiments on the Twitter15 dataset show that our model achieves competitive classification performance compared to strong baselines, and uniquely enables counterfactual intervention analysis. Qualitative results demonstrate that removing top-ranked causal nodes significantly alters graph connectivity, offering interpretable insights into rumor dynamics. Our framework provides a unified approach for rumor classification and influence analysis, paving the way for more explainable and actionable misinformation detection systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16191v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaotong Zhan, Xi Cheng</dc:creator>
    </item>
    <item>
      <title>ART: A Graph-based Framework for Investigating Illicit Activity in Monero via Address-Ring-Transaction Structures</title>
      <link>https://arxiv.org/abs/2511.16192</link>
      <description>arXiv:2511.16192v1 Announce Type: cross 
Abstract: As Law Enforcement Agencies advance in cryptocurrency forensics, criminal actors aiming to conceal illicit fund movements increasingly turn to "mixin" services or privacy-based cryptocurrencies. Monero stands out as a leading choice due to its strong privacy preserving and untraceability properties, making conventional blockchain analysis ineffective. Understanding the behavior and operational patterns of criminal actors within Monero is therefore challenging and it is essential to support future investigative strategies and disrupt illicit activities. In this work, we propose a case study in which we leverage a novel graph-based methodology to extract structural and temporal patterns from Monero transactions linked to already discovered criminal activities. By building Address-Ring-Transaction graphs from flagged transactions, we extract structural and temporal features and use them to train Machine Learning models capable of detecting similar behavioral patterns that could highlight criminal modus operandi. This represents a first partial step toward developing analytical tools that support investigative efforts in privacy-preserving blockchain ecosystems</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16192v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Venturi, Imanol Jerico-Yoldi, Francesco Zola, Raul Orduna</dc:creator>
    </item>
    <item>
      <title>Disparity-in-Differences: Extracting Hierarchical Backbones of Weighted Directed Networks</title>
      <link>https://arxiv.org/abs/2511.16598</link>
      <description>arXiv:2511.16598v1 Announce Type: cross 
Abstract: Networks are useful representations for complex systems. Especially, heterogeneous and asymmetrical relations commonly found in complex systems can be converted to weighted directed edges between nodes. The disparity filter (Serrano et al., 2009) has successfully extracted backbones, sets of important edges, from empirical networks but is not designed to incorporate node-node dependency that may encode hierarchical relations. This paper proposes an extended disparity filter named "disparity-in-differences" that assigns a synthetic relation between two nodes if one depends relatively more on the other where the extent of asymmetric dependence is measured by the disparity between a normalized edge weight difference and an expected edge weight difference. For evaluation, the proposed method is applied to a journal citation network, a U.S. airport network, the Enron email network, and a world trade network. Compared to the disparity filter, the proposed approach better captures hierarchical relations that align well with journal quality ratings, airport hub categories by size, levels of management, and a core-periphery structure of countries, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16598v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hyunuk Kim</dc:creator>
    </item>
    <item>
      <title>Zoo of Centralities: Encyclopedia of Node Metrics in Complex Networks</title>
      <link>https://arxiv.org/abs/2511.05122</link>
      <description>arXiv:2511.05122v3 Announce Type: replace 
Abstract: Centrality is a fundamental concept in network science, providing critical insights into the structure and dynamics of complex systems such as social, transportation, biological and financial networks. Despite its extensive use, there is no universally accepted definition of centrality, leading to the development of a large variety of distinct centrality measures. These measures have grown so numerous that they resemble a 'zoo', each representing a unique approach to capturing node importance within a network. However, the increasing number of metrics being developed has led to several challenges, including issues of discoverability, redundancy, naming conflicts, validation and accessibility. This work aims to address these challenges by providing a comprehensive catalog of over 400 centrality measures, along with clear descriptions and references to original sources. While not exhaustive, this compilation represents the most extensive and systematic effort to date in organizing and presenting centrality measures. We also encourage readers to explore and contribute to the Centrality Zoo website at https://centralityzoo.github.io/, which provides an interactive platform for discovering and comparing centrality measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05122v3</guid>
      <category>cs.SI</category>
      <category>cs.DM</category>
      <category>physics.soc-ph</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey Shvydun</dc:creator>
    </item>
    <item>
      <title>Bipartite Graph Variational Auto-Encoder with Fair Latent Representation to Account for Sampling Bias in Ecological Networks</title>
      <link>https://arxiv.org/abs/2403.02011</link>
      <description>arXiv:2403.02011v3 Announce Type: replace-cross 
Abstract: Citizen science monitoring programs can generate large amounts of valuable data, but are often affected by sampling bias. We focus on a citizen science initiative that records plant-pollinator interactions, with the goal of learning embeddings that summarize the observed interactions while accounting for such bias. In our approach, plant and pollinator species are embedded based on their probability of interaction. These embeddings are derived using an adaptation of variational graph autoencoders for bipartite graphs. To mitigate the influence of sampling bias, we incorporate the Hilbert-Schmidt Independence Criterion (HSIC) to ensure independence from continuous variables related to the sampling process. This allows us to integrate a fairness perspective, commonly explored in the social sciences, into the analysis of ecological data. We validate our method through a simulation study replicating key aspects of the sampling process and demonstrate its applicability and effectiveness using the Spipoll dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02011v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emre Anakok, Pierre Barbillon, Colin Fontaine, Elisa Thebault</dc:creator>
    </item>
    <item>
      <title>Random Abstract Cell Complexes</title>
      <link>https://arxiv.org/abs/2406.01999</link>
      <description>arXiv:2406.01999v2 Announce Type: replace-cross 
Abstract: We define a model for random (abstract) cell complexes (CCs), similiar to the well-known Erd\H{o}s-R\'enyi model for graphs and its extensions for simplicial complexes. To build a random cell complex, we first draw from an Erd\H{o}s-R\'enyi graph, and consecutively augment the graph with cells for each dimension with a specified probability. As the number of possible cells increases combinatorially -- e.g., 2-cells can be represented as cycles, or permutations -- we derive an approximate sampling algorithm for this model limited to two-dimensional abstract cell complexes. As a basis for this algorithm, we first introduce a spanning-tree-based method that samples simple cycles and allows the efficient approximation of various properties, most notably the probability of occurence of a given cycle. This approximation is of independent interest as it enables the approximation of a wide variety of cycle-related graph statistics using importance sampling. We use this to approximate the number of cycles of a given length on a graph, allowing us to calculate the sampling probability to arrive at a desired expected number of sampled 2-cells. The probability approximation also trivially leads to a sampling algorithm for $2$-cells with a desired sampling probability. We provide some initial analysis into the properties of random CCs drawn from this model. We further showcase practical applications for our random CCs as null models, and in the context of (random) liftings of graphs to cell complexes. The cycle sampling, cycle count estimation, and combined cell sampling algorithms are available in the package `py-raccoon` on the Python Packaging Index.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01999v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.SI</category>
      <category>math.AT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Josef Hoppe, Michael T. Schaub</dc:creator>
    </item>
  </channel>
</rss>
