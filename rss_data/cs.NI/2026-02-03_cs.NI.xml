<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Feb 2026 03:02:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Asynchronous MultiAgent Reinforcement Learning for 5G Routing under Side Constraints</title>
      <link>https://arxiv.org/abs/2602.00035</link>
      <description>arXiv:2602.00035v1 Announce Type: new 
Abstract: Networks in the current 5G and beyond systems increasingly carry heterogeneous traffic with diverse quality-of-service constraints, making real-time routing decisions both complex and time-critical. A common approach, such as a heuristic with human intervention or training a single centralized RL policy or synchronizing updates across multiple learners, struggles with scalability and straggler effects. We address this by proposing an asynchronous multi-agent reinforcement learning (AMARL) framework in which independent PPO agents, one per service, plan routes in parallel and commit resource deltas to a shared global resource environment. This coordination by state preserves feasibility across services and enables specialization for service-specific objectives. We evaluate the method on an O-RAN like network simulation using nearly real-time traffic data from the city of Montreal. We compared against a single-agent PPO baseline. AMARL achieves a similar Grade of Service (acceptance rate) (GoS) and end-to-end latency, with reduced training wall-clock time and improved robustness to demand shifts. These results suggest that asynchronous, service-specialized agents provide a scalable and practical approach to distributed routing, with applicability extending beyond the O-RAN domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00035v1</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Racedo, Brigitte Jaumard, Oscar Delgado, Meysam Masoudi</dc:creator>
    </item>
    <item>
      <title>NetWorld: Communication-Based Diffusion World Model for Multi-Agent Reinforcement Learning in Wireless Networks</title>
      <link>https://arxiv.org/abs/2602.00558</link>
      <description>arXiv:2602.00558v1 Announce Type: new 
Abstract: As wireless communication networks grow in scale and complexity, diverse resource allocation tasks become increasingly critical. Multi-Agent Reinforcement Learning (MARL) provides a promising solution for distributed control, yet it often requires costly real-world interactions and lacks generalization across diverse tasks. Meanwhile, recent advances in Diffusion Models (DMs) have demonstrated strong capabilities in modeling complex dynamics and supporting high-fidelity simulation. Motivated by these challenges and opportunities, we propose a Communication-based Diffusion World Model (NetWorld) to enable few-shot generalization across heterogeneous MARL tasks in wireless networks. To improve applicability to large-scale distributed networks, NetWorld adopts the Distributed Training with Decentralized Execution (DTDE) paradigm and is organized into a two-stage framework: (i) pre-training a classifier-guided conditional diffusion world model on multi-task offline datasets, and (ii) performing trajectory planning entirely within this world model to avoid additional online interaction. Cross-task heterogeneity is handled via shared latent processing for observations, two-hot discretization for task-specific actions and rewards, and an inverse dynamics model for action recovery. We further introduce a lightweight Mean Field (MF) communication mechanism to reduce non-stationarity and promote coordinated behaviors with low overhead. Experiments on three representative tasks demonstrate improved performance and sample efficiency over MARL baselines, indicating strong scalability and practical potential for wireless network optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00558v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kechen Meng, Rongpeng Li, Yansha Deng, Zhifeng Zhao, Honggang Zhang</dc:creator>
    </item>
    <item>
      <title>The Syntactic-Semantic Internet:Engineering Infrastructures for Autonomous Systems</title>
      <link>https://arxiv.org/abs/2602.00818</link>
      <description>arXiv:2602.00818v1 Announce Type: new 
Abstract: The Internet has evolved through successive architectural abstractions that enabled unprecedented scale, interoperability, and innovation. Packet-based networking enabled the reliable transport of bits; cloud-native systems enabled the orchestration of distributed computation. Today, the emergence of autonomous, learning-based systems introduces a new architectural challenge: intelligence is increasingly embedded directly into network control, computation, and decision-making, yet the Internet lacks a structural foundation for representing and exchanging meaning. In this paper, we argue that cognition alone: pattern recognition, prediction, and optimization, is insufficient for the next generation of networked systems. As autonomous agents act across safety-critical and socio-technical domains, systems must not only compute and communicate, but also comprehend intent, context, and consequence. We introduce the concept of a Semantic Layer: a new architectural stratum that treats meaning as a first-class construct, enabling interpretive alignment, semantic accountability, and intelligible autonomous behavior. We show that this evolution leads naturally to a Syntactic-Semantic Internet. The syntactic stack continues to transport bits, packets, and workloads with speed and reliability, while a parallel semantic stack transports meaning, grounding, and consequence. We describe the structure of this semantic stack-semantic communication, a semantic substrate, and an emerging Agentic Web, and draw explicit architectural parallels to TCP/IP and the World Wide Web. Finally, we examine current industry efforts, identify critical architectural gaps, and outline the engineering challenges required to make semantic interoperability a global, interoperable infrastructure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00818v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mallik Tatipamula, Xuesong Liu, Yao Sun, Muhammad Ali Imran</dc:creator>
    </item>
    <item>
      <title>LMTE: Putting the "Reasoning" into WAN Traffic Engineering with Language Models</title>
      <link>https://arxiv.org/abs/2602.00941</link>
      <description>arXiv:2602.00941v1 Announce Type: new 
Abstract: The rapid expansion of modern wide-area networks (WANs) has made traffic engineering (TE) increasingly challenging, as traditional solvers struggle to keep pace. Although existing offline ML-driven approaches accelerate TE optimization with deep neural networks (DNNs), they often lack sufficient expressiveness and generalization on unseen traffic patterns or topologies, limiting their practicality. Inspired by the success of large language models (LMs), for the first time, this paper investigates their potential as general-purpose traffic planners. Our contributions are two-fold: (i) Theoretically, we show that pre-trained LMs can simulate the sequential decision processes underlying TE and, crucially, exhibit parallel reasoning capabilities, making them well-suited for the task; (ii) Practically, we present LMTE, a novel LM-driven TE framework that embraces these insights through efficient multimodal alignment and lightweight configuration generation, all while preserving the model's original abilities. Extensive experiments demonstrate that fold matches top-tier performance on five datasets, achieving up to 15\% better maximum link utilization (MLU) and consistently lower performance degradation across diverse scenarios, e.g., less than 5\% with high traffic dynamics and link failures. Moreover, it achieves 10 to 100 times speedups over traditional TE solvers. To aid future works, our codebase is available at https://github.com/Y-debug-sys/LMTE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00941v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinyu Yuan, Yan Qiao, Zonghui Wang, Meng Li, Wenzhi Chen</dc:creator>
    </item>
    <item>
      <title>Resilience Optimization in 6G and Beyond Integrated Satellite-Terrestrial Networks: A Deep Reinforcement Learning Approach</title>
      <link>https://arxiv.org/abs/2602.01102</link>
      <description>arXiv:2602.01102v1 Announce Type: new 
Abstract: Ensuring network resilience in 6G and beyond is essential to maintain service continuity during base station (BS) outages due to failures, disasters, attacks, or energy-saving operations. This paper proposes a novel resilience optimization framework for integrated satellite-terrestrial networks (ISTNs), leveraging low Earth orbit (LEO) satellites to assist users when terrestrial BSs are unavailable. Specifically, we develop a realistic multi-cell model incorporating user association, antenna downtilt adaptation, power control, heterogeneous traffic demands, and dynamic user distribution. The objective is to maximize of the total user rate in the considered area by optimizing the BS's antenna tilt, transmission power, user association to neighboring BS or to a LEO satellite with a minimum number of successfully served user satisfaction constraint, defined by rate and Reference Signal Received Power (RSRP) requirements. To solve the non-convex, NP-hard problem, we design a deep Q-network (DQN)-based algorithm to learn network dynamics to maximize throughput while minimizing LEO satellite usage, thereby limiting reliance on links with longer propagation delays and prolonging satellite operational lifetime. Simulation results confirm that our approach significantly outperforms the benchmark one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01102v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dinh-Hieu Tran, Nguyen Van Huynh, Van Nhan Vo, Madyan Alsenwi, Eva Lagunas, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>Energy-efficient Software-defined 5G/6G Multimedia IoV: PID controller-based approach</title>
      <link>https://arxiv.org/abs/2602.01180</link>
      <description>arXiv:2602.01180v1 Announce Type: new 
Abstract: The rapid proliferation of multimedia applications in smart city environments and the Internet of Vehicles (IoV) presents significant challenges for existing network infrastructures, particularly with the advent of 5G and emerging 6G technologies. Traditional architectures struggle to meet the demands for scalability, adaptability, and energy efficiency required by data-intensive multimedia services. To address these challenges, this study proposes an innovative, energy-efficient framework for multimedia resource management in software-defined 5G/6G IoV networks, leveraging a Proportional-Integral-Derivative (PID) controller. The framework integrates Software-Defined Networking (SDN) and Network Functions Virtualization (NFV) technologies to enable centralized and adaptive control over network resources. By employing a PID controller, it dynamically manages load distribution and temperature, ensuring balanced resource allocation and minimizing energy waste. Comprehensive simulations validate the framework's effectiveness, demonstrating significant improvements in load balancing, CPU utilization, and energy consumption compared to traditional methods. For instance, under heavy traffic conditions, the proposed framework maintained resource efficiency, reducing power consumption by up to 30% and achieving nearly equal load distribution across all network components. Additionally, the controller exhibited exceptional scalability, effectively responding to over 98% of vehicle requests even in scenarios of extreme traffic demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01180v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TVT.2025.3649936</arxiv:DOI>
      <dc:creator>Ahmadreza Montazerolghaem</dc:creator>
    </item>
    <item>
      <title>AOASS: Adaptive Obstacle-Aware Square Spiral Framework for Single-mobile Anchor-Based WSN Localization</title>
      <link>https://arxiv.org/abs/2602.01290</link>
      <description>arXiv:2602.01290v1 Announce Type: new 
Abstract: Accurate and energy efficient localization remains a key challenge in Wireless Sensor Networks (WSNs), particularly when obstacles affect signal propagation. This study introduces AOASS (Adaptive Obstacle Aware Square Spiral), a new single mobile anchor framework that combines an optimized square spiral movement pattern with adaptive obstacle detection. The mobile anchor can sense and bypass obstacles while maintaining high localization accuracy and full network coverage, ensuring that each node receives at least three noncollinear beacon signals for reliable position estimation. Localization accuracy is further improved using the OLSTM DV Hop model, which integrates a Long Short Term Memory (LSTM) network with the traditional DV Hop algorithm to estimate hop distances better and reduce multi hop errors. The anchor trajectory is managed by a TD3 LSTM reinforcement learning agent, supported by a Kalman based prediction layer and a fuzzy logic ORCA safety module for smooth and collision free navigation. Simulation experiments across different obstacle densities show that AOASS consistently achieves higher localization accuracy, better energy efficiency, and more optimized trajectories than existing approaches. These results demonstrate the framework scalability and potential for real world WSN applications, offering an intelligent and adaptable solution for data driven IoT systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01290v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdelhady Naguib</dc:creator>
    </item>
    <item>
      <title>Federated Learning Meets Random Access: Energy-Efficient Uplink Resource Allocation</title>
      <link>https://arxiv.org/abs/2602.01913</link>
      <description>arXiv:2602.01913v1 Announce Type: new 
Abstract: Artificial intelligence-generated traffic is changing the shape of wireless networks. Specifically, as the amount of data generated to train machine learning models is massive, network resources must be carefully allocated to continue supporting standard applications. In this paper, we tackle the problem of allocating radio resources for two sets of concurrent devices communicating in uplink with a gateway over the same bandwidth. A set of devices performs federated learning (FL), and accesses the medium in FDMA, uploading periodically large models. The other set is throughput-oriented and accesses the medium via random access (RA), either with ALOHA or slotted-ALOHA protocols. We derive close-to-optimal solutions to the non-convex problem of minimizing the system energy consumption subject to FL latency and RA throughput constraints. Our solutions show that ALOHA can sustain high FL efficiency, yielding up to 48% lower consumption when the system is dominated by FL traffic. On the other hand, slotted-ALOHA becomes more efficient when RA traffic dominates, yielding 6% lower consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01913v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giovanni Perin, Eunjeong Jeong, Nikolaos Pappas</dc:creator>
    </item>
    <item>
      <title>TriCloudEdge: A multi-layer Cloud Continuum</title>
      <link>https://arxiv.org/abs/2602.02121</link>
      <description>arXiv:2602.02121v1 Announce Type: new 
Abstract: TriCloudEdge is a scalable three-tier cloud continuum that integrates far-edge devices, intermediate edge nodes, and central cloud services, working in parallel as a unified solution. At the far edge, ultra-low-cost microcontrollers can handle lightweight AI tasks, while intermediate edge devices provide local intelligence, and the cloud tier offers large-scale analytics, federated learning, model adaptation, and global identity management. The proposed architecture enables multi-protocols and technologies (WebSocket, MQTT, HTTP) compared to a versatile protocol (Zenoh) to transfer diverse bidirectional data across the tiers, offering a balance between computational challenges and latency requirements. Comparative implementations between these two architectures demonstrate the trade-offs between resource utilization and communication efficiency. The results show that TriCloudEdge can distribute computational challenges to address latency and privacy concerns. The work also presents tests of AI model adaptation on the far edge and the computational effort challenges under the prism of parallelism. This work offers a perspective on the practical continuum challenges of implementation aligned with recent research advances addressing challenges across the different cloud levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02121v1</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Violettas, Lefteris Mamatas</dc:creator>
    </item>
    <item>
      <title>Evaluating Acoustic Data Transmission Schemes for Ad-Hoc Communication Between Nearby Smart Devices</title>
      <link>https://arxiv.org/abs/2602.02249</link>
      <description>arXiv:2602.02249v1 Announce Type: new 
Abstract: Acoustic data transmission offers a compelling alternative to Bluetooth and NFC by leveraging the ubiquitous speakers and microphones in smartphones and IoT devices. However, most research in this field relies on simulations or limited on-device testing, which makes the real-world reliability of proposed schemes difficult to assess. We systematically reviewed 31 acoustic communication studies for commodity devices and found that none provided accessible source code. After contacting authors and re-implementing three promising schemes, we assembled a testbed of eight representative acoustic communication systems. Using over 11000 smartphone transmissions in both realistic indoor environments and an anechoic chamber, we provide a systematic and repeatable methodology for evaluating the reliability and generalizability of these schemes under real-world conditions. Our results show that many existing schemes face challenges in practical usage, largely due to severe multipath propagation indoors and varying audio characteristics across device models. To support future research and foster more robust evaluations, we release our re-implementations alongside the first comprehensive dataset of real-world acoustic transmissions. Overall, our findings highlight the importance of rigorous on-device testing and underscore the need for robust design strategies to bridge the gap between simulation results and reliable IoT deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02249v1</guid>
      <category>cs.NI</category>
      <category>cs.SD</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3779439</arxiv:DOI>
      <arxiv:journal_reference>ACM Trans. Internet Things 7, 1, Article 8 (February 2026), 32 pages</arxiv:journal_reference>
      <dc:creator>Florentin Putz, Philipp Fortmann, Jan Frank, Christoph Haugwitz, Mario Kupnik, Matthias Hollick</dc:creator>
    </item>
    <item>
      <title>Superstable Geometry in Triadic Percolation</title>
      <link>https://arxiv.org/abs/2602.01374</link>
      <description>arXiv:2602.01374v1 Announce Type: cross 
Abstract: Triadic percolation turns bond percolation into a dynamical problem governed by an effective one-dimensional unimodal map. We show that the geometry of superstable cycles provides a direct, map-agnostic probe of local nonlinearity: specifically, the distance from the map's maximum to a distinguished next-to-maximum point on the attracting $2^n$-cycle (which coincides with a preimage of the maximum at $2^n$-superstability) scales as $|\Delta p|^{\gamma}$ with $\gamma = 1/z$, where $z$ is the nonflat order of the maximum. This prediction is verified across canonical unimodal families and heterogeneous triadic ensembles, with Lyapunov spectra corroborating the one-dimensional reduction. A derivative condition on the activation kernel fixes the local nonlinearity order $z$ (and thus, under standard unimodal-map hypotheses, the associated $z$-logistic universality class) and gives conditions under which $z&gt;2$ can be realized. The diagnostic operates directly on orbit data under standard regularity assumptions, providing a practical tool to classify universality in higher-order networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01374v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.soft</category>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fatemeh Aghaei, Abbas Ali Saberi, Holger Kantz, Juergen Kurths</dc:creator>
    </item>
    <item>
      <title>&lt;SOG_k&gt;: One LLM Token for Explicit Graph Structural Understanding</title>
      <link>https://arxiv.org/abs/2602.01771</link>
      <description>arXiv:2602.01771v1 Announce Type: cross 
Abstract: Large language models show great potential in unstructured data understanding, but still face significant challenges with graphs due to their structural hallucination. Existing approaches mainly either verbalize graphs into natural language, which leads to excessive token consumption and scattered attention, or transform graphs into trainable continuous embeddings (i.e., soft prompt), but exhibit severe misalignment with original text tokens. To solve this problem, we propose to incorporate one special token &lt;SOG_k&gt; to fully represent the Structure Of Graph within a unified token space, facilitating explicit topology input and structural information sharing. Specifically, we propose a topology-aware structural tokenizer that maps each graph topology into a highly selective single token. Afterwards, we construct a set of hybrid structure Question-Answering corpora to align new structural tokens with existing text tokens. With this approach, &lt;SOG_k&gt; empowers LLMs to understand, generate, and reason in a concise and accurate manner. Extensive experiments on five graph-level benchmarks demonstrate the superiority of our method, achieving a performance improvement of 9.9% to 41.4% compared to the baselines while exhibiting interpretability and consistency. Furthermore, our method provides a flexible extension to node-level tasks, enabling both global and local structural understanding. The codebase is publicly available at https://github.com/Jingyao-Wu/SOG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01771v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jingyao Wu, Bin Lu, Zijun Di, Xiaoying Gan, Meng Jin, Luoyi Fu, Xinbing Wang, Chenghu Zhou</dc:creator>
    </item>
    <item>
      <title>Preemptive Scheduling for Age of Job Minimization in Task-Specific Machine Networks</title>
      <link>https://arxiv.org/abs/2602.02435</link>
      <description>arXiv:2602.02435v1 Announce Type: cross 
Abstract: We consider a time-slotted job-assignment system consisting of a central server, $N$ task-specific networks of machines, and multiple users. Each network specializes in executing a distinct type of task. Users stochastically generate jobs of various types and forward them to the central server, which routes each job to the appropriate network of machines. Due to resource constraints, the server cannot serve all users' jobs simultaneously, which motivates the design of scheduling policies with possible preemption. To evaluate scheduling performance, we introduce a novel timeliness metric, the age of job, inspired by the well-known metric, the age of information. We study the problem of minimizing the long-term weighted average age of job. We first propose a max-weight policy by minimizing the one-step Lyapunov drift and then derive the Whittle index (WI) policy when the job completion times of the networks of machines follow geometric distributions. For general job completion time distributions, we introduce a Whittle index with max-weight fallback (WIMWF) policy. We also investigate the Net-gain maximization (NGM) policy. Numerically, we show that the proposed WIMWF policy achieves the best performance in the general job completion time setting. We also observe a scaling trend: two different max-weight policies can outperform the NGM policy in small systems, whereas the NGM policy improves as we scale the system size and becomes asymptotically better than max-weight policies. For geometric service times, the WI policy yields the lowest age across all considered system sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02435v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Subhankar Banerjee, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Conflict-Aware Client Selection for Multi-Server Federated Learning</title>
      <link>https://arxiv.org/abs/2602.02458</link>
      <description>arXiv:2602.02458v1 Announce Type: cross 
Abstract: Federated learning (FL) has emerged as a promising distributed machine learning (ML) that enables collaborative model training across clients without exposing raw data, thereby preserving user privacy and reducing communication costs. Despite these benefits, traditional single-server FL suffers from high communication latency due to the aggregation of models from a large number of clients. While multi-server FL distributes workloads across edge servers, overlapping client coverage and uncoordinated selection often lead to resource contention, causing bandwidth conflicts and training failures. To address these limitations, we propose a decentralized reinforcement learning with conflict risk prediction, named RL CRP, to optimize client selection in multi-server FL systems. Specifically, each server estimates the likelihood of client selection conflicts using a categorical hidden Markov model based on its sparse historical client selection sequence. Then, a fairness-aware reward mechanism is incorporated to promote long-term client participation for minimizing training latency and resource contention. Extensive experiments demonstrate that the proposed RL-CRP framework effectively reduces inter-server conflicts and significantly improves training efficiency in terms of convergence speed and communication cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02458v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingwei Hong, Zheng Lin, Zehang Lin, Lin Li, Miao Yang, Xia Du, Zihan Fang, Zhaolu Kang, Dianxin Luan, Shunzhi Zhu</dc:creator>
    </item>
    <item>
      <title>Graph-Based Floor Separation Using Node Embeddings and Clustering of WiFi Trajectories</title>
      <link>https://arxiv.org/abs/2505.08088</link>
      <description>arXiv:2505.08088v3 Announce Type: replace 
Abstract: Vertical localization, particularly floor separation, remains a major challenge in indoor positioning systems operating in GPS-denied multistory environments. This paper proposes a fully data-driven, graph-based framework for blind floor separation using only Wi-Fi fingerprint trajectories, without requiring prior building information or knowledge of the number of floors.
  In the proposed method, Wi-Fi fingerprints are represented as nodes in a trajectory graph, where edges capture both signal similarity and sequential movement context. Structural node embeddings are learned via Node2Vec, and floor-level partitions are obtained using K-Means clustering with automatic cluster number estimation.
  The framework is evaluated on multiple publicly available datasets, including a newly released Huawei University Challenge 2021 dataset and a restructured version of the UJIIndoorLoc benchmark. Experimental results demonstrate that the proposed approach effectively captures the intrinsic vertical structure of multistory buildings using only received signal strength data.
  By eliminating dependence on building-specific metadata, the proposed method provides a scalable and practical solution for vertical localization in indoor environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08088v3</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rabia Yasa Kostas, Kahraman Kostas</dc:creator>
    </item>
    <item>
      <title>Hybrid Wi-Fi/PDR Indoor Localization with Fingerprint Matching</title>
      <link>https://arxiv.org/abs/2505.08258</link>
      <description>arXiv:2505.08258v2 Announce Type: replace 
Abstract: Indoor position technology has become one of the research highlights in the Internet of Things (IoT), but there is still a lack of universal, low-cost, and high-precision solutions. This paper conducts research on indoor position technology based on location fingerprints and proposes a practical hybrid indoor positioning system. In this experiment, the location fingerprint database is established by using RSS signal in the offline stage, the location algorithm is improved and innovated in the online stage. The weighted k-nearest neighbor algorithm is used for location fingerprint matching and pedestrian dead reckoning technology is used for trajectory tracking. This paper designs and implements an indoor position system that performs the functions of data collection, positioning, and position tracking. Through the test, it is found that it can meet the requirements of indoor positioning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08258v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunyi Zhang, Zongwei Li, Xiaoqi Li</dc:creator>
    </item>
    <item>
      <title>Exploiting Data Significance in Remote Estimation of Discrete-State Markov Sources</title>
      <link>https://arxiv.org/abs/2406.18270</link>
      <description>arXiv:2406.18270v2 Announce Type: replace-cross 
Abstract: We consider semantics-aware remote estimation of a discrete-state Markov source with both normal (low-priority) and alarm (high-priority) states. Erroneously announcing a normal state at the destination when the source is actually in an alarm state (i.e., missed alarm) incurs a significantly higher cost than falsely announcing an alarm state when the source is in a normal state (i.e., false alarm). Moreover, consecutive estimation errors may cause significant lasting impacts, such as maintenance costs and misoperations. Motivated by this, we introduce two new metrics, the Age of Missed Alarm (AoMA) and the Age of False Alarm (AoFA), to capture the lasting impacts incurred by different estimation errors. Notably, these two age processes evolve interdependently and distinguish between different error types. Our goal is to design a transmission policy that achieves an optimized trade-off between lasting impact and communication cost. The problem is formulated as a countably infinite-state Markov decision process (MDP) with an unbounded cost function. We show the existence of a simple switching policy with distinct thresholds for each age process and derive closed-form expressions for its performance. For symmetric and non-prioritized sources, we show that the optimal policy reduces to a threshold policy with identical thresholds. For numerical tractability, we propose a finite-state approximate MDP and prove that it converges exponentially fast to the original MDP in the truncation size. Finally, we develop an efficient search algorithm to compute the optimal switching policy and validate our theoretical findings with numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18270v2</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiping Luo, Nikolaos Pappas</dc:creator>
    </item>
    <item>
      <title>AgentRAN: An Agentic AI Architecture for Autonomous Control of Open 6G Networks</title>
      <link>https://arxiv.org/abs/2508.17778</link>
      <description>arXiv:2508.17778v2 Announce Type: replace-cross 
Abstract: Despite the programmable architecture of Open RAN, today's deployments still rely heavily on static control and manual operations. To move beyond this limitation, we introduce AgentRAN, an AI-native, Open RAN-aligned agentic framework that generates and orchestrates a fabric of distributed AI agents based on natural language intents. Unlike traditional approaches that require explicit programming, AgentRAN's LLM-powered agents interpret natural language intents, negotiate strategies through structured conversations, and orchestrate control loops across the network. AgentRAN instantiates a self-organizing hierarchy of agents that decompose complex intents across time scales (from sub-millisecond to minutes), spatial domains (cell to network-wide), and protocol layers (PHY/MAC to RRC). A central innovation is the AI-RAN Factory, which continuously generates improved agents and algorithms from operational data, transforming the network into a system that evolves its own intelligence. We validate AgentRAN through live 5G experiments, demonstrating dynamic adaptation to changing operator intents across power control and scheduling. Key benefits include transparent decision-making (all agent reasoning is auditable), bootstrapped intelligence (no initial training data required), and continuous self-improvement via the AI-RAN Factory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17778v2</guid>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maxime Elkael, Salvatore D'Oro, Leonardo Bonati, Michele Polese, Yunseong Lee, Koichiro Furueda, Tommaso Melodia</dc:creator>
    </item>
    <item>
      <title>When Routers, Switches and Interconnects Compute: A processing-in-interconnect Paradigm for Scalable Neuromorphic AI</title>
      <link>https://arxiv.org/abs/2508.19548</link>
      <description>arXiv:2508.19548v3 Announce Type: replace-cross 
Abstract: Routing, switching, and the interconnect fabric are essential components in implementing large-scale neuromorphic computing architectures. While this fabric plays only a supporting role in the process of computing, for large AI workloads, this fabric ultimately determines the overall system's performance, such as energy consumption and speed. In this paper, we offer a potential solution to address this bottleneck by addressing two fundamental questions: (a) What computing paradigms are inherent in existing routing, switching, and interconnect systems, and how can they be used to implement a Processing-in-Interconnect ($\pi^2$) computing paradigm? and (b) How to train $\pi^2$ network on standard AI benchmarks? To address the first question, we demonstrate that all operations required for typical AI workloads can be mapped onto delays, causality, time-outs, packet drops, and broadcast operations, all of which are already implemented in current packet-switching and packet-routing hardware. {We then show that existing buffering and traffic-shaping embedded algorithms can be minimally modified to implement $\pi^2$ neuron models and synaptic operations. To address the second question, we show how a knowledge distillation framework can be used to train and cross-map well-established neural network topologies onto $\pi^2$ architectures without any degradation in the generalization performance. Our analysis show that the effective energy utilization of a $\pi^2$ network is significantly higher than that of other neuromorphic computing platforms; as a result, we believe that the $\pi^2$ paradigm offers a more scalable architectural path toward achieving brain-scale AI inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19548v3</guid>
      <category>cs.NE</category>
      <category>cs.AR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Madhuvanthi Srivatsav, Chiranjib Bhattacharyya, Shantanu Chakrabartty, Chetan Singh Thakur</dc:creator>
    </item>
    <item>
      <title>AVERY: Adaptive VLM Split Computing through Embodied Self-Awareness for Efficient Disaster Response Systems</title>
      <link>https://arxiv.org/abs/2511.18151</link>
      <description>arXiv:2511.18151v2 Announce Type: replace-cross 
Abstract: Unmanned Aerial Vehicles (UAVs) in disaster response require complex, queryable intelligence that on-board CNNs cannot provide. While Vision-Language Models (VLMs) offer this semantic reasoning, their high resource demands make on-device deployment infeasible, and naive cloud offloading fails under the low-bandwidth networks common in disaster zones. We present AVERY, a framework that enables VLM deployment through adaptive split computing. We advance the split computing paradigm beyond traditional depth-wise partitioning by introducing a functional, cognitive-inspired dual-stream split that separates the VLM into a high-frequency, low-resolution "context stream" for real-time awareness and a low-frequency, high-fidelity "insight stream" for deep analysis. A lightweight, self-aware on-board controller manages this architecture, monitoring network conditions and operator intent to dynamically select from pre-trained compression models, navigating the fundamental accuracy-throughput trade-off. Evaluated using the VLM LISA-7B across an edge-cloud scenario under fluctuating network conditions, AVERY consistently outperforms static configurations, achieving 11.2% higher accuracy than raw image compression and 93.98% lower energy consumption compared to full-edge execution, thereby enhancing mission efficiency and enabling real-time, queryable intelligence on resource-constrained platforms in dynamic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18151v2</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajat Bhattacharjya, Sing-Yao Wu, Hyunwoo Oh, Chaewon Nam, Suyeon Koo, Mohsen Imani, Elaheh Bozorgzadeh, Nikil Dutt</dc:creator>
    </item>
    <item>
      <title>Reexamining Paradigms of End-to-End Data Movement</title>
      <link>https://arxiv.org/abs/2512.15028</link>
      <description>arXiv:2512.15028v4 Announce Type: replace-cross 
Abstract: The pursuit of high-performance data transfer often focuses on raw network bandwidth, where international links of 100 Gbps or higher are frequently considered the primary enabler. While necessary, this network-centric view is incomplete. It equates provisioned link speeds with practical, sustainable data movement capabilities. It is a common observation that lower-than-desired data rates manifest even on 10 Gbps links and commodity hardware, with higher-speed networks only amplifying their visibility. We investigate six paradigms -- from network latency and TCP congestion control to host-side factors such as CPU performance and virtualization -- that critically impact data movement workflows. These paradigms represent widely accepted engineering assumptions that inform system design, procurement decisions, and operational practices in production data movement environments. We introduce the Drainage Basin Pattern conceptual model for reasoning about end-to-end data flow constraints across heterogeneous hardware and software components at varying desired data rates to address the fidelity gap between raw bandwidth and application-level throughput. Our findings are validated through rigorous production-scale deployments, from 10 Gbps links to U.S. DOE ESnet technical evaluations and transcontinental production trials over 100 Gbps operational links. The results demonstrate that principal bottlenecks often reside outside the network core, and that a holistic hardware-software co-design enables consistent, predictable performance for moving data at scale and speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.15028v4</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.OS</category>
      <category>cs.PF</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chin Fang, Timothy Stitt, Michael J. McManus, Toshio Moriya</dc:creator>
    </item>
  </channel>
</rss>
