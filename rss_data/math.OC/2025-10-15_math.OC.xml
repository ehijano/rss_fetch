<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Oct 2025 01:45:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Mean-Field Games with Constraints</title>
      <link>https://arxiv.org/abs/2510.11843</link>
      <description>arXiv:2510.11843v1 Announce Type: new 
Abstract: This paper introduces a framework of Constrained Mean-Field Games (CMFGs), where each agent solves a constrained Markov decision process (CMDP). This formulation captures scenarios in which agents' strategies are subject to feasibility, safety, or regulatory restrictions, thereby extending the scope of classical mean field game (MFG) models. We first establish the existence of CMFG equilibria under a strict feasibility assumption, and we further show uniqueness under a classical monotonicity condition. To compute equilibria, we develop Constrained Mean-Field Occupation Measure Optimization (CMFOMO), an optimization-based scheme that parameterizes occupation measures and shows that finding CMFG equilibria is equivalent to solving a single optimization problem with convex constraints and bounded variables. CMFOMO does not rely on uniqueness of the equilibria and can approximate all equilibria with arbitrary accuracy. We further prove that CMFG equilibria induce $O(1 / \sqrt{N})$-Nash equilibria in the associated constrained $N$-player games, thereby extending the classical justification of MFGs as approximations for large but finite systems. Numerical experiments on a modified Susceptible-Infected-Susceptible (SIS) epidemic model with various constraints illustrate the effectiveness and flexibility of the framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11843v1</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <category>math.PR</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Anran Hu, Zijiu Lyu</dc:creator>
    </item>
    <item>
      <title>Linear Convergence of a Unified Primal--Dual Algorithm for Convex--Concave Saddle Point Problems with Quadratic Growth</title>
      <link>https://arxiv.org/abs/2510.11990</link>
      <description>arXiv:2510.11990v1 Announce Type: new 
Abstract: In this paper, we study saddle point (SP) problems, focusing on convex-concave optimization involving functions that satisfy either two-sided quadratic functional growth (QFG) or two-sided quadratic gradient growth (QGG)--novel conditions tailored specifically for SP problems as extensions of quadratic growth conditions in minimization. These conditions relax the traditional requirement of strong convexity-strong concavity, thereby encompassing a broader class of problems. We propose a generalized accelerated primal-dual (GAPD) algorithm to solve SP problems with non-bilinear objective functions, unifying and extending existing methods. We prove that our method achieves a linear convergence rate under these relaxed conditions. Additionally, we provide examples of structured SP problems that satisfy either two-sided QFG or QGG, demonstrating the practical applicability and relevance of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11990v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cody Melcher, Afrooz Jalilzadeh, Erfan Yazdandoost Hamedani</dc:creator>
    </item>
    <item>
      <title>Distributed Stochastic Model Predictive Control with Temporal Aggregation for the Joint Dispatch of Cascaded Hydropower and Renewables</title>
      <link>https://arxiv.org/abs/2510.11998</link>
      <description>arXiv:2510.11998v1 Announce Type: new 
Abstract: This paper addresses the real-time energy dispatch of a hybrid system comprising cascaded hydropower plants, wind, and solar units, jointly participating in the day-ahead energy market under inflow, renewable generation, and price uncertainties. Traditional scenario-based stochastic model predictive control (MPC) faces severe computational bottlenecks due to the complexity arising from the temporal, asset, and scenario dimensions of this control problem. To address this, we propose a novel control scheme that combines time series aggregation (TSA) with distributed stochastic MPC. TSA is applied exclusively to the tail of the MPC prediction horizon to preserve real-time accuracy, while distributed optimization enables decomposition across assets and scenarios. Notably, the controller offers a formal performance guarantee through theoretically validated bounds on its approximation error. Simulations on a real-world case study confirm the controller's effectiveness, achieving a 42% reduction in execution time compared to centralized full-scale MPC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11998v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Santosuosso, Sonja Wogrin</dc:creator>
    </item>
    <item>
      <title>Semi-infinite Nonconvex Constrained Min-Max Optimization</title>
      <link>https://arxiv.org/abs/2510.12007</link>
      <description>arXiv:2510.12007v1 Announce Type: new 
Abstract: Semi-Infinite Programming (SIP) has emerged as a powerful framework for modeling problems with infinite constraints, however, its theoretical development in the context of nonconvex and large-scale optimization remains limited. In this paper, we investigate a class of nonconvex min-max optimization problems with nonconvex infinite constraints, motivated by applications such as adversarial robustness and safety-constrained learning. We propose a novel inexact dynamic barrier primal-dual algorithm and establish its convergence properties. Specifically, under the assumption that the squared infeasibility residual function satisfies the Lojasiewicz inequality with exponent $\theta \in (0,1)$, we prove that the proposed method achieves $\mathcal{O}(\epsilon^{-3})$, $\mathcal{O}(\epsilon^{-6\theta})$, and $\mathcal{O}(\epsilon^{-3\theta/(1-\theta)})$ iteration complexities to achieve an $\epsilon$-approximate stationarity, infeasibility, and complementarity slackness, respectively. Numerical experiments on robust multitask learning with task priority further illustrate the practical effectiveness of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12007v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cody Melcher, Zeinab Alizadeh, Lindsey Hiett, Afrooz Jalilzadeh, Erfan Yazdandoost Hamedani</dc:creator>
    </item>
    <item>
      <title>New Classes of Non-monotone Variational Inequality Problems Solvable via Proximal Gradient on Smooth Gap Functions</title>
      <link>https://arxiv.org/abs/2510.12105</link>
      <description>arXiv:2510.12105v1 Announce Type: new 
Abstract: In this paper, we study the local linear convergence behavior of proximal-gradient (PG) descent algorithm on a parameterized gap-function reformulation of a smooth but non-monotone variational inequality problem (VIP). The aim is to solve the non-monotone VI problem without assuming the existence of a Minty-type solution. We first introduce and study various error bound conditions for the gap functions in relation to the VI model. In particular, we show that uniform type error bounds imply level-set type error bounds for composite optimization, revealing a key hierarchical structure there. As a result, local linear convergence is established under some easy-verifiable conditions induced by level-set error bounds, the gradient Lipschitz condition and a suitable initialization condition. Furthermore, for non-monotone affine VIs we present a homotopy continuation scheme that achieves global convergence by dynamically tracing a solution path. Our numerical experiments show the efficacy of the proposed approach, leading to the solutions of a broad class of non-monotone VI problems resulting from the need to compute Nash equilibria, traffic controls, and the GAN models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12105v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Zhao, Daoli Zhu, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>Learning Mean-Field Games through Mean-Field Actor-Critic Flow</title>
      <link>https://arxiv.org/abs/2510.12180</link>
      <description>arXiv:2510.12180v1 Announce Type: new 
Abstract: We propose the Mean-Field Actor-Critic (MFAC) flow, a continuous-time learning dynamics for solving mean-field games (MFGs), combining techniques from reinforcement learning and optimal transport. The MFAC framework jointly evolves the control (actor), value function (critic), and distribution components through coupled gradient-based updates governed by partial differential equations (PDEs). A central innovation is the Optimal Transport Geodesic Picard (OTGP) flow, which drives the distribution toward equilibrium along Wasserstein-2 geodesics. We conduct a rigorous convergence analysis using Lyapunov functionals and establish global exponential convergence of the MFAC flow under a suitable timescale. Our results highlight the algorithmic interplay among actor, critic, and distribution components. Numerical experiments illustrate the theoretical findings and demonstrate the effectiveness of the MFAC framework in computing MFG equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12180v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mo Zhou, Haosheng Zhou, Ruimeng Hu</dc:creator>
    </item>
    <item>
      <title>A Gradient Guided Diffusion Framework for Chance Constrained Programming</title>
      <link>https://arxiv.org/abs/2510.12238</link>
      <description>arXiv:2510.12238v1 Announce Type: new 
Abstract: Chance constrained programming (CCP) is a powerful framework for addressing optimization problems under uncertainty. In this paper, we introduce a novel Gradient-Guided Diffusion-based Optimization framework, termed GGDOpt, which tackles CCP through three key innovations. First, GGDOpt accommodates a broad class of CCP problems without requiring the knowledge of the exact distribution of uncertainty-relying solely on a set of samples. Second, to address the nonconvexity of the chance constraints, it reformulates the CCP as a sampling problem over the product of two distributions: an unknown data distribution supported on a nonconvex set and a Boltzmann distribution defined by the objective function, which fully leverages both first- and second-order gradient information. Third, GGDOpt has theoretical convergence guarantees and provides practical error bounds under mild assumptions. By progressively injecting noise during the forward diffusion process to convexify the nonconvex feasible region, GGDOpt enables guided reverse sampling to generate asymptotically optimal solutions. Experimental results on synthetic datasets and a waveform design task in wireless communications demonstrate that GGDOpt outperforms existing methods in both solution quality and stability with nearly 80% overhead reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12238v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boyang Zhang, Zhiguo Wang, Ya-Feng Liu</dc:creator>
    </item>
    <item>
      <title>Bilateral facial reduction: qualification-free subdifferential calculus and exact duality in convex analysis</title>
      <link>https://arxiv.org/abs/2510.12244</link>
      <description>arXiv:2510.12244v1 Announce Type: new 
Abstract: This paper introduces a geometric framework to extend convex analysis results beyond standard qualification conditions such as intersecting relative interiors of domains. We define the joint facial subspace $T$ as the span of the face of $C - D$ generated by $0$, with its affine translation $T_a$ containing $C \cap D$. The intersections $C \cap T_a$ and $D \cap T_a$ are faces of the original sets, establishing $T_a$ as a bilateral facial reduction with parallels to Borwein-Wolkowicz facial reduction in conic programming. When reducing the domains of two convex functions to their joint facial subspace $T_a$, their relative interiors then always intersect, enabling unqualified application of classical theorems via localization. Key generalizations include subdifferential additivity, normal cones of intersections, a subdifferential chain rule, attained infimal convolution for $(f+g)^*,$ and an exact Fenchel-Rockafellar dual. We characterize $T$ via generated faces and computationally through an iterative process converging in at most $n$ steps in $\mathbb{R}^n$. Proofs are self-contained and introduce novel concepts like facial subspaces and nested normals to describe convex boundaries and the lattice of faces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12244v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew S. Scott</dc:creator>
    </item>
    <item>
      <title>Adaptive Nonlinear Model Predictive Control of Monoclonal Antibody Glycosylation in CHO Cell Culture</title>
      <link>https://arxiv.org/abs/2510.12333</link>
      <description>arXiv:2510.12333v1 Announce Type: new 
Abstract: N-glycosylation is a critical quality attribute of monoclonal antibodies (mAbs), the dominant class of biopharmaceuticals. Controlling glycosylation remains difficult due to intrinsic pathway complexity, limited online measurements, and a lack of tailored control strategies. This work applies an adaptive nonlinear model predictive control (ANMPC) framework to a fed-batch mAb production process, using a multiscale model that links extracellular conditions to intracellular Golgi reactions to predict glycan profiles. Model parameters are updated online as new measurements arrive, after which a shrinking-horizon optimization computes the control inputs; only the first control move is implemented each cycle. Case studies show that, with a minimal day-1 galactose excitation, ANMPC mitigates model-plant mismatch and achieves up to 130% and 96% higher performance than open-loop optimization and state NMPC, respectively. Under more realistic conditions (partial measurement availability and longer preparation time), ANMPC maintains comparable performance, indicating robustness to practical limitations. Overall, the results demonstrate that ANMPC can actively shape glycan distributions in silico and offers a viable path toward closed-loop control of mAb glycosylation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12333v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yingjie Ma, Jing Guo, Alexis B. Dubs, Krystian K. Ganko, Richard D. Braatz</dc:creator>
    </item>
    <item>
      <title>Carleman Estimates and Controllability of Forward Stochastic Parabolic Equations with General Dynamic Boundary Conditions</title>
      <link>https://arxiv.org/abs/2510.12345</link>
      <description>arXiv:2510.12345v1 Announce Type: new 
Abstract: We derive a new Carleman estimate for a general backward stochastic parabolic equation with dynamic boundary conditions, incorporating weak divergence source terms in both the bulk and surface equations. This estimate is obtained through two main steps: first, by refining a known Carleman estimate for backward stochastic parabolic equations to explicitly account for the dependence of the parameters on the final control time \(T\); second, by applying a duality technique to address weak divergence source terms. As an application, we prove the null and approximate controllability of forward stochastic parabolic equations with dynamic boundary conditions, which involve both reaction and convection terms with bounded adapted coefficients, as well as general second-order parabolic operators. Additionally, we provide an explicit estimate for the null-controllability cost in terms of the final control time \(T\) and the coefficients of the equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12345v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Said Boulite, Abdellatif Elgrou, Lahcen Maniar, Abdelaziz Rhandi</dc:creator>
    </item>
    <item>
      <title>Heuristic Bundle Upper Bound Based Polyhedral Bundle Method for Semidefinite Programming</title>
      <link>https://arxiv.org/abs/2510.12374</link>
      <description>arXiv:2510.12374v1 Announce Type: new 
Abstract: Semidefinite programming (SDP) is a fundamental class of convex optimization problems with diverse applications in mathematics, engineering, machine learning, and related disciplines. This paper investigates the application of the polyhedral bundle method to standard SDPs. The basic idea of this method is to approximate semidefinite constraints using linear constraints, and thereby transform the SDP problem into a series of quadratic programming subproblems. However, the number of linear constraints often increases continuously during the iteration process, leading to a significant reduction in the solution efficiency. Therefore, based on the idea of limiting the upper bound on the number of bundles, we heuristically select the upper bound through numerical experiments according to the rank of the primal optimal solution and propose a modified subproblem. In this way, under the premise of ensuring the approximation ability of the lower approximation model, we minimize the number of bundles as much as possible to improve the solution efficiency of the subproblems. The algorithm performs well in both Max-Cut problems and random SDP problems. In particular, for random sparse SDP problems with low condition numbers, under the condition of a relative accuracy of \(10^{-4}\), it shows a significant improvement compared with algorithms such as interior-point methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12374v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zilong Cui, Ran Gu</dc:creator>
    </item>
    <item>
      <title>Tensor Completion via Monotone Inclusion: Generalized Low-Rank Priors Meet Deep Denoisers</title>
      <link>https://arxiv.org/abs/2510.12425</link>
      <description>arXiv:2510.12425v1 Announce Type: new 
Abstract: Missing entries in multi dimensional data pose significant challenges for downstream analysis across diverse real world applications. These data are naturally modeled as tensors, and recent completion methods integrating global low rank priors with plug and play denoisers have demonstrated strong empirical performance. However, these approaches often rely on empirical convergence alone or unrealistic assumptions, such as deep denoisers acting as proximal operators of implicit regularizers, which generally does not hold. To address these limitations, we propose a novel tensor completion framework grounded in the monotone inclusion paradigm, which unifies generalized low rank priors with deep pseudo contractive denoisers and extends beyond traditional convex optimization. Building on the Davis Yin splitting scheme, we develop the GTCTV DPC algorithm and rigorously establish its global convergence. Extensive experiments demonstrate that GTCTV DPC consistently outperforms existing methods in both quantitative metrics and visual quality, particularly at low sampling rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12425v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peng Chen, Deliang Wei, Jiale Yao, Fang Li</dc:creator>
    </item>
    <item>
      <title>The value of storage in electricity distribution: The role of markets</title>
      <link>https://arxiv.org/abs/2510.12435</link>
      <description>arXiv:2510.12435v2 Announce Type: new 
Abstract: Electricity distribution companies deploy battery storage to defer grid upgrades by reducing peak demand. In deregulated jurisdictions, such storage often sits idle because regulatory constraints bar participation in electricity markets. Here, we develop an optimization framework that, to our knowledge, provides the first formal model of market participation constraints within storage investment and operation planning. Applying the framework to a Massachusetts case study, we find that market participation could deliver similar savings as peak demand reduction. Under current conditions, market participation does not increase storage investment, but at very low storage costs, could incentivize deployment beyond local distribution needs. This might run contrary to the separation of distribution from generation in deregulated markets. Our framework can identify investment levels appropriate for local distribution needs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12435v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>econ.GN</category>
      <category>eess.SY</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dirk Lauinger, Deepjyoti Deka, Sungho Shin</dc:creator>
    </item>
    <item>
      <title>Micro-Macro Backstepping Control of Large-Scale Hyperbolic Systems (Extended Version)</title>
      <link>https://arxiv.org/abs/2510.12456</link>
      <description>arXiv:2510.12456v1 Announce Type: new 
Abstract: We introduce a control design and analysis framework for micro-macro, boundary control of large-scale, $n+m$ hyperbolic PDE systems. Specifically, we develop feedback laws for stabilization of hyperbolic systems at the micro level (i.e., of the large-scale system) that employ a) measurements obtained from the $n+m$ system (i.e., at micro level) and kernels constructed based on an $\infty+\infty$ continuum system counterpart (i.e., at macro level), or b) kernels and measurements both stemming from a continuum counterpart, or c) averaged-continuum kernels/measurements. We also address (d)) stabilization of the continuum (macro) system, employing continuum kernels and measurements. Towards addressing d) we derive in a constructive manner an $\infty+\infty$ continuum approximation of $n+m$ hyperbolic systems and establish that its solutions approximate, for large $n$ and $m$, the solutions of the $n+m$ system. We then construct a feedback law for stabilization of the $\infty+\infty$ system via introduction of a continuum-PDE backstepping transformation. We establish well-posedness of the resulting 4-D kernel equations and prove closed-loop stability via construction of a novel Lyapunov functional. Furthermore, under control configuration a) we establish that the closed-loop system is exponentially stable provided that $n$ and $m$ are large, by proving that the exact, stabilizing $n+m$ control kernels can be accurately approximated by the continuum kernels. While under control configurations b) and c), we establish closed-loop stability capitalizing on the established solutions' and kernels' approximation properties via employment of infinite-dimensional ISS arguments. We provide two numerical simulation examples to illustrate the effectiveness and potential limitations of our design approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12456v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jukka-Pekka Humaloja, Nikolaos Bekiaris-Liberis</dc:creator>
    </item>
    <item>
      <title>Column Generation for Periodic Timetabling</title>
      <link>https://arxiv.org/abs/2510.12466</link>
      <description>arXiv:2510.12466v1 Announce Type: new 
Abstract: Periodic timetabling for public transportation networks is typically modelled as a Periodic Event Scheduling Problem (PESP). Solving instances of the benchmark library PESPlib to optimality continues to pose a challenge. As a further approach towards this goal, we remodel the problem by a time discretization of the underlying graph and consider arc-based as well as path-based integer programming formulations. For the path-based case, we use cycles on the graph expansion of the operational lines as variables and, therefore, include more of the problem inherent structure into the model. A consequence is the validity of several known inequalities and a lower bound on the LP-relaxation, that is the best known to date. As an extension we integrate passenger routing into the new model. The proposed models have an advantage in the linear programming relaxation, on the one hand, but have an increased problem size, on the other hand. We define the corresponding pricing problems for the use of column generation to handle the size. Both models are practically tested on different problem instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12466v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Stephanie Riedm\"uller, Niels Lindner</dc:creator>
    </item>
    <item>
      <title>Temporal Variabilities Limit Convergence Rates in Gradient-Based Online Optimization</title>
      <link>https://arxiv.org/abs/2510.12512</link>
      <description>arXiv:2510.12512v1 Announce Type: new 
Abstract: This paper investigates the fundamental performance limits of gradient-based algorithms for time-varying optimization. Leveraging the internal model principle and root locus techniques, we show that temporal variabilities impose intrinsic limits on the achievable rate of convergence. For a problem with condition ratio $\kappa$ and time variation whose model has degree $n$, we show that the worst-case convergence rate of any minimal-order gradient-based algorithm is $\rho_\text{TV} = (\frac{\kappa-1}{\kappa+1})^{1/n}$. This bound reveals a fundamental tradeoff between problem conditioning, temporal complexity, and rate of convergence. We further construct explicit controllers that attain the bound for low-degree models of time variation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12512v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bryan Van Scoy, Gianluca Bianchin</dc:creator>
    </item>
    <item>
      <title>Schr\"odinger bridge for generative AI: Soft-constrained formulation and convergence analysis</title>
      <link>https://arxiv.org/abs/2510.11829</link>
      <description>arXiv:2510.11829v1 Announce Type: cross 
Abstract: Generative AI can be framed as the problem of learning a model that maps simple reference measures into complex data distributions, and it has recently found a strong connection to the classical theory of the Schr\"odinger bridge problems (SBPs) due partly to their common nature of interpolating between prescribed marginals via entropy-regularized stochastic dynamics. However, the classical SBP enforces hard terminal constraints, which often leads to instability in practical implementations, especially in high-dimensional or data-scarce regimes. To address this challenge, we follow the idea of the so-called soft-constrained Schr\"odinger bridge problem (SCSBP), in which the terminal constraint is replaced by a general penalty function. This relaxation leads to a more flexible stochastic control formulation of McKean-Vlasov type.
  We establish the existence of optimal solutions for all penalty levels and prove that, as the penalty grows, both the controls and value functions converge to those of the classical SBP at a linear rate. Our analysis builds on Doob's h-transform representations, the stability results of Schr\"odinger potentials, Gamma-convergence, and a novel fixed-point argument that couples an optimization problem over the space of measures with an auxiliary entropic optimal transport problem. These results not only provide the first quantitative convergence guarantees for soft-constrained bridges but also shed light on how penalty regularization enables robust generative modeling, fine-tuning, and transfer learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11829v1</guid>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jin Ma, Ying Tan, Renyuan Xu</dc:creator>
    </item>
    <item>
      <title>Non-spherical minimizers in the generalized liquid drop model for Yukawa and truncated Coulomb potentials</title>
      <link>https://arxiv.org/abs/2510.11893</link>
      <description>arXiv:2510.11893v1 Announce Type: cross 
Abstract: We investigate generalized liquid drop models with screened Riesz-type interactions, focusing in particular on truncated Coulomb and Yukawa potentials in three dimensions. While the classical Gamow model with Coulomb interaction is conjectured to admit only spherical minimizers below a critical mass and no minimizer above, we show that this conjecture fails if the interaction is screened. In the case of truncated Coulomb and Yukawa potentials, we establish the existence of non-spherical minimizers for some values of the screening parameter. This gives the first evidence of such minimizers in the class of repulsive, radial, and radially nonincreasing kernels in three dimensions. Our approach relies on a comparison of the energy-per-mass ratios of balls and cylinders, in contrast with recent two-dimensional results obtained via $\Gamma$-convergence. We further show that in the unscreened Riesz case, the conjecture remains consistent, though delicate. Indeed we observe that the energy-per-mass ratios of balls and of cylinders are surprisingly close.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11893v1</guid>
      <category>math.AP</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lia Bronsard, Beno\^it Merlet, Marc Pegon</dc:creator>
    </item>
    <item>
      <title>Completions of pairwise comparison data that minimize the triad measure of inconsistency</title>
      <link>https://arxiv.org/abs/2510.12351</link>
      <description>arXiv:2510.12351v1 Announce Type: cross 
Abstract: We consider incomplete pairwise comparison matrices and determine exactly when they have a consistent completion and, if not, when they have a nearly consistent completion. We use the maximum 3-cycle product as a measure of inconsistency and show that, when the graph of the specified entries is chordal, a completion in which this measure is not increased is always possible. Methodology to produce such completions is developed. Such methodology may also be used to reduce inconsistency with few changes of comparisons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12351v1</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Susana Furtado, Charles Johnson</dc:creator>
    </item>
    <item>
      <title>Improved Central Limit Theorem and Bootstrap Approximations for Linear Stochastic Approximation</title>
      <link>https://arxiv.org/abs/2510.12375</link>
      <description>arXiv:2510.12375v1 Announce Type: cross 
Abstract: In this paper, we refine the Berry-Esseen bounds for the multivariate normal approximation of Polyak-Ruppert averaged iterates arising from the linear stochastic approximation (LSA) algorithm with decreasing step size. We consider the normal approximation by the Gaussian distribution with covariance matrix predicted by the Polyak-Juditsky central limit theorem and establish the rate up to order $n^{-1/3}$ in convex distance, where $n$ is the number of samples used in the algorithm. We also prove a non-asymptotic validity of the multiplier bootstrap procedure for approximating the distribution of the rescaled error of the averaged LSA estimator. We establish approximation rates of order up to $1/\sqrt{n}$ for the latter distribution, which significantly improves upon the previous results obtained by Samsonov et al. (2024).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12375v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bogdan Butyrin, Eric Moulines, Alexey Naumov, Sergey Samsonov, Qi-Man Shao, Zhuo-Song Zhang</dc:creator>
    </item>
    <item>
      <title>Cautious Weight Decay</title>
      <link>https://arxiv.org/abs/2510.12402</link>
      <description>arXiv:2510.12402v1 Announce Type: cross 
Abstract: We introduce Cautious Weight Decay (CWD), a one-line, optimizer-agnostic modification that applies weight decay only to parameter coordinates whose signs align with the optimizer update. Unlike standard decoupled decay, which implicitly optimizes a regularized or constrained objective, CWD preserves the original loss and admits a bilevel interpretation: it induces sliding-mode behavior upon reaching the stationary manifold, allowing it to search for locally Pareto-optimal stationary points of the unmodified objective. In practice, CWD is a drop-in change for optimizers such as AdamW, Lion, and Muon, requiring no new hyperparameters or additional tuning. For language model pre-training and ImageNet classification, CWD consistently improves final loss and accuracy at million- to billion-parameter scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12402v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lizhang Chen, Jonathan Li, Kaizhao Liang, Baiyu Su, Cong Xie, Nuo Wang Pierse, Chen Liang, Ni Lao, Qiang Liu</dc:creator>
    </item>
    <item>
      <title>Kinetic modelling of the CO2 capture and utilisation on NiRu-Ca/Al dual function material via parameter estimation</title>
      <link>https://arxiv.org/abs/2510.12439</link>
      <description>arXiv:2510.12439v1 Announce Type: cross 
Abstract: This study presents a detailed, open-source kinetic modelling computational framework for CO2 capture and utilisation using a newly formulated dual-function material (DFM) comprising 15 wt% Ni, 1 wt% Ru, and 10 wt% CaO supported on spherical alumina. A finite difference reactor model was developed to simulate the cyclic adsorption, purge, and hydrogenation stages. The model incorporates experimentally-derived rate expressions, accounts for system delay via a second-order response function, and was fitted to time-resolved concentration laboratory data using Bayesian optimisation. A combined parameter estimation strategy was employed to ensure mass continuity across stages and improve the robustness of purge kinetics. The kinetic parameters extracted reveal that carbonate decomposition, not methanation, is the rate-limiting step during hydrogenation. Temperature-dependent simulations confirm a trade-off between reaction kinetics and CO2 storage capacity, with methane yield maximised at 300C when compared with the other temperature sets. By offering transparent methodology and reproducible code, this work provides a robust platform for researchers and practitioners to study, validate, and optimise DFM systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12439v1</guid>
      <category>physics.chem-ph</category>
      <category>math.OC</category>
      <category>physics.app-ph</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Meshkat Dolat, Andrew David Wright, Soudabeh Bahrami Gharamaleki, Loukia-Pantzechroula Merkouri, Melis S. Duyar, Michael Short</dc:creator>
    </item>
    <item>
      <title>Multi-Armed Bandits with Minimum Aggregated Revenue Constraints</title>
      <link>https://arxiv.org/abs/2510.12523</link>
      <description>arXiv:2510.12523v1 Announce Type: cross 
Abstract: We examine a multi-armed bandit problem with contextual information, where the objective is to ensure that each arm receives a minimum aggregated reward across contexts while simultaneously maximizing the total cumulative reward. This framework captures a broad class of real-world applications where fair revenue allocation is critical and contextual variation is inherent. The cross-context aggregation of minimum reward constraints, while enabling better performance and easier feasibility, introduces significant technical challenges -- particularly the absence of closed-form optimal allocations typically available in standard MAB settings. We design and analyze algorithms that either optimistically prioritize performance or pessimistically enforce constraint satisfaction. For each algorithm, we derive problem-dependent upper bounds on both regret and constraint violations. Furthermore, we establish a lower bound demonstrating that the dependence on the time horizon in our results is optimal in general and revealing fundamental limitations of the free exploration principle leveraged in prior work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12523v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed Ben Yahmed, Hafedh El Ferchichi, Marc Abeille, Vianney Perchet</dc:creator>
    </item>
    <item>
      <title>A tactical time slot management problem under mixed logit demand</title>
      <link>https://arxiv.org/abs/2407.02308</link>
      <description>arXiv:2407.02308v5 Announce Type: replace 
Abstract: We study the tactical time slot management problem under mixed logit demand for attended home delivery in subscription settings. We propose a static mixed-integer linear programming model that integrates delivery slot assortment, price discount decisions, and routing optimization while capturing customer heterogeneity through the mixed logit model. To overcome the computational challenges posed by simulation-based choice probabilities, we develop a simulation-based Adaptive Large Neighborhood Search method aligned with a Sample Average Approximation reformulation. Computational experiments on large-scale instances demonstrate the effectiveness of our approach in capturing stochastic customer behavior and preference heterogeneity, providing a scalable and flexible method for optimizing time slot management under complex demand structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02308v5</guid>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dorsa Abdolhamidi, Virginie Lurkin</dc:creator>
    </item>
    <item>
      <title>Verification theorem related to a zero sum stochastic differential game, based on a chain rule for non-smooth functions</title>
      <link>https://arxiv.org/abs/2407.06243</link>
      <description>arXiv:2407.06243v3 Announce Type: replace 
Abstract: In the framework of stochastic zero-sum differential games, we establish a verification theorem, inspired by those existing in stochastic control, to provide sufficient conditions for a pair of feedback controls to form a Nash equilibrium. Suppose the validity of the classical Isaacs' condition and the existence of a (what is termed) quasi-strong solution to the Bellman-Isaacs (BI) equations. If the diffusion coefficient of the state equation is non-degenerate, we are able to show the existence of a saddle point constituted by a couple of feedback controls that achieve the value of the game: moreover, the latter is equal to the (necessarily unique) solution of the BI equations. A suitable generalization is available when the diffusion is possibly degenerate. Similarly we have also improved a well-known verification theorem in stochastic control theory. The techniques of stochastic calculus via regularization we use, in particular specific chain rules, are borrowed from a companion paper of the authors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06243v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlo Ciccarella (OC, ENSTA Paris), Francesco Russo (OC, ENSTA Paris)</dc:creator>
    </item>
    <item>
      <title>Nonasymptotic Analysis of Accelerated Methods With Inexact Oracle Under Absolute Error Bound</title>
      <link>https://arxiv.org/abs/2408.00720</link>
      <description>arXiv:2408.00720v2 Announce Type: replace 
Abstract: Performance analysis of first-order algorithms with inexact oracles has gained recent attention due to various emerging applications in which obtaining exact gradients is impossible or computationally expensive. Previous research has demonstrated that the performance of accelerated first-order methods is more sensitive to gradient errors compared with non-accelerated ones. This paper investigates the nonasymptotic convergence bound of two accelerated methods with inexact gradients to solve deterministic smooth convex problems. Performance Estimation Problem (PEP) is used as the primary tool to analyze the convergence bounds of the underlying algorithms. By finding an analytical solution to PEP, we derive novel convergence bounds of Generalized Optimized Gradient Method (GOGM) and Generalized Fast Gradient Method (GFGM) with inexact gradient oracles following the absolute error bound. The derived bounds allow varying oracle inexactness along the iterations; furthermore, their accumulated error terms are independent of the initial condition and any unknown parameters. Furthermore, we analyze the tradeoff between the vanishing term and the accumulated error in the convergence bound that guides finding the optimal stepsize. Finally, we determine the optimal strategy to set the gradient inexactness along iterations (if possible in a given application), ensuring that the accumulated error remains subordinate to the vanishing term.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00720v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yin Liu, Sam Davanloo Tajbakhsh</dc:creator>
    </item>
    <item>
      <title>Growth model with externalities for energetic transition via MFG with common external variable</title>
      <link>https://arxiv.org/abs/2501.11988</link>
      <description>arXiv:2501.11988v2 Announce Type: replace 
Abstract: This article introduces a novel mean-field game model for multi-sector economic growth in which a dynamically evolving externality, influenced by the collective actions of agents, plays a central role. Building on classical growth theories and integrating environmental considerations, the framework incorporates common noise to capture shared uncertainties among agents about the externality variable. We demonstrate the existence and uniqueness of a strong mean-field game equilibrium by reformulating the equilibrium conditions as a Forward-Backward Stochastic Differential Equation under the stochastic maximum principle and establishing a contraction argument to ensure a unique solution. We provide a numerical resolution for a specified model using a fixed-point approach combined with neural network approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11988v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Lavigne, Quentin Petit, Xavier Warin</dc:creator>
    </item>
    <item>
      <title>System Architecting for GEO Communication Satellite Considering On-Orbit Refueling</title>
      <link>https://arxiv.org/abs/2504.07438</link>
      <description>arXiv:2504.07438v3 Announce Type: replace 
Abstract: This paper introduces the problem of selecting a satellite system architecture considering commercial on-orbit refueling (OOR). This problem answers two questions: "What design lifetime should the satellite have?" and "How much propellant should be carried at launch?" We formulate this as a mathematical optimization problem by adopting design lifetime and initial propellant mass as design variables and considering two objective functions to balance the returns and risks. To solve this problem, we develop a surrogate model-based framework grounded in a satellite lifecycle simulation. The framework captures various uncertainties and operational flexibility, and integrates a modified satellite sizing and cost model by adjusting traditional models with OOR. Based on the developed framework, we conduct a case study of GEO communication satellites to examine current target service performance and explore the potential of a new system architecture that diverges from traditional design trends.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07438v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.2514/1.A36403</arxiv:DOI>
      <dc:creator>Jaewoo Kim, Jaemyung Ahn</dc:creator>
    </item>
    <item>
      <title>Going from a Representative Agent to Counterfactuals in Combinatorial Choice</title>
      <link>https://arxiv.org/abs/2505.23546</link>
      <description>arXiv:2505.23546v2 Announce Type: replace 
Abstract: We study decision-making problems where data comprises points from a collection of binary polytopes, capturing aggregate information stemming from various combinatorial selection environments. We propose a nonparametric approach for counterfactual inference in this setting based on a representative agent model, where the available data is viewed as arising from maximizing separable concave utility functions over the respective binary polytopes. Our first contribution is to precisely characterize the selection probabilities representable under this model and show that verifying the consistency of any given aggregated selection dataset reduces to solving a polynomial-sized linear program. Building on this characterization, we develop a nonparametric method for counterfactual prediction. When data is inconsistent with the model, finding a best-fitting approximation for prediction reduces to solving a compact mixed-integer convex program. Numerical experiments based on synthetic data demonstrate the method's flexibility, predictive accuracy, and strong representational power even under model misspecification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23546v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yanqiu Ruan, Karthyek Murthy, Karthik Natarajan</dc:creator>
    </item>
    <item>
      <title>Convex Formulation of the Zero Emission Vessel Route Planning Problem</title>
      <link>https://arxiv.org/abs/2510.04313</link>
      <description>arXiv:2510.04313v2 Announce Type: replace 
Abstract: This paper focuses on the zero emission vessel route planning problem, which deals with cost-effective planning of battery-electric vessel services for predetermined routes. Vessel characteristics (including battery capacity), fleet size, cyclic schedule frequencies, sailing leg speeds, and shore charging infrastructure are jointly optimized. The problem is nonlinear and nonconvex in its original form, which makes it intractable for most real-world instances. The conventional approach in the literature is to solve a linear approximation by restricting vessel designs and sailing leg speeds to a small finite set. Contrary to the conventional linearization approach, this paper deals with the nonlinearities directly. We show that the problem exhibits a hidden convex structure uncovered by nonlinear changes of variables. By exploiting the favorable convex form of the transformed problem, we solve it in a few seconds using a free off-the-shelf solver that requires no initial guesses, variable bounds, or parameter tuning. We then easily recover the exact solution to the original nonconvex problem by reversing the variable changes. We provide an open-source implementation of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04313v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antti Ritari, Jani Romanoff, Kari Tammi</dc:creator>
    </item>
    <item>
      <title>Quantizer Design for Finite Model Approximations, Model Learning, and Quantized Q-Learning for MDPs with Unbounded Spaces</title>
      <link>https://arxiv.org/abs/2510.04355</link>
      <description>arXiv:2510.04355v2 Announce Type: replace 
Abstract: In this paper, for Markov decision processes (MDPs) with unbounded state spaces we present refined upper bounds presented in [Kara et. al. JMLR'23] on finite model approximation errors via optimizing the quantizers used for finite model approximations. We also consider implications on quantizer design for quantized Q-learning and empirical model learning, and the performance of policies obtained via Q-learning where the quantized state is treated as the state itself. We highlight the distinctions between planning, where approximating MDPs can be independently designed, and learning (either via Q-learning or empirical model learning), where approximating MDPs are restricted to be defined by invariant measures of Markov chains under exploration policies, leading to significant subtleties on quantizer design performance, even though asymptotic near optimality can be established under both setups. In particular, under Lyapunov growth conditions, we obtain explicit upper bounds which decay to zero as the number of bins approaches infinity</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04355v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Osman Bicer, Ali D. Kara, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>On time-consistent equilibrium stopping under aggregation of diverse discount rates</title>
      <link>https://arxiv.org/abs/2302.07470</link>
      <description>arXiv:2302.07470v4 Announce Type: replace-cross 
Abstract: This paper studies a central planner's decision making on behalf of a group of members with diverse discount rates. In the context of optimal stopping, we work with an aggregation preference to incorporate all discount rates via an attitude function that reflects the aggregation rule chosen by the central planner. The problem formulation is also applicable to single agent's stopping problem with uncertain discount rate, where our aggregation preference coincides with the conventional smooth ambiguity preference. The resulting optimal stopping problem is time inconsistent, for which we develop an iterative approach using consistent planning and characterize all time-consistent mild equilibria as fixed points of an operator in the setting of one-dimensional diffusion processes. We provide some sufficient conditions on the underlying models and the attitude function such that the smallest mild equilibrium attains the optimal equilibrium. In addition, we show that the optimal equilibrium is a weak equilibrium. When the sufficient condition of the attitude function is violated, we illustrate by various examples that the characterization of the optimal equilibrium may differ significantly from some existing results for a single agent, which now sensitively depends on the attitude function and the diversity distribution of discount rates within the group.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.07470v4</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuoqing Deng, Xiang Yu, Jiacheng Zhang</dc:creator>
    </item>
    <item>
      <title>Eco-driving Incentive Mechanisms for Mitigating Emissions in Urban Transportation</title>
      <link>https://arxiv.org/abs/2410.07952</link>
      <description>arXiv:2410.07952v2 Announce Type: replace-cross 
Abstract: This paper develops incentive mechanisms for promoting eco-driving with the overarching goal of minimizing emissions in transportation networks. The system operator provides drivers with energy-efficient driving guidance throughout their trips and measures compliance through vehicle telematics that capture how closely drivers follow this guidance. Drivers optimize their behaviors based on personal trade-offs between travel times and emissions. To design effective incentives, the operator elicits driver preferences regarding trip urgency and willingness to eco-drive, while determining optimal budget allocations and eco-driving recommendations. Two distinct settings based on driver behavior are analyzed. When drivers report their preferences truthfully, an incentive mechanism ensuring obedience (drivers find it optimal to follow recommendations) is designed by implementing eco-driving recommendations as a Nash equilibrium. When drivers may report strategically, the mechanism is extended to be both obedient and truthful (drivers find it optimal to report truthfully). Unlike existing works that focus on congestion or routing decisions in transportation networks, our framework explicitly targets emissions reduction by incentivizing drivers. The proposed mechanism addresses both strategic behavior and network effects arising from driver interactions, without requiring the operator to reveal system parameters to the drivers. Numerical simulations demonstrate the effects of budget constraints, driver types, and strategic misreporting on equilibrium outcomes and emissions reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07952v2</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Umar B. Niazi, Jung-Hoon Cho, Munther A. Dahleh, Roy Dong, Cathy Wu</dc:creator>
    </item>
    <item>
      <title>Regularity lost: the fundamental limitations and constraint qualifications in the problems of elastoplasticity</title>
      <link>https://arxiv.org/abs/2412.13068</link>
      <description>arXiv:2412.13068v2 Announce Type: replace-cross 
Abstract: We investigate the existence and non-existence of a function-valued strain solution in various models of elastoplasticity from the perspective of the constraint-based ``dual'' formulations. We describe abstract frameworks for linear elasticity, elasticity-perfect plasticity and elasticity-hardening plasticity in terms of adjoint linear operators and convert them to equivalent formulations in terms of differential inclusions (the sweeping process in particular). Within such frameworks we consider several manually solvable examples of discrete and continuous models. Despite their simplicity, the examples show how for discrete models with perfect plasticity it is possible to find the evolution of stress and strain (elongation), yet continuum models within the same framework may not possess a function-valued strain. Although some examples with such phenomenon are already known, we demonstrate that it may appear due to displacement loading. The central idea of the paper is to explain the loss of strain regularity in the dual formulation by the lack of additivity of the normal cones and the failure of Slater's constraint qualification.
  In contrast to perfect plasticity, models with hardening are known to be well-solvable for strains. We show that more advanced constraint qualifications can help to distinguish between those cases and, in the case of hardening, ensure the additivity of the normal cones, which means the existence of a function-valued strain rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13068v2</guid>
      <category>math.AP</category>
      <category>math-ph</category>
      <category>math.DS</category>
      <category>math.FA</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Gudoshnikov</dc:creator>
    </item>
    <item>
      <title>Dynamics-aware Diffusion Models for Planning and Control</title>
      <link>https://arxiv.org/abs/2504.00236</link>
      <description>arXiv:2504.00236v3 Announce Type: replace-cross 
Abstract: This paper addresses the problem of generating dynamically admissible trajectories for control tasks using diffusion models, particularly in scenarios where the environment is complex and system dynamics are crucial for practical application. We propose a novel framework that integrates system dynamics directly into the diffusion model's denoising process through a sequential prediction and projection mechanism. This mechanism, aligned with the diffusion model's noising schedule, ensures generated trajectories are both consistent with expert demonstrations and adhere to underlying physical constraints. Notably, our approach can generate maximum likelihood trajectories and accurately recover trajectories generated by linear feedback controllers, even when explicit dynamics knowledge is unavailable. We validate the effectiveness of our method through experiments on standard control tasks and a complex non-convex optimal control problem involving waypoint tracking and collision avoidance, demonstrating its potential for efficient trajectory generation in practical applications. Our code repository is available at www.github.com/darshangm/dynamics-aware-diffusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.00236v3</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Darshan Gadginmath, Fabio Pasqualetti</dc:creator>
    </item>
    <item>
      <title>PSN Game: Game-theoretic Prediction and Planning via a Player Selection Network</title>
      <link>https://arxiv.org/abs/2505.00213</link>
      <description>arXiv:2505.00213v2 Announce Type: replace-cross 
Abstract: While game-theoretic planning frameworks are effective at modeling multi-agent interactions, they require solving large optimization problems where the number of variables increases with the number of agents, resulting in long computation times that limit their use in large-scale, real-time systems. To address this issue, we propose 1) PSN Game: a learning-based, game-theoretic prediction and planning framework that reduces runtime by learning a Player Selection Network (PSN); and 2) a Goal Inference Network (GIN) that makes it possible to use the PSN in incomplete information games where agents' intentions are unknown. A PSN outputs a player selection mask that distinguishes influential players from less relevant ones, enabling the ego player to solve a smaller, masked game involving only selected players. By reducing the number of players in the game, and therefore reducing the number of variables in the corresponding optimization problem, PSN directly lowers computation time. The PSN Game framework is more flexible than existing player selection methods as it 1) relies solely on observations of players' past trajectories, without requiring full state, action, or other game-specific information; and 2) requires no online parameter tuning. Experiments in both simulated scenarios and human trajectory datasets demonstrate that PSNs outperform baseline selection methods in 1) prediction accuracy; and 2) planning safety. PSNs also generalize effectively to real-world scenarios in which agents' objectives are unknown without fine-tuning. By selecting only the most relevant players for decision-making, PSN Game offers a general mechanism for reducing planning complexity that can be seamlessly integrated into existing multi-agent planning frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00213v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianyu Qiu, Eric Ouano, Fernando Palafox, Christian Ellis, David Fridovich-Keil</dc:creator>
    </item>
    <item>
      <title>Geometric optimization for quantum communication</title>
      <link>https://arxiv.org/abs/2509.15106</link>
      <description>arXiv:2509.15106v2 Announce Type: replace-cross 
Abstract: Determining the ultimate limits of quantum communication, such as the quantum capacity of a channel and the distillable entanglement of a shared state, remains a central challenge in quantum information theory, primarily due to the phenomenon of superadditivity. This work develops Riemannian optimization methods to establish significantly tighter, computable two-sided bounds on these fundamental quantities. For upper bounds, our method systematically searches for state and channel extensions that minimize known information-theoretic bounds. We achieve this by parameterizing the space of all possible extensions as a Stiefel manifold, enabling a universal search that overcomes the limitations of ad-hoc constructions. Combined with an improved upper bound on the one-way distillable entanglement based on a refined continuity bound on quantum conditional entropy, our approach yields new state-of-the-art upper bounds on the quantum capacity of the qubit depolarizing channel for large values of the depolarizing parameter, strictly improving the previously best-known bounds. For lower bounds, we introduce Riemannian optimization methods to compute multi-shot coherent information. We establish lower bounds on the one-way distillable entanglement by parameterizing quantum instruments on the unitary manifold, and on the quantum capacity by parameterizing code states with a product of unitary manifolds. Numerical results for noisy entangled states and different channels demonstrate that our methods successfully unlock superadditive gains, improving previous results. Together, these findings establish Riemannian optimization as a principled and powerful tool for navigating the complex landscape of quantum communication limits. Furthermore, we prove that amortization does not enhance the channel coherent information, thereby closing a potential avenue for improving capacity lower bounds in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15106v2</guid>
      <category>quant-ph</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengkai Zhu, Hongyu Mao, Kun Fang, Xin Wang</dc:creator>
    </item>
    <item>
      <title>Central Limit Theorems for Asynchronous Averaged Q-Learning</title>
      <link>https://arxiv.org/abs/2509.18964</link>
      <description>arXiv:2509.18964v2 Announce Type: replace-cross 
Abstract: This paper establishes central limit theorems for Polyak-Ruppert averaged Q-learning under asynchronous updates. We prove a non-asymptotic central limit theorem, where the convergence rate in Wasserstein distance explicitly reflects the dependence on the number of iterations, state-action space size, the discount factor, and the quality of exploration. In addition, we derive a functional central limit theorem, showing that the partial-sum process converges weakly to a Brownian motion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.18964v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xingtu Liu</dc:creator>
    </item>
  </channel>
</rss>
