<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Jun 2025 04:00:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On Solving the Shortest Paths with Exclusive-Disjunction Arc Pairs Conflicts</title>
      <link>https://arxiv.org/abs/2506.03326</link>
      <description>arXiv:2506.03326v1 Announce Type: new 
Abstract: A variant of the well-known Shortest Path Problem is studied in this paper, where pairs of conflicting arcs are provided, and for each conflicting pair a penalty is paid once neither or both of the arcs are selected. This configures a set of soft-constraints. The problem, which can be used to model real applications, looks for a path from a given origin to a given destination that minimizes the cost of the arcs traversed plus the penalties incurred. In this paper, we consider a compact mixed integer linear program representing the problem and we solve it with the open-source solver CP-SAT, part of the Google OR-Tools computational suite. An experimental campaign on the instances available from the literature indicates that the approach we propose achieves results comparable with those of state-of-the-art solvers, notwithstanding it is a compact model, while the other approaches require the generation of dynamic constraints in order for the models to be competitive. Some best-known results have been improved in this study, and some instances have been closed for the first time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03326v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Montemanni, Derek H. Smith</dc:creator>
    </item>
    <item>
      <title>On Solving the Knapsack Problem with Conflicts</title>
      <link>https://arxiv.org/abs/2506.03330</link>
      <description>arXiv:2506.03330v1 Announce Type: new 
Abstract: A variant of the well-known Knapsack Problem is studied in this paper, where pairs of items are conflicting, and cannot be selected at the same time. This configures a set of hard constraints. The problem, which can be used to model real applications, looks for a selection of items such that the total profit is maximized, the capacity of the container is respected, and no conflict is violated. In this paper, we consider a previously known mixed integer linear program representing the problem and we solve it with the open-source solver CP-SAT, part of the Google OR-Tools computational suite. An experimental campaign on the instances available from the literature and adopted in the last decade, indicate that the approach we propose achieves results comparable with, and often better than, those of state-of-the-art solvers, notwithstanding its intrinsic conceptual and implementation simplicity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03330v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Montemanni, Derek H. Smith</dc:creator>
    </item>
    <item>
      <title>A line search framework with restarting for noisy optimization problems</title>
      <link>https://arxiv.org/abs/2506.03358</link>
      <description>arXiv:2506.03358v1 Announce Type: new 
Abstract: Nonlinear optimization methods are typically iterative and make use of gradient information to determine a direction of improvement and function information to effectively check for progress. When this information is corrupted by noise, designing a convergent and practical algorithmic process becomes challenging, as care must be taken to avoid taking bad steps due to erroneous information. For this reason, simple gradient-based schemes have been quite popular, despite being outperformed by more advanced techniques in the noiseless setting. In this paper, we propose a general algorithmic framework based on line search that is endowed with iteration and evaluation complexity guarantees even in a noisy setting. These guarantees are obtained as a result of a restarting condition, that monitors desirable properties for the steps taken at each iteration and can be checked even in the presence of noise. Experiments using a nonlinear conjugate gradient variant and a quasi-Newton variant illustrate that restarting can be performed without compromising practical efficiency and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03358v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Albert S. Berahas, Michael J. O'Neill, Cl\'ement W. Royer</dc:creator>
    </item>
    <item>
      <title>Disjunctive Benders Decomposition</title>
      <link>https://arxiv.org/abs/2506.03561</link>
      <description>arXiv:2506.03561v1 Announce Type: new 
Abstract: We propose a novel enhancement to Benders Decomposition (BD) that generates valid inequalities for the convex hull of the Benders reformulation, addressing a key limitation of conventional BD-its cuts are typically tight only for the continuous relaxation. Our method efficiently integrates disjunctive programming theory with BD, introducing a new routine that leverages existing cut-generating oracles for uncovering constraints required to construct valid inequalities for the convex hull. For mixed-binary linear programs, this approach eliminates the need to solve the master problem as a mixed-integer program. Additionally, we extend the a posteriori strengthening and lifting procedure for lift-and-project cuts into the BD framework, and present an approximate routine for generating lift-and-project cuts. Numerical results on large-scale instances show that our approach significantly reduces the number of branch-and-bound nodes required to reach the lower bound achieved by conventional BD, often by orders of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03561v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaiwen Fang, Inho Sin, Geunyeong Byeon</dc:creator>
    </item>
    <item>
      <title>Inexact Projected Preconditioned Gradient Methods with Variable Metrics: General Convergence Theory via Lyapunov Approach</title>
      <link>https://arxiv.org/abs/2506.03671</link>
      <description>arXiv:2506.03671v1 Announce Type: new 
Abstract: Projected gradient methods are widely used for constrained optimization. A key application is for partial differential equations (PDEs), where the objective functional represents physical energy and the linear constraints enforce conservation laws. However, computing the projections onto the constraint set generally requires solving large-scale ill-conditioned linear systems. A common strategy is to relax projection accuracy and apply preconditioners, which leads to the inexact preconditioned projected gradient descent (IPPGD) methods studied here. However, the theoretical analysis and the dynamic behavior of the IPPGD methods, along with an effective construction of the inexact projection operator itself, all remain largely unexplored. We propose a strategy for constructing the inexact projection operator and develop a gradient-type flow to model the IPPGD methods. Discretization of this flow not only recovers the original IPPGD method but also yields a potentially faster novel method. Furthermore, we apply Lyapunov analysis, designing a delicate Lyapunov function, to prove the exponential convergence at the continuous level and linear convergence at the discrete level. We then apply the proposed method to solve nonlinear PDEs and present numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03671v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruchi Guo, Jun Zou</dc:creator>
    </item>
    <item>
      <title>An Efficient and Globally Optimal Algorithm for Nonconvex QCQP with One Equality Constraint</title>
      <link>https://arxiv.org/abs/2506.03692</link>
      <description>arXiv:2506.03692v1 Announce Type: new 
Abstract: In this paper, we concentrate on a particular category of quadratically constrained quadratic programming (QCQP): nonconvex QCQP with one equality constraint. This type of QCQP problem optimizes a quadratic objective under a fixed second-order cost and has various engineering applications. It often serves as a subproblem in an iterative algorithm framework. However, the development of a high-quality and efficient solution remains an open problem in the existing literature. Traditionally, the Semidefinite Relaxation (SDR) technique is applied for an optimal solution with a prohibitively high order of time complexity. To improve computational efficiency, we propose a fast and non-iterative algorithm to reach a globally optimal solution. This algorithm consists of two consecutive stages: Simultaneous Diagonalization (SD) and Bisection Search (BS). The SD stage decouples the original problem through an affine mapping and the BS stage finds the optimal Lagrange multiplier by solving an equation induced from first- and second-order Karush-Kuhn-Tucker (KKT) conditions. In addition, we enrich the proposed algorithm with further extensions on the problem structure, namely, rank-deficient parameter, indefiniteness, constraint augmentation, and matrix-format variable. Numerical simulations show that the proposed algorithm achieves good numerical performance in terms of constraint satisfaction, optimality gap, and computational time, and scales to problem sizes at least ten times those supported by the traditional benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03692v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Licheng Zhao, Rui Zhou, Wenqiang Pu</dc:creator>
    </item>
    <item>
      <title>Feedback stabilization of switched systems under arbitrary switching: A convex characterization</title>
      <link>https://arxiv.org/abs/2506.03759</link>
      <description>arXiv:2506.03759v1 Announce Type: new 
Abstract: In this paper, we study stabilizability of discrete-time switched linear systems where the switching signal is considered as an arbitrary disturbance (and not a control variable). We characterize feedback stabilization via necessary and sufficient linear matrix inequalities (LMIs) conditions based on novel graph structures. We analyze both the cases in which the controller has (or has not) access to the current switching mode, the so-called mode-dependent and mode-independent settings, providing specular results. Moreover, our approach provides explicit piecewise-linear and memory-dependent linear controllers, highlighting the connections with existing stabilization approaches. The effectiveness of the proposed technique is finally illustrated with the help of some numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03759v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thiago Alves Lima, Matteo Della Rossa, Antoine Girard</dc:creator>
    </item>
    <item>
      <title>LQ optimal control for infinite-dimensional passive systems</title>
      <link>https://arxiv.org/abs/2506.03882</link>
      <description>arXiv:2506.03882v1 Announce Type: new 
Abstract: We study the Linear-Quadratic optimal control problem for a general class of infinite-dimensional passive systems, allowing for unbounded input and output operators. We show that under mild assumptions, the finite cost condition is always satisfied. Moreover, we show that the optimal cost operator is a contraction. In the case where the system is energy preserving, the optimal cost operator is shown to be the identity, which allows to deduce easily the unique stabilizing optimal control. In this case, we derive an explicit solution to an adapted operator Riccati equation. We apply our results to boundary control systems, first-order port-Hamiltonian systems and an Euler-Bernoulli beam with shear force control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03882v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anthony Hastir, Birgit Jacob</dc:creator>
    </item>
    <item>
      <title>Multilevel Bregman Proximal Gradient Descent</title>
      <link>https://arxiv.org/abs/2506.03950</link>
      <description>arXiv:2506.03950v1 Announce Type: new 
Abstract: We present the Multilevel Bregman Proximal Gradient Descent (ML-BPGD) method, a novel multilevel optimization framework tailored to constrained convex problems with relative Lipschitz smoothness. Our approach extends the classical multilevel optimization framework (MGOPT) to handle Bregman-based geometries and constrained domains. We provide a rigorous analysis of ML BPGD for multiple coarse levels and establish a global linear convergence rate. We demonstrate the effectiveness of ML BPGD in the context of image reconstruction, providing theoretical guarantees for the well-posedness of the multilevel framework and validating its performance through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03950v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yara Elshiaty, Stefania Petra</dc:creator>
    </item>
    <item>
      <title>A variable dimension sketching strategy for nonlinear least-squares</title>
      <link>https://arxiv.org/abs/2506.03965</link>
      <description>arXiv:2506.03965v1 Announce Type: new 
Abstract: We present a stochastic inexact Gauss-Newton method for the solution of nonlinear least-squares. To reduce the computational cost with respect to the classical method, at each iteration the proposed algorithm approximately minimizes the local model on a random subspace. The dimension of the subspace varies along the iterations, and two strategies are considered for its update: the first is based solely on the Armijo condition, the latter is based on information from the true Gauss-Newton model. Under suitable assumptions on the objective function and the random subspace, we prove a probabilistic bound on the number of iterations needed to drive the norm of the gradient below any given threshold. Moreover, we provide a theoretical analysis of the local behavior of the method. The numerical experiments demonstrate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03965v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefania Bellavia, Greta Malaspina, Benedetta Morini</dc:creator>
    </item>
    <item>
      <title>A Generic Branch-and-Bound Algorithm for $\ell_0$-Penalized Problems with Supplementary Material</title>
      <link>https://arxiv.org/abs/2506.03974</link>
      <description>arXiv:2506.03974v1 Announce Type: new 
Abstract: We present a generic Branch-and-Bound procedure designed to solve L0-penalized optimization problems. Existing approaches primarily focus on quadratic losses and construct relaxations using "Big-M" constraints and/or L2-norm penalties. In contrast, our method accommodates a broader class of loss functions and allows greater flexibility in relaxation design through a general penalty term, encompassing existing techniques as special cases. We establish theoretical results ensuring that all key quantities required for the Branch-and-Bound implementation admit closed-form expressions under the general blanket assumptions considered in our work. Leveraging this framework, we introduce El0ps, an open-source Python solver with a plug-and-play workflow that enables user-defined losses and penalties in L0-penalized problems. Through extensive numerical experiments, we demonstrate that El0ps achieves state-of-the-art performance on classical instances and extends computational feasibility to previously intractable ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03974v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cl\'ement Elvira, Th\'eo Guyard, C\'edric Herzet</dc:creator>
    </item>
    <item>
      <title>Similarity-based fuzzy clustering scientific articles: potentials and challenges from mathematical and computational perspectives</title>
      <link>https://arxiv.org/abs/2506.04045</link>
      <description>arXiv:2506.04045v1 Announce Type: new 
Abstract: Fuzzy clustering, which allows an article to belong to multiple clusters with soft membership degrees, plays a vital role in analyzing publication data. This problem can be formulated as a constrained optimization model, where the goal is to minimize the discrepancy between the similarity observed from data and the similarity derived from a predicted distribution. While this approach benefits from leveraging state-of-the-art optimization algorithms, tailoring them to work with real, massive databases like OpenAlex or Web of Science - containing about 70 million articles and a billion citations - poses significant challenges. We analyze potentials and challenges of the approach from both mathematical and computational perspectives. Among other things, second-order optimality conditions are established, providing new theoretical insights, and practical solution methods are proposed by exploiting the structure of the problem. Specifically, we accelerate the gradient projection method using GPU-based parallel computing to efficiently handle large-scale data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04045v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vu Thi Huong, Ida Litzel, Thorsten Koch</dc:creator>
    </item>
    <item>
      <title>A primal-dual price-optimization method for computing equilibrium prices in mean-field games models</title>
      <link>https://arxiv.org/abs/2506.04169</link>
      <description>arXiv:2506.04169v1 Announce Type: new 
Abstract: We develop a simple yet efficient Lagrangian method for computing equilibrium prices in a mean-field game price-formation model. We prove that equilibrium prices are optimal in terms of a suitable criterion and derive a primal-dual gradient-based algorithm for computing them. One of the highlights of our computational framework is the efficient, simple, and flexible implementation of the algorithm using modern automatic differentiation techniques. Our implementation is modular and admits a seamless extension to high-dimensional settings with more complex dynamics, costs, and equilibrium conditions. Additionally, automatic differentiation enables a versatile algorithm that requires only coding the cost functions of agents. It automatically handles the gradients of the costs, thereby eliminating the need to manually form the adjoint equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04169v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>econ.TH</category>
      <category>math.NA</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xu Wang, Samy Wu Fung, Levon Nurbekyan</dc:creator>
    </item>
    <item>
      <title>Learning Parametric Convex Functions</title>
      <link>https://arxiv.org/abs/2506.04183</link>
      <description>arXiv:2506.04183v1 Announce Type: new 
Abstract: A parametrized convex function depends on a variable and a parameter, and is convex in the variable for any valid value of the parameter. Such functions can be used to specify parametrized convex optimization problems, i.e., a convex optimization family, in domain specific languages for convex optimization. In this paper we address the problem of fitting a parametrized convex function that is compatible with disciplined programming, to some given data. This allows us to fit a function arising in a convex optimization formulation directly to observed or simulated data. We demonstrate our open-source implementation on several examples, ranging from illustrative to practical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04183v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Schaller, Alberto Bemporad, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>Lions and Muons: Optimization via Stochastic Frank-Wolfe</title>
      <link>https://arxiv.org/abs/2506.04192</link>
      <description>arXiv:2506.04192v1 Announce Type: new 
Abstract: Stochastic Frank-Wolfe is a classical optimization method for solving constrained optimization problems. On the other hand, recent optimizers such as Lion and Muon have gained quite significant popularity in deep learning. In this work, we provide a unifying perspective by interpreting these seemingly disparate methods through the lens of Stochastic Frank-Wolfe. Specifically, we show that Lion and Muon with weight decay can be viewed as special instances of a Stochastic Frank-Wolfe, and we establish their convergence guarantees in terms of the Frank-Wolfe gap, a standard stationarity measure in non-convex optimization for Frank-Wolfe methods. We further find that convergence to this gap implies convergence to a KKT point of the original problem under a norm constraint for Lion and Muon. Moreover, motivated by recent empirical findings that stochastic gradients in modern machine learning tasks often exhibit heavy-tailed distributions, we extend Stochastic Frank-Wolfe to settings with heavy-tailed noise by developing two robust variants with strong theoretical guarantees, which in turn yields new variants of Lion and Muon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04192v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria-Eleni Sfyraki, Jun-Kun Wang</dc:creator>
    </item>
    <item>
      <title>Measurement incompatibility and quantum steering via linear programming</title>
      <link>https://arxiv.org/abs/2506.03045</link>
      <description>arXiv:2506.03045v1 Announce Type: cross 
Abstract: The problem of deciding whether a set of quantum measurements is jointly measurable is known to be equivalent to determining whether a quantum assemblage is unsteerable. This problem can be formulated as a semidefinite program (SDP). However, the number of variables and constraints in such a formulation grows exponentially with the number of measurements, rendering it intractable for large measurement sets. In this work, we circumvent this problem by transforming the SDP into a hierarchy of linear programs that compute upper and lower bounds on the incompatibility robustness with a complexity that grows polynomially in the number of measurements. The hierarchy is guaranteed to converge and it can be applied to arbitrary measurements -- including non-projective POVMs -- in arbitrary dimensions. While convergence becomes impractical in high dimensions, in the case of qubits our method reliably provides accurate upper and lower bounds for the incompatibility robustness of sets with several hundred measurements in a short time using a standard laptop. We also apply our methods to qutrits, obtaining non-trivial upper and lower bounds in scenarios that are otherwise intractable using the standard SDP approach. Finally, we show how our methods can be used to construct local hidden state models for states, or conversely, to certify that a given state exhibits steering; for two-qubit quantum states, our approach is comparable to, and in some cases outperforms, the current best methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03045v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas E. A. Porto, S\'ebastien Designolle, Sebastian Pokutta, Marco T\'ulio Quintino</dc:creator>
    </item>
    <item>
      <title>DiaBlo: Diagonal Blocks Are Sufficient For Finetuning</title>
      <link>https://arxiv.org/abs/2506.03230</link>
      <description>arXiv:2506.03230v1 Announce Type: cross 
Abstract: Finetuning is a critical step for adapting large language models (LLMs) to domain-specific downstream tasks. To mitigate the substantial computational and memory costs of full-model fine-tuning, Parameter-Efficient Finetuning (PEFT) methods have been proposed to update only a small subset of model parameters. However, performance gaps between PEFT approaches and full-model fine-tuning still exist. In this work, we present DiaBlo, a simple yet effective PEFT approach that updates only the diagonal blocks of selected model weight matrices. Unlike Low Rank Adaptation (LoRA) and its variants, DiaBlo eliminates the need for low rank matrix products, thereby avoiding the reliance on auxiliary initialization schemes or customized optimization strategies to improve convergence. This design leads to stable and robust convergence while maintaining comparable memory efficiency and training speed to LoRA. We conduct extensive experiments across a range of tasks, including commonsense reasoning, arithmetic reasoning, code generation, and safety alignment, to evaluate the effectiveness and efficiency of DiaBlo. Across these benchmarks, DiaBlo demonstrates strong and consistent performance while maintaining high memory efficiency and fast finetuning speed. Codes are available at https://github.com/ziyangjoy/DiaBlo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03230v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Selcuk Gurses, Aozhong Zhang, Yanxia Deng, Xun Dong, Xin Li, Naigang Wang, Penghang Yin, Zi Yang</dc:creator>
    </item>
    <item>
      <title>From Average-Iterate to Last-Iterate Convergence in Games: A Reduction and Its Applications</title>
      <link>https://arxiv.org/abs/2506.03464</link>
      <description>arXiv:2506.03464v1 Announce Type: cross 
Abstract: The convergence of online learning algorithms in games under self-play is a fundamental question in game theory and machine learning. Among various notions of convergence, last-iterate convergence is particularly desirable, as it reflects the actual decisions made by the learners and captures the day-to-day behavior of the learning dynamics. While many algorithms are known to converge in the average-iterate, achieving last-iterate convergence typically requires considerably more effort in both the design and the analysis of the algorithm. Somewhat surprisingly, we show in this paper that for a large family of games, there exists a simple black-box reduction that transforms the average iterates of an uncoupled learning dynamics into the last iterates of a new uncoupled learning dynamics, thus also providing a reduction from last-iterate convergence to average-iterate convergence. Our reduction applies to games where each player's utility is linear in both their own strategy and the joint strategy of all opponents. This family includes two-player bimatrix games and generalizations such as multi-player polymatrix games. By applying our reduction to the Optimistic Multiplicative Weights Update algorithm, we obtain new state-of-the-art last-iterate convergence rates for uncoupled learning dynamics in two-player zero-sum normal-form games: (1) an $O(\frac{\log d}{T})$ last-iterate convergence rate under gradient feedback, representing an exponential improvement in the dependence on the dimension $d$ (i.e., the maximum number of actions available to either player); and (2) an $\widetilde{O}(d^{\frac{1}{5}} T^{-\frac{1}{5}})$ last-iterate convergence rate under bandit feedback, improving upon the previous best rates of $\widetilde{O}(\sqrt{d} T^{-\frac{1}{8}})$ and $\widetilde{O}(\sqrt{d} T^{-\frac{1}{6}})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03464v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng</dc:creator>
    </item>
    <item>
      <title>Conformal Mixed-Integer Constraint Learning with Feasibility Guarantees</title>
      <link>https://arxiv.org/abs/2506.03531</link>
      <description>arXiv:2506.03531v1 Announce Type: cross 
Abstract: We propose Conformal Mixed-Integer Constraint Learning (C-MICL), a novel framework that provides probabilistic feasibility guarantees for data-driven constraints in optimization problems. While standard Mixed-Integer Constraint Learning methods often violate the true constraints due to model error or data limitations, our C-MICL approach leverages conformal prediction to ensure feasible solutions are ground-truth feasible. This guarantee holds with probability at least $1{-}\alpha$, under a conditional independence assumption. The proposed framework supports both regression and classification tasks without requiring access to the true constraint function, while avoiding the scalability issues associated with ensemble-based heuristics. Experiments on real-world applications demonstrate that C-MICL consistently achieves target feasibility rates, maintains competitive objective performance, and significantly reduces computational cost compared to existing methods. Our work bridges mathematical optimization and machine learning, offering a principled approach to incorporate uncertainty-aware constraints into decision-making with rigorous statistical guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03531v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Ovalle, Lorenz T. Biegler, Ignacio E. Grossmann, Carl D. Laird, Mateo Dulce Rubio</dc:creator>
    </item>
    <item>
      <title>Sign-SGD is the Golden Gate between Multi-Node to Single-Node Learning: Significant Boost via Parameter-Free Optimization</title>
      <link>https://arxiv.org/abs/2506.03725</link>
      <description>arXiv:2506.03725v1 Announce Type: cross 
Abstract: Quite recently, large language models have made a significant breakthrough across various disciplines. However, training them is an extremely resource-intensive task, even for major players with vast computing resources. One of the methods gaining popularity in light of these challenges is Sign-SGD. This method can be applied both as a memory-efficient approach in single-node training and as a gradient compression technique in the distributed learning. Nevertheless, it is impossible to automatically determine the effective stepsize from the theoretical standpoint. Indeed, it depends on the parameters of the dataset to which we do not have access in the real-world learning paradigm. To address this issue, we design several variants of single-node deterministic Sign-SGD. We extend our approaches to practical scenarios: stochastic single-node and multi-node learning, methods with incorporated momentum. We conduct extensive experiments on real machine learning problems that emphasize the practical applicability of our ideas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03725v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniil Medyakov, Sergey Stanko, Gleb Molodtsov, Philip Zmushko, Grigoriy Evseev, Egor Petrov, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>PPO in the Fisher-Rao geometry</title>
      <link>https://arxiv.org/abs/2506.03757</link>
      <description>arXiv:2506.03757v1 Announce Type: cross 
Abstract: Proximal Policy Optimization (PPO) has become a widely adopted algorithm for reinforcement learning, offering a practical policy gradient method with strong empirical performance. Despite its popularity, PPO lacks formal theoretical guarantees for policy improvement and convergence. PPO is motivated by Trust Region Policy Optimization (TRPO) that utilizes a surrogate loss with a KL divergence penalty, which arises from linearizing the value function within a flat geometric space. In this paper, we derive a tighter surrogate in the Fisher-Rao (FR) geometry, yielding a novel variant, Fisher-Rao PPO (FR-PPO). Our proposed scheme provides strong theoretical guarantees, including monotonic policy improvement. Furthermore, in the tabular setting, we demonstrate that FR-PPO achieves sub-linear convergence without any dependence on the dimensionality of the action or state spaces, marking a significant step toward establishing formal convergence results for PPO-based algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03757v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Razvan-Andrei Lascu, David \v{S}i\v{s}ka, {\L}ukasz Szpruch</dc:creator>
    </item>
    <item>
      <title>Learning Fair And Effective Points-Based Rewards Programs</title>
      <link>https://arxiv.org/abs/2506.03911</link>
      <description>arXiv:2506.03911v1 Announce Type: cross 
Abstract: Points-based rewards programs are a prevalent way to incentivize customer loyalty; in these programs, customers who make repeated purchases from a seller accumulate points, working toward eventual redemption of a free reward. These programs have recently come under scrutiny due to accusations of unfair practices in their implementation. Motivated by these concerns, we study the problem of fairly designing points-based rewards programs, with a focus on two obstacles that put fairness at odds with their effectiveness. First, due to customer heterogeneity, the seller should set different redemption thresholds for different customers to generate high revenue. Second, the relationship between customer behavior and the number of accumulated points is typically unknown; this requires experimentation which may unfairly devalue customers' previously earned points. We first show that an individually fair rewards program that uses the same redemption threshold for all customers suffers a loss in revenue of at most a factor of $1+\ln 2$, compared to the optimal personalized strategy that differentiates between customers. We then tackle the problem of designing temporally fair learning algorithms in the presence of demand uncertainty. Toward this goal, we design a learning algorithm that limits the risk of point devaluation due to experimentation by only changing the redemption threshold $O(\log T)$ times, over a horizon of length $T$. This algorithm achieves the optimal (up to polylogarithmic factors) $\widetilde{O}(\sqrt{T})$ regret in expectation. We then modify this algorithm to only ever decrease redemption thresholds, leading to improved fairness at a cost of only a constant factor in regret. Extensive numerical experiments show the limited value of personalization in average-case settings, in addition to demonstrating the strong practical performance of our proposed learning algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03911v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chamsi Hssaine, Yichun Hu, Ciara Pike-Burke</dc:creator>
    </item>
    <item>
      <title>Incremental Gradient Descent with Small Epoch Counts is Surprisingly Slow on Ill-Conditioned Problems</title>
      <link>https://arxiv.org/abs/2506.04126</link>
      <description>arXiv:2506.04126v1 Announce Type: cross 
Abstract: Recent theoretical results demonstrate that the convergence rates of permutation-based SGD (e.g., random reshuffling SGD) are faster than uniform-sampling SGD; however, these studies focus mainly on the large epoch regime, where the number of epochs $K$ exceeds the condition number $\kappa$. In contrast, little is known when $K$ is smaller than $\kappa$, and it is still a challenging open question whether permutation-based SGD can converge faster in this small epoch regime (Safran and Shamir, 2021). As a step toward understanding this gap, we study the naive deterministic variant, Incremental Gradient Descent (IGD), on smooth and strongly convex functions. Our lower bounds reveal that for the small epoch regime, IGD can exhibit surprisingly slow convergence even when all component functions are strongly convex. Furthermore, when some component functions are allowed to be nonconvex, we prove that the optimality gap of IGD can be significantly worse throughout the small epoch regime. Our analyses reveal that the convergence properties of permutation-based SGD in the small epoch regime may vary drastically depending on the assumptions on component functions. Lastly, we supplement the paper with tight upper and lower bounds for IGD in the large epoch regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04126v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yujun Kim, Jaeyoung Cha, Chulhee Yun</dc:creator>
    </item>
    <item>
      <title>Thinking Beyond Visibility: A Near-Optimal Policy Framework for Locally Interdependent Multi-Agent MDPs</title>
      <link>https://arxiv.org/abs/2506.04215</link>
      <description>arXiv:2506.04215v1 Announce Type: cross 
Abstract: Decentralized Partially Observable Markov Decision Processes (Dec-POMDPs) are known to be NEXP-Complete and intractable to solve. However, for problems such as cooperative navigation, obstacle avoidance, and formation control, basic assumptions can be made about local visibility and local dependencies. The work DeWeese and Qu 2024 formalized these assumptions in the construction of the Locally Interdependent Multi-Agent MDP. In this setting, it establishes three closed-form policies that are tractable to compute in various situations and are exponentially close to optimal with respect to visibility. However, it is also shown that these solutions can have poor performance when the visibility is small and fixed, often getting stuck during simulations due to the so called "Penalty Jittering" phenomenon. In this work, we establish the Extended Cutoff Policy Class which is, to the best of our knowledge, the first non-trivial class of near optimal closed-form partially observable policies that are exponentially close to optimal with respect to the visibility for any Locally Interdependent Multi-Agent MDP. These policies are able to remember agents beyond their visibilities which allows them to perform significantly better in many small and fixed visibility settings, resolve Penalty Jittering occurrences, and under certain circumstances guarantee fully observable joint optimal behavior despite the partial observability. We also propose a generalized form of the Locally Interdependent Multi-Agent MDP that allows for transition dependence and extended reward dependence, then replicate our theoretical results in this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04215v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex DeWeese, Guannan Qu</dc:creator>
    </item>
    <item>
      <title>Differentially Private Distributed Mismatch Tracking Algorithm for Constraint-Coupled Resource Allocation Problems</title>
      <link>https://arxiv.org/abs/2204.07330</link>
      <description>arXiv:2204.07330v2 Announce Type: replace 
Abstract: This paper considers privacy-concerned distributed constraint-coupled resource allocation problems over an undirected network, where each agent holds a private cost function and obtains the solution via only local communication. With privacy concerns, we mask the exchanged information with independent Laplace noise against a potential attacker with potential access to all network communications. We propose a differentially private distributed mismatch tracking algorithm (diff-DMAC) to achieve cost-optimal distribution of resources while preserving privacy. Adopting constant stepsizes, the linear convergence property of diff-DMAC in mean square is established under the standard assumptions of Lipschitz gradients and strong convexity. Moreover, it is theoretically proven that the proposed algorithm is {\epsilon}-differentially private.And we also show the trade-off between convergence accuracy and privacy level. Finally, a numerical example is provided for verification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.07330v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/CDC51059.2022.9993173.</arxiv:DOI>
      <arxiv:journal_reference>2022 IEEE 61st Conference on Decision and Control (CDC), Cancun, Mexico, 2022, pp. 3965-3970</arxiv:journal_reference>
      <dc:creator>Wenwen Wu, Shanying Zhu, Shuai Liu, Xinping Guan</dc:creator>
    </item>
    <item>
      <title>Data-driven stabilization of switched and constrained linear systems</title>
      <link>https://arxiv.org/abs/2208.11392</link>
      <description>arXiv:2208.11392v2 Announce Type: replace 
Abstract: We consider the design of state feedback control laws for both the switching signal and the continuous input of an unknown switched linear system, given past noisy input-state trajectories measurements. Based on Lyapunov-Metzler inequalities, we derive data-dependent bilinear programs whose solution directly returns a provably stabilizing controller and ensures $\mathcal{H}_2$ or $\mathcal{H}_{\infty}$ performance. We further present relaxations that considerably reduce the computational cost, still without requiring stabilizability of any of the switching modes. Finally, we showcase the flexibility of our approach on the constrained stabilization problem for a perturbed linear system. We validate our theoretical findings numerically, demonstrating the favourable trade-off between conservatism and tractability achieved by the proposed relaxations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.11392v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.automatica.2024.111974</arxiv:DOI>
      <dc:creator>Mattia Bianchi, Sergio Grammatico, Jorge Cort\'es</dc:creator>
    </item>
    <item>
      <title>Tikhonov Regularization for Stochastic Non-Smooth Convex Optimization in Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2403.06708</link>
      <description>arXiv:2403.06708v4 Announce Type: replace 
Abstract: To solve convex optimization problems with a noisy gradient input, we analyze the global behavior of subgradient-like flows under stochastic errors. The objective function is composite, being equal to the sum of two convex functions, one being differentiable and the other potentially non-smooth. We then use stochastic differential inclusions where the drift term is minus the subgradient of the objective function, and the diffusion term is either bounded or square-integrable. In this context, under Lipschitz's continuity of the differentiable term and a growth condition of the non-smooth term, our first main result shows almost sure weak convergence of the trajectory process towards a minimizer of the objective function. Then, using Tikhonov regularization with a properly tuned vanishing parameter, we can obtain almost sure strong convergence of the trajectory towards the minimum norm solution. We find an explicit tuning of this parameter when our objective function satisfies a local error-bound inequality. We also provide a comprehensive complexity analysis by establishing several new pointwise and ergodic convergence rates in expectation for the convex, strongly convex, and Lojasiewicz case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06708v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rodrigo Maulen-Soto, Jalal Fadili, Hedy Attouch</dc:creator>
    </item>
    <item>
      <title>Global Optimization Algorithm through High-Resolution Sampling</title>
      <link>https://arxiv.org/abs/2410.13737</link>
      <description>arXiv:2410.13737v3 Announce Type: replace 
Abstract: We present an optimization algorithm that can identify a global minimum of a potentially nonconvex smooth function with high probability, assuming the Gibbs measure of the potential satisfies a logarithmic Sobolev inequality. Our contribution is twofold: on the one hand we propose a global optimization method, which is built on an oracle sampling algorithm producing arbitrarily accurate samples from a given Gibbs measure. On the other hand, we propose a new sampling algorithm, drawing inspiration from both overdamped and underdamped Langevin dynamics, as well as from the high-resolution differential equation known for its acceleration in deterministic settings. While the focus of the paper is primarily theoretical, we demonstrate the effectiveness of our algorithms on the Rastrigin function, where it outperforms recent approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13737v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Cortild, Claire Delplancke, Nadia Oudjane, Juan Peypouquet</dc:creator>
    </item>
    <item>
      <title>Moment-sos and spectral hierarchies for polynomial optimization on the sphere and quantum de Finetti theorems</title>
      <link>https://arxiv.org/abs/2412.13191</link>
      <description>arXiv:2412.13191v2 Announce Type: replace 
Abstract: We revisit the convergence analysis of two approximation hierarchies for polynomial optimization on the unit sphere. The first one is based on the moment-sos approach and gives semidefinite bounds for which Fang and Fawzi (2021) showed an analysis in $O(1/r^2)$ for the r-th level bound, using the polynomial kernel method. The second hierarchy was recently proposed by Lovitz and Johnston (2023) and gives spectral bounds for which they show a convergence rate in $O(1/r)$, using a quantum de Finetti theorem of Christandl et al. (2007) that applies to complex Hermitian matrices with a "double" symmetry. We investigate links between these approaches, in particular, via duality of moments and sums of squares.
  Our main results include showing that the spectral bounds cannot have a convergence rate better than $O(1/r^2)$ and that they do not enjoy generic finite convergence. In addition, we propose alternative performance analyses that involve explicit constants depending on intrinsic parameters of the optimization problem. For this we develop a novel "banded" real de Finetti theorem that applies to real matrices with "double" symmetry. We also show how to use the polynomial kernel method to obtain a de Finetti type result in $O(1/r^2)$ for real maximally symmetric matrices, improving an earlier result in $O(1/r)$ of Doherty and Wehner (2012).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13191v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Taveira Blomenhofer, Monique Laurent</dc:creator>
    </item>
    <item>
      <title>First-Order Projected Algorithms With the Same Linear Convergence Rate Bounds as Their Unconstrained Counterparts</title>
      <link>https://arxiv.org/abs/2503.13965</link>
      <description>arXiv:2503.13965v3 Announce Type: replace 
Abstract: In this paper, we propose a systematic approach for constructing first-order projected algorithms for optimization problems with general set constraints, building upon their unconstrained counterparts. We show that these projected algorithms retain the same linear convergence rate bounds, when the latter are obtained for the unconstrained algorithms via quadratic Lyapunov functions arising from integral quadratic constraint (IQC) characterizations. The projected algorithms are constructed by applying a projection in the norm induced by the Lyapunov matrix, ensuring both constraint satisfaction and optimality at the fixed point. Furthermore, under a linear transformation associated with this matrix, the projection becomes non-expansive in the Euclidean norm, allowing the use of the contraction mapping theorem to establish convergence. Our results indicate that, when analyzing worst-case convergence rates or when synthesizing first-order optimization algorithms with potentially higher-order dynamics, it suffices to focus solely on the unconstrained dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13965v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengmou Li, Ioannis Lestas, Masaaki Nagahara</dc:creator>
    </item>
    <item>
      <title>Level-set topology optimisation with unfitted finite elements and automatic shape differentiation</title>
      <link>https://arxiv.org/abs/2504.09748</link>
      <description>arXiv:2504.09748v2 Announce Type: replace 
Abstract: In this paper we develop automatic shape differentiation techniques for unfitted discretisations and link these to recent advances in shape calculus for unfitted methods. We extend existing analytic shape calculus results to the case where the domain boundary intersects with the boundary of the background domain. We further show that we can recover these analytic derivatives to machine precision regardless of the mesh size using the developed automatic shape differentiation techniques, drastically reducing the burden associated with the analytic derivation of these quantities. In addition, we show that we can also recover the symmetric shape Hessian. We implement these techniques for both serial and distributed computing frameworks in the Julia package GridapTopOpt and the wider Gridap ecosystem. As part of this implementation we propose a novel graph-based approach for isolated volume detection. We demonstrate the applicability of the unfitted automatic shape differentiation framework and our implementation by considering the three-dimensional minimum compliance topology optimisation of a linear elastic wheel and of a linear elastic structure in a fluid-structure interaction problem with Stokes flow. The implementation is general and allows GridapTopOpt to solve a wider range of problems on unstructured meshes without analytic calculation of shape derivatives and avoiding issues that arise when material properties are smoothed at the domain boundary. The software is open source and available at https://github.com/zjwegert/GridapTopOpt.jl.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09748v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zachary J. Wegert, Jordi Manyer, Connor Mallon, Santiago Badia, Vivien J. Challis</dc:creator>
    </item>
    <item>
      <title>Signed Angle Rigid Graphs for Network Localization and Formation Control</title>
      <link>https://arxiv.org/abs/2505.19945</link>
      <description>arXiv:2505.19945v2 Announce Type: replace 
Abstract: Graph rigidity theory studies the capability of a graph embedded in the Euclidean space to constrain its global geometric shape via local constraints among nodes and edges, and has been widely exploited in network localization and formation control. In recent years, the traditional rigidity theory has been extended by considering new types of local constraints such as bearing, angle, ratio of distance, etc. Among them, the signed angle constraint has received extensive attention, since it is practically measurable and independent of the global coordinate frame. However, the relevant studies always consider special graph structures, which are sufficient but not necessary for signed angle rigidity. This paper presents a comprehensive combinatorial analysis in terms of graphs and angle index sets for signed angle rigidity. We show that Laman graphs equivalently characterize minimally signed angle rigid graphs. Moreover, we propose a method to construct the minimal set of signed angle constraints in a Laman graph to effectively ensure signed angle rigidity. These results are finally applied to distributed network localization and formation stabilization problems, respectively, where each agent only has access to signed angle measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19945v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinpeng Huang, Gangshan Jing</dc:creator>
    </item>
    <item>
      <title>Convergence rates of regularized quasi-Newton methods without strong convexity</title>
      <link>https://arxiv.org/abs/2506.00521</link>
      <description>arXiv:2506.00521v2 Announce Type: replace 
Abstract: In this paper, we study convergence rates of the cubic regularized proximal quasi-Newton method (\csr) for solving non-smooth additive composite problems that satisfy the so-called Kurdyka-\L ojasiewicz (K\L ) property with respect to some desingularization function $\phi$ rather than strong convexity. After a number of iterations $k_0$, Cubic SR1 PQN exhibits non-asymptotic explicit super-linear convergence rates for any $k\geq k_0$. In particular, when $\phi(t)=ct^{1/2}$, Cubic SR1 PQN has a convergence rate of order $\left(\frac{C}{(k-k_0)^{1/2}}\right)^{(k-k_0)/2}$, where $k$ is the number of iterations and $C&gt;0$ is a constant. For the special case, i.e. functions which satisfy \L ojasiewicz inequality, the rate becomes global and non-asymptotic. This work presents, for the first time, non-asymptotic explicit convergence rates of regularized (proximal) SR1 quasi-Newton methods applied to non-convex non-smooth problems with K\L\ property. Actually, the rates are novel even in the smooth non-convex case. Notably, we achieve this without employing line search or trust region strategies, without assuming the Dennis-Mor\'e condition, without any assumptions on quasi-Newton metrics and without assuming strong convexity. Furthermore, for convex problems, we focus on a more tractable gradient regularized quasi-Newton method (Grad SR1 PQN) which can achieve results similar to those obtained with cubic regularization. We also demonstrate, for the first time, the non-asymptotic super-linear convergence rate of Grad SR1 PQN for solving convex problems with the help of the \L ojasiewicz inequality instead of strong convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00521v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shida Wang, Jalal Fadili, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Efficient Quadratic Corrections for Frank-Wolfe Algorithms</title>
      <link>https://arxiv.org/abs/2506.02635</link>
      <description>arXiv:2506.02635v2 Announce Type: replace 
Abstract: We develop a Frank-Wolfe algorithm with corrective steps, generalizing previous algorithms including blended pairwise conditional gradients and fully-corrective Frank-Wolfe, and propose a highly efficient corrective algorithm in the case of convex quadratic objectives based on linear optimization or linear system solving, akin to Wolfe's minimum-norm point. Beyond optimization problems that are directly quadratic, we revisit two algorithms, split conditional gradient for the intersection of two sets accessible through linear oracles, and second-order conditional gradient sliding, which approximately solves Variable-Metric projection subproblems, proposing improvement of the algorithms and their guarantees that may be of interest beyond our work, and we leverage quadratic corrections to accelerate the quadratic subproblems they solve. We show significant computational acceleration of Frank-Wolfe-based algorithms equipped with the quadratic correction on the considered problem classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02635v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jannis Halbey, Seta Rakotomandimby, Mathieu Besan\c{c}on, S\'ebastien Designolle, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Non-exchangeable evolutionary and mean field games and their applications</title>
      <link>https://arxiv.org/abs/2506.02644</link>
      <description>arXiv:2506.02644v2 Announce Type: replace 
Abstract: A replicator dynamic for non-exchangeable agents in a continuous action space is formulated and its well-posedness is proven in a space of probability measures. The non-exchangeability allows for the analysis of evolutionary games involving agents with distinct (and possibly infinitely many) types. We also explicitly connect this replicator dynamic to a stationary mean field game, which determines the pairwise actions of the heterogeneous agents. Moreover, as a byproduct of our theoretical results, we show that a class of nonlinear voter models, recently the subject of increasing interest, called q-voter models, can be viewed as a replicator dynamic driven by a utility that is a power of the probability density. This implies that non-exchangeable and/or mean-field game formulations of these models can also be constructed. We also present computational examples of evolutionary and mean field game models using a finite difference method, focusing on tragedy of the commons and the q-voter model with non-exchangeable agents, of which are interesting cases from theoretical and computational perspectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02644v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H. Yoshioka, M. Tsujimura, T. Tanaka</dc:creator>
    </item>
    <item>
      <title>Non-Conforming Structure Preserving Finite Element Method for Doubly Diffusive Flows on Bounded Lipschitz Domains</title>
      <link>https://arxiv.org/abs/2403.10282</link>
      <description>arXiv:2403.10282v2 Announce Type: replace-cross 
Abstract: We study a stationary model of doubly diffusive flows with temperature-dependent viscosity on bounded Lipschitz domains in two and three dimensions. A new well-posedness and regularity analysis of weak solutions under minimal assumptions on domain geometry and data regularity are established. A fully non-conforming finite element method based on Crouzeix-Raviart elements, which ensures locally exactly divergence-free velocity fields is explored. Unlike previously proposed schemes, this discretisation enables to establish uniqueness of the discrete solutions. We prove the well-posedness of the discrete problem and derive pressure-robust a priori error estimates. An accuracy test is conducted to verify the theoretical error decay rates in flow, Stokes and Darcy regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10282v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jai Tushar, Arbaz Khan, Manil T. Mohan</dc:creator>
    </item>
    <item>
      <title>OptiBench Meets ReSocratic: Measure and Improve LLMs for Optimization Modeling</title>
      <link>https://arxiv.org/abs/2407.09887</link>
      <description>arXiv:2407.09887v4 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have exhibited their problem-solving abilities in mathematical reasoning. Solving realistic optimization (OPT) problems in application scenarios requires advanced and applied mathematics ability. However, current OPT benchmarks that merely solve linear programming are far from complex realistic situations. In this work, we propose OptiBench, a benchmark for End-to-end optimization problem-solving with human-readable inputs and outputs. OptiBench contains rich optimization problems, including linear and nonlinear programming with or without tabular data, which can comprehensively evaluate LLMs' solving ability. In our benchmark, LLMs are required to call a code solver to provide precise numerical answers. Furthermore, to alleviate the data scarcity for optimization problems, and to bridge the gap between open-source LLMs on a small scale (e.g., Llama-3-8b) and closed-source LLMs (e.g., GPT-4), we further propose a data synthesis method namely ReSocratic. Unlike general data synthesis methods that proceed from questions to answers, \ReSocratic first incrementally synthesizes formatted optimization demonstration with mathematical formulations step by step and then back-translates the generated demonstrations into questions. Based on this, we synthesize the ReSocratic-29k dataset. We further conduct supervised fine-tuning with ReSocratic-29k on multiple open-source models. Experimental results show that ReSocratic-29k significantly improves the performance of open-source models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09887v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:journal_reference>The Thirteenth International Conference on Learning Representations, 2025</arxiv:journal_reference>
      <dc:creator>Zhicheng Yang, Yiwei Wang, Yinya Huang, Zhijiang Guo, Wei Shi, Xiongwei Han, Liang Feng, Linqi Song, Xiaodan Liang, Jing Tang</dc:creator>
    </item>
    <item>
      <title>Quantum Natural Stochastic Pairwise Coordinate Descent</title>
      <link>https://arxiv.org/abs/2407.13858</link>
      <description>arXiv:2407.13858v2 Announce Type: replace-cross 
Abstract: Variational quantum algorithms, optimized using gradient-based methods, often exhibit sub-optimal convergence performance due to their dependence on Euclidean geometry. Quantum natural gradient descent (QNGD) is a more efficient method that incorporates the geometry of the state space via a quantum information metric. However, QNGD is computationally intensive and suffers from high sample complexity. In this work, we formulate a novel quantum information metric and construct an unbiased estimator for this metric using single-shot measurements. We develop a quantum optimization algorithm that leverages the geometry of the state space via this estimator while avoiding full-state tomography, as in conventional techniques. We provide the convergence analysis of the algorithm under mild conditions. Furthermore, we provide experimental results that demonstrate the better sample complexity and faster convergence of our algorithm compared to the state-of-the-art approaches. Our results illustrate the algorithm's ability to avoid saddle points and local minima.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13858v2</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Aamir Sohail, Mohsen Heidari, S. Sandeep Pradhan</dc:creator>
    </item>
    <item>
      <title>Subspace Optimization for Large Language Models with Convergence Guarantees</title>
      <link>https://arxiv.org/abs/2410.11289</link>
      <description>arXiv:2410.11289v2 Announce Type: replace-cross 
Abstract: Subspace optimization algorithms, such as GaLore (Zhao et al., 2024), have gained attention for pre-training and fine-tuning large language models (LLMs) due to their memory efficiency. However, their convergence guarantees remain unclear, particularly in stochastic settings. In this paper, we reveal that GaLore does not always converge to the optimal solution and provide an explicit counterexample to support this finding. We further explore the conditions under which GaLore achieves convergence, showing that it does so when either (i) a sufficiently large mini-batch size is used or (ii) the gradient noise is isotropic. More significantly, we introduce GoLore (Gradient random Low-rank projection), a novel variant of GaLore that provably converges in typical stochastic settings, even with standard batch sizes. Our convergence analysis extends naturally to other subspace optimization algorithms. Finally, we empirically validate our theoretical results and thoroughly test the proposed mechanisms. Codes are available at https://github.com/pkumelon/Golore.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11289v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yutong He, Pengrui Li, Yipeng Hu, Chuyan Chen, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>Efficient Learning for Entropy-Regularized Markov Decision Processes via Multilevel Monte Carlo</title>
      <link>https://arxiv.org/abs/2503.21224</link>
      <description>arXiv:2503.21224v3 Announce Type: replace-cross 
Abstract: Designing efficient learning algorithms with complexity guarantees for Markov decision processes (MDPs) with large or continuous state and action spaces remains a fundamental challenge. We address this challenge for entropy-regularized MDPs with Polish state and action spaces, assuming access to a generative model of the environment. We propose a novel family of multilevel Monte Carlo (MLMC) algorithms that integrate fixed-point iteration with MLMC techniques and a generic stochastic approximation of the Bellman operator. We quantify the precise impact of the chosen approximate Bellman operator on the accuracy of the resulting MLMC estimator. Leveraging this error analysis, we show that using a biased plain MC estimate for the Bellman operator results in quasi-polynomial sample complexity, whereas an unbiased randomized multilevel approximation of the Bellman operator achieves polynomial sample complexity in expectation. Notably, these complexity bounds are independent of the dimensions or cardinalities of the state and action spaces, distinguishing our approach from existing algorithms whose complexities scale with the sizes of these spaces. We validate these theoretical performance guarantees through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21224v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthieu Meunier, Christoph Reisinger, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>Random-key genetic algorithms: Principles and applications</title>
      <link>https://arxiv.org/abs/2506.02120</link>
      <description>arXiv:2506.02120v2 Announce Type: replace-cross 
Abstract: A random-key genetic algorithm is an evolutionary metaheuristic for discrete and global optimization. Each solution is encoded as a vector of N random keys, where a random key is a real number randomly generated in the continuous interval [0, 1). A decoder maps each vector of random keys to a solution of the optimization problem being solved and computes its cost. The benefit of this approach is that all genetic operators and transformations can be maintained within the unitary hypercube, regardless of the problem being addressed. This enhances the productivity and maintainability of the core framework. The algorithm starts with a population of P vectors of random keys. At each iteration, the vectors are partitioned into two sets: a smaller set of high-valued elite solutions and the remaining non-elite solutions. All elite elements are copied, without change, to the next population. A small number of random-key vectors (the mutants) is added to the population of the next iteration. The remaining elements of the population of the next iteration are generated by combining, with the parametrized uniform crossover of Spears and DeJong (1991), pairs of solutions. This chapter reviews random-key genetic algorithms and describes an effective variant called biased random-key genetic algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02120v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 05 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mariana A. Londe, Luciana S. Pessoa, Carlos E. Andrade, Jos\'e F. Gon\c{c}alves, Mauricio G. C. Resende</dc:creator>
    </item>
  </channel>
</rss>
