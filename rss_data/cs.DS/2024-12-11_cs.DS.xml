<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Dec 2024 05:00:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Massively Parallel Algorithms for Approximate Shortest Paths</title>
      <link>https://arxiv.org/abs/2412.06952</link>
      <description>arXiv:2412.06952v1 Announce Type: new 
Abstract: We present fast algorithms for approximate shortest paths in the massively parallel computation (MPC) model. We provide randomized algorithms that take $poly(\log{\log{n}})$ rounds in the near-linear memory MPC model. Our results are for unweighted undirected graphs with $n$ vertices and $m$ edges.
  Our first contribution is a $(1+\epsilon)$-approximation algorithm for Single-Source Shortest Paths (SSSP) that takes $poly(\log{\log{n}})$ rounds in the near-linear MPC model, where the memory per machine is $\tilde{O}(n)$ and the total memory is $\tilde{O}(mn^{\rho})$, where $\rho$ is a small constant.
  Our second contribution is a distance oracle that allows to approximate the distance between any pair of vertices. The distance oracle is constructed in $poly(\log{\log{n}})$ rounds and allows to query a $(1+\epsilon)(2k-1)$-approximate distance between any pair of vertices $u$ and $v$ in $O(1)$ additional rounds. The algorithm is for the near-linear memory MPC model with total memory of size $\tilde{O}((m+n^{1+\rho})n^{1/k})$, where $\rho$ is a small constant.
  While our algorithms are for the near-linear MPC model, in fact they only use one machine with $\tilde{O}(n)$ memory, where the rest of machines can have sublinear memory of size $O(n^{\gamma})$ for a small constant $\gamma &lt; 1$. All previous algorithms for approximate shortest paths in the near-linear MPC model either required $\Omega(\log{n})$ rounds or had an $\Omega(\log{n})$ approximation.
  Our approach is based on fast construction of near-additive emulators, limited-scale hopsets and limited-scale distance sketches that are tailored for the MPC model. While our end-results are for the near-linear MPC model, many of the tools we construct such as hopsets and emulators are constructed in the more restricted sublinear MPC model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06952v1</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michal Dory, Shaked Matar</dc:creator>
    </item>
    <item>
      <title>Parallel simulation for sampling under isoperimetry and score-based diffusion models</title>
      <link>https://arxiv.org/abs/2412.07435</link>
      <description>arXiv:2412.07435v1 Announce Type: new 
Abstract: In recent years, there has been a surge of interest in proving discretization bounds for sampling under isoperimetry and for diffusion models. As data size grows, reducing the iteration cost becomes an important goal. Inspired by the great success of the parallel simulation of the initial value problem in scientific computation, we propose parallel Picard methods for sampling tasks. Rigorous theoretical analysis reveals that our algorithm achieves better dependence on dimension $d$ than prior works in iteration complexity (i.e., reduced from $\widetilde{O}(\log^2 d)$ to $\widetilde{O}(\log d)$), which is even optimal for sampling under isoperimetry with specific iteration complexity. Our work highlights the potential advantages of simulation methods in scientific computation for dynamics-based sampling and diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07435v1</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huanjian Zhou, Masashi Sugiyama</dc:creator>
    </item>
    <item>
      <title>NP-hardness and a PTAS for the Euclidean Steiner Line Problem</title>
      <link>https://arxiv.org/abs/2412.07046</link>
      <description>arXiv:2412.07046v1 Announce Type: cross 
Abstract: The Euclidean Steiner Tree Problem (EST) seeks a minimum-cost tree interconnecting a given set of terminal points in the Euclidean plane, allowing the use of additional intersection points. In this paper, we consider two variants that include an additional straight line $\gamma$ with zero cost, which must be incorporated into the tree. In the Euclidean Steiner fixed Line Problem (ESfL), this line is given as input and can be treated as a terminal. In contrast, the Euclidean Steiner Line Problem (ESL) requires determining the optimal location of $\gamma$. Despite recent advances, including heuristics and a 1.214-approximation algorithm for both problems, a formal proof of NP-hardness has remained open. In this work, we close this gap by proving that both the ESL and ESfL are NP-hard. Additionally, we prove that both problems admit a polynomial-time approximation scheme (PTAS), by demonstrating that approximation algorithms for the EST can be adapted to the ESL and ESfL with appropriate modifications. Specifically, we show ESfL$\leq_{\text{PTAS}}$EST and ESL$\leq_{\text{PTAS}}$EST, i.e., provide a PTAS reduction to the EST.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07046v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Bartlmae, Paul J. J\"unger, Elmar Langetepe</dc:creator>
    </item>
    <item>
      <title>Streaming Private Continual Counting via Binning</title>
      <link>https://arxiv.org/abs/2412.07093</link>
      <description>arXiv:2412.07093v1 Announce Type: cross 
Abstract: In differential privacy, $\textit{continual observation}$ refers to problems in which we wish to continuously release a function of a dataset that is revealed one element at a time. The challenge is to maintain a good approximation while keeping the combined output over all time steps differentially private. In the special case of $\textit{continual counting}$ we seek to approximate a sum of binary input elements. This problem has received considerable attention lately, in part due to its relevance in implementations of differentially private stochastic gradient descent. $\textit{Factorization mechanisms}$ are the leading approach to continual counting, but the best such mechanisms do not work well in $\textit{streaming}$ settings since they require space proportional to the size of the input. In this paper, we present a simple approach to approximating factorization mechanisms in low space via $\textit{binning}$, where adjacent matrix entries with similar values are changed to be identical in such a way that a matrix-vector product can be maintained in sublinear space. Our approach has provable sublinear space guarantees for a class of lower triangular matrices whose entries are monotonically decreasing away from the diagonal. We show empirically that even with very low space usage we are able to closely match, and sometimes surpass, the performance of asymptotically optimal factorization mechanisms. Recently, and independently of our work, Dvijotham et al. have also suggested an approach to implementing factorization mechanisms in a streaming setting. Their work differs from ours in several respects: It only addresses factorization into $\textit{Toeplitz}$ matrices, only considers $\textit{maximum}$ error, and uses a different technique based on rational function approximation that seems less versatile than our binning approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07093v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joel Daniel Andersson, Rasmus Pagh</dc:creator>
    </item>
    <item>
      <title>Covered Forest: Fine-grained generalization analysis of graph neural networks</title>
      <link>https://arxiv.org/abs/2412.07106</link>
      <description>arXiv:2412.07106v1 Announce Type: cross 
Abstract: The expressive power of message-passing graph neural networks (MPNNs) is reasonably well understood, primarily through combinatorial techniques from graph isomorphism testing. However, MPNNs' generalization abilities -- making meaningful predictions beyond the training set -- remain less explored. Current generalization analyses often overlook graph structure, limit the focus to specific aggregation functions, and assume the impractical, hard-to-optimize $0$-$1$ loss function. Here, we extend recent advances in graph similarity theory to assess the influence of graph structure, aggregation, and loss functions on MPNNs' generalization abilities. Our empirical study supports our theoretical insights, improving our understanding of MPNNs' generalization properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07106v1</guid>
      <category>cs.LG</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.NE</category>
      <category>stat.ML</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonis Vasileiou, Ben Finkelshtein, Floris Geerts, Ron Levie, Christopher Morris</dc:creator>
    </item>
    <item>
      <title>Automated Discovery of Branching Rules with Optimal Complexity for the Maximum Independent Set Problem</title>
      <link>https://arxiv.org/abs/2412.07685</link>
      <description>arXiv:2412.07685v1 Announce Type: cross 
Abstract: The branching algorithm is a fundamental technique for designing fast exponential-time algorithms to solve combinatorial optimization problems exactly. It divides the entire solution space into independent search branches using predetermined branching rules, and ignores the search on suboptimal branches to reduce the time complexity. The complexity of a branching algorithm is primarily determined by the branching rules it employs, which are often designed by human experts. In this paper, we show how to automate this process with a focus on the maximum independent set problem. The main contribution is an algorithm that efficiently generate optimal branching rules for a given sub-graph with tens of vertices. Its efficiency enables us to generate the branching rules on-the-fly, which is provably optimal and significantly reduces the number of branches compared to existing methods that rely on expert-designed branching rules. Numerical experiment on 3-regular graphs shows an average complexity of O(1.0441^n) can be achieved, better than any previous methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07685v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuan-Zhao Gao, Yi-Jia Wang, Pan Zhang, Jin-Guo Liu</dc:creator>
    </item>
    <item>
      <title>Highway Preferential Attachment Models for Geographic Routing</title>
      <link>https://arxiv.org/abs/2403.08105</link>
      <description>arXiv:2403.08105v2 Announce Type: replace 
Abstract: In the 1960s, the world-renowned social psychologist Stanley Milgram conducted experiments that showed that not only do there exist ``short chains'' of acquaintances between any two arbitrary people, but that these arbitrary strangers are able to find these short chains. This phenomenon, known as the \emph{small-world phenomenon}, is explained in part by any model that has a low diameter, such as the Barab\'asi and Albert's \emph{preferential attachment} model, but these models do not display the same efficient routing that Milgram's experiments showed. In the year 2000, Kleinberg proposed a model with an efficient $\mathcal{O}(\log^2{n})$ greedy routing algorithm. In 2004, Martel and Nguyen showed that Kleinberg's analysis was tight, while also showing that Kleinberg's model had an expected diameter of only $\Theta(\log{n})$ -- a much smaller value than the greedy routing algorithm's path lengths. In 2022, Goodrich and Ozel proposed the \emph{neighborhood preferential attachment} model (NPA), combining elements from Barab\'asi and Albert's model with Kleinberg's model, and experimentally showed that the resulting model outperformed Kleinberg's greedy routing performance on U.S. road networks. While they displayed impressive empirical results, they did not provide any theoretical analysis of their model. In this paper, we first provide a theoretical analysis of a generalization of Kleinberg's original model and show that it can achieve expected $\mathcal{O}(\log{n})$ routing, a much better result than Kleinberg's model. We then propose a new model, \emph{windowed NPA}, that is similar to the neighborhood preferential attachment model but has provable theoretical guarantees w.h.p. We show that this model is able to achieve $\mathcal{O}(\log^{1 + \epsilon}{n})$ greedy routing for any $\epsilon &gt; 0$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08105v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ofek Gila (University of California, Irvine), Evrim Ozel (University of California, Irvine), Michael T. Goodrich (University of California, Irvine)</dc:creator>
    </item>
  </channel>
</rss>
