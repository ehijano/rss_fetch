<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Sep 2024 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Enabling Distributed Generative Artificial Intelligence in 6G: Mobile Edge Generation</title>
      <link>https://arxiv.org/abs/2409.05870</link>
      <description>arXiv:2409.05870v1 Announce Type: new 
Abstract: Mobile edge generation (MEG) is an emerging technology that allows the network to meet the challenging traffic load expectations posed by the rise of generative artificial intelligence~(GAI). A novel MEG model is proposed for deploying GAI models on edge servers (ES) and user equipment~(UE) to jointly complete text-to-image generation tasks. In the generation task, the ES and UE will cooperatively generate the image according to the text prompt given by the user. To enable the MEG, a pre-trained latent diffusion model (LDM) is invoked to generate the latent feature, and an edge-inferencing MEG protocol is employed for data transmission exchange between the ES and the UE. A compression coding technique is proposed for compressing the latent features to produce seeds. Based on the above seed-enabled MEG model, an image quality optimization problem with transmit power constraint is formulated. The transmitting power of the seed is dynamically optimized by a deep reinforcement learning agent over the fading channel. The proposed MEG enabled text-to-image generation system is evaluated in terms of image quality and transmission overhead. The numerical results indicate that, compared to the conventional centralized generation-and-downloading scheme, the symbol number of the transmission of MEG is materially reduced. In addition, the proposed compression coding approach can improve the quality of generated images under low signal-to-noise ratio (SNR) conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05870v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruikang Zhong, Xidong Mu, Mona Jaber, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>Compute-Forward Multiple Access for Gaussian MIMO Channels</title>
      <link>https://arxiv.org/abs/2409.06110</link>
      <description>arXiv:2409.06110v1 Announce Type: new 
Abstract: Compute-forward multiple access (CFMA) is a multiple access transmission scheme based on Compute-and-Forward (CF) which allows the receiver to first decode linear combinations of the transmitted signals and then solve for individual messages. This paper extends the CFMA scheme to a two-user Gaussian multiple-input multiple-output (MIMO) multiple access channel (MAC). We propose the CFMA serial coding scheme (SCS) and the CFMA parallel coding scheme (PCS) with nested lattice codes. We first derive the expression of the achievable rate pair for MIMO MAC with CFMA-SCS. We prove a general condition under which CFMA-SCS can achieve the sum capacity of the channel. Furthermore, this result is specialized to single-input multiple-output (SIMO) and $2$-by-$2$ diagonal MIMO multiple access channels, for which more explicit sum capacity-achieving conditions on power and channel matrices are derived. We construct an equivalent SIMO model for CFMA-PCS and also derive the achievable rates. Its sum capacity achieving conditions are then analysed. Numerical results are provided for the performance of CFMA-SCS and CFMA-PCS in different channel conditions. In general, CFMA-PCS has better sum capacity achievability with higher coding complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06110v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lanwei Zhang, Jamie Evans, Jingge Zhu</dc:creator>
    </item>
    <item>
      <title>Generalized Approximate Message-Passing for Compressed Sensing with Sublinear Sparsity</title>
      <link>https://arxiv.org/abs/2409.06320</link>
      <description>arXiv:2409.06320v1 Announce Type: new 
Abstract: This paper addresses the reconstruction of an unknown signal vector with sublinear sparsity from generalized linear measurements. Generalized approximate message-passing (GAMP) is proposed via state evolution in the sublinear sparsity limit, where the signal dimension $N$, measurement dimension $M$, and signal sparsity $k$ satisfy $\log k/\log N\to \gamma\in[0, 1)$ and $M/\{k\log (N/k)\}\to\delta$ as $N$ and $k$ tend to infinity. While the overall flow in state evolution is the same as that for linear sparsity, each proof step for inner denoising requires stronger assumptions than those for linear sparsity. The required new assumptions are proved for Bayesian inner denoising. When Bayesian outer and inner denoisers are used in GAMP, the obtained state evolution recursion is utilized to evaluate the prefactor $\delta$ in the sample complexity, called reconstruction threshold. If and only if $\delta$ is larger than the reconstruction threshold, Bayesian GAMP can achieve asymptotically exact signal reconstruction. In particular, the reconstruction threshold is finite for noisy linear measurements when the support of non-zero signal elements does not include a neighborhood of zero. As numerical examples, this paper considers linear measurements and 1-bit compressed sensing. Numerical simulations for both cases show that Bayesian GAMP outperforms existing algorithms for sublinear sparsity in terms of the sample complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06320v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keigo Takeuchi</dc:creator>
    </item>
    <item>
      <title>Compute-Update Federated Learning: A Lattice Coding Approach</title>
      <link>https://arxiv.org/abs/2409.06343</link>
      <description>arXiv:2409.06343v1 Announce Type: new 
Abstract: This paper introduces a federated learning framework that enables over-the-air computation via digital communications, using a new joint source-channel coding scheme. Without relying on channel state information at devices, this scheme employs lattice codes to both quantize model parameters and exploit interference from the devices. We propose a novel receiver structure at the server, designed to reliably decode an integer combination of the quantized model parameters as a lattice point for the purpose of aggregation. We present a mathematical approach to derive a convergence bound for the proposed scheme and offer design remarks. In this context, we suggest an aggregation metric and a corresponding algorithm to determine effective integer coefficients for the aggregation in each communication round. Our results illustrate that, regardless of channel dynamics and data heterogeneity, our scheme consistently delivers superior learning accuracy across various parameters and markedly surpasses other over-the-air methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06343v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Seyed Mohammad Azimi-Abarghouyi, Lav R. Varshney</dc:creator>
    </item>
    <item>
      <title>New constructions of DNA codes under multiple constraints and parallel searching algorithms</title>
      <link>https://arxiv.org/abs/2409.06519</link>
      <description>arXiv:2409.06519v1 Announce Type: new 
Abstract: DNA codes have garnered significant interest due to their utilization in digital media storage, cryptography, and DNA computing. In this paper, we first extend the results of constructing reversible group codes \cite{Cengellenmis} and reversible composite group codes \cite{Korban5} to general even-order finite groups. By using these results, we give parallel searching algorithms to find some new DNA codes with better parameters. Secondly, by mapping codes over $\mathbb{F}_4$ to DNA codes, we establish a relationship between the $GC$-weight enumerator of DNA codes and the Hamming weight enumerator of their trace codes, which greatly improves the computational efficiency of searching for DNA codes. Based on this relationship, we propose an efficient algorithm for generating DNA codes with $50\%$ $GC$-content. Furthermore, we find that there is no direct connection between the $GC$-weight enumerator of a DNA code and the $GC$-weight enumerator of its dual code. Finally, we present algorithms for determining whether a DNA code is free from secondary structures or conflict-free, and some new DNA codes with better parameters under multiple constraints are obtained, which are listed in Tables 1 and 4.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06519v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guodong Wang, Hongwei Liu, Xueyan Chen</dc:creator>
    </item>
    <item>
      <title>A General Framework for Clustering and Distribution Matching with Bandit Feedback</title>
      <link>https://arxiv.org/abs/2409.05072</link>
      <description>arXiv:2409.05072v1 Announce Type: cross 
Abstract: We develop a general framework for clustering and distribution matching problems with bandit feedback. We consider a $K$-armed bandit model where some subset of $K$ arms is partitioned into $M$ groups. Within each group, the random variable associated to each arm follows the same distribution on a finite alphabet. At each time step, the decision maker pulls an arm and observes its outcome from the random variable associated to that arm. Subsequent arm pulls depend on the history of arm pulls and their outcomes. The decision maker has no knowledge of the distributions of the arms or the underlying partitions. The task is to devise an online algorithm to learn the underlying partition of arms with the least number of arm pulls on average and with an error probability not exceeding a pre-determined value $\delta$. Several existing problems fall under our general framework, including finding $M$ pairs of arms, odd arm identification, and $M$-ary clustering of $K$ arms belong to our general framework. We derive a non-asymptotic lower bound on the average number of arm pulls for any online algorithm with an error probability not exceeding $\delta$. Furthermore, we develop a computationally-efficient online algorithm based on the Track-and-Stop method and Frank--Wolfe algorithm, and show that the average number of arm pulls of our algorithm asymptotically matches that of the lower bound. Our refined analysis also uncovers a novel bound on the speed at which the average number of arm pulls of our algorithm converges to the fundamental limit as $\delta$ vanishes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05072v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Recep Can Yavas, Yuqi Huang, Vincent Y. F. Tan, Jonathan Scarlett</dc:creator>
    </item>
    <item>
      <title>OciorCOOL: Faster Byzantine Agreement and Reliable Broadcast</title>
      <link>https://arxiv.org/abs/2409.06008</link>
      <description>arXiv:2409.06008v1 Announce Type: cross 
Abstract: COOL (Chen'21) is an error-free and deterministic Byzantine agreement protocol that achieves consensus on an $\ell$-bit message with a communication complexity of $O(\max\{n\ell, n t \log t \})$ bits in four phases, given $n\geq 3t + 1$, for a network of $n$ nodes, where up to $t$ nodes may be dishonest. In this work we show that COOL can be optimized by reducing one communication round. The new protocol is called OciorCOOL. Additionally, building on OciorCOOL, we design an optimal reliable broadcast protocol that requires only six communication rounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06008v1</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinyuan Chen</dc:creator>
    </item>
    <item>
      <title>Typicality, entropy and the generalization of statistical mechanics</title>
      <link>https://arxiv.org/abs/2409.06537</link>
      <description>arXiv:2409.06537v1 Announce Type: cross 
Abstract: When at equilibrium, large-scale systems obey conventional thermodynamics because they belong to microscopic configurations (or states) that are typical. Crucially, the typical states usually represent only a small fraction of the total number of possible states, and yet the characterization of the set of typical states -- the typical set -- alone is sufficient to describe the macroscopic behavior of a given system. Consequently, the concept of typicality, and the associated Asymptotic Equipartition Property allow for a drastic reduction of the degrees of freedom needed for system's statistical description. The mathematical rationale for such a simplification in the description is due to the phenomenon of concentration of measure. The later emerges for equilibrium configurations thanks to very strict constraints on the underlying dynamics, such as weekly interacting and (almost) independent system constituents. The question naturally arises as to whether the concentration of measure and related typicality considerations can be extended and applied to more general complex systems, and if so, what mathematical structure can be expected in the ensuing generalized thermodynamics. In this paper we illustrate the relevance of the concept of typicality in the toy model context of the "thermalized" coin and show how this leads naturally to Shannon entropy. We also show an intriguing connection: The characterization of typical sets in terms of Renyi and Tsallis entropies naturally leads to the free energy and partition function, respectively, and makes their relationship explicit. Finally, we propose potential ways to generalize the concept of typicality to systems where the standard microscopic assumptions do not hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06537v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1140/epjb/s10051-024-00764-7</arxiv:DOI>
      <arxiv:journal_reference>Eur. Phys. J. B 97, 129 (2024)</arxiv:journal_reference>
      <dc:creator>Bernat Corominas-Murtra, Rudolf Hanel, Petr Jizba</dc:creator>
    </item>
    <item>
      <title>Reconfigurable Massive MIMO: Precoding Design and Channel Estimation in the Electromagnetic Domain</title>
      <link>https://arxiv.org/abs/2405.02823</link>
      <description>arXiv:2405.02823v2 Announce Type: replace 
Abstract: Reconfigurable massive multiple-input multiple-output (RmMIMO) technology offers increased flexibility for future communication systems by exploiting previously untapped degrees of freedom in the electromagnetic (EM) domain. The representation of the traditional spatial domain channel state information (sCSI) limits the insights into the potential of EM domain channel properties, constraining the base station's (BS) utmost capability for precoding design. This paper leverages the EM domain channel state information (eCSI) for antenna radiation patterns design at the BS. We develop an orthogonal decomposition method based on spherical harmonic functions to decompose the radiation pattern into a linear combination of orthogonal bases. By formulating the radiation pattern design as an optimization problem for the projection coefficients over these bases, we develop a manifold optimization-based method for iterative radiation pattern and digital precoder design. To address the eCSI estimation problem, we capitalize on the inherent structure of the channel. Specifically, we propose a subspace-based scheme to reduce the pilot overhead for wideband sCSI estimation. Given the estimated full-band sCSI, we further employ parameterized methods for angle of arrival estimation. Subsequently, the complete eCSI can be reconstructed after estimating the equivalent channel gain via the least squares method. Simulation results demonstrate that, in comparison to traditional mMIMO systems with fixed antenna radiation patterns, the proposed RmMIMO architecture offers significant throughput gains for multi-user transmission at a low channel estimation overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02823v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keke Ying, Zhen Gao, Yu Su, Tong Qin, Michail Matthaiou, Robert Schober</dc:creator>
    </item>
    <item>
      <title>Efficient entanglement purification based on noise guessing decoding</title>
      <link>https://arxiv.org/abs/2310.19914</link>
      <description>arXiv:2310.19914v3 Announce Type: replace-cross 
Abstract: In this paper, we propose a novel bipartite entanglement purification protocol built upon hashing and upon the guessing random additive noise decoding (GRAND) approach recently devised for classical error correction codes. Our protocol offers substantial advantages over existing hashing protocols, requiring fewer qubits for purification, achieving higher fidelities, and delivering better yields with reduced computational costs. We provide numerical and semi-analytical results to corroborate our findings and provide a detailed comparison with the hashing protocol of Bennet et al. Although that pioneering work devised performance bounds, it did not offer an explicit construction for implementation. The present work fills that gap, offering both an explicit and more efficient purification method. We demonstrate that our protocol is capable of purifying states with noise on the order of 10% per Bell pair even with a small ensemble of 16 pairs. The work explores a measurement-based implementation of the protocol to address practical setups with noise. This work opens the path to practical and efficient entanglement purification using hashing-based methods with feasible computational costs. Compared to the original hashing protocol, the proposed method can achieve some desired fidelity with a number of initial resources up to one hundred times smaller. Therefore, the proposed method seems well-fit for future quantum networks with a limited number of resources and entails a relatively low computational overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.19914v3</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andr\'e Roque, Diogo Cruz, Francisco A. Monteiro, Bruno C. Coutinho</dc:creator>
    </item>
    <item>
      <title>Can Large Language Models Learn Independent Causal Mechanisms?</title>
      <link>https://arxiv.org/abs/2402.02636</link>
      <description>arXiv:2402.02636v2 Announce Type: replace-cross 
Abstract: Despite impressive performance on language modelling and complex reasoning tasks, Large Language Models (LLMs) fall short on the same tasks in uncommon settings or with distribution shifts, exhibiting a lack of generalisation ability. By contrast, systems such as causal models, that learn abstract variables and causal relationships, can demonstrate increased robustness against changes in the distribution. One reason for this success is the existence and use of Independent Causal Mechanisms (ICMs) representing high-level concepts that only sparsely interact. In this work, we apply two concepts from causality to learn ICMs within LLMs. We develop a new LLM architecture composed of multiple sparsely interacting language modelling modules. We show that such causal constraints can improve out-of-distribution performance on abstract and causal reasoning tasks. We also investigate the level of independence and domain specialisation and show that LLMs rely on pre-trained partially domain-invariant mechanisms resilient to fine-tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02636v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ga\"el Gendron, Bao Trung Nguyen, Alex Yuxuan Peng, Michael Witbrock, Gillian Dobbie</dc:creator>
    </item>
    <item>
      <title>Transmit and Receive Antenna Port Selection for Channel Capacity Maximization in Fluid-MIMO Systems</title>
      <link>https://arxiv.org/abs/2404.06072</link>
      <description>arXiv:2404.06072v2 Announce Type: replace-cross 
Abstract: In this letter, we study a discrete optimization problem, namely, the maximization of channel capacity in fluid multiple-input multiple-output (fluid-MIMO) systems through the selection of antenna ports/positions at both the transmitter and the receiver. First, we present a new joint convex relaxation (JCR) problem by using an upper bound on the channel capacity and exploiting the binary nature of optimization variables. Then, we develop and analyze two optimization algorithms with different performance-complexity tradeoffs. The first algorithm is based on JCR and reduced exhaustive search (JCR&amp;RES), while the second on JCR and alternating optimization (JCR&amp;AO).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06072v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LWC.2024.3458417</arxiv:DOI>
      <dc:creator>Christos N. Efrem, Ioannis Krikidis</dc:creator>
    </item>
    <item>
      <title>Pre-Training and Personalized Fine-Tuning via Over-the-Air Federated Meta-Learning: Convergence-Generalization Trade-Offs</title>
      <link>https://arxiv.org/abs/2406.11569</link>
      <description>arXiv:2406.11569v2 Announce Type: replace-cross 
Abstract: For modern artificial intelligence (AI) applications such as large language models (LLMs), the training paradigm has recently shifted to pre-training followed by fine-tuning. Furthermore, owing to dwindling open repositories of data and thanks to efforts to democratize access to AI models, pre-training is expected to increasingly migrate from the current centralized deployments to federated learning (FL) implementations. Meta-learning provides a general framework in which pre-training and fine-tuning can be formalized. Meta-learning-based personalized FL (meta-pFL) moves beyond basic personalization by targeting generalization to new agents and tasks. This paper studies the generalization performance of meta-pFL for a wireless setting in which the agents participating in the pre-training phase, i.e., meta-learning, are connected via a shared wireless channel to the server. Adopting over-the-air computing, we study the trade-off between generalization to new agents and tasks, on the one hand, and convergence, on the other hand. The trade-off arises from the fact that channel impairments may enhance generalization, while degrading convergence. Extensive numerical results validate the theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11569v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haifeng Wen, Hong Xing, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Reliability Function of Classical-Quantum Channels</title>
      <link>https://arxiv.org/abs/2407.12403</link>
      <description>arXiv:2407.12403v2 Announce Type: replace-cross 
Abstract: We study the reliability function of general classical-quantum channels, which describes the optimal exponent of the decay of decoding error when the communication rate is below the capacity. As main result, we prove a lower bound, in terms of the quantum Renyi information in Petz's form, for the reliability function. This resolves Holevo's conjecture proposed in 2000, a long-standing open problem in quantum information theory. It turns out that the obtained lower bound matches the upper bound derived by Dalai in 2013, when the communication rate is above a critical value. Thus we have determined the reliability function in this high-rate case. Our approach relies on Renes' breakthrough made in 2022, which relates classical-quantum channel coding to that of privacy amplification, as well as our new characterization of the channel Renyi information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12403v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 11 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ke Li, Dong Yang</dc:creator>
    </item>
  </channel>
</rss>
