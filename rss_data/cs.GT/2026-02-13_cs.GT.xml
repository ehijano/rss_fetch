<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Feb 2026 13:07:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Computing stable limit cycles of learning in games</title>
      <link>https://arxiv.org/abs/2602.11315</link>
      <description>arXiv:2602.11315v1 Announce Type: new 
Abstract: Many well-studied learning dynamics, such as fictitious play and the replicator, are known to not converge in general $N$-player games. The simplest mode of non-convergence is cyclical or periodic behavior. Such cycles are fundamental objects, and have inspired a number of significant insights in the field, beginning with the pioneering work of Shapley (1964). However a central question remains unanswered: which cycles are stable under game dynamics? In this paper we give a complete and computational answer to this question for the two best-studied dynamics, fictitious play/best-response dynamics and the replicator dynamic. We show (1) that a periodic sequence of profiles is stable under one of these dynamics if and only it is stable under the other, and (2) we provide a polynomial-time spectral stability test to determine whether a given periodic sequence is stable under either dynamic. Finally, we give an entirely `structural' sufficient condition for stability: every cycle that is a sink equilibrium of the preference graph of the game is stable, and moreover it is an attractor of the replicator dynamic. This result generalizes the famous theorems of Shapley (1964) and Jordan (1993), and extends the frontier of recent work relating the preference graph to the replicator attractors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11315v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oliver Biggar, Christos Papadimitriou</dc:creator>
    </item>
    <item>
      <title>When agents choose bundles autonomously: guarantees beyond discrepancy</title>
      <link>https://arxiv.org/abs/2602.11330</link>
      <description>arXiv:2602.11330v1 Announce Type: new 
Abstract: We consider the fair division of indivisible items among $n$ agents with additive non-negative normalized valuations, with the goal of obtaining high value guarantees, that is, close to the proportional share for each agent.
  We prove that partitions where \emph{every} part yields high value for each agent are asymptotically limited by a discrepancy barrier of $\Theta(\sqrt{n})$. Guided by this, our main objective is to overcome this barrier and achieve stronger individual guarantees for each agent in polynomial time.
  Towards this, we are able to exhibit an exponential improvement over the discrepancy barrier. In particular, we can create partitions on-the-go such that when agents arrive sequentially (representing a previously-agreed priority order) and pick a part autonomously and rationally (i.e., one of highest value), then each is guaranteed a part of value at least $\mathsf{PROP} - \mathcal{O}{(\log n)}$. Moreover, we show even better guarantees for three restricted valuation classes such as those defined by: a common ordering on items, a bound on the multiplicity of values, and a hypergraph with a bound on the \emph{influence} of any agent. Specifically, we study instances where: (1) the agents are ``close'' to unanimity in their relative valuation of the items -- a generalization of the ordered additive setting; (2) the valuation functions do not assign the same positive value to more than $t$ items; and (3) the valuation functions respect a hypergraph, a setting introduced by Christodoulou et al. [EC'23], where agents are vertices and items are hyperedges. While the sizes of the hyperedges and neighborhoods can be arbitrary, the influence of any agent $a$, defined as the number of its neighbors who value at least one item positively that $a$ also values positively, is bounded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11330v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sushmita Gupta, Pallavi Jain, Sanjay Seetharaman, Meirav Zehavi</dc:creator>
    </item>
    <item>
      <title>Maximizing Index Diversity in Committee Elections</title>
      <link>https://arxiv.org/abs/2602.11400</link>
      <description>arXiv:2602.11400v1 Announce Type: new 
Abstract: We introduce two models of multiwinner elections with approval preferences and labelled candidates that take the committee's diversity into account. One model aims to find a committee with maximal diversity given a scoring function (e.g. of a scoring-based voting rule) and a lower bound for the score to be respected. The second model seeks to maximize the diversity given a minimal satisfaction for each agent to be respected. To measure the diversity of a committee, we use multiple diversity indices used in ecology and introduce one new index. We define (desirable) properties of diversity indices, test the indices considered against these properties, and characterize the new index. We analyze the computational complexity of computing a committee for both models and scoring functions of well-known voting rules, and investigate the influence of weakening the score or satisfaction constraints on the diversity empirically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11400v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paula B\"ohm, Robert Bredereck, Till Fluschnik</dc:creator>
    </item>
    <item>
      <title>The Distortion of Prior-Independent b-Matching Mechanisms</title>
      <link>https://arxiv.org/abs/2602.11404</link>
      <description>arXiv:2602.11404v1 Announce Type: new 
Abstract: In a setting where $m$ items need to be partitioned among $n$ agents, we evaluate the performance of mechanisms that take as input each agent's \emph{ordinal preferences}, i.e., their ranking of the items from most- to least-preferred. The standard measure for evaluating ordinal mechanisms is the \emph{distortion}, and the vast majority of the literature on distortion has focused on worst-case analysis, leading to some overly pessimistic results. We instead evaluate the distortion of mechanisms with respect to their expected performance when the agents' preferences are generated stochastically. We first show that no ordinal mechanism can achieve a distortion better than $e/(e-1)\approx 1.582$, even if each agent needs to receive exactly one item (i.e., $m=n$) and every agent's values for different items are drawn i.i.d.\ from the same known distribution. We then complement this negative result by proposing an ordinal mechanism that achieves the optimal distortion of $e/(e-1)$ even if each agent's values are drawn from an agent-specific distribution that is unknown to the mechanism. To further refine our analysis, we also optimize the \emph{distortion gap}, i.e., the extent to which an ordinal mechanism approximates the optimal distortion possible for the instance at hand, and we propose a mechanism with a near-optimal distortion gap of $1.076$. Finally, we also evaluate the distortion and distortion gap of simple mechanisms that have a one-pass structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11404v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis Caragiannis, Vasilis Gkatzelis, Sebastian Homrighausen</dc:creator>
    </item>
    <item>
      <title>Fair Data-Exchange Mechanisms</title>
      <link>https://arxiv.org/abs/2602.11417</link>
      <description>arXiv:2602.11417v1 Announce Type: new 
Abstract: We study data exchange among strategic agents without monetary transfers, motivated by domains such as research consortia and healthcare collaborations where payments are infeasible or restricted. The central challenge is to reap the benefits of data-sharing while preventing free-riding that would otherwise lead agents to under invest in data collection. We introduce a simple fair-exchange contract in which, for every pair of agents, each agent receives exactly as many data points as it provides, equal to the minimum of their two collection levels. We show that the game induced by this contract is supermodular under a transformation of the strategy space. This results in a clean structure: pure Nash equilibria exist, they form a lattice, and can be computed in time quadratic in the number of agents. In addition, the maximal equilibrium is truthfully implementable under natural enforcement assumptions and is globally Pareto-optimal across all strategy profiles. In a graph-restricted variant of the model supermodularity fails, but an adaptation of the construction still yields efficiently computable pure Nash equilibria and Pareto-optimal outcomes. Overall, fair exchange provides a tractable and incentive-aligned mechanism for data exchange in the absence of payments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11417v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rashida Hakim, Christos Papadimitriou, Mihalis Yannakakis</dc:creator>
    </item>
    <item>
      <title>Dueling over Multiple Pieces of Dessert</title>
      <link>https://arxiv.org/abs/2602.11486</link>
      <description>arXiv:2602.11486v1 Announce Type: new 
Abstract: We study the dynamics of repeated fair division between two players, Alice and Bob, where Alice partitions a cake into two subsets and Bob chooses his preferred one over $T$ rounds. Alice aims to minimize her regret relative to the Stackelberg value -- the maximum utility she could achieve if she knew Bob's private valuation.
  We show that if Alice uses arbitrary measurable partitions, achieving strongly sublinear regret is impossible; she suffers a regret of $\Omega\Bigl(\frac{T}{\log^2 T}\Bigr)$ regret even against a myopic Bob. However, when Alice uses at most $k$ cuts, the learning landscape becomes tractable. We analyze Alice's performance based on her knowledge of Bob's strategic sophistication (his regret budget). When Bob's learning rate is public, we establish a hierarchy of polynomial regret bounds determined by $k$ and Bob's regret budget. In contrast, when this learning rate is private, Alice can universally guarantee $O\Bigl(\frac{T}{\log T}\Bigr)$ regret, but any attempt to secure a polynomial rate $O(T^\beta)$ (for $\beta &lt; 1$) leaves her vulnerable to incurring strictly linear regret against some Bob.
  Finally, as a corollary of our online learning dynamics, we characterize the randomized query complexity of finding approximate Stackelberg allocations with a constant number of cuts in the Robertson-Webb model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11486v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simina Br\^anzei, Reed Phillips</dc:creator>
    </item>
    <item>
      <title>Searching for Optimal Prices in Two-Sided Markets</title>
      <link>https://arxiv.org/abs/2602.11691</link>
      <description>arXiv:2602.11691v1 Announce Type: new 
Abstract: We investigate online pricing in two-sided markets where a platform repeatedly posts prices based on binary accept/reject feedback to maximize gains-from-trade (GFT) or profit. We characterize the regret achievable across three mechanism classes: Single-Price, Two-Price, and Segmented-Price.
  For profit maximization, we design an algorithm using Two-Price Mechanisms that achieves $O(n^2 \log\log T)$ regret, where $n$ is the number of traders.
  For GFT maximization, the optimal regret depends critically on both market size and mechanism expressiveness. Constant regret is achievable in bilateral trade, but this guarantee breaks down as the market grows: even in a one-seller, two-buyer market, any algorithm using Single-Price Mechanisms suffers regret at least $\Omega\!\big(\frac{\log\log T}{\log\log\log\log T}\big)$, and we provide a nearly matching $O(\log\log T)$ upper bound for general one-to-many markets. In full many-to-many markets, we prove that Two-Price Mechanisms inevitably incur linear regret $\Omega(T)$ due to a \emph{mismatch phenomenon}, wherein inefficient pairings prevent near-optimal trade. To overcome this barrier, we introduce \emph{Segmented-Price Mechanisms}, which partition traders into groups and assign distinct prices per group. Using this richer mechanism, we design an algorithm achieving $O(n^2 \log\log T + n^3)$ regret for GFT maximization.
  Finally, we extend our results to the contextual setting, where traders' costs and values depend linearly on observed $d$-dimensional features that vary across rounds, obtaining regret bounds of $O(n^2 d \log\log T + n^2 d \log d)$ for profit and $O(n^2 d^2 \log T)$ for GFT. Our work delineates sharp boundaries between learnable and unlearnable regimes in two-sided dynamic pricing and demonstrates how modest increases in pricing expressiveness can circumvent fundamental hardness barriers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11691v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiding Feng, Mengfan Ma, Bo Peng, Zongqi Wan</dc:creator>
    </item>
    <item>
      <title>Achieving EF1 and Epistemic EFX Guarantees Simultaneously</title>
      <link>https://arxiv.org/abs/2602.11732</link>
      <description>arXiv:2602.11732v1 Announce Type: new 
Abstract: We study the fundamental problem of fairly dividing a set of indivisible goods among agents with additive valuations. Here, envy-freeness up to any good (EFX) is a central fairness notion and resolving its existence is regarded as one of the most important open problems in this area of research. Two prominent relaxations of EFX are envy-freeness up to one good (EF1) and epistemic EFX (EEFX). While allocations satisfying each of these notions individually are known to exist even for general monotone valuations, whether both can be satisfied simultaneously remains open for all instances in which the EFX problem is itself unresolved.
  In this work, we show that there always exists an allocation that is both EF1 (in fact, the stronger notion EFL) and EEFX for additive valuations, thereby resolving the primary open question raised by Akrami and Rathi (2025) and bringing us one step closer to resolving the elusive EFX problem. We introduce a new share-based fairness notion, termed strong EEFX share, which may be of independent interest and which implies EEFX feasibility of bundles. We show that this notion is compatible with EF1, leading to the desired existence result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11732v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannaneh Akrami, Ryoga Mahara, Kurt Mehlhorn, Nidhi Rathi</dc:creator>
    </item>
    <item>
      <title>Global Convergence to Nash Equilibrium in Nonconvex General-Sum Games under the $n$-Sided PL Condition</title>
      <link>https://arxiv.org/abs/2602.11835</link>
      <description>arXiv:2602.11835v1 Announce Type: new 
Abstract: We consider the problem of finding a Nash equilibrium (NE) in a general-sum game, where player $i$'s objective is $f_i(x)=f_i(x_1,...,x_n)$, with $x_j\in\mathbb{R}^{d_j}$ denoting the strategy variables of player $j$. Our focus is on investigating first-order gradient-based algorithms and their variations, such as the block coordinate descent (BCD) algorithm, for tackling this problem. We introduce a set of conditions, called the $n$-sided PL condition, which extends the well-established gradient dominance condition a.k.a Polyak-{\L}ojasiewicz (PL) condition and the concept of multi-convexity. This condition, satisfied by various classes of non-convex functions, allows us to analyze the convergence of various gradient descent (GD) algorithms. Moreover, our study delves into scenarios where the standard gradient descent methods fail to converge to NE. In such cases, we propose adapted variants of GD that converge towards NE and analyze their convergence rates. Finally, we evaluate the performance of the proposed algorithms through several experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11835v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>The 25th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2026)</arxiv:journal_reference>
      <dc:creator>Yutong Chao, Jalal Etesami</dc:creator>
    </item>
    <item>
      <title>Scale-Invariant Fast Convergence in Games</title>
      <link>https://arxiv.org/abs/2602.11857</link>
      <description>arXiv:2602.11857v1 Announce Type: new 
Abstract: Scale-invariance in games has recently emerged as a widely valued desirable property. Yet, almost all fast convergence guarantees in learning in games require prior knowledge of the utility scale. To address this, we develop learning dynamics that achieve fast convergence while being both scale-free, requiring no prior information about utilities, and scale-invariant, remaining unchanged under positive rescaling of utilities. For two-player zero-sum games, we obtain scale-free and scale-invariant dynamics with external regret bounded by $\tilde{O}(A_{\mathrm{diff}})$, where $A_{\mathrm{diff}}$ is the payoff range, which implies an $\tilde{O}(A_{\mathrm{diff}} / T)$ convergence rate to Nash equilibrium after $T$ rounds. For multiplayer general-sum games with $n$ players and $m$ actions, we obtain scale-free and scale-invariant dynamics with swap regret bounded by $O(U_{\mathrm{max}} \log T)$, where $U_{\mathrm{max}}$ is the range of the utilities, ignoring the dependence on the number of players and actions. This yields an $O(U_{\mathrm{max}} \log T / T)$ convergence rate to correlated equilibrium. Our learning dynamics are based on optimistic follow-the-regularized-leader with an adaptive learning rate that incorporates the squared path length of the opponents' gradient vectors, together with a new stopping-time analysis that exploits negative terms in regret bounds without scale-dependent tuning. For general-sum games, scale-free learning is enabled also by a technique called doubling clipping, which clips observed gradients based on past observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11857v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taira Tsuchiya, Haipeng Luo, Shinji Ito</dc:creator>
    </item>
    <item>
      <title>Incentive Effects of a Cut-Off Score: Optimal Contest Design with Transparent Pre-Selection</title>
      <link>https://arxiv.org/abs/2602.11914</link>
      <description>arXiv:2602.11914v1 Announce Type: new 
Abstract: Shortlisting is a common and effective method for pre-selecting participants in competitive settings. To ensure fairness, a cut-off score is typically announced, allowing only contestants who exceed it to enter the contest, while others are eliminated. In this paper, we study rank-order contests with shortlisting and cut-off score disclosure. We fully characterize the equilibrium behavior of shortlisted contestants for any given prize structure and shortlist size. We examine two objective functions: the highest individual performance and total performance. For both objectives, the optimal contest is in a winner-take-all format. For the highest individual performance, the optimal shortlist size is exactly two contestants, but, in contrast, for total performance, the shortlist size does not affect the outcome, i.e., any size yields the same total performance. Furthermore, we compare the highest individual performance achieved with and without shortlisting, and show that the former is 4/3 times greater than the latter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11914v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanbing Liu, Ningyuan Li, Weian Li, Qi Qi, Changyuan Yu</dc:creator>
    </item>
    <item>
      <title>Strengthening Bulow-Klemperer-Style Results for Multi-Unit Auctions</title>
      <link>https://arxiv.org/abs/2602.11959</link>
      <description>arXiv:2602.11959v1 Announce Type: new 
Abstract: The classic result of Bulow and Klemperer (1996) shows that in multi-unit auctions with $m$ units and $n\geq m$ buyers whose values are sampled i.i.d. from a regular distribution, the revenue of the VCG auction with $m$ additional buyers is at least as large as the optimal revenue. Unfortunately, for regular distributions, adding $m$ additional buyers is sometimes indeed necessary, so the "competition complexity" of the VCG auction is $m$. We seek proving better competition complexity results in two dimensions.
  First, under stronger distributional assumptions, the competition complexity of VCG auction drops dramatically. In balanced markets (where $m=n$) with MHR distributions, it is sufficient to only add $(e^{1/e} - 1 + o(1))n \approx 0.4447n$ additional buyers to match the optimal revenue -- less than half the number that is necessary under regularity -- and this bound is asymptotically tight. We provide both exact finite-market results for small value of $n$, and closed-form asymptotic formulas for general market with any $m\leq n$, and any target fraction of the optimal revenue.
  Second, we analyze a supply-limiting variant of VCG auction that caps the number of units sold in a prior-independent way. Whenever the goal is to achieve almost the optimal revenue, this mechanism strictly improves upon standard VCG auction, requiring significantly fewer additional buyers.
  Together, our results show that both stronger distributional assumptions, as well as a simple prior-independent refinement to the VCG auction, can each substantially reduce the number of additional buyers that is sufficient to achieve (near-)optimal revenue. Our analysis hinges on a unified worst-case reduction to truncated generalized Pareto distributions, enabling both numerical computation and analytical tractability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11959v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moshe Babaioff, Yiding Feng, Zihan Luo</dc:creator>
    </item>
    <item>
      <title>Pareto-Efficient Multi-Buyer Mechanisms: Characterization, Fairness and Welfare</title>
      <link>https://arxiv.org/abs/2602.11967</link>
      <description>arXiv:2602.11967v1 Announce Type: new 
Abstract: A truthful mechanism for a Bayesian single-item auction results with some ex-ante revenue for the seller, and some ex-ante total surplus for the buyers. We study the Pareto frontier of the set of seller-buyers ex-ante utilities, generated by all truthful mechanisms when buyers values are sampled independently and identically (i.i.d.). We first provide a complete structural characterization of the Pareto frontier under natural distributional assumptions. For example, when valuations are drawn i.i.d. from a distribution that is both regular and anti-MHR, every Pareto-optimal mechanism is a second-price auction with a reserve no larger than the monopoly reserve.
  Building on this, we interpret the problem of picking a mechanism as a two-sided bargaining game, and analyze two canonical Pareto-optimal solutions from cooperative bargaining theory: the Kalai-Smorodinsky (KS) solution, and the Nash solution. We prove that when values are drawn i.i.d. from a distribution that is both regular and anti-MHR, in large markets both solutions yield near-optimal welfare. In contrast, under worst-case MHR distributions, their performance diverges sharply: the KS solution guarantees one-half of the optimal welfare, while the Nash solution might only achieve an arbitrarily small fraction of it. These results highlight the sensitivity of fairness-efficiency tradeoffs to distributional structure, and affirm the KS solution as the more robust notion of fairness for asymmetric two-sided markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11967v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moshe Babaioff, Sijin Chen, Zhaohua Chen, Yiding Feng</dc:creator>
    </item>
    <item>
      <title>Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation</title>
      <link>https://arxiv.org/abs/2602.12089</link>
      <description>arXiv:2602.12089v1 Announce Type: new 
Abstract: As AI usage becomes more prevalent in social contexts, understanding agent-user interaction is critical to designing systems that improve both individual and group outcomes. We present an online behavioral experiment (N = 243) in which participants play three multi-turn bargaining games in groups of three. Each game, presented in randomized order, grants \textit{access to} a single LLM assistance modality: proactive recommendations from an \textit{Advisor}, reactive feedback from a \textit{Coach}, or autonomous execution by a \textit{Delegate}; all modalities are powered by an underlying LLM that achieves superhuman performance in an all-agent environment. On each turn, participants privately decide whether to act manually or use the AI modality available in that game. Despite preferring the \textit{Advisor} modality, participants achieve the highest mean individual gains with the \textit{Delegate}, demonstrating a preference-performance misalignment. Moreover, delegation generates positive externalities; even non-adopting users in \textit{access-to-delegate} treatment groups benefit by receiving higher-quality offers. Mechanism analysis reveals that the \textit{Delegate} agent acts as a market maker, injecting rational, Pareto-improving proposals that restructure the trading environment. Our research reveals a gap between agent capabilities and realized group welfare. While autonomous agents can exhibit super-human strategic performance, their impact on realized welfare gains can be constrained by interfaces, user perceptions, and adoption barriers. Assistance modalities should be designed as mechanisms with endogenous participation; adoption-compatible interaction rules are a prerequisite to improving human welfare with automated assistance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12089v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kehang Zhu, Lithium Thain, Vivian Tsai, James Wexler, Crystal Qian</dc:creator>
    </item>
    <item>
      <title>Anonymous Contracts</title>
      <link>https://arxiv.org/abs/2602.12118</link>
      <description>arXiv:2602.12118v1 Announce Type: new 
Abstract: We study a multi-agent contracting problem where agents exert costly effort to achieve individually observable binary outcomes. While the principal can theoretically extract the full social welfare using a discriminatory contract that tailors payments to individual costs, such contracts may be perceived as unfair. In this work, we introduce and analyze anonymous contracts, where payments depend solely on the total number of successes, ensuring identical treatment of agents.
  We first establish that every anonymous contract admits a pure Nash equilibrium. However, because general anonymous contracts can suffer from multiple equilibria with unbounded gaps in principal utility, we identify uniform anonymous contracts as a desirable subclass. We prove that uniform anonymous contracts guarantee a unique equilibrium, thereby providing robust performance guarantees.
  In terms of efficiency, we prove that under limited liability, anonymous contracts cannot generally approximate the social welfare better than a factor logarithmic in the spread of agent success probabilities. We show that uniform contracts are sufficient to match this theoretical limit. Finally, we demonstrate that removing limited liability significantly boosts performance: anonymous contracts generally achieve an $O(\log n)$ approximation to the social welfare and, surprisingly, can extract the full welfare whenever agents' success probabilities are distinct. This reveals a structural reversal: widely spread probabilities are the hardest case under limited liability, whereas identical probabilities become the hardest case when limited liability is removed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12118v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Brustle, Paul Duetting, Stefano Leonardi, Tomasz Ponitka, Matteo Russo</dc:creator>
    </item>
    <item>
      <title>Convex Markov Games and Beyond: New Proof of Existence, Characterization and Learning Algorithms for Nash Equilibria</title>
      <link>https://arxiv.org/abs/2602.12181</link>
      <description>arXiv:2602.12181v1 Announce Type: new 
Abstract: Convex Markov Games (cMGs) were recently introduced as a broad class of multi-agent learning problems that generalize Markov games to settings where strategic agents optimize general utilities beyond additive rewards. While cMGs expand the modeling frontier, their theoretical foundations, particularly the structure of Nash equilibria (NE) and guarantees for learning algorithms, are not yet well understood. In this work, we address these gaps for an extension of cMGs, which we term General Utility Markov Games (GUMGs), capturing new applications requiring coupling between agents' occupancy measures. We prove that in GUMGs, Nash equilibria coincide with the fixed points of projected pseudo-gradient dynamics (i.e., first-order stationary points), enabled by a novel agent-wise gradient domination property. This insight also yields a simple proof of NE existence using Brouwer's fixed-point theorem. We further show the existence of Markov perfect equilibria. Building on this characterization, we establish a policy gradient theorem for GUMGs and design a model-free policy gradient algorithm. For potential GUMGs, we establish iteration complexity guarantees for computing approximate-NE under exact gradients and provide sample complexity bounds in both the generative model and on-policy settings. Our results extend beyond prior work restricted to zero-sum cMGs, providing the first theoretical analysis of common-interest cMGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12181v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anas Barakat, Ioannis Panageas, Antonios Varvitsiotis</dc:creator>
    </item>
    <item>
      <title>Bandit Learning in Matching Markets with Interviews</title>
      <link>https://arxiv.org/abs/2602.12224</link>
      <description>arXiv:2602.12224v1 Announce Type: new 
Abstract: Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matching markets with interviews, modeling interviews as \textit{low-cost hints} that reveal partial preference information to both sides. Our framework departs from existing work by allowing firm-side uncertainty: firms, like agents, may be unsure of their own preferences and can make early hiring mistakes by hiring less preferred agents. To handle this, we extend the firm's action space to allow \emph{strategic deferral} (choosing not to hire in a round), enabling recovery from suboptimal hires and supporting decentralized learning without coordination. We design novel algorithms for (i) a centralized setting with an omniscient interview allocator and (ii) decentralized settings with two types of firm-side feedback. Across all settings, our algorithms achieve time-independent regret, a substantial improvement over the $O(\log T)$ regret bounds known for learning stable matchings without interviews. Also, under mild structured markets, decentralized performance matches the centralized counterpart up to polynomial factors in the number of agents and firms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12224v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>econ.TH</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amirmahdi Mirfakhar, Xuchuang Wang, Mengfan Xu, Hedyeh Beyhaghi, Mohammad Hajiesmaili</dc:creator>
    </item>
    <item>
      <title>Adjusted Winner: from Splitting to Selling</title>
      <link>https://arxiv.org/abs/2602.12231</link>
      <description>arXiv:2602.12231v1 Announce Type: new 
Abstract: The Adjusted Winner (AW) method is a fundamental procedure for the fair division of indivisible resources between two agents. However, its reliance on splitting resources can lead to practical complications. To address this limitation, we propose an extension of AW that allows the sale of selected resources under a budget constraint, with the proceeds subsequently redistributed, thereby aiming for allocations that remain as equitable as possible. Alongside developing this extended framework, we provide an axiomatic analysis that examines how equitability and envy-freeness are modified in our setting. We then formally define the resulting combinatorial problems, establish their computational complexity, and design a fully polynomial-time approximation scheme (FPTAS) to mitigate their inherent intractability. Finally, we complement our theoretical results with computer-based simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12231v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Bredereck, Bin Sun, Eyal Briman, Nimrod Talmon</dc:creator>
    </item>
    <item>
      <title>Is Online Linear Optimization Sufficient for Strategic Robustness?</title>
      <link>https://arxiv.org/abs/2602.12253</link>
      <description>arXiv:2602.12253v1 Announce Type: new 
Abstract: We consider bidding in repeated Bayesian first-price auctions. Bidding algorithms that achieve optimal regret have been extensively studied, but their strategic robustness to the seller's manipulation remains relatively underexplored. Bidding algorithms based on no-swap-regret algorithms achieve both desirable properties, but are suboptimal in terms of statistical and computational efficiency. In contrast, online gradient ascent is the only algorithm that achieves $O(\sqrt{TK})$ regret and strategic robustness [KSS24], where $T$ denotes the number of auctions and $K$ the number of bids.
  In this paper, we explore whether simple online linear optimization (OLO) algorithms suffice for bidding algorithms with both desirable properties. Our main result shows that sublinear linearized regret is sufficient for strategic robustness. Specifically, we construct simple black-box reductions that convert any OLO algorithm into a strategically robust no-regret bidding algorithm, in both known and unknown value distribution settings. For the known value distribution case, our reduction yields a bidding algorithm that achieves $O(\sqrt{T \log K})$ regret and strategic robustness (with exponential improvement on the $K$-dependence compared to [KSS24]). For the unknown value distribution case, our reduction gives a bidding algorithm with high-probability $O(\sqrt{T (\log K+\log(T/\delta)})$ regret and strategic robustness, while removing the bounded density assumption made in [KSS24].</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12253v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Haipeng Luo, Chen-Yu Wei, Weiqiang Zheng</dc:creator>
    </item>
    <item>
      <title>Cooperation Breakdown in LLM Agents Under Communication Delays</title>
      <link>https://arxiv.org/abs/2602.11754</link>
      <description>arXiv:2602.11754v1 Announce Type: cross 
Abstract: LLM-based multi-agent systems (LLM-MAS), in which autonomous AI agents cooperate to solve tasks, are gaining increasing attention. For such systems to be deployed in society, agents must be able to establish cooperation and coordination under real-world computational and communication constraints. We propose the FLCOA framework (Five Layers for Cooperation/Coordination among Autonomous Agents) to conceptualize how cooperation and coordination emerge in groups of autonomous agents, and highlight that the influence of lower-layer factors - especially computational and communication resources - has been largely overlooked. To examine the effect of communication delay, we introduce a Continuous Prisoner's Dilemma with Communication Delay and conduct simulations with LLM-based agents. As delay increases, agents begin to exploit slower responses even without explicit instructions. Interestingly, excessive delay reduces cycles of exploitation, yielding a U-shaped relationship between delay magnitude and mutual cooperation. These results suggest that fostering cooperation requires attention not only to high-level institutional design but also to lower-layer factors such as communication delay and resource allocation, pointing to new directions for MAS research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11754v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keita Nishimoto, Kimitaka Asatani, Ichiro Sakata</dc:creator>
    </item>
    <item>
      <title>Towards Sustainable Investment Policies Informed by Opponent Shaping</title>
      <link>https://arxiv.org/abs/2602.11829</link>
      <description>arXiv:2602.11829v1 Announce Type: cross 
Abstract: Addressing climate change requires global coordination, yet rational economic actors often prioritize immediate gains over collective welfare, resulting in social dilemmas. InvestESG is a recently proposed multi-agent simulation that captures the dynamic interplay between investors and companies under climate risk. We provide a formal characterization of the conditions under which InvestESG exhibits an intertemporal social dilemma, deriving theoretical thresholds at which individual incentives diverge from collective welfare. Building on this, we apply Advantage Alignment, a scalable opponent shaping algorithm shown to be effective in general-sum games, to influence agent learning in InvestESG. We offer theoretical insights into why Advantage Alignment systematically favors socially beneficial equilibria by biasing learning dynamics toward cooperative outcomes. Our results demonstrate that strategically shaping the learning processes of economic agents can result in better outcomes that could inform policy mechanisms to better align market incentives with long-term sustainability goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11829v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Agustin Duque, Razvan Ciuca, Ayoub Echchahed, Hugo Larochelle, Aaron Courville</dc:creator>
    </item>
    <item>
      <title>How Sampling Shapes LLM Alignment: From One-Shot Optima to Iterative Dynamics</title>
      <link>https://arxiv.org/abs/2602.12180</link>
      <description>arXiv:2602.12180v1 Announce Type: cross 
Abstract: Standard methods for aligning large language models with human preferences learn from pairwise comparisons among sampled candidate responses and regularize toward a reference policy. Despite their effectiveness, the effects of sampling and reference choices are poorly understood theoretically. We investigate these effects through Identity Preference Optimization, a widely used preference alignment framework, and show that proper instance-dependent sampling can yield stronger ranking guarantees, while skewed on-policy sampling can induce excessive concentration under structured preferences. We then analyze iterative alignment dynamics in which the learned policy feeds back into future sampling and reference policies, reflecting a common practice of model-generated preference data. We prove that these dynamics can exhibit persistent oscillations or entropy collapse for certain parameter choices, and characterize regimes that guarantee stability. Our theoretical insights extend to Direct Preference Optimization, indicating the phenomena we captured are common to a broader class of preference-alignment methods. Experiments on real-world preference data validate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12180v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yurong Chen, Yu He, Michael I. Jordan, Fan Yao</dc:creator>
    </item>
    <item>
      <title>Creative Ownership in the Age of AI</title>
      <link>https://arxiv.org/abs/2602.12270</link>
      <description>arXiv:2602.12270v1 Announce Type: cross 
Abstract: Copyright law focuses on whether a new work is "substantially similar" to an existing one, but generative AI can closely imitate style without copying content, a capability now central to ongoing litigation. We argue that existing definitions of infringement are ill-suited to this setting and propose a new criterion: a generative AI output infringes on an existing work if it could not have been generated without that work in its training corpus. To operationalize this definition, we model generative systems as closure operators mapping a corpus of existing works to an output of new works. AI generated outputs are \emph{permissible} if they do not infringe on any existing work according to our criterion. Our results characterize structural properties of permissible generation and reveal a sharp asymptotic dichotomy: when the process of organic creations is light-tailed, dependence on individual works eventually vanishes, so that regulation imposes no limits on AI generation; with heavy-tailed creations, regulation can be persistently constraining.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.12270v1</guid>
      <category>econ.TH</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Annie Liang, Jay Lu</dc:creator>
    </item>
    <item>
      <title>On the Fairness of Normalized p-Means for Allocating Goods and Chores</title>
      <link>https://arxiv.org/abs/2402.14996</link>
      <description>arXiv:2402.14996v2 Announce Type: replace 
Abstract: Allocating items in a fair and economically efficient manner is a central problem in fair division. We study this problem for agents with additive preferences, when items are all goods or all chores, divisible or indivisible. The celebrated notion of Nash welfare is known to produce fair and efficient allocations for both divisible and indivisible goods; there is no known analogue for dividing chores. The Nash welfare objective belongs to a large, parameterized family of objectives called the p-mean welfare functions, which includes other notable members, like social welfare and egalitarian welfare. However, among the members of this family, only the Nash welfare produces fair allocations for goods. Incidentally, Nash welfare is also the only member that satisfies the axiom of scale invariance, which is crucially associated with its fairness properties.
  We define the class of "normalized p-mean" objectives, which imparts the missing key axiom of scale invariance to the p-mean family. Our results show that optimizing the normalized p-mean objectives produces fair and efficient allocations when the items are goods or chores, divisible or indivisible. For instance, the normalized p-means gives us an infinite class of objectives that produce (i) proportional and Pareto efficient allocations for divisible goods, (ii) approximately proportional and Pareto efficient allocations for divisible chores, (iii) EF1 and Pareto efficient allocations for indivisible goods for two agents, and (iv) EF1 and Pareto efficient allocations for indivisible chores for two agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.14996v2</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Owen Eckart, Alexandros Psomas, Paritosh Verma</dc:creator>
    </item>
    <item>
      <title>Learning in Structured Stackelberg Games</title>
      <link>https://arxiv.org/abs/2504.09006</link>
      <description>arXiv:2504.09006v3 Announce Type: replace 
Abstract: We initiate the study of structured Stackelberg games, a novel form of strategic interaction between a leader and a follower where contextual information can be predictive of the follower's (unknown) type. Motivated by applications such as security games and AI safety, we show how this additional structure can help the leader learn a utility-maximizing policy in both the online and distributional settings. In the online setting, we first prove that standard learning-theoretic measures of complexity do not characterize the difficulty of the leader's learning task. Notably, we find that there exists a learning-theoretic measure of complexity, analogous to the Littlestone dimension in online classification, that tightly characterizes the leader's instance-optimal regret. We term this the Stackelberg-Littlestone dimension, and leverage it to provide a provably optimal online learning algorithm. In the distributional setting, we provide analogous results by showing that two new dimensions control the sample complexity upper- and lower-bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09006v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria-Florina Balcan, Kiriaki Fragkia, Keegan Harris</dc:creator>
    </item>
    <item>
      <title>The Keychain Problem: On Minimizing the Opportunity Cost of Uncertainty</title>
      <link>https://arxiv.org/abs/2509.06187</link>
      <description>arXiv:2509.06187v2 Announce Type: replace 
Abstract: In this paper, we introduce a family of sequential decision-making problems, collectively termed the Keychain Problem, that involve exploring a set of actions to maximize expected payoff when only a subset of actions are available in each stage. In an instance of the Keychain Problem, a locksmith faces a sequence of decisions, each of which involves selecting one key from a keychain (a subset of keys) to attempt to open a lock. Given a Bayesian prior on the effectiveness of keys, the locksmith's goal is to minimize the opportunity cost, which is the expected number of rounds in which the chain has a correct key but our selected key is incorrect.
  We study the computation of the Bayes optimal solution for Keychain Problems. Employing polynomial-time reductions, we establish formal connections between natural variants of the Keychain Problem and well-studied algorithmic economics problems on bipartite graphs. When the keychain order is known to the locksmith, we show that it reduces to Maximum Weight Bipartite Matching (MWBM). More general is the situation when the keychain order is sampled from a prior distribution (possibly correlated with the correct key). Here the Keychain Problem reduces to a novel generalization of MWBM which we coin the Maximum Weight Laminar Matching, which then further reduces to combinatorial auctions under XOS valuation functions. Finally, we show that when the locksmith can choose the keychain order, the Keychain problem reduces from a classic NP-hard combinatorial problem, again, on bipartite graphs. Besides implying algorithmic results and deepening our structural understanding about the Keychain Problem, our established reductions also find applications beyond -- for example, to the Philosopher Inequality for online bipartite matching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06187v2</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ramiro N. Deo-Campo Vuong, Robert Kleinberg, Aditya Prasad, Eric Xiao, Haifeng Xu</dc:creator>
    </item>
    <item>
      <title>The Architecture of Illusion: Network Opacity and Strategic Escalation</title>
      <link>https://arxiv.org/abs/2602.10053</link>
      <description>arXiv:2602.10053v2 Announce Type: replace 
Abstract: Standard models of bounded rationality typically assume agents either possess accurate knowledge of the population's reasoning abilities (Cognitive Hierarchy) or hold dogmatic, degenerate beliefs (Level-$k$). We introduce the ``Connected Minds'' model, which unifies these frameworks by integrating iterative reasoning with a parameterized network bias. We posit that agents do not observe the global population; rather, they observe a sample biased by their network position, governed by a locality parameter $p$ representing algorithmic ranking, social homophily, or information disclosure. We show that this parameter acts as a continuous bridge: the model collapses to the myopic Level-$k$ recursion as networks become opaque ($p \to 0$) and recovers the standard Cognitive Hierarchy model under full transparency ($p=1$). Theoretically, we establish that network opacity induces a \emph{Sophisticated Bias}, causing agents to systematically overestimate the cognitive depth of their opponents while preserving the log-concavity of belief distributions. This makes $p$ an actionable lever: a planner or platform can tune transparency, globally or by segment (a personalized $p_k$), to shape equilibrium behavior. From a mechanism design perspective, we derive the \emph{Escalation Principle}: in games of strategic complements, restricting information can maximize aggregate effort by trapping agents in echo chambers where they compete against hallucinated, high-sophistication peers. Conversely, we identify a \emph{Transparency Reversal} for coordination games, where maximizing network visibility is required to minimize variance and stabilize outcomes. Our results suggest that network topology functions as a cognitive zoom lens, determining whether agents behave as local imitators or global optimizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10053v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raman Ebrahimi, Sepehr Ilami, Babak Heydari, Isabel Trevino, Massimo Franceschetti</dc:creator>
    </item>
    <item>
      <title>Equity by Design: Fairness-Driven Recommendation in Heterogeneous Two-Sided Markets</title>
      <link>https://arxiv.org/abs/2602.10739</link>
      <description>arXiv:2602.10739v2 Announce Type: replace 
Abstract: Two-sided marketplaces embody heterogeneity in incentives: producers seek exposure while consumers seek relevance, and balancing these competing objectives through constrained optimization is now a standard practice. Yet real platforms face finer-grained complexity: consumers differ in preferences and engagement patterns, producers vary in catalog value and capacity, and business objectives impose additional constraints beyond raw relevance. We formalize two-sided fairness under these realistic conditions, extending prior work from soft single-item allocations to discrete multi-item recommendations. We introduce Conditional Value-at-Risk (CVaR) as a consumer-side objective that compresses group-level utility disparities, and integrate business constraints directly into the optimization. Our experiments reveal that the "free fairness" regime, where producer constraints impose no consumer cost, disappears in multi item settings. Strikingly, moderate fairness constraints can improve business metrics by diversifying exposure away from saturated producers. Scalable solvers match exact solutions at a fraction of the runtime, making fairness-aware allocation practical at scale. These findings reframe fairness not as a tax on platform efficiency but as a lever for sustainable marketplace health.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10739v2</guid>
      <category>cs.GT</category>
      <category>cs.IR</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Dominykas Seputis, Alexander Timans, Rajeev Verma</dc:creator>
    </item>
    <item>
      <title>Right Reward Right Time for Federated Learning</title>
      <link>https://arxiv.org/abs/2503.07869</link>
      <description>arXiv:2503.07869v3 Announce Type: replace-cross 
Abstract: Critical learning periods (CLPs) in federated learning (FL) refer to early stages during which low-quality contributions (e.g., sparse training data availability) can permanently impair the performance of the global model owned by the cloud server. However, existing incentive mechanisms typically assume temporal homogeneity, treating all training rounds as equally important, thereby failing to prioritize and attract high-quality contributions during CLPs. This inefficiency is compounded by information asymmetry due to privacy regulations, where the cloud lacks knowledge of client training capabilities, leading to adverse selection and moral hazard. Thus, in this article, we propose a time-aware contract-theoretic incentive framework, named Right Reward Right Time (R3T), to encourage client involvement, especially during CLPs, to maximize the utility of the cloud server. We formulate a cloud utility function that captures the trade-off between the achieved model performance and rewards allocated for clients' contributions, explicitly accounting for client heterogeneity in time and system capabilities, effort, and joining time. Then, we devise a CLP-aware incentive mechanism deriving an optimal contract design that satisfies individual rationality, incentive compatibility, and budget feasibility constraints, motivating rational clients to participate early and contribute efforts. By providing the right reward at the right time, our approach can attract the highest-quality contributions during CLPs. Simulation and proof-of-concept studies show that R3T mitigates information asymmetry, increases cloud utility, and yields superior economic efficiency compared to conventional incentive mechanisms. Our proof-of-concept results demonstrate up to a 47.6% reduction in the total number of clients and up to a 300% improvement in convergence time while achieving competitive test accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07869v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.GT</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thanh Linh Nguyen, Dinh Thai Hoang, Diep N. Nguyen, Quoc-Viet Pham</dc:creator>
    </item>
    <item>
      <title>The Invisible Handshake: Tacit Collusion between Adaptive Market Agents</title>
      <link>https://arxiv.org/abs/2510.15995</link>
      <description>arXiv:2510.15995v2 Announce Type: replace-cross 
Abstract: We study the emergence of tacit collusion in a repeated game between a market maker, who controls market liquidity, and a market taker, who chooses trade quantities. The market price evolves according to the endogenous price impact of trades and exogenous innovations to economic fundamentals. We define collusion as persistent overpricing over economic fundamentals and characterize the set of feasible and collusive strategy profiles. Our main result shows that a broad class of simple learning dynamics, including gradient ascent updates, converges in finite time to collusive strategies when the agents maximize individual wealth, defined as the value of their portfolio, without any explicit coordination. The key economic mechanism is that when aggregate supply in the market is positive, overpricing raises the market capitalization and thus the total wealth of market participants, inducing a cooperative component in otherwise non-cooperative learning objectives. These results identify an inherent structure through which decentralized learning by AI-driven agents can autonomously generate persistent overpricing in financial markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15995v2</guid>
      <category>q-fin.TR</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luigi Foscari, Emanuele Guidotti, Nicol\`o Cesa-Bianchi, Tatjana Chavdarova, Alfio Ferrara</dc:creator>
    </item>
    <item>
      <title>CONSENT: A Negotiation Framework for Leveraging User Flexibility in Vehicle-to-Building Charging under Uncertainty</title>
      <link>https://arxiv.org/abs/2601.01581</link>
      <description>arXiv:2601.01581v2 Announce Type: replace-cross 
Abstract: The growth of Electric Vehicles (EVs) creates a conflict in vehicle-to-building (V2B) settings between building operators, who face high energy costs from uncoordinated charging, and drivers, who prioritize convenience and a full charge. To resolve this, we propose a negotiation-based framework that, by design, guarantees voluntary participation, strategy-proofness, and budget feasibility. It transforms EV charging into a strategic resource by offering drivers a range of incentive-backed options for modest flexibility in their departure time or requested state of charge (SoC). Our framework is calibrated with user survey data and validated using real operational data from a commercial building and an EV manufacturer. Simulations show that our negotiation protocol creates a mutually beneficial outcome: lowering the building operator's costs by over 3.5\% compared to an optimized, non-negotiating smart charging policy, while simultaneously reducing user charging expenses by 22\% below the utility's retail energy rate. By aligning operator and EV user objectives, our framework provides a strategic bridge between energy and mobility systems, transforming EV charging from a source of operational friction into a platform for collaboration and shared savings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01581v2</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.65109/V1X2Y3Z4</arxiv:DOI>
      <dc:creator>Rishav Sen, Fangqi Liu, Jose Paolo Talusan, Ava Pettet, Yoshinori Suzue, Mark Bailey, Ayan Mukhopadhyay, Abhishek Dubey</dc:creator>
    </item>
  </channel>
</rss>
