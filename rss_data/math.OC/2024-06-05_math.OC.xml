<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Jun 2024 04:01:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 06 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Stable MPC with maximal terminal sets and quadratic terminal costs</title>
      <link>https://arxiv.org/abs/2406.02760</link>
      <description>arXiv:2406.02760v1 Announce Type: new 
Abstract: This paper develops a technique for computing a quadratic terminal cost for linear model predictive controllers that is valid for all states in the maximal control invariant set. This maximizes the set of recursively feasible states for the controller, ensures asymptotic stability using standard proofs, and allows for easy tuning of the controller in linear operation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02760v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikael Johansson, Hamed Taghavian</dc:creator>
    </item>
    <item>
      <title>Achieving Near-Optimal Convergence for Distributed Minimax Optimization with Adaptive Stepsizes</title>
      <link>https://arxiv.org/abs/2406.02939</link>
      <description>arXiv:2406.02939v1 Announce Type: new 
Abstract: In this paper, we show that applying adaptive methods directly to distributed minimax problems can result in non-convergence due to inconsistency in locally computed adaptive stepsizes. To address this challenge, we propose D-AdaST, a Distributed Adaptive minimax method with Stepsize Tracking. The key strategy is to employ an adaptive stepsize tracking protocol involving the transmission of two extra (scalar) variables. This protocol ensures the consistency among stepsizes of nodes, eliminating the steady-state error due to the lack of coordination of stepsizes among nodes that commonly exists in vanilla distributed adaptive methods, and thus guarantees exact convergence. For nonconvex-strongly-concave distributed minimax problems, we characterize the specific transient times that ensure time-scale separation of stepsizes and quasi-independence of networks, leading to a near-optimal convergence rate of $\tilde{\mathcal{O}} \left( \epsilon ^{-\left( 4+\delta \right)} \right)$ for any small $\delta &gt; 0$, matching that of the centralized counterpart. To our best knowledge, D-AdaST is the first distributed adaptive method achieving near-optimal convergence without knowing any problem-dependent parameters for nonconvex minimax problems. Extensive experiments are conducted to validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02939v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Huang, Xiang Li, Yipeng Shen, Niao He, Jinming Xu</dc:creator>
    </item>
    <item>
      <title>Particle Filter Optimization: A Bayesian Approach for Global Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2406.03089</link>
      <description>arXiv:2406.03089v1 Announce Type: new 
Abstract: This paper introduces a novel global optimization algorithm called Particle Filter Optimization (PFO), designed for a class of stochastic problems. PFO leverages the Bayesian inference framework of Particle Filters (PF) by integrating the optimization problem into the PF estimation process. In this context, the objective function replaces the measurement, and a customized transitional prior is developed to function as state dynamics. This dynamic replaces classic acquisition function and grants the PF a local optimization capability, facilitating its transformation towards global optimization. In PFO, the particles serve as agents in the optimization problem. Given the noisy nature of measured outputs, the Unscented Transform (UT) is utilized to estimate the true mean, thereby reducing the impact of erroneous information on particle transitions and weight updates. The algorithm is designed to minimize the introduction of unnecessary parameters and adheres to theoretically validated PF procedures, resulting in a robust heuristic algorithm supported by rigorous theoretical foundations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03089v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mostafa Eslami, Maryam Babazadeh</dc:creator>
    </item>
    <item>
      <title>The Optimal Production Transport: Model and Algorithm</title>
      <link>https://arxiv.org/abs/2406.03090</link>
      <description>arXiv:2406.03090v1 Announce Type: new 
Abstract: In this paper, we propose the optimal production transport model, which is an extension of the classical optimal transport model. We observe in economics, the production of the factories can always be adjusted within a certain range, while the classical optimal transport does not take this situation into account. Therefore, differing from the classical optimal transport, one of the marginals is allowed to vary within a certain range in our proposed model. To address this, we introduce a multiple relaxation optimal production transport model and propose the generalized alternating Sinkhorn algorithms, inspired by the Sinkhorn algorithm and the double regularization method. By incorporating multiple relaxation variables and multiple regularization terms, the inequality and capacity constraints in the optimal production transport model are naturally satisfied. Alternating iteration algorithms are derived based on the duality of the regularized model. We also provide a theoretical analysis to guarantee the convergence of our proposed algorithms. Numerical results indicate significant advantages in terms of accuracy and efficiency. Furthermore, we apply the optimal production transport model to the coal production and transport problem. Numerical simulation demonstrates that our proposed model can save the production and transport cost by 13.17%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03090v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Fan, Tianhao Wu, Hao Wu</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Semilinear Elliptic Partial Differential Equations with Non-Lipschitzian Nonlinearities</title>
      <link>https://arxiv.org/abs/2406.03110</link>
      <description>arXiv:2406.03110v1 Announce Type: new 
Abstract: We study optimal control problems that are governed by semilinear elliptic partial differential equations that involve non-Lipschitzian nonlinearities. It is shown that, for a certain class of such PDEs, the solution map is Fr\'{e}chet differentiable even though the differential operator contains a nondifferentiable term. We exploit this effect to establish first-order necessary optimality conditions for minimizers of the considered control problems. The resulting KKT-conditions take the form of coupled PDE-systems that are posed in non-Muckenhoupt weighted Sobolev spaces and raise interesting questions regarding the regularity of optimal controls, the derivation of second-order optimality conditions, and the analysis of finite element discretizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03110v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Constantin Christof</dc:creator>
    </item>
    <item>
      <title>Sensitivity-Based Distributed Model Predictive Control for Nonlinear Systems under Inexact Optimization</title>
      <link>https://arxiv.org/abs/2406.03134</link>
      <description>arXiv:2406.03134v1 Announce Type: new 
Abstract: This paper presents a distributed model predictive control (DMPC) scheme for nonlinear continuous-time systems. The underlying distributed optimal control problem is cooperatively solved in parallel via a sensitivity-based algorithm. The algorithm is fully distributed in the sense that only one neighbor-to-neighbor communication step per iteration is necessary and that all computations are performed locally. Sufficient conditions are derived for the algorithm to converge towards the central solution. Based on this result, stability is shown for the suboptimal DMPC scheme under inexact minimization with the sensitivity-based algorithm and verified with numerical simulations. In particular, stability can be guaranteed with either a suitable stopping criterion or a fixed number of algorithm iterations in each MPC sampling step which allows for a real-time capable implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03134v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maximilian Pierer von Esch, Andreas V\"olz, Knut Graichen</dc:creator>
    </item>
    <item>
      <title>Floorplanning with I/O assignment via feasibility-seeking and superiorization methods</title>
      <link>https://arxiv.org/abs/2406.03165</link>
      <description>arXiv:2406.03165v1 Announce Type: new 
Abstract: The feasibility-seeking approach offers a systematic framework for managing and resolving intricate constraints in continuous problems, making it a promising avenue to explore in the context of floorplanning problems with increasingly heterogeneous constraints. The classic legality constraints can be expressed as the union of convex sets. In implementation, we introduce a resetting strategy aimed at effectively reducing the problem of algorithmic divergence in the projection-based method used for the feasibility-seeking formulation. Furthermore, we introduce the novel application of the superiorization method (SM) to floorplanning, which bridges the gap between feasibility-seeking and constrained optimization. The SM employs perturbations to steer the iterations of the feasibility-seeking algorithm towards feasible solutions with reduced (not necessarily minimal) total wirelength. To evaluate the performance of Per-RMAP, we conduct comprehensive experiments on the MCNC benchmarks and GSRC benchmarks. The results demonstrate that we can obtain legal floorplanning results 166 times faster than the branch-and-bound (B&amp;B) method while incurring only a 5% wirelength increase compared to the optimal results. Furthermore, we evaluate the effectiveness of the algorithmic flow that considers the I/O assignment constraints, which achieves an 6% improvement in wirelength. Besides, considering the soft modules with a larger feasible solution space, we obtain 15% improved runtime compared with PeF, the state-of-the-art analytical method. Moreover, we compared our method with Parquet-4 and Fast-SA on GSRC benchmarks which include larger-scale instances. The results highlight the ability of our approach to maintain a balance between floorplanning quality and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03165v1</guid>
      <category>math.OC</category>
      <category>cs.AR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TCAD.2024.3408106.</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems (2024)</arxiv:journal_reference>
      <dc:creator>Shan Yu, Yair Censor, Guojie Luo</dc:creator>
    </item>
    <item>
      <title>A biobjective Home Care Scheduling Problem with dynamic breaks</title>
      <link>https://arxiv.org/abs/2406.03217</link>
      <description>arXiv:2406.03217v1 Announce Type: new 
Abstract: This paper presents a multiobjective Home Care Scheduling Problem (from now on multiobjective HCSP) related to a home care company for elderly and dependent people located in the North of Spain. In particular, a biobjective problem is considered, with the following two conflicting objectives: the welfare of users and the cost of schedules. To tackle the problem, a custom metaheuristic algorithm based on the Multi-Directional Local Search (MDLS) was designed, obtaining good approximations of the Pareto frontier in efficient computational times. This biobjective algorithm can be divided into three steps: initializing the set of non dominated solutions, generating solutions composed by different routes and obtaining non dominated solutions. The performance of the biobjective algorithm was analyzed by implementing two other well known methods in the literature: the exact method AUGMECON2, which is just an improved version of the Epsilon Constraint approach, and an NSGA-II-based algorithm. Finally, an extensive computational study was developed to compare the three methods over a set of instances from the literature, where the biobjective algorithm exhibited a superior behaviour. Furthermore, the algorithm was also applied to real instances providing solutions to the company with a good trade-off between the two objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03217v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Isabel M\'endez-Fern\'andez, Silvia Lorenzo-Freire, \'Angel Manuel Gonz\'alez-Rueda</dc:creator>
    </item>
    <item>
      <title>A Successive Gap Constraint Linearization Method for Optimal Control Problems with Equilibrium Constraints</title>
      <link>https://arxiv.org/abs/2406.03270</link>
      <description>arXiv:2406.03270v1 Announce Type: new 
Abstract: In this study, we propose a novel gap-constraint-based reformulation for optimal control problems with equilibrium constraints (OCPECs). We show that the proposed reformulation generates a new constraint system equivalent to the original one but more concise and with favorable differentiability. Moreover, constraint regularity can be recovered by a relaxation strategy. We show that the gap constraint and its gradient can be evaluated efficiently. We then propose a successive gap constraint linearization method to solve the discretized OCPEC. We also provide an intuitive geometric interpretation of the gap constraint. Numerical experiments validate the effectiveness of the proposed reformulation and solution method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03270v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kangyu Lin, Toshiyuki Ohtsuka</dc:creator>
    </item>
    <item>
      <title>Exponential Consensus Formation in Time-Varying Multiagent Systems via Compactification Methods</title>
      <link>https://arxiv.org/abs/2406.03286</link>
      <description>arXiv:2406.03286v1 Announce Type: new 
Abstract: In this article, we establish exponential contraction results for the diameter and variance of general first-order multiagent systems. Our approach is based on compactification techniques, and works under rather mild assumptions. Namely, we posit that either the scrambling coefficient, or the algebraic connectivity of the averaged interaction graphs of the system over all time windows of a given length are uniformly positive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03286v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Beno\^it Bonnet-Weill (CNRS, L2S), Mario Sigalotti (SU)</dc:creator>
    </item>
    <item>
      <title>Forward-backward algorithms devised by graphs</title>
      <link>https://arxiv.org/abs/2406.03309</link>
      <description>arXiv:2406.03309v1 Announce Type: new 
Abstract: In this work, we present a methodology for devising forward-backward methods for finding zeros in the sum of a finite number of maximally monotone operators. We extend the framework and techniques from [SIAM J. Optim., 34 (2024), pp. 1569-1594] to cover the case involving a finite number of cocoercive operators, which should be directly evaluated instead of computing their resolvent. The algorithms are induced by three graphs that determine how the algorithm variables interact with each other and how they are combined to compute each resolvent. The hypotheses on these graphs ensure that the algorithms obtained have minimal lifting and are frugal, meaning that the ambient space of the underlying fixed point operator has minimal dimension and that each resolvent and each cocoercive operator is evaluated only once per iteration. This framework not only allows to recover some known methods, but also to generate new ones, as the forward-backward algorithm induced by a complete graph. We conclude with a numerical experiment showing how the choice of graphs influences the performance of the algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03309v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francisco J. Arag\'on-Artacho, Rub\'en Campoy, C\'esar L\'opez-Pastor</dc:creator>
    </item>
    <item>
      <title>Synchronized Optimal Transport for Joint Modeling of Dynamics Across Multiple Spaces</title>
      <link>https://arxiv.org/abs/2406.03319</link>
      <description>arXiv:2406.03319v1 Announce Type: new 
Abstract: Optimal transport has been an essential tool for reconstructing dynamics from complex data. With the increasingly available multifaceted data, a system can often be characterized across multiple spaces. Therefore, it is crucial to maintain coherence in the dynamics across these diverse spaces. To address this challenge, we introduce Synchronized Optimal Transport (SyncOT), a novel approach to jointly model dynamics that represent the same system through multiple spaces. With given correspondence between the spaces, SyncOT minimizes the aggregated cost of the dynamics induced across all considered spaces. The problem is discretized into a finite-dimensional convex problem using a staggered grid. Primal-dual algorithm-based approaches are then developed to solve the discretized problem. Various numerical experiments demonstrate the capabilities and properties of SyncOT and validate the effectiveness of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03319v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixuan Cang, Yanxiang Zhao</dc:creator>
    </item>
    <item>
      <title>Quantitative metastability of the Tikhonov-Mann iteration for countable families of mappings</title>
      <link>https://arxiv.org/abs/2406.03429</link>
      <description>arXiv:2406.03429v1 Announce Type: new 
Abstract: In this paper, we obtain rates of metastability for the Tikhonov-Mann iteration for countable families of mappings in CAT(0) spaces. This iteration was recently defined by the author in the setting of W-hyperbolic spaces as a generalization of the strongly convergent version of the Krasnoselskii-Mann iteration introduced by Bot and Meier for finding common fixed points of families of nonexpansive mappings in Hilbert spaces, and as an extension of the Tikhonov-Mann iteration for single mappings, for which Leustean and the author obtained rates of asymptotic regularity in W-hyperbolic spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03429v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Horatiu Cheval</dc:creator>
    </item>
    <item>
      <title>A Brief Overview of Optimization-Based Algorithms for MRI Reconstruction Using Deep Learning</title>
      <link>https://arxiv.org/abs/2406.02626</link>
      <description>arXiv:2406.02626v1 Announce Type: cross 
Abstract: Magnetic resonance imaging (MRI) is renowned for its exceptional soft tissue contrast and high spatial resolution, making it a pivotal tool in medical imaging. The integration of deep learning algorithms offers significant potential for optimizing MRI reconstruction processes. Despite the growing body of research in this area, a comprehensive survey of optimization-based deep learning models tailored for MRI reconstruction has yet to be conducted. This review addresses this gap by presenting a thorough examination of the latest optimization-based algorithms in deep learning specifically designed for MRI reconstruction. The goal of this paper is to provide researchers with a detailed understanding of these advancements, facilitating further innovation and application within the MRI community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02626v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Wanyu Bian</dc:creator>
    </item>
    <item>
      <title>Existence and nonexistence of minimizers for classical capillarity problems in presence of nonlocal repulsion and gravity</title>
      <link>https://arxiv.org/abs/2406.02735</link>
      <description>arXiv:2406.02735v1 Announce Type: cross 
Abstract: We investigate, under a volume constraint and among sets contained in a Euclidean half-space, the minimization problem of an energy functional given by the sum of a capillarity perimeter, a nonlocal repulsive term and a gravitational potential energy. The capillarity perimeter assigns a constant weight to the portion of the boundary touching the boundary of the half-space. The nonlocal term is represented by a double integral of a positive kernel $g$, while the gravitational term is represented by the integral of a positive potential $G$.
  We first establish existence of volume-constrained minimizers in the small mass regime, together with several qualitative properties of minimizers. The existence result holds even for rather general choices of kernels in the nonlocal term, including attractive-repulsive ones. When the nonlocal kernel $g(x)=1/|x|^\beta$ with $\beta \in (0,2]$, we also obtain nonexistence of volume constrained minimizers in the large mass regime. Finally, we prove a generalized existence result of minimizers holding for all masses, meaning that the infimum of the problem is realized by a finite disjoint union of sets thought located at "infinite distance" one from the other.
  These results stem from an application of quantitative isoperimetric inequalities for the capillarity problem in a half-space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02735v1</guid>
      <category>math.AP</category>
      <category>math.DG</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giulio Pascale</dc:creator>
    </item>
    <item>
      <title>Randomized Geometric Algebra Methods for Convex Neural Networks</title>
      <link>https://arxiv.org/abs/2406.02806</link>
      <description>arXiv:2406.02806v1 Announce Type: cross 
Abstract: We introduce randomized algorithms to Clifford's Geometric Algebra, generalizing randomized linear algebra to hypercomplex vector spaces. This novel approach has many implications in machine learning, including training neural networks to global optimality via convex optimization. Additionally, we consider fine-tuning large language model (LLM) embeddings as a key application area, exploring the intersection of geometric algebra and modern AI techniques. In particular, we conduct a comparative analysis of the robustness of transfer learning via embeddings, such as OpenAI GPT models and BERT, using traditional methods versus our novel approach based on convex optimization. We test our convex optimization transfer learning method across a variety of case studies, employing different embeddings (GPT-4 and BERT embeddings) and different text classification datasets (IMDb, Amazon Polarity Dataset, and GLUE) with a range of hyperparameter settings. Our results demonstrate that convex optimization and geometric algebra not only enhances the performance of LLMs but also offers a more stable and reliable method of transfer learning via embeddings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02806v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifei Wang, Sungyoon Kim, Paul Chu, Indu Subramaniam, Mert Pilanci</dc:creator>
    </item>
    <item>
      <title>Statistical inference of convex order by Wasserstein projection</title>
      <link>https://arxiv.org/abs/2406.02840</link>
      <description>arXiv:2406.02840v1 Announce Type: cross 
Abstract: Ranking distributions according to a stochastic order has wide applications in diverse areas. Although stochastic dominance has received much attention,convex order, particularly in general dimensions, has yet to be investigated from a statistical point of view. This article addresses this gap by introducing a simple statistical test for convex order based on the Wasserstein projection distance. This projection distance not only encodes whether two distributions are indeed in convex order, but also quantifies the deviation from the desired convex order and produces an optimal convex order approximation. Lipschitz stability of the backward and forward Wasserstein projection distance is proved, which leads to elegant consistency results of the estimator we employ as our test statistic. Combining these with state of the art results regarding the convergence rate of empirical distributions, we also derive upper bounds for the $p$-value and type I error our test statistic, as well as upper bounds on the type II error for an appropriate class of strict alternatives. Lastly, we provide an efficient numerical scheme for our test statistic, by way of an entropic Frank-Wolfe algorithm. Some experiments based on synthetic data sets illuminates the success of our approach empirically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02840v1</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jakwang Kim, Young-Heon Kim, Yuanlong Ruan, Andrew Warren</dc:creator>
    </item>
    <item>
      <title>Which exceptional low-dimensional projections of a Gaussian point cloud can be found in polynomial time?</title>
      <link>https://arxiv.org/abs/2406.02970</link>
      <description>arXiv:2406.02970v1 Announce Type: cross 
Abstract: Given $d$-dimensional standard Gaussian vectors $\boldsymbol{x}_1,\dots, \boldsymbol{x}_n$, we consider the set of all empirical distributions of its $m$-dimensional projections, for $m$ a fixed constant. Diaconis and Freedman (1984) proved that, if $n/d\to \infty$, all such distributions converge to the standard Gaussian distribution. In contrast, we study the proportional asymptotics, whereby $n,d\to \infty$ with $n/d\to \alpha \in (0, \infty)$. In this case, the projection of the data points along a typical random subspace is again Gaussian, but the set $\mathscr{F}_{m,\alpha}$ of all probability distributions that are asymptotically feasible as $m$-dimensional projections contains non-Gaussian distributions corresponding to exceptional subspaces.
  Non-rigorous methods from statistical physics yield an indirect characterization of $\mathscr{F}_{m,\alpha}$ in terms of a generalized Parisi formula. Motivated by the goal of putting this formula on a rigorous basis, and to understand whether these projections can be found efficiently, we study the subset $\mathscr{F}^{\rm alg}_{m,\alpha}\subseteq \mathscr{F}_{m,\alpha}$ of distributions that can be realized by a class of iterative algorithms. We prove that this set is characterized by a certain stochastic optimal control problem, and obtain a dual characterization of this problem in terms of a variational principle that extends Parisi's formula.
  As a byproduct, we obtain computationally achievable values for a class of random optimization problems including `generalized spherical perceptron' models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02970v1</guid>
      <category>math.PR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Montanari, Kangjie Zhou</dc:creator>
    </item>
    <item>
      <title>Quantum Algorithms and Lower Bounds for Finite-Sum Optimization</title>
      <link>https://arxiv.org/abs/2406.03006</link>
      <description>arXiv:2406.03006v1 Announce Type: cross 
Abstract: Finite-sum optimization has wide applications in machine learning, covering important problems such as support vector machines, regression, etc. In this paper, we initiate the study of solving finite-sum optimization problems by quantum computing. Specifically, let $f_1,\ldots,f_n\colon\mathbb{R}^d\to\mathbb{R}$ be $\ell$-smooth convex functions and $\psi\colon\mathbb{R}^d\to\mathbb{R}$ be a $\mu$-strongly convex proximal function. The goal is to find an $\epsilon$-optimal point for $F(\mathbf{x})=\frac{1}{n}\sum_{i=1}^n f_i(\mathbf{x})+\psi(\mathbf{x})$. We give a quantum algorithm with complexity $\tilde{O}\big(n+\sqrt{d}+\sqrt{\ell/\mu}\big(n^{1/3}d^{1/3}+n^{-2/3}d^{5/6}\big)\big)$, improving the classical tight bound $\tilde{\Theta}\big(n+\sqrt{n\ell/\mu}\big)$. We also prove a quantum lower bound $\tilde{\Omega}(n+n^{3/4}(\ell/\mu)^{1/4})$ when $d$ is large enough. Both our quantum upper and lower bounds can extend to the cases where $\psi$ is not necessarily strongly convex, or each $f_i$ is Lipschitz but not necessarily smooth. In addition, when $F$ is nonconvex, our quantum algorithm can find an $\epsilon$-critial point using $\tilde{O}(n+\ell(d^{1/3}n^{1/3}+\sqrt{d})/\epsilon^2)$ queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03006v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yexin Zhang, Chenyi Zhang, Cong Fang, Liwei Wang, Tongyang Li</dc:creator>
    </item>
    <item>
      <title>Graph Convolutional Branch and Bound</title>
      <link>https://arxiv.org/abs/2406.03099</link>
      <description>arXiv:2406.03099v1 Announce Type: cross 
Abstract: This article demonstrates the effectiveness of employing a deep learning model in an optimization pipeline. Specifically, in a generic exact algorithm for a NP problem, multiple heuristic criteria are usually used to guide the search of the optimum within the set of all feasible solutions. In this context, neural networks can be leveraged to rapidly acquire valuable information, enabling the identification of a more expedient path in this vast space. So, after the explanation of the tackled traveling salesman problem, the implemented branch and bound for its classical resolution is described. This algorithm is then compared with its hybrid version termed "graph convolutional branch and bound" that integrates the previous branch and bound with a graph convolutional neural network. The empirical results obtained highlight the efficacy of this approach, leading to conclusive findings and suggesting potential directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03099v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Sciandra, Roberto Esposito, Andrea Cesare Grosso, Laura Sacerdote, Cristina Zucca</dc:creator>
    </item>
    <item>
      <title>A Short and General Duality Proof for Wasserstein Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2205.00362</link>
      <description>arXiv:2205.00362v4 Announce Type: replace 
Abstract: We present a general duality result for Wasserstein distributionally robust optimization that holds for any Kantorovich transport cost, measurable loss function, and nominal probability distribution. Assuming an interchangeability principle inherent in existing duality results, our proof only uses one-dimensional convex analysis. Furthermore, we demonstrate that the interchangeability principle holds if and only if certain measurable projection and weak measurable selection conditions are satisfied. To illustrate the broader applicability of our approach, we provide a rigorous treatment of duality results in distributionally robust Markov decision processes and distributionally robust multistage stochastic programming. Additionally, we extend our analysis to other problems such as infinity-Wasserstein distributionally robust optimization, risk-averse optimization, and globalized distributionally robust counterpart.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.00362v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luhao Zhang, Jincheng Yang, Rui Gao</dc:creator>
    </item>
    <item>
      <title>On the equivalence between the minimax theorem and strong duality of conic linear programming</title>
      <link>https://arxiv.org/abs/2302.03066</link>
      <description>arXiv:2302.03066v3 Announce Type: replace 
Abstract: We prove the almost equivalence between two-player zero-sum games and conic linear programming problems in reflexive Banach spaces. The previous fundamental results of von Neumann, Dantzig, Adler, and von Stengel, regarding the equivalence between finite games with strategy sets defined over $\mathbb{R}^n$, and linear programming, are therefore generalized to the infinite-dimensional case. In fact, we show that for every two-player zero-sum game with a bilinear function of the form $u(x,y)=\langle y,Ax\rangle$, for some linear operator $A$, and strategy sets that represent bases of convex cones, the minimax theorem holds, and its game value and Nash equilibria can be computed by solving a primal-dual pair of conic linear problems. Conversely, the minimax theorem for the same class of games "almost always" implies strong duality of conic linear programming. The main results are applied to a number of infinite zero-sum games, whose classes include those of semi-infinite, semidefinite, time-continuous, quantum, polynomial, and homogeneous separable games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.03066v3</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikos Dimou</dc:creator>
    </item>
    <item>
      <title>The alternating simultaneous Halpern-Lions-Wittmann-Bauschke algorithm for finding the best approximation pair for two disjoint intersections of convex sets</title>
      <link>https://arxiv.org/abs/2304.09600</link>
      <description>arXiv:2304.09600v3 Announce Type: replace 
Abstract: Given two nonempty and disjoint intersections of closed and convex subsets, we look for a best approximation pair relative to them, i.e., a pair of points, one in each intersection, attaining the minimum distance between the disjoint intersections. We propose an iterative process based on projections onto the subsets which generate the intersections. The process is inspired by the Halpern-Lions-Wittmann-Bauschke algorithm and the classical alternating process of Cheney and Goldstein, and its advantage is that there is no need to project onto the intersections themselves, a task which can be rather demanding. We prove that under certain conditions the two interlaced subsequences converge to a best approximation pair. These conditions hold, in particular, when the space is Euclidean and the subsets which generate the intersections are compact and strictly convex. Our result extends the one of Aharoni, Censor and Jiang ["Finding a best approximation pair of points for two polyhedra'', Computational Optimization and Applications 71 (2018), 509--523] who considered the case of finite-dimensional polyhedra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.09600v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jat.2024.106045</arxiv:DOI>
      <arxiv:journal_reference>Journal of Approximation Theory 301 (2024) 106045 (22 pages)</arxiv:journal_reference>
      <dc:creator>Yair Censor, Rafiq Mansour, Daniel Reem</dc:creator>
    </item>
    <item>
      <title>On the equivalence of static and dynamic weak optimal transport</title>
      <link>https://arxiv.org/abs/2311.13872</link>
      <description>arXiv:2311.13872v2 Announce Type: replace 
Abstract: We show that there is a PDE formulation in terms of Fokker-Planck equations for weak optimal transport problems. The main novelty is that we introduce a minimization problem involving Fokker-Planck equations in the extended sense of measure-valued solutions and prove that it is equal to the associated weak transport problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13872v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bohdan Bulanyi</dc:creator>
    </item>
    <item>
      <title>A Joint Optimization Approach for Power-Efficient Heterogeneous OFDMA Radio Access Networks</title>
      <link>https://arxiv.org/abs/2403.14555</link>
      <description>arXiv:2403.14555v2 Announce Type: replace 
Abstract: Heterogeneous networks have emerged as a popular solution for accommodating the growing number of connected devices and increasing traffic demands in cellular networks. While offering broader coverage, higher capacity, and lower latency, the escalating energy consumption poses sustainability challenges. In this paper a novel optimization approach for OFDMA heterogeneous networks is proposed to minimize transmission power while respecting individual users throughput constraints. The problem is formulated as a mixed integer geometric program, and optimizes at once multiple system variables such as user association, working bandwidth, and base stations transmission powers. Crucially, the proposed approach becomes a convex optimization problem when user-base station associations are provided. Evaluations in multiple realistic scenarios from the production mobile network of a major European operator and based on precise channel gains and throughput requirements from measured data validate the effectiveness of the proposed approach. Overall, our original solution paves the road for greener connectivity by reducing the energy footprint of heterogeneous mobile networks, hence fostering more sustainable communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14555v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel O. Ferreira, Andr\'e F. Zanella, Stefanos Bakirtzis, Chiara Ravazzi, Fabrizio Dabbene, Giuseppe C. Calafiore, Ian Wassel, Jie Zhang, Marco Fiore</dc:creator>
    </item>
    <item>
      <title>Gradient Descent for Noisy Optimization</title>
      <link>https://arxiv.org/abs/2405.06539</link>
      <description>arXiv:2405.06539v3 Announce Type: replace 
Abstract: We study the use of gradient descent with backtracking line search (GD-BLS) to solve the noisy optimization problem $\theta_\star:=\mathrm{argmin}_{\theta\in\mathbb{R}^d} \mathbb{E}[f(\theta,Z)]$, imposing that the function $F(\theta):=\mathbb{E}[f(\theta,Z)]$ is strictly convex but not necessarily $L$-smooth. Assuming that $\mathbb{E}[\|\nabla_\theta f(\theta_\star,Z)\|^2]&lt;\infty$, we first prove that sample average approximation based on GD-BLS allows to estimate $\theta_\star$ with an error of size $\mathcal{O}_{\mathbb{P}}(B^{-0.25})$, where $B$ is the available computational budget. We then show that we can improve upon this rate by stopping the optimization process earlier when the gradient of the objective function is sufficiently close to zero, and use the residual computational budget to optimize, again with GD-BLS, a finer approximation of $F$. By iteratively applying this strategy $J$ times, we establish that we can estimate $\theta_\star$ with an error of size $\mathcal{O}_{\mathbb{P}}(B^{-\frac{1}{2}(1-\delta^{J})})$, where $\delta\in(1/2,1)$ is a user-specified parameter. More generally, we show that if $\mathbb{E}[\|\nabla_\theta f(\theta_\star,Z)\|^{1+\alpha}]&lt;\infty$ for some known $\alpha\in (0,1]$ then this approach, which can be seen as a retrospective approximation algorithm with a fixed computational budget, allows to learn $\theta_\star$ with an error of size $\mathcal{O}_{\mathbb{P}}(B^{-\frac{\alpha}{1+\alpha}(1-\delta^{J})})$, where $\delta\in(2\alpha/(1+3\alpha),1)$ is a tuning parameter. Beyond knowing $\alpha$, achieving the aforementioned convergence rates do not require to tune the algorithms parameters according to the specific functions $F$ and $f$ at hand, and we exhibit a simple noisy optimization problem for which stochastic gradient is not guaranteed to converge while the algorithms discussed in this work are.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06539v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Annie Hu, Mathieu Gerber</dc:creator>
    </item>
    <item>
      <title>Graphon Mean Field Games with a Representative Player: Analysis and Learning Algorithm</title>
      <link>https://arxiv.org/abs/2405.08005</link>
      <description>arXiv:2405.08005v2 Announce Type: replace 
Abstract: We propose a discrete time graphon game formulation on continuous state and action spaces using a representative player to study stochastic games with heterogeneous interaction among agents. This formulation admits both philosophical and mathematical advantages, compared to a widely adopted formulation using a continuum of players. We prove the existence and uniqueness of the graphon equilibrium with mild assumptions, and show that this equilibrium can be used to construct an approximate solution for finite player game on networks, which is challenging to analyze and solve due to curse of dimensionality. An online oracle-free learning algorithm is developed to solve the equilibrium numerically, and sample complexity analysis is provided for its convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08005v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fuzhong Zhou, Chenyu Zhang, Xu Chen, Xuan Di</dc:creator>
    </item>
    <item>
      <title>The Power of Extrapolation in Federated Learning</title>
      <link>https://arxiv.org/abs/2405.13766</link>
      <description>arXiv:2405.13766v4 Announce Type: replace 
Abstract: We propose and study several server-extrapolation strategies for enhancing the theoretical and empirical convergence properties of the popular federated learning optimizer FedProx [Li et al., 2020]. While it has long been known that some form of extrapolation can help in the practice of FL, only a handful of works provide any theoretical guarantees. The phenomenon seems elusive, and our current theoretical understanding remains severely incomplete. In our work, we focus on smooth convex or strongly convex problems in the interpolation regime. In particular, we propose Extrapolated FedProx (FedExProx), and study three extrapolation strategies: a constant strategy (depending on various smoothness parameters and the number of participating devices), and two smoothness-adaptive strategies; one based on the notion of gradient diversity (FedExProx-GraDS), and the other one based on the stochastic Polyak stepsize (FedExProx-StoPS). Our theory is corroborated with carefully constructed numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13766v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanmin Li, Kirill Acharya, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Fredholm backstepping for critical operators and application to rapid stabilization for the linearized water waves</title>
      <link>https://arxiv.org/abs/2202.08321</link>
      <description>arXiv:2202.08321v2 Announce Type: replace-cross 
Abstract: Fredholm-type backstepping transformation, introduced by Coron and L\"u, has become a powerful tool for rapid stabilization with fast development over the last decade. Its strength lies in its systematic approach, allowing to deduce rapid stabilization from approximate controllability. But limitations with the current approach exist for operators of the form $|D_x|^\alpha$ for $\alpha \in (1,3/2]$. We present here a new compactness/duality method which hinges on Fredholm's alternative to overcome the $\alpha=3/2$ threshold. More precisely, the compactness/duality method allows to prove the existence of a Riesz basis for the backstepping transformation for skew-adjoint operator verifying $\alpha&gt;1$, a key step in the construction of the Fredholm backstepping transformation, where the usual methods only work for $\alpha&gt;3/2$. The illustration of this new method is shown on the rapid stabilization of the linearized capillary-gravity water wave equation exhibiting an operator of critical order $\alpha=3/2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.08321v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ludovick Gagnon, Amaury Hayat, Shengquan Xiang, Christophe Zhang</dc:creator>
    </item>
    <item>
      <title>MoMo: Momentum Models for Adaptive Learning Rates</title>
      <link>https://arxiv.org/abs/2305.07583</link>
      <description>arXiv:2305.07583v3 Announce Type: replace-cross 
Abstract: Training a modern machine learning architecture on a new task requires extensive learning-rate tuning, which comes at a high computational cost. Here we develop new Polyak-type adaptive learning rates that can be used on top of any momentum method, and require less tuning to perform well. We first develop MoMo, a Momentum Model based adaptive learning rate for SGD-M (stochastic gradient descent with momentum). MoMo uses momentum estimates of the losses and gradients sampled at each iteration to build a model of the loss function. Our model makes use of any known lower bound of the loss function by using truncation, e.g. most losses are lower-bounded by zero. The model is then approximately minimized at each iteration to compute the next step. We show how MoMo can be used in combination with any momentum-based method, and showcase this by developing MoMo-Adam, which is Adam with our new model-based adaptive learning rate. We show that MoMo attains a $\mathcal{O}(1/\sqrt{K})$ convergence rate for convex problems with interpolation, needing knowledge of no problem-specific quantities other than the optimal value. Additionally, for losses with unknown lower bounds, we develop on-the-fly estimates of a lower bound, that are incorporated in our model. We show that MoMo and MoMo-Adam improve over SGD-M and Adam in terms of robustness to hyperparameter tuning for training image classifiers on MNIST, CIFAR, and Imagenet, for recommender systems on Criteo, for a transformer model on the translation task IWSLT14, and for a diffusion model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.07583v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Schaipp, Ruben Ohana, Michael Eickenberg, Aaron Defazio, Robert M. Gower</dc:creator>
    </item>
    <item>
      <title>Error Feedback Can Accurately Compress Preconditioners</title>
      <link>https://arxiv.org/abs/2306.06098</link>
      <description>arXiv:2306.06098v5 Announce Type: replace-cross 
Abstract: Leveraging second-order information about the loss at the scale of deep networks is one of the main lines of approach for improving the performance of current optimizers for deep learning. Yet, existing approaches for accurate full-matrix preconditioning, such as Full-Matrix Adagrad (GGT) or Matrix-Free Approximate Curvature (M-FAC) suffer from massive storage costs when applied even to small-scale models, as they must store a sliding window of gradients, whose memory requirements are multiplicative in the model dimension. In this paper, we address this issue via a novel and efficient error-feedback technique that can be applied to compress preconditioners by up to two orders of magnitude in practice, without loss of convergence. Specifically, our approach compresses the gradient information via sparsification or low-rank compression \emph{before} it is fed into the preconditioner, feeding the compression error back into future iterations. Experiments on deep neural networks show that this approach can compress full-matrix preconditioners to up to 99\% sparsity without accuracy loss, effectively removing the memory overhead of full-matrix preconditioners such as GGT and M-FAC. Our code is available at \url{https://github.com/IST-DASLab/EFCP}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.06098v5</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ionut-Vlad Modoranu, Aleksei Kalinov, Eldar Kurtic, Elias Frantar, Dan Alistarh</dc:creator>
    </item>
    <item>
      <title>UniAP: Unifying Inter- and Intra-Layer Automatic Parallelism by Mixed Integer Quadratic Programming</title>
      <link>https://arxiv.org/abs/2307.16375</link>
      <description>arXiv:2307.16375v3 Announce Type: replace-cross 
Abstract: Distributed learning is commonly used for training deep learning models, especially large models. In distributed learning, manual parallelism (MP) methods demand considerable human effort and have limited flexibility. Hence, automatic parallelism (AP) methods have recently been proposed for automating the parallel strategy optimization process. Existing AP methods suffer from sub-optimal solutions because they do not jointly optimize the two categories of parallel strategies (i.e., inter-layer parallelism and intra-layer parallelism). In this paper, we propose a novel AP method called UniAP, which unifies inter- and intra-layer automatic parallelism by mixed integer quadratic programming. To the best of our knowledge, UniAP is the first parallel method that can jointly optimize the two categories of parallel strategies to find an optimal solution. Experimental results show that UniAP outperforms state-of-the-art methods by up to 3.80$\times$ in throughput and reduces strategy optimization time by up to 107$\times$ across five Transformer-based models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.16375v3</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Lin, Ke Wu, Jie Li, Jun Li, Wu-Jun Li</dc:creator>
    </item>
    <item>
      <title>Riemannian Preconditioned LoRA for Fine-Tuning Foundation Models</title>
      <link>https://arxiv.org/abs/2402.02347</link>
      <description>arXiv:2402.02347v3 Announce Type: replace-cross 
Abstract: Low-Rank Adaptation (LoRA) emerges as a popular parameter-efficient fine-tuning (PEFT) method, which proposes to freeze pretrained model weights and update an additive low-rank trainable matrix. In this work, we study the enhancement of LoRA training by introducing an $r \times r$ preconditioner in each gradient step where $r$ is the LoRA rank. We theoretically verify that the proposed preconditioner stabilizes feature learning with LoRA under infinite-width NN setting. Empirically, the implementation of this new preconditioner requires a small change to existing optimizer code and creates virtually minuscule storage and runtime overhead. Our experimental results with both large language models and text-to-image diffusion models show that with this new preconditioner, the convergence and reliability of SGD and AdamW can be significantly enhanced. Moreover, the training process becomes much more robust to hyperparameter choices such as learning rate. The new preconditioner can be derived from a novel Riemannian metric in low-rank matrix field. Code can be accessed at https://github.com/pilancilab/Riemannian_Preconditioned_LoRA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02347v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fangzhao Zhang, Mert Pilanci</dc:creator>
    </item>
    <item>
      <title>Deconstructing the Goldilocks Zone of Neural Network Initialization</title>
      <link>https://arxiv.org/abs/2402.03579</link>
      <description>arXiv:2402.03579v2 Announce Type: replace-cross 
Abstract: The second-order properties of the training loss have a massive impact on the optimization dynamics of deep learning models. Fort &amp; Scherlis (2019) discovered that a large excess of positive curvature and local convexity of the loss Hessian is associated with highly trainable initial points located in a region coined the "Goldilocks zone". Only a handful of subsequent studies touched upon this relationship, so it remains largely unexplained. In this paper, we present a rigorous and comprehensive analysis of the Goldilocks zone for homogeneous neural networks. In particular, we derive the fundamental condition resulting in excess of positive curvature of the loss, explaining and refining its conventionally accepted connection to the initialization norm. Further, we relate the excess of positive curvature to model confidence, low initial loss, and a previously unknown type of vanishing cross-entropy loss gradient. To understand the importance of excessive positive curvature for trainability of deep networks, we optimize fully-connected and convolutional architectures outside the Goldilocks zone and analyze the emergent behaviors. We find that strong model performance is not perfectly aligned with the Goldilocks zone, calling for further research into this relationship.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03579v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artem Vysogorets, Anna Dawid, Julia Kempe</dc:creator>
    </item>
    <item>
      <title>On the Duality Between Sharpness-Aware Minimization and Adversarial Training</title>
      <link>https://arxiv.org/abs/2402.15152</link>
      <description>arXiv:2402.15152v2 Announce Type: replace-cross 
Abstract: Adversarial Training (AT), which adversarially perturb the input samples during training, has been acknowledged as one of the most effective defenses against adversarial attacks, yet suffers from inevitably decreased clean accuracy. Instead of perturbing the samples, Sharpness-Aware Minimization (SAM) perturbs the model weights during training to find a more flat loss landscape and improve generalization. However, as SAM is designed for better clean accuracy, its effectiveness in enhancing adversarial robustness remains unexplored. In this work, considering the duality between SAM and AT, we investigate the adversarial robustness derived from SAM. Intriguingly, we find that using SAM alone can improve adversarial robustness. To understand this unexpected property of SAM, we first provide empirical and theoretical insights into how SAM can implicitly learn more robust features, and conduct comprehensive experiments to show that SAM can improve adversarial robustness notably without sacrificing any clean accuracy, shedding light on the potential of SAM to be a substitute for AT when accuracy comes at a higher priority. Code is available at https://github.com/weizeming/SAM_AT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15152v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihao Zhang, Hangzhou He, Jingyu Zhu, Huanran Chen, Yifei Wang, Zeming Wei</dc:creator>
    </item>
    <item>
      <title>From Inverse Optimization to Feasibility to ERM</title>
      <link>https://arxiv.org/abs/2402.17890</link>
      <description>arXiv:2402.17890v2 Announce Type: replace-cross 
Abstract: Inverse optimization involves inferring unknown parameters of an optimization problem from known solutions and is widely used in fields such as transportation, power systems, and healthcare. We study the contextual inverse optimization setting that utilizes additional contextual information to better predict the unknown problem parameters. We focus on contextual inverse linear programming (CILP), addressing the challenges posed by the non-differentiable nature of LPs. For a linear prediction model, we reduce CILP to a convex feasibility problem allowing the use of standard algorithms such as alternating projections. The resulting algorithm for CILP is equipped with theoretical convergence guarantees without additional assumptions such as degeneracy or interpolation. Next, we reduce CILP to empirical risk minimization (ERM) on a smooth, convex loss that satisfies the Polyak-Lojasiewicz condition. This reduction enables the use of scalable first-order optimization methods to solve large non-convex problems while maintaining theoretical guarantees in the convex setting. Subsequently, we use the reduction to ERM to quantify the generalization performance of the proposed algorithm on previously unseen instances. Finally, we experimentally validate our approach on synthetic and real-world problems and demonstrate improved performance compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17890v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saurabh Mishra, Anant Raj, Sharan Vaswani</dc:creator>
    </item>
    <item>
      <title>How Transformers Learn Diverse Attention Correlations in Masked Vision Pretraining</title>
      <link>https://arxiv.org/abs/2403.02233</link>
      <description>arXiv:2403.02233v2 Announce Type: replace-cross 
Abstract: Masked reconstruction, which predicts randomly masked patches from unmasked ones, has emerged as an important approach in self-supervised pretraining. However, the theoretical understanding of masked pretraining is rather limited, especially for the foundational architecture of transformers. In this paper, to the best of our knowledge, we provide the first end-to-end theoretical guarantee of learning one-layer transformers in masked reconstruction self-supervised pretraining. On the conceptual side, we posit a mechanism of how transformers trained with masked vision pretraining objectives produce empirically observed local and diverse attention patterns, on data distributions with spatial structures that highlight feature-position correlations. On the technical side, our end-to-end characterization of training dynamics in softmax-attention models simultaneously accounts for input and position embeddings, which is developed based on a careful analysis tracking the interplay between feature-wise and position-wise attention correlations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02233v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Huang, Zixin Wen, Yuejie Chi, Yingbin Liang</dc:creator>
    </item>
    <item>
      <title>Remove that Square Root: A New Efficient Scale-Invariant Version of AdaGrad</title>
      <link>https://arxiv.org/abs/2403.02648</link>
      <description>arXiv:2403.02648v2 Announce Type: replace-cross 
Abstract: Adaptive methods are extremely popular in machine learning as they make learning rate tuning less expensive. This paper introduces a novel optimization algorithm named KATE, which presents a scale-invariant adaptation of the well-known AdaGrad algorithm. We prove the scale-invariance of KATE for the case of Generalized Linear Models. Moreover, for general smooth non-convex problems, we establish a convergence rate of $O \left(\frac{\log T}{\sqrt{T}} \right)$ for KATE, matching the best-known ones for AdaGrad and Adam. We also compare KATE to other state-of-the-art adaptive algorithms Adam and AdaGrad in numerical experiments with different problems, including complex machine learning tasks like image classification and text classification on real data. The results indicate that KATE consistently outperforms AdaGrad and matches/surpasses the performance of Adam in all considered scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02648v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sayantan Choudhury, Nazarii Tupitsa, Nicolas Loizou, Samuel Horvath, Martin Takac, Eduard Gorbunov</dc:creator>
    </item>
    <item>
      <title>Scalable Online Exploration via Coverability</title>
      <link>https://arxiv.org/abs/2403.06571</link>
      <description>arXiv:2403.06571v2 Announce Type: replace-cross 
Abstract: Exploration is a major challenge in reinforcement learning, especially for high-dimensional domains that require function approximation. We propose exploration objectives -- policy optimization objectives that enable downstream maximization of any reward function -- as a conceptual framework to systematize the study of exploration. Within this framework, we introduce a new objective, $L_1$-Coverage, which generalizes previous exploration schemes and supports three fundamental desiderata:
  1. Intrinsic complexity control. $L_1$-Coverage is associated with a structural parameter, $L_1$-Coverability, which reflects the intrinsic statistical difficulty of the underlying MDP, subsuming Block and Low-Rank MDPs.
  2. Efficient planning. For a known MDP, optimizing $L_1$-Coverage efficiently reduces to standard policy optimization, allowing flexible integration with off-the-shelf methods such as policy gradient and Q-learning approaches.
  3. Efficient exploration. $L_1$-Coverage enables the first computationally efficient model-based and model-free algorithms for online (reward-free or reward-driven) reinforcement learning in MDPs with low coverability.
  Empirically, we find that $L_1$-Coverage effectively drives off-the-shelf policy optimization algorithms to explore the state space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06571v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip Amortila, Dylan J. Foster, Akshay Krishnamurthy</dc:creator>
    </item>
    <item>
      <title>Convergence of Some Convex Message Passing Algorithms to a Fixed Point</title>
      <link>https://arxiv.org/abs/2403.07004</link>
      <description>arXiv:2403.07004v2 Announce Type: replace-cross 
Abstract: A popular approach to the MAP inference problem in graphical models is to minimize an upper bound obtained from a dual linear programming or Lagrangian relaxation by (block-)coordinate descent. This is also known as convex/convergent message passing; examples are max-sum diffusion and sequential tree-reweighted message passing (TRW-S). Convergence properties of these methods are currently not fully understood. They have been proved to converge to the set characterized by local consistency of active constraints, with unknown convergence rate; however, it was not clear if the iterates converge at all (to any point). We prove a stronger result (conjectured before but never proved): the iterates converge to a fixed point of the method. Moreover, we show that the algorithm terminates within $\mathcal{O}(1/\varepsilon)$ iterations. We first prove this for a version of coordinate descent applied to a general piecewise-affine convex objective. Then we show that several convex message passing methods are special cases of this method. Finally, we show that a slightly different version of coordinate descent can cycle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07004v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vaclav Voracek, Tomas Werner</dc:creator>
    </item>
    <item>
      <title>Span-Based Optimal Sample Complexity for Weakly Communicating and General Average Reward MDPs</title>
      <link>https://arxiv.org/abs/2403.11477</link>
      <description>arXiv:2403.11477v2 Announce Type: replace-cross 
Abstract: We study the sample complexity of learning an $\varepsilon$-optimal policy in an average-reward Markov decision process (MDP) under a generative model. For weakly communicating MDPs, we establish the complexity bound $\widetilde{O}(SA\frac{H}{\varepsilon^2} )$, where $H$ is the span of the bias function of the optimal policy and $SA$ is the cardinality of the state-action space. Our result is the first that is minimax optimal (up to log factors) in all parameters $S,A,H$, and $\varepsilon$, improving on existing work that either assumes uniformly bounded mixing times for all policies or has suboptimal dependence on the parameters. We also initiate the study of sample complexity in general (multichain) average-reward MDPs. We argue a new transient time parameter $B$ is necessary, establish an $\widetilde{O}(SA\frac{B + H}{\varepsilon^2})$ complexity bound, and prove a matching (up to log factors) minimax lower bound. Both results are based on reducing the average-reward MDP to a discounted MDP, which requires new ideas in the general setting. To optimally analyze this reduction, we develop improved bounds for $\gamma$-discounted MDPs, showing that $\widetilde{O}(SA\frac{H}{(1-\gamma)^2\varepsilon^2} )$ and $\widetilde{O}(SA\frac{B + H}{(1-\gamma)^2\varepsilon^2} )$ samples suffice to learn $\varepsilon$-optimal policies in weakly communicating and in general MDPs, respectively. Both these results circumvent the well-known minimax lower bound of $\widetilde{\Omega}(SA\frac{1}{(1-\gamma)^3\varepsilon^2} )$ for $\gamma$-discounted MDPs, and establish a quadratic rather than cubic horizon dependence for a fixed MDP instance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11477v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Zurek, Yudong Chen</dc:creator>
    </item>
    <item>
      <title>Conditional Wasserstein Distances with Applications in Bayesian OT Flow Matching</title>
      <link>https://arxiv.org/abs/2403.18705</link>
      <description>arXiv:2403.18705v2 Announce Type: replace-cross 
Abstract: In inverse problems, many conditional generative models approximate the posterior measure by minimizing a distance between the joint measure and its learned approximation. While this approach also controls the distance between the posterior measures in the case of the Kullback--Leibler divergence, this is in general not hold true for the Wasserstein distance. In this paper, we introduce a conditional Wasserstein distance via a set of restricted couplings that equals the expected Wasserstein distance of the posteriors. Interestingly, the dual formulation of the conditional Wasserstein-1 flow resembles losses in the conditional Wasserstein GAN literature in a quite natural way. We derive theoretical properties of the conditional Wasserstein distance, characterize the corresponding geodesics and velocity fields as well as the flow ODEs. Subsequently, we propose to approximate the velocity fields by relaxing the conditional Wasserstein distance. Based on this, we propose an extension of OT Flow Matching for solving Bayesian inverse problems and demonstrate its numerical advantages on an inverse problem and class-conditional image generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18705v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jannis Chemseddine, Paul Hagemann, Gabriele Steidl, Christian Wald</dc:creator>
    </item>
    <item>
      <title>Lyapunov-stable Neural Control for State and Output Feedback: A Novel Formulation</title>
      <link>https://arxiv.org/abs/2404.07956</link>
      <description>arXiv:2404.07956v2 Announce Type: replace-cross 
Abstract: Learning-based neural network (NN) control policies have shown impressive empirical performance in a wide range of tasks in robotics and control. However, formal (Lyapunov) stability guarantees over the region-of-attraction (ROA) for NN controllers with nonlinear dynamical systems are challenging to obtain, and most existing approaches rely on expensive solvers such as sums-of-squares (SOS), mixed-integer programming (MIP), or satisfiability modulo theories (SMT). In this paper, we demonstrate a new framework for learning NN controllers together with Lyapunov certificates using fast empirical falsification and strategic regularizations. We propose a novel formulation that defines a larger verifiable region-of-attraction (ROA) than shown in the literature, and refines the conventional restrictive constraints on Lyapunov derivatives to focus only on certifiable ROAs. The Lyapunov condition is rigorously verified post-hoc using branch-and-bound with scalable linear bound propagation-based NN verification techniques. The approach is efficient and flexible, and the full training and verification procedure is accelerated on GPUs without relying on expensive solvers for SOS, MIP, nor SMT. The flexibility and efficiency of our framework allow us to demonstrate Lyapunov-stable output feedback control with synthesized NN-based controllers and NN-based observers with formal stability guarantees, for the first time in literature. Source code at https://github.com/Verified-Intelligence/Lyapunov_Stable_NN_Controllers</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07956v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lujie Yang, Hongkai Dai, Zhouxing Shi, Cho-Jui Hsieh, Russ Tedrake, Huan Zhang</dc:creator>
    </item>
    <item>
      <title>Optimization without Retraction on the Random Generalized Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2405.01702</link>
      <description>arXiv:2405.01702v2 Announce Type: replace-cross 
Abstract: Optimization over the set of matrices $X$ that satisfy $X^\top B X = I_p$, referred to as the generalized Stiefel manifold, appears in many applications involving sampled covariance matrices such as the canonical correlation analysis (CCA), independent component analysis (ICA), and the generalized eigenvalue problem (GEVP). Solving these problems is typically done by iterative methods that require a fully formed $B$. We propose a cheap stochastic iterative method that solves the optimization problem while having access only to a random estimates of $B$. Our method does not enforce the constraint in every iteration; instead, it produces iterations that converge to critical points on the generalized Stiefel manifold defined in expectation. The method has lower per-iteration cost, requires only matrix multiplications, and has the same convergence rates as its Riemannian optimization counterparts that require the full matrix $B$. Experiments demonstrate its effectiveness in various machine learning applications involving generalized orthogonality constraints, including CCA, ICA, and the GEVP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01702v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Vary, Pierre Ablin, Bin Gao, P. -A. Absil</dc:creator>
    </item>
    <item>
      <title>The Riemann hypothesis and dynamics of Backtracking New Q-Newton's method</title>
      <link>https://arxiv.org/abs/2405.05834</link>
      <description>arXiv:2405.05834v3 Announce Type: replace-cross 
Abstract: A new variant of Newton's method - named Backtracking New Q-Newton's method (BNQN) - was recently introduced by the second author. This method has good global convergence guarantees, specially concerning finding roots of meromorphic functions. This paper explores using BNQN for the Riemann xi function. We show in particular that the Riemann hypothesis is equivalent to that all attractors of BNQN lie on the critical line. We also explain how an apparent relation between the basins of attraction of BNQN and Voronoi's diagram can be helpful for verifying the Riemann hypothesis or finding a counterexample to it. Some illustrating experimental results are included, which convey some interesting phenomena. The experiments show that BNQN works very stably with highly transcendental functions like the Riemann xi function and its derivatives. Based on insights from the experiments, we discuss some concrete steps on using BNQN towards the Riemann hypothesis, by combining with de Bruijn -Newman's constant. Ideas and results from this paper can be extended to other zeta functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05834v3</guid>
      <category>math.DS</category>
      <category>math.CV</category>
      <category>math.NT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Thuan Quang Tran, Tuyen Trung Truong</dc:creator>
    </item>
  </channel>
</rss>
