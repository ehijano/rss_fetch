<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Nov 2024 02:45:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Satellite monitoring uncovers progress but large disparities in doubling crop yields</title>
      <link>https://arxiv.org/abs/2411.03322</link>
      <description>arXiv:2411.03322v1 Announce Type: new 
Abstract: High-resolution satellite-based crop yield mapping offers enormous promise for monitoring progress towards the SDGs. Across 15,000 villages in Rwanda we uncover areas that are on and off track to double productivity by 2030. This machine learning enabled analysis is used to design spatially explicit productivity targets that, if met, would simultaneously ensure national goals without leaving anyone behind.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03322v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katie Fankhauser, Evan Thomas, Zia Mehrabi</dc:creator>
    </item>
    <item>
      <title>AI Horizon Scanning -- White Paper p3395, IEEE-SA. Part III: Technology Watch: a selection of key developments, emerging technologies, and industry trends in Artificial Intelligence</title>
      <link>https://arxiv.org/abs/2411.03449</link>
      <description>arXiv:2411.03449v1 Announce Type: new 
Abstract: Generative Artificial Intelligence (AI) technologies are in a phase of unprecedented rapid development following the landmark release of Chat-GPT, which brought the phenomenon to wide public attention. As the deployment of AI products rises geometrically, considerable attention is being given to the threats and opportunities that AI technologies offer, and to the need for regulatory and standards initiatives to ensure that use of the technology aligns with societal needs and generates broad benefits while mitigating risks and threats. This manuscript is the third of a series of White Papers informing the development of IEEE-SA's p3995 {\it `Standard for the Implementation of Safeguards, Controls, and Preventive Techniques for Artificial Intelligence Models'} \cite{P3395}, Chair Marina Cort\^{e}s. This part focuses on assessing calmly and objectively, as far as is possible, the current state of Artificial Intelligence (AI) technology development and identifying predominant trends, prospects, and ensuing risks. It necessarily forms a snapshot of the current instant of a rapidly-evolving landscape, with new products and innovations emerging continuously. While our main focus is on software and hardware developments and their corporate context, we also briefly review progress on robotics within the AI context and describe some implications of the substantial and growing AI energy demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03449v1</guid>
      <category>cs.CY</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>George Tambouratzis, Marina Cort\^es, Andrew R. Liddle</dc:creator>
    </item>
    <item>
      <title>Towards Scalable Automated Grading: Leveraging Large Language Models for Conceptual Question Evaluation in Engineering</title>
      <link>https://arxiv.org/abs/2411.03659</link>
      <description>arXiv:2411.03659v1 Announce Type: new 
Abstract: This study explores the feasibility of using large language models (LLMs), specifically GPT-4o (ChatGPT), for automated grading of conceptual questions in an undergraduate Mechanical Engineering course. We compared the grading performance of GPT-4o with that of human teaching assistants (TAs) on ten quiz problems from the MEEN 361 course at Texas A&amp;M University, each answered by approximately 225 students. Both the LLM and TAs followed the same instructor-provided rubric to ensure grading consistency. We evaluated performance using Spearman's rank correlation coefficient and Root Mean Square Error (RMSE) to assess the alignment between rankings and the accuracy of scores assigned by GPT-4o and TAs under zero- and few-shot grading settings. In the zero-shot setting, GPT-4o demonstrated a strong correlation with TA grading, with Spearman's rank correlation coefficient exceeding 0.6 in seven out of ten datasets and reaching a high of 0.9387. Our analysis reveals that GPT-4o performs well when grading criteria are straightforward but struggles with nuanced answers, particularly those involving synonyms not present in the rubric. The model also tends to grade more stringently in ambiguous cases compared to human TAs. Overall, ChatGPT shows promise as a tool for grading conceptual questions, offering scalability and consistency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03659v1</guid>
      <category>cs.CY</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rujun Gao, Xiaosu Guo, Xiaodi Li, Arun Balajiee Lekshmi Narayanan, Naveen Thomas, Arun R. Srinivasa</dc:creator>
    </item>
    <item>
      <title>Optimizing Metro Station Locations and Line Layouts in Selangor using Genetic Algorithm Approach: Technical Report</title>
      <link>https://arxiv.org/abs/2411.03797</link>
      <description>arXiv:2411.03797v1 Announce Type: new 
Abstract: This report presents an approach for optimizing metro station locations and line layouts in the area of Selangor, located in Malaysia. The project utilized the genetic algorithm in identifying the locations and lines layout. With population in Selangor projected to reach 7.3 million by 2024, the existing transport infrastructure is under increasing strain. This project addresses this challenge by optimizing the metro network to effectively cover the expanding population and minimize travel times. We employed a genetic algorithm to achieve these objectives, focusing on both the strategic placement of metro stations and the efficient layout of metro lines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03797v1</guid>
      <category>cs.CY</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hasna Lammaihri, Marwa Erramla, Norjihan Abdul Ghani</dc:creator>
    </item>
    <item>
      <title>Game-Theoretic Machine Unlearning: Mitigating Extra Privacy Leakage</title>
      <link>https://arxiv.org/abs/2411.03914</link>
      <description>arXiv:2411.03914v1 Announce Type: new 
Abstract: With the extensive use of machine learning technologies, data providers encounter increasing privacy risks. Recent legislation, such as GDPR, obligates organizations to remove requested data and its influence from a trained model. Machine unlearning is an emerging technique designed to enable machine learning models to erase users' private information. Although several efficient machine unlearning schemes have been proposed, these methods still have limitations. First, removing the contributions of partial data may lead to model performance degradation. Second, discrepancies between the original and generated unlearned models can be exploited by attackers to obtain target sample's information, resulting in additional privacy leakage risks. To address above challenges, we proposed a game-theoretic machine unlearning algorithm that simulates the competitive relationship between unlearning performance and privacy protection. This algorithm comprises unlearning and privacy modules. The unlearning module possesses a loss function composed of model distance and classification error, which is used to derive the optimal strategy. The privacy module aims to make it difficult for an attacker to infer membership information from the unlearned data, thereby reducing the privacy leakage risk during the unlearning process. Additionally, the experimental results on real-world datasets demonstrate that this game-theoretic unlearning algorithm's effectiveness and its ability to generate an unlearned model with a performance similar to that of the retrained one while mitigating extra privacy leakage risks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03914v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hengzhu Liu, Tianqing Zhu, Lefeng Zhang, Ping Xiong</dc:creator>
    </item>
    <item>
      <title>Where postdoctoral journeys lead</title>
      <link>https://arxiv.org/abs/2411.03938</link>
      <description>arXiv:2411.03938v1 Announce Type: new 
Abstract: Postdoctoral training is a career stage often described as a demanding and anxiety-laden time when many promising PhDs see their academic dreams slip away due to circumstances beyond their control. We use a unique data set of academic publishing and careers to chart the more or less successful postdoctoral paths. We build a measure of academic success on the citation patterns two to five years into a faculty career. Then, we monitor how students' postdoc positions -- in terms of relocation, change of topic, and early well-cited papers -- relate to their early-career success. One key finding is that the postdoc period seems more important than the doctoral training to achieve this form of success. This is especially interesting in light of the many studies of academic faculty hiring that link Ph.D. granting institutions and hires, omitting the postdoc stage. Another group of findings can be summarized as a Goldilocks principle: it seems beneficial to change one's direction, but not too much.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03938v1</guid>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yueran Duan, Shahan Ali Memon, Bedoor AlShebli, Qing Guan, Petter Holme, Talal Rahwan</dc:creator>
    </item>
    <item>
      <title>Taming Toxicity or Fueling It? The Great Ban`s Role in Shifting Toxic User Behavior and Engagement</title>
      <link>https://arxiv.org/abs/2411.04037</link>
      <description>arXiv:2411.04037v2 Announce Type: new 
Abstract: In today's online environments users experience harm and abuse on a daily basis. Therefore, content moderation is crucial to ensure their safety and well-being. However, the effectiveness of many moderation interventions is still uncertain. We evaluate the effectiveness of The Great Ban, one of the largest deplatforming interventions carried out by Reddit that affected almost 2,000 communities. We analyze 53M comments shared by nearly 34K users, providing in-depth results on both the intended and unintended consequences of this ban. We found that 15.6% of the moderated users abandoned the platform while the remaining ones decreased their overall toxicity by 4.1%. Nonetheless, a subset of those users increased their toxicity by 70% after the intervention. In any case, increases in toxicity did not lead to marked increases in activity or engagement, meaning that the most toxic users had overall a limited impact. Our findings bring to light new insights on the effectiveness of deplatforming. Furthermore, they also contribute to informing future content moderation strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04037v2</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Cima, Benedetta Tessa, Stefano Cresci, Amaury Trujillo, Marco Avvenuti</dc:creator>
    </item>
    <item>
      <title>Multilingual Large Language Models and Curse of Multilinguality</title>
      <link>https://arxiv.org/abs/2406.10602</link>
      <description>arXiv:2406.10602v1 Announce Type: cross 
Abstract: Multilingual Large Language Models (LLMs) have gained large popularity among Natural Language Processing (NLP) researchers and practitioners. These models, trained on huge datasets, show proficiency across various languages and demonstrate effectiveness in numerous downstream tasks. This paper navigates the landscape of multilingual LLMs, providing an introductory overview of their technical aspects. It explains underlying architectures, objective functions, pre-training data sources, and tokenization methods. This work explores the unique features of different model types: encoder-only (mBERT, XLM-R), decoder-only (XGLM, PALM, BLOOM, GPT-3), and encoder-decoder models (mT5, mBART). Additionally, it addresses one of the significant limitations of multilingual LLMs - the curse of multilinguality - and discusses current attempts to overcome it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10602v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.48550/arXiv.2406.10602</arxiv:DOI>
      <dc:creator>Daniil Gurgurov, Tanja B\"aumel, Tatiana Anikina</dc:creator>
    </item>
    <item>
      <title>Maximal Extractable Value in Decentralized Finance: Taxonomy, Detection, and Mitigation</title>
      <link>https://arxiv.org/abs/2411.03327</link>
      <description>arXiv:2411.03327v1 Announce Type: cross 
Abstract: Decentralized Finance (DeFi) leverages blockchain-enabled smart contracts to deliver automated and trustless financial services without the need for intermediaries. However, the public visibility of financial transactions on the blockchain can be exploited, as participants can reorder, insert, or remove transactions to extract value, often at the expense of others. This extracted value is known as the Maximal Extractable Value (MEV). MEV causes financial losses and consensus instability, disrupting the security, efficiency, and decentralization goals of the DeFi ecosystem. Therefore, it is crucial to analyze, detect, and mitigate MEV to safeguard DeFi. Our comprehensive survey offers a holistic view of the MEV landscape in the DeFi ecosystem. We present an in-depth understanding of MEV through a novel taxonomy of MEV transactions supported by real transaction examples. We perform a critical comparative analysis of various MEV detection approaches, evaluating their effectiveness in identifying different transaction types. Furthermore, we assess different categories of MEV mitigation strategies and discuss their limitations. We identify the challenges of current mitigation and detection approaches and discuss potential solutions. This survey provides valuable insights for researchers, developers, stakeholders, and policymakers, helping to curb and democratize MEV for a more secure and efficient DeFi ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03327v1</guid>
      <category>cs.CR</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huned Materwala, Shraddha M. Naik, Aya Taha, Tala Abdulrahman Abed, Davor Svetinovic</dc:creator>
    </item>
    <item>
      <title>Climate AI for Corporate Decarbonization Metrics Extraction</title>
      <link>https://arxiv.org/abs/2411.03402</link>
      <description>arXiv:2411.03402v1 Announce Type: cross 
Abstract: Corporate Greenhouse Gas (GHG) emission targets are important metrics in sustainable investing [12, 16]. To provide a comprehensive view of company emission objectives, we propose an approach to source these metrics from company public disclosures. Without automation, curating these metrics manually is a labor-intensive process that requires combing through lengthy corporate sustainability disclosures that often do not follow a standard format. Furthermore, the resulting dataset needs to be validated thoroughly by Subject Matter Experts (SMEs), further lengthening the time-to-market. We introduce the Climate Artificial Intelligence for Corporate Decarbonization Metrics Extraction (CAI) model and pipeline, a novel approach utilizing Large Language Models (LLMs) to extract and validate linked metrics from corporate disclosures. We demonstrate that the process improves data collection efficiency and accuracy by automating data curation, validation, and metric scoring from public corporate disclosures. We further show that our results are agnostic to the choice of LLMs. This framework can be applied broadly to information extraction from textual data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03402v1</guid>
      <category>q-fin.PM</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditya Dave, Mengchen Zhu, Dapeng Hu, Sachin Tiwari</dc:creator>
    </item>
    <item>
      <title>Potential Use of IoT Distance Measurement Tool in Boule Sports</title>
      <link>https://arxiv.org/abs/2411.03585</link>
      <description>arXiv:2411.03585v1 Announce Type: cross 
Abstract: In Petanque, each player aims to throw the boule closer to the jack. The closest boule to the jack among players will score the point. Currently, the distance of the boule to the jack is still measured using manual measurement tools such as measuring tape, string, and calipers. The manual measurement method is considered time-consuming and prone to inconsistent reading, which the ordinary referees and players conduct. A steady hand is required to hold the tape at two ends while squatting or kneeling. The technique of reading the measurement is also important to determine the accuracy of the length. This project aims to design and develop a prototype device that can measure the distance between jack and boule using a microcontroller and ultrasonic sensor technology. The device is expected to provide an instant measurement of the distance between the jack and the boule. The measurement data can be displayed on the mobile device to ease the user to view the result. This prototype device also counts the score points and determines the winner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03585v1</guid>
      <category>cs.NI</category>
      <category>cs.CY</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.5121/ijwmn.2024.16501</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Wireless &amp; Mobile Networks (IJWMN), Vol.16, No.4/5. Oct. 2024</arxiv:journal_reference>
      <dc:creator>Wahidah Md Shah, M Azim. Adnan, Aslinda Hassan, Norharyati Harum, Isredza Rahmi A. Hamid</dc:creator>
    </item>
    <item>
      <title>PyroGuardian: An IoT-Enabled System for Health and Location Monitoring in High-Risk Firefighting Environments</title>
      <link>https://arxiv.org/abs/2411.03654</link>
      <description>arXiv:2411.03654v1 Announce Type: cross 
Abstract: First responders risk their lives to reduce property damage and prevent injuries during disasters. Among first responders, firefighters work with fires in residential properties, forests, or other locations where fire occurs. We built the PyroGuardian system that uses wearable modules to transmit unit information over Long Range (LoRa) to an Android tablet. The tablet runs our application, PyroPortal, to assign each firefighter's stats, such as body temperature, heart rate, and GPS location. PyroPortal displays this information on unit dashboards, and markers on Google Maps represent the firefighter's location and the direction they are facing. These dashboards can help the incident commander (IC) make more informed decisions on mission control operations and remove specific units whose health stats, such as oximeter and pulse, passed certain thresholds. PyroGuardian completes all these tasks at an affordable cost and in an impressive maximum range between the units and IC. In addition, PyroGuardian has various application scenarios, such as law enforcement and military operations, besides firefighting. We also conducted a sample mission inside a burning building while real firefighters watched. After the demonstration, they completed a survey on system usability and PyroGuardian's potential to meet their requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03654v1</guid>
      <category>cs.NI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Berkay Kaplan, Buhe Li</dc:creator>
    </item>
    <item>
      <title>No Culture Left Behind: ArtELingo-28, a Benchmark of WikiArt with Captions in 28 Languages</title>
      <link>https://arxiv.org/abs/2411.03769</link>
      <description>arXiv:2411.03769v1 Announce Type: cross 
Abstract: Research in vision and language has made considerable progress thanks to benchmarks such as COCO. COCO captions focused on unambiguous facts in English; ArtEmis introduced subjective emotions and ArtELingo introduced some multilinguality (Chinese and Arabic). However we believe there should be more multilinguality. Hence, we present ArtELingo-28, a vision-language benchmark that spans $\textbf{28}$ languages and encompasses approximately $\textbf{200,000}$ annotations ($\textbf{140}$ annotations per image). Traditionally, vision research focused on unambiguous class labels, whereas ArtELingo-28 emphasizes diversity of opinions over languages and cultures. The challenge is to build machine learning systems that assign emotional captions to images. Baseline results will be presented for three novel conditions: Zero-Shot, Few-Shot and One-vs-All Zero-Shot. We find that cross-lingual transfer is more successful for culturally-related languages. Data and code are provided at www.artelingo.org.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03769v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Youssef Mohamed, Runjia Li, Ibrahim Said Ahmad, Kilichbek Haydarov, Philip Torr, Kenneth Ward Church, Mohamed Elhoseiny</dc:creator>
    </item>
    <item>
      <title>Navigating the landscape of multimodal AI in medicine: a scoping review on technical challenges and clinical applications</title>
      <link>https://arxiv.org/abs/2411.03782</link>
      <description>arXiv:2411.03782v1 Announce Type: cross 
Abstract: Recent technological advances in healthcare have led to unprecedented growth in patient data quantity and diversity. While artificial intelligence (AI) models have shown promising results in analyzing individual data modalities, there is increasing recognition that models integrating multiple complementary data sources, so-called multimodal AI, could enhance clinical decision-making. This scoping review examines the landscape of deep learning-based multimodal AI applications across the medical domain, analyzing 432 papers published between 2018 and 2024. We provide an extensive overview of multimodal AI development across different medical disciplines, examining various architectural approaches, fusion strategies, and common application areas. Our analysis reveals that multimodal AI models consistently outperform their unimodal counterparts, with an average improvement of 6.2 percentage points in AUC. However, several challenges persist, including cross-departmental coordination, heterogeneous data characteristics, and incomplete datasets. We critically assess the technical and practical challenges in developing multimodal AI systems and discuss potential strategies for their clinical implementation, including a brief overview of commercially available multimodal AI models for clinical decision-making. Additionally, we identify key factors driving multimodal AI development and propose recommendations to accelerate the field's maturation. This review provides researchers and clinicians with a thorough understanding of the current state, challenges, and future directions of multimodal AI in medicine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03782v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daan Schouten, Giulia Nicoletti, Bas Dille, Catherine Chia, Pierpaolo Vendittelli, Megan Schuurmans, Geert Litjens, Nadieh Khalili</dc:creator>
    </item>
    <item>
      <title>Deep Learning Based Amharic Chatbot for FAQs in Universities</title>
      <link>https://arxiv.org/abs/2402.01720</link>
      <description>arXiv:2402.01720v2 Announce Type: replace 
Abstract: University students often spend a considerable amount of time seeking answers to common questions from administrators or teachers. This can become tedious for both parties, leading to a need for a solution. In response, this paper proposes a chatbot model that utilizes natural language processing and deep learning techniques to answer frequently asked questions (FAQs) in the Amharic language. Chatbots are computer programs that simulate human conversation through the use of artificial intelligence (AI), acting as a virtual assistant to handle questions and other tasks. The proposed chatbot program employs tokenization, normalization, stop word removal, and stemming to analyze and categorize Amharic input sentences. Three machine learning model algorithms were used to classify tokens and retrieve appropriate responses: Support Vector Machine (SVM), Multinomial Na\"ive Bayes, and deep neural networks implemented through TensorFlow, Keras, and NLTK. The deep learning model achieved the best results with 91.55% accuracy and a validation loss of 0.3548 using an Adam optimizer and SoftMax activation function. The chatbot model was integrated with Facebook Messenger and deployed on a Heroku server for 24-hour accessibility. The experimental results demonstrate that the chatbot framework achieved its objectives and effectively addressed challenges such as Amharic Fidel variation, morphological variation, and lexical gaps. Future research could explore the integration of Amharic WordNet to narrow the lexical gap and support more complex questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01720v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.48550/arXiv.2402.01720</arxiv:DOI>
      <arxiv:journal_reference>Machine Learning (cs.LG), V1, 2024</arxiv:journal_reference>
      <dc:creator>Goitom Ybrah Hailu, Hadush Hailu, Shishay Welay</dc:creator>
    </item>
    <item>
      <title>Evaluation of Systems Programming Exercises through Tailored Static Analysis</title>
      <link>https://arxiv.org/abs/2410.17260</link>
      <description>arXiv:2410.17260v3 Announce Type: replace 
Abstract: In large programming classes, it takes a significant effort from teachers to evaluate exercises and provide detailed feedback. In systems programming, test cases are not sufficient to assess exercises, since concurrency and resource management bugs are difficult to reproduce. This paper presents an experience report on static analysis for the automatic evaluation of systems programming exercises. We design systems programming assignments with static analysis rules that are tailored for each assignment, to provide detailed and accurate feedback. Our evaluation shows that static analysis can identify a significant number of erroneous submissions missed by test cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17260v3</guid>
      <category>cs.CY</category>
      <category>cs.SE</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3641554.3701836</arxiv:DOI>
      <dc:creator>Roberto Natella</dc:creator>
    </item>
    <item>
      <title>ElectionSim: Massive Population Election Simulation Powered by Large Language Model Driven Agents</title>
      <link>https://arxiv.org/abs/2410.20746</link>
      <description>arXiv:2410.20746v3 Announce Type: replace-cross 
Abstract: The massive population election simulation aims to model the preferences of specific groups in particular election scenarios. It has garnered significant attention for its potential to forecast real-world social trends. Traditional agent-based modeling (ABM) methods are constrained by their ability to incorporate complex individual background information and provide interactive prediction results. In this paper, we introduce ElectionSim, an innovative election simulation framework based on large language models, designed to support accurate voter simulations and customized distributions, together with an interactive platform to dialogue with simulated voters. We present a million-level voter pool sampled from social media platforms to support accurate individual simulation. We also introduce PPE, a poll-based presidential election benchmark to assess the performance of our framework under the U.S. presidential election scenario. Through extensive experiments and analyses, we demonstrate the effectiveness and robustness of our framework in U.S. presidential election simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20746v3</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinnong Zhang, Jiayu Lin, Libo Sun, Weihong Qi, Yihang Yang, Yue Chen, Hanjia Lyu, Xinyi Mou, Siming Chen, Jiebo Luo, Xuanjing Huang, Shiping Tang, Zhongyu Wei</dc:creator>
    </item>
  </channel>
</rss>
