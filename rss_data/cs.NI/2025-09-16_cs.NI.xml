<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 16 Sep 2025 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Energy-Aware Data Center Management: A Sustainable Approach to Reducing Carbon Footprint</title>
      <link>https://arxiv.org/abs/2509.10462</link>
      <description>arXiv:2509.10462v1 Announce Type: new 
Abstract: The rapid expansion of cloud computing and data center infrastructure has led to significant energy consumption, posing environmental challenges due to the growing carbon footprint. This research explores energy-aware management strategies aimed at creating sustainable data center operations. By integrating advanced energy-efficient technologies and optimizing resource utilization, this study proposes a framework to minimize power usage while maintaining high performance. Key elements include dynamic workload allocation, renewable energy integration, and intelligent cooling systems, all of which contribute to reducing overall energy consumption. The study also examines the impact of these strategies on operational costs and performance efficiency, demonstrating how sustainable practices can be both environmentally and economically beneficial. Through simulations and case studies, the research offers practical insights into reducing carbon emissions in data centers, supporting the transition towards greener cloud infrastructure. The findings highlight the potential for scalable, energy-aware data center designs that significantly lower environmental impact while ensuring optimal functionality, contributing to the global effort of mitigating climate change.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10462v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rabab Khan Rongon, Krishna Das</dc:creator>
    </item>
    <item>
      <title>A Dynamic Service Offloading Algorithm Based on Lyapunov Optimization in Edge Computing</title>
      <link>https://arxiv.org/abs/2509.10475</link>
      <description>arXiv:2509.10475v1 Announce Type: new 
Abstract: This study investigates the trade-off between system stability and offloading cost in collaborative edge computing. While collaborative offloading among multiple edge servers enhances resource utilization, existing methods often overlook the role of queue stability in overall system performance. To address this, a multi-hop data transmission model is developed, along with a cost model that captures both energy consumption and delay. A time-varying queue model is then introduced to maintain system stability. Based on Lyapunov optimization, a dynamic offloading algorithm (LDSO) is proposed to minimize offloading cost while ensuring long-term stability. Theoretical analysis and experimental results verify that the proposed LDSO achieves significant improvements in both cost efficiency and system stability compared to the state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10475v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Peiyan Yuan, Ming Li, Chenyang Wang, Ledong An, Xiaoyan Zhao, Junna Zhang, Xiangyang Li, Huadong Ma</dc:creator>
    </item>
    <item>
      <title>The LLM as a Network Operator: A Vision for Generative AI in the 6G Radio Access Network</title>
      <link>https://arxiv.org/abs/2509.10478</link>
      <description>arXiv:2509.10478v1 Announce Type: new 
Abstract: The management of future AI-native Next-Generation (NextG) Radio Access Networks (RANs), including 6G and beyond, presents a challenge of immense complexity that exceeds the capabilities of traditional automation. In response, we introduce the concept of the LLM-RAN Operator. In this paradigm, a Large Language Model (LLM) is embedded into the RAN control loop to translate high-level human intents into optimal network actions. Unlike prior empirical studies, we present a formal framework for an LLM-RAN operator that builds on earlier work by making guarantees checkable through an adapter aligned with the Open RAN (O-RAN) standard, separating strategic LLM-driven guidance in the Non-Real-Time (RT) RAN intelligent controller (RIC) from reactive execution in the Near-RT RIC, including a proposition on policy expressiveness and a theorem on convergence to stable fixed points. By framing the problem with mathematical rigor, our work provides the analytical tools to reason about the feasibility and stability of AI-native RAN control. It identifies critical research challenges in safety, real-time performance, and physical-world grounding. This paper aims to bridge the gap between AI theory and wireless systems engineering in the NextG era, aligning with the AI4NextG vision to develop knowledgeable, intent-driven wireless networks that integrate generative AI into the heart of the RAN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10478v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oluwaseyi Giwa, Michael Adewole, Tobi Awodumila, Pelumi Aderinto</dc:creator>
    </item>
    <item>
      <title>Exploring Busy Period for Worst-Case Deadline Failure Probability Analysis</title>
      <link>https://arxiv.org/abs/2509.10479</link>
      <description>arXiv:2509.10479v1 Announce Type: new 
Abstract: Busy period is a fundamental concept in classical deterministic real-time scheduling analysis. In this deterministic context, only one busy period - which starts at the critical instant - needs to be considered, which identifies the worst-case scenario and thus paves the way for the development of efficient and safe analysis techniques. However, a recent work has revealed that, in the context of \textit{probabilistic} real-time scheduling analysis, only considering critical instant is not safe. In this paper, we address this gap by systematically analyzing deadline miss probabilities across varying busy period starting points. We propose a novel method of Worst-Case Deadline Failure Probability (WCDFP) for probabilistic fixed-priority preemptive scheduling. Experimental results demonstrate significant improvements over state-of-the-art methods achieved by our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10479v1</guid>
      <category>cs.NI</category>
      <category>cs.OS</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyi Liu, Xu Jiang, Yuanzhen Mu, Wang Yi, Nan Guan</dc:creator>
    </item>
    <item>
      <title>Synergetic Empowerment: Wireless Communications Meets Embodied Intelligence</title>
      <link>https://arxiv.org/abs/2509.10481</link>
      <description>arXiv:2509.10481v1 Announce Type: new 
Abstract: Wireless communication is evolving into an agent era, where large-scale agents with inherent embodied intelligence are not just users but active participants. The perfect combination of wireless communication and embodied intelligence can achieve a synergetic empowerment and greatly facilitate the development of agent communication. An overview of this synergetic empowerment is presented, framing it as a co-evolutionary process that transforms wireless communication from a simple utility into the digital nervous system of a collective intelligence, while simultaneously elevating isolated agents into a unified superorganism with emergent capabilities far exceeding individual contributions. Moreover, we elaborate how embodied intelligence and wireless communication mutually benefit each other through the lens of the perception-cognition-execution (PCE) loop, revealing a fundamental duality where each PCE stage both challenges network capacity and creates unprecedented opportunities for system-wide optimization. Furthermore, critical open issues and future research directions are identified.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10481v1</guid>
      <category>cs.NI</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongtao Liang, Yihe Diao, YuHang Wu, Fuhui Zhou, Qihui Wu</dc:creator>
    </item>
    <item>
      <title>SABR: A Stable Adaptive Bitrate Framework Using Behavior Cloning Pretraining and Reinforcement Learning Fine-Tuning</title>
      <link>https://arxiv.org/abs/2509.10486</link>
      <description>arXiv:2509.10486v1 Announce Type: new 
Abstract: With the advent of 5G, the internet has entered a new video-centric era. From short-video platforms like TikTok to long-video platforms like Bilibili, online video services are reshaping user consumption habits. Adaptive Bitrate (ABR) control is widely recognized as a critical factor influencing Quality of Experience (QoE). Recent learning-based ABR methods have attracted increasing attention. However, most of them rely on limited network trace sets during training and overlook the wide-distribution characteristics of real-world network conditions, resulting in poor generalization in out-of-distribution (OOD) scenarios. To address this limitation, we propose SABR, a training framework that combines behavior cloning (BC) pretraining with reinforcement learning (RL) fine-tuning. We also introduce benchmarks, ABRBench-3G and ABRBench-4G+, which provide wide-coverage training traces and dedicated OOD test sets for assessing robustness to unseen network conditions. Experimental results demonstrate that SABR achieves the best average rank compared with Pensieve, Comyco, and NetLLM across the proposed benchmarks. These results indicate that SABR enables more stable learning across wide distributions and improves generalization to unseen network conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10486v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MM</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengcheng Luo, Yunyang Zhao, Bowen Zhang, Genke Yang, Boon-Hee Soong, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Online Learning Based Efficient Resource Allocation for LoRaWAN Network</title>
      <link>https://arxiv.org/abs/2509.10493</link>
      <description>arXiv:2509.10493v1 Announce Type: new 
Abstract: The deployment of large-scale LoRaWAN networks requires jointly optimizing conflicting metrics like Packet Delivery Ratio (PDR) and Energy Efficiency (EE) by dynamically allocating transmission parameters, including Carrier Frequency, Spreading Factor, and Transmission Power. Existing methods often oversimplify this challenge, focusing on a single metric or lacking the adaptability needed for dynamic channel environments, leading to suboptimal performance. To address this, we propose two online learning-based resource allocation frameworks that intelligently navigate the PDR-EE trade-off. Our foundational proposal, D-LoRa, is a fully distributed framework that models the problem as a Combinatorial Multi-Armed Bandit. By decomposing the joint parameter selection and employing specialized, disaggregated reward functions, D-LoRa dramatically reduces learning complexity and enables nodes to autonomously adapt to network dynamics. To further enhance performance in LoRaWAN networks, we introduce CD-LoRa, a hybrid framework that integrates a lightweight, centralized initialization phase to perform a one-time, quasi-optimal channel assignment and action space pruning, thereby accelerating subsequent distributed learning. Extensive simulations and real-world field experiments demonstrate the superiority of our frameworks, showing that D-LoRa excels in non-stationary environments while CD-LoRa achieves the fastest convergence in stationary conditions. In physical deployments, our methods outperform state-of-the-art baselines, improving PDR by up to 10.8% and EE by 26.1%, confirming their practical effectiveness for scalable and efficient LoRaWAN networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10493v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruiqi Wang, Jing Ren, Tongyu Song, Wenjun Li, Xiong Wang, Sheng Wang, Shizhong Xu</dc:creator>
    </item>
    <item>
      <title>Towards Scalable O-RAN Resource Management: Graph-Augmented Proximal Policy Optimization</title>
      <link>https://arxiv.org/abs/2509.10499</link>
      <description>arXiv:2509.10499v1 Announce Type: new 
Abstract: Open Radio Access Network (O-RAN) architectures enable flexible, scalable, and cost-efficient mobile networks by disaggregating and virtualizing baseband functions. However, this flexibility introduces significant challenges for resource management, requiring joint optimization of functional split selection and virtualized unit placement under dynamic demands and complex topologies. Existing solutions often address these aspects separately or lack scalability in large and real-world scenarios. In this work, we propose a novel Graph-Augmented Proximal Policy Optimization (GPPO) framework that leverages Graph Neural Networks (GNNs) for topology-aware feature extraction and integrates action masking to efficiently navigate the combinatorial decision space. Our approach jointly optimizes functional split and placement decisions, capturing the full complexity of O-RAN resource allocation. Extensive experiments on both small-and large-scale O-RAN scenarios demonstrate that GPPO consistently outperforms state-of-the-art baselines, achieving up to 18% lower deployment cost and 25% higher reward in generalization tests, while maintaining perfect reliability. These results highlight the effectiveness and scalability of GPPO for practical O-RAN deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10499v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Duc-Thinh Ngo (STACK, LS2N), Kandaraj Piamrat, Ons Aouedi, Thomas Hassan, Philippe Raipin-Parv\'edy</dc:creator>
    </item>
    <item>
      <title>An Internet of Intelligent Things Framework for Decentralized Heterogeneous Platforms</title>
      <link>https://arxiv.org/abs/2509.10507</link>
      <description>arXiv:2509.10507v1 Announce Type: new 
Abstract: Internet of Intelligent Things (IoIT), an emerging field, combines the utility of Internet of Things (IoT) devices with the innovation of embedded AI algorithms. However, it does not come without challenges, and struggles regarding available computing resources, energy supply, and storage limitations. In particular, many impediments to IoIT are linked to the energy-efficient deployment of machine learning (ML)/deep learning (DL) models in embedded devices. Research has been conducted to design energy-efficient IoIT platforms, but these papers often focus on centralized systems, in which some central entity processes all the data and coordinates actions. This can be problematic, e.g., serve as bottleneck or lead to security concerns. In a decentralized system, nodes/devices would self-organize and make their own decisions. Therefore, to address such issues, we propose a heterogeneous, decentralized sensing and monitoring IoIT peer-to-peer mesh network system model. Nodes in the network will coordinate towards several optimization goals: reliability, energy efficiency, and latency. The system employs federated learning to train nodes in a distributed manner, metaheuristics to optimize task allocation and routing paths, and multi-objective optimization to balance conflicting performance goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10507v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vadim Allayev, Mahbubur Rahman</dc:creator>
    </item>
    <item>
      <title>CAR-BRAINet: Sub-6GHz Aided Spatial Adaptive Beam Prediction with Multi Head Attention for Heterogeneous Vehicular Networks</title>
      <link>https://arxiv.org/abs/2509.10508</link>
      <description>arXiv:2509.10508v1 Announce Type: new 
Abstract: Heterogeneous Vehicular Networks (HetVNets) play a key role by stacking different communication technologies such as sub-6GHz, mm-wave and DSRC to meet diverse connectivity needs of 5G/B5G vehicular networks. HetVNet helps address the humongous user demands-but maintaining a steady connection in a highly mobile, real-world conditions remain a challenge. Though there has been ample of studies on beam prediction models a dedicated solution for HetVNets is sparsely explored. Hence, it is the need of the hour to develop a reliable beam prediction solution, specifically for HetVNets. This paper introduces a lightweight deep learning-based solution termed-"CAR-BRAINet" which consists of convolutional neural networks with a powerful multi-head attention (MHA) mechanism. Existing literature on beam prediction is largely studied under a limited, idealised vehicular scenario, often overlooking the real-time complexities and intricacies of vehicular networks. Therefore, this study aims to mimic the complexities of a real-time driving scenario by incorporating key factors such as prominent MAC protocols-3GPP-C-V2X and IEEE 802.11BD, the effect of Doppler shifts under high velocity and varying distance and SNR levels into three high-quality dynamic datasets pertaining to urban, rural and highway vehicular networks. CAR-BRAINet performs effectively across all the vehicular scenarios, demonstrating precise beam prediction with minimal beam overhead and a steady improvement of 17.9422% on the spectral efficiency over the existing methods. Thus, this study justifies the effectiveness of CAR-BRAINet in complex HetVNets, offering promising performance without relying on the location angle and antenna dimensions of the mobile users, and thereby reducing the redundant sensor-latency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10508v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aathira G Menon (Department of Electronics and Communication Engineering, National Institute of Technology Karnataka), Prabu Krishnan (Department of Electronics and Communication Engineering, National Institute of Technology Karnataka), Shyam Lal (Department of Electronics and Communication Engineering, National Institute of Technology Karnataka)</dc:creator>
    </item>
    <item>
      <title>Pair-Bid Auction Model for Optimized Network Slicing in 5G RAN</title>
      <link>https://arxiv.org/abs/2509.10533</link>
      <description>arXiv:2509.10533v1 Announce Type: new 
Abstract: Network slicing is a key 5G technology that enables multiple virtual networks to share physical infrastructure, optimizing flexibility and resource allocation. This involves Mobile Network Operators (MNO), Mobile Virtual Network Operators (MVNOs), and end users, where MNO leases network slices to MVNOs, and then provides customized services. This work considers end-to-end network slicing with a focus on fair sharing and financial-related power efficiency, modeled as a two level hierarchical combinatorial auction. At the upper level, an MNO auctions slices to competing MVNOs, while at the lower level, MVNOs allocate resources to end users through their own auctions. Dynamic user requests add complexity to the process. Our model optimizes resource allocation and revenue generation using a pair-bid mechanism and Vickrey-Clarke-Groves (VCG) pricing. The pair-bid approach enhances competition and efficiency, while VCG ensures truthful bidding based on marginal system impact. Simulations validate the model's effectiveness in resource distribution and financial performance, showing a 12.5% revenue improvement over the baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10533v1</guid>
      <category>cs.NI</category>
      <category>cs.GT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mengyao Li, Sebastian Troia, Yingqian Zhang, Guido Maier</dc:creator>
    </item>
    <item>
      <title>ASL360: AI-Enabled Adaptive Streaming of Layered 360{\deg} Video over UAV-assisted Wireless Networks</title>
      <link>https://arxiv.org/abs/2509.10544</link>
      <description>arXiv:2509.10544v1 Announce Type: new 
Abstract: We propose ASL360, an adaptive deep reinforcement learning-based scheduler for on-demand 360{\deg} video streaming to mobile VR users in next generation wireless networks. We aim to maximize the overall Quality of Experience (QoE) of the users served over a UAV-assisted 5G wireless network. Our system model comprises a macro base station (MBS) and a UAV-mounted base station which both deploy mm-Wave transmission to the users. The 360{\deg} video is encoded into dependent layers and segmented tiles, allowing a user to schedule downloads of each layer's segments. Furthermore, each user utilizes multiple buffers to store the corresponding video layer's segments. We model the scheduling decision as a Constrained Markov Decision Process (CMDP), where the agent selects Base or Enhancement layers to maximize the QoE and use a policy gradient-based method (PPO) to find the optimal policy. Additionally, we implement a dynamic adjustment mechanism for cost components, allowing the system to adaptively balance and prioritize the video quality, buffer occupancy, and quality change based on real-time network and streaming session conditions. We demonstrate that ASL360 significantly improves the QoE, achieving approximately 2 dB higher average video quality, 80% lower average rebuffering time, and 57% lower video quality variation, relative to competitive baseline methods. Our results show the effectiveness of our layered and adaptive approach in enhancing the QoE in immersive videostreaming applications, particularly in dynamic and challenging network environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10544v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MM</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alireza Mohammadhosseini, Jacob Chakareski, Nicholas Mastronarde</dc:creator>
    </item>
    <item>
      <title>Empowering AI-Native 6G Wireless Networks with Quantum Federated Learning</title>
      <link>https://arxiv.org/abs/2509.10559</link>
      <description>arXiv:2509.10559v1 Announce Type: new 
Abstract: AI-native 6G networks are envisioned to tightly embed artificial intelligence (AI) into the wireless ecosystem, enabling real-time, personalized, and privacy-preserving intelligence at the edge. A foundational pillar of this vision is federated learning (FL), which allows distributed model training across devices without sharing raw data. However, implementing classical FL methods faces several bottlenecks in heterogeneous dynamic wireless networks, including limited device compute capacity, unreliable connectivity, intermittent communications, and vulnerability to model security and data privacy breaches. This article investigates the integration of quantum federated learning (QFL) into AI-native 6G networks, forming a transformative paradigm capable of overcoming these challenges. By leveraging quantum techniques across computing, communication, and cryptography within FL workflows, QFL offers new capabilities along three key dimensions: (i) edge intelligence, (ii) network optimization, and (iii) security and privacy, which are studied in this work. We further present a case study demonstrating that a QFL framework employing the quantum approximate optimization algorithm outperforms classical methods in model convergence. We conclude the paper by identifying practical challenges facing QFL deployment, such as quantum state fragility, incompatibility with classical protocols, and hardware constraints, and then outline key research directions toward its scalable real-world adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10559v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaba Shaon, Md Raihan Uddin, Dinh C. Nguyen, Seyyedali Hosseinalipour, Dusit Niyato, Octavia A. Dobre</dc:creator>
    </item>
    <item>
      <title>gNB-based Local Breakout for URLLC in industrial 5G</title>
      <link>https://arxiv.org/abs/2509.10617</link>
      <description>arXiv:2509.10617v1 Announce Type: new 
Abstract: Industrial URLLC workloads-coordinated robotics, automated guided vehicles, machine-vision collaboration require sub-5 ms latency and five-nines reliability. In standardized 5G Multicast/Broadcast Services, intra-cell group traffic remains anchored in the core using MB-SMF/MB-UPF, and the Application Function. This incurs a core network path and packet delay that is avoidable when data transmitters and receivers share a cell. We propose a gNB-local multicast breakout that pivots eligible uplink flows to a downlink point-to-multipoint bearer within the gNB, while maintaining authorization, membership, and policy in the 5G core. The design specifies an eligibility policy, configured-grant uplink. 3GPP security and compliance are preserved via unchanged control-plane anchors. A latency budget and simulation indicate that removing the backhaul/UPF/AF segment reduces end-to-end latency from approximate 6.5-11.5 ms (anchored to the core) to 1.5-4.0 ms (local breakout), producing sub-2 ms averages and a stable gap approximate 10 ms between group sizes. The approach offers a practical, standards-aligned path to deterministic intra-cell group dissemination in private 5G. We outline multi-cell and prototype validation as future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10617v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rajendra Paudyal, Rajendra Upadhyay, Al Nahian Bin Emran, Duminda Wijesekera</dc:creator>
    </item>
    <item>
      <title>Deep Learning based Moving Target Defence for Federated Learning against Poisoning Attack in MEC Systems with a 6G Wireless Model</title>
      <link>https://arxiv.org/abs/2509.10914</link>
      <description>arXiv:2509.10914v1 Announce Type: new 
Abstract: Collaboration opportunities for devices are facilitated with Federated Learning (FL). Edge computing facilitates aggregation at edge and reduces latency. To deal with model poisoning attacks, model-based outlier detection mechanisms may not operate efficiently with hetereogenous models or in recognition of complex attacks. This paper fosters the defense line against model poisoning attack by exploiting device-level traffic analysis to anticipate the reliability of participants. FL is empowered with a topology mutation strategy, as a Moving Target Defence (MTD) strategy to dynamically change the participants in learning. Based on the adoption of recurrent neural networks for time-series analysis of traffic and a 6G wireless model, optimization framework for MTD strategy is given. A deep reinforcement mechanism is provided to optimize topology mutation in adaption with the anticipated Byzantine status of devices and the communication channel capabilities at devices. For a DDoS attack detection application and under Botnet attack at devices level, results illustrate acceptable malicious models exclusion and improvement in recognition time and accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10914v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Somayeh Kianpisheh, Tarik Taleb, Jari Iinatti, JaeSeung Song</dc:creator>
    </item>
    <item>
      <title>RU Energy Modeling for O-RAN in ns3-oran</title>
      <link>https://arxiv.org/abs/2509.10978</link>
      <description>arXiv:2509.10978v1 Announce Type: new 
Abstract: This paper presents a detailed and flexible power consumption model for Radio Units (RUs) in O-RAN using the ns3-oran simulator. This is the first ns3-oran model supporting xApp control to perform the RU power modeling. In contrast to existing frameworks like EARTH or VBS-DRX, the proposed framework is RU-centric and is parameterized by hardware-level features, such as the number of transceivers, the efficiency of the power amplifier, mmWave overheads, and standby behavior. It enables simulation-driven assessment of energy efficiency at various transmit power levels and seamlessly integrates with ns-3's energy tracking system. To help upcoming xApp-driven energy management strategies in O-RAN installations, numerical research validates the model's capacity to represent realistic nonlinear power scaling. It identifies ideal operating points for effective RU behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10978v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdul Wadud, Nima Afraz</dc:creator>
    </item>
    <item>
      <title>Multi-Modal Sensing Aided mmWave Beamforming for V2V Communications with Transformers</title>
      <link>https://arxiv.org/abs/2509.11112</link>
      <description>arXiv:2509.11112v1 Announce Type: new 
Abstract: Beamforming techniques are utilized in millimeter wave (mmWave) communication to address the inherent path loss limitation, thereby establishing and maintaining reliable connections. However, adopting standard defined beamforming approach in highly dynamic vehicular environments often incurs high beam training overheads and reduces the available airtime for communications, which is mainly due to exchanging pilot signals and exhaustive beam measurements. To this end, we present a multi-modal sensing and fusion learning framework as a potential alternative solution to reduce such overheads. In this framework, we first extract the features individually from the visual and GPS coordinates sensing modalities by modality specific encoders, and subsequently fuse the multimodal features to obtain predicted top-k beams so that the best line-of-sight links can be proactively established. To show the generalizability of the proposed framework, we perform a comprehensive experiment in four different vehicle-to-vehicle (V2V) scenarios from real-world multi-modal sensing and communication dataset. From the experiment, we observe that the proposed framework achieves up to 77.58% accuracy on predicting top-15 beams correctly, outperforms single modalities, incurs roughly as low as 2.32 dB average power loss, and considerably reduces the beam searching space overheads by 76.56% for top-15 beams with respect to standard defined approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11112v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Baqer Mollah, Honggang Wang, Hua Fang</dc:creator>
    </item>
    <item>
      <title>On the Feasibility of Inter-Flow Service Degradation Detection</title>
      <link>https://arxiv.org/abs/2509.11140</link>
      <description>arXiv:2509.11140v1 Announce Type: new 
Abstract: Hardware acceleration in modern networks creates monitoring blind spots by offloading flows to a non-observable state, hindering real-time service degradation (SD) detection. To address this, we propose and formalize a novel inter-flow correlation framework, built on the hypothesis that observable flows can act as environmental sensors for concurrent, non-observable flows. We conduct a comprehensive statistical analysis of this inter-flow landscape, revealing a fundamental trade-off: while the potential for correlation is vast, the most explicit signals (i.e., co-occurring SD events) are sparse and rarely perfectly align. Critically, however, our analysis shows these signals frequently precede degradation in the target flow, validating the potential for timely detection. We then evaluate the framework using a standard machine learning model. While the model achieves high classification accuracy, a feature-importance analysis reveals it relies primarily on simpler intra-flow features. This key finding demonstrates that harnessing the complex contextual information requires more than simple models. Our work thus provides not only a foundational analysis of the inter-flow problem but also a clear outline for future research into the structure-aware models needed to solve it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11140v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Balint Bicski, Adrian Pekar</dc:creator>
    </item>
    <item>
      <title>UDFS: Lightweight Representation-Driven Robust Network Traffic Classification</title>
      <link>https://arxiv.org/abs/2509.11157</link>
      <description>arXiv:2509.11157v1 Announce Type: new 
Abstract: In recent years, sequence features such as packet length have received considerable attention due to their central role in encrypted traffic analysis. Existing sequence modeling approaches can be broadly categorized into flow-level and trace-level methods: the former suffer from high feature redundancy, limiting their discriminative power, whereas the latter preserve complete information but incur substantial computational and storage overhead. To address these limitations, we propose the \textbf{U}p-\textbf{D}own \textbf{F}low \textbf{S}equence (\textbf{UDFS}) representation, which compresses an entire trace into a two-dimensional sequence and characterizes each flow by the aggregate of its upstream and downstream traffic, reducing complexity while maintaining high discriminability. Furthermore, to address the challenge of class-specific discriminability differences, we propose an adaptive threshold mechanism that dynamically adjusts training weights and rejection boundaries, enhancing the model's classification performance. Experimental results demonstrate that the proposed method achieves superior classification performance and robustness on both coarse-grained and fine-grained datasets, as well as under concept drift and open-world scenarios. Code and Dataset are available at https://github.com/kid1999/UDFS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11157v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youquan Xian, Xueying Zeng, Mei Huang, Aoxiang Zhou, Xiaoyu Cui, Peng Liu, Lei Cui</dc:creator>
    </item>
    <item>
      <title>Multi-Layer Perceptron-Based Relay Node Selection for Next-Generation Intelligent Delay-Tolerant Networks</title>
      <link>https://arxiv.org/abs/2509.11239</link>
      <description>arXiv:2509.11239v1 Announce Type: new 
Abstract: Delay Tolerant Networks (DTNs) are critical for emergency communication in highly dynamic and challenging scenarios characterized by intermittent connectivity, frequent disruptions, and unpredictable node mobility. While some protocols are widely adopted for simplicity and low overhead, their static replication strategy lacks the ability to adaptively distinguish high-quality relay nodes, often leading to inefficient and suboptimal message dissemination. To address this challenge, we propose a novel intelligent routing enhancement that integrates machine learning-based node evaluation into the Spray and Wait framework. Several dynamic, core features are extracted from simulation logs and are used to train multiple classifiers - Multi-Layer Perceptron (MLP), Support Vector Machine (SVM), and Random Forest (RF) - to predict whether a node is suitable as a relay under dynamic conditions. The trained models are deployed via a lightweight Flask-based RESTful API, enabling real-time, adaptive predictions. We implement the enhanced router MLPBasedSprayRouter, which selectively forwards messages based on the predicted relay quality. A caching mechanism is incorporated to reduce computational overhead and ensure stable, low-latency inference. Extensive experiments under realistic emergency mobility scenarios demonstrate that the proposed framework significantly improves delivery ratio while reducing average latency compared to the baseline protocols. Among all evaluated classifiers, MLP achieved the most robust performance, consistently outperforming both SVM and RF in terms of accuracy, adaptability, and inference speed. These results confirm the novelty and practicality of integrating machine learning into DTN routing, paving the way for resilient and intelligent communication systems in smart cities, disaster recovery, and other dynamic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11239v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhekun Huang, Milena Radenkovic</dc:creator>
    </item>
    <item>
      <title>Energy-Aware 6G Network Design: A Survey</title>
      <link>https://arxiv.org/abs/2509.11289</link>
      <description>arXiv:2509.11289v1 Announce Type: new 
Abstract: 6th Generation (6G) mobile networks are envisioned to support several new capabilities and data-centric applications for unprecedented number of users, potentially raising significant energy efficiency and sustainability concerns. This brings focus on sustainability as one of the key objectives in the their design. To move towards sustainable solution, research and standardization community is focusing on several key issues like energy information monitoring and exposure, use of renewable energy, and use of Artificial Intelligence/Machine Learning (AI/ML) for improving the energy efficiency in 6G networks. The goal is to build energy-aware solutions that takes into account the energy information resulting in energy efficient networks. Design of energy-aware 6G networks brings in new challenges like increased overheads in gathering and exposing of energy related information, and the associated user consent management. The aim of this paper is to provide a comprehensive survey of methods used for design of energy efficient 6G networks, like energy harvesting, energy models and parameters, classification of energy-aware services, and AI/ML-based solutions. The survey also includes few use cases that demonstrate the benefits of incorporating energy awareness into network decisions. Several ongoing standardization efforts in 3GPP, ITU, and IEEE are included to provide insights into the ongoing work and highlight the opportunities for new contributions. We conclude this survey with open research problems and challenges that can be explored to make energy-aware design feasible and ensure optimality regarding performance and energy goals for 6G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11289v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rashmi Kamran, Mahesh Ganesh Bhat, Pranav Jha, Shana Moothedath, Manjesh Hanawal, Prasanna Chaporkar</dc:creator>
    </item>
    <item>
      <title>Federated Edge Learning for Predictive Maintenance in 6G Small Cell Networks</title>
      <link>https://arxiv.org/abs/2509.11421</link>
      <description>arXiv:2509.11421v1 Announce Type: new 
Abstract: The rollout of 6G networks introduces unprecedented demands for autonomy, reliability, and scalability. However, the transmission of sensitive telemetry data to central servers raises concerns about privacy and bandwidth. To address this, we propose a federated edge learning framework for predictive maintenance in 6G small cell networks. The system adopts a Knowledge Defined Networking (KDN) architecture in Data, Knowledge, and Control Planes to support decentralized intelligence, telemetry-driven training, and coordinated policy enforcement. In the proposed model, each base station independently trains a failure prediction model using local telemetry metrics, including SINR, jitter, delay, and transport block size, without sharing raw data. A threshold-based multi-label encoding scheme enables the detection of concurrent fault conditions. We then conduct a comparative analysis of centralized and federated training strategies to evaluate their performance in this context. A realistic simulation environment is implemented using the ns-3 mmWave module, incorporating hybrid user placement and base station fault injection across various deployment scenarios. The learning pipeline is orchestrated via the Flower framework, and model aggregation is performed using the Federated Averaging (FedAvg) algorithm. Experimental results demonstrate that the federated model achieves performance comparable to centralized training in terms of accuracy and per-label precision, while preserving privacy and reducing communication overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11421v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yusuf Emir Sezgin, Mehmet \"Ozdem, Tu\u{g}\c{c}e Bilen</dc:creator>
    </item>
    <item>
      <title>Towards Dynamic Urban Scene Synthesis: The Digital Twin Descriptor Service</title>
      <link>https://arxiv.org/abs/2509.11810</link>
      <description>arXiv:2509.11810v1 Announce Type: new 
Abstract: Digital twins have been introduced as supporters to city operations, yet existing scene-descriptor formats and digital twin platforms often lack the integration, federation, and adaptable connectivity that urban environments demand. Modern digital twin platforms decouple data streams and representations into separate architectural planes, fusing them only at the visualization layer and limiting potential for simulation or further processing of the combined assets. At the same time, geometry-centric file standards for digital twin description, and services built on top of them, focus primarily on explicitly declaring geometry and additional structural or photorealistic parameters, making integration with evolving context information a complicated process while limiting compatibility with newer representation methods. Additionally, multi-provider federation, critical in smart city services where multiple stakeholders may control distinct infrastructure or representation assets, is sparsely supported. Consequently, most pilots isolate context and representation, fusing them per use case with ad hoc components and custom description files or glue code, which hinders interoperability. To address these gaps, this paper proposes a novel concept, the 'Digital Twin Descriptor Service (DTDS)' that fuses abstracted references to geometry assets and context information within a single, extensible descriptor service through NGSI-LD. The proposed DTDS provides dynamic and federated integration of context data, representations, and runtime synchronization across heterogeneous engines and simulators. This concept paper outlines the DTDS architectural components and description ontology that enable digital-twin processes in the modern smart city.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11810v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ioannis Tsampras, Georgios Stergiopoulos, Tanya Politi, Spyros Denazis</dc:creator>
    </item>
    <item>
      <title>Optimization for Massive 3D-RIS Deployment: A Generative Diffusion Model-Based Approach</title>
      <link>https://arxiv.org/abs/2509.11969</link>
      <description>arXiv:2509.11969v1 Announce Type: new 
Abstract: Reconfigurable Intelligent Surfaces (RISs) transform the wireless environment by modifying the amplitude, phase, and polarization of incoming waves, significantly improving coverage performance. Notably, optimizing the deployment of RISs becomes vital, but existing optimization methods face challenges such as high computational complexity, limited adaptability to changing environments, and a tendency to converge on local optima. In this paper, we propose to optimize the deployment of large-scale 3D RISs using a diffusion model based on probabilistic generative learning. We begin by dividing the target area into fixed grids, with each grid corresponding to a potential deployment location. Then, a multi-RIS deployment optimization problem is formulated, which is difficult to solve directly. By treating RIS deployment as a conditional generation task, the well-trained diffusion model can generate the distribution of deployment strategies, and thus, the optimal deployment strategy can be obtained by sampling from this distribution. Simulation results demonstrate that the proposed diffusion-based method outperforms traditional benchmark approaches in terms of exceed ratio and generalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11969v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaining Wang, Bo Yang, Zhiwen Yu, Xuelin Cao, M\'erouane Debbah, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Information Entropy-Based Scheduling for Communication-Efficient Decentralized Learning</title>
      <link>https://arxiv.org/abs/2507.17426</link>
      <description>arXiv:2507.17426v1 Announce Type: cross 
Abstract: This paper addresses decentralized stochastic gradient descent (D-SGD) over resource-constrained networks by introducing node-based and link-based scheduling strategies to enhance communication efficiency. In each iteration of the D-SGD algorithm, only a few disjoint subsets of nodes or links are randomly activated, subject to a given communication cost constraint. We propose a novel importance metric based on information entropy to determine node and link scheduling probabilities. We validate the effectiveness of our approach through extensive simulations, comparing it against state-of-the-art methods, including betweenness centrality (BC) for node scheduling and \textit{MATCHA} for link scheduling. The results show that our method consistently outperforms the BC-based method in the node scheduling case, achieving faster convergence with up to 60\% lower communication budgets. At higher communication budgets (above 60\%), our method maintains comparable or superior performance. In the link scheduling case, our method delivers results that are superior to or on par with those of \textit{MATCHA}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17426v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaiprakash Nagar, Zheng Chen, Marios Kountouris, Photios A. Stavrou</dc:creator>
    </item>
    <item>
      <title>Agentic DDQN-Based Scheduling for Licensed and Unlicensed Band Allocation in Sidelink Networks</title>
      <link>https://arxiv.org/abs/2509.06775</link>
      <description>arXiv:2509.06775v1 Announce Type: cross 
Abstract: This paper presents an agentic artificial intelligence (AI)-driven double deep Q-network (DDQN) scheduling framework for licensed and unlicensed band allocation in New Radio (NR) sidelink (SL) networks. SL must share licensed spectrum with cellular communications (CC) and unlicensed bands with Wi-Fi, posing significant challenges for coexistence. Unlike prior rule-based or threshold-based methods, the proposed agentic scheduler autonomously perceives queueing dynamics, channel conditions, and coexistence states, and adapts its policy to maintain quality-of-service (QoS). Simulation results show that our framework reduces the blocking rate by up to 87.5% compared to threshold-based scheduling under limited licensed bandwidth. These findings demonstrate the potential of Agentic AI to enable stable, QoS-aware, and adaptive scheduling for future NR SL systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06775v1</guid>
      <category>eess.SY</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Po-Heng Chou, Pin-Qi Fu, Walid Saad, Li-Chun Wang</dc:creator>
    </item>
    <item>
      <title>Cost-Free Personalization via Information-Geometric Projection in Bayesian Federated Learning</title>
      <link>https://arxiv.org/abs/2509.10132</link>
      <description>arXiv:2509.10132v1 Announce Type: cross 
Abstract: Bayesian Federated Learning (BFL) combines uncertainty modeling with decentralized training, enabling the development of personalized and reliable models under data heterogeneity and privacy constraints. Existing approaches typically rely on Markov Chain Monte Carlo (MCMC) sampling or variational inference, often incorporating personalization mechanisms to better adapt to local data distributions. In this work, we propose an information-geometric projection framework for personalization in parametric BFL. By projecting the global model onto a neighborhood of the user's local model, our method enables a tunable trade-off between global generalization and local specialization. Under mild assumptions, we show that this projection step is equivalent to computing a barycenter on the statistical manifold, allowing us to derive closed-form solutions and achieve cost-free personalization. We apply the proposed approach to a variational learning setup using the Improved Variational Online Newton (IVON) optimizer and extend its application to general aggregation schemes in BFL. Empirical evaluations under heterogeneous data distributions confirm that our method effectively balances global and local performance with minimal computational overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10132v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nour Jamoussi, Giuseppe Serra, Photios A. Stavrou, Marios Kountouris</dc:creator>
    </item>
    <item>
      <title>Large-Scale Network Utility Maximization via GPU-Accelerated Proximal Message Passing</title>
      <link>https://arxiv.org/abs/2509.10722</link>
      <description>arXiv:2509.10722v1 Announce Type: cross 
Abstract: We present a GPU-accelerated proximal message passing algorithm for large-scale network utility maximization (NUM). NUM is a fundamental problem in resource allocation, where resources are allocated across various streams in a network to maximize total utility while respecting link capacity constraints. Our method, a variant of ADMM, requires only sparse matrix-vector multiplies with the link-route matrix and element-wise proximal operator evaluations, enabling fully parallel updates across streams and links. It also supports heterogeneous utility types, including logarithmic utilities common in NUM, and does not assume strict concavity. We implement our method in PyTorch and demonstrate its performance on problems with tens of millions of variables and constraints, achieving 4x to 20x speedups over existing CPU and GPU solvers and solving problem sizes that exhaust the memory of baseline methods. Additionally, we show that our algorithm is robust to congestion and link-capacity degradation. Finally, using a time-expanded transit seat allocation case study, we illustrate how our approach yields interpretable allocations in realistic networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10722v1</guid>
      <category>math.OC</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akshay Sreekumar, Anthony Degleris, Ram Rajagopal</dc:creator>
    </item>
    <item>
      <title>Agent-based Simulation for Drone Charging in an Internet of Things Environment System</title>
      <link>https://arxiv.org/abs/2509.10867</link>
      <description>arXiv:2509.10867v1 Announce Type: cross 
Abstract: This paper presents an agent-based simulation model for coordinating battery recharging in drone swarms, focusing on applications in Internet of Things (IoT) and Industry 4.0 environments. The proposed model includes a detailed description of the simulation methodology, system architecture, and implementation. One practical use case is explored: Smart Farming, highlighting how autonomous coordination strategies can optimize battery usage and mission efficiency in large-scale drone deployments. This work uses a machine learning technique to analyze the agent-based simulation sensitivity analysis output results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10867v1</guid>
      <category>cs.MA</category>
      <category>cs.NI</category>
      <category>cs.RO</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leonardo Grando, Jos\'e Roberto Emiliano Leite, Edson Luiz Ursini</dc:creator>
    </item>
    <item>
      <title>Task-Agnostic Learnable Weighted-Knowledge Base Scheme for Robust Semantic Communications</title>
      <link>https://arxiv.org/abs/2509.11636</link>
      <description>arXiv:2509.11636v1 Announce Type: cross 
Abstract: With the emergence of diverse and massive data in the upcoming sixth-generation (6G) networks, the task-agnostic semantic communication system is regarded to provide robust intelligent services. In this paper, we propose a task-agnostic learnable weighted-knowledge base semantic communication (TALSC) framework for robust image transmission to address the real-world heterogeneous data bias in KB, including label flipping noise and class imbalance. The TALSC framework incorporates a sample confidence module (SCM) as meta-learner and the semantic coding networks as learners. The learners are updated based on the empirical knowledge provided by the learnable weighted-KB (LW-KB). Meanwhile, the meta-learner evaluates the significance of samples according to the task loss feedback, and adjusts the update strategy of learners to enhance the robustness in semantic recovery for unknown tasks. To strike a balance between SCM parameters and precision of significance evaluation, we design an SCM-grid extension (SCM-GE) approach by embedding the Kolmogorov-Arnold networks (KAN) within SCM, which leverages the concept of spline refinement in KAN and enables scalable SCM with customizable granularity without retraining. Simulations demonstrate that the TALSC framework effectively mitigates the effects of flipping noise and class imbalance in task-agnostic image semantic communication, achieving at least 12% higher semantic recovery accuracy (SRA) and multi-scale structural similarity (MS-SSIM) compared to state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11636v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiyao Jiang, Jian Jiao, Xingjian Zhang, Ye Wang, Dusit Niyato, Qinyu Zhang</dc:creator>
    </item>
    <item>
      <title>Beyond Regularity: Modeling Chaotic Mobility Patterns for Next Location Prediction</title>
      <link>https://arxiv.org/abs/2509.11713</link>
      <description>arXiv:2509.11713v1 Announce Type: cross 
Abstract: Next location prediction is a key task in human mobility analysis, crucial for applications like smart city resource allocation and personalized navigation services. However, existing methods face two significant challenges: first, they fail to address the dynamic imbalance between periodic and chaotic mobile patterns, leading to inadequate adaptation over sparse trajectories; second, they underutilize contextual cues, such as temporal regularities in arrival times, which persist even in chaotic patterns and offer stronger predictability than spatial forecasts due to reduced search spaces. To tackle these challenges, we propose \textbf{\method}, a \underline{\textbf{C}}h\underline{\textbf{A}}otic \underline{\textbf{N}}eural \underline{\textbf{O}}scillator n\underline{\textbf{E}}twork for next location prediction, which introduces a biologically inspired Chaotic Neural Oscillatory Attention mechanism to inject adaptive variability into traditional attention, enabling balanced representation of evolving mobility behaviors, and employs a Tri-Pair Interaction Encoder along with a Cross Context Attentive Decoder to fuse multimodal ``who-when-where'' contexts in a joint framework for enhanced prediction performance. Extensive experiments on two real-world datasets demonstrate that CANOE consistently and significantly outperforms a sizeable collection of state-of-the-art baselines, yielding 3.17\%-13.11\% improvement over the best-performing baselines across different cases. In particular, CANOE can make robust predictions over mobility trajectories of different mobility chaotic levels. A series of ablation studies also supports our key design choices. Our code is available at: https://github.com/yuqian2003/CANOE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11713v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqian Wu, Yuhong Peng, Jiapeng Yu, Xiangyu Liu, Zeting Yan, Kang Lin, Weifeng Su, Bingqing Qu, Raymond Lee, Dingqi Yang</dc:creator>
    </item>
    <item>
      <title>A Uniqueness Theorem for Distributed Computation under Physical Constraint</title>
      <link>https://arxiv.org/abs/2509.11754</link>
      <description>arXiv:2509.11754v1 Announce Type: cross 
Abstract: Foundational models of computation often abstract away physical hardware limitations. However, in extreme environments like In-Network Computing (INC), these limitations become inviolable laws, creating an acute trilemma among communication efficiency, bounded memory, and robust scalability. Prevailing distributed paradigms, while powerful in their intended domains, were not designed for this stringent regime and thus face fundamental challenges. This paper demonstrates that resolving this trilemma requires a shift in perspective - from seeking engineering trade-offs to deriving solutions from logical necessity. We establish a rigorous axiomatic system that formalizes these physical constraints and prove that for the broad class of computations admitting an idempotent merge operator, there exists a unique, optimal paradigm. Any system satisfying these axioms must converge to a single normal form: Self-Describing Parallel Flows (SDPF), a purely data-centric model where stateless executors process flows that carry their own control logic. We further prove this unique paradigm is convergent, Turing-complete, and minimal. In the same way that the CAP theorem established a boundary for what is impossible in distributed state management, our work provides a constructive dual: a uniqueness theorem that reveals what is \textit{inevitable} for distributed computation flows under physical law.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11754v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyuan Ren, Mingxuan Lu, Wenchi Cheng</dc:creator>
    </item>
    <item>
      <title>From private to public governance: The case for reconfiguring energy systems as a commons</title>
      <link>https://arxiv.org/abs/2008.04028</link>
      <description>arXiv:2008.04028v2 Announce Type: replace-cross 
Abstract: The discussions around the unsustainability of the dominant socio-economic structures have yet to produce solutions to address the escalating problems we face as a species. Such discussions, this paper argues, are hindered by the limited scope of the proposed solutions within a business-as-usual context as well as by the underlying technological rationale upon which these solutions are developed. In this paper, we conceptualize a radical sustainable alternative to the energy conundrum based on an emerging mode of production and a commons-based political economy. We propose a commons-oriented Energy Internet as a potential system for energy production and consumption, which may be better suited to tackle the current issues society faces. We conclude by referring to some of the challenges that the implementation of such a proposal would entail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.04028v2</guid>
      <category>eess.SY</category>
      <category>cs.CY</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.erss.2020.101737</arxiv:DOI>
      <dc:creator>Chris Giotitsas, Pedro H. J. Nardelli, Vasilis Kostakis, Arun Narayanan</dc:creator>
    </item>
    <item>
      <title>Magnetic Localization for In-Body Nano-Communication Medical Systems</title>
      <link>https://arxiv.org/abs/2403.02497</link>
      <description>arXiv:2403.02497v2 Announce Type: replace-cross 
Abstract: Nano-machines circulating inside the human body, collecting data on tissue conditions, represent a vital part of next-generation medical diagnostic systems. However, for these devices to operate effectively, they need to relay not only their medical measurements but also their positions. This paper introduces a novel localization method for in-body nano-machines based on the magnetic field, leveraging the advantageous magnetic permeability of all human tissues. The entire proposed localization system is described, starting from 10 um x 10 um magnetometers to be integrated into the nano-machines, to a set of external wires generating the magnetic field. Mathematical equations for the localization algorithm are also provided, assuming the nano-machines do not execute the computations themselves, but transmit their magnetic field measurements together with medical data outside of the body. The whole system is validated with computer simulations that capture the measurement error of the magnetometers, the error induced by the Earth magnetic field, and a human body model assuming different possible positions of nano-machines. The results show a very high system accuracy with position errors even below 1 cm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02497v2</guid>
      <category>cs.IR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/JSEN.2024.3432167</arxiv:DOI>
      <arxiv:journal_reference>IEEE Sensors Journal, vol. 24, no. 19, pp. 30304-30314, October 2024</arxiv:journal_reference>
      <dc:creator>Krzysztof Skos, Albert Diez Comas, Josep Miquel Jornet, Pawel Kulakowski</dc:creator>
    </item>
    <item>
      <title>Toward a Sustainable Low-Altitude Economy: A Survey of Energy-Efficient RIS-UAV Networks</title>
      <link>https://arxiv.org/abs/2504.02162</link>
      <description>arXiv:2504.02162v2 Announce Type: replace-cross 
Abstract: The integration of RIS into UAV networks presents a transformative solution for achieving energy-efficient and reliable communication, particularly within the rapidly expanding low-altitude economy (LAE). As UAVs facilitate diverse aerial services-spanning logistics to smart surveillance-their limited energy reserves create significant challenges. RIS effectively addresses this issue by dynamically shaping the wireless environment to enhance signal quality, reduce power consumption, and extend UAV operation time, thus enabling sustainable and scalable deployment across various LAE applications. This survey provides a comprehensive review of RIS-assisted UAV networks, focusing on energy-efficient design within LAE applications. We begin by introducing the fundamentals of RIS, covering its operational modes, deployment architectures, and roles in both terrestrial and aerial environments. Next, advanced EE-driven strategies for integrating RIS and UAVs. Techniques such as trajectory optimization, power control, beamforming, and dynamic resource management are examined. Emphasis is placed on collaborative solutions that incorporate UAV-mounted RIS, wireless energy harvesting (EH), and intelligent scheduling frameworks. We further categorize RIS-enabled schemes based on key performance objectives relevant to LAE scenarios. These objectives include sum rate maximization, coverage extension, QoS guarantees, secrecy rate improvement, latency reduction, and age of information (AoI) minimization. The survey also delves into RIS-UAV synergy with emerging technologies like MEC, NOMA, V2X communication, and WPT. These technologies are crucial to the LAE ecosystem. Finally, we outline open research challenges and future directions, emphasizing the critical role of energy-aware, RIS-enhanced UAV networks in shaping scalable, sustainable, and intelligent infrastructures within the LAE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02162v2</guid>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manzoor Ahmed, Aized Amin Soofi, Feroz Khan, Salman Raza, Wali Ullah Khan, Lina Su, Fang Xu, Zhu Han</dc:creator>
    </item>
    <item>
      <title>Realistic UE Antennas for 6G in the 3GPP Channel Model</title>
      <link>https://arxiv.org/abs/2509.10357</link>
      <description>arXiv:2509.10357v2 Announce Type: replace-cross 
Abstract: The transition to 6G has driven significant updates to the 3GPP channel model, particularly in modeling UE antennas and user-induced blockage for handheld devices. The 3GPP Rel.19 revision of TR 38.901 introduces a more realistic framework that captures directive antenna patterns, practical antenna placements, polarization effects, and element-specific blockage. These updates are based on high-fidelity simulations and measurements of a reference smartphone across multiple frequency ranges. By aligning link- and system-level simulations with real-world device behavior, the new model enables more accurate evaluation of 6G technologies and supports consistent performance assessment across industry and research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10357v2</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Tue, 16 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Svendsen, Dimitri Gold, Christian Rom, Volker Pauli, Vuokko Nurmela</dc:creator>
    </item>
  </channel>
</rss>
