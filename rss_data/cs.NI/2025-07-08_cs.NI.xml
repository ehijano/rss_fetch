<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Jul 2025 04:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An End-to-End Assurance Framework for AI/ML Workloads in Datacenters</title>
      <link>https://arxiv.org/abs/2507.03158</link>
      <description>arXiv:2507.03158v1 Announce Type: new 
Abstract: Modern machine learning workloads such as large language model training, fine-tuning jobs are highly distributed and span across hundreds of systems with multiple GPUs. Job completion time for these workloads is the artifact of the application, compute, network and storage performance. In case of failure or degraded performance it is imperative to understand the root cause and possible remediation for the problem for end-to-end assurance. This demo showcases SaaSbased observability and automated troubleshooting for AI/ML workload performance issues using cross-layer telemetry and logs (e.g., Application telemetry, Collective communication logs, GPU Health metrics, Network Flow Data, NIC ROCEv2 telemetry). Different use cases are demonstrated for end-to-end assurance such as Cross-layer Dependency Graph, Cross-layer Service Level Expectations, Automated Root Cause Analysis, GPU-toGPU application path tracing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03158v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jit Gupta, Tarun Banka, Rahul Gupta, Mithun Dharmaraj, Jasleen Kaur</dc:creator>
    </item>
    <item>
      <title>RCA Copilot: Transforming Network Data into Actionable Insights via Large Language Models</title>
      <link>https://arxiv.org/abs/2507.03224</link>
      <description>arXiv:2507.03224v1 Announce Type: new 
Abstract: Ensuring the reliability and availability of complex networked services demands effective root cause analysis (RCA) across cloud environments, data centers, and on-premises networks. Traditional RCA methods, which involve manual inspection of data sources such as logs and telemetry data, are often time-consuming and challenging for on-call engineers. While statistical inference methods have been employed to estimate the causality of network events, these approaches alone are similarly challenging and suffer from a lack of interpretability, making it difficult for engineers to understand the predictions made by black-box models. In this paper, we present RCACopilot, an advanced on-call system that combines statistical tests and large language model (LLM) reasoning to automate RCA across various network environments. RCACopilot gathers and synthesizes critical runtime diagnostic information, predicts the root cause of incidents, provides a clear explanatory narrative, and offers targeted action steps for engineers to resolve the issues. By utilizing LLM reasoning techniques and retrieval, RCACopilot delivers accurate and practical support for operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03224v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Shan, Jasleen Kaur, Rahul Singh, Tarun Banka, Raj Yavatkar, T. Sridhar</dc:creator>
    </item>
    <item>
      <title>OpenSN: An Open Source Library for Emulating LEO Satellite Networks</title>
      <link>https://arxiv.org/abs/2507.03248</link>
      <description>arXiv:2507.03248v1 Announce Type: new 
Abstract: Low-earth-orbit (LEO) satellite constellations (e.g., Starlink) are becoming a necessary component of future Internet. There have been increasing studies on LEO satellite networking. It is a crucial problem how to evaluate these studies in a systematic and reproducible manner. In this paper, we present OpenSN, i.e., an open source library for emulating large-scale satellite network (SN). Different from Mininet-based SN emulators (e.g., LeoEM), OpenSN adopts container-based virtualization, thus allows for running distributed routing software on each node, and can achieve horizontal scalability via flexible multi-machine extension. Compared to other container-based SN emulators (e.g., StarryNet), OpenSN streamlines the interaction with Docker command line interface and significantly reduces unnecessary operations of creating virtual links. These modifications improve emulation efficiency and vertical scalability on a single machine. Furthermore, OpenSN separates user-defined configuration from container network management via a Key-Value Database that records the necessary information for SN emulation. Such a separation architecture enhances the function extensibility. To sum up, OpenSN exhibits advantages in efficiency, scalability, and extensibility, thus is a valuable open source library that empowers research on LEO satellite networking. Experiment results show that OpenSN constructs mega-constellations 5X-10X faster than StarryNet, and updates link state 2X-4X faster than LeoEM. We also verify the scalability of OpenSN by successfully emulating the five-shell Starlink constellation with a total of 4408 satellites.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03248v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TPDS.2025.3575920</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Parallel and Distributed Systems (TPDS), 2025</arxiv:journal_reference>
      <dc:creator>Wenhao Lu, Zhiyuan Wang, Hefan Zhang, Shan Zhang, Hongbin Luo</dc:creator>
    </item>
    <item>
      <title>Low-power Wireless Network with Real-Time Guarantees for Edge-Cloud Applications</title>
      <link>https://arxiv.org/abs/2507.03317</link>
      <description>arXiv:2507.03317v1 Announce Type: new 
Abstract: The goal of this project is to explore the feasibility of building a scalable &amp; easy-to-deploy real-time LoRa testbed, made from multiple units of Raspberry Pi (RPI), where each RPI manages its own set of LoRa radios. This project is motivated by the lack of concrete large-scale LoRa testbeds that effectively integrate LoRa communications into the real-time world. The paper introduces how the idea of using RPI came about and why it should work in theory. The paper then carries out experiments on a component of the large-scale testbed, to evaluate the feasibility of the said component based on performance metrics such as RSSI, SNR, PLR and the ability to carry out millisecond-accurate transmissions. The performance metrics are also used to explore the impact of using different combinations of spread factors and transmission frequencies, as well as making comparisons between time-division multiple access (TDMA) and carrier-sense multiple access (CSMA) approaches. The results show that with the right parameters configured, the system can achieve stable and low-latency communications, proving some feasibility to operate under real-time situations. Future work includes giving each RPI control over more radios, carrying out true parallel transmissions, and finally integrating multiple RPIs for a more complete large-scale real-time LoRa testbed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03317v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Don Tan</dc:creator>
    </item>
    <item>
      <title>AoI-Energy-Spectrum Optimization in Post-Disaster Powered Communication Intelligent Network via Hierarchical Heterogeneous Graph Neural Network</title>
      <link>https://arxiv.org/abs/2507.03401</link>
      <description>arXiv:2507.03401v1 Announce Type: new 
Abstract: This paper designs a post-disaster powered communication intelligent network (PDPCIN) to address communication disruptions caused by ground base station (GBS) failures within the post-disaster area. PDPCIN employs unmanned aerial vehicles (UAVs) to provide wireless data collection (WDC) and wireless energy transmission (WET) for affected areas and leverages low earth orbit satellites (LEO SATs) to relay UAV data to the nearest survival GBS. To ensure basic post-disaster communication while co-optimizing age of information (AoI), energy efficiency, and spectrum efficiency, intelligent synchronization-UAV (IS-UAV) architecture, AoI-based four thresholds updating (AFTU) mechanism, and Dynamic multi-LEO access (DMLA) strategy are proposed. However, three key challenges remain: time-varying task-resource imbalances, complex topology caused by multi-device scheduling, and nonlinear coupling in multidimensional metric optimization, making system optimization NP-hard. Therefore, this paper proposes a hierarchical heterogeneous graph neural networks (HHGNN) framework. It models heterogeneous device nodes and their communication relations as a hierarchical heterogeneous graph structure, integrating our defined graph sensing, exchange, and mask layer to handle the network's input, feature propagation, and output. To search appropriate number of single-LEO SATs, we propose single-LEO SAT density optimization (S-LSDO) algorithm. Finally, we compare the proposed scheme with state-of-the-art benchmarks to validate its superior collaborative optimization of AoI, energy efficiency, and spectrum efficiency. Based on this, we derive the expressions for the expected values of AoI and stagnant AoI proportion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03401v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanjian Liu, Jinsong Gui</dc:creator>
    </item>
    <item>
      <title>RateCount: Learning-Free Device Counting by Wi-Fi Probe Listening</title>
      <link>https://arxiv.org/abs/2507.03873</link>
      <description>arXiv:2507.03873v1 Announce Type: new 
Abstract: A Wi-Fi-enabled device, or simply Wi-Fi device, sporadically broadcasts probe request frames (PRFs) to discover nearby access points (APs), whether connected to an AP or not. To protect user privacy, unconnected devices often randomize their MAC addresses in the PRFs, known as MAC address randomization. While prior works have achieved accurate device counting under MAC address randomization, they typically rely on machine learning, resulting in inefficient deployment due to the time-consuming processes of data cleaning, model training, and hyperparameter tuning. To enhance deployment efficiency, we propose RateCount, an accurate, lightweight, and learning-free counting approach based on the rate at which APs receive PRFs within a window. RateCount employs a provably unbiased closed-form expression to estimate the device count time-averaged over the window and an error model to compute the lower bound of the estimation variance. We also demonstrate how to extend RateCount to people counting by incorporating a device-to-person calibration scheme. Through extensive real-world experiments conducted at multiple sites spanning a wide range of counts, we show that RateCount, without any deployment costs for machine learning, achieves comparable counting accuracy with the state-of-the-art learning-based device counting and improves previous people counting schemes by a large margin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03873v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianlang He, Zhangyu Chang, S. -H. Gary Chan</dc:creator>
    </item>
    <item>
      <title>Optimizing Age of Trust and Throughput in Multi-Hop UAV-Aided IoT Networks</title>
      <link>https://arxiv.org/abs/2507.03950</link>
      <description>arXiv:2507.03950v1 Announce Type: new 
Abstract: Devices operating in Internet of Things (IoT) networks may be deployed across vast geographical areas and interconnected via multi-hop communications. Further, they may be unguarded. This makes them vulnerable to attacks and motivates operators to check on devices frequently. To this end, we propose and study an Unmanned Aerial Vehicle (UAV)-aided attestation framework for use in IoT networks with a charging station powered by solar. A key challenge is optimizing the trajectory of the UAV to ensure it attests as many devices as possible. A trade-off here is that devices being checked by the UAV are offline, which affects the amount of data delivered to a gateway. Another challenge is that the charging station experiences time-varying energy arrivals, which in turn affect the flight duration and charging schedule of the UAV. To address these challenges, we employ a Deep Reinforcement Learning (DRL) solution to optimize the UAV's charging schedule and the selection of devices to be attested during each flight. The simulation results show that our solution reduces the average age of trust by 88% and throughput loss due to attestation by 30%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03950v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizhou Luo, Kwan-Wu Chin, Ruyi Guan, Xi Xiao, Caimeng Wang, Jingyin Feng, Tengjiao He</dc:creator>
    </item>
    <item>
      <title>In-Network Memory Access: Bridging SmartNIC and Host Memory</title>
      <link>https://arxiv.org/abs/2507.04001</link>
      <description>arXiv:2507.04001v1 Announce Type: new 
Abstract: SmartNICs have been increasingly utilized across various applications to offload specific computational tasks, thereby enhancing overall system performance. However, this offloading process introduces several communication challenges that must be addressed for effective integration. A key challenge lies in establishing efficient communication between the offloaded components and the main application running on the host. In this study, we evaluate different approaches for achieving memory access between the host and SmartNIC. We analyze memory access performance on both the SmartNIC and the host to support in-network applications and guide the selection of an appropriate memory access design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04001v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammed Zain Farooqi, Masoud Hemmatpour, Tore Heide Larsen</dc:creator>
    </item>
    <item>
      <title>Graph Diffusion-Based AeBS Deployment and Resource Allocation for RSMA-Enabled URLLC Low-Altitude Economy Networks</title>
      <link>https://arxiv.org/abs/2507.04081</link>
      <description>arXiv:2507.04081v1 Announce Type: new 
Abstract: As a key component of low-altitude economic networks, aerial base stations (AeBSs) provide flexible and reliable wireless coverage to support 6G ultra-reliable and low-latency communication (URLLC) services. However, limited spectrum resources and severe co-channel interference pose significant challenges to the deployment and resource allocation of AeBSs. To address these limitations, this paper proposes a novel rate-splitting multiple access (RSMA)-enabled transmission design to flexibly manage interference and effectively enhance URLLC services in spectrum-constrained multi-AeBS networks. On this basis, we formulate a joint optimization problem involving AeBS deployment, user association, and resource allocation to maximize the achievable sum rate and coverage of the total system. Given the NP-hard nature of the problem and the highly dynamic environment, we propose a novel alternating optimization framework based on the generative graph diffusion models. Specifically, we model AeBSs and ground users as graph nodes, then we employ a discrete graph generation process solved via denoising diffusion is employed to explore the combinatorial space of deployment and association strategies. Moreover, the algorithm adopts the successive convex approximation (SCA) method to optimize AeBS beamforming and RSMA rate allocation under finite blocklength constraints. Extensive simulations demonstrate that the proposed algorithm outperforms existing methods in terms of convergence speed, sum rate, and coverage, while also exhibiting robust performance under varying network densities and interference levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04081v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xudong Wang, Lei Feng, Jiacheng Wang, Hongyang Du, Changyuan Zhao, Wenjing Li, Zehui Xiong, Dusit Niyato, Ping Zhang</dc:creator>
    </item>
    <item>
      <title>Resource-Efficient Seamless Transitions For High-Performance Multi-hop UAV Multicasting</title>
      <link>https://arxiv.org/abs/2507.04421</link>
      <description>arXiv:2507.04421v1 Announce Type: new 
Abstract: Many UAV-related applications require group communications between UAVs to reliably and efficiently deliver rich media content as well as to extend line-of-sight coverage between sky and ground. This paper studies fast yet resource-efficient UAV transitions while maintaining high multicasting performance. We develop a set of analytic and algorithmic results to form the efficient transition formation (ETF) algorithm that deals with different UAV transition scenarios in a multicasting environment. The ETF algorithm first evaluates the seamlessness of a straight-line trajectory (SLT), by processing low-complexity computations (e.g., Euclidean distances) or a chain of fast checks with controlled traffic overheads. For an interrupted SLT, ETF establishes a new trajectory consisting of a minimum number of seamless straight lines that join at specially selected locations in terms of controlling mobile UAVs' seamless travel distances. Our simulation studies quantify the multicasting performance gains that ETF allows, outperforming compared studies when seamlessly transiting UAV group members.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04421v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wanqing Tu</dc:creator>
    </item>
    <item>
      <title>TeleSim: A Network-Aware Testbed and Benchmark Dataset for Telerobotic Applications</title>
      <link>https://arxiv.org/abs/2507.04425</link>
      <description>arXiv:2507.04425v1 Announce Type: new 
Abstract: Telerobotic technologies are becoming increasingly essential in fields such as remote surgery, nuclear decommissioning, and space exploration. Reliable datasets and testbeds are essential for evaluating telerobotic system performance prior to real-world deployment. However, there is a notable lack of datasets that capture the impact of network delays, as well as testbeds that realistically model the communication link between the operator and the robot. This paper introduces TeleSim, a network-aware teleoperation dataset and testbed designed to assess the performance of telerobotic applications under diverse network conditions. TeleSim systematically collects performance data from fine manipulation tasks executed under three predefined network quality tiers: High, Medium, and Low. Each tier is characterized through controlled settings of bandwidth, latency, jitter, and packet loss. Using OMNeT++ for precise network simulation, we record a wide range of metrics, including completion time, success rates, video quality indicators (Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure (SSIM)), and quality of service (QoS) parameters. TeleSim comprises 300 experimental trials, providing a robust benchmark for evaluating teleoperation systems across heterogeneous network scenarios. In the worst network condition, completion time increases by 221.8% and success rate drops by 64%. Our findings reveal that network degradation leads to compounding negative impacts, notably reduced video quality and prolonged task execution, highlighting the need for adaptive, resilient teleoperation protocols. The full dataset and testbed software are publicly available on our GitHub repository: https://github.com/ConnectedRoboticsLab and YouTube channel: https://youtu.be/Fz_1iOYe104.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04425v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zexin Deng (University of Warwick, UK), Zhenhui Yuan (University of Warwick, UK), Longhao Zou (Pengcheng Laboratory, China)</dc:creator>
    </item>
    <item>
      <title>On-Demand Multimedia Delivery in 6G: An Optimal-Cost Steiner Tree Approach</title>
      <link>https://arxiv.org/abs/2507.04589</link>
      <description>arXiv:2507.04589v1 Announce Type: new 
Abstract: The exponential growth of multimedia data traffic in 6G networks poses unprecedented challenges for immersive communication, where ultra-high-definition, multi-quality streaming must be delivered on demand while minimizing network operational costs. Traditional routing approaches, such as shortest-path algorithms, fail to optimize flow multiplexing across multiple destinations, while conventional Steiner tree methods cannot accommodate heterogeneous quality-of-service (QoS) requirements-a critical need for 6G's personalized services. In this paper, we address a fundamental but unsolved challenge: the minimum flow problem (MFP) with multi-destination, heterogeneous outflow demands, which is pivotal for efficient multimedia distribution such as adaptive-resolution video streaming. To overcome the limitations of existing methods, we propose a two-stage dynamic programming-enhanced On-demand Steiner Tree (OST) algorithm, the first approach that jointly optimizes flow aggregation and QoS-aware path selection for arbitrary outflow requirements. We rigorously prove the optimality of OST using mathematical induction, demonstrating that it guarantees the minimum-cost multicast flow under differentiated service constraints. Extensive experiments in 6G-like multimedia transmission scenarios show that OST reduces total network flow by over 10% compared to state-of-the-art methods while ensuring on-demand QoS fulfillment. The complete code is available at https://github.com/UNIC-Lab/OST.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04589v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zien Wang, Xiucheng Wang, Nan Cheng, Wenchao Xu, Wei Quan, Ruijin Sun, Conghao Zhou</dc:creator>
    </item>
    <item>
      <title>Low-Latency Software Polar Encoders and Decoders for Short Blocklengths</title>
      <link>https://arxiv.org/abs/2507.04734</link>
      <description>arXiv:2507.04734v1 Announce Type: new 
Abstract: This paper presents our low-latency Polar code encoders and decoders developed for the 2025 International Symposium on Topics in Coding (ISTC 2025) contest, which challenges participants to implement the fastest possible channel code encoders and decoders in terms of average and maximum latency on a CPU target. Our solution is based on Polar codes with an Adaptive Successive Cancellation List (ASCL) decoder. We introduce a novel ASCL unrolled decoder generator. We conduct an extensive exploration of the design space, including code construction, CRC selection, and list size, to identify optimal trade-offs between signal-to-noise ratio and decoding time across various operating points. The considered operating points are frame error rates of 10^{-3} and 10^{-5}, information bit lengths of 64, 128, 256, and 512, and code rates of 1/4, 1/2, and 4/5. We also propose an optimized bit-packed encoder. All implementations of the encoders and decoders, along with the code construction and the unrolled decoders generator, are released as open source in the AFF3CT toolbox.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04734v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>International Symposium on Topics in Coding (ISTC), Aug 2025, Los Angeles, United States</arxiv:journal_reference>
      <dc:creator>Mathieu Leonardon (IMT Atlantique - MEE, Lab\_STICC\_BRAIn), Mohammed El Houcine Ayoubi (IMT Atlantique), Adrien Cassagne (ALSOC), Romain Tajan (Bordeaux INP, UB), Camille Leroux (Bordeaux INP, UB)</dc:creator>
    </item>
    <item>
      <title>User Association in the Presence of Jamming in Wireless Networks Using the Whittle Index</title>
      <link>https://arxiv.org/abs/2507.04968</link>
      <description>arXiv:2507.04968v1 Announce Type: new 
Abstract: In wireless networks, algorithms for user association, i.e., the task of choosing the base station (BS) that every arriving user should join, significantly impact the network performance. A wireless network with multiple BSs, operating on non-overlapping channels, is considered. The channels of the BSs are susceptible to jamming by attackers. During every time slot, a user arrives with a certain probability. There exists a holding cost in each slot for every user associated with a BS. The goal here is to design a user association scheme, which assigns a BS to each user upon arrival with the objective of minimizing the long-run total average holding cost borne within the network. This objective results in low average delays attained by the users. This association problem is an instance of restless multi-armed bandit problems, and is known to be hard to solve. By making use of the framework presented by Whittle, the hard per-stage constraint that every arriving user must connect to exactly one BS in a time slot is relaxed to a long-term time-averaged constraint. Subsequently, we employ the Lagrangian multiplier strategy to reformulate the problem into an unconstrained form and decompose it into separate Markov Decision Processes at the BSs. Further, the problem is proven to be Whittle indexable and a method for calculating the Whittle indices corresponding to different BSs is presented. We design a user association policy under which, upon arrival of a user in a time slot, it is assigned to the BS having the least Whittle index in that slot. Through extensive simulations, we show that our proposed association policy based on the Whittle index outperforms various user association policies proposed in previous work in terms of different metrics such as average cost, average delay, and Jain's fairness index.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04968v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pramod N Chine, Suven Jagtiani, Mandar R Nalavade, Gaurav S Kasbekar</dc:creator>
    </item>
    <item>
      <title>Benchmarking Vector, Graph and Hybrid Retrieval Augmented Generation (RAG) Pipelines for Open Radio Access Networks (ORAN)</title>
      <link>https://arxiv.org/abs/2507.03608</link>
      <description>arXiv:2507.03608v1 Announce Type: cross 
Abstract: Generative AI (GenAI) is expected to play a pivotal role in enabling autonomous optimization in future wireless networks. Within the ORAN architecture, Large Language Models (LLMs) can be specialized to generate xApps and rApps by leveraging specifications and API definitions from the RAN Intelligent Controller (RIC) platform. However, fine-tuning base LLMs for telecom-specific tasks remains expensive and resource-intensive. Retrieval-Augmented Generation (RAG) offers a practical alternative through in-context learning, enabling domain adaptation without full retraining. While traditional RAG systems rely on vector-based retrieval, emerging variants such as GraphRAG and Hybrid GraphRAG incorporate knowledge graphs or dual retrieval strategies to support multi-hop reasoning and improve factual grounding. Despite their promise, these methods lack systematic, metric-driven evaluations, particularly in high-stakes domains such as ORAN. In this study, we conduct a comparative evaluation of Vector RAG, GraphRAG, and Hybrid GraphRAG using ORAN specifications. We assess performance across varying question complexities using established generation metrics: faithfulness, answer relevance, context relevance, and factual correctness. Results show that both GraphRAG and Hybrid GraphRAG outperform traditional RAG. Hybrid GraphRAG improves factual correctness by 8%, while GraphRAG improves context relevance by 7%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03608v1</guid>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarat Ahmad, Zeinab Nezami, Maryam Hafeez, Syed Ali Raza Zaidi</dc:creator>
    </item>
    <item>
      <title>MOD-X: A Modular Open Decentralized eXchange Framework proposal for Heterogeneous Interoperable Artificial Agents</title>
      <link>https://arxiv.org/abs/2507.04376</link>
      <description>arXiv:2507.04376v1 Announce Type: cross 
Abstract: As Artificial Intelligence systems evolve from monolithic models to ecosystems of specialized agents, the need for standardized communication protocols becomes increasingly critical. This paper introduces MOD-X (Modular Open Decentralized eXchange), a novel architectural framework proposal for agent interoperability that addresses key limitations of existing protocols. Unlike current approaches, MOD-X proposes a layered architecture with a Universal Message Bus, thorough state management, translation capabilities, and blockchain-based security mechanisms. We present MOD-X's architecture, compare it with existing protocols, and demonstrate its application through a worked example how it enables integration between heterogeneous specialist agents (agents with different architectures, vendors, capabilities, and knowledge representations--including rule-based systems, neural networks, symbolic reasoning engines, and legacy software with agent wrappers). MOD-X's key innovations include a publish-subscribe communication model, semantic capability discovery, and dynamic workflow orchestration--providing a framework that bridges theoretical formalism with practical implementation. This architecture addresses the growing need for truly decentralized, interoperable agent ecosystems that can scale effectively without the need for central coordination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04376v1</guid>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georgios Ioannides, Christos Constantinou, Vinija Jain, Aman Chadha, Aaron Elkins</dc:creator>
    </item>
    <item>
      <title>Multimodal LLM Integrated Semantic Communications for 6G Immersive Experiences</title>
      <link>https://arxiv.org/abs/2507.04621</link>
      <description>arXiv:2507.04621v1 Announce Type: cross 
Abstract: 6G networks promise revolutionary immersive communication experiences including augmented reality (AR), virtual reality (VR), and holographic communications. These applications demand high-dimensional multimodal data transmission and intelligent data processing in real-time, which is extremely challenging over resource-limited wireless communication systems. Moreover, a joint understanding of the environment, context, and user intent is essential to deliver task-relevant content effectively. This article presents a novel multimodal large language model (MLLM) integrated semantic communications framework, termed MLLM-SC, which fully leverages reasoning and generative capabilities of pre-trained foundation models for context-aware and task-oriented wireless communication. The MLLM-SC framework adopts a device-edge collaborative architecture. At the edge, MLLM-empowered semantic guidance module analyzes multimodal inputs, user intents, and channel conditions to generate importance-aware attention maps prioritizing semantically critical information. An importance-aware semantic encoder and a resource-adaptive semantic decoder are jointly designed and optimized, which can utilize the semantic guidance for adaptive bandwidth allocation and high-quality content reconstruction or generation. Extensive case studies on visual question answering for AR/VR applications and diffusion-driven image generation validate the effectiveness of MLLM-SC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04621v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yusong Zhang, Yuxuan Sun, Lei Guo, Wei Chen, Bo Ai, Deniz Gunduz</dc:creator>
    </item>
    <item>
      <title>Large Language Models for Network Intrusion Detection Systems: Foundations, Implementations, and Future Directions</title>
      <link>https://arxiv.org/abs/2507.04752</link>
      <description>arXiv:2507.04752v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have revolutionized various fields with their exceptional capabilities in understanding, processing, and generating human-like text. This paper investigates the potential of LLMs in advancing Network Intrusion Detection Systems (NIDS), analyzing current challenges, methodologies, and future opportunities. It begins by establishing a foundational understanding of NIDS and LLMs, exploring the enabling technologies that bridge the gap between intelligent and cognitive systems in AI-driven NIDS. While Intelligent NIDS leverage machine learning and deep learning to detect threats based on learned patterns, they often lack contextual awareness and explainability. In contrast, Cognitive NIDS integrate LLMs to process both structured and unstructured security data, enabling deeper contextual reasoning, explainable decision-making, and automated response for intrusion behaviors. Practical implementations are then detailed, highlighting LLMs as processors, detectors, and explainers within a comprehensive AI-driven NIDS pipeline. Furthermore, the concept of an LLM-centered Controller is proposed, emphasizing its potential to coordinate intrusion detection workflows, optimizing tool collaboration and system performance. Finally, this paper identifies critical challenges and opportunities, aiming to foster innovation in developing reliable, adaptive, and explainable NIDS. By presenting the transformative potential of LLMs, this paper seeks to inspire advancement in next-generation network security systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04752v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuo Yang, Xinran Zheng, Xinchen Zhang, Jinfeng Xu, Jinze Li, Donglin Xie, Weicai Long, Edith C. H. Ngai</dc:creator>
    </item>
    <item>
      <title>Age-Aware CSI Acquisition of a Finite-State Markovian Channel</title>
      <link>https://arxiv.org/abs/2507.05042</link>
      <description>arXiv:2507.05042v1 Announce Type: cross 
Abstract: The Age of Information (AoI) has emerged as a critical metric for quantifying information freshness; however, its interplay with channel estimation in partially observable wireless systems remains underexplored. This work considers a transmitter-receiver pair communicating over an unreliable channel with time-varying reliability levels. The transmitter observes the instantaneous link reliability through a channel state information acquisition procedure, during which the data transmission is interrupted. This leads to a fundamental trade-off between utilizing limited network resources for either data transmission or channel state information acquisition to combat the channel aging effect. Assuming the wireless channel is modeled as a finite-state Markovian channel, we formulate an optimization problem as a partially observable Markov decision process (POMDP), obtain the optimal policy through the relative value iteration algorithm, and demonstrate the efficiency of our solution through simulations. To the best of our knowledge, this is the first work to aim for an optimal scheduling policy for data transmissions while considering the effect of channel state information aging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05042v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Onur Ayan, Jiping Luo, Xueli An, Nikolaos Pappas</dc:creator>
    </item>
    <item>
      <title>On the Optimization and Stability of Sectorized Wireless Networks</title>
      <link>https://arxiv.org/abs/2308.10970</link>
      <description>arXiv:2308.10970v2 Announce Type: replace 
Abstract: Future wireless networks need to support the increasing demands for high data rates and improved coverage. One promising solution is sectorization, where an infrastructure node is equipped with multiple sectors employing directional communication. Although the concept of sectorization is not new, it is critical to fully understand the potential of sectorized networks, such as the rate gain achieved when multiple sectors can be simultaneously activated. In this paper, we focus on sectorized wireless networks, where sectorized infrastructure nodes with beam-steering capabilities form a multi-hop mesh network. We present a sectorized node model and characterize the capacity region of these sectorized networks. We define the flow extension ratio and the corresponding sectorization gain, which quantitatively measure the performance gain introduced by node sectorization as a function of the network flow. Our objective is to find the sectorization of each node that achieves the maximum flow extension ratio, and thus the sectorization gain. Towards this goal, we formulate the corresponding optimization problem and develop an efficient distributed algorithm that obtains the node sectorization under a given network flow with an approximation ratio of 2/3. Additionally, we emphasize the class of Even Homogeneous Sectorizations, which simultaneously enhances the efficiency of dynamic routing schemes with unknown arrival rates and increases network capacity. We further propose that if sectorization can be adapted dynamically over time, either a backpressure-driven or maximum weighted b-matching-based routing approach can be employed, thereby expanding the achievable capacity region while preserving stability under unknown traffic conditions. Through extensive simulations, we evaluate the sectorization gain and the performance of the proposed algorithms in various network scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.10970v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Panagiotis Promponas, Tingjun Chen, Leandros Tassiulas</dc:creator>
    </item>
    <item>
      <title>A Taxonomy and Comparative Analysis of IPv4 Identifier Selection Correctness, Security, and Performance</title>
      <link>https://arxiv.org/abs/2406.06483</link>
      <description>arXiv:2406.06483v3 Announce Type: replace 
Abstract: The battle for a more secure Internet is waged on many fronts, including the most basic of networking protocols. Our focus is the IPv4 Identifier (IPID), an IPv4 header field as old as the Internet with an equally long history as an exploited side channel for scanning network properties, inferring off-path connections, and poisoning DNS caches. This article taxonomizes the 25-year history of IPID-based exploits and the corresponding changes to IPID selection methods. By mathematically analyzing these methods' correctness and security and empirically evaluating their performance, we reveal recommendations for best practice as well as shortcomings of current operating system implementations, emphasizing the value of systematic evaluations in network security.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06483v3</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joshua J. Daymude, Antonio M. Espinoza, Sean Bergen, Benjamin Mixon-Baca, Jeffrey Knockel, Jedidiah R. Crandall</dc:creator>
    </item>
    <item>
      <title>Learning-based Power Control for Secure Covert Semantic Communication</title>
      <link>https://arxiv.org/abs/2407.07475</link>
      <description>arXiv:2407.07475v2 Announce Type: replace 
Abstract: Despite progress in semantic communication (SemCom), research on SemCom security is still in its infancy. To bridge this gap, we propose a general covert SemCom framework for wireless networks, reducing eavesdropping risk. Our approach transmits semantic information covertly, making it difficult for wardens to detect. Given the aim of maximizing covert SemCom performance, we formulate a power control problem in covert SemCom under energy constraints. Furthermore, we propose a learning-based approach based on the soft actor-critic algorithm, optimizing the power of the transmitter and friendly jammer. Numerical results demonstrate that our approach effectively enhances the performance of covert SemCom.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07475v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yansheng Liu, Jinbo Wen, Zongyao Zhang, Kun Zhu, Yang Zhang, Jiangtian Nie, Jiawen Kang</dc:creator>
    </item>
    <item>
      <title>Data Matters: The Case of Predicting Mobile Cellular Traffic</title>
      <link>https://arxiv.org/abs/2411.02418</link>
      <description>arXiv:2411.02418v2 Announce Type: replace 
Abstract: Accurate predictions of base stations' traffic load are essential to mobile cellular operators and their users as they support the efficient use of network resources and allow delivery of services that sustain smart cities and roads. Traditionally, cellular network time-series have been considered for this prediction task. More recently, exogenous factors such as points of interest and other environmental knowledge have been explored too. In contrast to incorporating external factors, we propose to learn the processes underlying cellular load generation by employing population dynamics data. In this study, we focus on smart roads and use road traffic measures to improve prediction accuracy. Comprehensive experiments demonstrate that by employing road flow and speed, in addition to cellular network metrics, base station load prediction errors can be substantially reduced, by as much as $56.5\%.$ The code, visualizations and extensive results are available on https://github.com/nvassileva/DataMatters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02418v2</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/VNC64509.2025.11054248</arxiv:DOI>
      <dc:creator>Natalia Vesselinova, Matti Harjula, Pauliina Ilmonen</dc:creator>
    </item>
    <item>
      <title>RF-3DGS: Wireless Channel Modeling with Radio Radiance Field and 3D Gaussian Splatting</title>
      <link>https://arxiv.org/abs/2411.19420</link>
      <description>arXiv:2411.19420v3 Announce Type: replace 
Abstract: Precisely modeling radio propagation in complex environments has been a significant challenge, especially with the advent of 5G and beyond networks, where managing massive antenna arrays demands more detailed information. Traditional methods, such as empirical models and ray tracing, often fall short, either due to insufficient details or because of challenges for real-time applications. Inspired by the newly proposed 3D Gaussian Splatting method in the computer vision domain, which outperforms other methods in reconstructing optical radiance fields, we propose RF-3DGS, a novel approach that enables precise site-specific reconstruction of radio radiance fields from sparse samples. RF-3DGS can render radio spatial spectra at arbitrary positions within 2 ms following a brief 3-minute training period, effectively identifying dominant propagation paths. Furthermore, RF-3DGS can provide fine-grained Spatial Channel State Information (Spatial-CSI) of these paths, including the channel gain, the delay, the angle of arrival (AoA), and the angle of departure (AoD). Our experiments, calibrated through real-world measurements, demonstrate that RF-3DGS not only significantly improves reconstruction quality, training efficiency, and rendering speed compared to state-of-the-art methods, but also holds great potential for supporting wireless communication and advanced applications such as Integrated Sensing and Communication (ISAC). Code and dataset will be available at https://github.com/SunLab-UGA/RF-3DGS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19420v3</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lihao Zhang, Haijian Sun, Samuel Berweger, Camillo Gentile, Rose Qingyang Hu</dc:creator>
    </item>
    <item>
      <title>BECS: A Privacy-Preserving Computing Sharing Mechanism in 6G Computing Power Network</title>
      <link>https://arxiv.org/abs/2412.06196</link>
      <description>arXiv:2412.06196v2 Announce Type: replace 
Abstract: 5G networks provide secure and reliable information transmission services for the Internet of Everything, thus paving the way for 6G networks, which is anticipated to be an AI-based network, supporting unprecedented intelligence across applications. Abundant computing resources will establish the 6G Computing Power Network (CPN) to facilitate ubiquitous intelligent services. In this article, we propose BECS, a computing sharing mechanism based on evolutionary algorithm and blockchain, designed to balance task offloading among user devices, edge devices, and cloud resources within 6G CPN, thereby enhancing the computing resource utilization. We model computing sharing as a multi-objective optimization problem, aiming to improve resource utilization while balancing other issues. To tackle this NP-hard problem, we devise a kernel distance-based dominance relation and incorporated it into the Non-dominated Sorting Genetic Algorithm III, significantly enhancing the diversity of the evolutionary population. In addition, we propose a pseudonym scheme based on zero-knowledge proof to protect the privacy of users participating in computing sharing. Finally, the security analysis and simulation results demonstrate that BECS can fully and effectively utilize all computing resources in 6G CPN, significantly improving the computing resource utilization while protecting user privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06196v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kun Yan, Wenping Ma, Shaohui Sun</dc:creator>
    </item>
    <item>
      <title>Consumer-Oriented Computing: A Path to Community Data Centers</title>
      <link>https://arxiv.org/abs/2501.16752</link>
      <description>arXiv:2501.16752v2 Announce Type: replace 
Abstract: Modern large-scale data centers are known for their engineering complexity, cooling, and oversubscription challenges. To mitigate these issues, this article proposes the implementation of community data centers that are closer to consumers as part of the data center ecosystem. Having a community data center can reduce latency, minimize network burden on Internet Service Providers (ISPs), utilize full computing capability, available during disaster events, and simplify the engineering complexity associated with traditional data centers. In addition to that, this article explores one technical design for such a community data center and the business strategy for operating community data centers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16752v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianhao Zhang</dc:creator>
    </item>
    <item>
      <title>The Forest Behind the Tree: Revealing Hidden Smart Home Communication Patterns</title>
      <link>https://arxiv.org/abs/2502.08535</link>
      <description>arXiv:2502.08535v3 Announce Type: replace 
Abstract: The widespread use of Smart Home devices has attracted significant research interest in understanding their behavior within home networks. Unlike general-purpose computers, these devices exhibit relatively simple and predictable network activity patterns. However, previous studies have primarily focused on normal network conditions, overlooking potential hidden patterns that emerge under challenging conditions. Discovering these hidden flows is crucial for assessing device robustness. This paper addresses this gap by presenting a framework that systematically and automatically reveals these hidden communication patterns. By actively disturbing communication and blocking observed traffic, the framework generates comprehensive profiles structured as behavior trees, uncovering flows that are missed by more shallow methods. This approach was applied to ten real-world devices, identifying 254 unique flows, with over 27% only discovered through this new method. These insights enhance our understanding of device robustness and can be leveraged to improve the accuracy of network security measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08535v3</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois De Keersmaeker, R\'emi Van Boxem, Cristel Pelsser, Ramin Sadre</dc:creator>
    </item>
    <item>
      <title>Satellite-Assisted Low-Altitude Economy Networking: Concepts, Applications, and Opportunities</title>
      <link>https://arxiv.org/abs/2505.04098</link>
      <description>arXiv:2505.04098v2 Announce Type: replace 
Abstract: The low-altitude economy (LAE) is a new economic paradigm that leverages low-altitude vehicles (LAVs) to perform diverse missions across diverse areas. To support the operations of LAE, it is essential to establish LAE networks that enable LAV management and communications.Existing studies mainly reuse terrestrial networks to construct LAE networks. However, the limited coverage of terrestrial networks poses challenges for serving LAVs in remote areas. Besides, efficient LAV operations also require support such as localization and navigation, which terrestrial networks designed for communications cannot fully provide. Due to ubiquitous coverage and diverse functions, satellites are a promising technology to support LAVs. Therefore, this article investigates satellite-assisted LAE networking. First, we introduce an overview of LAE and satellites, discussing their features, applications, and architectures. Next, we investigate opportunities for satellites to assist LAE from aspects of communication, control, and computation. As all assistance depends on reliable satellite-LAV communications, we propose a satellite-assisted LAE framework to tackle issues caused by the severe path loss and high dynamics in satellite-assisted LAE networks.The case study demonstrates that the distributed MIMO architecture efficiently reduces the required transmission power and extends service duration, while the two-timescale optimization scheme balances the performance and control signaling overheads. Specifically, the proposed framework comprises distributed satellite MIMO, distributed LAV MIMO, and a two-timescale optimization scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04098v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shizhao He, Jiacheng Wang, Ying-Chang Liang, Geng Sun, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>Coordinated Spatial Reuse Scheduling With Machine Learning in IEEE 802.11 MAPC Networks</title>
      <link>https://arxiv.org/abs/2505.07278</link>
      <description>arXiv:2505.07278v3 Announce Type: replace 
Abstract: The densification of Wi-Fi deployments means that fully distributed random channel access is no longer sufficient for high and predictable performance. Therefore, the upcoming IEEE 802.11bn amendment introduces multi-access point coordination (MAPC) methods. This paper addresses a variant of MAPC called coordinated spatial reuse (C-SR), where devices transmit simultaneously on the same channel, with the power adjusted to minimize interference. The C-SR scheduling problem is selecting which devices transmit concurrently and with what settings. We provide a theoretical upper bound model, optimized for either throughput or fairness, which finds the best possible transmission schedule using mixed-integer linear programming. Then, a practical, probing-based approach is proposed which uses multi-armed bandits (MABs), a type of reinforcement learning, to solve the C-SR scheduling problem. We validate both classical (flat) MAB and hierarchical MAB (H-MAB) schemes with simulations and in a testbed. Using H-MABs for C-SR improves aggregate throughput over legacy IEEE 802.11 (on average by 80% in random scenarios), without reducing the number of transmission opportunities per station. Finally, our framework is lightweight and ready for implementation in Wi-Fi devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07278v3</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/JSAC.2025.3584555</arxiv:DOI>
      <dc:creator>Maksymilian Wojnar, Wojciech Ci\k{e}\.zobka, Artur Tomaszewski, Piotr Cho{\l}da, Krzysztof Rusek, Katarzyna Kosek-Szott, Jetmir Haxhibeqiri, Jeroen Hoebeke, Boris Bellalta, Anatolij Zubow, Falko Dressler, Szymon Szott</dc:creator>
    </item>
    <item>
      <title>DRST: a Non-Intrusive Framework for Performance Analysis in Softwarized Networks</title>
      <link>https://arxiv.org/abs/2506.17658</link>
      <description>arXiv:2506.17658v3 Announce Type: replace 
Abstract: The last decade has witnessed the proliferation of network function virtualization (NFV) in the telco industry, thanks to its unparalleled flexibility, scalability, and cost-effectiveness. However, as the NFV infrastructure is shared by virtual network functions (VNFs), sporadic resource contentions are inevitable. Such contention makes it extremely challenging to guarantee the performance of the provisioned network services, especially in high-speed regimes (e.g., Gigabit Ethernet). Existing solutions typically rely on direct traffic analysis (e.g., packet- or flow-level measurements) to detect performance degradation and identify bottlenecks, which is not always applicable due to significant integration overhead and system-level constraints. This paper complements existing solutions with a lightweight, non-intrusive framework for online performance inference that easily adapts to drift (i.e., a change over time of the actual state of our system). Instead of direct data-plane collection, we reuse hardware features in the underlying NFV infrastructure, introducing negligible interference in the data-plane. Our Drift-Resilient and Self-Tuning (DRST) framework can be integrated into existing NFV systems with minimal engineering effort and operate without the need for predefined traffic models or VNF-specific customization. DRST is deployed via a lightweight MLOps pipeline that automates the adaptation under runtime drift. We show how DRST can deliver accurate performance inference or diagnose run-time bottlenecks, as demonstrated through a comprehensive evaluation across diverse NFV scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17658v3</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiong Liu, Jianke Lin, Tianzhu Zhang, Leonardo Linguaglossa</dc:creator>
    </item>
    <item>
      <title>Towards a Playground to Democratize Experimentation and Benchmarking of AI Agents for Network Troubleshooting</title>
      <link>https://arxiv.org/abs/2507.01997</link>
      <description>arXiv:2507.01997v2 Announce Type: replace 
Abstract: Recent research has demonstrated the effectiveness of Artificial Intelligence (AI), and more specifically, Large Language Models (LLMs), in supporting network configuration synthesis and automating network diagnosis tasks, among others. In this preliminary work, we restrict our focus to the application of AI agents to network troubleshooting and elaborate on the need for a standardized, reproducible, and open benchmarking platform, where to build and evaluate AI agents with low operational effort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01997v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhihao Wang, Alessandro Cornacchia, Franco Galante, Carlo Centofanti, Alessio Sacco, Dingde Jiang</dc:creator>
    </item>
    <item>
      <title>Smart Grid: Cyber Attacks, Critical Defense Approaches, and Digital Twin</title>
      <link>https://arxiv.org/abs/2205.11783</link>
      <description>arXiv:2205.11783v2 Announce Type: replace-cross 
Abstract: As a national critical infrastructure, the smart grid has attracted widespread attention for its cybersecurity issues. The development towards an intelligent, digital, and Internet-connected smart grid has attracted external adversaries for malicious activities. It is necessary to enhance its cybersecurity by both improving the existing defense approaches and introducing novel developed technologies to the smart grid context. As an emerging technology, digital twin (DT) is considered as an enabler for enhanced security. However, the practical implementation is quite challenging. This is due to the knowledge barriers among smart grid designers, security experts, and DT developers. Each single domain is a complicated system covering various components and technologies. As a result, works are needed to sort out relevant contents so that DT can be better embedded in the security architecture design of smart grid.
  In order to meet this demand, our paper covers the above three domains, i.e., smart grid, cybersecurity, and DT. Specifically, the paper i) introduces the background of the smart grid; ii) reviews external cyber attacks from attack incidents and attack methods; iii) introduces critical defense approaches in industrial cyber systems, which include device identification, vulnerability discovery, intrusion detection systems (IDSs), honeypots, attribution, and threat intelligence (TI); iv) reviews the relevant content of DT, including its basic concepts, applications in the smart grid, and how DT enhances the security. In the end, the paper puts forward our security considerations on the future development of DT-based smart grid. The survey is expected to help developers break knowledge barriers among smart grid, cybersecurity, and DT, and provide guidelines for future security design of DT-based smart grid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.11783v2</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianming Zheng, Ping Yi, Yue Wu</dc:creator>
    </item>
    <item>
      <title>Comparing One- and Two-way Quantum Repeater Architectures</title>
      <link>https://arxiv.org/abs/2409.06152</link>
      <description>arXiv:2409.06152v2 Announce Type: replace-cross 
Abstract: Quantum repeaters are an essential building block for realizing long-distance quantum communications. However, due to the fragile nature of quantum information, these repeaters suffer from loss and operational errors. Prior works have classified repeaters into three broad categories based on their use of probabilistic or near-deterministic methods to mitigate these errors. Besides differences in classical communication times, these approaches also vary in technological complexity, with near-deterministic methods requiring more advanced technology. Recent increases in the number of available memories, and introduction of entanglement generation through multiplexing motivate a re-comparison of one-way and two-way repeater architectures. In this work, we propose a novel protocol that optimizes multiplexed elementary link generation and distillation in memory-unconstrained 'connection-oriented' two-way repeaters to boost the entanglement generation rates. We introduce a recursive formulation to derive the probability distribution of the number of Bell pairs in multiplexed two-way repeater architectures, compatible with probabilistic $n$-to-$k$ distillation protocols. We then compare the performance of this new protocol with one-way schemes in the parameter regime where one-way schemes have previously been shown to be advantageous, and find that the multiplexed two-way protocol provides better performance with lower resource and technology requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06152v2</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prateek Mantri, Kenneth Goodenough, Don Towsley</dc:creator>
    </item>
    <item>
      <title>Incremental Firmware Update Over-the-Air for Low-Power IoT Devices over LoRaWAN</title>
      <link>https://arxiv.org/abs/2505.13764</link>
      <description>arXiv:2505.13764v2 Announce Type: replace-cross 
Abstract: Efficiently supporting remote firmware updates in Internet of Things (IoT) devices remains a significant challenge due to the limitations of many IoT communication protocols, which often make it impractical to transmit full firmware images. Techniques such as firmware partitioning have been introduced to mitigate this issue, but they frequently fall short, especially in battery-powered systems where time and energy constraints are critical. As a result, physical maintenance interventions are still commonly required, which is costly and inconvenient in large-scale deployments. In this work, we present a lightweight and innovative method that addresses this challenge by generating highly compact delta patches, enabling firmware reconstruction directly on the device. Our algorithm is specifically optimized for low-power devices, minimizing both memory usage and computational overhead. Compared to existing solutions, our approach significantly reduces the data volume needed for updates while maintaining performance comparable to more complex alternatives. Experimental evaluations confirm that our method yields substantial time and energy savings, making it particularly well-suited for battery-powered IoT nodes. Although our implementation targets the LoRaWAN protocol, the approach is flexible and can be adapted to other IoT communication technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13764v2</guid>
      <category>eess.SY</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andrea De Simone, Giovanna Turvani, Fabrizio Riente</dc:creator>
    </item>
    <item>
      <title>Crowdsourcing Ubiquitous Indoor Localization with Non-Cooperative Wi-Fi Ranging</title>
      <link>https://arxiv.org/abs/2506.18317</link>
      <description>arXiv:2506.18317v2 Announce Type: replace-cross 
Abstract: Indoor localization opens the path to potentially transformative applications. Although many indoor localization methods have been proposed over the years, they remain too impractical for widespread deployment in the real world. In this paper, we introduce PeepLoc, a deployable and scalable Wi-Fi-based solution for indoor localization that relies only on pre-existing devices and infrastructure. Specifically, PeepLoc works on any mobile device with an unmodified Wi-Fi transceiver and in any indoor environment with a sufficient number of Wi-Fi access points (APs) and pedestrian traffic. At the core of PeepLoc is (a) a mechanism which allows any Wi-Fi device to obtain non-cooperative time-of-flight (ToF) to any Wi-Fi AP and (b) a novel bootstrapping mechanism that relies on pedestrian dead reckoning (PDR) and crowdsourcing to opportunistically initialize pre-existing APs as anchor points within an environment. We implement PeepLoc using commodity hardware and evaluate it extensively across 4 campus buildings. We show PeepLoc leads to a mean and median positional error of 3.41 m and 3.06 m respectively, which is superior to existing deployed indoor localization systems and is competitive with commodity GPS in outdoor environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18317v2</guid>
      <category>cs.HC</category>
      <category>cs.NI</category>
      <category>cs.RO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emerson Sie, Enguang Fan, Federico Cifuentes-Urtubey, Deepak Vasisht</dc:creator>
    </item>
  </channel>
</rss>
