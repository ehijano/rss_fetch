<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Aug 2024 04:00:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Controlling Dataflows with a Bolt-on Data Escrow</title>
      <link>https://arxiv.org/abs/2408.01580</link>
      <description>arXiv:2408.01580v1 Announce Type: new 
Abstract: The data-driven economy has created tremendous value in our society. Individuals share their data with platforms in exchange for services such as search, social networks, and health recommendations. Platforms use the data to provide those services and create other revenue-generating opportunities, e.g., selling the data to data brokers. With the ever-expanding data economy comes the growing concern about potential data misuse. While most platforms give individuals certain control over their data (i.e., what data is being shared), individuals do not know how the data will be used once shared; they cannot control the purpose.
  In this paper, we introduce a data escrow design that permits individuals to observe all dataflows - not just what is shared but for what purpose. Rather than data flowing to the platform, the platform delegates their computation to the escrow, where individuals can observe and manage their data. To make the data escrow practical, we design and implement a prototype that works alongside the Apple ecosystem; specifically, we retrofit the Apple SDKs with a programming interface to enable delegated computation. Our solution does not depend on Apple's software and can be applied to other platforms, but building for Apple lets us study the main hypothesis of our work: whether such a data escrow solution is a feasible alternative to today's data governance. We show that our escrow prototype implementation is efficient, and we analyze the dataflows in real-world apps and show that the escrow's programming interface supports implementing a wide range of dataflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01580v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiru Zhu, Raul Castro Fernandez</dc:creator>
    </item>
    <item>
      <title>Complex event recognition meets hierarchical conjunctive queries</title>
      <link>https://arxiv.org/abs/2408.01652</link>
      <description>arXiv:2408.01652v1 Announce Type: new 
Abstract: Hierarchical conjunctive queries (HCQ) are a subclass of conjunctive queries (CQ) with robust algorithmic properties. Among others, Berkholz, Keppeler, and Schweikardt have shown that HCQ is the subclass of CQ (without projection) that admits dynamic query evaluation with constant update time and constant delay enumeration. On a different but related setting stands Complex Event Recognition (CER), a prominent technology for evaluating sequence patterns over streams. Since one can interpret a data stream as an unbounded sequence of inserts in dynamic query evaluation, it is natural to ask to which extent CER can take advantage of HCQ to find a robust class of queries that can be evaluated efficiently.
  In this paper, we search to combine HCQ with sequence patterns to find a class of CER queries that can get the best of both worlds. To reach this goal, we propose a class of complex event automata model called Parallelized Complex Event Automata (PCEA) for evaluating CER queries with correlation (i.e., joins) over streams. This model allows us to express sequence patterns and compare values among tuples, but it also allows us to express conjunctions by incorporating a novel form of non-determinism that we call parallelization. We show that for every HCQ (under bag semantics), we can construct an equivalent PCEA. Further, we show that HCQ is the biggest class of acyclic CQ that this automata model can define. Then, PCEA stands as a sweet spot that precisely expresses HCQ (i.e., among acyclic CQ) and extends them with sequence patterns. Finally, we show that PCEA also inherits the good algorithmic properties of HCQ by presenting a streaming evaluation algorithm under sliding windows with logarithmic update time and output-linear delay for the class of PCEA with equality predicates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01652v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dante Pinto, Cristian Riveros</dc:creator>
    </item>
    <item>
      <title>Towards Tractability of the Diversity of Query Answers: Ultrametrics to the Rescue</title>
      <link>https://arxiv.org/abs/2408.01657</link>
      <description>arXiv:2408.01657v1 Announce Type: new 
Abstract: The set of answers to a query may be very large, potentially overwhelming users when presented with the entire set. In such cases, presenting only a small subset of the answers to the user may be preferable. A natural requirement for this subset is that it should be as diverse as possible to reflect the variety of the entire population. To achieve this, the diversity of a subset is measured using a metric that determines how different two solutions are and a diversity function that extends this metric from pairs to sets. In the past, several studies have shown that finding a diverse subset from an explicitly given set is intractable even for simple metrics (like Hamming distance) and simple diversity functions (like summing all pairwise distances). This complexity barrier becomes even more challenging when trying to output a diverse subset from a set that is only implicitly given such as the query answers of a query and a database. Until now, tractable cases have been found only for restricted problems and particular diversity functions.
  To overcome these limitations, we focus on the notion of ultrametrics, which have been widely studied and used in many applications. Starting from any ultrametric $d$ and a diversity function $\delta$ extending $d$, we provide sufficient conditions over $\delta$ for having polynomial-time algorithms to construct diverse answers. To the best of our knowledge, these conditions are satisfied by all diversity functions considered in the literature. Moreover, we complement these results with lower bounds that show specific cases when these conditions are not satisfied and finding diverse subsets becomes intractable. We conclude by applying these results to the evaluation of conjunctive queries, demonstrating efficient algorithms for finding a diverse subset of solutions for acyclic conjunctive queries when the attribute order is used to measure diversity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01657v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcelo Arenas, Timo Camillo Merkl, Reinhard Pichler, Cristian Riveros</dc:creator>
    </item>
    <item>
      <title>Mining Path Association Rules in Large Property Graphs (with Appendix)</title>
      <link>https://arxiv.org/abs/2408.02029</link>
      <description>arXiv:2408.02029v1 Announce Type: new 
Abstract: How can we mine frequent path regularities from a graph with edge labels and vertex attributes? The task of association rule mining successfully discovers regular patterns in item sets and substructures. Still, to our best knowledge, this concept has not yet been extended to path patterns in large property graphs. In this paper, we introduce the problem of path association rule mining (PARM). Applied to any \emph{reachability path} between two vertices within a large graph, PARM discovers regular ways in which path patterns, identified by vertex attributes and edge labels, co-occur with each other. We develop an efficient and scalable algorithm PIONEER that exploits an anti-monotonicity property to effectively prune the search space. Further, we devise approximation techniques and employ parallelization to achieve scalable path association rule mining. Our experimental study using real-world graph data verifies the significance of path association rules and the efficiency of our solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02029v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuya Sasaki, Panagiotis Karras</dc:creator>
    </item>
    <item>
      <title>Is Large Language Model Good at Database Knob Tuning? A Comprehensive Experimental Evaluation</title>
      <link>https://arxiv.org/abs/2408.02213</link>
      <description>arXiv:2408.02213v1 Announce Type: new 
Abstract: Knob tuning plays a crucial role in optimizing databases by adjusting knobs to enhance database performance. However, traditional tuning methods often follow a Try-Collect-Adjust approach, proving inefficient and database-specific. Moreover, these methods are often opaque, making it challenging for DBAs to grasp the underlying decision-making process.
  The emergence of large language models (LLMs) like GPT-4 and Claude-3 has excelled in complex natural language tasks, yet their potential in database knob tuning remains largely unexplored. This study harnesses LLMs as experienced DBAs for knob-tuning tasks with carefully designed prompts. We identify three key subtasks in the tuning system: knob pruning, model initialization, and knob recommendation, proposing LLM-driven solutions to replace conventional methods for each subtask.
  We conduct extensive experiments to compare LLM-driven approaches against traditional methods across the subtasks to evaluate LLMs' efficacy in the knob tuning domain. Furthermore, we explore the adaptability of LLM-based solutions in diverse evaluation settings, encompassing new benchmarks, database engines, and hardware environments. Our findings reveal that LLMs not only match or surpass traditional methods but also exhibit notable interpretability by generating responses in a coherent ``chain-of-thought'' manner. We further observe that LLMs exhibit remarkable generalizability through simple adjustments in prompts, eliminating the necessity for additional training or extensive code modifications.
  Drawing insights from our experimental findings, we identify several opportunities for future research aimed at advancing the utilization of LLMs in the realm of database management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02213v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiyan Li, Haoyang Li, Zhao Pu, Jing Zhang, Xinyi Zhang, Tao Ji, Luming Sun, Cuiping Li, Hong Chen</dc:creator>
    </item>
    <item>
      <title>Self-Enhancing Video Data Management System for Compositional Events with Large Language Models [Technical Report]</title>
      <link>https://arxiv.org/abs/2408.02243</link>
      <description>arXiv:2408.02243v1 Announce Type: new 
Abstract: Complex video queries can be answered by decomposing them into modular subtasks. However, existing video data management systems assume the existence of predefined modules for each subtask. We introduce VOCAL-UDF, a novel self-enhancing system that supports compositional queries over videos without the need for predefined modules. VOCAL-UDF automatically identifies and constructs missing modules and encapsulates them as user-defined functions (UDFs), thus expanding its querying capabilities. To achieve this, we formulate a unified UDF model that leverages large language models (LLMs) to aid in new UDF generation. VOCAL-UDF handles a wide range of concepts by supporting both program-based UDFs (i.e., Python functions generated by LLMs) and distilled-model UDFs (lightweight vision models distilled from strong pretrained models). To resolve the inherent ambiguity in user intent, VOCAL-UDF generates multiple candidate UDFs and uses active learning to efficiently select the best one. With the self-enhancing capability, VOCAL-UDF significantly improves query performance across three video datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02243v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enhao Zhang, Nicole Sullivan, Brandon Haynes, Ranjay Krishna, Magdalena Balazinska</dc:creator>
    </item>
    <item>
      <title>AMIDER: A Multidisciplinary Research Database and Its Application to Promote Open Science</title>
      <link>https://arxiv.org/abs/2408.02246</link>
      <description>arXiv:2408.02246v1 Announce Type: new 
Abstract: The AMIDER, Advanced Multidisciplinary Integrated-Database for Exploring new Research, is a newly developed research data catalog to demonstrate an advanced database application. AMIDER is characterized as a multidisciplinary database equipped with a user-friendly web application. Its catalog view displays diverse research data at once beyond any limitation of each individual discipline. Some useful functions, such as a selectable data download, data format conversion, and display of data visual information, are also implemented. Further advanced functions, such as visualization of dataset mutual relationship, are also implemented as a preliminary trial. These characteristics and functions are expected to enhance the accessibility to individual research data, even from non-expertized users, and be helpful for collaborations among diverse scientific fields beyond individual disciplines. Multidisciplinary data management is also one of AMIDER's uniqueness, where various metadata schemas can be mapped to a uniform metadata table, and standardized and self-describing data formats are adopted. AMIDER website (https://amider.rois.ac.jp/) had been launched in April 2024. As of July 2024, over 15,000 metadata in various research fields of polar science have been registered in the database, and approximately 500 visitors are viewing the website every day on average. Expansion of the database to further multidisciplinary scientific fields, not only polar science, is planned, and advanced attempts, such as applying Natural Language Processing (NLP) to metadata, have also been considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02246v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Masayoshi Kozai (Polar Environment Data Science Center, Joint Support-Center for Data Science Research, Research Organization of Information and Systems, Tachikawa, Japan), Yoshimasa Tanaka (Polar Environment Data Science Center, Joint Support-Center for Data Science Research, Research Organization of Information and Systems, Tachikawa, Japan, National Institute of Polar Research, Research Organization of Information and Systems, Tachikawa, Japan), Shuji Abe (International Research Center for Space and Planetary Environmental Science, Kyushu University, Fukuoka, Japan), Yasuyuki Minamiyama (Research Center for Open Science and Data Platform, National Institute of Informatics, Research Organization of Information and Systems, Tokyo, Japan), Atsuki Shinbori (Institute for Space and Earth Environmental Research Center for Integrated Data Science, Nagoya University, Nagoya, Japan), Akira Kadokura (Polar Environment Data Science Center, Joint Support-Center for Data Science Research, Research Organization of Information and Systems, Tachikawa, Japan)</dc:creator>
    </item>
    <item>
      <title>Flow with FlorDB: Incremental Context Maintenance for the Machine Learning Lifecycle</title>
      <link>https://arxiv.org/abs/2408.02498</link>
      <description>arXiv:2408.02498v1 Announce Type: new 
Abstract: The metadata involved in integrating code, data, configuration, and feedback into predictive models is varied and complex. This complexity is further compounded by the agile development practices favored by data scientists and machine learning engineers. These practices emphasize high experimentation velocity and frequent deployments, which can make it challenging to keep track of all the relevant metadata. The iterative nature of agile methods means that models, datasets, and configurations are constantly evolving. Each experiment might involve tweaks to the data preprocessing steps, changes in model hyperparameters, or updates to the deployment environment. The need for rapid iteration can lead to shortcuts or oversights in documentation and metadata management. Effective metadata management requires robust yet flexible tools and practices that can integrate and organize this information without slowing down the development process. Traditional context management often emphasizes a ``metadata first'' approach, which can introduce significant friction for developers. FlorDB reduces this friction through multiversion hindsight logging and incremental context maintenance, allowing developers to add and refine metadata after the fact. This ``metadata later'' approach enables a more flexible and incremental development process, allowing data scientists to focus on model creation and refinement without the burden of documentation upfront. As shown in a demo, FlorDB can be used to build AI/ML applications with integrated train-infer pipelines and managed feedback loops. Ultimately, the goal of FlorDB is to ensure that critical metadata is maintained accurately and efficiently, even in fast-paced agile workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02498v1</guid>
      <category>cs.DB</category>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rolando Garcia, Pragya Kallanagoudar, Chithra Anand, Sarah E. Chasins, Joseph M. Hellerstein, Aditya G. Parameswaran</dc:creator>
    </item>
    <item>
      <title>Earth System Data Cubes: Avenues for advancing Earth system research</title>
      <link>https://arxiv.org/abs/2408.02348</link>
      <description>arXiv:2408.02348v1 Announce Type: cross 
Abstract: Recent advancements in Earth system science have been marked by the exponential increase in the availability of diverse, multivariate datasets characterised by moderate to high spatio-temporal resolutions. Earth System Data Cubes (ESDCs) have emerged as one suitable solution for transforming this flood of data into a simple yet robust data structure. ESDCs achieve this by organising data into an analysis-ready format aligned with a spatio-temporal grid, facilitating user-friendly analysis and diminishing the need for extensive technical data processing knowledge. Despite these significant benefits, the completion of the entire ESDC life cycle remains a challenging task. Obstacles are not only of a technical nature but also relate to domain-specific problems in Earth system research. There exist barriers to realising the full potential of data collections in light of novel cloud-based technologies, particularly in curating data tailored for specific application domains. These include transforming data to conform to a spatio-temporal grid with minimum distortions and managing complexities such as spatio-temporal autocorrelation issues. Addressing these challenges is pivotal for the effective application of Artificial Intelligence (AI) approaches. Furthermore, adhering to open science principles for data dissemination, reproducibility, visualisation, and reuse is crucial for fostering sustainable research. Overcoming these challenges offers a substantial opportunity to advance data-driven Earth system research, unlocking the full potential of an integrated, multidimensional view of Earth system processes. This is particularly true when such research is coupled with innovative research paradigms and technological progress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02348v1</guid>
      <category>cs.CV</category>
      <category>cs.DB</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Montero, Guido Kraemer, Anca Anghelea, C\'esar Aybar, Gunnar Brandt, Gustau Camps-Valls, Felix Cremer, Ida Flik, Fabian Gans, Sarah Habershon, Chaonan Ji, Teja Kattenborn, Laura Mart\'inez-Ferrer, Francesco Martinuzzi, Martin Reinhardt, Maximilian S\"ochting, Khalil Teber, Miguel D. Mahecha</dc:creator>
    </item>
    <item>
      <title>Distinctiveness Maximization in Datasets Assemblage</title>
      <link>https://arxiv.org/abs/2401.00659</link>
      <description>arXiv:2401.00659v3 Announce Type: replace 
Abstract: In this paper, given a user's query set and a budget limit, we aim to help the user assemble a set of datasets that can enrich a base dataset by introducing the maximum number of distinct tuples (i.e., maximizing distinctiveness). We prove this problem to be NP-hard and, subsequently, we develop a greedy algorithm that attains an approximation ratio of (1-e^{-1})/2. However, this algorithm lacks efficiency and scalability due to its frequent computation of the exact distinctiveness marginal gain of any candidate dataset for selection, which requires scanning through every tuple in candidate datasets and thus is unaffordable in practice. To overcome this limitation, we propose an efficient machine learning (ML)-based method for estimating the distinctiveness marginal gain of any candidate dataset. This effectively eliminates the need to test each tuple individually. Estimating the distinctiveness marginal gain of a dataset involves estimating the number of distinct tuples in the tuple sets returned by each query in a query set across multiple datasets. This can be viewed as the cardinality estimation for a query set on a set of datasets, and the proposed method is the first to tackle this cardinality estimation problem. This is a significant advancement over prior methods that were limited to single-query cardinality estimation on a single dataset and struggled with identifying overlaps among tuple sets returned by each query in a query set across multiple datasets. Extensive experiments using five real-world data pools demonstrate that our algorithm, which utilizes ML-based distinctiveness estimation, outperforms all relevant baselines in both effectiveness and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00659v3</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tingting Wang, Shixun Huang, Zhifeng Bao, J. Shane Culpepper, Volkan Dedeoglu, Reza Arablouei</dc:creator>
    </item>
    <item>
      <title>CuckooGraph: A Scalable and Space-Time Efficient Data Structure for Large-Scale Dynamic Graphs</title>
      <link>https://arxiv.org/abs/2405.15193</link>
      <description>arXiv:2405.15193v2 Announce Type: replace 
Abstract: Graphs play an increasingly important role in various big data applications. However, existing graph data structures cannot simultaneously address the performance bottlenecks caused by the dynamic updates, large scale, and high query complexity of current graphs. This paper proposes a novel data structure for large-scale dynamic graphs called CuckooGraph. It does not require any prior knowledge of the upcoming graphs, and can adaptively resize to the most memory-efficient form while requiring few memory accesses for very fast graph data processing. The key techniques of CuckooGraph include TRANSFORMATION and DENYLIST. TRANSFORMATION fully utilizes the limited memory by designing related data structures that allow flexible space transformations to smoothly expand/tighten the required space depending on the number of incoming items. DENYLIST efficiently handles item insertion failures and further improves processing speed. Our experimental results show that compared with the most competitive solution Spruce, CuckooGraph achieves about $33\times$ higher insertion throughput while requiring only about $68\%$ of the memory space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15193v2</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuochen Fan, Yalun Cai, Zirui Liu, Jiarui Guo, Xin Fan, Tong Yang, Bin Cui</dc:creator>
    </item>
    <item>
      <title>The Complexity of Resilience Problems via Valued Constraint Satisfaction Problems</title>
      <link>https://arxiv.org/abs/2309.15654</link>
      <description>arXiv:2309.15654v3 Announce Type: replace-cross 
Abstract: Valued constraint satisfaction problems (VCSPs) constitute a large class of computational optimisation problems. It was shown recently that, over finite domains, every VCSP is in P or NP-complete, depending on the admitted cost functions. In this article, we study cost functions over countably infinite domains whose automorphisms form an oligomorphic permutation group. Our results include a hardness condition based on a generalisation of pp-constructability as known from classical CSPs and a polynomial-time tractability condition based on the concept of fractional polymorphisms. We then observe that the resilience problem for unions of conjunctive queries (UCQs) studied in database theory, under bag semantics, may be viewed as a special case of the VCSPs that we consider. We obtain a complexity dichotomy for the case of incidence-acyclic UCQs and exemplarily use our methods to determine the complexity of a query that had remained open in the literature. Further, we conjecture that our hardness and tractability conditions match for resilience problems for UCQs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15654v3</guid>
      <category>math.LO</category>
      <category>cs.CC</category>
      <category>cs.DB</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3661814.3662071</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 39th Annual ACM/IEEE Symposium on Logic in Computer Science (LICS '24). Association for Computing Machinery, New York, NY, USA, Article 14, 1-14, 2024</arxiv:journal_reference>
      <dc:creator>Manuel Bodirsky, \v{Z}aneta Semani\v{s}inov\'a, Carsten Lutz</dc:creator>
    </item>
  </channel>
</rss>
