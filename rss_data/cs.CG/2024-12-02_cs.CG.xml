<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CG updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CG</link>
    <description>cs.CG updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CG" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Dec 2024 05:00:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Extraction Theorems With Small Extraction Numbers</title>
      <link>https://arxiv.org/abs/2411.18655</link>
      <description>arXiv:2411.18655v1 Announce Type: new 
Abstract: In this work, we develop Extraction Theorems for classes of geometric objects with small extraction numbers. These classes include intervals, axis-parallel segments, axis-parallel rays, and octants. We investigate these classes of objects and prove small bounds on the extraction numbers. The tightness of these bounds is demonstrated by examples with matching lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18655v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arjun Agarwal, Sayan Bandyapadhyay</dc:creator>
    </item>
    <item>
      <title>Noncommutative Model Selection and the Data-Driven Estimation of Real Cohomology Groups</title>
      <link>https://arxiv.org/abs/2411.19894</link>
      <description>arXiv:2411.19894v1 Announce Type: new 
Abstract: We propose three completely data-driven methods for estimating the real cohomology groups $H^k (X ; \mathbb{R})$ of a compact metric-measure space $(X, d_X, \mu_X)$ embedded in a metric-measure space $(Y,d_Y,\mu_Y)$, given a finite set of points $S$ sampled from a uniform distrbution $\mu_X$ on $X$, possibly corrupted with noise from $Y$. We present the results of several computational experiments in the case that $X$ is embedded in $\mathbb{R}^n$, where two of the three algorithms performed well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19894v1</guid>
      <category>cs.CG</category>
      <category>cs.LG</category>
      <category>math.AT</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Araceli Guzm\'an-Trist\'an, Antonio Rieser, Eduardo Vel\'azquez-Richards</dc:creator>
    </item>
    <item>
      <title>Decomposing zero-dimensional persistent homology over rooted tree quivers</title>
      <link>https://arxiv.org/abs/2411.19319</link>
      <description>arXiv:2411.19319v1 Announce Type: cross 
Abstract: Given a functor from any category into the category of topological spaces, one obtains a linear representation of the category by post-composing the given functor with a homology functor with field coefficients. This construction is fundamental in persistence theory, where it is known as persistent homology, and where the category is typically a poset. Persistence theory is particularly successful when the poset is a finite linearly ordered set, owing to the fact that in this case its category of representations is of finite type. We show that when the poset is a rooted tree poset (a poset with a maximum and whose Hasse diagram is a tree) the additive closure of the category of representations obtainable as zero-dimensional persistent homology is of finite type, and give a quadratic-time algorithm for decomposition into indecomposables. In doing this, we give an algebraic characterization of the additive closure in terms of Ringel's tree modules, and show that its indecomposable objects are the reduced representations of Kinser.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19319v1</guid>
      <category>math.RT</category>
      <category>cs.CG</category>
      <category>math.AT</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Riju Bindua, Thomas Br\"ustle, Luis Scoccola</dc:creator>
    </item>
    <item>
      <title>Shadoks Approach to Knapsack Polygonal Packing</title>
      <link>https://arxiv.org/abs/2403.20123</link>
      <description>arXiv:2403.20123v2 Announce Type: replace 
Abstract: The 2024 edition of the CG:SHOP Challenge focused on the knapsack polygonal packing problem. Each instance consists of a convex polygon known as the container and a multiset of items, where each item is a simple polygon with an associated integer value. A feasible packing solution places a selection of the items inside the container without overlapping and using only translations. The goal is to achieve a packing that maximizes the total value of the items in the solution. Our approach to win first place is divided into two main steps. First, we generate promising initial solutions using two strategies: one based on integer linear programming and the other on employing a combination of geometric greedy heuristics. In the second step, we enhance these solutions through local search techniques, which involve repositioning items and exploring potential replacements to improve the total value of the packing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20123v2</guid>
      <category>cs.CG</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.SoCG.2024.84</arxiv:DOI>
      <dc:creator>Guilherme D. da Fonseca, Yan Gerard</dc:creator>
    </item>
    <item>
      <title>NeCGS: Neural Compression for 3D Geometry Sets</title>
      <link>https://arxiv.org/abs/2405.15034</link>
      <description>arXiv:2405.15034v2 Announce Type: replace 
Abstract: We present NeCGS, the first neural compression paradigm, which can compress a geometry set encompassing thousands of detailed and diverse 3D mesh models by up to 900 times with high accuracy and preservation of detailed geometric structures. Specifically, we first propose TSDF-Def, a new implicit representation that is capable of \textbf{accurately} representing irregular 3D mesh models with various structures into regular 4D tensors of \textbf{uniform} and \textbf{compact} size, where 3D surfaces can be extracted through the deformable marching cubes. Then we construct a quantization-aware auto-decoder network architecture to regress these 4D tensors to explore the local geometric similarity within each shape and across different shapes for redundancy removal, resulting in more compact representations, including an embedded feature of a smaller size associated with each 3D model and a network parameter shared by all models. We finally encode the resulting features and network parameters into bitstreams through entropy coding. Besides, our NeCGS can handle the dynamic scenario well, where new 3D models are constantly added to a compressed set. Extensive experiments and ablation studies demonstrate the significant advantages of our NeCGS over state-of-the-art methods both quantitatively and qualitatively. The source code is available at https://github.com/rsy6318/NeCGS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15034v2</guid>
      <category>cs.CG</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siyu Ren, Junhui Hou, Wenping Wang</dc:creator>
    </item>
  </channel>
</rss>
