<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Jul 2025 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Local Clustering in Hypergraphs through Higher-Order Motifs</title>
      <link>https://arxiv.org/abs/2507.10570</link>
      <description>arXiv:2507.10570v1 Announce Type: new 
Abstract: Hypergraphs provide a powerful framework for modeling complex systems and networks with higher-order interactions beyond simple pairwise relationships. However, graph-based clustering approaches, which focus primarily on pairwise relations, fail to represent higher-order interactions, often resulting in low-quality clustering outcomes. In this work, we introduce a novel approach for local clustering in hypergraphs based on higher-order motifs, small connected subgraphs in which nodes may be linked by interactions of any order, extending motif-based techniques previously applied to standard graphs. Our method exploits hypergraph-specific higher-order motifs to better characterize local structures and optimize motif conductance. We propose two alternative strategies for identifying local clusters around a seed hyperedge: a core-based method utilizing hypergraph core decomposition and a BFS-based method based on breadth-first exploration. We construct an auxiliary hypergraph to facilitate efficient partitioning and introduce a framework for local motif-based clustering. Extensive experiments on real-world datasets demonstrate the effectiveness of our framework and provide a comparative analysis of the two proposed clustering strategies in terms of clustering quality and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10570v1</guid>
      <category>cs.SI</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe F. Italiano, Athanasios L. Konstantinidis, Anna Mpanti, Fariba Ranjbar</dc:creator>
    </item>
    <item>
      <title>The Shape of Deceit: Behavioral Consistency and Fragility in Money Laundering Patterns</title>
      <link>https://arxiv.org/abs/2507.10608</link>
      <description>arXiv:2507.10608v1 Announce Type: new 
Abstract: Conventional anti-money laundering (AML) systems predominantly focus on identifying anomalous entities or transactions, flagging them for manual investigation based on statistical deviation or suspicious behavior. This paradigm, however, misconstrues the true nature of money laundering, which is rarely anomalous but often deliberate, repeated, and concealed within consistent behavioral routines. In this paper, we challenge the entity-centric approach and propose a network-theoretic perspective that emphasizes detecting predefined laundering patterns across directed transaction networks. We introduce the notion of behavioral consistency as the core trait of laundering activity, and argue that such patterns are better captured through subgraph structures expressing semantic and functional roles - not solely geometry. Crucially, we explore the concept of pattern fragility: the sensitivity of laundering patterns to small attribute changes and, conversely, their semantic robustness even under drastic topological transformations. We claim that laundering detection should not hinge on statistical outliers, but on preservation of behavioral essence, and propose a reconceptualization of pattern similarity grounded in this insight. This philosophical and practical shift has implications for how AML systems model, scan, and interpret networks in the fight against financial crime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10608v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danny Butvinik, Ofir Yakobi, Michal Einhorn Cohen, Elina Maliarsky</dc:creator>
    </item>
    <item>
      <title>Multilayer Artificial Benchmark for Community Detection (mABCD)</title>
      <link>https://arxiv.org/abs/2507.10795</link>
      <description>arXiv:2507.10795v1 Announce Type: new 
Abstract: The Artificial Benchmark for Community Detection (ABCD) model is a random graph model with community structure and power-law distribution for both degrees and community sizes. The model generates graphs similar to the well-known LFR model but it is faster, more interpretable, and can be investigated analytically. In this paper, we use the underlying ingredients of the ABCD model and introduce its variant for multilayer networks, mABCD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10795v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>{\L}ukasz Krai\'nski, Micha{\l} Czuba, Piotr Br\'odka, Pawe{\l} Pra{\l}at, Bogumi{\l} Kami\'nski, Fran\c{c}ois Th\'eberge</dc:creator>
    </item>
    <item>
      <title>Toxicity in State Sponsored Information Operations</title>
      <link>https://arxiv.org/abs/2507.10936</link>
      <description>arXiv:2507.10936v1 Announce Type: new 
Abstract: State-sponsored information operations (IOs) increasingly influence global discourse on social media platforms, yet their emotional and rhetorical strategies remain inadequately characterized in scientific literature. This study presents the first comprehensive analysis of toxic language deployment within such campaigns, examining 56 million posts from over 42 thousand accounts linked to 18 distinct geopolitical entities on X/Twitter. Using Google's Perspective API, we systematically detect and quantify six categories of toxic content and analyze their distribution across national origins, linguistic structures, and engagement metrics, providing essential information regarding the underlying patterns of such operations. Our findings reveal that while toxic content constitutes only 1.53% of all posts, they are associated with disproportionately high engagement and appear to be strategically deployed in specific geopolitical contexts. Notably, toxic content originating from Russian influence operations receives significantly higher user engagement compared to influence operations from any other country in our dataset. Our code is available at https://github.com/shafin191/Toxic_IO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10936v1</guid>
      <category>cs.SI</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ashfaq Ali Shafin, Khandaker Mamun Ahmed</dc:creator>
    </item>
    <item>
      <title>Urban delineation through the lens of commute networks: Leveraging graph embeddings to distinguish socioeconomic groups in cities</title>
      <link>https://arxiv.org/abs/2507.11057</link>
      <description>arXiv:2507.11057v1 Announce Type: new 
Abstract: Delineating areas within metropolitan regions stands as an important focus among urban researchers, shedding light on the urban perimeters shaped by evolving population dynamics. Applications to urban science are numerous, from facilitating comparisons between delineated districts and administrative divisions to informing policymakers of the shifting economic and labor landscapes. In this study, we propose using commute networks sourced from the census for the purpose of urban delineation, by modeling them with a Graph Neural Network (GNN) architecture. We derive low-dimensional representations of granular urban areas (nodes) using GNNs. Subsequently, nodes' embeddings are clustered to identify spatially cohesive communities in urban areas. Our experiments across the U.S. demonstrate the effectiveness of network embeddings in capturing significant socioeconomic disparities between communities in various cities, particularly in factors such as median household income. The role of census mobility data in regional delineation is also noted, and we establish the utility of GNNs in urban community detection, as a powerful alternative to existing methods in this domain. The results offer insights into the wider effects of commute networks and their use in building meaningful representations of urban regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11057v1</guid>
      <category>cs.SI</category>
      <category>stat.ML</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Devashish Khulbe, Stanislav Sobolevsky</dc:creator>
    </item>
    <item>
      <title>Enhance Stability of Network by Edge Anchor</title>
      <link>https://arxiv.org/abs/2507.11090</link>
      <description>arXiv:2507.11090v1 Announce Type: new 
Abstract: With the rapid growth of online social networks, strengthening their stability has emerged as a key research focus. This study aims to identify influential relationships that significantly impact community stability. In this paper, we introduce and explore the anchor trussness reinforcement problem to reinforce the overall user engagement of networks by anchoring some edges. Specifically, for a given graph $G$ and a budget $b$, we aim to identify $b$ edges whose anchoring maximizes the trussness gain, which is the cumulative increment of trussness across all edges in $G$. We establish the NP-hardness of the problem. To address this problem, we introduce a greedy framework that iteratively selects the current best edge. To scale for larger networks, we first propose an upward-route method to constrain potential trussness increment edges. Augmented with a support check strategy, this approach enables the efficient computation of the trussness gain for anchoring one edge. Then, we design a classification tree structure to minimize redundant computations in each iteration by organizing edges based on their trussness. We conduct extensive experiments on 8 real-world networks to validate the efficiency and effectiveness of the proposed model and methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11090v1</guid>
      <category>cs.SI</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongbo Qiu, Renjie Sun, Chen chen, Xiaoyang Wang</dc:creator>
    </item>
    <item>
      <title>RedOne: Revealing Domain-specific LLM Post-Training in Social Networking Services</title>
      <link>https://arxiv.org/abs/2507.10605</link>
      <description>arXiv:2507.10605v1 Announce Type: cross 
Abstract: As a primary medium for modern information dissemination, social networking services (SNS) have experienced rapid growth, which has proposed significant challenges for platform content management and interaction quality improvement. Recently, the development of large language models (LLMs) has offered potential solutions but existing studies focus on isolated tasks, which not only encounter diminishing benefit from the data scaling within individual scenarios but also fail to flexibly adapt to diverse real-world context. To address these challenges, we introduce RedOne, a domain-specific LLM designed to break the performance bottleneck of single-task baselines and establish a comprehensive foundation for the SNS. RedOne was developed through a three-stage training strategy consisting of continue pretraining, supervised fine-tuning, and preference optimization, using a large-scale real-world dataset. Through extensive experiments, RedOne maintains strong general capabilities, and achieves an average improvement up to 14.02% across 8 major SNS tasks and 7.56% in SNS bilingual evaluation benchmark, compared with base models. Furthermore, through online testing, RedOne reduced the exposure rate in harmful content detection by 11.23% and improved the click page rate in post-view search by 14.95% compared with single-tasks finetuned baseline models. These results establish RedOne as a robust domain-specific LLM for SNS, demonstrating excellent generalization across various tasks and promising applicability in real-world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10605v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fei Zhao, Chonggang Lu, Yue Wang, Zheyong Xie, Ziyan Liu, Haofu Qian, JianZhao Huang, Fangcheng Shi, Zijie Meng, Hongcheng Guo, Mingqian He, Xinze Lyu, Yiming Lu, Ziyang Xiang, Zheyu Ye, Chengqiang Lu, Zhe Xu, Yi Wu, Yao Hu, Yan Gao, Jun Fan, Xiaolong Jiang, Weiting Liu, Boyang Wang, Shaosheng Cao</dc:creator>
    </item>
    <item>
      <title>Testing Hypotheses from the Social Approval Theory of Online Hate: An Analysis of 110 Million Posts from Parler</title>
      <link>https://arxiv.org/abs/2507.10810</link>
      <description>arXiv:2507.10810v1 Announce Type: cross 
Abstract: In this paper, we explored how online hate is motivated by receiving social approval from others. We specifically examined two central tenets of Walther's (2024) social approval theory of online hate: (H1a) more signals of social approval on hate messages predicts more subsequent hate messages, and (H1b) as social approval increases, hate speech messages become more extreme. Using over 110 million posts from Parler (2018-2021), we observed that the number of upvotes a person received on a hate speech post was unassociated with the amount of hate speech in their next post and posts during the next week, month, three months, and six months. Between-person effects revealed an average negative relationship between social approval and hate speech production at the post level, but this relationship was mixed at other time intervals. Social approval reinforcement mechanisms of online hate may operate differently on niche social media platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10810v1</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David M. Markowitz, Samuel Hardman Taylor</dc:creator>
    </item>
    <item>
      <title>The Potential Impact of Disruptive AI Innovations on U.S. Occupations</title>
      <link>https://arxiv.org/abs/2507.11403</link>
      <description>arXiv:2507.11403v1 Announce Type: cross 
Abstract: The rapid rise of AI is poised to disrupt the labor market. However, AI is not a monolith; its impact depends on both the nature of the innovation and the jobs it affects. While computational approaches are emerging, there is no consensus on how to systematically measure an innovation's disruptive potential. Here, we calculate the disruption index of 3,237 U.S. AI patents (2015-2022) and link them to job tasks to distinguish between "consolidating" AI innovations that reinforce existing structures and "disruptive" AI innovations that alter them. Our analysis reveals that consolidating AI primarily targets physical, routine, and solo tasks, common in manufacturing and construction in the Midwest and central states. By contrast, disruptive AI affects unpredictable and mental tasks, particularly in coastal science and technology sectors. Surprisingly, we also find that disruptive AI disproportionately affects areas already facing skilled labor shortages, suggesting disruptive AI technologies may accelerate change where workers are scarce rather than replacing a surplus. Ultimately, consolidating AI appears to extend current automation trends, while disruptive AI is set to transform complex mental work, with a notable exception for collaborative tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11403v1</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Munjung Kim, Marios Constantinides, Sanja \v{S}\'cepanovi\'c, Yong-Yeol Ahn, Daniele Quercia</dc:creator>
    </item>
    <item>
      <title>HIF: The hypergraph interchange format for higher-order networks</title>
      <link>https://arxiv.org/abs/2507.11520</link>
      <description>arXiv:2507.11520v1 Announce Type: cross 
Abstract: Many empirical systems contain complex interactions of arbitrary size, representing, for example, chemical reactions, social groups, co-authorship relationships, and ecological dependencies. These interactions are known as higher-order interactions and the collection of these interactions comprise a higher-order network, or hypergraph. Hypergraphs have established themselves as a popular and versatile mathematical representation of such systems and a number of software packages written in various programming languages have been designed to analyze these networks. However, the ecosystem of higher-order network analysis software is fragmented due to specialization of each software's programming interface and compatible data representations. To enable seamless data exchange between higher-order network analysis software packages, we introduce the Hypergraph Interchange Format (HIF), a standardized format for storing higher-order network data. HIF supports multiple types of higher-order networks, including undirected hypergraphs, directed hypergraphs, and simplicial complexes, while actively exploring extensions to represent multiplex hypergraphs, temporal hypergraphs, and ordered hypergraphs. To accommodate the wide variety of metadata used in different contexts, HIF also includes support for attributes associated with nodes, edges, and incidences. This initiative is a collaborative effort involving authors, maintainers, and contributors from prominent hypergraph software packages. This project introduces a JSON schema with corresponding documentation and unit tests, example HIF-compliant datasets, and tutorials demonstrating the use of HIF with several popular higher-order network analysis software packages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11520v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mart\'in Coll, Cliff A. Joslyn, Nicholas W. Landry, Quintino Francesco Lotito, Audun Myers, Joshua Pickard, Brenda Praggastis, Przemys{\l}aw Szufel</dc:creator>
    </item>
    <item>
      <title>Entropy-based models to randomize real-world hypergraphs</title>
      <link>https://arxiv.org/abs/2207.12123</link>
      <description>arXiv:2207.12123v3 Announce Type: replace 
Abstract: Network theory has often disregarded many-body relationships, solely focusing on pairwise interactions: neglecting them, however, can lead to misleading representations of complex systems. Hypergraphs represent a suitable framework for describing polyadic interactions. Here, we leverage the representation of hypergraphs based on the incidence matrix for extending the entropy-based approach to higher-order structures: in analogy with the Exponential Random Graphs, we introduce the Exponential Random Hypergraphs (ERHs). After exploring the asymptotic behaviour of thresholds generalising the percolation one, we apply ERHs to study real-world data. First, we generalise key network metrics to hypergraphs; then, we compute their expected value and compare it with the empirical one, in order to detect deviations from random behaviours. Our method is analytically tractable, scalable and capable of revealing structural patterns of real-world hypergraphs that differ significantly from those emerging as a consequence of simpler constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.12123v3</guid>
      <category>cs.SI</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s42005-025-02182-2</arxiv:DOI>
      <arxiv:journal_reference>Comm. Phys. 8 (284) (2025)</arxiv:journal_reference>
      <dc:creator>Fabio Saracco, Giovanni Petri, Renaud Lambiotte, Tiziano Squartini</dc:creator>
    </item>
    <item>
      <title>Verified authors shape X/Twitter discursive communities</title>
      <link>https://arxiv.org/abs/2405.04896</link>
      <description>arXiv:2405.04896v2 Announce Type: replace 
Abstract: In this study, we address the challenge of detecting ``discursive communities'' on X/Twitter by focusing on the role of verified users as the main content creators in online political debates. The analysis centers on three major Italian political events in 2022 - the Presidential election, a governmental crisis, and the general elections - occurring before the introduction of paid account verification. We propose and compare two novel methodologies, MonoDC and BiDC, which exploit, respectively, the retweet network among users and a similarity network based on shared audiences, while integrating a maximum entropy null model to filter out the inherent noise in online social networks. Our results demonstrate that leveraging verified users-considered as indicators of prestige and authority-leads to significantly clear community partitions that closely reflect the actual political affiliations, outperforming standard community detection algorithms applied to the entire retweet network. Moreover, the comparison of different methodologies and user sets suggests that the status conferred by the blue verification tick plays a dominant role in shaping online discourse, with important implications for platform governance, especially in light of the recent shift to paid verification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04896v2</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Stefano Guarino, Ayoub Mounim, Guido Caldarelli, Fabio Saracco</dc:creator>
    </item>
    <item>
      <title>Crowd: A Social Network Simulation Framework</title>
      <link>https://arxiv.org/abs/2412.10781</link>
      <description>arXiv:2412.10781v3 Announce Type: replace 
Abstract: To observe how individual behavior shapes a larger community's actions, agent-based modeling and simulation (ABMS) has been widely adopted by researchers in social sciences, economics, and epidemiology. While simulations can be run on general-purpose ABMS frameworks, these tools are not specifically designed for social networks and, therefore, provide limited features, increasing the effort required for complex simulations. In this paper, we introduce Crowd, a social network simulator that adopts the agent-based modeling methodology to model real-world phenomena within a network environment. Designed to facilitate easy and quick modeling, Crowd supports simulation setup through YAML configuration and enables further customization with user-defined methods. Other features include no-code simulations for diffusion tasks, interactive visualizations, data aggregation, and chart drawing facilities. Designed in Python, Crowd also supports generative agents and connects easily with Python's libraries for data analysis and machine learning. Finally, we include three case studies to illustrate the use of the framework, including generative agents in epidemics, influence maximization, and networked trust games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10781v3</guid>
      <category>cs.SI</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCSS.2025.3565377</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Computational Social Systems, pp. 1-15, 2025</arxiv:journal_reference>
      <dc:creator>Ann Nedime Nese Rende, Tolga Yilmaz, \"Ozg\"ur Ulusoy</dc:creator>
    </item>
    <item>
      <title>Technological Complexity Based on Japanese Patent Data</title>
      <link>https://arxiv.org/abs/2504.11932</link>
      <description>arXiv:2504.11932v4 Announce Type: replace 
Abstract: As international competition intensifies in technologies, nations need to identify key technologies to foster innovation. However, the identification is challenging due to the independent and inherently complex nature of technologies. Traditionally, regional analyses of technological portfolios have been limited to binary evaluations, indicating merely whether a region specializes in a technology, or relying on the average Technological Complexity Index (TCI) of the specialized technologies. This study proposes that evaluating TCI at the corporate level could provide finer granularity and more detailed insights. To address the underutilization of corporate-level TCI assessments in Japan, this study applies the Technological Complexity Index using carefully processed patent data spanning fiscal years 1981 to 2010. Specifically, we analyze a bipartite network composed of 1,938 corporations connected to technological fields categorized into either 35 or 124 classifications. Our findings quantitatively characterize the ubiquity and sophistication of each technological field, reveal detailed technological trends reflecting broader societal contexts, and demonstrate methodological stability even when employing finer technological classifications. Additionally, our corporate-level approach allows consistent comparisons across different regions and technological fields, clarifying regional advantages in specific technologies. This refined analytical framework offers policymakers and researchers robust, targeted insights, thereby significantly contributing to innovation strategy formulation in Japan.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11932v4</guid>
      <category>cs.SI</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rintaro Karashima, Hiroyasu Inoue</dc:creator>
    </item>
    <item>
      <title>Capturing Dynamics in Online Public Discourse: A Case Study of Universal Basic Income Discussions on Reddit</title>
      <link>https://arxiv.org/abs/2312.09611</link>
      <description>arXiv:2312.09611v2 Announce Type: replace-cross 
Abstract: Societal change is often driven by shifts in public opinion. As citizens evolve in their norms, beliefs, and values, public policies change too. While traditional opinion polling and surveys can outline the broad strokes of whether public opinion on a particular topic is changing, they usually cannot capture the full multi-dimensional richness and diversity of opinion present in a large heterogeneous population. However, an increasing fraction of public discourse about public policy issues is now occurring on online platforms, which presents an opportunity to measure public opinion change at a qualitatively different scale of resolution and context.
  In this paper, we present a conceptual model of observed opinion change on online platforms and apply it to study public discourse on Universal Basic Income (UBI) on Reddit throughout its history. UBI is a periodic, no-strings-attached cash payment given to every citizen of a population. We study UBI as it is a clearly-defined policy proposal that has recently experienced a surge of interest through trends like automation and events like the COVID-19 pandemic. We find that overall stance towards UBI on Reddit significantly declined until mid-2019, when this historical trend suddenly reversed and Reddit became substantially more supportive. Using our model, we find the most significant drivers of this overall stance change were shifts within different user cohorts, within communities that represented similar affluence levels, and within communities that represented similar partisan leanings. Our method identifies nuanced social drivers of opinion change in the large-scale public discourse that now regularly occurs online, and could be applied to a broad set of other important issues and policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09611v2</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rachel Kim, Veniamin Veselovsky, Ashton Anderson</dc:creator>
    </item>
    <item>
      <title>Leveraging Large Language Models for Multi-Class and Multi-Label Detection of Drug Use and Overdose Symptoms on Social Media</title>
      <link>https://arxiv.org/abs/2504.12355</link>
      <description>arXiv:2504.12355v3 Announce Type: replace-cross 
Abstract: Drug overdose remains a critical global health issue, often driven by misuse of opioids, painkillers, and psychiatric medications. Traditional research methods face limitations, whereas social media offers real-time insights into self-reported substance use and overdose symptoms. This study proposes an AI-driven NLP framework trained on annotated social media data to detect commonly used drugs and associated overdose symptoms. Using a hybrid annotation strategy with LLMs and human annotators, we applied traditional ML models, neural networks, and advanced transformer-based models. Our framework achieved 98% accuracy in multi-class and 97% in multi-label classification, outperforming baseline models by up to 8%. These findings highlight the potential of AI for supporting public health surveillance and personalized intervention strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12355v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Ahmad, Fida Ullah, Muhammad Usman, Umyh Habiba, ldar Batyrshin, Grigori Sidorov</dc:creator>
    </item>
  </channel>
</rss>
