<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>astro-ph.IM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/astro-ph.IM</link>
    <description>astro-ph.IM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/astro-ph.IM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 Oct 2025 01:43:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>CCAT: Magnetic Sensitivity Measurements of Kinetic Inductance Detectors</title>
      <link>https://arxiv.org/abs/2510.03653</link>
      <description>arXiv:2510.03653v2 Announce Type: new 
Abstract: The CCAT Observatory is a ground-based submillimeter to millimeter experiment located on Cerro Chajnantor in the Atacama Desert, at an altitude of 5,600 meters. CCAT features the 6-meter Fred Young Submillimeter Telescope (FYST), which will cover frequency bands from 210 GHz to 850 GHz using its first-generation science instrument, Prime-Cam. The detectors used in Prime-Cam are feedhorn-coupled, lumped-element superconducting microwave kinetic inductance detectors (KIDs). The telescope will perform wide-area surveys at speeds on the order of degrees per second. During telescope operation, the KIDs are exposed to changes in the magnetic field caused by the telescope's movement through Earth's magnetic field and internal sources within the telescope. We present and compare measurements of the magnetic sensitivity of three different CCAT KID designs at 100 mK. The measurements are conducted in a dilution refrigerator (DR) with a set of room temperature Helmholtz coils positioned around the DR. We discuss the implications of these results for CCAT field operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03653v2</guid>
      <category>astro-ph.IM</category>
      <category>physics.ins-det</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin J. Vaughan (Matt), Yuhan Wang (Matt), Cody J. Duell (Matt), Jason Austermann (Matt), James R. Burgoyne (Matt), Scott Chapman (Matt), Steve K. Choi (Matt), Abigail T. Crites (Matt), Eliza Gazda (Matt), Ben Keller (Matt), Michael D. Niemack (Matt), Darshan A. Patel (Matt), Anna Vaskuri (Matt), Eve M. Vavagiakis (Matt), Michael Vissers (Matt), Samantha Walker (Matt), Jordan Wheeler (Matt),  Ruixuan (Matt),  Xie</dc:creator>
    </item>
    <item>
      <title>Introducing The SHell misAlignment Detection for straylight Estimation (SHADE) algorithm: the case of XMM-Newton</title>
      <link>https://arxiv.org/abs/2510.04659</link>
      <description>arXiv:2510.04659v1 Announce Type: new 
Abstract: When performing X-ray observations with a Wolter-I telescope, the presence of bright off-axis sources can introduce unfocused rays, known as straylight, which contaminate the detector and compromise the scientific analysis. Among the different components of straylight, single reflections off the hyperboloid section of the mirror shells often produce arc-like patterns on the detector. These arcs depend not only on the off-axis angle of the source but also on the geometrical alignment of the individual shells. In this paper, we introduce the SHell misAlignment Detection for straylight Estimation (SHADE) algorithm, a novel and flexible tool designed to infer the misalignment parameters of individual shells, reproduce the geometry of straylight arcs and predict its pattern on the detector. SHADE allows us to model each shell displacement with two parameters: $(\gamma,\xi)$ that represents the tilt amplitude and direction. While the algorithm is general and applicable to any Wolter-like telescope, we demonstrate its effectiveness using a set of XMM-Newton observations of the low-mass X-ray binary GX5-1. As a proof of concept, we recover the best-fit misalignment parameters for a selected shell, obtaining $\gamma = 21.9''^{+10.3}_{-9.02}$ and $\xi = 5.88^{+1.02}_{-0.97}$ rad. SHADE represents a new approach to diagnosing mirror misalignments from straylight patterns and can support both pre and post-launch calibration efforts and future telescope designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04659v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. Piscitelli, G. Ponti, M. Civitani, D. Spiga</dc:creator>
    </item>
    <item>
      <title>Interactive High-Performance Visualization for Astronomy and Cosmology</title>
      <link>https://arxiv.org/abs/2510.04665</link>
      <description>arXiv:2510.04665v1 Announce Type: new 
Abstract: The exponential growth of data in Astrophysics and Cosmology demands scalable computational tools and intuitive interfaces for analysis and visualization. In this work, we present an innovative integration of the VisIVO scientific visualization framework with the InterActive Computing (IAC) service at Cineca, enabling interactive, high-performance visual workflows directly within HPC environments. Through seamless integration into Jupyter-based science gateways, users can now access GPU-enabled compute nodes to perform complex 3D visualizations using VisIVO via custom Python wrappers and preconfigured interactive notebooks. We demonstrate how this infrastructure simplifies access to advanced HPC resources, enhances reproducibility, and accelerates exploratory workflows in astronomical research. Our approach has been validated through a set of representative use cases involving large-scale simulations from the GADGET code, highlighting the effectiveness of this system in visualizing the large-scale structure of the Universe. This work exemplifies how science gateways can bridge domain-specific tools and advanced infrastructures, fostering user-centric, scalable, and reproducible research environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04665v1</guid>
      <category>astro-ph.IM</category>
      <category>cs.DC</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eva Sciacca, Nicola Tuccari, Umer Arshad, Fabio Pitari, Giuseppa Muscianisi, Emiliano Tramontana</dc:creator>
    </item>
    <item>
      <title>BGRem: A background noise remover for astronomical images based on a diffusion model</title>
      <link>https://arxiv.org/abs/2510.04718</link>
      <description>arXiv:2510.04718v1 Announce Type: new 
Abstract: Context: Astronomical imaging aims to maximize signal capture while minimizing noise. Enhancing the signal-to-noise ratio directly on detectors is difficult and expensive, leading to extensive research in advanced post-processing techniques.
  Aims: Removing background noise from images is a valuable pre-processing step catalog-building tasks. We introduce BGRem, a machine learning (ML) based tool to remove background noise from astronomical images.
  Methods: BGRem uses a diffusion-based model with an attention U-Net as backbone, trained on simulated images for optical and gamma ({\gamma})-ray data from the MeerLICHT and Fermi-LAT telescopes. In a supervised manner, BGRem learns to denoise astronomical images over several diffusion steps.
  Results: BGRem performance was compared with a widely used tool for cataloging astronomical sources, SourceExtractor (SExtractor). It was shown that the amount of true positive sources using SExtractor increased by about 7% for MeerLICHT data when BGRem was used as a pre-processing step. We also show the generalizability of BGRem by testing it with optical images from different telescopes and also on simulated {\gamma}-ray data representative of the Fermi-LAT telescope. We show that in both cases, BGRem improves the source detection efficiency.
  Conclusions: BGRem can improve the accuracy in source detection of traditional pixel-based methods by removing complex background noise. Using zero-shot approach, BGRem can generalize well to a wide range of optical images. The successful application of BGRem to simulated {\gamma}-ray images, alongside optical data, demonstrates its adaptability to distinct noise characteristics and observational domains. This cross-wavelength performance highlights its potential as a general-purpose background removal framework for multi-wavelength astronomical surveys.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04718v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>R. Nicolaas, S. Caron, F. Stoppa, S. Bhattacharyya, R. Ruiz de Austri, P. J. Groot, A. J. Levan</dc:creator>
    </item>
    <item>
      <title>Galaxy Model Subtraction with a Convolutional Denoising Autoencoder</title>
      <link>https://arxiv.org/abs/2510.04957</link>
      <description>arXiv:2510.04957v1 Announce Type: new 
Abstract: Galaxy model subtraction removes the smooth light of nearby galaxies so that fainter sources (e.g., stars, star clusters, background galaxies) can be identified and measured. Traditional approaches (isophotal or parametric fitting) are semi-automated and can be challenging for large data sets. We build a convolutional denoising autoencoder (DAE) for galaxy model subtraction: images are compressed to a latent representation and reconstructed to yield the smooth galaxy, suppressing other objects. The DAE is trained on GALFIT-generated model galaxies injected into real sky backgrounds and tested on real images from the Next Generation Virgo Cluster Survey (NGVS). To quantify performance, we conduct an injection-recovery experiment on residual images by adding mock globular clusters (GCs) with known fluxes and positions. Our tests confirm a higher recovery rate of mock GCs near galaxy centers for complex morphologies, while matching ellipse fitting for smooth ellipticals. Overall, the DAE achieves subtraction equivalent to isophotal ellipse fitting for regular ellipticals and superior results for galaxies with high ellipticities or spiral features. Photometry of small-scale sources on DAE residuals is consistent with that on ellipse-subtracted residuals. Once trained, the DAE processes an image cutout in $\lesssim 0.1$ s, enabling fast, fully automatic analysis of large data sets. We make our code available for download and use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04957v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.GA</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rongrong Liu, Eric W. Peng, Kaixiang Wang, Laura Ferrarese, Patrick C\^ot\'e</dc:creator>
    </item>
    <item>
      <title>Study of Lobster and Kirkpatrick-Baez Designs for a Small Mission dedicated to Gravitational Wave Transient Localization</title>
      <link>https://arxiv.org/abs/2510.05002</link>
      <description>arXiv:2510.05002v1 Announce Type: new 
Abstract: The localization of X-ray counterparts to gravitational wave events requires a telescope with accurate localization capability in a field of view comparable to the region constrained by the gravitational wave detectors. In the context of a small, dedicated, mission, we investigate which optical design could satisfy this capability. We compare the possible optical designs that have been proposed for X-rays: the Lobster Eye design (both in the Angel and Schmidt variant) - inspired by the eyes of crustaceans - consisting of many small capillaries where grazing incidence reflection occurs, the Kirkpatrick-Baez design, where double reflection occurs on two orthogonal parabolic mirrors, and the standard Wolter-I design. We find that the first two designs, compared to the latter, can achieve a significantly larger field of view, and have a good localization capability if the focal length is longer than existing Lobster Eye designs. The Kirkpatrick-Baez design presents the best angular resolution, but the best overall field of view is obtained with a Lobster system: we present a small optical module able to achieve an effective area $&gt;$100 cm$^2$ at 1 keV in a field of view of 10 deg$^2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05002v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1117/12.3063855</arxiv:DOI>
      <arxiv:journal_reference>Proc. SPIE 13626, Optics for EUV, X-Ray, and Gamma-Ray Astronomy XII, 1362611, 2025</arxiv:journal_reference>
      <dc:creator>John Rankin, Sergio Campana, Giovanni Pareschi, Daniele Spiga, Stefano Basso, Marta Maria Civitani, Paolo Conconi, Vincenzo Cotroneo</dc:creator>
    </item>
    <item>
      <title>Large Language Models Achieve Gold Medal Performance at the International Olympiad on Astronomy &amp; Astrophysics (IOAA)</title>
      <link>https://arxiv.org/abs/2510.05016</link>
      <description>arXiv:2510.05016v2 Announce Type: new 
Abstract: While task-specific demonstrations show early success in applying large language models (LLMs) to automate some astronomical research tasks, they only provide incomplete views of all necessary capabilities in solving astronomy problems, calling for more thorough understanding of LLMs' strengths and limitations. So far, existing benchmarks and evaluations focus on simple question-answering that primarily tests astronomical knowledge and fails to evaluate the complex reasoning required for real-world research in the discipline. Here, we address this gap by systematically benchmarking five state-of-the-art LLMs on the International Olympiad on Astronomy and Astrophysics (IOAA) exams, which are designed to examine deep conceptual understanding, multi-step derivations, and multimodal analysis. With average scores of 85.6% and 84.2%, Gemini 2.5 Pro and GPT-5 (the two top-performing models) not only achieve gold medal level performance but also rank in the top two among ~200-300 participants in all four IOAA theory exams evaluated (2022-2025). In comparison, results on the data analysis exams show more divergence. GPT-5 still excels in the exams with an 88.5% average score, ranking top 10 among the participants in the four most recent IOAAs, while other models' performances drop to 48-76%. Furthermore, our in-depth error analysis underscores conceptual reasoning, geometric reasoning, and spatial visualization (52-79% accuracy) as consistent weaknesses among all LLMs. Hence, although LLMs approach peak human performance in theory exams, critical gaps must be addressed before they can serve as autonomous research agents in astronomy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05016v2</guid>
      <category>astro-ph.IM</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Carrit Delgado Pinheiro, Ziru Chen, Bruno Caixeta Piazza, Ness Shroff, Yingbin Liang, Yuan-Sen Ting, Huan Sun</dc:creator>
    </item>
    <item>
      <title>Spectral Mixture Modeling with Laboratory Near-Infrared Data I: Insights into Compositional Analysis of Europa</title>
      <link>https://arxiv.org/abs/2510.03436</link>
      <description>arXiv:2510.03436v1 Announce Type: cross 
Abstract: Europa's surface composition and physical characteristics are commonly constrained using spectral deconvolution through linear mixture (LM) modeling and radiative transfer-based (RT) intimate mixture modeling. Here, I compared the results of these two spectral modeling- LM versus RT- against laboratory spectra of water (H$_{2}$O) ice and sulfuric acid octahydrate (SAO; H$_{2}$SO$_{4}$$\cdot$8H$_{2}$O) mixtures measured at near-infrared wavelengths ($\sim$1.2-2.5 $\mu$m) with grain sizes of 90-106 $\mu$m (Hayes and Li, 2025). The modeled abundances indicate that the RT more closely reproduces the laboratory abundances, with deviations within $\pm$5% for both H$_{2}$O ice and H$_{2}$SO$_{4}$$\cdot$8H$_{2}$O with $\sim$100 $\mu$m grains. In contrast, the LM shows slightly larger discrepancies, typically ranging from $\pm$5-15% from the true abundances. Interestingly, both LM and RT tend to consistently overestimate the abundance of H$_{2}$SO$_{4}$$\cdot$8H$_{2}$O and underestimate H$_{2}$O ice across all mixtures. Nonetheless, when H$_{2}$SO$_{4}$$\cdot$8H$_{2}$O either dominates (&gt;80% as observed on Europa's trailing hemisphere; Carlson et al. 2005) or is present only in trace amounts ($\sim$10% on areas in Europa's leading hemisphere; Dalton III et al. 2013; Ligier et al. 2016), both the LM and RT render acceptable results within $\pm$10% uncertainty. Thus, spectral modeling using the RT is preferred for constraining the surface composition across Europa, although the LM remains viable in specific compositional regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03436v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Emran</dc:creator>
    </item>
    <item>
      <title>Surveying the State of Writing Education in Physics and Astronomy</title>
      <link>https://arxiv.org/abs/2510.03493</link>
      <description>arXiv:2510.03493v1 Announce Type: cross 
Abstract: Writing is a critical skill for modern science, enabling collaboration, scientific discourse, public outreach, and more. Accordingly, it is important to consider how physicists and astronomers are trained to write. This study aims to understand the landscape of science writing education, specifically in physics and astronomy, in higher education in the United States. An online survey probing various aspects of their writing training in both undergraduate and graduate school was administered to 515 participants who have obtained training in physics and/or astronomy, or related fields, at the level equal to or beyond upper-division undergraduate study. Humanities and writing requirement courses appear to have a key role in general writing education, while laboratory courses and feedback from mentors are the dominant modes of science writing education in undergraduate and graduate school respectively. There is substantial variation in the quality of writing education in physics and astronomy, often dependent on the student's institution and/or mentor. Some participants also report that their success in disciplinary writing was a result of a solid foundation from K-12 education and/or self-direction towards resources; such reliance on past experiences and student background may contribute to inequality in the field. Many participants also stated a clear desire for more structured writing training to be available in the field. We provide suggestions for how to implement such training to meet the needs of the community identified in the survey.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03493v1</guid>
      <category>physics.ed-ph</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Briley L. Lewis</dc:creator>
    </item>
    <item>
      <title>Cosmological Hydrodynamics at Exascale: A Trillion-Particle Leap in Capability</title>
      <link>https://arxiv.org/abs/2510.03557</link>
      <description>arXiv:2510.03557v1 Announce Type: cross 
Abstract: Resolving the most fundamental questions in cosmology requires simulations that match the scale, fidelity, and physical complexity demanded by next-generation sky surveys. To achieve the realism needed for this critical scientific partnership, detailed gas dynamics, along with a host of astrophysical effects, must be treated self-consistently with gravity for end-to-end modeling of structure formation. As an important step on this roadmap, exascale computing enables simulations that span survey-scale volumes while incorporating key subgrid processes that shape complex cosmic structures. We present results from CRK-HACC, a cosmological hydrodynamics code built for the extreme scalability requirements set by modern cosmological surveys. Using separation-of-scale techniques, GPU-resident tree solvers, in situ analysis pipelines, and multi-tiered I/O, CRK-HACC executed Frontier-E: a four trillion particle full-sky simulation, over an order of magnitude larger than previous efforts. The run achieved 513.1 PFLOPs peak performance, processing 46.6 billion particles per second and writing more than 100 PB of data in just over one week of runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03557v1</guid>
      <category>cs.DC</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <category>cs.PF</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Frontiere, J. D. Emberson, Michael Buehlmann, Esteban M. Rangel, Salman Habib, Katrin Heitmann, Patricia Larsen, Vitali Morozov, Adrian Pope, Claude-Andr\'e Faucher-Gigu\`ere, Antigoni Georgiadou, Damien Lebrun-Grandi\'e, Andrey Prokopenko</dc:creator>
    </item>
    <item>
      <title>Fisher-Bingham-like normalizing flows on the sphere</title>
      <link>https://arxiv.org/abs/2510.04762</link>
      <description>arXiv:2510.04762v1 Announce Type: cross 
Abstract: A generic D-dimensional Gaussian can be conditioned or projected onto the D-1 unit sphere, thereby leading to the well-known Fisher-Bingham (FB) or Angular Gaussian (AG) distribution families, respectively. These are some of the most fundamental distributions on the sphere, yet cannot straightforwardly be written as a normalizing flow except in two special cases: the von-Mises Fisher in D=3 and the central angular Gaussian in any D. In this paper, we describe how to generalize these special cases to a family of normalizing flows that behave similarly to the full FB or AG family in any D. We call them "zoom-linear-project" (ZLP)-Fisher flows. Unlike a normal Fisher-Bingham distribution, their composition allows to gradually add complexity as needed. Furthermore, they can naturally handle conditional density estimation with target distributions that vary by orders of magnitude in scale - a setting that is important in astronomical applications but that existing flows often struggle with. A particularly useful member of the new family is the Kent analogue that can cheaply upgrade any flow in this situation to yield better performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04762v1</guid>
      <category>stat.ML</category>
      <category>astro-ph.IM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thorsten Gl\"usenkamp</dc:creator>
    </item>
    <item>
      <title>Joint eROSITA and H.E.S.S. analysis of MSH 15-52 using Gammapy</title>
      <link>https://arxiv.org/abs/2510.04857</link>
      <description>arXiv:2510.04857v1 Announce Type: cross 
Abstract: Pulsar wind nebulae (PWNe) are prominent sources in the very-high energy (VHE) gamma-ray sky, constituting the most numerous identified source class in the H.E.S.S. Galactic Plane Survey (HGPS). They are comprised of energetic particles originating from the pulsar and expanding into the surrounding medium. As such, PWNe are of very high scientific interest as PeVatron candidates, objects that could potentially accelerate particles up to PeV energies. Additionally other aspects of their acceleration mechanism are being actively investigated, such as the open question of whether they accelerate not only leptonic but also hadronic particles, and the details of their morphology and particle transport mechanism. As PWNe emit photons over a broad range of the electromagnetic spectrum, multiwavelength (MWL) studies are crucial for the investigation and study of their emission.
  In this vein we present a joint eROSITA X-ray and H.E.S.S. gamma-ray study of the PWN MSH 15-52. We showcase our custom code for integrating the EDR and DR1 eROSITA data into the Gammapy framework, a python package optimised for the analysis of gamma-ray data. We present the first 3D (spatial and spectral) fit to eROSITA data by using Gammapy. We furthermore combine these data with the public H.E.S.S. gamma-ray observations of MSH 15-52, resulting in a joint physical fit of the underlying particle population, and a subsequent discussion of the physical implications of our results. Finally we give an outlook towards future efforts in MWL studies of PWNe and the broader context of MWL data analysis with Gammapy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04857v1</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.22323/1.501.0637</arxiv:DOI>
      <arxiv:journal_reference>PoS(ICRC2025)637</arxiv:journal_reference>
      <dc:creator>Katharina Egg, Alison M. W. Mitchell</dc:creator>
    </item>
    <item>
      <title>Chroma+ model stellar surface intensities: Spherical formal solution</title>
      <link>https://arxiv.org/abs/2510.05035</link>
      <description>arXiv:2510.05035v2 Announce Type: cross 
Abstract: We announce V. 2025-08-08 of the Chroma+ suite of stellar atmosphere and spectrum modelling codes for fast, approximate, effectively platform-independent stellar spectrum synthesis, written in a number of free well-supported programming languages. The Chroma+ suite now computes the emergent surface intensity and flux distributions and the hydrostatic pressure structure assuming a spherical atmosphere rather than local flatness by implementing the analytic formal solution of the 1D spherical radiative transfer equation of Chapman (1966} based on an integration factor. We present our adaptation and discretization of the solution and demonstrate the resulting impact of our sphericity treatment on a number of computed observables, including exo-planet transit light-curves. All codes are available from the OpenStars www site: www.ap.smu.ca/OpenStars.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05035v2</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C. Ian Short</dc:creator>
    </item>
    <item>
      <title>The CCOR Compact Coronagraphs for the Geostationary Operational Environmental Satellite-19 (GOES-19) and the Space Weather Follow On (SWFO) Missions</title>
      <link>https://arxiv.org/abs/2508.13467</link>
      <description>arXiv:2508.13467v2 Announce Type: replace 
Abstract: The CCOR Compact Coronagraph is a series of two operational solar coronagraphs sponsored by the National Oceanic and Atmospheric Administration (NOAA). They were designed, built, and tested by the U.S. Naval Research Laboratory (NRL). The CCORs will be used by NOAA's Space Weather Prediction Center to detect and track Coronal Mass Ejections (CMEs) and predict the Space Weather. CCOR-1 is on board the Geostationary Operational Environmental Satellite -U (GOES-U, now GOES-19/GOES-East). GOES-U was launched from Kennedy Space Flight Center, Florida, on 25 June 2024. CCOR-2 is on board the Space Weather Follow On at Lagrange point 1 (SWFO-L1). SWFO-L1 is scheduled to launch in the fall of 2025. SWFO will be renamed SOLAR-1 once it reaches L1. The CCORs are white-light coronagraphs that have a field of view and performance similar to the SOHO LASCO C3 coronagraph. CCOR-1 FOV spans from 4 to 22 Rsun, while CCOR-2 spans from 3.5 to 26 Rsun. The spatial resolution is 39 arcsec for CCOR-1 and 65 arcsec for CCOR-2. They both operate in a band-pass of 470 - 740 nm. The synoptic cadence is 15 min and the latency from image capture to the forecaster on the ground is less than 30 min. Compared to past generation coronagraphs such as the Large Angle and Spectrometric Coronagraph (LASCO), CCOR uses a compact design; all the solar occultation is done with a single multi-disk external occulter. No internal occulter is used. This allowed a substantial reduction in size and mass compared to SECCHI COR-2, for example, but with slightly lower signal-to-noise ratio. In this article, we review the science that the CCORs will capitalize on for the purpose of operational space weather prediction. We give a description of the driving requirements and accommodations, and provide details on the instrument design. In the end, information on ground processing and data levels is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13467v2</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>A. F. Thernisien, D. H. Chua, M. T. Carter, N. B. Rich, M. Noya, T. A. Babich, C. E. Crippa, B. Baugh, Y. Bordlemay, D. Socker, D. Biesecker, C. Korendyke, D. Wang, D. Vassiliadis, N-Y. Wang, S. Abbay, S. Bagnall, L. Balmaceda, S. Brown, J. Bonafede, D. Boyer, J. Declet, P. Cheng, K. Corsi, L. Cremerius, I. Chavis, J. Chiralo, G. Clifford, J. Dancheck, J. Davis, G. Dima, R. Dudley, D. Gardner, L. Gardner, B. Hagood, R. Hagood, B. Hohl, T. Hunt, F. Jenkins, J. M. Johnson, M. Koehler, N. Kuroda, A. Lanagan, S. Laut, B. Lynch, T. Mallory, D. Mechel, N. D. Miles, A. Miranda, M. Newman, B. Nguyen, M. Ogindo, K. Pellak, R. Podgurski, T. Ragan, V. Richards, D. Silver, J. Simmons, D. J. Schmit, L. Smith, J. Spitzak, S. K. Tadikonda, S. Tanner, D. Uhl, J. Verzosa, P. Walker, G. Wiggins, E. Williams, C. Wilson, D. Zurcher</dc:creator>
    </item>
    <item>
      <title>A long period transient search method for the Murchison Widefield Array</title>
      <link>https://arxiv.org/abs/2509.06315</link>
      <description>arXiv:2509.06315v2 Announce Type: replace 
Abstract: We present an automated search method for radio transients on the minute timescale focused on the emerging long period transients (LPTs) in image-plane radio data. The method is tuned for use with the Murchison Widefield Array (MWA) and tested on archival observations from the GaLactic and Extragalactic All-Sky MWA Extended Survey (GLEAM-X) in the 70--300 MHz range. The images are formed from model-subtracted visibilities, before applying three filters to the time series of each pixel in an image, with each filter designed to be sensitive to a different transient behaviour. Due to the nature of radio interferometry and the refraction of the fluctuating ionosphere, the vast majority of candidates at this stage are artefacts which we identify and remove using a set of flagging measures. Of the 336 final candidates, 7 were genuine transients; 1 new LPT, 1 new pulsar, and 5 known pulsars. The performance of the method is analysed by injecting modelled transient pulses into a subset of the observations and applying the method to the result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06315v2</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1017/pasa.2025.10093</arxiv:DOI>
      <arxiv:journal_reference>Publications of the Astronomical Society of Australia 42 (2025) e129</arxiv:journal_reference>
      <dc:creator>Csan\'ad Horv\'ath, Natasha Hurley-Walker, Samuel J. McSweeney, Timothy J. Galvin, John Morgan</dc:creator>
    </item>
    <item>
      <title>CWT-LSTM Autoencoder: A Novel Approach for Gravitational Wave Detection in LIGO Data</title>
      <link>https://arxiv.org/abs/2509.10505</link>
      <description>arXiv:2509.10505v4 Announce Type: replace 
Abstract: Gravitational wave detection requires sophisticated signal processing to identify weak astrophysical signals buried in instrumental noise. Traditional matched filtering approaches face computational challenges with diverse signal morphologies and non-stationary noise. This work presents a deep learning methodology integrating Continuous Wavelet Transform (CWT) preprocessing with Long Short-Term Memory (LSTM) autoencoder architecture for gravitational wave detection. The CWT provides optimal time-frequency decomposition capturing chirp evolution and transient characteristics essential for compact binary coalescence identification. We first develop the model using synthetic datasets incorporating binary black hole merger signals with masses ranging from 10 to 80 solar masses. These signals are then embedded in colored Gaussian noise representative of Advanced LIGO sensitivity. The trained model demonstrates strong performance metrics. We then apply the CWT-LSTM model to gravitational wave data from multiple LIGO observing runs. We use 1639 clean noise samples for training the anomaly detection model, while the test dataset contained a mix of 114 confirmed gravitational wave events and 410 noise samples. The model demonstrates strong performance with an AUC of 1.000 and Average Precision (AP) of 1.000, achieving a precision of 1.0 at the optimal threshold with a recall of 1.0. The reconstruction error distribution shows clear separation between noise and gravitational wave signals, with noise samples clustering around lower reconstruction error values and signals around higher reconstruction error values. This unsupervised approach enables discovery of signals with unknown morphologies that could provide complementary "blind search" capability for detecting exotic astrophysical sources and novel physics beyond current theoretical models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10505v4</guid>
      <category>astro-ph.IM</category>
      <category>gr-qc</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jericho Cain</dc:creator>
    </item>
    <item>
      <title>Interpreting deep learning-based stellar mass estimation via causal analysis and mutual information decomposition</title>
      <link>https://arxiv.org/abs/2509.23901</link>
      <description>arXiv:2509.23901v2 Announce Type: replace 
Abstract: End-to-end deep learning models fed with multi-band galaxy images are powerful data-driven tools used to estimate galaxy physical properties in the absence of spectroscopy. However, due to a lack of interpretability and the associational nature of such models, it is difficult to understand how the information that is included in addition to integrated photometry (e.g., morphology) contributes to the estimation task. Improving our understanding in this field would enable further advances into unraveling the physical connections among galaxy properties and optimizing data exploitation. Therefore, our work is aimed at interpreting the deep learning-based estimation of stellar mass via two interpretability techniques: causal analysis and mutual information decomposition. The former reveals the causal paths between multiple variables beyond nondirectional statistical associations, while the latter quantifies the multicomponent contributions (i.e., redundant, unique, and synergistic) of different input data to the stellar mass estimation. Using data from the Sloan Digital Sky Survey (SDSS) and the Wide-field Infrared Survey Explorer (WISE), we obtained meaningful results that provide physical interpretations for image-based models. Our work demonstrates the gains from combining deep learning with interpretability techniques, and holds promise in promoting more data-driven astrophysical research (e.g., astrophysical parameter estimations and investigations on complex multivariate physical processes).</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23901v2</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.GA</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Zhang, Qiufan Lin, Yuan-Sen Ting, Shupei Chen, Hengxin Ruan, Song Li, Yifan Wang</dc:creator>
    </item>
    <item>
      <title>Identifying and Mitigating Machine Learning Biases for the Gravitational Wave Detection Problem</title>
      <link>https://arxiv.org/abs/2501.13846</link>
      <description>arXiv:2501.13846v2 Announce Type: replace-cross 
Abstract: Matched filtering is a long-standing technique for the optimal detection of known signals in stationary Gaussian noise. However, it has known departures from optimality when operating on unknown signals in real noise and suffers from computational inefficiencies in its pursuit of near-optimality. A compelling alternative that has emerged in recent years to address this problem is deep learning. Although it has shown significant promise when applied to the search for gravitational waves (GWs) in detector noise, we demonstrate the existence of learning biases that hinder generalisation and lead to significant loss in detection sensitivity. Our work identifies the sources of a set of 11 interconnected biases present in the supervised learning of the GW detection problem and contributes mitigation tactics and training strategies to concurrently address them. In light of the identified biases, we demonstrate that existing detection sensitivity metrics are not reliable for machine-learning (ML) pipelines and discuss the trustworthiness of previous results. We use GW domain knowledge to build a bespoke ML based binary black hole search pipeline called Sage that addresses these biases. Via the injection study presented in the Machine Learning Gravitational-Wave Search Challenge, we show that Sage detects ~11.2% more signals than the benchmark PyCBC analysis at a false alarm rate of one per month in O3a noise. Moreover, we also show that it can detect ~48.29% more signals than the previous best-performing ML pipeline on the same dataset. We empirically prove that Sage can: [i] effectively handle out-of-distribution noise power spectral densities, [ii] strongly reject non-Gaussian transient noise artefacts, and [iii] achieve higher detection sensitivities using less data than network architectures of a similar size. All code and implementations are available at https://github.com/nnarenraju/sage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13846v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/zwj9-ycyz</arxiv:DOI>
      <dc:creator>Narenraju Nagarajan, Christopher Messenger</dc:creator>
    </item>
    <item>
      <title>J-PLUS: Spectroscopic validation of H$\alpha$ emission line maps in spatially resolved galaxies</title>
      <link>https://arxiv.org/abs/2502.05830</link>
      <description>arXiv:2502.05830v2 Announce Type: replace-cross 
Abstract: We present a dedicated automated pipeline to construct spatially resolved emission H$\alpha$+[NII] maps and to derive the spectral energy distributions (SEDs) in 12 optical filters (five broad and seven narrow/medium) of H$\alpha$ emission line regions in nearby galaxies (z $&lt;$ 0.0165) observed by the Javalambre Photometric Local Universe Survey (J-PLUS). We used the $J0660$ filter of $140${\AA} width centered at $6600${\AA} to trace H$\alpha$ + [NII] emission and $r$ and $i$ broad bands were used to estimate the stellar continuum. We create pure emission line images after the continnum subtraction, where the H$\alpha$ emission line regions were detected. This method was also applied to Integral Field Unit (IFU) spectroscopic data from PHANGS-MUSE, CALIFA and MaNGA surveys by building synthetic narrow-bands based on J-PLUS filters. The studied sample includes the cross-matched catalog of these IFU surveys with J-PLUS third data release (DR3), amounting to $2$ PHANGS-MUSE, $78$ CALIFA, and $78$ MaNGA galaxies at $z &lt; 0.0165$, respectively. We compared the H$\alpha$+[NII] radial profiles from J-PLUS and the IFU surveys, finding good agreement within the expected uncertainties. We also compared the SEDs from the emission line regions detected in J-PLUS images, reproducing the main spectral features present in the spectroscopic data. Finally, we compared the emission fluxes from the J-PLUS and IFU surveys accounting for scale differences, finding a difference of only 2% with a dispersion of 7% in the measurements. The J-PLUS data provides reliable spatially resolved H$\alpha$+[NII] emission maps for nearby galaxies. We provide the J-PLUS DR3 catalog for the $158$ galaxies with IFU data, including emission maps, SEDs of star-forming clumps, and radial profiles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05830v2</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1051/0004-6361/202453633</arxiv:DOI>
      <arxiv:journal_reference>A&amp;A 695, A200 (2025)</arxiv:journal_reference>
      <dc:creator>P. T. Rahna, M. Akhlaghi, C. L\'opez-Sanjuan, R. Logro\~no-Garc\'ia, D. J. Muniesa, H. Dom\'inguez-S\'anchez, J. A. Fern\'andez-Ontiveros, David Sobral, A. Lumbreras-Calle, A. L. Chies-Santos, J. E. Rodr\'iguez-Mart\'in, S. Eskandarlou, A. Ederoclite, A. Alvarez-Candal, H. V\'azquez Rami\'o, A. J. Cenarro, A. Mar\'in-Franch, J. Alcaniz, R. E. Angulo, D. Crist\'obal-Hornillos, R. A. Dupke, C. Hern\'andez-Monteagudo, M. Moles, L. Sodr\'e Jr., J. Varela</dc:creator>
    </item>
    <item>
      <title>Map-level baryonification: unified treatment of weak lensing two-point and higher-order statistics</title>
      <link>https://arxiv.org/abs/2505.07949</link>
      <description>arXiv:2505.07949v2 Announce Type: replace-cross 
Abstract: Precision cosmology benefits from extracting maximal information from cosmic structures, motivating the use of higher-order statistics (HOS) at small spatial scales. However, predicting how baryonic processes modify matter statistics at these scales has been challenging. The baryonic correction model (BCM) addresses this by modifying dark-matter-only simulations to mimic baryonic effects, providing a flexible, simulation-based framework for predicting both two-point and HOS. We show that a 3-parameter version of the BCM can jointly fit weak lensing maps' two-point statistics, wavelet phase harmonics coefficients, scattering coefficients, and the third and fourth moments to within 2% accuracy across all scales $\ell &lt; 2000$ and tomographic bins for a DES-Y3-like redshift distribution ($z \lesssim 2$), using the FLAMINGO simulations. These results demonstrate the viability of BCM-assisted, simulation-based weak lensing inference of two-point and HOS, paving the way for robust cosmological constraints that fully exploit non-Gaussian information on small spatial scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07949v2</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1475-7516/2025/09/073</arxiv:DOI>
      <arxiv:journal_reference>JCAP09(2025)073</arxiv:journal_reference>
      <dc:creator>Alan Junzhe Zhou, Marco Gatti, Dhayaa Anbajagane, Scott Dodelson, Matthieu Schaller, Joop Schaye</dc:creator>
    </item>
    <item>
      <title>Comparative Analysis of Richardson-Lucy Deconvolution and Data Unfolding with Mean Integrated Square Error Optimization</title>
      <link>https://arxiv.org/abs/2505.10283</link>
      <description>arXiv:2505.10283v3 Announce Type: replace-cross 
Abstract: Two maximum likelihood-based algorithms for unfolding or deconvolution are considered: the Richardson-Lucy method and the Data Unfolding method with Mean Integrated Square Error (MISE) optimization [10]. Unfolding is viewed as a procedure for estimating an unknown probability density function. Both external and internal quality assessment methods can be applied for this purpose. In some cases, external criteria exist to evaluate deconvolution quality. A typical example is the deconvolution of a blurred image, where the sharpness of the restored image serves as an indicator of quality. However, defining such external criteria can be challenging, particularly when a measurement has not been performed previously. In such instances, internal criteria are necessary to assess the quality of the result independently of external information. The article discusses two internal criteria: MISE for the unfolded distribution and the condition number of the correlation matrix of the unfolded distribution. These internal quality criteria are applied to a comparative analysis of the two methods using identical numerical data. The results of the analysis demonstrate the superiority of the Data Unfolding method with MISE optimization over the Richardson-Lucy method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10283v3</guid>
      <category>physics.data-an</category>
      <category>astro-ph.IM</category>
      <category>hep-ex</category>
      <category>nucl-ex</category>
      <category>stat.AP</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolay D. Gagunashvili</dc:creator>
    </item>
    <item>
      <title>Performance of multiple filter-cavity schemes for frequency-dependent squeezing in gravitational-wave detectors</title>
      <link>https://arxiv.org/abs/2506.02222</link>
      <description>arXiv:2506.02222v2 Announce Type: replace-cross 
Abstract: Gravitational-wave detectors use state-of-the-art quantum technologies to reduce the noise induced by vacuum fluctuations, via injection of squeezed states of light. Future detectors, such as Einstein Telescope, may require the use of two filter cavities or a 3-mirror coupled filter cavity to achieve a complex rotation of the squeezing ellipse, in order to reduce the quantum noise over the whole detector bandwidth. In this work, we compare the theoretical feasibility and performances of these two optical layouts and their resilience with respect to different degradation sources (optical losses, mismatching, locking precision), analytically and numerically. We extend previous analysis on squeezing degradation and find that the coupled cavity scheme provides similar or better performances than the two-cavity option, in terms of resilience with respect to imperfections and optical losses. We further highlight the role of mode-mismatch phases in limiting squeezing. Finally, we propose a possible two-step implementation scheme for Einstein Telescope using a single filter cavity that can be possibly upgraded into a coupled filter cavity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02222v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <category>physics.optics</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jacques Ding, Eleonora Capocasa, Isander Ahrend, Fangfei Liu, Yuhang Zhao, Matteo Barsuglia</dc:creator>
    </item>
    <item>
      <title>Machine-learning inference of stellar properties using integrated photometric and spectroscopic data</title>
      <link>https://arxiv.org/abs/2507.10666</link>
      <description>arXiv:2507.10666v2 Announce Type: replace-cross 
Abstract: Stellar astrophysics relies on diverse observational modalities-primarily photometric light curves and spectroscopic data from which fundamental stellar properties are inferred. While machine learning (ML) has advanced analysis within individual modalities, the complementary information encoded across modalities remains largely underexploited. We present DESA (Dual Embedding model for Stellar Astrophysics), a novel multi-modal foundation model that integrates light curves and spectra to learn a unified, physically meaningful latent space for stars. DESA first trains separate modality-specific encoders using a hybrid supervised/self-supervised scheme, and then aligns them through DualFormer, a Transformer-based cross-modal integration module tailored for astrophysical data. DualFormer combines cross- and self-attention, a novel dual-projection alignment loss, and a projection-space eigendecomposition that yields physically structured embeddings. We demonstrate that DESA significantly outperforms leading unimodal and self-supervised baselines across a range of tasks. In zero- and few-shot settings, DESA's learned representations recover stellar color-magnitude and Hertzsprung-Russell diagrams with high fidelity ($R^2 = 0.92$ for photometric regressions). In full fine-tuning, DESA achieves state-of-the-art accuracy for binary star detection (AUC = $0.99$, AP = $1.00$) and stellar age prediction (RMSE = $0.94$ Gyr). As a compelling case, DESA naturally separates synchronized binaries from young stars, two populations with nearly identical light curves, purely from their embedded positions in UMAP space, without requiring external kinematic or luminosity information. DESA thus offers a powerful new framework for multimodal, data-driven stellar population analysis, enabling both accurate prediction and novel discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10666v2</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ilay Kamai, Alex M. Bronstein, Hagai B. Perets</dc:creator>
    </item>
    <item>
      <title>The Roman Space Telescope as a Planetary Defense Asset</title>
      <link>https://arxiv.org/abs/2508.14412</link>
      <description>arXiv:2508.14412v2 Announce Type: replace-cross 
Abstract: NASA's Nancy Grace Roman Space Telescope, slated to launch in October 2026, will serve a critical role in the characterization and threat assessment of near-Earth Objects (NEOs), thus contributing to national and international planetary defense objectives. Operating from the Earth-Sun L2 point and observing in the near-infrared, Roman has the high sensitivity and high spatial resolution needed to measure the physical properties, compositions, and orbital trajectories of NEOs in order to understand their physical nature and potential hazards to Earth. Roman's planetary defense capabilities complement those of two wide-field survey missions: the now operational ground-based Vera C. Rubin Observatory's Legacy Survey of Space and Time and the upcoming space-based NEO Surveyor. Rubin, observing in visible light, will discover over 100,000 NEOs. NEO Surveyor, observing in the mid-infrared where NEO thermal emission peaks, will detect 200,000-300,000 NEOs, some as small as ~20 meters in diameter. With investment in developing the pipeline infrastructure required to extract information from moving target streaks, Roman will be able to observe NEOs down to the smallest sizes in order to improve our measurements of NEO orbits by 2-3 orders of magnitude, enable accurate diameter and albedo estimates in conjunction with NEO Surveyor, and reveal the spectral types and bulk compositions of the smallest NEOs. Together, these three US-led facilities will operate across the electromagnetic spectrum to form a comprehensive planetary defense network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14412v2</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bryan J. Holler, Richard G. Cosentino, William C. Schultz, Timothy D. Brandt, Joseph R. Masiero, Benjamin N. L. Sharkey, Pedro H. Bernardinelli, Carrie E. Holt</dc:creator>
    </item>
    <item>
      <title>Estimating the Local Hubble Parameter from the Thermal Evolution of Earth and Mars</title>
      <link>https://arxiv.org/abs/2508.16694</link>
      <description>arXiv:2508.16694v2 Announce Type: replace-cross 
Abstract: The problem of local (e.g., interplanetary) Hubble expansion is studied for a long time but remains a controversial subject till now; and of particular interest is a plausible value of the local Hubble parameter at the scale of the Solar system. Here, we tried to estimate the corresponding quantity by the analysis of surface temperatures on the Earth and Mars, which are formed by a competition between a variable luminosity of the Sun and increasing radii of the planetary orbits. Our work employs paleochemical and paleobiological data on the temperature of the ancient Earth, on the one hand, and geological data on the existence of an ocean of liquid water on the ancient Mars, on the other hand. As follows from our analysis, the martian data impose only a weak constraint on the admissible values of the Hubble parameter because of the unknown salinity - and, therefore, the freezing point - of the martian water. On the other hand, the terrestrial data turn out to be much more valuable, especially, for the Precambrian period, when temperature variation was sufficiently smooth and monotonic. For example, in the framework of standard LambdaCDM model with 70% of dark energy, contemporary value of the local Hubble parameter was found to be 70-90 km/s/Mpc under assumption that the Earth's surface temperature in the end of Precambrian equaled 45 C. This is in reasonable agreement both with the intergalactic data and with an independent estimate of the local Hubble parameter from tidal evolution of the Earth-Moon system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16694v2</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yurii V. Dumin, Elizaveta G. Khramova, Ludmila M. Svirskaya, Eugen S. Savinykh</dc:creator>
    </item>
    <item>
      <title>Advanced Weights for IXPE Polarization Analysis</title>
      <link>https://arxiv.org/abs/2509.07981</link>
      <description>arXiv:2509.07981v2 Announce Type: replace-cross 
Abstract: As the Imaging X-ray Polarimetry Explorer (IXPE) measures increasingly faint sources, the need for precise polarimetry extraction becomes paramount. In addition to previously described neural-net (NN) weights, we introduce here point-spread function weights and particle background weights, which can be critical for faint sources. In some cases these can be augmented by time/phase and energy weights. We provide a publicly available analysis tool to incorporate these new weights, validate our method on simulated data, and test it on archival IXPE observations. Together these weights decrease the area of the polarization uncertainty contour by a factor of two compared to baseline IXPE analysis and will be essential for background-limited IXPE observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07981v2</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jack T. Dinsmore, Roger W. Romani</dc:creator>
    </item>
    <item>
      <title>Bayesian Gaussian Methods for Robust Background Modeling in CALorimetric Electron Telescope (CALET) Gravitational-Wave Searches</title>
      <link>https://arxiv.org/abs/2509.25893</link>
      <description>arXiv:2509.25893v2 Announce Type: replace-cross 
Abstract: The search for gamma-ray counterparts to gravitational-wave events with the CALET Gamma-ray Burst Monitor (CGBM) requires accurate and robust background modeling. Previous CALET observing runs (O3 and O4) relied on averaged pre/post-event baselines or low-order polynomial fits, approaches that neglect correlated noise, temporal non-stationarity, and the propagation of background uncertainty into derived flux upper limits. These simplifications can lead to reduced sensitivity to faint or atypical transients. In this work, we present a novel Bayesian framework for background estimation based on Gaussian Process (GP) regression and change-point modeling. Our approach captures correlated structures in the detector background, quantifies predictive uncertainties, and propagates them into both detection statistics and Bayesian credible upper limits. We demonstrate, using archival CALET time-tagged event data and simulated signal injections, that our method improves sensitivity to weak short-duration bursts by up to an order of magnitude compared to traditional polynomial fits. This probabilistic background treatment enables a more physically robust interpretation of non-detections and offers a scalable, real-time compatible extension for future joint multi-messenger searches. All codes used in this paper are available at https://github.com/SMALLSCALEDEV/Bayesian-Gaussian-Approach-for-Background-Estimation-in-CALET-GW.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25893v2</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bisweswar Sen</dc:creator>
    </item>
  </channel>
</rss>
