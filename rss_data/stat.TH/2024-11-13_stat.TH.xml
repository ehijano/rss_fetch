<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 13 Nov 2024 05:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Testing LRD in the spectral domain for functional time series in manifolds</title>
      <link>https://arxiv.org/abs/2411.07731</link>
      <description>arXiv:2411.07731v1 Announce Type: new 
Abstract: A statistical hypothesis test for long range dependence (LRD) in manifold-supported functional time series is formulated in the spectral domain. The proposed test statistic operator is based on the weighted periodogram operator. It is assumed that the elements of the spectral density operator family are invariant with respect to the group of isometries of the manifold. A Central Limit Theorem is derived to obtain the asymptotic Gaussian distribution of the proposed test statistics operator under the null hypothesis. The rate of convergence to zero, in the Hilbert--Schmidt operator norm, of the bias of the integrated empirical second and fourth order cumulant spectral density operators is established under the alternative hypothesis. The consistency of the test is derived, from the consistency, in the sense of the integrated mean square error, of the weighted periodogram operator under LRD. Our proposal to implement, in practice, the testing approach is based on the temporal-frequency-varying Karhunen-Lo\'eve expansion obtained here for invariant random Hilbert-Schmidt kernels on manifolds. A simulation study illustrates the main results regarding asymptotic normality and consistency, and the empirical size and power properties of the proposed testing approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07731v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. D. Ruiz-Medina, R. M. Crujeiras</dc:creator>
    </item>
    <item>
      <title>Exogenous Randomness Empowering Random Forests</title>
      <link>https://arxiv.org/abs/2411.07554</link>
      <description>arXiv:2411.07554v1 Announce Type: cross 
Abstract: We offer theoretical and empirical insights into the impact of exogenous randomness on the effectiveness of random forests with tree-building rules independent of training data. We formally introduce the concept of exogenous randomness and identify two types of commonly existing randomness: Type I from feature subsampling, and Type II from tie-breaking in tree-building processes. We develop non-asymptotic expansions for the mean squared error (MSE) for both individual trees and forests and establish sufficient and necessary conditions for their consistency. In the special example of the linear regression model with independent features, our MSE expansions are more explicit, providing more understanding of the random forests' mechanisms. It also allows us to derive an upper bound on the MSE with explicit consistency rates for trees and forests. Guided by our theoretical findings, we conduct simulations to further explore how exogenous randomness enhances random forest performance. Our findings unveil that feature subsampling reduces both the bias and variance of random forests compared to individual trees, serving as an adaptive mechanism to balance bias and variance. Furthermore, our results reveal an intriguing phenomenon: the presence of noise features can act as a "blessing" in enhancing the performance of random forests thanks to feature subsampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07554v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianxing Mei, Yingying Fan, Jinchi Lv</dc:creator>
    </item>
    <item>
      <title>Discrete-Valued Signal Estimation via Low-Complexity Message Passing Algorithm for Highly Correlated Measurements</title>
      <link>https://arxiv.org/abs/2411.07558</link>
      <description>arXiv:2411.07558v1 Announce Type: cross 
Abstract: This paper considers a discrete-valued signal estimation scheme based on a low-complexity Bayesian optimal message passing algorithm (MPA) for solving massive linear inverse problems under highly correlated measurements. Gaussian belief propagation (GaBP) can be derived by applying the central limit theorem (CLT)-based Gaussian approximation to the sum-product algorithm (SPA) operating on a dense factor graph (FG), while matched filter (MF)-expectation propagation (EP) can be obtained based on the EP framework tailored for the same FG. Generalized approximate message passing (GAMP) can be found by applying a rigorous approximation technique for both of them in the large-system limit, and these three MPAs perform signal detection using MF by assuming large-scale uncorrelated observations. However, each of them has a different inherent self-noise suppression mechanism, which makes a significant difference in the robustness against the correlation of the observations when we apply an annealed discrete denoiser (ADD) that adaptively controls its nonlinearity with the inverse temperature parameter corresponding to the number of iterations. In this paper, we unravel the mechanism of this interesting phenomenon, and further demonstrate the practical applicability of the low-complexity Bayesian optimal MPA with ADD under highly correlated measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07558v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomoharu Furudoi, Takumi Takahashi, Shinsuke Ibi, Hideki Ochiai</dc:creator>
    </item>
    <item>
      <title>Changepoint Detection in Complex Models: Cross-Fitting Is Needed</title>
      <link>https://arxiv.org/abs/2411.07874</link>
      <description>arXiv:2411.07874v1 Announce Type: cross 
Abstract: Changepoint detection is commonly approached by minimizing the sum of in-sample losses to quantify the model's overall fit across distinct data segments. However, we observe that flexible modeling techniques, particularly those involving hyperparameter tuning or model selection, often lead to inaccurate changepoint estimation due to biases that distort the target of in-sample loss minimization. To mitigate this issue, we propose a novel cross-fitting methodology that incorporates out-of-sample loss evaluations using independent samples separate from those used for model fitting. This approach ensures consistent changepoint estimation, contingent solely upon the models' predictive accuracy across nearly homogeneous data segments. Extensive numerical experiments demonstrate that our proposed cross-fitting strategy significantly enhances the reliability and adaptability of changepoint detection in complex scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07874v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengde Qian, Guanghui Wang, Zhaojun Wang, Changliang Zou</dc:creator>
    </item>
    <item>
      <title>Bernstein-type and Bennett-type inequalities for unbounded matrix martingales</title>
      <link>https://arxiv.org/abs/2411.07878</link>
      <description>arXiv:2411.07878v1 Announce Type: cross 
Abstract: We derive explicit Bernstein-type and Bennett-type concentration inequalities for matrix-valued supermartingale processes with unbounded observations. Specifically, we assume that the $\psi_{\alpha}$-Orlicz (quasi-)norms of their difference process are bounded for some $\alpha &gt; 0$. As corollaries, we prove an empirical version of Bernstein's inequality and an extension of the bounded differences inequality, also known as McDiarmid's inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07878v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexey Kroshnin, Alexandra Suvorikova</dc:creator>
    </item>
    <item>
      <title>Doubly Robust Regression Discontinuity Designs</title>
      <link>https://arxiv.org/abs/2411.07978</link>
      <description>arXiv:2411.07978v1 Announce Type: cross 
Abstract: This study introduces a doubly robust (DR) estimator for regression discontinuity (RD) designs. In RD designs, treatment effects are estimated in a quasi-experimental setting where treatment assignment depends on whether a running variable surpasses a predefined cutoff. A common approach in RD estimation is to apply nonparametric regression methods, such as local linear regression. In such an approach, the validity relies heavily on the consistency of nonparametric estimators and is limited by the nonparametric convergence rate, thereby preventing $\sqrt{n}$-consistency. To address these issues, we propose the DR-RD estimator, which combines two distinct estimators for the conditional expected outcomes. If either of these estimators is consistent, the treatment effect estimator remains consistent. Furthermore, due to the debiasing effect, our proposed estimator achieves $\sqrt{n}$-consistency if both regression estimators satisfy certain mild conditions, which also simplifies statistical inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07978v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>The geometry of Gaussian double Markovian distributions</title>
      <link>https://arxiv.org/abs/2107.00134</link>
      <description>arXiv:2107.00134v4 Announce Type: replace 
Abstract: Gaussian double Markovian models consist of covariance matrices constrained by a pair of graphs specifying zeros simultaneously in the covariance matrix and its inverse. We study the semi-algebraic geometry of these models, in particular their dimension, smoothness and connectedness as well as algebraic and combinatorial properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.00134v4</guid>
      <category>math.ST</category>
      <category>math.AG</category>
      <category>stat.TH</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1111/sjos.12604</arxiv:DOI>
      <dc:creator>Tobias Boege, Thomas Kahle, Andreas Kretschmer, Frank R\"ottger</dc:creator>
    </item>
    <item>
      <title>L\'evy graphical models</title>
      <link>https://arxiv.org/abs/2410.19952</link>
      <description>arXiv:2410.19952v2 Announce Type: replace 
Abstract: Conditional independence and graphical models are crucial concepts for sparsity and statistical modeling in higher dimensions. For L\'evy processes, a widely applied class of stochastic processes, these notions have not been studied. By the L\'evy-It\^o decomposition, a multivariate L\'evy process can be decomposed into the sum of a Brownian motion part and an independent jump process. We show that conditional independence statements between the marginal processes can be studied separately for these two parts. While the Brownian part is well-understood, we derive a novel characterization of conditional independence between the sample paths of the jump process in terms of the L\'evy measure. We define L\'evy graphical models as L\'evy processes that satisfy undirected or directed Markov properties. We prove that the graph structure is invariant under changes of the univariate marginal processes. L\'evy graphical models allow the construction of flexible, sparse dependence models for L\'evy processes in large dimensions, which are interpretable thanks to the underlying graph. For trees, we develop statistical methodology to learn the underlying structure from low- or high-frequency observations of the L\'evy process and show consistent graph recovery. We apply our method to model stock returns from U.S. companies to illustrate the advantages of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19952v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Engelke, Jevgenijs Ivanovs, Jakob D. Th{\o}stesen</dc:creator>
    </item>
    <item>
      <title>Shared-Endpoint Correlations and Hierarchy in Random Flows on Graphs</title>
      <link>https://arxiv.org/abs/2411.06314</link>
      <description>arXiv:2411.06314v2 Announce Type: replace 
Abstract: We analyze the correlation between randomly chosen edge weights on neighboring edges in a directed graph. This shared-endpoint correlation controls the expected organization of randomly drawn edge flows when the flow on each edge is conditionally independent of the flows on other edges given its endpoints. To model different relationships between endpoints and flow, we draw edge weights in two stages. First, assign a random description to the vertices by sampling random attributes at each vertex. Then, sample a Gaussian process (GP) and evaluate it on the pair of endpoints connected by each edge. We model different relationships between endpoint attributes and flow by varying the kernel associated with the GP. We then relate the expected flow structure to the smoothness class containing functions generated by the GP. We compute the exact shared-endpoint correlation for the squared exponential kernel and provide accurate approximations for Mat\'ern kernels. In addition, we provide asymptotics in both smooth and rough limits and isolate three distinct domains distinguished by the regularity of the ensemble of sampled functions. Taken together, these results demonstrate a consistent effect; smoother functions relating attributes to flow produce more organized flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06314v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Richland, Alexander Strang</dc:creator>
    </item>
    <item>
      <title>Hyperbolic contractivity and the Hilbert metric on probability measures</title>
      <link>https://arxiv.org/abs/2309.02413</link>
      <description>arXiv:2309.02413v2 Announce Type: replace-cross 
Abstract: This paper gives a self-contained introduction to the Hilbert projective metric $\mathcal{H}$ and its fundamental properties, with a particular focus on the space of probability measures. We start by defining the Hilbert pseudo-metric on convex cones, focusing mainly on dual formulations of $\mathcal{H}$ . We show that linear operators on convex cones contract in the distance given by the hyperbolic tangent of $\mathcal{H}$, which in particular implies Birkhoff's classical contraction result for $\mathcal{H}$. Turning to spaces of probability measures, where $\mathcal{H}$ is a metric, we analyse the dual formulation of $\mathcal{H}$ in the general setting, and explore the geometry of the probability simplex under $\mathcal{H}$ in the special case of discrete probability measures. Throughout, we compare $\mathcal{H}$ with other distances between probability measures. In particular, we show how convergence in $\mathcal{H}$ implies convergence in total variation, $p$-Wasserstein distance, and any $f$-divergence. Furthermore, we derive a novel sharp bound for the total variation between two probability measures in terms of their Hilbert distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.02413v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel N. Cohen, Eliana Fausti</dc:creator>
    </item>
    <item>
      <title>Flexible Functional Treatment Effect Estimation</title>
      <link>https://arxiv.org/abs/2309.08039</link>
      <description>arXiv:2309.08039v2 Announce Type: replace-cross 
Abstract: We study treatment effect estimation with functional treatments where the average potential outcome functional is a function of functions, in contrast to continuous treatment effect estimation where the target is a function of real numbers. By considering a flexible scalar-on-function marginal structural model, a weight-modified kernel ridge regression (WMKRR) is adopted for estimation. The weights are constructed by directly minimizing the uniform balancing error resulting from a decomposition of the WMKRR estimator, instead of being estimated under a particular treatment selection model. Despite the complex structure of the uniform balancing error derived under WMKRR, finite-dimensional convex algorithms can be applied to efficiently solve for the proposed weights thanks to a representer theorem. The optimal convergence rate is shown to be attainable by the proposed WMKRR estimator without any smoothness assumption on the true weight function. Corresponding empirical performance is demonstrated by a simulation study and a real data application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.08039v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayi Wang, Raymond K. W. Wong, Xiaoke Zhang, Kwun Chuen Gary Chan</dc:creator>
    </item>
    <item>
      <title>Piecewise Linearity of Min-Norm Solution Map of a Nonconvexly Regularized Convex Sparse Model</title>
      <link>https://arxiv.org/abs/2311.18438</link>
      <description>arXiv:2311.18438v3 Announce Type: replace-cross 
Abstract: It is well known that the minimum $\ell_2$-norm solution of the convex LASSO model, say $\mathbf{x}_{\star}$, is a continuous piecewise linear function of the regularization parameter $\lambda$, and its signed sparsity pattern is constant within each linear piece. The current study is an extension of this classic result, proving that the aforementioned properties extend to the min-norm solution map $\mathbf{x}_{\star}(\mathbf{y},\lambda)$, where $\mathbf{y}$ is the observed signal, for a generalization of LASSO termed the scaled generalized minimax concave (sGMC) model. The sGMC model adopts a nonconvex debiased variant of the $\ell_1$-norm as sparse regularizer, but its objective function is overall-convex. Based on the geometric properties of $\mathbf{x}_{\star}(\mathbf{y},\lambda)$, we propose an extension of the least angle regression (LARS) algorithm, which iteratively computes the closed-form expression of $\mathbf{x}_{\star}(\mathbf{y},\lambda)$ in each linear zone. Under suitable conditions, the proposed algorithm provably obtains the whole solution map $\mathbf{x}_{\star}(\mathbf{y},\lambda)$ within finite iterations. Notably, our proof techniques for establishing continuity and piecewise linearity of $\mathbf{x}_{\star}(\mathbf{y},\lambda)$ are novel, and they lead to two side contributions: (a) our proofs establish continuity of the sGMC solution set as a set-valued mapping of $(\mathbf{y},\lambda)$; (b) to prove piecewise linearity and piecewise constant sparsity pattern of $\mathbf{x}_{\star}(\mathbf{y},\lambda)$, we do not require any assumption that previous work relies on (whereas to prove some additional properties of $\mathbf{x}_{\star}(\mathbf{y},\lambda)$, we use a different set of assumptions from previous work).</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18438v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Zhang, Isao Yamada</dc:creator>
    </item>
  </channel>
</rss>
