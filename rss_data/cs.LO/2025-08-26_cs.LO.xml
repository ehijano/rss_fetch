<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 27 Aug 2025 01:33:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On systematic construction of correct logic programs</title>
      <link>https://arxiv.org/abs/2508.16782</link>
      <description>arXiv:2508.16782v1 Announce Type: new 
Abstract: Partial correctness of imperative or functional programming divides in logic programming into two notions. Correctness means that all answers of the program are compatible with the specification. Completeness means that the program produces all the answers required by the specifications. We also consider semi-completeness -- completeness for those queries for which the program does not diverge. This paper presents an approach to systematically construct provably correct and semi-complete logic programs, for a given specification. Normal programs are considered, under Kunen's 3-valued completion semantics (of negation as finite failure) and the well-founded semantics (of negation as possibly infinite failure). The approach is declarative, it abstracts from details of operational semantics, like e.g.\ the form of the selected literals (``procedure calls'') during the computation. The proposed method is simple, and can be used (maybe informally) in actual everyday programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16782v1</guid>
      <category>cs.LO</category>
      <category>cs.SE</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>W{\l}odzimierz Drabent</dc:creator>
    </item>
    <item>
      <title>Paraconsistent Constructive Modal Logic</title>
      <link>https://arxiv.org/abs/2508.17758</link>
      <description>arXiv:2508.17758v1 Announce Type: new 
Abstract: We present a family of paraconsistent counterparts of the constructive modal logic CK. These logics aim to formalise reasoning about contradictory but non-trivial propositional attitudes like beliefs or obligations. We define their Kripke-style semantics based on intuitionistic frames with two valuations which provide independent support for truth and falsity; they are connected by strong negation as defined in Nelson's logic. A family of systems is obtained depending on whether both modal operators are defined using the same or by different accessibility relations for their positive and negative support. We propose Hilbert-style axiomatisations for all logics determined by this semantic framework. We also propose a~family of modular cut-free sequent calculi that we use to establish decidability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17758v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-99536-1_5</arxiv:DOI>
      <dc:creator>Han Gao, Daniil Kozhemiachenko, Nicola Olivetti</dc:creator>
    </item>
    <item>
      <title>Certificates and Witnesses for Multi-objective {\omega}-regular Queries in Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2508.17859</link>
      <description>arXiv:2508.17859v1 Announce Type: new 
Abstract: Multi-objective probabilistic model checking is a powerful technique for verifying stochastic systems against multiple (potentially conflicting) properties. To enhance the trustworthiness and explainability of model checking tools, we present independently checkable certificates and witnesses for multi-objective {\omega}-regular queries in Markov decision processes. For the certification, we extend and improve existing certificates for the decomposition of maximal end components and reachability properties. We then derive mixed-integer linear programs (MILPs) for finding minimal witnessing subsystems. For the special case of Markov chains and LTL properties, we use unambiguous B\"uchi automata to find witnesses, resulting in an algorithm that requires single-exponential space. Existing approaches based on deterministic automata require doubly-exponential space in the worst case. Finally, we consider the practical computation of our certificates and witnesses and provide an implementation of the developed techniques, along with an experimental evaluation, demonstrating the efficacy of our techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17859v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Christel Baier, Calvin Chau, Volodymyr Drobitko, Simon Jantsch, Sascha Kl\"uppelholz</dc:creator>
    </item>
    <item>
      <title>Model-Based Testing of an Intermediate Verifier Using Executable Operational Semantics</title>
      <link>https://arxiv.org/abs/2508.17895</link>
      <description>arXiv:2508.17895v1 Announce Type: new 
Abstract: Lightweight validation technique, such as those based on random testing, are sometimes practical alternatives to full formal verification -- providing valuable benefits, such as finding bugs, without requiring a disproportionate effort. In fact, they can be useful even for fully formally verified tools, by exercising the parts of a complex system that go beyond the reach of formal models.
  In this context, this paper introduces BCC: a model-based testing technique for the Boogie intermediate verifier. BCC combines the formalization of a small, deterministic subset of the Boogie language with the generative capabilities of the PLT Redex language engineering framework. Basically, BCC uses PLT Redex to generate random Boogie programs, and to execute them according to a formal operational semantics; then, it runs the same programs through the Boogie verifier. Any inconsistency between the two executions (in PLT Redex and with Boogie) may indicate a potential bug in Boogie's implementation.
  To understand whether BCC can be useful in practice, we used it to generate three million Boogie programs. These experiments found 2% of cases indicative of completeness failures (i.e., spurious verification failures) in Boogie's toolchain. These results indicate that lightweight analysis tools, such as those for model-based random testing, are also useful to test and validate formal verification tools such as Boogie.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17895v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lidia Losavio, Marco Paganoni, Carlo A. Furia</dc:creator>
    </item>
    <item>
      <title>Compositional Verification in Concurrent Separation Logic with Permissions Regions</title>
      <link>https://arxiv.org/abs/2508.18115</link>
      <description>arXiv:2508.18115v1 Announce Type: new 
Abstract: Concurrent separation logic with fractional permissions (CSLPerm) provides a promising reasoning system to verify most complex sequential and concurrent fine-grained programs. The logic with strong and weak separating conjunctions offers a solid foundation for producing concise and precise proofs. However, it lacks automation and compositionality support. This paper addresses this limitation by introducing a compositional verification system for concurrent programs that manipulate regions of shared memory. The centre of our system is novel logical principles and an entailment procedure that can infer the residual heaps in the frame rule for a fragment of CSL-Perm with explicit arithmetical constraints for memory heaps' disjointness. This procedure enables the compositional reasoning for concurrent threads and function calls. We have implemented the proposal in a prototype tool called CoSl, tested it with 10 challenging concurrent programs, including those beyond the state-of-the-art, and confirmed the advantage of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18115v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quang Loc Le</dc:creator>
    </item>
    <item>
      <title>First-Order LTLf Synthesis with Lookback (Extended Version)</title>
      <link>https://arxiv.org/abs/2508.18149</link>
      <description>arXiv:2508.18149v1 Announce Type: new 
Abstract: Reactive synthesis addresses the problem of generating a controller for a temporal specification in an adversarial environment; it was typically studied for LTL. Driven by applications ranging from AI to business process management, LTL modulo first order-theories over finite traces (LTLfMT) has recently gained traction, where propositional variables in properties are replaced by first-order constraints. Though reactive synthesis for LTLf with some first-order features has been addressed, existing work in this direction strongly restricts or excludes the possibility to compare variables across instants, a limitation that severely restricts expressiveness and applicability.
  In this work we present a reactive synthesis procedure for LTLfMT, where properties support "lookback" to model cross-instant comparison of variables. Our procedure works for full LTLfMT with lookback, subsuming the fragments of LTLfMT for which realizability was studied earlier. However, the setting with cross-instant comparison is inherently highly complex, as realizability is undecidable even over decidable background theories. Hence termination of our approach is in general not guaranteed. Nevertheless, we prove its soundness, and show that it is complete if a bound on the strategy length exists. Finally, we show that our approach constitutes a decision procedure for several relevant fragments of LTLfMT, at once re-proving known decidability results and identifying new decidable classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18149v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah Winkler</dc:creator>
    </item>
    <item>
      <title>The Computational Complexity of Satisfiability in State Space Models</title>
      <link>https://arxiv.org/abs/2508.18162</link>
      <description>arXiv:2508.18162v1 Announce Type: new 
Abstract: We analyse the complexity of the satisfiability problem ssmSAT for State Space Models (SSM), which asks whether an input sequence can lead the model to an accepting configuration. We find that ssmSAT is undecidable in general, reflecting the computational power of SSM. Motivated by practical settings, we identify two natural restrictions under which ssmSAT becomes decidable and establish corresponding complexity bounds. First, for SSM with bounded context length, ssmSAT is NP-complete when the input length is given in unary and in NEXPTIME (and PSPACE-hard) when the input length is given in binary. Second, for quantised SSM operating over fixed-width arithmetic, ssmSAT is PSPACE-complete resp. in EXPSPACE depending on the bit-width encoding. While these results hold for diagonal gated SSM we also establish complexity bounds for time-invariant SSM. Our results establish a first complexity landscape for formal reasoning in SSM and highlight fundamental limits and opportunities for the verification of SSM-based language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18162v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Alsmann, Martin Lange</dc:creator>
    </item>
    <item>
      <title>To bind or not to bind? Discovering Stable Relationships in Object-centric Processes (Extended Version)</title>
      <link>https://arxiv.org/abs/2508.18231</link>
      <description>arXiv:2508.18231v1 Announce Type: new 
Abstract: Object-centric process mining investigates the intertwined behavior of multiple objects in business processes. From object-centric event logs, object-centric Petri nets (OCPN) can be discovered to replay the behavior of processes accessing different object types. Although they indicate how objects flow through the process and co-occur in events, OCPNs remain underspecified about the relationships of objects. Hence, they are not able to represent synchronization, i.e. executing objects only according to their intended relationships, and fail to identify violating executions. Existing formal modeling approaches, such as object-centric Petri nets with identifiers (OPID), represent object identities and relationships to synchronize them correctly. However, OPID discovery has not yet been studied. This paper uses explicit data models to bridge the gap between OCPNs and formal OPIDs. We identify the implicit assumptions of stable many-to-one relationships in object-centric event logs, which implies synchronization of related objects. To formally underpin this observation, we combine OCPNs with explicit stable many-to-one relationships in a rigorous mapping from OCPNs to OPIDs explicitly capturing the intended stable relationships and the synchronization of related objects. We prove that the original OCPNs and the resulting OPIDs coincide for those executions that satisfy the intended relationships. Moreover, we provide an implementation of the mapping from OCPN to OPID under stable relationships.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18231v1</guid>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <category>cs.PL</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anjo Seidel, Sarah Winkler, Alessandro Gianola, Marco Montali, Mathias Weske</dc:creator>
    </item>
    <item>
      <title>A Straightforward Pipeline for Targeted Entailment and Contradiction Detection</title>
      <link>https://arxiv.org/abs/2508.17127</link>
      <description>arXiv:2508.17127v1 Announce Type: cross 
Abstract: Finding the relationships between sentences in a document is crucial for tasks like fact-checking, argument mining, and text summarization. A key challenge is to identify which sentences act as premises or contradictions for a specific claim. Existing methods often face a trade-off: transformer attention mechanisms can identify salient textual connections but lack explicit semantic labels, while Natural Language Inference (NLI) models can classify relationships between sentence pairs but operate independently of contextual saliency. In this work, we introduce a method that combines the strengths of both approaches for a targeted analysis. Our pipeline first identifies candidate sentences that are contextually relevant to a user-selected target sentence by aggregating token-level attention scores. It then uses a pretrained NLI model to classify each candidate as a premise (entailment) or contradiction. By filtering NLI-identified relationships with attention-based saliency scores, our method efficiently isolates the most significant semantic relationships for any given claim in a text.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17127v1</guid>
      <category>cs.CL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonin Sulc</dc:creator>
    </item>
    <item>
      <title>MC3G: Model Agnostic Causally Constrained Counterfactual Generation</title>
      <link>https://arxiv.org/abs/2508.17221</link>
      <description>arXiv:2508.17221v1 Announce Type: cross 
Abstract: Machine learning models increasingly influence decisions in high-stakes settings such as finance, law and hiring, driving the need for transparent, interpretable outcomes. However, while explainable approaches can help understand the decisions being made, they may inadvertently reveal the underlying proprietary algorithm: an undesirable outcome for many practitioners. Consequently, it is crucial to balance meaningful transparency with a form of recourse that clarifies why a decision was made and offers actionable steps following which a favorable outcome can be obtained. Counterfactual explanations offer a powerful mechanism to address this need by showing how specific input changes lead to a more favorable prediction. We propose Model-Agnostic Causally Constrained Counterfactual Generation (MC3G), a novel framework that tackles limitations in the existing counterfactual methods. First, MC3G is model-agnostic: it approximates any black-box model using an explainable rule-based surrogate model. Second, this surrogate is used to generate counterfactuals that produce a favourable outcome for the original underlying black box model. Third, MC3G refines cost computation by excluding the ``effort" associated with feature changes that occur automatically due to causal dependencies. By focusing only on user-initiated changes, MC3G provides a more realistic and fair representation of the effort needed to achieve a favourable outcome. We show that MC3G delivers more interpretable and actionable counterfactual recommendations compared to existing techniques all while having a lower cost. Our findings highlight MC3G's potential to enhance transparency, accountability, and practical utility in decision-making processes that incorporate machine-learning approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17221v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sopam Dasgupta, Sadaf MD Halim, Joaqu\'in Arias, Elmer Salazar, Gopal Gupta</dc:creator>
    </item>
    <item>
      <title>Additive systems for $\mathbb{Z}$ are undecidable</title>
      <link>https://arxiv.org/abs/2508.17285</link>
      <description>arXiv:2508.17285v1 Announce Type: cross 
Abstract: What are the collections of sets ${A}_i\subset\mathbb{Z}$ such that any $n\in\mathbb{Z}$ has exactly one representation as $n=a_0+a_1+\dotsb$ with $a_i\in{A}_i$? The answer for $\mathbb{N}_0$ instead of $\mathbb{Z}$ is given by a theorem of de Bruijn. We describe a family of natural candidate collections for $\mathbb{Z}$, which we call canonical collections. Translating the problem into the language of dynamical systems, we show that the question of whether the sumset of a canonical collection covers the entire $\mathbb{Z}$ is difficult: specifically, there is a collection for which this question is equivalent to the Collatz conjecture, and there is a well-behaved family of collections for which this question is equivalent to the universal halting problem for Fractran and is therefore undecidable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17285v1</guid>
      <category>math.CO</category>
      <category>cs.LO</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrei Zabolotskii</dc:creator>
    </item>
    <item>
      <title>On The Space Complexity of Partial Derivatives of Regular Expressions with Shuffle</title>
      <link>https://arxiv.org/abs/2508.17451</link>
      <description>arXiv:2508.17451v1 Announce Type: cross 
Abstract: Partial derivatives of regular expressions, introduced by Antimirov, define an elegant algorithm for generating equivalent non-deterministic finite automata (NFA) with a limited number of states.
  Here we focus on runtime verification (RV) of simple properties expressible with regular expressions. In this case, words are finite traces of monitorable events forming the language's alphabet, and the generated NFA may have an intractable number of states.
  This typically occurs when sub-traces of mutually independent events are allowed to interleave.
  To address this issue, regular expressions used for RV are extended with the shuffle operator to make specifications more compact and easier to read.
  Exploiting partial derivatives enables a rewriting-based approach to RV, where only one derivative is stored at each step, avoiding the construction of an intractably large automaton.
  This raises the question of the space complexity of the largest generated partial derivative. While the total number of generated partial derivatives is known to be linear in the size of the initial regular expression, no results can be found in the literature regarding the size of the largest partial derivative.
  We study this problem w.r.t. two metrics (height and size of regular expressions), and show that the former increases by at most one, while the latter is quadratic in the size of the regular expression. Surprisingly, these results also hold with shuffle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17451v1</guid>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Ancona, Angelo Ferrando</dc:creator>
    </item>
    <item>
      <title>Interpretable Early Failure Detection via Machine Learning and Trace Checking-based Monitoring</title>
      <link>https://arxiv.org/abs/2508.17786</link>
      <description>arXiv:2508.17786v1 Announce Type: cross 
Abstract: Monitoring is a runtime verification technique that allows one to check whether an ongoing computation of a system (partial trace) satisfies a given formula. It does not need a complete model of the system, but it typically requires the construction of a deterministic automaton doubly exponential in the size of the formula (in the worst case), which limits its practicality. In this paper, we show that, when considering finite, discrete traces, monitoring of pure past (co)safety fragments of Signal Temporal Logic (STL) can be reduced to trace checking, that is, evaluation of a formula over a trace, that can be performed in time polynomial in the size of the formula and the length of the trace. By exploiting such a result, we develop a GPU-accelerated framework for interpretable early failure detection based on vectorized trace checking, that employs genetic programming to learn temporal properties from historical trace data. The framework shows a 2-10% net improvement in key performance metrics compared to the state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17786v1</guid>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andrea Brunello, Luca Geatti, Angelo Montanari, Nicola Saccomanno</dc:creator>
    </item>
    <item>
      <title>On Bisimilarity for Quasi-discrete Closure Spaces</title>
      <link>https://arxiv.org/abs/2301.11634</link>
      <description>arXiv:2301.11634v5 Announce Type: replace 
Abstract: Closure spaces, a generalisation of topological spaces, have shown to be a convenient theoretical framework for spatial model checking. The closure operator of closure spaces and quasi-discrete closure spaces induces a notion of neighborhood akin to that of topological spaces that build on open sets. For closure models and quasi-discrete closure models, in this paper we present three notions of bisimilarity that are logically characterised by corresponding modal logics with spatial modalities: (i) CM-bisimilarity for closure models (CMs) is shown to generalise topo-bisimilarity for topological models and to be an instantiation of neighbourhood bisimilarity, when CMs are seen as (augmented) neighbourhood models. CM-bisimilarity corresponds to equivalence with respect to the infinitary modal logic IML that includes the modality ${\cal N}$ for ``being near to''. (ii) CMC-bisimilarity, with `CMC' standing for CM-bisimilarity with converse, refines CM-bisimilarity for quasi-discrete closure spaces, carriers of quasi-discrete closure models. Quasi-discrete closure models come equipped with two closure operators, Direct ${\cal C}$ and Converse ${\cal C}$, stemming from the binary relation underlying closure and its converse. CMC-bisimilarity, is captured by the infinitary modal logic IMLC including two modalities, Direct ${\cal N}$ and Converse ${\cal N}$, corresponding to the two closure operators. (iii) CoPa-bisimilarity on quasi-discrete closure models, which is weaker than CMC-bisimilarity, is based on the notion of compatible paths. The logical counterpart of CoPa-bisimilarity is the infinitary modal logic ICRL with modalities Direct $\zeta$ and Converse $\zeta$, whose semantics relies on forward and backward paths, respectively. It is shown that CoPa-bisimilarity for quasi-discrete closure models relates to divergence-blind stuttering equivalence for Kripke models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.11634v5</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincenzo Ciancia, Diego Latella, Mieke Massink, Erik P. de Vink</dc:creator>
    </item>
    <item>
      <title>Machine Space I: Weak exponentials and quantification over compact spaces</title>
      <link>https://arxiv.org/abs/2209.11339</link>
      <description>arXiv:2209.11339v4 Announce Type: replace-cross 
Abstract: Topology may be interpreted as the study of verifiability, where opens correspond to semi-decidable properties. In this paper we make a distinction between verifiable properties themselves and processes which carry out the verification procedure. The former are simply opens, while we call the latter machines. Given a frame presentation $\mathcal{O} X = \langle G \mid R\rangle$ we construct a space of machines $\Sigma^{\Sigma^G}$ whose points are given by formal combinations of basic machines corresponding to generators in $G$. This comes equipped with an `evaluation' map making it a weak exponential with base $\Sigma$ and exponent $X$.
  When it exists, the true exponential $\Sigma^X$ occurs as a retract of machine space. We argue this helps explain why some spaces are exponentiable and others not. We then use machine space to study compactness by giving a purely topological version of Escard\'o's algorithm for universal quantification over compact spaces in finite time. Finally, we relate our study of machine space to domain theory and domain embeddings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.11339v4</guid>
      <category>math.GN</category>
      <category>cs.LO</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter F. Faul, Graham Manuell</dc:creator>
    </item>
    <item>
      <title>Products of Recursive Programs for Hypersafety Verification (Extended Version)</title>
      <link>https://arxiv.org/abs/2504.10800</link>
      <description>arXiv:2504.10800v2 Announce Type: replace-cross 
Abstract: We study the problem of automated hypersafety verification of infinite-state recursive programs. We propose an infinite class of product programs, specifically designed with recursion in mind, that reduce the hypersafety verification of a recursive program to standard safety verification. For this, we combine insights from language theory and concurrency theory to propose an algorithmic solution for constructing an infinite class of recursive product programs. One key insight is that, using the simple theory of visibly pushdown languages, one can maintain the recursive structure of syntactic program alignments which is vital to constructing a new product program that can be viewed as a classic recursive program -- that is, one that can be executed on a single stack. Another key insight is that techniques from concurrency theory can be generalized to help define product programs based on the view that the parallel composition of individual recursive programs includes all possible alignments from which a sound set of alignments that faithfully preserve the satisfaction of the hypersafety property can be selected. On the practical side, we formulate a family of parametric canonical product constructions that are intuitive to programmers and can be used as building blocks to specify recursive product programs for the purpose of relational and hypersafety verification, with the idea that the right product program can be verified automatically using existing techniques. We demonstrate the effectiveness of these techniques through an implementation and highly promising experimental results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10800v2</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruotong Cheng, Azadeh Farzan</dc:creator>
    </item>
    <item>
      <title>From Legal Texts to Defeasible Deontic Logic via LLMs: A Study in Automated Semantic Analysis</title>
      <link>https://arxiv.org/abs/2506.08899</link>
      <description>arXiv:2506.08899v2 Announce Type: replace-cross 
Abstract: We present a novel approach to the automated semantic analysis of legal texts using large language models (LLMs), targeting their transformation into formal representations in Defeasible Deontic Logic (DDL). We propose a structured pipeline that segments complex normative language into atomic snippets, extracts deontic rules, and evaluates them for syntactic and semantic coherence. Our methodology is evaluated across various LLM configurations, including prompt engineering strategies, fine-tuned models, and multi-stage pipelines, focusing on legal norms from the Australian Telecommunications Consumer Protections Code. Empirical results demonstrate promising alignment between machine-generated and expert-crafted formalizations, showing that LLMs - particularly when prompted effectively - can significantly contribute to scalable legal informatics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08899v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LO</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elias Horner, Cristinel Mateis, Guido Governatori, Agata Ciabattoni</dc:creator>
    </item>
    <item>
      <title>Neural Logic Networks for Interpretable Classification</title>
      <link>https://arxiv.org/abs/2508.08172</link>
      <description>arXiv:2508.08172v2 Announce Type: replace-cross 
Abstract: Traditional neural networks have an impressive classification performance, but what they learn cannot be inspected, verified or extracted. Neural Logic Networks on the other hand have an interpretable structure that enables them to learn a logical mechanism relating the inputs and outputs with AND and OR operations. We generalize these networks with NOT operations and biases that take into account unobserved data and develop a rigorous logical and probabilistic modeling in terms of concept combinations to motivate their use. We also propose a novel factorized IF-THEN rule structure for the model as well as a modified learning algorithm. Our method improves the state-of-the-art in Boolean networks discovery and is able to learn relevant, interpretable rules in tabular classification, notably on examples from the medical and industrial fields where interpretability has tangible value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08172v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Tue, 26 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Perreault, Katsumi Inoue, Richard Labib, Alain Hertz</dc:creator>
    </item>
  </channel>
</rss>
