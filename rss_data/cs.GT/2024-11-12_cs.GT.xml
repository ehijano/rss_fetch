<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 13 Nov 2024 02:44:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Online Bayesian Persuasion Without a Clue</title>
      <link>https://arxiv.org/abs/2411.06141</link>
      <description>arXiv:2411.06141v1 Announce Type: new 
Abstract: We study online Bayesian persuasion problems in which an informed sender repeatedly faces a receiver with the goal of influencing their behavior through the provision of payoff-relevant information. Previous works assume that the sender has knowledge about either the prior distribution over states of nature or receiver's utilities, or both. We relax such unrealistic assumptions by considering settings in which the sender does not know anything about the prior and the receiver. We design an algorithm that achieves sublinear regret with respect to an optimal signaling scheme, and we also provide a collection of lower bounds showing that the guarantees of such an algorithm are tight. Our algorithm works by searching a suitable space of signaling schemes in order to learn receiver's best responses. To do this, we leverage a non-standard representation of signaling schemes that allows to cleverly overcome the challenge of not knowing anything about the prior over states of nature and receiver's utilities. Finally, our results also allow to derive lower/upper bounds on the sample complexity of learning signaling schemes in a related Bayesian persuasion PAC-learning problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06141v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Bacchiocchi, Matteo Bollini, Matteo Castiglioni, Alberto Marchesi, Nicola Gatti</dc:creator>
    </item>
    <item>
      <title>Maximizing Nash Social Welfare in 2-Value Instances: A Simpler Proof for the Half-Integer Case</title>
      <link>https://arxiv.org/abs/2411.06924</link>
      <description>arXiv:2411.06924v1 Announce Type: new 
Abstract: A set of $m$ indivisible goods is to be allocated to a set of $n$ agents. Each agent $i$ has an additive valuation function $v_i$ over goods. The value of a good $g$ for agent $i$ is either $1$ or $s$, where $s$ is a fixed rational number greater than one, and the value of a bundle of goods is the sum of the values of the goods in the bundle. An \emph{allocation} $X$ is a partition of the goods into bundles $X_1$, \ldots, $X_n$, one for each agent. The \emph{Nash Social Welfare} ($\NSW$) of an allocation $X$ is defined as \[ \NSW(X) = \left( \prod_i v_i(X_i) \right)^{\sfrac{1}{n}}.\] The \emph{$\NSW$-allocation} maximizes the Nash Social Welfare. In~\cite{NSW-twovalues-halfinteger} it was shown that the $\NSW$-allocation can be computed in polynomial time, if $s$ is an integer or a half-integer, and that the problem is NP-complete otherwise. The proof for the half-integer case is quite involved. In this note we give a simpler and shorter proof</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06924v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kurt Mehlhorn</dc:creator>
    </item>
    <item>
      <title>Bounded Rationality Equilibrium Learning in Mean Field Games</title>
      <link>https://arxiv.org/abs/2411.07099</link>
      <description>arXiv:2411.07099v1 Announce Type: new 
Abstract: Mean field games (MFGs) tractably model behavior in large agent populations. The literature on learning MFG equilibria typically focuses on finding Nash equilibria (NE), which assume perfectly rational agents and are hence implausible in many realistic situations. To overcome these limitations, we incorporate bounded rationality into MFGs by leveraging the well-known concept of quantal response equilibria (QRE). Two novel types of MFG QRE enable the modeling of large agent populations where individuals only noisily estimate the true objective. We also introduce a second source of bounded rationality to MFGs by restricting agents' planning horizon. The resulting novel receding horizon (RH) MFGs are combined with QRE and existing approaches to model different aspects of bounded rationality in MFGs. We formally define MFG QRE and RH MFGs and compare them to existing equilibrium concepts such as entropy-regularized NE. Subsequently, we design generalized fixed point iteration and fictitious play algorithms to learn QRE and RH equilibria. After a theoretical analysis, we give different examples to evaluate the capabilities of our learning algorithms and outline practical differences between the equilibrium concepts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07099v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yannick Eich, Christian Fabian, Kai Cui, Heinz Koeppl</dc:creator>
    </item>
    <item>
      <title>Game-theoretic LLM: Agent Workflow for Negotiation Games</title>
      <link>https://arxiv.org/abs/2411.05990</link>
      <description>arXiv:2411.05990v2 Announce Type: cross 
Abstract: This paper investigates the rationality of large language models (LLMs) in strategic decision-making contexts, specifically within the framework of game theory. We evaluate several state-of-the-art LLMs across a spectrum of complete-information and incomplete-information games. Our findings reveal that LLMs frequently deviate from rational strategies, particularly as the complexity of the game increases with larger payoff matrices or deeper sequential trees.
  To address these limitations, we design multiple game-theoretic workflows that guide the reasoning and decision-making processes of LLMs. These workflows aim to enhance the models' ability to compute Nash Equilibria and make rational choices, even under conditions of uncertainty and incomplete information. Experimental results demonstrate that the adoption of these workflows significantly improves the rationality and robustness of LLMs in game-theoretic tasks. Specifically, with the workflow, LLMs exhibit marked improvements in identifying optimal strategies, achieving near-optimal allocations in negotiation scenarios, and reducing susceptibility to exploitation during negotiations. Furthermore, we explore the meta-strategic considerations of whether it is rational for agents to adopt such workflows, recognizing that the decision to use or forgo the workflow constitutes a game-theoretic issue in itself.
  Our research contributes to a deeper understanding of LLMs' decision-making capabilities in strategic contexts and provides insights into enhancing their rationality through structured workflows. The findings have implications for the development of more robust and strategically sound AI agents capable of navigating complex interactive environments. Code and data supporting this study are available at \url{https://github.com/Wenyueh/game_theory}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05990v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenyue Hua, Ollie Liu, Lingyao Li, Alfonso Amayuelas, Julie Chen, Lucas Jiang, Mingyu Jin, Lizhou Fan, Fei Sun, William Wang, Xintong Wang, Yongfeng Zhang</dc:creator>
    </item>
    <item>
      <title>Model Selection for Average Reward RL with Application to Utility Maximization in Repeated Games</title>
      <link>https://arxiv.org/abs/2411.06069</link>
      <description>arXiv:2411.06069v1 Announce Type: cross 
Abstract: In standard RL, a learner attempts to learn an optimal policy for a Markov Decision Process whose structure (e.g. state space) is known. In online model selection, a learner attempts to learn an optimal policy for an MDP knowing only that it belongs to one of $M &gt;1$ model classes of varying complexity. Recent results have shown that this can be feasibly accomplished in episodic online RL. In this work, we propose $\mathsf{MRBEAR}$, an online model selection algorithm for the average reward RL setting. The regret of the algorithm is in $\tilde O(M C_{m^*}^2 \mathsf{B}_{m^*}(T,\delta))$ where $C_{m^*}$ represents the complexity of the simplest well-specified model class and $\mathsf{B}_{m^*}(T,\delta)$ is its corresponding regret bound. This result shows that in average reward RL, like the episodic online RL, the additional cost of model selection scales only linearly in $M$, the number of model classes. We apply $\mathsf{MRBEAR}$ to the interaction between a learner and an opponent in a two-player simultaneous general-sum repeated game, where the opponent follows a fixed unknown limited memory strategy. The learner's goal is to maximize its utility without knowing the opponent's utility function. The interaction is over $T$ rounds with no episode or discounting which leads us to measure the learner's performance by average reward regret. In this application, our algorithm enjoys an opponent-complexity-dependent regret in $\tilde O(M(\mathsf{sp}(h^*) B^{m^*} A^{m^*+1})^{\frac{3}{2}} \sqrt{T})$, where $m^*\le M$ is the unknown memory limit of the opponent, $\mathsf{sp}(h^*)$ is the unknown span of optimal bias induced by the opponent, and $A$ and $B$ are the number of actions for the learner and opponent respectively. We also show that the exponential dependency on $m^*$ is inevitable by proving a lower bound on the learner's regret.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06069v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alireza Masoumian, James R. Wright</dc:creator>
    </item>
    <item>
      <title>Multidimensional Screening with Rich Consumer Data</title>
      <link>https://arxiv.org/abs/2411.06312</link>
      <description>arXiv:2411.06312v1 Announce Type: cross 
Abstract: A multi-product monopolist faces a buyer who is privately informed about his valuations for the goods. As is well-known, optimal mechanisms are in general complicated, while simple mechanisms -- such as pure bundling or separate sales -- can be far from optimal and do not admit clear-cut comparisons. We show that this changes if the monopolist observes sufficiently rich data about the buyer's valuations: Now, pure bundling always outperforms separate sales; moreover, there is a sense in which pure bundling performs essentially as well as the optimal mechanism. To formalize this, we characterize how fast the corresponding revenues converge to the first-best revenue as the monopolist's data grows rich: Pure bundling achieves the same convergence rate to the first-best as optimal mechanisms; in contrast, the convergence rate under separate sales is suboptimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06312v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mira Frick, Ryota Iijima, Yuhta Ishii</dc:creator>
    </item>
    <item>
      <title>A dynamic auction for multilateral collaboration</title>
      <link>https://arxiv.org/abs/2411.06545</link>
      <description>arXiv:2411.06545v1 Announce Type: cross 
Abstract: We study the problem of multilateral collaboration among agents with transferable utilities. Any group of agents can sign a contract consisting of a primitive contract and monetary transfers among the signatories. We propose a dynamic auction that finds a stable outcome when primitive contracts are gross complements for all participants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06545v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Huang</dc:creator>
    </item>
    <item>
      <title>Designing Local Distributed Mechanisms</title>
      <link>https://arxiv.org/abs/2411.06788</link>
      <description>arXiv:2411.06788v1 Announce Type: cross 
Abstract: In this work we introduce a new notion: local mechanisms. These are truthful mechanisms that have an implementation as fast distributed algorithms and non-trivial approximation guarantees. We show how monotone distributed optimisation algorithms can be turned into truthful mechanisms using Myerson's Lemma. We demonstrate mechanisms for four fundamental graph problems: maximum-weight independent set, minimum-weight vertex cover, minimum-weight dominating set, and a variant of weighted colouring.
  We show how these mechanisms can be implemented in the distributed setting. The key observation is that computing the so-called critical prices of a monotone algorithm can be done with the same time complexity as the original algorithm in the LOCAL model of distributed computing. Our work establishes a new connection between algorithmic mechanism design and distributed graph algorithms. We pose several open questions, such as can critical prices be computed with small messages. It also points to the importance of designing monotone distributed optimisation algorithms.
  Our work extends previous work in Distributed Algorithmic Mechanism Design (DAMD) in a new direction. Instead of studying global problems like routing or leader election, we study local resource allocation problems. Our algorithms are simple and thus potentially practical. Local algorithms are particularly interesting for highly dynamic large-scale systems, and there are many potential future application domains, e.g. demand-side load management in electric grids or resource allocation in IoT computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06788v1</guid>
      <category>cs.DC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juho Hirvonen, Sara Ranjbaran</dc:creator>
    </item>
    <item>
      <title>The Shapley index for music streaming platforms</title>
      <link>https://arxiv.org/abs/2411.07166</link>
      <description>arXiv:2411.07166v1 Announce Type: cross 
Abstract: We study an index to measure the popularity of artists in music streaming platforms. This index, which can be used to allocate the amount raised via paid subscriptions among participating artists, is based on the Shapley value, a centerpiece in cooperative game theory. We characterize this Shapley index combining several axioms formalizing principles with normative appeal. This permits to place the index in the literature, as an alternative to the well-known (and widely used in the industry) pro-rata and user-centric indices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07166v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.IR</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gustavo Berganti\~nos, Juan D. Moreno-Ternero</dc:creator>
    </item>
    <item>
      <title>Tightness without Counterexamples: A New Approach and New Results for Prophet Inequalities</title>
      <link>https://arxiv.org/abs/2205.00588</link>
      <description>arXiv:2205.00588v4 Announce Type: replace 
Abstract: Prophet inequalities consist of many beautiful statements that establish tight performance ratios between online and offline allocation algorithms. Typically, tightness is established by constructing an algorithmic guarantee and a worst-case instance separately, whose bounds match as a result of some "ingenuity". In this paper, we instead formulate the construction of the worst-case instance as an optimization problem, which directly finds the tight ratio without needing to construct two bounds separately. Our analysis of this complex optimization problem involves identifying structure in a new "Type Coverage" dual problem. It can be seen as akin to the celebrated Magician and OCRS (Online Contention Resolution Scheme) problems, except more general in that it can also provide tight ratios relative to the optimal offline allocation, whereas the earlier problems only establish tight ratios relative to the ex-ante relaxation of the offline problem.
  Through this analysis, our paper provides a unified framework that derives new prophet inequalities and recovers existing ones, with our principal results being two-fold. First, we show that the "oblivious" method of setting a static threshold due to Chawla et al. (2020), surprisingly, is best-possible among all static threshold algorithms, under any number $k$ of starting units. We emphasize that this result is derived without needing to explicitly find any counterexample instances. This implies the tightness of the asymptotic convergence rate of $1-O(\sqrt{\log k/k})$ for static threshold algorithms, which dates back to from Hajiaghayi et al. (2007). Turning to the IID setting, our second principal result is to use our framework to characterize the tight guarantee (of adaptive algorithms) under any number $k$ of selection slots and any fixed number of agents $n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.00588v4</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiashuo Jiang, Will Ma, Jiawei Zhang</dc:creator>
    </item>
    <item>
      <title>Universal Complexity Bounds Based on Value Iteration for Stochastic Mean Payoff Games and Entropy Games</title>
      <link>https://arxiv.org/abs/2206.09044</link>
      <description>arXiv:2206.09044v2 Announce Type: replace 
Abstract: We develop value iteration-based algorithms to solve in a unified manner different classes of combinatorial zero-sum games with mean-payoff type rewards. These algorithms rely on an oracle, evaluating the dynamic programming operator up to a given precision. We show that the number of calls to the oracle needed to determine exact optimal (positional) strategies is, up to a factor polynomial in the dimension, of order R/sep, where the "separation" sep is defined as the minimal difference between distinct values arising from strategies, and R is a metric estimate, involving the norm of approximate sub and super-eigenvectors of the dynamic programming operator. We illustrate this method by two applications. The first one is a new proof, leading to improved complexity estimates, of a theorem of Boros, Elbassioni, Gurvich and Makino, showing that turn-based mean-payoff games with a fixed number of random positions can be solved in pseudo-polynomial time. The second one concerns entropy games, a model introduced by Asarin, Cervelle, Degorre, Dima, Horn and Kozyakin. The rank of an entropy game is defined as the maximal rank among all the ambiguity matrices determined by strategies of the two players. We show that entropy games with a fixed rank, in their original formulation, can be solved in polynomial time, and that an extension of entropy games incorporating weights can be solved in pseudo-polynomial time under the same fixed rank condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.09044v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xavier Allamigeon, St\'ephane Gaubert, Ricardo D. Katz, Mateusz Skomra</dc:creator>
    </item>
    <item>
      <title>Maximizing Nash Social Welfare in 2-Value Instances: Delineating Tractability</title>
      <link>https://arxiv.org/abs/2207.10949</link>
      <description>arXiv:2207.10949v5 Announce Type: replace 
Abstract: We study the problem of allocating a set of indivisible goods among a set of agents with \emph{2-value additive valuations}. In this setting, each good is valued either $1$ or $\sfrac{p}{q}$, for some fixed co-prime numbers $p,q\in \NN$ such that $1\leq q &lt; p$. Our goal is to find an allocation maximizing the \emph{Nash social welfare} (\NSW), i.e., the geometric mean of the valuations of the agents. In this work, we give a complete characterization of polynomial-time tractability of \NSW\ maximization that solely depends on the values of $q$.
  We start by providing a rather simple polynomial-time algorithm to find a maximum \NSW\ allocation when the valuation functions are \emph{integral}, that is, $q=1$. We then exploit more involved techniques to get an algorithm producing a maximum \NSW\ allocation for the \emph{half-integral} case, that is, $q=2$. Finally, we show it is \classNP-hard to compute an allocation with maximum \NSW\ whenever $q\geq3$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.10949v5</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannaneh Akrami, Bhaskar Ray Chaudhury, Martin Hoefer, Kurt Mehlhorn, Marco Schmalhofer, Golnoosh Shahkarami, Giovanna Varricchio, Quentin Vermande, Ernest van Wijland</dc:creator>
    </item>
    <item>
      <title>Learning in Repeated Multi-Unit Pay-As-Bid Auctions</title>
      <link>https://arxiv.org/abs/2307.15193</link>
      <description>arXiv:2307.15193v3 Announce Type: replace 
Abstract: Motivated by Carbon Emissions Trading Schemes, Treasury Auctions, Procurement Auctions, and Wholesale Electricity Markets, which all involve the auctioning of homogeneous multiple units, we consider the problem of learning how to bid in repeated multi-unit pay-as-bid auctions. In each of these auctions, a large number of (identical) items are to be allocated to the largest submitted bids, where the price of each of the winning bids is equal to the bid itself. In this work, we study the problem of optimizing bidding strategies from the perspective of a single bidder.
  Effective bidding in pay-as-bid (PAB) auctions is complex due to the combinatorial nature of the action space. We show that a utility decoupling trick enables a polynomial time algorithm to solve the offline problem where competing bids are known in advance. Leveraging this structure, we design efficient algorithms for the online problem under both full information and bandit feedback settings that achieve an upper bound on regret of $O(M \sqrt{T \log T})$ and $O(M T^{\frac{2}{3}} \sqrt{\log T})$ respectively, where $M$ is the number of units demanded by the bidder and $T$ is the total number of auctions. We accompany these results with a regret lower bound of $\Omega(M\sqrt{T})$ for the full information setting and $\Omega (M^{2/3}T^{2/3})$ for the bandit setting. We also present additional findings on the characterization of PAB equilibria.
  While the Nash equilibria of PAB auctions possess nice properties such as winning bid uniformity and high welfare \&amp; revenue, they are not guaranteed under no regret learning dynamics. Nevertheless, our simulations suggest these properties hold anyways, regardless of Nash equilibrium existence. Compared to its uniform price counterpart, the PAB dynamics converge faster and achieve higher revenue, making PAB appealing whenever revenue holds significant social value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15193v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Manufacturing &amp; Service Operations Management 2024</arxiv:journal_reference>
      <dc:creator>Rigel Galgana, Negin Golrezaei</dc:creator>
    </item>
    <item>
      <title>Skill Dominance Analysis of Two(Four) player, Three(Five) dice Variant of the Ludo Game</title>
      <link>https://arxiv.org/abs/2409.00376</link>
      <description>arXiv:2409.00376v2 Announce Type: replace 
Abstract: This paper examines two different variants of the Ludo game, involving multiple dice and a fixed number of total turns. Within each variant, multiple game lengths (total no. of turns) are considered. To compare the two variants, a set of intuitive, rule-based strategies is designed, representing different broad methods of strategic play. Game play is simulated between bots (automated software applications executing repetitive tasks over a network) following these strategies. The expected results are computed using certain game theoretic and probabilistic explanations, helping to understand the performance of the different strategies. The different strategies are further analyzed using win percentage in a large number of simulations, and Nash Equilibrium strategies are computed for both variants for a varying number of total turns. The Nash Equilibrium strategies across different game lengths are compared. A clear distinction between performances of strategies is observed, with more sophisticated strategies beating the naive one. A gradual shift in optimal strategy profiles is observed with changing game length, and certain sophisticated strategies even confound each other's performance while playing against each other.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00376v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tathagata Banerjee, Diganta Mukherjee</dc:creator>
    </item>
    <item>
      <title>Reducing Leximin Fairness to Utilitarian Optimization</title>
      <link>https://arxiv.org/abs/2409.10395</link>
      <description>arXiv:2409.10395v2 Announce Type: replace 
Abstract: Two prominent objectives in social choice are utilitarian - maximizing the sum of agents' utilities, and leximin - maximizing the smallest agent's utility, then the second-smallest, etc. Utilitarianism is typically computationally easier to attain but is generally viewed as less fair. This paper presents a general reduction scheme that, given a utilitarian solver, produces a distribution over outcomes that is leximin in expectation. Importantly, the scheme is robust in the sense that, given an approximate utilitarian solver, it produces an outcome that is approximately-leximin (in expectation) - with the same approximation factor. We apply our scheme to several social choice problems: stochastic allocations of indivisible goods, giveaway lotteries, and fair lotteries for participatory budgeting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10395v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eden Hartman, Yonatan Aumann, Avinatan Hassidim, Erel Segal-Halevi</dc:creator>
    </item>
    <item>
      <title>Opinion Dynamics for Utility Maximizing Agents: Exploring the Impact of the Resource Penalty</title>
      <link>https://arxiv.org/abs/2404.04912</link>
      <description>arXiv:2404.04912v2 Announce Type: replace-cross 
Abstract: We propose a continuous-time nonlinear model of opinion dynamics with utility-maximizing agents connected via a social influence network. A distinguishing feature of the proposed model is the inclusion of an opinion-dependent resource-penalty term in the utilities, which limits the agents from holding opinions of large magnitude. This model is applicable in scenarios where the opinions pertain to the usage of resources, such as money, time, computational resources etc. Each agent myopically seeks to maximize its utility by revising its opinion in the gradient ascent direction of its utility function, thus leading to the proposed opinion dynamics. We show that, for any arbitrary social influence network, opinions are ultimately bounded. For networks with weak antagonistic relations, we show that there exists a globally exponentially stable equilibrium using contraction theory. We establish conditions for the existence of consensus equilibrium and analyze the relative dominance of the agents at consensus. We also conduct a game-theoretic analysis of the underlying opinion formation game, including on Nash equilibria and on prices of anarchy in terms of satisfaction ratios. Additionally, we also investigate the oscillatory behavior of opinions in a two-agent scenario. Finally, simulations illustrate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04912v2</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <pubDate>Tue, 12 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prashil Wankhede, Nirabhra Mandal, Sonia Mart\'inez, Pavankumar Tallapragada</dc:creator>
    </item>
  </channel>
</rss>
