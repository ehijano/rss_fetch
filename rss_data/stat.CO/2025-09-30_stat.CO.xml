<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 01 Oct 2025 02:06:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Adaptive Pseudo-Marginal Algorithm</title>
      <link>https://arxiv.org/abs/2509.24820</link>
      <description>arXiv:2509.24820v1 Announce Type: new 
Abstract: The Pseudo-Marginal (PM) algorithm is a popular Markov chain Monte Carlo (MCMC) method used to sample from a target distribution when its density is inaccessible, but can be estimated with a non-negative unbiased estimator. Its performance depends on a key parameter, N, the number of iterations (or particles) used to approximate the target density. Larger values of N yield more accurate estimates but at increased running time. Previous studies has provided guidelines for selecting an optimal value of N to balance this tradeoff. However, this approach involves multiple steps and manual adjustments. To overcome these limitations, we introduce an adaptive version of the PM algorithm, where N is automatically adjusted during the iterative process toward its optimal value, thus eliminating the need for manual intervention. This algorithm ensures convergence under certain conditions. On two examples, including a real data problem on pulmonary infection in preschool children, the proposed algorithm compares favorably to the existing approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24820v1</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarra Abaoubida, Myl\`ene B\'edard, Florian Maire</dc:creator>
    </item>
    <item>
      <title>Covariance-Adaptive Bouncy Particle Samplers via Split Lagrangian Dynamics</title>
      <link>https://arxiv.org/abs/2509.24847</link>
      <description>arXiv:2509.24847v1 Announce Type: new 
Abstract: Piecewise Deterministic Markov Processes (PDMPs) provide a powerful framework for continuous-time Monte Carlo, with the Bouncy Particle Sampler (BPS) as a prominent example. Recent advances through the Metropolised PDMP framework allow local adaptivity in step size and effective path length, the latter acting as a refreshment rate. However, current PDMP samplers cannot adapt to local changes in the covariance structure of the target distribution.
  We extend BPS by introducing a position-dependent velocity distribution that varies with the local covariance structure of the target. Building on ideas from Riemannian Manifold Hamiltonian Monte Carlo and its velocity-based variant, Lagrangian Dynamical Monte Carlo, we construct a PDMP for which changes in the metric trigger additional velocity update events. Using a metric derived from the target Hessian, the resulting algorithm adapts to the local covariance structure.
  Through a series of controlled experiments, we provide practical guidance on when the proposed covariance-adaptive BPS should be preferred over standard PDMP algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24847v1</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Augustin Chevallier, Erik Raab</dc:creator>
    </item>
    <item>
      <title>Graph-based Analysis for Revealing the Stochastic Gravitational Wave Background in Pulsar Timing Arrays</title>
      <link>https://arxiv.org/abs/2509.24904</link>
      <description>arXiv:2509.24904v1 Announce Type: cross 
Abstract: The stochastic gravitational wave background (SGWB) reveals valuable information about its origin and the Universe. The pulsar timing arrays (PTAs) are suitable indicators for detecting SGWB within the nano-Hertz frequency range. In this work, we propose a graph-based method implemented on the pulsar timing residuals (PTRs) for SGWB detection and examining uncertainties of its parameters. We construct a correlation graph with pulsars as its nodes, and analyze the graph-based summary statistics, which include topological and geometrical characteristics, for identifying SGWB in real and synthetic datasets. The effect of the number of pulsars, the observation time span, and the strength of the SGWB on the graph-based feature vector is evaluated. Our results demonstrate that the merit feature vector for common signal detection consists of the average clustering coefficient and the edge weight fluctuation. The SGWB detection conducted after the observation of a common signal and then exclusion of non-Hellings \&amp; Downs templates is performed by the second cumulant of edge weight for angular separation thresholds $\bar{\zeta}\gtrsim 40^{\circ}$. The lowest detectable value of SGWB strain amplitude utilizing our graph-based measures at the current PTAs sensitivity is $A_{\rm SGWB}\gtrsim 1.2\times 10^{-15}$. Fisher forecasts confirmed that the uncertainty levels of $\log_{10} A_{\rm SGWB}$ and spectral index reach $2.2\%$ and $28.3\%$, respectively, at $2\sigma$ confidence interval. Evidence for an SGWB at the $3\sigma$ level is obtained by applying our graph-based method to the NANOGrav 15-year dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24904v1</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <category>stat.CO</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Alakhras, S. M. S. Movahed</dc:creator>
    </item>
    <item>
      <title>Improving Software Engineering in Biostatistics: Challenges and Opportunities</title>
      <link>https://arxiv.org/abs/2301.11791</link>
      <description>arXiv:2301.11791v2 Announce Type: replace 
Abstract: Programming is ubiquitous in applied biostatistics; adopting software engineering skills will help biostatisticians do a better job. To explain this, we start by highlighting key challenges for software development and application in biostatistics. Silos between different statistician roles, projects, departments, and organizations lead to the development of duplicate and suboptimal code. Building on top of open-source software requires critical appraisal and risk-based assessment of the used modules. Code that is written needs to be readable to ensure reliable software. The software needs to be easily understandable for the user, as well as developed within testing frameworks to ensure that long term maintenance of the software is feasible. Finally, the reproducibility of research results is hindered by manual analysis workflows and uncontrolled code development. We next describe how the awareness of the importance and application of good software engineering practices and strategies can help address these challenges. The foundation is a better education in basic software engineering skills in schools, universities, and during the work life. Dedicated software engineering teams within academic institutions and companies can be a key factor for the establishment of good software engineering practices and catalyze improvements across research projects. Providing attractive career paths is important for the retainment of talents. Readily available tools can improve the reproducibility of statistical analyses and their use can be exercised in community events. [...]</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.11791v2</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Saban\'es Bov\'e, Heidi Seibold, Anne-Laure Boulesteix, Juliane Manitz, Alessandro Gasparini, Burak K. Gu\"unhan, Oliver Boix, Armin Schu\"uler, Sven Fillinger, Sven Nahnsen, Anna E. Jacob, Thomas Jaki</dc:creator>
    </item>
    <item>
      <title>reslife: Residual Lifetime Analysis Tool in R</title>
      <link>https://arxiv.org/abs/2308.07410</link>
      <description>arXiv:2308.07410v4 Announce Type: replace 
Abstract: Mean residual lifetime is an important measure utilized in various fields, including pharmaceutical companies, manufacturing companies, and insurance companies for survival analysis. However, the computation of mean residual lifetime can be laborious and challenging. To address this issue, the R package reslife has been developed, which enables efficient calculation of mean residual lifetime based on closed-form solution in a user-friendly manner. reslife offers the capability to utilize either the results of a flexsurv regression or user-provided parameters to compute mean residual lifetime. Furthermore, there are options to return median and percentile residual lifetime. If the user chooses to use the outputs of a flexsurv regression, there is an option to input a data frame with unobserved data. In this article, we present reslife, explain its underlying mathematical principles, illustrate its functioning, and provide examples on how to utilize the package. The aim is to facilitate the use of mean residual lifetime, making it more accessible and efficient for practitioners in various disciplines, particularly those involved in survival analysis within the pharmaceutical industry. This package has been approved and available on CRAN: https://cran.r-project.org/web/packages/reslife/index.html</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07410v4</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zekai Wang, Andrew Crawford, Ka Lok Lee, Lin Lu, Srihari Jaganathan</dc:creator>
    </item>
    <item>
      <title>changepointGA: An R package for Fast Changepoint Detection via Genetic Algorithm</title>
      <link>https://arxiv.org/abs/2410.15571</link>
      <description>arXiv:2410.15571v2 Announce Type: replace 
Abstract: Detecting changepoints in a time series of length $N$ entails evaluating up to $2^{N-1}$ possible changepoint models, making exhaustive enumeration computationally infeasible. Genetic algorithms (GAs) provide a stochastic way to identify the structural changes: a population of candidate models evolves via selection, crossover, and mutation operators until it converges on one changepoint model that balances the goodness-of-fit with parsimony. The R package changepointGA encodes each candidate model as an integer chromosome vector and supports both the basic single-population model GA and the island model GA. Parallel computing is implemented on multi-core hardware to further accelerate computation. Users may supply custom fitness functions or genetic operators, while a user-friendly wrapper streamlines routine analyses. Extensive simulations demonstrate that our package runs significantly faster than binary-encoded GA alternatives. Additionally, this package can simultaneously locate changepoints and estimate their effects, as well as other model parameters and any integer-valued hyperparameters. Applications to array-based comparative genomic hybridization data and a century-long temperature series further highlight the package's value in biological and climate research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15571v2</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mo Li, QiQi Lu</dc:creator>
    </item>
    <item>
      <title>Exact Bayesian inference for Markov switching diffusions</title>
      <link>https://arxiv.org/abs/2502.09126</link>
      <description>arXiv:2502.09126v2 Announce Type: replace 
Abstract: We develop the first exact Bayesian methodology for the problem of inference in discretely observed regime switching diffusions. Switching diffusion models extend ordinary diffusions by allowing for jumps in instantaneous drift and volatility. The jumps are driven by a latent, continuous time Markov switching process. We address the problem through an MCMC and an MCEM algorithm that target the exact posterior of diffusion parameters and the latent regime process. The algorithms are exact in the sense that they target the correct posterior distribution of the continuous model, so that the errors are due to Monte Carlo only. We illustrate the method on numerical examples, including an empirical analysis of the method's scalability in the length of the time series, and find that it is comparable in computational cost with discrete approximations while avoiding their shortcomings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09126v2</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timoth\'ee Stumpf-F\'etizon, Krzysztof {\L}atuszy\'nski, Jan Palczewski, Gareth Roberts</dc:creator>
    </item>
    <item>
      <title>sae4health: An R Shiny Application for Small Area Estimation in Low- and Middle-Income Countries</title>
      <link>https://arxiv.org/abs/2505.01467</link>
      <description>arXiv:2505.01467v2 Announce Type: replace 
Abstract: Accurate subnational estimation of health indicators is critical for public health planning, particularly in low- and middle-income countries (LMICs), where data and analytic tools are often limited. sae4health is an open-access Shiny application (https://rsc.stat.washington.edu/sae4health/) that generates small area estimates for more than 150 demographic and health indicators, based on over 150 Demographic and Health Surveys (DHS) from 60 countries. The platform offers both area- and unit-level models with spatial random effects, implemented through fast Bayesian inference using Integrated Nested Laplace Approximation (INLA). The app is fully browser-based and requires no data input, programming skills, or statistical modeling expertise, making advanced methods accessible to a wide range of users. Estimates are processed in real time and presented as interactive maps, tables, and downloadable reports. A companion website (https://sae4health.stat.uw.edu) provides documentation and methodological background to support the app. Together, these resources enhance access to subnational health data and facilitate the use of DHS surveys for evidence-based decision making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01467v2</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yunhan Wu, Qianyu Dong, Jieyi Xu, Zehang Richard Li, Jon Wakefield</dc:creator>
    </item>
    <item>
      <title>Smoothed pseudo-population bootstrap methods with applications to finite population quantiles</title>
      <link>https://arxiv.org/abs/2410.07996</link>
      <description>arXiv:2410.07996v2 Announce Type: replace-cross 
Abstract: This paper introduces smoothed pseudo-population bootstrap methods for the purposes of variance estimation and the construction of confidence intervals for finite population quantiles. In an i.i.d. context, it has been shown that resampling from a smoothed estimate of the distribution function instead of the usual empirical distribution function can improve the convergence rate of the bootstrap variance estimator of a sample quantile. We extend the smoothed bootstrap to the survey sampling framework by implementing it in pseudo-population bootstrap methods for high entropy, single-stage survey designs, such as simple random sampling without replacement and Poisson sampling. Given a kernel function and a bandwidth, it consists of smoothing the pseudo-population from which bootstrap samples are drawn using the original sampling design. Given that the implementation of the proposed algorithms requires the specification of the bandwidth, we develop a plug-in selection method along with a grid search selection method based on a bootstrap estimate of the mean squared error. Simulation results suggest a gain in efficiency associated with the smoothed approach as compared to the standard pseudo-population bootstrap for estimating the variance of a quantile estimator together with mixed results regarding confidence interval coverage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07996v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Vanessa McNealis, Christian L\'eger</dc:creator>
    </item>
    <item>
      <title>A Nonparametric Bayesian Local-Global Model for Enhanced Adverse Event Signal Detection in Spontaneous Reporting System Data</title>
      <link>https://arxiv.org/abs/2504.10881</link>
      <description>arXiv:2504.10881v2 Announce Type: replace-cross 
Abstract: Spontaneous reporting system databases are key resources for post-marketing surveillance, providing real-world evidence (RWE) on the adverse events (AEs) of regulated drugs or other medical products. Various statistical methods have been proposed for AE signal detection in these databases, flagging drug-specific AEs with disproportionately high observed counts compared to expected counts under independence. However, signal detection remains challenging for rare AEs or newer drugs, which receive small observed and expected counts and thus suffer from reduced statistical power. Principled information sharing on signal strengths across drugs/AEs is crucial in such cases to enhance signal detection. However, existing methods typically ignore complex between-drug associations on AE signal strengths, limiting their ability to detect signals. We propose novel local-global mixture Dirichlet process (DP) prior-based nonparametric Bayesian models to capture these associations, enabling principled information sharing between drugs while balancing flexibility and shrinkage for each drug, thereby enhancing statistical power. We develop efficient Markov chain Monte Carlo algorithms for implementation and employ a false discovery rate (FDR)-controlled, false negative rate (FNR)-optimized hypothesis testing framework for AE signal detection. Extensive simulations demonstrate our methods' superior sensitivity -- often surpassing existing approaches by a twofold or greater margin -- while strictly controlling the FDR. An application to FDA FAERS data on statin drugs further highlights our methods' effectiveness in real-world AE signal detection. Software implementing our methods is provided as supplementary material.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10881v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Xin-Wei Huang, Saptarshi Chakraborty</dc:creator>
    </item>
  </channel>
</rss>
