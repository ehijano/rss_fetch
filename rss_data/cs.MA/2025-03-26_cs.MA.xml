<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Mar 2025 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Multi-agent Uncertainty-Aware Pessimistic Model-Based Reinforcement Learning for Connected Autonomous Vehicles</title>
      <link>https://arxiv.org/abs/2503.20462</link>
      <description>arXiv:2503.20462v1 Announce Type: new 
Abstract: Deep Reinforcement Learning (DRL) holds significant promise for achieving human-like Autonomous Vehicle (AV) capabilities, but suffers from low sample efficiency and challenges in reward design. Model-Based Reinforcement Learning (MBRL) offers improved sample efficiency and generalizability compared to Model-Free Reinforcement Learning (MFRL) in various multi-agent decision-making scenarios. Nevertheless, MBRL faces critical difficulties in estimating uncertainty during the model learning phase, thereby limiting its scalability and applicability in real-world scenarios. Additionally, most Connected Autonomous Vehicle (CAV) studies focus on single-agent decision-making, while existing multi-agent MBRL solutions lack computationally tractable algorithms with Probably Approximately Correct (PAC) guarantees, an essential factor for ensuring policy reliability with limited training data. To address these challenges, we propose MA-PMBRL, a novel Multi-Agent Pessimistic Model-Based Reinforcement Learning framework for CAVs, incorporating a max-min optimization approach to enhance robustness and decision-making. To mitigate the inherent subjectivity of uncertainty estimation in MBRL and avoid incurring catastrophic failures in AV, MA-PMBRL employs a pessimistic optimization framework combined with Projected Gradient Descent (PGD) for both model and policy learning. MA-PMBRL also employs general function approximations under partial dataset coverage to enhance learning efficiency and system-level performance. By bounding the suboptimality of the resulting policy under mild theoretical assumptions, we successfully establish PAC guarantees for MA-PMBRL, demonstrating that the proposed framework represents a significant step toward scalable, efficient, and reliable multi-agent decision-making for CAVs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20462v1</guid>
      <category>cs.MA</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruoqi Wen, Rongpeng Li, Xing Xu, Zhifeng Zhao</dc:creator>
    </item>
    <item>
      <title>Abstracting Geo-specific Terrains to Scale Up Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2503.20078</link>
      <description>arXiv:2503.20078v1 Announce Type: cross 
Abstract: Multi-agent reinforcement learning (MARL) is increasingly ubiquitous in training dynamic and adaptive synthetic characters for interactive simulations on geo-specific terrains. Frameworks such as Unity's ML-Agents help to make such reinforcement learning experiments more accessible to the simulation community. Military training simulations also benefit from advances in MARL, but they have immense computational requirements due to their complex, continuous, stochastic, partially observable, non-stationary, and doctrine-based nature. Furthermore, these simulations require geo-specific terrains, further exacerbating the computational resources problem. In our research, we leverage Unity's waypoints to automatically generate multi-layered representation abstractions of the geo-specific terrains to scale up reinforcement learning while still allowing the transfer of learned policies between different representations. Our early exploratory results on a novel MARL scenario, where each side has differing objectives, indicate that waypoint-based navigation enables faster and more efficient learning while producing trajectories similar to those taken by expert human players in CSGO gaming environments. This research points out the potential of waypoint-based navigation for reducing the computational costs of developing and training MARL models for military training simulations, where geo-specific terrains and differing objectives are crucial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20078v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Volkan Ustun, Soham Hans, Rajay Kumar, Yunzhe Wang</dc:creator>
    </item>
    <item>
      <title>CTS-CBS: A New Approach for Multi-Agent Collaborative Task Sequencing and Path Finding</title>
      <link>https://arxiv.org/abs/2503.20324</link>
      <description>arXiv:2503.20324v1 Announce Type: cross 
Abstract: This paper addresses a generalization problem of Multi-Agent Pathfinding (MAPF), called Collaborative Task Sequencing - Multi-Agent Pathfinding (CTS-MAPF), where agents must plan collision-free paths and visit a series of intermediate task locations in a specific order before reaching their final destinations. To address this problem, we propose a new approach, Collaborative Task Sequencing - Conflict-Based Search (CTS-CBS), which conducts a two-level search. In the high level, it generates a search forest, where each tree corresponds to a joint task sequence derived from the jTSP solution. In the low level, CTS-CBS performs constrained single-agent path planning to generate paths for each agent while adhering to high-level constraints. We also provide heoretical guarantees of its completeness and optimality (or sub-optimality with a bounded parameter). To evaluate the performance of CTS-CBS, we create two datasets, CTS-MAPF and MG-MAPF, and conduct comprehensive experiments. The results show that CTS-CBS adaptations for MG-MAPF outperform baseline algorithms in terms of success rate (up to 20 times larger) and runtime (up to 100 times faster), with less than a 10% sacrifice in solution quality. Furthermore, CTS-CBS offers flexibility by allowing users to adjust the sub-optimality bound omega to balance between solution quality and efficiency. Finally, practical robot tests demonstrate the algorithm's applicability in real-world scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20324v1</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junkai Jiang, Ruochen Li, Yibin Yang, Yihe Chen, Yuning Wang, Shaobing Xu, Jianqiang Wang</dc:creator>
    </item>
    <item>
      <title>A multi-agentic framework for real-time, autonomous freeform metasurface design</title>
      <link>https://arxiv.org/abs/2503.20479</link>
      <description>arXiv:2503.20479v1 Announce Type: cross 
Abstract: Innovation in nanophotonics currently relies on human experts who synergize specialized knowledge in photonics and coding with simulation and optimization algorithms, entailing design cycles that are time-consuming, computationally demanding, and frequently suboptimal. We introduce MetaChat, a multi-agentic design framework that can translate semantically described photonic design goals into high-performance, freeform device layouts in an automated, nearly real-time manner. Multi-step reasoning is enabled by our Agentic Iterative Monologue (AIM) paradigm, which coherently interfaces agents with code-based tools, other specialized agents, and human designers. Design acceleration is facilitated by Feature-wise Linear Modulation-conditioned Maxwell surrogate solvers that support the generalized evaluation of metasurface structures. We use freeform dielectric metasurfaces as a model system and demonstrate with MetaChat the design of multi-objective, multi-wavelength metasurfaces orders of magnitude faster than conventional methods. These concepts present a scientific computing blueprint for utilizing specialist design agents, surrogate solvers, and human interactions to drive multi-physics innovation and discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20479v1</guid>
      <category>physics.app-ph</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Lupoiu, Yixuan Shao, Tianxiang Dai, Chenkai Mao, Kofi Edee, Jonathan A. Fan</dc:creator>
    </item>
    <item>
      <title>Multi-Robot Coordination Under Physical Limitations</title>
      <link>https://arxiv.org/abs/2503.20723</link>
      <description>arXiv:2503.20723v1 Announce Type: cross 
Abstract: Multi-robot coordination is fundamental to various applications, including autonomous exploration, search and rescue, and cooperative transportation. This paper presents an optimal consensus framework for multi-robot systems (MRSs) that ensures efficient rendezvous while minimizing energy consumption and addressing actuator constraints. A critical challenge in real-world deployments is actuator limitations, particularly wheel velocity saturation, which can significantly degrade control performance. To address this issue, we incorporate Pontryagin Minimum Principle (PMP) into the control design, facilitating constrained optimization while ensuring system stability and feasibility. The resulting optimal control policy effectively balances coordination efficiency and energy consumption, even in the presence of actuation constraints. The proposed framework is validated through extensive numerical simulations and real-world experiments conducted using a team of Robotarium mobile robots. The experimental results confirm that our control strategies achieve reliable and efficient coordinated rendezvous while addressing real-world challenges such as communication delays, sensor noise, and packet loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20723v1</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tohid Kargar Tasooji, Sakineh Khodadadi</dc:creator>
    </item>
    <item>
      <title>Welfare and Cost Aggregation for Multi-Agent Control: When to Choose Which Social Cost Function, and Why?</title>
      <link>https://arxiv.org/abs/2503.20772</link>
      <description>arXiv:2503.20772v1 Announce Type: cross 
Abstract: Many multi-agent socio-technical systems rely on aggregating heterogeneous agents' costs into a social cost function (SCF) to coordinate resource allocation in domains like energy grids, water allocation, or traffic management. The choice of SCF often entails implicit assumptions and may lead to undesirable outcomes if not rigorously justified. In this paper, we demonstrate that what determines which SCF ought to be used is the degree to which individual costs can be compared across agents and which axioms the aggregation shall fulfill. Drawing on the results from social choice theory, we provide guidance on how this process can be used in control applications. We demonstrate which assumptions about interpersonal utility comparability -- ranging from ordinal level comparability to full cardinal comparability -- together with a choice of desirable axioms, inform the selection of a correct SCF, be it the classical utilitarian sum, the Nash SCF, or maximin. We then demonstrate how the proposed framework can be applied for principled allocations of water and transportation resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20772v1</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilia Shilov, Ezzat Elokda, Sophie Hall, Heinrich H. Nax, Saverio Bolognani</dc:creator>
    </item>
    <item>
      <title>FREIDA: A Framework for developing quantitative agent based models based on qualitative expert knowledge: an example of organised crime</title>
      <link>https://arxiv.org/abs/2308.00505</link>
      <description>arXiv:2308.00505v2 Announce Type: replace-cross 
Abstract: Developing ABMs of organized crime networks supports law enforcement strategies but is often limited by scarce quantitative data. This challenge extends to other psychosocial contexts like mental health and social systems. While qualitative data from reports and interviews is more accessible, current ABM methodologies struggle to integrate both data types effectively. To address this, we propose FREIDA, a mixed-methods framework that combines qualitative and quantitative data to develop, train, and validate ABMs in data-sparse contexts. FREIDA's four-phase process includes data acquisition, conceptual modeling, computational implementation, and model assessment. Using Thematic Content Analysis (TCA), Expected System Behaviors (ESBs) are translated into Training Statements (TS) for calibration and Validation Statements (VS) for assessment. Iterative sensitivity analysis and uncertainty quantification refine the model's accuracy. We apply FREIDA to a case study of the Netherlands cocaine network, producing the Criminal Cocaine Replacement Model (CCRM) to simulate kingpin removal dynamics. FREIDA enables robust ABM development with limited data, aiding law enforcement decisions and resource allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.00505v2</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederike Oetker, Vittorio Nespeca, Rick Quax</dc:creator>
    </item>
    <item>
      <title>An Accelerated Distributed Stochastic Gradient Method with Momentum</title>
      <link>https://arxiv.org/abs/2402.09714</link>
      <description>arXiv:2402.09714v3 Announce Type: replace-cross 
Abstract: In this paper, we introduce an accelerated distributed stochastic gradient method with momentum for solving the distributed optimization problem, where a group of $n$ agents collaboratively minimize the average of the local objective functions over a connected network. The method, termed ``Distributed Stochastic Momentum Tracking (DSMT)'', is a single-loop algorithm that utilizes the momentum tracking technique as well as the Loopless Chebyshev Acceleration (LCA) method. We show that DSMT can asymptotically achieve comparable convergence rates as centralized stochastic gradient descent (SGD) method under a general variance condition regarding the stochastic gradients. Moreover, the number of iterations (transient times) required for DSMT to achieve such rates behaves as $\mathcal{O}(n^{5/3}/(1-\lambda))$ for minimizing general smooth objective functions, and $\mathcal{O}(\sqrt{n/(1-\lambda)})$ under the Polyak-{\L}ojasiewicz (PL) condition. Here, the term $1-\lambda$ denotes the spectral gap of the mixing matrix related to the underlying network topology. Notably, the obtained results do not rely on multiple inter-node communications or stochastic gradient accumulation per iteration, and the transient times are the shortest under the setting to the best of our knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09714v3</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kun Huang, Shi Pu, Angelia Nedi\'c</dc:creator>
    </item>
    <item>
      <title>TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models</title>
      <link>https://arxiv.org/abs/2403.17246</link>
      <description>arXiv:2403.17246v2 Announce Type: replace-cross 
Abstract: Classical planning formulations like the Planning Domain Definition Language (PDDL) admit action sequences guaranteed to achieve a goal state given an initial state if any are possible. However, reasoning problems defined in PDDL do not capture temporal aspects of action taking, such as concurrent actions between two agents when there are no conflicting conditions, without significant modification and definition to existing PDDL domains. A human expert aware of such constraints can decompose a goal into subgoals, each reachable through single agent planning, to take advantage of simultaneous actions. In contrast to classical planning, large language models (LLMs) directly used for inferring plan steps rarely guarantee execution success, but are capable of leveraging commonsense reasoning to assemble action sequences. We combine the strengths of both classical planning and LLMs by approximating human intuitions for multi-agent planning goal decomposition. We demonstrate that LLM-based goal decomposition leads to faster planning times than solving multi-agent PDDL problems directly while simultaneously achieving fewer plan execution steps than a single agent plan alone, as well as most multiagent plans, while guaranteeing execution success. Additionally, we find that LLM-based approximations of subgoals result in similar multi-agent execution lengths to those specified by human experts. Website and resources at https://glamor-usc.github.io/twostep</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17246v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Bai, Ishika Singh, David Traum, Jesse Thomason</dc:creator>
    </item>
    <item>
      <title>Fully Distributed Fog Load Balancing with Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2405.12236</link>
      <description>arXiv:2405.12236v2 Announce Type: replace-cross 
Abstract: Real-time Internet of Things (IoT) applications require real-time support to handle the ever-growing demand for computing resources to process IoT workloads. Fog Computing provides high availability of such resources in a distributed manner. However, these resources must be efficiently managed to distribute unpredictable traffic demands among heterogeneous Fog resources. This paper proposes a fully distributed load-balancing solution with Multi-Agent Reinforcement Learning (MARL) that intelligently distributes IoT workloads to optimize the waiting time while providing fair resource utilization in the Fog network. These agents use transfer learning for life-long self-adaptation to dynamic changes in the environment. By leveraging distributed decision-making, MARL agents effectively minimize the waiting time compared to a single centralized agent solution and other baselines, enhancing end-to-end execution delay. Besides performance gain, a fully distributed solution allows for a global-scale implementation where agents can work independently in small collaboration regions, leveraging nearby local resources. Furthermore, we analyze the impact of a realistic frequency to observe the state of the environment, unlike the unrealistic common assumption in the literature of having observations readily available in real-time for every required action. The findings highlight the trade-off between realism and performance using an interval-based Gossip-based multi-casting protocol against assuming real-time observation availability for every generated workload.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12236v2</guid>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maad Ebrahim, Abdelhakim Hafid</dc:creator>
    </item>
  </channel>
</rss>
