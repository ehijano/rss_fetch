<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 Jan 2025 02:37:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Gain modulation of actions selection without synaptic relearning</title>
      <link>https://arxiv.org/abs/2501.01964</link>
      <description>arXiv:2501.01964v1 Announce Type: new 
Abstract: Adaptation of behavior requires the brain to change goals in a changing environment. Synaptic learning has demonstrated its effectiveness in changing the probability of selecting actions based on their outcome. In the extreme case, it is vital not to repeat an action to a given goal that led to harmful punishment. The present model proposes a simple neural mechanism of gain modulation that makes possible immediate changes in the probability of selecting a goal after punishment of variable intensity. Results show how gain modulation determine the type of elementary navigation process within the state space of a network of neuronal populations of excitatory neurons regulated by inhibition. Immediately after punishment, the system can avoid the punished populations by going back or by jumping to unpunished populations. This does not require particular credit assignment at the `choice' population but only gain modulation of neurons active at the time of punishment. Gain modulation does not require statistical relearning that may lead to further errors, but can encode memories of past experiences without modification of synaptic efficacies. Therefore, gain modulation can complements synaptic plasticity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01964v1</guid>
      <category>q-bio.NC</category>
      <category>math.DS</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elif K\"oksal-Ers\"oz (COPHY), Pascal Chossat (MATHNEURO, LJAD), Fr\'ed\'eric Lavigne (BCL)</dc:creator>
    </item>
    <item>
      <title>The impact of motor and non-motor symptoms fluctuations on health-related quality of life in people with functional motor disorder</title>
      <link>https://arxiv.org/abs/2501.01966</link>
      <description>arXiv:2501.01966v1 Announce Type: new 
Abstract: Objective: To assess the effect of overall, between- and within-day subjectively rated fluctuations in motor and non-motor symptoms in people with functional motor disorder (FMD) on the health-related quality of life (HRQoL).
  Background: FMD is a complex condition characterized by fluctuating motor and non-motor symptoms that may negatively impact HRQoL.
  Methods: Seventy-seven patients (54 females, mean age 45.4 (SD 10.4) years) with a clinically established diagnosis of FMD, including weakness, completed symptom diaries, rating the severity of motor and non-motor symptoms (i.e., pain, fatigue, mood, cognitive difficulties) on a 10-point numerical scale three times daily for seven consecutive days. HRQoL was assessed using the SF-36 questionnaire. For the analysis, fluctuation magnitude was defined in terms of the variability in self-reported symptom scores.
  Results: The mental component of SF-36 was jointly predicted by the overall severity scores (P&lt;0.001) and overall general fluctuations (P=0.004). The physical SF-36 was found to be related only to the overall symptom severity scores (P&lt;0.001), but not to the overall fluctuations. The assessment of the impact of different components showed that the mental component of SF-36 was significantly influenced by the combined effect of average fatigue (P&lt;0.001), between-day cognitive symptoms fluctuations (P=0.002), and within-day mood fluctuations (P=0.015).
  Conclusions: This study demonstrated the impact of self-reported symptom fluctuations across multiple motor and non-motor domains on mental but not physical HRQoL in FMD and highlighted the importance of assessing and managing fluctuations in clinical practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01966v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Jir\'asek (Department of Neurology and Center of Clinical Neuroscience, First Faculty of Medicine, Charles University and General University Hospital in Prague, Prague/Czech Republic, Department of Rehabilitation and Sports Medicine, Second Faculty of Medicine, Charles University and University Hospital Motol, Prague/Czech Republic), Tom\'a\v{s} Sieger (Department of Neurology and Center of Clinical Neuroscience, First Faculty of Medicine, Charles University and General University Hospital in Prague, Prague/Czech Republic, Department of Cybernetics, Faculty of Electrical Engineering, Czech Technical University, Prague/Czech Republic), Gabriela Chaloupkov\'a (Department of Neurology and Center of Clinical Neuroscience, First Faculty of Medicine, Charles University and General University Hospital in Prague, Prague/Czech Republic), Lucia Nov\'akov\'a (Department of Neurology and Center of Clinical Neuroscience, First Faculty of Medicine, Charles University and General University Hospital in Prague, Prague/Czech Republic), Petr Sojka (Department of Neurology and Center of Clinical Neuroscience, First Faculty of Medicine, Charles University and General University Hospital in Prague, Prague/Czech Republic), Mark J Edwards (King's College London, Institute of Psychiatry, Psychology &amp; Neuroscience, Department of Basic &amp; Clinical Neuroscience, London/United Kingdom), Tereza Serranov\'a (Department of Neurology and Center of Clinical Neuroscience, First Faculty of Medicine, Charles University and General University Hospital in Prague, Prague/Czech Republic)</dc:creator>
    </item>
    <item>
      <title>On The Causal Network Of Face-selective Regions In Human Brain During Movie Watching</title>
      <link>https://arxiv.org/abs/2501.02333</link>
      <description>arXiv:2501.02333v1 Announce Type: new 
Abstract: Understanding the causal interactions in simple brain tasks, such as face detection, remains a challenging and ambiguous process for researchers. In this study, we address this issue by employing a novel causal discovery method -- Directed Acyclic Graphs via M-matrices for Acyclicity (DAGMA) -- to investigate the causal structure of the brain's face-selective network and gain deeper insights into its mechanism. Using natural movie stimuli, we extract causal network of face-selective regions and analyze how frames containing faces influence this network. Our findings reveal that the presence of faces in the stimuli have causal effect both on the number and strength of causal connections within the network. Additionally, our results highlight the crucial role of subcortical regions in satisfying causal sufficiency, emphasizing its importance in causal studies of brain. This study provides a new perspective on understanding the causal architecture of the face-selective network of the brain, motivating further research on neural causality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02333v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Bavafa, Gholam-Ali Hossein-Zadeh</dc:creator>
    </item>
    <item>
      <title>Asynchronous Hebbian/anti-Hebbian networks</title>
      <link>https://arxiv.org/abs/2501.02402</link>
      <description>arXiv:2501.02402v1 Announce Type: new 
Abstract: Lateral inhibition models coupled with Hebbian plasticity have been shown to learn factorised causal representations of input stimuli, for instance, oriented edges are learned from natural images. Currently, these models require the recurrent dynamics to settle into a stable state before weight changes can be applied, which is not only biologically implausible, but also impractical for real-time learning systems. Here, we propose a new Hebbian learning rule which is implemented using plausible biological mechanisms that have been observed experimentally. We find that this rule allows for efficient, time-continuous learning of factorised representations, very similar to the classic noncontinuous Hebbian/anti-Hebbian learning. Furthermore, we show that this rule naturally prevents catastrophic forgetting when stimuli from different distributions are shown sequentially.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02402v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henrique Reis Aguiar, Matthias H. Hennig</dc:creator>
    </item>
    <item>
      <title>Key-value memory in the brain</title>
      <link>https://arxiv.org/abs/2501.02950</link>
      <description>arXiv:2501.02950v1 Announce Type: new 
Abstract: Classical models of memory in psychology and neuroscience rely on similarity-based retrieval of stored patterns, where similarity is a function of retrieval cues and the stored patterns. While parsimonious, these models do not allow distinct representations for storage and retrieval, despite their distinct computational demands. Key-value memory systems, in contrast, distinguish representations used for storage (values) and those used for retrieval (keys). This allows key-value memory systems to optimize simultaneously for fidelity in storage and discriminability in retrieval. We review the computational foundations of key-value memory, its role in modern machine learning systems, related ideas from psychology and neuroscience, applications to a number of empirical puzzles, and possible biological implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02950v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel J. Gershman, Ila Fiete, Kazuki Irie</dc:creator>
    </item>
    <item>
      <title>Inverse receptive field attention for naturalistic image reconstruction from the brain</title>
      <link>https://arxiv.org/abs/2501.03051</link>
      <description>arXiv:2501.03051v1 Announce Type: new 
Abstract: Visual perception in the brain largely depends on the organization of neuronal receptive fields. Although extensive research has delineated the coding principles of receptive fields, most studies have been constrained by their foundational assumptions. Moreover, while machine learning has successfully been used to reconstruct images from brain data, this approach faces significant challenges, including inherent feature biases in the model and the complexities of brain structure and function. In this study, we introduce an inverse receptive field attention (IRFA) model, designed to reconstruct naturalistic images from neurophysiological data in an end-to-end fashion. This approach aims to elucidate the tuning properties and representational transformations within the visual cortex. The IRFA model incorporates an attention mechanism that determines the inverse receptive field for each pixel, weighting neuronal responses across the visual field and feature spaces. This method allows for an examination of the dynamics of neuronal representations across stimuli in both spatial and feature dimensions. Our results show highly accurate reconstructions of naturalistic data, independent of pre-trained models. Notably, IRF models trained on macaque V1, V4, and IT regions yield remarkably consistent spatial receptive fields across different stimuli, while the features to which neuronal representations are selective exhibit significant variation. Additionally, we propose a data-driven method to explore representational clustering within various visual areas, further providing testable hypotheses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03051v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lynn Le, Thirza Dado, Katja Seeliger, Paolo Papale, Antonio Lozano, Pieter Roelfsema, Ya\u{g}mur G\"u\c{c}l\"ut\"urk, Marcel van Gerven, Umut G\"u\c{c}l\"u</dc:creator>
    </item>
    <item>
      <title>Digging into CTM's consciousness: A possible mechanism for CTM generating self-conscious</title>
      <link>https://arxiv.org/abs/2501.03062</link>
      <description>arXiv:2501.03062v1 Announce Type: new 
Abstract: Based on the former work Conscious Turing Machine, in this paper, we attempt to talk about the consciousness of CTM, dig deeper into the self-consciousness in CTM, offer a clear definition of it, and design a possible model of the Model-of-the-World processor. To prove the consciousness of CTM does exist, we chose two definitions of human consciousness and extracted four key points to see if the CTM framework meets with them. If it does, we affirm that it's more likely to be able to generate consciousness. About self-consciousness, our definition of it refers to both the definition of conscious awareness in CTM and former studies about the duality of self. After that, we give a brief introduction to a possible model of MoTW processors including five important parts: Modeling function, Gist function, Value function, Cache, and Long term memory. Finally, we use some illusions and disorders to explain our MotW processor model, trying to understand how these illusions work on a CTM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03062v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaoyang Cui, Shanglin Wu, Nikolai Madlener</dc:creator>
    </item>
    <item>
      <title>Plasma-CycleGAN: Plasma Biomarker-Guided MRI to PET Cross-modality Translation Using Conditional CycleGAN</title>
      <link>https://arxiv.org/abs/2501.02146</link>
      <description>arXiv:2501.02146v1 Announce Type: cross 
Abstract: Cross-modality translation between MRI and PET imaging is challenging due to the distinct mechanisms underlying these modalities. Blood-based biomarkers (BBBMs) are revolutionizing Alzheimer's disease (AD) detection by identifying patients and quantifying brain amyloid levels. However, the potential of BBBMs to enhance PET image synthesis remains unexplored. In this paper, we performed a thorough study on the effect of incorporating BBBM into deep generative models. By evaluating three widely used cross-modality translation models, we found that BBBMs integration consistently enhances the generative quality across all models. By visual inspection of the generated results, we observed that PET images generated by CycleGAN exhibit the best visual fidelity. Based on these findings, we propose Plasma-CycleGAN, a novel generative model based on CycleGAN, to synthesize PET images from MRI using BBBMs as conditions. This is the first approach to integrate BBBMs in conditional cross-modality translation between MRI and PET.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02146v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanxi Chen, Yi Su, Celine Dumitrascu, Kewei Chen, David Weidman, Richard J Caselli, Nicholas Ashton, Eric M Reiman, Yalin Wang</dc:creator>
    </item>
    <item>
      <title>A ghost mechanism: An analytical model of abrupt learning</title>
      <link>https://arxiv.org/abs/2501.02378</link>
      <description>arXiv:2501.02378v1 Announce Type: cross 
Abstract: \emph{Abrupt learning} is commonly observed in neural networks, where long plateaus in network performance are followed by rapid convergence to a desirable solution. Yet, despite its common occurrence, the complex interplay of task, network architecture, and learning rule has made it difficult to understand the underlying mechanisms. Here, we introduce a minimal dynamical system trained on a delayed-activation task and demonstrate analytically how even a one-dimensional system can exhibit abrupt learning through ghost points rather than bifurcations. Through our toy model, we show that the emergence of a ghost point destabilizes learning dynamics. We identify a critical learning rate that prevents learning through two distinct loss landscape features: a no-learning zone and an oscillatory minimum. Testing these predictions in recurrent neural networks (RNNs), we confirm that ghost points precede abrupt learning and accompany the destabilization of learning. We demonstrate two complementary remedies: lowering the model output confidence prevents the network from getting stuck in no-learning zones, while increasing trainable ranks beyond task requirements (\textit{i.e.}, adding sloppy parameters) provides more stable learning trajectories. Our model reveals a bifurcation-free mechanism for abrupt learning and illustrates the importance of both deliberate uncertainty and redundancy in stabilizing learning dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02378v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fatih Dinc, Ege Cirakman, Yiqi Jiang, Mert Yuksekgonul, Mark J. Schnitzer, Hidenori Tanaka</dc:creator>
    </item>
    <item>
      <title>A Bio-Inspired Research Paradigm of Collision Perception Neurons Enabling Neuro-Robotic Integration: The LGMD Case</title>
      <link>https://arxiv.org/abs/2501.02982</link>
      <description>arXiv:2501.02982v1 Announce Type: cross 
Abstract: Compared to human vision, insect visual systems excel at rapid and precise collision detection, despite relying on only tens of thousands of neurons organized through a few neuropils. This efficiency makes them an attractive model system for developing artificial collision-detecting systems. Specifically, researchers have identified collision-selective neurons in the locust's optic lobe, called lobula giant movement detectors (LGMDs), which respond specifically to approaching objects. Research upon LGMD neurons began in the early 1970s. Initially, due to their large size, these neurons were identified as motion detectors, but their role as looming detectors was recognized over time. Since then, progress in neuroscience, computational modeling of LGMD's visual neural circuits, and LGMD-based robotics has advanced in tandem, each field supporting and driving the others. Today, with a deeper understanding of LGMD neurons, LGMD-based models have significantly improved collision-free navigation in mobile robots including ground and aerial robots. This review highlights recent developments in LGMD research from the perspectives of neuroscience, computational modeling, and robotics. It emphasizes a biologically plausible research paradigm, where insights from neuroscience inform real-world applications, which would in turn validate and advance neuroscience. With strong support from extensive research and growing application demand, this paradigm has reached a mature stage and demonstrates versatility across different areas of neuroscience research, thereby enhancing our understanding of the interconnections between neuroscience, computational modeling, and robotics. Furthermore, other motion-sensitive neurons have also shown promising potential for adopting this research paradigm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02982v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ziyan Qin, Jigen Peng, Shigang Yue, Qinbing Fu</dc:creator>
    </item>
    <item>
      <title>Brain-Inspired AI with Hyperbolic Geometry</title>
      <link>https://arxiv.org/abs/2409.12990</link>
      <description>arXiv:2409.12990v2 Announce Type: replace 
Abstract: Artificial neural networks (ANNs) were inspired by the architecture and functions of the human brain and have revolutionised the field of artificial intelligence (AI). Inspired by studies on the latent geometry of the brain, in this perspective paper we posit that an increase in the research and application of hyperbolic geometry in ANNs and machine learning will lead to increased accuracy, improved feature space representations and more efficient models across a range of tasks. We examine the structure and functions of the human brain, emphasising the correspondence between its scale-free hierarchical organization and hyperbolic geometry, and reflecting on the central role hyperbolic geometry plays in facilitating human intelligence. Empirical evidence indicates that hyperbolic neural networks outperform Euclidean models for tasks including natural language processing, computer vision and complex network analysis, requiring fewer parameters and exhibiting better generalisation. Despite its nascent adoption, hyperbolic geometry holds promise for improving machine learning models through brain-inspired geometric representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12990v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Joseph, Nathan Francis, Meijke Balay</dc:creator>
    </item>
    <item>
      <title>Active learning of neural population dynamics using two-photon holographic optogenetics</title>
      <link>https://arxiv.org/abs/2412.02529</link>
      <description>arXiv:2412.02529v2 Announce Type: replace 
Abstract: Recent advances in techniques for monitoring and perturbing neural populations have greatly enhanced our ability to study circuits in the brain. In particular, two-photon holographic optogenetics now enables precise photostimulation of experimenter-specified groups of individual neurons, while simultaneous two-photon calcium imaging enables the measurement of ongoing and induced activity across the neural population. Despite the enormous space of potential photostimulation patterns and the time-consuming nature of photostimulation experiments, very little algorithmic work has been done to determine the most effective photostimulation patterns for identifying the neural population dynamics. Here, we develop methods to efficiently select which neurons to stimulate such that the resulting neural responses will best inform a dynamical model of the neural population activity. Using neural population responses to photostimulation in mouse motor cortex, we demonstrate the efficacy of a low-rank linear dynamical systems model, and develop an active learning procedure which takes advantage of low-rank structure to determine informative photostimulation patterns. We demonstrate our approach on both real and synthetic data, obtaining in some cases as much as a two-fold reduction in the amount of data required to reach a given predictive power. Our active stimulation design method is based on a novel active learning procedure for low-rank regression, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02529v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Wagenmaker, Lu Mi, Marton Rozsa, Matthew S. Bull, Karel Svoboda, Kayvon Daie, Matthew D. Golub, Kevin Jamieson</dc:creator>
    </item>
    <item>
      <title>The Algonauts Project 2025 Challenge: How the Human Brain Makes Sense of Multimodal Movies</title>
      <link>https://arxiv.org/abs/2501.00504</link>
      <description>arXiv:2501.00504v2 Announce Type: replace 
Abstract: There is growing symbiosis between artificial and biological intelligence sciences: neural principles inspire new intelligent machines, which are in turn used to advance our theoretical understanding of the brain. To promote further collaboration between biological and artificial intelligence researchers, we introduce the 2025 edition of the Algonauts Project challenge: How the Human Brain Makes Sense of Multimodal Movies (https://algonautsproject.com/). In collaboration with the Courtois Project on Neuronal Modelling (CNeuroMod), this edition aims to bring forth a new generation of brain encoding models that are multimodal and that generalize well beyond their training distribution, by training them on the largest dataset of fMRI responses to movie watching available to date. Open to all, the 2025 challenge provides transparent, directly comparable results through a public leaderboard that is updated automatically after each submission to facilitate rapid model assessment and guide development. The challenge will end with a session at the 2025 Cognitive Computational Neuroscience (CCN) conference that will feature winning models. We welcome researchers interested in collaborating with the Algonauts Project by contributing ideas and datasets for future challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00504v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro T. Gifford, Domenic Bersch, Marie St-Laurent, Basile Pinsard, Julie Boyle, Lune Bellec, Aude Oliva, Gemma Roig, Radoslaw M. Cichy</dc:creator>
    </item>
    <item>
      <title>A Robotics-Inspired Scanpath Model Reveals the Importance of Uncertainty and Semantic Object Cues for Gaze Guidance in Dynamic Scenes</title>
      <link>https://arxiv.org/abs/2408.01322</link>
      <description>arXiv:2408.01322v2 Announce Type: replace-cross 
Abstract: The objects we perceive guide our eye movements when observing real-world dynamic scenes. Yet, gaze shifts and selective attention are critical for perceiving details and refining object boundaries. Object segmentation and gaze behavior are, however, typically treated as two independent processes. Here, we present a computational model that simulates these processes in an interconnected manner and allows for hypothesis-driven investigations of distinct attentional mechanisms. Drawing on an information processing pattern from robotics, we use a Bayesian filter to recursively segment the scene, which also provides an uncertainty estimate for the object boundaries that we use to guide active scene exploration. We demonstrate that this model closely resembles observers' free viewing behavior on a dataset of dynamic real-world scenes, measured by scanpath statistics, including foveation duration and saccade amplitude distributions used for parameter fitting and higher-level statistics not used for fitting. These include how object detections, inspections, and returns are balanced and a delay of returning saccades without an explicit implementation of such temporal inhibition of return. Extensive simulations and ablation studies show that uncertainty promotes balanced exploration and that semantic object cues are crucial to forming the perceptual units used in object-based attention. Moreover, we show how our model's modular design allows for extensions, such as incorporating saccadic momentum or pre-saccadic attention, to further align its output with human scanpaths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01322v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vito Mengers, Nicolas Roth, Oliver Brock, Klaus Obermayer, Martin Rolfs</dc:creator>
    </item>
  </channel>
</rss>
