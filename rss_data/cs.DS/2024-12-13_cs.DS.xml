<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Dec 2024 05:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Differential Privacy Releasing of Hierarchical Origin/Destination Data with a TopDown Approach</title>
      <link>https://arxiv.org/abs/2412.09256</link>
      <description>arXiv:2412.09256v1 Announce Type: new 
Abstract: This paper presents a novel method to generate differentially private tabular datasets for hierarchical data, with a specific focus on origin-destination (O/D) trips. The approach builds upon the TopDown algorithm, a constraint-based mechanism designed to incorporate invariant queries into tabular data, developed by the US Census. O/D hierarchical data refers to datasets representing trips between geographical areas organized in a hierarchical structure (e.g., region $\rightarrow$ province $\rightarrow$ city). The developed method is crafted to improve accuracy on queries spanning wider geographical areas that can be obtained by aggregation. Maintaining high accuracy for aggregated geographical queries is a crucial attribute of the differentially private dataset, particularly for practitioners. Furthermore, the approach is designed to minimize false positives detection and to replicate the sparsity of the sensitive data. The key technical contributions of this paper include a novel TopDown algorithm that employs constrained optimization with Chebyshev distance minimization, with theoretical guarantees based on the maximum absolute error. Additionally, we propose a new integer optimization algorithm that significantly reduces the incidence of false positives. The effectiveness of the proposed approach is validated using both real-world and synthetic O/D datasets, demonstrating its ability to generate private data with high utility and a reduced number of false positives. We emphasize that the proposed algorithm is applicable to any tabular data with a hierarchical structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09256v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabrizio Boninsegna, Francesco Silvestri</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Survey of Data Reduction Rules for the Maximum Weighted Independent Set Problem</title>
      <link>https://arxiv.org/abs/2412.09303</link>
      <description>arXiv:2412.09303v1 Announce Type: new 
Abstract: The Maximum Weight Independent Set (MWIS) problem, as well as its related problems such as Minimum Weight Vertex Cover, are fundamental NP-hard problems with numerous practical applications. Due to their computational complexity, a variety of data reduction rules have been proposed in recent years to simplify instances of these problems, enabling exact solvers and heuristics to handle them more effectively. Data reduction rules are polynomial time procedures that can reduce an instance while ensuring that an optimal solution on the reduced instance can be easily extended to an optimal solution for the original instance. Data reduction rules have proven to be especially useful in branch-and-reduce methods, where successful reductions often lead to problem instances that can be solved exactly. This survey provides a comprehensive overview of data reduction rules for the MWIS problem. We also provide a reference implementation for these reductions. This survey will be updated as new reduction techniques are developed, serving as a centralized resource for researchers and practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09303v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ernestine Gro{\ss}mann, Kenneth Langedal, Christian Schulz</dc:creator>
    </item>
    <item>
      <title>Temporal Triadic Closure: Finding Dense Structures in Social Networks That Evolve</title>
      <link>https://arxiv.org/abs/2412.09567</link>
      <description>arXiv:2412.09567v1 Announce Type: new 
Abstract: A graph G is c-closed if every two vertices with at least c common neighbors are adjacent to each other. Introduced by Fox, Roughgarden, Seshadhri, Wei and Wein [ICALP 2018, SICOMP 2020], this definition is an abstraction of the triadic closure property exhibited by many real-world social networks, namely, friends of friends tend to be friends themselves. Social networks, however, are often temporal rather than static -- the connections change over a period of time. And hence temporal graphs, rather than static graphs, are often better suited to model social networks. Motivated by this, we introduce a definition of temporal c-closed graphs, in which if two vertices u and v have at least c common neighbors during a short interval of time, then u and v are adjacent to each other around that time. Our pilot experiments show that several real-world temporal networks are c-closed for rather small values of c. We also study the computational problems of enumerating maximal cliques and similar dense subgraphs in temporal c-closed graphs; a clique in a temporal graph is a subgraph that lasts for a certain period of time, during which every possible edge in the subgraph becomes active often enough, and other dense subgraphs are defined similarly. We bound the number of such maximal dense subgraphs in a temporal c-closed graph that evolves slowly, and thus show that the corresponding enumeration problems admit efficient algorithms; by slow evolution, we mean that between consecutive time-steps, the local change in adjacencies remains small. Our work also adds to a growing body of literature on defining suitable structural parameters for temporal graphs that can be leveraged to design efficient algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09567v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.SI</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom Davot, Jessica Enright, Jayakrishnan Madathil, Kitty Meeks</dc:creator>
    </item>
    <item>
      <title>Parsing Millions of DNS Records per Second</title>
      <link>https://arxiv.org/abs/2411.12035</link>
      <description>arXiv:2411.12035v2 Announce Type: replace 
Abstract: The Domain Name System (DNS) plays a critical role in the functioning of the Internet. It provides a hierarchical name space for locating resources. Data is typically stored in plain text files, possibly spanning gigabytes. Frequent parsing of these files to refresh the data is computationally expensive: processing a zone file can take minutes.
  We propose a novel approach called simdzone to enhance DNS parsing throughput. We use data parallelism, specifically the Single Instruction Multiple Data (SIMD) instructions available on commodity processors. We show that we can multiply the parsing speed compared to state-of-the-art parsers found in Knot DNS and the NLnet Labs Name Server Daemon (NSD). The resulting software library replaced the parser in NSD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12035v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1002/spe.339</arxiv:DOI>
      <dc:creator>Jeroen Koekkoek, Daniel Lemire</dc:creator>
    </item>
    <item>
      <title>Parallel simulation for sampling under isoperimetry and score-based diffusion models</title>
      <link>https://arxiv.org/abs/2412.07435</link>
      <description>arXiv:2412.07435v2 Announce Type: replace 
Abstract: In recent years, there has been a surge of interest in proving discretization bounds for sampling under isoperimetry and for diffusion models. As data size grows, reducing the iteration cost becomes an important goal. Inspired by the great success of the parallel simulation of the initial value problem in scientific computation, we propose parallel Picard methods for sampling tasks. Rigorous theoretical analysis reveals that our algorithm achieves better dependence on dimension $d$ than prior works in iteration complexity (i.e., reduced from $\widetilde{O}(\log^2 d)$ to $\widetilde{O}(\log d)$), which is even optimal for sampling under isoperimetry with specific iteration complexity. Our work highlights the potential advantages of simulation methods in scientific computation for dynamics-based sampling and diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07435v2</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huanjian Zhou, Masashi Sugiyama</dc:creator>
    </item>
    <item>
      <title>Randomized matrix-free quadrature: unified and uniform bounds for stochastic Lanczos quadrature and the kernel polynomial method</title>
      <link>https://arxiv.org/abs/2204.01941</link>
      <description>arXiv:2204.01941v3 Announce Type: replace-cross 
Abstract: We analyze randomized matrix-free quadrature algorithms for spectrum and spectral sum approximation. The algorithms studied include the kernel polynomial method and stochastic Lanczos quadrature, two widely used methods for these tasks. Our analysis of spectrum approximation unifies and simplifies several one-off analyses for these algorithms which have appeared over the past decade. In addition, we derive bounds for spectral sum approximation which guarantee that, with high probability, the algorithms are simultaneously accurate on all bounded analytic functions. Finally, we provide comprehensive and complimentary numerical examples. These examples illustrate some of the qualitative similarities and differences between the algorithms, as well as relative drawbacks and benefits to their use on different types of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.01941v3</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tyler Chen, Thomas Trogdon, Shashanka Ubaru</dc:creator>
    </item>
    <item>
      <title>Learning $k$-body Hamiltonians via compressed sensing</title>
      <link>https://arxiv.org/abs/2410.18928</link>
      <description>arXiv:2410.18928v2 Announce Type: replace-cross 
Abstract: We study the problem of learning a $k$-body Hamiltonian with $M$ unknown Pauli terms that are not necessarily geometrically local. We propose a protocol that learns the Hamiltonian to precision $\epsilon$ with total evolution time ${\mathcal{O}}(M^{1/2+1/p}/\epsilon)$ up to logarithmic factors, where the error is quantified by the $\ell^p$-distance between Pauli coefficients. Our learning protocol uses only single-qubit control operations and a GHZ state initial state, is non-adaptive, is robust against SPAM errors, and performs well even if $M$ and $k$ are not precisely known in advance or if the Hamiltonian is not exactly $M$-sparse. Methods from the classical theory of compressed sensing are used for efficiently identifying the $M$ terms in the Hamiltonian from among all possible $k$-body Pauli operators. We also provide a lower bound on the total evolution time needed in this learning task, and we discuss the operational interpretations of the $\ell^1$ and $\ell^2$ error metrics. In contrast to most previous works, our learning protocol requires neither geometric locality nor any other relaxed locality conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18928v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Muzhou Ma, Steven T. Flammia, John Preskill, Yu Tong</dc:creator>
    </item>
  </channel>
</rss>
