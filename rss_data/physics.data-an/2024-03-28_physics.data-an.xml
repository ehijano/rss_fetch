<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 29 Mar 2024 04:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 29 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Environmental monitoring using orbital angular momentum mode decomposition enhanced machine learning</title>
      <link>https://arxiv.org/abs/2403.19179</link>
      <description>arXiv:2403.19179v1 Announce Type: cross 
Abstract: Atmospheric interaction with light has been an area of fascination for many researchers over the last century. Environmental conditions, such as temperature and wind speed, heavily influence the complex and rapidly varying optical distortions propagating optical fields experience. The continuous random phase fluctuations commonly make deciphering the exact origins of specific optical aberrations challenging. The generation of eddies is a major contributor to atmospheric turbulence, similar in geometric structure to optical vortices that sit at the centre of OAM beams. Decomposing the received optical fields into OAM provides a unique spatial similarity that can be used to analyse turbulent channels. In this work, we present a novel mode decomposition assisted machine learning approach that reveals trainable features in the distortions of vortex beams that allow for effective environmental monitoring. This novel technique can be used reliably with Support Vector Machine regression models to measure temperature variations of 0.49C and wind speed variations of 0.029 m/s over a 36m experimental turbulent free-space channels with controllable and verifiable temperature and wind speed with short 3s measurement. The predictable nature of these findings could indicate the presence of an underlying physical relationship between environmental conditions that lead to specific eddy formation and the OAM spiral spectra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19179v1</guid>
      <category>physics.optics</category>
      <category>physics.ao-ph</category>
      <category>physics.app-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhaozhong Chen, Ultan Daly, Aleksandr Boldin, Lenny Hirsch, Mingjian Cheng, Martin P. J. Lavery</dc:creator>
    </item>
    <item>
      <title>A Constrained Spectral Approximation of Subgrid-Scale Orography on Unstructured Grids</title>
      <link>https://arxiv.org/abs/2403.19184</link>
      <description>arXiv:2403.19184v1 Announce Type: cross 
Abstract: The representation of subgrid-scale orography is a challenge in the physical parameterization of orographic gravity-wave sources in weather forecasting. A significant hurdle is encoding as much physical information with as simple a representation as possible. Other issues include scale awareness, i.e., the orographic representation has to change according to the grid cell size and usability on unstructured geodesic grids with non-quadrilateral grid cells. This work introduces a novel spectral analysis method approximating a scale-aware spectrum of subgrid-scale orography on unstructured geodesic grids. The dimension of the physical orographic data is reduced by more than two orders of magnitude in its spectral representation. Simultaneously, the power of the approximated spectrum is close to the physical value. The method is based on well-known least-squares spectral analyses. However, it is robust to the choice of the free parameters, and tuning the algorithm is generally unnecessary. Numerical experiments involving an idealized setup show that this novel spectral analysis performs significantly better than a straightforward least-squares spectral analysis in representing the physical energy of a spectrum. Studies involving real-world topographic data are conducted, and reasonable error scores within $\pm 10\%$ error relative to the maximum physical quantity of interest are achieved across different grid sizes and background wind speeds. The deterministic behavior of the method is investigated along with its principal capabilities and potential biases, and it is shown that the error scores can be iteratively improved if an optimization target is known. Discussions on the method's limitations and broader applicability conclude this work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19184v1</guid>
      <category>physics.ao-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ray Chew, Stamen Dolaptchiev, Maja-Sophie Wedel, Ulrich Achatz</dc:creator>
    </item>
    <item>
      <title>RootInteractive tool for multidimensional statistical analysis, machine learning and analytical model validation</title>
      <link>https://arxiv.org/abs/2403.19330</link>
      <description>arXiv:2403.19330v1 Announce Type: cross 
Abstract: The ALICE experiment at CERN LHC is specifically designed for investigating heavy ion collisions. The upgraded ALICE accommodates a tenfold increase in PbPb luminosity and a two-order of magnitude surge in minimum bias events. To address the challenges of high detector occupancy and event pile-ups, advanced multidimensional data analysis techniques, including machine learning (ML), are indispensable. Despite ML popularity, the complexity of its models presents interpretation challenges, and oversimplification in analysis often leads to inaccuracies.
  Our objective was to develop RootInteractive, a tool for multidimensional statistical analysis. This tool simplifies data analysis across dimensions, visualizes functions with uncertainties, and validates assumptions and approximations. In RootInteractive, it is crucial to easily define the functional composition of analytical parametric and non-parametric functions, exploit symmetries, and define multidimensional invariant functions and corresponding alarms.
  RootInteractive adopts a declarative programming paradigm, ensuring userfriendliness for experts, students, and educators. It facilitates interactive visualization, n-dimensional histogramming/projection, and information extraction on both Python,C++ server and client. Data compression, datasets with O(10 to 7) entries and O(25) attributes can be interactively analyzed in a browser with O(0.500-1 GB) size. Representative downsampling and reweighting/pre-aggregation enable the effective analysis of one year of ALICE data for various purposes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19330v1</guid>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marian Invanov, Marian Ivanov jr, Giulion Eulise</dc:creator>
    </item>
    <item>
      <title>pyMSER -- An open-source library for automatic equilibration detection in molecular simulations</title>
      <link>https://arxiv.org/abs/2403.19387</link>
      <description>arXiv:2403.19387v1 Announce Type: cross 
Abstract: Automated molecular simulations are used extensively for predicting material properties. Typically, these simulations exhibit two regimes: a dynamic equilibration part, followed by a steady state. For extracting observable properties, the simulations must first reach a steady state so that thermodynamic averages can be taken. However, as equilibration depends on simulation conditions, predicting the optimal number of simulation steps a priori is impossible. Here, we demonstrate the application of the Marginal Standard Error Rule (MSER) for automatically identifying the optimal truncation point in Grand Canonical Monte Carlo (GCMC) simulations. This novel automatic procedure determines the point in which steady state is reached, ensuring that figures-of-merits are extracted in an objective, accurate, and reproducible fashion. In the case of GCMC simulations of gas adsorption in metal-organic frameworks, we find that this methodology reduces the computational cost by up to 90%. As MSER statistics are independent of the simulation method that creates the data, this library is, in principle, applicable to any time series analysis in which equilibration truncation is required. The open-source Python implementation of our method, pyMSER, is publicly available for reuse and validation at https://github.com/IBM/pymser.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19387v1</guid>
      <category>cond-mat.mes-hall</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Felipe Lopes Oliveira, Binquan Luan, Pierre Moth\'e Esteves, Mathias Steiner, Rodrigo Neumann Barros Ferreira</dc:creator>
    </item>
    <item>
      <title>Dimensional homogeneity constrained gene expression programming for discovering governing equations</title>
      <link>https://arxiv.org/abs/2211.09679</link>
      <description>arXiv:2211.09679v3 Announce Type: replace 
Abstract: Data-driven discovery of governing equations is of great significance for helping us understand intrinsic mechanisms and build physical models. Recently, numerous highly innovative algorithms have emerged, aimed at inversely discovering the underlying governing equations from data, such as sparse regression-based methods and symbolic regression-based methods. Along this direction, a novel dimensional homogeneity constrained gene expression programming (DHC-GEP) method is proposed in this work. DHC-GEP simultaneously discovers the forms and coefficients of functions using basic mathematical operators and physical variables, without requiring pre-assumed candidate functions. The constraint of dimensional homogeneity is capable of filtering out the overfitting equations effectively. The key advantages of DHC-GEP compared to Original-GEP, including being more robust to hyperparameters, the noise level and the size of datasets, are demonstrated on two benchmark studies. Furthermore, DHC-GEP is employed to discover the unknown constitutive relations of two representative non-equilibrium flows. Galilean invariance and the second law of thermodynamics are imposed as constraints to enhance the reliability of the discovered constitutive relations. Comparisons, both quantitative and qualitative, indicate that the derived constitutive relations are more accurate than the conventional Burnett equations in a wide range of Knudsen number and Mach number, and are also applicable to the cases beyond the parameter space of the training data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.09679v3</guid>
      <category>physics.data-an</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wenjun Ma, Jun Zhang, Kaikai Feng, Haoyun Xing, Dongsheng Wen</dc:creator>
    </item>
  </channel>
</rss>
