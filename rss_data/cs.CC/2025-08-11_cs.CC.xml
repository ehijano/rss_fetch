<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Aug 2025 04:01:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Counting Martingales for Measure and Dimension in Complexity Classes</title>
      <link>https://arxiv.org/abs/2508.07619</link>
      <description>arXiv:2508.07619v1 Announce Type: new 
Abstract: This paper makes two primary contributions. First, we introduce the concept of counting martingales and use it to define counting measures, counting dimensions, and counting strong dimensions. Second, we apply these new tools to strengthen previous circuit lower bounds.
  Resource-bounded measure and dimension have traditionally focused on deterministic time and space bounds. We use counting complexity classes to develop resource-bounded counting measures and dimensions. Counting martingales are constructed using functions from the #P, SpanP, and GapP complexity classes. We show that counting martingales capture many martingale constructions in complexity theory. The resulting counting measures and dimensions are intermediate in power between the standard time-bounded and space-bounded notions, enabling finer-grained analysis where space-bounded measures are known, but time-bounded measures remain open. For example, we show that BPP has #P-dimension 0 and BQP has GapP-dimension 0.
  As our main application, we improve circuit-size lower bounds. Lutz (1992) strengthened Shannon's classic $(1-\epsilon)\frac{2^n}{n}$ lower bound (1949) to PSPACE-measure, showing that almost all problems require circuits of size $\frac{2^n}{n}\left(1+\frac{\alpha \log n}{n}\right)$, for any $\alpha &lt; 1$. We extend this result to SpanP-measure, with a proof that uses a connection through the Minimum Circuit Size Problem (MCSP) to construct a counting martingale. Our results imply that the stronger lower bound holds within the third level of the exponential-time hierarchy, whereas previously, it was only known in ESPACE. We study the #P-dimension of classical circuit complexity classes and the GapP-dimension of quantum circuit complexity classes. We also show that if one-way functions exist, then #P-dimension is strictly more powerful than P-dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07619v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>John M. Hitchcock, Adewale Sekoni, Hadi Shafei</dc:creator>
    </item>
    <item>
      <title>Computing a Fixed Point of Contraction Maps in Polynomial Queries</title>
      <link>https://arxiv.org/abs/2403.19911</link>
      <description>arXiv:2403.19911v2 Announce Type: replace 
Abstract: We give an algorithm for finding an $\epsilon$-fixed point of a contraction map $f:[0,1]^k\mapsto[0,1]^k$ under the $\ell_\infty$-norm with query complexity $O (k\log (1/\epsilon ) )$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19911v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3744738</arxiv:DOI>
      <dc:creator>Xi Chen, Yuhao Li, Mihalis Yannakakis</dc:creator>
    </item>
    <item>
      <title>AdaBoost is not an Optimal Weak to Strong Learner</title>
      <link>https://arxiv.org/abs/2301.11571</link>
      <description>arXiv:2301.11571v2 Announce Type: replace-cross 
Abstract: AdaBoost is a classic boosting algorithm for combining multiple inaccurate classifiers produced by a weak learner, to produce a strong learner with arbitrarily high accuracy when given enough training data. Determining the optimal number of samples necessary to obtain a given accuracy of the strong learner, is a basic learning theoretic question. Larsen and Ritzert (NeurIPS'22) recently presented the first provably optimal weak-to-strong learner. However, their algorithm is somewhat complicated and it remains an intriguing question whether the prototypical boosting algorithm AdaBoost also makes optimal use of training samples. In this work, we answer this question in the negative. Concretely, we show that the sample complexity of AdaBoost, and other classic variations thereof, are sub-optimal by at least one logarithmic factor in the desired accuracy of the strong learner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.11571v2</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikael M{\o}ller H{\o}gsgaard, Kasper Green Larsen, Martin Ritzert</dc:creator>
    </item>
    <item>
      <title>Combinatorial Parameterized Algorithms for Chemical Descriptors based on Molecular Graph Sparsity</title>
      <link>https://arxiv.org/abs/2303.13279</link>
      <description>arXiv:2303.13279v2 Announce Type: replace-cross 
Abstract: We present efficient combinatorial parameterized algorithms for several classical graph-based counting problems in computational chemistry, including (i) Kekule structures, (ii) the Hosoya index, (iii) the Merrifield-Simmons index, and (iv) Graph entropy based on matchings and independent sets. All these problems were known to be #P-complete. Building on the intuition that molecular graphs are often sparse and tree-like, we provide fixed-parameter tractable (FPT) algorithms using treewidth as our parameter. We also provide extensive experimental results over the entire PubChem database of chemical compounds, containing more than 113 million real-world molecules. In our experiments, we observe that the molecules are indeed sparse and tree-like, with more than 99.9% of them having a treewidth of at most 5. This justifies our choice of parameter. Our experiments also illustrate considerable improvements over the previous approaches. Based on these results, we argue that parameterized algorithms, especially based on treewidth, should be adopted as the default approach for problems in computational chemistry that are defined over molecular graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.13279v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giovanna K. Conrado, Amir K. Goharshady, Harshit J. Motwani, Sergei Novozhilov</dc:creator>
    </item>
    <item>
      <title>A Theory of Learning with Autoregressive Chain of Thought</title>
      <link>https://arxiv.org/abs/2503.07932</link>
      <description>arXiv:2503.07932v2 Announce Type: replace-cross 
Abstract: For a given base class of sequence-to-next-token generators, we consider learning prompt-to-answer mappings obtained by iterating a fixed, time-invariant generator for multiple steps, thus generating a chain-of-thought, and then taking the final token as the answer. We formalize the learning problems both when the chain-of-thought is observed and when training only on prompt-answer pairs, with the chain-of-thought latent. We analyze the sample and computational complexity both in terms of general properties of the base class (e.g. its VC dimension) and for specific base classes such as linear thresholds. We present a simple base class that allows for universal representability and computationally tractable chain-of-thought learning. Central to our development is that time invariance allows for sample complexity that is independent of the length of the chain-of-thought. Attention arises naturally in our construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07932v2</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 12 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nirmit Joshi, Gal Vardi, Adam Block, Surbhi Goel, Zhiyuan Li, Theodor Misiakiewicz, Nathan Srebro</dc:creator>
    </item>
  </channel>
</rss>
