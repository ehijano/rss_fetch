<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ML updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ML</link>
    <description>stat.ML updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ML" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Sep 2025 04:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Variance-Bounded Evaluation without Ground Truth: VB-Score</title>
      <link>https://arxiv.org/abs/2509.22751</link>
      <description>arXiv:2509.22751v1 Announce Type: new 
Abstract: Reliable evaluation is a central challenge in machine learning when tasks lack ground truth labels or involve ambiguity and noise. Conventional frameworks, rooted in the Cranfield paradigm and label-based metrics, fail in such cases because they cannot assess how robustly a system performs under uncertain interpretations. We introduce VB-Score, a variance-bounded evaluation framework that measures both effectiveness and robustness without requiring ground truth. Given a query or input, VB-Score enumerates plausible interpretations, assigns probabilities, and evaluates output by expected success penalized by variance, rewarding consistent performance across intents. We provide a formal analysis of VB-Score, establishing range, monotonicity, and stability properties, and relate it to risk-sensitive measures such as mean-variance utility. Experiments on ambiguous queries and entity-centric retrieval tasks show that VB-Score surfaces robustness differences hidden by conventional metrics. By enabling reproducible, label-free evaluation, VB-Score offers a principled foundation for benchmarking machine learning systems in ambiguous or label-scarce domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22751v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaihua Ding</dc:creator>
    </item>
    <item>
      <title>Concept activation vectors: a unifying view and adversarial attacks</title>
      <link>https://arxiv.org/abs/2509.22755</link>
      <description>arXiv:2509.22755v1 Announce Type: new 
Abstract: Concept Activation Vectors (CAVs) are a tool from explainable AI, offering a promising approach for understanding how human-understandable concepts are encoded in a model's latent spaces. They are computed from hidden-layer activations of inputs belonging either to a concept class or to non-concept examples. Adopting a probabilistic perspective, the distribution of the (non-)concept inputs induces a distribution over the CAV, making it a random vector in the latent space. This enables us to derive mean and covariance for different types of CAVs, leading to a unified theoretical view. This probabilistic perspective also reveals a potential vulnerability: CAVs can strongly depend on the rather arbitrary non-concept distribution, a factor largely overlooked in prior work. We illustrate this with a simple yet effective adversarial attack, underscoring the need for a more systematic study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22755v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ekkehard Schnoor, Malik Tiomoko, Jawher Said, Alex Jung, Wojciech Samek</dc:creator>
    </item>
    <item>
      <title>Identifying Memory Effects in Epidemics via a Fractional SEIRD Model and Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2509.22760</link>
      <description>arXiv:2509.22760v1 Announce Type: new 
Abstract: We develop a physics-informed neural network (PINN) framework for parameter estimation in fractional-order SEIRD epidemic models. By embedding the Caputo fractional derivative into the network residuals via the L1 discretization scheme, our method simultaneously reconstructs epidemic trajectories and infers both epidemiological parameters and the fractional memory order $\alpha$. The fractional formulation extends classical integer-order models by capturing long-range memory effects in disease progression, incubation, and recovery. Our framework learns the fractional memory order $\alpha$ as a trainable parameter while simultaneously estimating the epidemiological rates $(\beta, \sigma, \gamma, \mu)$. A composite loss combining data misfit, physics residuals, and initial conditions, with constraints on positivity and population conservation, ensures both accuracy and biological consistency. Tests on synthetic Mpox data confirm reliable recovery of $\alpha$ and parameters under noise, while applications to COVID-19 show that optimal $\alpha \in (0, 1]$ captures memory effects and improves predictive performance over the classical SEIRD model. This work establishes PINNs as a robust tool for learning memory effects in epidemic dynamics, with implications for forecasting, control strategies, and the analysis of non-Markovian epidemic processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22760v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Achraf Zinihi</dc:creator>
    </item>
    <item>
      <title>A theoretical guarantee for SyncRank</title>
      <link>https://arxiv.org/abs/2509.22766</link>
      <description>arXiv:2509.22766v1 Announce Type: new 
Abstract: We present a theoretical and empirical analysis of the SyncRank algorithm for recovering a global ranking from noisy pairwise comparisons. By adopting a complex-valued data model where the true ranking is encoded in the phases of a unit-modulus vector, we establish a sharp non-asymptotic recovery guarantee for the associated semidefinite programming (SDP) relaxation. Our main theorem characterizes a critical noise threshold - scaling as sigma = O(sqrt(n / log n)) - below which SyncRank achieves exact ranking recovery with high probability. Extensive experiments under this model confirm the theoretical predictions and demonstrate the algorithm's robustness across varying problem sizes and noise regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22766v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Rao</dc:creator>
    </item>
    <item>
      <title>Differentially Private Two-Stage Gradient Descent for Instrumental Variable Regression</title>
      <link>https://arxiv.org/abs/2509.22794</link>
      <description>arXiv:2509.22794v1 Announce Type: new 
Abstract: We study instrumental variable regression (IVaR) under differential privacy constraints. Classical IVaR methods (like two-stage least squares regression) rely on solving moment equations that directly use sensitive covariates and instruments, creating significant risks of privacy leakage and posing challenges in designing algorithms that are both statistically efficient and differentially private. We propose a noisy two-state gradient descent algorithm that ensures $\rho$-zero-concentrated differential privacy by injecting carefully calibrated noise into the gradient updates. Our analysis establishes finite-sample convergence rates for the proposed method, showing that the algorithm achieves consistency while preserving privacy. In particular, we derive precise bounds quantifying the trade-off among privacy parameters, sample size, and iteration-complexity. To the best of our knowledge, this is the first work to provide both privacy guarantees and provable convergence rates for instrumental variable regression in linear models. We further validate our theoretical findings with experiments on both synthetic and real datasets, demonstrating that our method offers practical accuracy-privacy trade-offs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22794v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haodong Liang, Yanhao Jin, Krishnakumar Balasubramanian, Lifeng Lai</dc:creator>
    </item>
    <item>
      <title>Label-Guided Imputation via Forest-Based Proximities for Improved Time Series Classification</title>
      <link>https://arxiv.org/abs/2509.22919</link>
      <description>arXiv:2509.22919v1 Announce Type: new 
Abstract: Missing data is a common problem in time series data. Most methods for imputation ignore label information pertaining to the time series even if that information exists. In this paper, we provide a framework for missing data imputation in the context of time series classification, where each time series is associated with a categorical label. We define a means of imputing missing values conditional upon labels, the method being guided by powerful, existing supervised models designed for high accuracy in this task. From each model, we extract a tree-based proximity measure from which imputation can be applied. We show that imputation using this method generally provides richer information leading to higher classification accuracies, despite the imputed values differing from the true values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22919v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jake S. Rhodes, Adam G. Rustad, Sofia Pelagalli Maia, Evan Thacker, Hyunmi Choi, Jose Gutierrez, Tatjana Rundek, Ben Shaw</dc:creator>
    </item>
    <item>
      <title>Localized Uncertainty Quantification in Random Forests via Proximities</title>
      <link>https://arxiv.org/abs/2509.22928</link>
      <description>arXiv:2509.22928v1 Announce Type: new 
Abstract: In machine learning, uncertainty quantification helps assess the reliability of model predictions, which is important in high-stakes scenarios. Traditional approaches often emphasize predictive accuracy, but there is a growing focus on incorporating uncertainty measures. This paper addresses localized uncertainty quantification in random forests. While current methods often rely on quantile regression or Monte Carlo techniques, we propose a new approach using naturally occurring test sets and similarity measures (proximities) typically viewed as byproducts of random forests. Specifically, we form localized distributions of OOB errors around nearby points, defined using the proximities, to create prediction intervals for regression and trust scores for classification. By varying the number of nearby points, our intervals can be adjusted to achieve the desired coverage while retaining the flexibility that reflects the certainty of individual predictions. For classification, excluding points identified as unclassifiable by our method generally enhances the accuracy of the model and provides higher accuracy-rejection AUC scores than competing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22928v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jake S. Rhodes, Scott D. Brown, J. Riley Wilkinson</dc:creator>
    </item>
    <item>
      <title>Unsupervised Conformal Inference: Bootstrapping and Alignment to Control LLM Uncertainty</title>
      <link>https://arxiv.org/abs/2509.23002</link>
      <description>arXiv:2509.23002v1 Announce Type: new 
Abstract: Deploying black-box LLMs requires managing uncertainty in the absence of token-level probability or true labels. We propose introducing an unsupervised conformal inference framework for generation, which integrates: generative models, incorporating: (i) an LLM-compatible atypical score derived from response-embedding Gram matrix, (ii) UCP combined with a bootstrapping variant (BB-UCP) that aggregates residuals to refine quantile precision while maintaining distribution-free, finite-sample coverage, and (iii) conformal alignment, which calibrates a single strictness parameter $\tau$ so a user predicate (e.g., factuality lift) holds on unseen batches with probability $\ge 1-\alpha$. Across different benchmark datasets, our gates achieve close-to-nominal coverage and provide tighter, more stable thresholds than split UCP, while consistently reducing the severity of hallucination, outperforming lightweight per-response detectors with similar computational demands. The result is a label-free, API-compatible gate for test-time filtering that turns geometric signals into calibrated, goal-aligned decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23002v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lingyou Pang, Lei Huang, Jianyu Lin, Tianyu Wang, Akira Horiguchi, Alexander Aue, Carey E. Priebe</dc:creator>
    </item>
    <item>
      <title>Sparse Deep Additive Model with Interactions: Enhancing Interpretability and Predictability</title>
      <link>https://arxiv.org/abs/2509.23068</link>
      <description>arXiv:2509.23068v1 Announce Type: new 
Abstract: Recent advances in deep learning highlight the need for personalized models that can learn from small or moderate samples, handle high dimensional features, and remain interpretable. To address this challenge, we propose the Sparse Deep Additive Model with Interactions (SDAMI), a framework that combines sparsity driven feature selection with deep subnetworks for flexible function approximation. Unlike conventional deep learning models, which often function as black boxes, SDAMI explicitly disentangles main effects and interaction effects to enhance interpretability. At the same time, its deep additive structure achieves higher predictive accuracy than classical additive models. Central to SDAMI is the concept of an Effect Footprint, which assumes that higher order interactions project marginally onto main effects. Guided by this principle, SDAMI adopts a two stage strategy: first, identify strong main effects that implicitly carry information about important interactions. second, exploit this information through structured regularization such as group lasso to distinguish genuine main effects from interaction effects. For each selected main effect, SDAMI constructs a dedicated subnetwork, enabling nonlinear function approximation while preserving interpretability and providing a structured foundation for modeling interactions. Extensive simulations with comparisons confirm SDAMI$'$s ability to recover effect structures across diverse scenarios, while applications in reliability analysis, neuroscience, and medical diagnostics further demonstrate its versatility in addressing real-world high-dimensional modeling challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23068v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yi-Ting Hung, Li-Hsiang Lin, Vince D. Calhoun</dc:creator>
    </item>
    <item>
      <title>Statistical Inference for Gradient Boosting Regression</title>
      <link>https://arxiv.org/abs/2509.23127</link>
      <description>arXiv:2509.23127v1 Announce Type: new 
Abstract: Gradient boosting is widely popular due to its flexibility and predictive accuracy. However, statistical inference and uncertainty quantification for gradient boosting remain challenging and under-explored. We propose a unified framework for statistical inference in gradient boosting regression. Our framework integrates dropout or parallel training with a recently proposed regularization procedure that allows for a central limit theorem (CLT) for boosting. With these enhancements, we surprisingly find that increasing the dropout rate and the number of trees grown in parallel at each iteration substantially enhances signal recovery and overall performance. Our resulting algorithms enjoy similar CLTs, which we use to construct built-in confidence intervals, prediction intervals, and rigorous hypothesis tests for assessing variable importance. Numerical experiments demonstrate that our algorithms perform well, interpolate between regularized boosting and random forests, and confirm the validity of their built-in statistical inference procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23127v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haimo Fang, Kevin Tan, Giles Hooker</dc:creator>
    </item>
    <item>
      <title>Conditional Risk Minimization with Side Information: A Tractable, Universal Optimal Transport Framework</title>
      <link>https://arxiv.org/abs/2509.23128</link>
      <description>arXiv:2509.23128v1 Announce Type: new 
Abstract: Conditional risk minimization arises in high-stakes decisions where risk must be assessed in light of side information, such as stressed economic conditions, specific customer profiles, or other contextual covariates. Constructing reliable conditional distributions from limited data is notoriously difficult, motivating a series of optimal-transport-based proposals that address this uncertainty in a distributionally robust manner. Yet these approaches remain fragmented, each constrained by its own limitations: some rely on point estimates or restrictive structural assumptions, others apply only to narrow classes of risk measures, and their structural connections are unclear. We introduce a universal framework for distributionally robust conditional risk minimization, built on a novel union-ball formulation in optimal transport. This framework offers three key advantages: interpretability, by subsuming existing methods as special cases and revealing their deep structural links; tractability, by yielding convex reformulations for virtually all major risk functionals studied in the literature; and scalability, by supporting cutting-plane algorithms for large-scale conditional risk problems. Applications to portfolio optimization with rank-dependent expected utility highlight the practical effectiveness of the framework, with conditional models converging to optimal solutions where unconditional ones clearly do not.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23128v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinqiao Xie, Jonathan Yu-Meng Li</dc:creator>
    </item>
    <item>
      <title>A Generative Model for Controllable Feature Heterophily in Graphs</title>
      <link>https://arxiv.org/abs/2509.23230</link>
      <description>arXiv:2509.23230v1 Announce Type: new 
Abstract: We introduce a principled generative framework for graph signals that enables explicit control of feature heterophily, a key property underlying the effectiveness of graph learning methods. Our model combines a Lipschitz graphon-based random graph generator with Gaussian node features filtered through a smooth spectral function of the rescaled Laplacian. We establish new theoretical guarantees: (i) a concentration result for the empirical heterophily score; and (ii) almost-sure convergence of the feature heterophily measure to a deterministic functional of the graphon degree profile, based on a graphon-limit law for polynomial averages of Laplacian eigenvalues. These results elucidate how the interplay between the graphon and the filter governs the limiting level of feature heterophily, providing a tunable mechanism for data modeling and generation. We validate the theory through experiments demonstrating precise control of homophily across graph families and spectral filters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23230v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoyu Wang, Renyuan Ma, Gonzalo Mateos, Luana Ruiz</dc:creator>
    </item>
    <item>
      <title>Flow Matching for Robust Simulation-Based Inference under Model Misspecification</title>
      <link>https://arxiv.org/abs/2509.23385</link>
      <description>arXiv:2509.23385v1 Announce Type: new 
Abstract: Simulation-based inference (SBI) is transforming experimental sciences by enabling parameter estimation in complex non-linear models from simulated data. A persistent challenge, however, is model misspecification: simulators are only approximations of reality, and mismatches between simulated and real data can yield biased or overconfident posteriors. We address this issue by introducing Flow Matching Corrected Posterior Estimation (FMCPE), a framework that leverages the flow matching paradigm to refine simulation-trained posterior estimators using a small set of real calibration samples. Our approach proceeds in two stages: first, a posterior approximator is trained on abundant simulated data; second, flow matching transports its predictions toward the true posterior supported by real observations, without requiring explicit knowledge of the misspecification. This design enables FMCPE to combine the scalability of SBI with robustness to distributional shift. Across synthetic benchmarks and real-world datasets, we show that our proposal consistently mitigates the effects of misspecification, delivering improved inference accuracy and uncertainty calibration compared to standard SBI baselines, while remaining computationally efficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23385v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre-Louis Ruhlmann, Pedro L. C. Rodrigues, Michael Arbel, Florence Forbes</dc:creator>
    </item>
    <item>
      <title>End-to-End Deep Learning for Predicting Metric Space-Valued Outputs</title>
      <link>https://arxiv.org/abs/2509.23544</link>
      <description>arXiv:2509.23544v1 Announce Type: new 
Abstract: Many modern applications involve predicting structured, non-Euclidean outputs such as probability distributions, networks, and symmetric positive-definite matrices. These outputs are naturally modeled as elements of general metric spaces, where classical regression techniques that rely on vector space structure no longer apply. We introduce E2M (End-to-End Metric regression), a deep learning framework for predicting metric space-valued outputs. E2M performs prediction via a weighted Fr\'echet means over training outputs, where the weights are learned by a neural network conditioned on the input. This construction provides a principled mechanism for geometry-aware prediction that avoids surrogate embeddings and restrictive parametric assumptions, while fully preserving the intrinsic geometry of the output space. We establish theoretical guarantees, including a universal approximation theorem that characterizes the expressive capacity of the model and a convergence analysis of the entropy-regularized training objective. Through extensive simulations involving probability distributions, networks, and symmetric positive-definite matrices, we show that E2M consistently achieves state-of-the-art performance, with its advantages becoming more pronounced at larger sample sizes. Applications to human mortality distributions and New York City taxi networks further demonstrate the flexibility and practical utility of the framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23544v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yidong Zhou, Su I Iao, Hans-Georg M\"uller</dc:creator>
    </item>
    <item>
      <title>Define latent spaces by example: optimisation over the outputs of generative models</title>
      <link>https://arxiv.org/abs/2509.23800</link>
      <description>arXiv:2509.23800v1 Announce Type: new 
Abstract: Modern generative AI models such as diffusion and flow matching can sample from rich data distributions, but many downstream tasks -- such as experimental design or creative content generation -- require a higher level of control than unconstrained sampling. The challenge is to efficiently identify outputs that are both probable under the model and satisfy task-specific constraints. We address this by introducing surrogate latent spaces: non-parametric, low-dimensional Euclidean embeddings that can be extracted from any generative model without additional training. The axes in the Euclidean space can be defined via examples, providing a simple and interpretable approach to define custom latent spaces that both express intended features and are convenient to use in downstream tasks. The representation is Euclidean and has controllable dimensionality, permitting direct application of standard optimisation algorithms to traverse the outputs of generative models. Our approach is architecture-agnostic, incurs almost no additional computational cost, and generalises across modalities, including images, audio, videos, and structured objects like proteins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23800v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Willis, Alexandru I. Stere, Dragos D. Margineantu, Henry T. Oldroyd, John A. Fozard, Carl Henrik Ek, Henry Moss, Erik Bodin</dc:creator>
    </item>
    <item>
      <title>Singleton-Optimized Conformal Prediction</title>
      <link>https://arxiv.org/abs/2509.24095</link>
      <description>arXiv:2509.24095v1 Announce Type: new 
Abstract: Conformal prediction can be used to construct prediction sets that cover the true outcome with a desired probability, but can sometimes lead to large prediction sets that are costly in practice. The most useful outcome is a singleton prediction-an unambiguous decision-yet existing efficiency-oriented methods primarily optimize average set size. Motivated by this, we propose a new nonconformity score that aims to minimize the probability of producing non-singleton sets. Starting from a non-convex constrained optimization problem as a motivation, we provide a geometric reformulation and associated algorithm for computing the nonconformity score and associated split conformal prediction sets in O(K) time for K-class problems. Using this score in split conformal prediction leads to our proposed Singleton-Optimized Conformal Prediction (SOCOP) method. We evaluate our method in experiments on image classification and LLM multiple-choice question-answering, comparing with standard nonconformity scores such as the (negative) label probability estimates and their cumulative distribution function; both of which are motivated by optimizing length. The results show that SOCOP increases singleton frequency (sometimes by over 20%) compared to the above scores, with minimal impact on average set size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24095v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Wang, Yan Sun, Edgar Dobriban</dc:creator>
    </item>
    <item>
      <title>ActiveCQ: Active Estimation of Causal Quantities</title>
      <link>https://arxiv.org/abs/2509.24293</link>
      <description>arXiv:2509.24293v1 Announce Type: new 
Abstract: Estimating causal quantities (CQs) typically requires large datasets, which can be expensive to obtain, especially when measuring individual outcomes is costly. This challenge highlights the importance of sample-efficient active learning strategies. To address the narrow focus of prior work on the conditional average treatment effect, we formalize the broader task of Actively estimating Causal Quantities (ActiveCQ) and propose a unified framework for this general problem. Built upon the insight that many CQs are integrals of regression functions, our framework models the regression function with a Gaussian Process. For the distribution component, we explore both a baseline using explicit density estimators and a more integrated method using conditional mean embeddings in a reproducing kernel Hilbert space. This latter approach offers key advantages: it bypasses explicit density estimation, operates within the same function space as the GP, and adaptively refines the distributional model after each update. Our framework enables the principled derivation of acquisition strategies from the CQ's posterior uncertainty; we instantiate this principle with two utility functions based on information gain and total variance reduction. A range of simulated and semi-synthetic experiments demonstrate that our principled framework significantly outperforms relevant baselines, achieving substantial gains in sample efficiency across a variety of CQs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24293v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erdun Gao, Dino Sejdinovic</dc:creator>
    </item>
    <item>
      <title>PEARL: Performance-Enhanced Aggregated Representation Learning</title>
      <link>https://arxiv.org/abs/2509.24312</link>
      <description>arXiv:2509.24312v1 Announce Type: new 
Abstract: Representation learning is a key technique in modern machine learning that enables models to identify meaningful patterns in complex data. However, different methods tend to extract distinct aspects of the data, and relying on a single approach may overlook important insights relevant to downstream tasks. This paper proposes a performance-enhanced aggregated representation learning method, which combines multiple representation learning approaches to improve the performance of downstream tasks. The framework is designed to be general and flexible, accommodating a wide range of loss functions commonly used in machine learning models. To ensure computational efficiency, we use surrogate loss functions to facilitate practical weight estimation. Theoretically, we prove that our method asymptotically achieves optimal performance in downstream tasks, meaning that the risk of our predictor is asymptotically equivalent to the theoretical minimum. Additionally, we derive that our method asymptotically assigns nonzero weights to correctly specified models. We evaluate our method on diverse tasks by comparing it with advanced machine learning models. The experimental results demonstrate that our method consistently outperforms baseline methods, showing its effectiveness and broad applicability in real-world machine learning scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24312v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenhui Li, Shijin Gong, Xinyu Zhang</dc:creator>
    </item>
    <item>
      <title>Preference-Based Dynamic Ranking Structure Recognition</title>
      <link>https://arxiv.org/abs/2509.24493</link>
      <description>arXiv:2509.24493v1 Announce Type: new 
Abstract: Preference-based data often appear complex and noisy but may conceal underlying homogeneous structures. This paper introduces a novel framework of ranking structure recognition for preference-based data. We first develop an approach to identify dynamic ranking groups by incorporating temporal penalties into a spectral estimation for the celebrated Bradley-Terry model. To detect structural changes, we introduce an innovative objective function and present a practicable algorithm based on dynamic programming. Theoretically, we establish the consistency of ranking group recognition by exploiting properties of a random `design matrix' induced by a reversible Markov chain. We also tailor a group inverse technique to quantify the uncertainty in item ability estimates. Additionally, we prove the consistency of structure change recognition, ensuring the robustness of the proposed framework. Experiments on both synthetic and real-world datasets demonstrate the practical utility and interpretability of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24493v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nan Lu, Jian Shi, Xin-Yu Tian</dc:creator>
    </item>
    <item>
      <title>Quantitative convergence of trained single layer neural networks to Gaussian processes</title>
      <link>https://arxiv.org/abs/2509.24544</link>
      <description>arXiv:2509.24544v1 Announce Type: new 
Abstract: In this paper, we study the quantitative convergence of shallow neural networks trained via gradient descent to their associated Gaussian processes in the infinite-width limit.
  While previous work has established qualitative convergence under broad settings, precise, finite-width estimates remain limited, particularly during training.
  We provide explicit upper bounds on the quadratic Wasserstein distance between the network output and its Gaussian approximation at any training time $t \ge 0$, demonstrating polynomial decay with network width.
  Our results quantify how architectural parameters, such as width and input dimension, influence convergence, and how training dynamics affect the approximation error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24544v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eloy Mosig, Andrea Agazzi, Dario Trevisan</dc:creator>
    </item>
    <item>
      <title>MAD: Manifold Attracted Diffusion</title>
      <link>https://arxiv.org/abs/2509.24710</link>
      <description>arXiv:2509.24710v1 Announce Type: new 
Abstract: Score-based diffusion models are a highly effective method for generating samples from a distribution of images. We consider scenarios where the training data comes from a noisy version of the target distribution, and present an efficiently implementable modification of the inference procedure to generate noiseless samples. Our approach is motivated by the manifold hypothesis, according to which meaningful data is concentrated around some low-dimensional manifold of a high-dimensional ambient space. The central idea is that noise manifests as low magnitude variation in off-manifold directions in contrast to the relevant variation of the desired distribution which is mostly confined to on-manifold directions. We introduce the notion of an extended score and show that, in a simplified setting, it can be used to reduce small variations to zero, while leaving large variations mostly unchanged. We describe how its approximation can be computed efficiently from an approximation to the standard score and demonstrate its efficacy on toy problems, synthetic data, and real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24710v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dennis Elbr\"achter, Giovanni S. Alberti, Matteo Santacesaria</dc:creator>
    </item>
    <item>
      <title>When Scores Learn Geometry: Rate Separations under the Manifold Hypothesis</title>
      <link>https://arxiv.org/abs/2509.24912</link>
      <description>arXiv:2509.24912v1 Announce Type: new 
Abstract: Score-based methods, such as diffusion models and Bayesian inverse problems, are often interpreted as learning the data distribution in the low-noise limit ($\sigma \to 0$). In this work, we propose an alternative perspective: their success arises from implicitly learning the data manifold rather than the full distribution. Our claim is based on a novel analysis of scores in the small-$\sigma$ regime that reveals a sharp separation of scales: information about the data manifold is $\Theta(\sigma^{-2})$ stronger than information about the distribution. We argue that this insight suggests a paradigm shift from the less practical goal of distributional learning to the more attainable task of geometric learning, which provably tolerates $O(\sigma^{-2})$ larger errors in score approximation. We illustrate this perspective through three consequences: i) in diffusion models, concentration on data support can be achieved with a score error of $o(\sigma^{-2})$, whereas recovering the specific data distribution requires a much stricter $o(1)$ error; ii) more surprisingly, learning the uniform distribution on the manifold-an especially structured and useful object-is also $O(\sigma^{-2})$ easier; and iii) in Bayesian inverse problems, the maximum entropy prior is $O(\sigma^{-2})$ more robust to score errors than generic priors. Finally, we validate our theoretical findings with preliminary experiments on large-scale models, including Stable Diffusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24912v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Li, Zebang Shen, Ya-Ping Hsieh, Niao He</dc:creator>
    </item>
    <item>
      <title>Inductive Bias and Spectral Properties of Single-Head Attention in High Dimensions</title>
      <link>https://arxiv.org/abs/2509.24914</link>
      <description>arXiv:2509.24914v1 Announce Type: new 
Abstract: We study empirical risk minimization in a single-head tied-attention layer trained on synthetic high-dimensional sequence tasks, given by the recently introduced attention-indexed model. Using tools from random matrix theory, spin-glass physics, and approximate message passing, we derive sharp asymptotics for training and test errors, locate interpolation and recovery thresholds, and characterize the limiting spectral distribution of the learned weights. Weight decay induces an implicit nuclear-norm regularization, favoring low-rank query and key matrices. Leveraging this, we compare the standard factorized training of query and key matrices with a direct parameterization in which their product is trained element-wise, revealing the inductive bias introduced by the factorized form. Remarkably, the predicted spectral distribution echoes empirical trends reported in large-scale transformers, offering a theoretical perspective consistent with these phenomena.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24914v1</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabrizio Boncoraglio, Vittorio Erba, Emanuele Troiani, Florent Krzakala, Lenka Zdeborov\'a</dc:creator>
    </item>
    <item>
      <title>A Spectral-Grassmann Wasserstein metric for operator representations of dynamical systems</title>
      <link>https://arxiv.org/abs/2509.24920</link>
      <description>arXiv:2509.24920v1 Announce Type: new 
Abstract: The geometry of dynamical systems estimated from trajectory data is a major challenge for machine learning applications. Koopman and transfer operators provide a linear representation of nonlinear dynamics through their spectral decomposition, offering a natural framework for comparison. We propose a novel approach representing each system as a distribution of its joint operator eigenvalues and spectral projectors and defining a metric between systems leveraging optimal transport. The proposed metric is invariant to the sampling frequency of trajectories. It is also computationally efficient, supported by finite-sample convergence guarantees, and enables the computation of Fr\'echet means, providing interpolation between dynamical systems. Experiments on simulated and real-world datasets show that our approach consistently outperforms standard operator-based distances in machine learning applications, including dimensionality reduction and classification, and provides meaningful interpolation between dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24920v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thibaut Germain, R\'emi Flamary, Vladimir R. Kostic, Karim Lounici</dc:creator>
    </item>
    <item>
      <title>Symmetry-Aware Bayesian Optimization via Max Kernels</title>
      <link>https://arxiv.org/abs/2509.25051</link>
      <description>arXiv:2509.25051v1 Announce Type: new 
Abstract: Bayesian Optimization (BO) is a powerful framework for optimizing noisy, expensive-to-evaluate black-box functions. When the objective exhibits invariances under a group action, exploiting these symmetries can substantially improve BO efficiency. While using maximum similarity across group orbits has long been considered in other domains, the fact that the max kernel is not positive semidefinite (PSD) has prevented its use in BO. In this work, we revisit this idea by considering a PSD projection of the max kernel. Compared to existing invariant (and non-invariant) kernels, we show it achieves significantly lower regret on both synthetic and real-world BO benchmarks, without increasing computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25051v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anthony Bardou, Antoine Gonon, Aryan Ahadinia, Patrick Thiran</dc:creator>
    </item>
    <item>
      <title>On Spectral Learning for Odeco Tensors: Perturbation, Initialization, and Algorithms</title>
      <link>https://arxiv.org/abs/2509.25126</link>
      <description>arXiv:2509.25126v1 Announce Type: new 
Abstract: We study spectral learning for orthogonally decomposable (odeco) tensors, emphasizing the interplay between statistical limits, optimization geometry, and initialization. Unlike matrices, recovery for odeco tensors does not hinge on eigengaps, yielding improved robustness under noise. While iterative methods such as tensor power iterations can be statistically efficient, initialization emerges as the main computational bottleneck. We investigate perturbation bounds, non-convex optimization analysis, and initialization strategies, clarifying when efficient algorithms attain statistical limits and when fundamental barriers remain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25126v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnab Auddy, Ming Yuan</dc:creator>
    </item>
    <item>
      <title>Deep P-Spline: Theory, Fast Tuning, and Application</title>
      <link>https://arxiv.org/abs/2501.01376</link>
      <description>arXiv:2501.01376v1 Announce Type: cross 
Abstract: Deep neural networks (DNNs) have been widely applied to solve real-world regression problems. However, selecting optimal network structures remains a significant challenge. This study addresses this issue by linking neuron selection in DNNs to knot placement in basis expansion techniques. We introduce a difference penalty that automates knot selection, thereby simplifying the complexities of neuron selection. We name this method Deep P-Spline (DPS). This approach extends the class of models considered in conventional DNN modeling and forms the basis for a latent variable modeling framework using the Expectation-Conditional Maximization (ECM) algorithm for efficient network structure tuning with theoretical guarantees. From a nonparametric regression perspective, DPS is proven to overcome the curse of dimensionality, enabling the effective handling of datasets with a large number of input variable, a scenario where conventional nonparametric regression methods typically underperform. This capability motivates the application of the proposed methodology to computer experiments and image data analyses, where the associated regression problems involving numerous inputs are common. Numerical results validate the effectiveness of the model, underscoring its potential for advanced nonlinear regression tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01376v1</guid>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noah Yi-Ting Hung, Li-Hsiang Lin, Vince D. Calhoun</dc:creator>
    </item>
    <item>
      <title>Distinguishability of causal structures under latent confounding and selection</title>
      <link>https://arxiv.org/abs/2509.20433</link>
      <description>arXiv:2509.20433v1 Announce Type: cross 
Abstract: Statistical relationships in observed data can arise for several different reasons: the observed variables may be causally related, they may share a latent common cause, or there may be selection bias. Each of these scenarios can be modelled using different causal graphs. Not all such causal graphs, however, can be distinguished by experimental data. In this paper, we formulate the equivalence class of causal graphs as a novel graphical structure, the selected-marginalized directed graph (smDG). That is, we show that two directed acyclic graphs with latent and selected vertices have the same smDG if and only if they are indistinguishable, even when allowing for arbitrary interventions on the observed variables. As a substitute for the more familiar d-separation criterion for DAGs, we provide an analogous sound and complete separation criterion in smDGs for conditional independence relative to passive observations. Finally, we provide a series of sufficient conditions under which two causal structures are indistinguishable when there is only access to passive observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20433v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan Carey, Marina Maciel Ansanelli, Elie Wolfe, Robin J. Evans</dc:creator>
    </item>
    <item>
      <title>Profit over Proxies: A Scalable Bayesian Decision Framework for Optimizing Multi-Variant Online Experiments</title>
      <link>https://arxiv.org/abs/2509.22677</link>
      <description>arXiv:2509.22677v1 Announce Type: cross 
Abstract: Online controlled experiments (A/B tests) are fundamental to data-driven decision-making in the digital economy. However, their real-world application is frequently compromised by two critical shortcomings: the use of statistically flawed heuristics like "p-value peeking", which inflates false positive rates, and an over-reliance on proxy metrics like conversion rates, which can lead to decisions that inadvertently harm core business profitability. This paper addresses these challenges by introducing a comprehensive and scalable Bayesian decision framework designed for profit optimization in multi-variant (A/B/n) experiments.
  We propose a hierarchical Bayesian model that simultaneously estimates the probability of conversion (using a Beta-Bernoulli model) and the monetary value of that conversion (using a robust Bayesian model for the mean transaction value). Building on this, we employ a decision-theoretic stopping rule based on Expected Loss, enabling experiments to be concluded not only when a superior variant is identified but also when it becomes clear that no variant offers a practically significant improvement (stopping for futility). The framework successfully navigates "revenue traps" where a variant with a higher conversion rate would have resulted in a net financial loss, correctly terminates futile experiments early to conserve resources, and maintains strict statistical integrity throughout the monitoring process.
  Ultimately, this work provides a practical and principled methodology for organizations to move beyond simple A/B testing towards a mature, profit-driven experimentation culture, ensuring that statistical conclusions translate directly to strategic business value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22677v1</guid>
      <category>stat.AP</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Srijesh Pillai, Rajesh Kumar Chandrawat</dc:creator>
    </item>
    <item>
      <title>Metadata-Guided Adaptable Frequency Scaling across Heterogeneous Applications and Devices</title>
      <link>https://arxiv.org/abs/2509.22707</link>
      <description>arXiv:2509.22707v1 Announce Type: cross 
Abstract: Dynamic Voltage and Frequency Scaling is essential for enhancing energy efficiency in mobile platforms. However, traditional heuristic-based governors are increasingly inadequate for managing the complexity of heterogeneous System-on-Chip designs and diverse application workloads. Although reinforcement learning approaches offer improved performance, their poor generalization capability and reliance on extensive retraining for each hardware and application combination leads to significant deployment costs. In this work, we observe that device and application metadata inherently encapsulate valuable knowledge for DVFS, presenting an opportunity to overcome these limitations. We formulate DVFS for heterogeneous devices and applications as a multi-task reinforcement learning problem. We introduce MetaDVFS, which is a metadata-guided framework that systematically leverages metadata to discover and transfer shared knowledge across DVFS tasks. MetaDVFS can output a set of DVFS models with significant generalization capability for various applications of heterogeneous devices. Evaluations on five Google Pixel devices running six applications show that MetaDVFS achieves up to 17% improvement in Performance-Power Ratio and up to 26% improvement in Quality of Experience. Compared to state-of-the-art methods, MetaDVFS delivers 70.8% faster adaptation and 5.8-27.6% higher performance over standalone device-application specific training, while avoiding negative transfer effects. These results establish MetaDVFS as an effective and scalable solution for DVFS deployment in heterogeneous mobile environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22707v1</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jinqi Yan, Fang He, Qianlong Sang, Bifeng Tong, Peng Sun, Yili Gong, Chuang Hu, Dazhao Cheng</dc:creator>
    </item>
    <item>
      <title>Consistency Models as Plug-and-Play Priors for Inverse Problems</title>
      <link>https://arxiv.org/abs/2509.22736</link>
      <description>arXiv:2509.22736v1 Announce Type: cross 
Abstract: Diffusion models have found extensive use in solving numerous inverse problems. Such diffusion inverse problem solvers aim to sample from the posterior distribution of data given the measurements, using a combination of the unconditional score function and an approximation of the posterior related to the forward process. Recently, consistency models (CMs) have been proposed to directly predict the final output from any point on the diffusion ODE trajectory, enabling high-quality sampling in just a few NFEs. CMs have also been utilized for inverse problems, but existing CM-based solvers either require additional task-specific training or utilize data fidelity operations with slow convergence, not amenable to large-scale problems. In this work, we reinterpret CMs as proximal operators of a prior, enabling their integration into plug-and-play (PnP) frameworks. We propose a solver based on PnP-ADMM, which enables us to leverage the fast convergence of conjugate gradient method. We further accelerate this with noise injection and momentum, dubbed PnP-CM, and show it maintains the convergence properties of the baseline PnP-ADMM. We evaluate our approach on a variety of inverse problems, including inpainting, super-resolution, Gaussian deblurring, and magnetic resonance imaging (MRI) reconstruction. To the best of our knowledge, this is the first CM trained for MRI datasets. Our results show that PnP-CM achieves high-quality reconstructions in as few as 4 NFEs, and can produce meaningful results in 2 steps, highlighting its effectiveness in real-world inverse problems while outperforming comparable CM-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22736v1</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>physics.med-ph</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Merve G\"ulle, Junno Yun, Ya\c{s}ar Utku Al\c{c}alar, Mehmet Ak\c{c}akaya</dc:creator>
    </item>
    <item>
      <title>Painless Activation Steering: An Automated, Lightweight Approach for Post-Training Large Language Models</title>
      <link>https://arxiv.org/abs/2509.22739</link>
      <description>arXiv:2509.22739v1 Announce Type: cross 
Abstract: Language models (LMs) are typically post-trained for desired capabilities and behaviors via weight-based or prompt-based steering, but the former is time-consuming and expensive, and the latter is not precisely controllable and often requires manual trial-and-error. While activation steering (AS) promises a cheap, fast, and controllable alternative to the two existing post-training methods, current AS techniques require hand-crafted prompt pairs or labor-intensive feature annotation, making them more inconvenient than the plug-and-play methods such as Reinforcement Learning (RL) and Supervised Fine-Tuning (SFT). We introduce Painless Activation Steering (PAS), a family of fully automated methods that make AS readily usable with any given labeled dataset, with no need for prompt construction, feature labeling, or human intervention. We evaluate PAS on three open-weight models (Llama3.1-8B-Instruct, DeepSeek-R1-Distill-8B, and Nous-Hermes-2) and 18 tasks; we find that PAS reliably improves performance for behavior tasks, but not for intelligence-oriented tasks. The introspective variant (iPAS) delivers the strongest causal steering effects (10.1% on Bias, 5.2% on Morality, and 34.8% on Alignment). We also show PAS delivers additional gains on top of In-Context Learning (ICL) and SFT. PAS constructs a fast, lightweight activation vector that can be cheaply trained, easily stored, and activated at will. Our results provide a characterization of where AS helps, where it fails, and how to deploy it as a practical, automated LM post-training option.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22739v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sasha Cui, Zhongren Chen</dc:creator>
    </item>
    <item>
      <title>Generalization Analysis for Classification on Korobov Space</title>
      <link>https://arxiv.org/abs/2509.22748</link>
      <description>arXiv:2509.22748v1 Announce Type: cross 
Abstract: In this paper, the classification algorithm arising from Tikhonov regularization is discussed. The main intention is to derive learning rates for the excess misclassification error according to the convex $\eta$-norm loss function $\phi(v)=(1 - v)_{+}^{\eta}$, $\eta\geq1$. Following the argument, the estimation of error under Tsybakov noise conditions is studied. In addition, we propose the rate of $L_p$ approximation of functions from Korobov space $X^{2, p}([-1,1]^{d})$, $1\leq p \leq \infty$, by the shallow ReLU neural network. This result consists of a novel Fourier analysis</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22748v1</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuqing Liu</dc:creator>
    </item>
    <item>
      <title>Ringleader ASGD: The First Asynchronous SGD with Optimal Time Complexity under Data Heterogeneity</title>
      <link>https://arxiv.org/abs/2509.22860</link>
      <description>arXiv:2509.22860v1 Announce Type: cross 
Abstract: Asynchronous stochastic gradient methods are central to scalable distributed optimization, particularly when devices differ in computational capabilities. Such settings arise naturally in federated learning, where training takes place on smartphones and other heterogeneous edge devices. In addition to varying computation speeds, these devices often hold data from different distributions. However, existing asynchronous SGD methods struggle in such heterogeneous settings and face two key limitations. First, many rely on unrealistic assumptions of similarity across workers' data distributions. Second, methods that relax this assumption still fail to achieve theoretically optimal performance under heterogeneous computation times. We introduce Ringleader ASGD, the first asynchronous SGD algorithm that attains the theoretical lower bounds for parallel first-order stochastic methods in the smooth nonconvex regime, thereby achieving optimal time complexity under data heterogeneity and without restrictive similarity assumptions. Our analysis further establishes that Ringleader ASGD remains optimal under arbitrary and even time-varying worker computation speeds, closing a fundamental gap in the theory of asynchronous optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22860v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artavazd Maranjyan, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Neighborhood Sampling Does Not Learn the Same Graph Neural Network</title>
      <link>https://arxiv.org/abs/2509.22868</link>
      <description>arXiv:2509.22868v1 Announce Type: cross 
Abstract: Neighborhood sampling is an important ingredient in the training of large-scale graph neural networks. It suppresses the exponential growth of the neighborhood size across network layers and maintains feasible memory consumption and time costs. While it becomes a standard implementation in practice, its systemic behaviors are less understood. We conduct a theoretical analysis by using the tool of neural tangent kernels, which characterize the (analogous) training dynamics of neural networks based on their infinitely wide counterparts -- Gaussian processes (GPs). We study several established neighborhood sampling approaches and the corresponding posterior GP. With limited samples, the posteriors are all different, although they converge to the same one as the sample size increases. Moreover, the posterior covariance, which lower-bounds the mean squared prediction error, is uncomparable, aligning with observations that no sampling approach dominates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22868v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zehao Niu, Mihai Anitescu, Jie Chen</dc:creator>
    </item>
    <item>
      <title>Guided Manifold Alignment with Geometry-Regularized Twin Autoencoders</title>
      <link>https://arxiv.org/abs/2509.22913</link>
      <description>arXiv:2509.22913v1 Announce Type: cross 
Abstract: Manifold alignment (MA) involves a set of techniques for learning shared representations across domains, yet many traditional MA methods are incapable of performing out-of-sample extension, limiting their real-world applicability. We propose a guided representation learning framework leveraging a geometry-regularized twin autoencoder (AE) architecture to enhance MA while enabling generalization to unseen data. Our method enforces structured cross-modal mappings to maintain geometric fidelity in learned embeddings. By incorporating a pre-trained alignment model and a multitask learning formulation, we improve cross-domain generalization and representation robustness while maintaining alignment fidelity. We evaluate our approach using several MA methods, showing improvements in embedding consistency, information preservation, and cross-domain transfer. Additionally, we apply our framework to Alzheimer's disease diagnosis, demonstrating its ability to integrate multi-modal patient data and enhance predictive accuracy in cases limited to a single domain by leveraging insights from the multi-modal problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22913v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jake S. Rhodes, Adam G. Rustad, Marshall S. Nielsen, Morgan Chase McClellan, Dallan Gardner, Dawson Hedges</dc:creator>
    </item>
    <item>
      <title>GDR-learners: Orthogonal Learning of Generative Models for Potential Outcomes</title>
      <link>https://arxiv.org/abs/2509.22953</link>
      <description>arXiv:2509.22953v1 Announce Type: cross 
Abstract: Various deep generative models have been proposed to estimate potential outcomes distributions from observational data. However, none of them have the favorable theoretical property of general Neyman-orthogonality and, associated with it, quasi-oracle efficiency and double robustness. In this paper, we introduce a general suite of generative Neyman-orthogonal (doubly-robust) learners that estimate the conditional distributions of potential outcomes. Our proposed GDR-learners are flexible and can be instantiated with many state-of-the-art deep generative models. In particular, we develop GDR-learners based on (a) conditional normalizing flows (which we call GDR-CNFs), (b) conditional generative adversarial networks (GDR-CGANs), (c) conditional variational autoencoders (GDR-CVAEs), and (d) conditional diffusion models (GDR-CDMs). Unlike the existing methods, our GDR-learners possess the properties of quasi-oracle efficiency and rate double robustness, and are thus asymptotically optimal. In a series of (semi-)synthetic experiments, we demonstrate that our GDR-learners are very effective and outperform the existing methods in estimating the conditional distributions of potential outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22953v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valentyn Melnychuk, Stefan Feuerriegel</dc:creator>
    </item>
    <item>
      <title>Sensitivity Analysis for Diffusion Models</title>
      <link>https://arxiv.org/abs/2509.23092</link>
      <description>arXiv:2509.23092v1 Announce Type: cross 
Abstract: Training a diffusion model approximates a map from a data distribution $\rho$ to the optimal score function $s_t$ for that distribution. Can we differentiate this map? If we could, then we could predict how the score, and ultimately the model's samples, would change under small perturbations to the training set before committing to costly retraining. We give a closed-form procedure for computing this map's directional derivatives, relying only on black-box access to a pre-trained score model and its derivatives with respect to its inputs. We extend this result to estimate the sensitivity of a diffusion model's samples to additive perturbations of its target measure, with runtime comparable to sampling from a diffusion model and computing log-likelihoods along the sample path. Our method is robust to numerical and approximation error, and the resulting sensitivities correlate with changes in an image diffusion model's samples after retraining and fine-tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23092v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher Scarvelis, Justin Solomon</dc:creator>
    </item>
    <item>
      <title>Dense associative memory on the Bures-Wasserstein space</title>
      <link>https://arxiv.org/abs/2509.23162</link>
      <description>arXiv:2509.23162v1 Announce Type: cross 
Abstract: Dense associative memories (DAMs) store and retrieve patterns via energy-functional fixed points, but existing models are limited to vector representations. We extend DAMs to probability distributions equipped with the 2-Wasserstein distance, focusing mainly on the Bures-Wasserstein class of Gaussian densities. Our framework defines a log-sum-exp energy over stored distributions and a retrieval dynamics aggregating optimal transport maps in a Gibbs-weighted manner. Stationary points correspond to self-consistent Wasserstein barycenters, generalizing classical DAM fixed points. We prove exponential storage capacity, provide quantitative retrieval guarantees under Wasserstein perturbations, and validate the model on synthetic and real-world distributional tasks. This work elevates associative memory from vectors to full distributions, bridging classical DAMs with modern generative modeling and enabling distributional storage and retrieval in memory-augmented learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23162v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chandan Tankala, Krishnakumar Balasubramanian</dc:creator>
    </item>
    <item>
      <title>Landing with the Score: Riemannian Optimization through Denoising</title>
      <link>https://arxiv.org/abs/2509.23357</link>
      <description>arXiv:2509.23357v1 Announce Type: cross 
Abstract: Under the data manifold hypothesis, high-dimensional data are concentrated near a low-dimensional manifold. We study the problem of Riemannian optimization over such manifolds when they are given only implicitly through the data distribution, and the standard manifold operations required by classical algorithms are unavailable. This formulation captures a broad class of data-driven design problems that are central to modern generative AI. Our key idea is to introduce a link function that connects the data distribution to the geometric operations needed for optimization. We show that this function enables the recovery of essential manifold operations, such as retraction and Riemannian gradient computation. Moreover, we establish a direct connection between our construction and the score function in diffusion models of the data distribution. This connection allows us to leverage well-studied parameterizations, efficient training procedures, and even pretrained score networks from the diffusion model literature to perform optimization. Building on this foundation, we propose two efficient inference-time algorithms -- Denoising Landing Flow (DLF) and Denoising Riemannian Gradient Descent (DRGD) -- and provide theoretical guarantees for both feasibility (approximate manifold adherence) and optimality (small Riemannian gradient norm). Finally, we demonstrate the effectiveness of our approach on finite-horizon reference tracking tasks in data-driven control, highlighting its potential for practical generative and design applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23357v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrey Kharitenko, Zebang Shen, Riccardo de Santi, Niao He, Florian Doerfler</dc:creator>
    </item>
    <item>
      <title>Better Hessians Matter: Studying the Impact of Curvature Approximations in Influence Functions</title>
      <link>https://arxiv.org/abs/2509.23437</link>
      <description>arXiv:2509.23437v1 Announce Type: cross 
Abstract: Influence functions offer a principled way to trace model predictions back to training data, but their use in deep learning is hampered by the need to invert a large, ill-conditioned Hessian matrix. Approximations such as Generalised Gauss-Newton (GGN) and Kronecker-Factored Approximate Curvature (K-FAC) have been proposed to make influence computation tractable, yet it remains unclear how the departure from exactness impacts data attribution performance. Critically, given the restricted regime in which influence functions are derived, it is not necessarily clear better Hessian approximations should even lead to better data attribution performance. In this paper, we investigate the effect of Hessian approximation quality on influence-function attributions in a controlled classification setting. Our experiments show that better Hessian approximations consistently yield better influence score quality, offering justification for recent research efforts towards that end. We further decompose the approximation steps for recent Hessian approximation methods and evaluate each step's influence on attribution accuracy. Notably, the mismatch between K-FAC eigenvalues and GGN/EK-FAC eigenvalues accounts for the majority of the error and influence loss. These findings highlight which approximations are most critical, guiding future efforts to balance computational tractability and attribution accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23437v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steve Hong, Runa Eschenhagen, Bruno Mlodozeniec, Richard Turner</dc:creator>
    </item>
    <item>
      <title>Data-Efficient Training by Evolved Sampling</title>
      <link>https://arxiv.org/abs/2509.23461</link>
      <description>arXiv:2509.23461v1 Announce Type: cross 
Abstract: Data selection is designed to accelerate learning with preserved performance. To achieve this, a fundamental thought is to identify informative data samples with significant contributions to the training. In this work, we propose \textbf{Evolved Sampling} (\textbf{ES}), a simple yet effective framework for \emph{dynamic} sampling along the training process. This method conducts \em batch \em level data selection based on the dynamics of losses and augmented \emph{loss differences}, which enables flexible \emph{frequency tuning}, and hence significantly reduces the back propagation time with maintained model performance. Due to its conciseness, ES is also readily extensible to incorporate \em set \em level data selection (to form ES with pruning, \textbf{ESWP}) for further accelerations. As a plug-and-play framework, ES(WP) consistently achieves lossless training accelerations across various pre-training and post-training tasks, saving up to nearly 45\% wall-clock time. Our results motivate further investigations on the data efficiency aspect of modern large-scale machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23461v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziheng Cheng, Zhong Li, Jiang Bian</dc:creator>
    </item>
    <item>
      <title>Statistical Learning Guarantees for Group-Invariant Barron Functions</title>
      <link>https://arxiv.org/abs/2509.23474</link>
      <description>arXiv:2509.23474v1 Announce Type: cross 
Abstract: We investigate the generalization error of group-invariant neural networks within the Barron framework. Our analysis shows that incorporating group-invariant structures introduces a group-dependent factor $\delta_{G,\Gamma,\sigma} \le 1$ into the approximation rate. When this factor is small, group invariance yields substantial improvements in approximation accuracy. On the estimation side, we establish that the Rademacher complexity of the group-invariant class is no larger than that of the non-invariant counterpart, implying that the estimation error remains unaffected by the incorporation of symmetry. Consequently, the generalization error can improve significantly when learning functions with inherent group symmetries. We further provide illustrative examples demonstrating both favorable cases, where $\delta_{G,\Gamma,\sigma}\approx |G|^{-1}$, and unfavorable ones, where $\delta_{G,\Gamma,\sigma}\approx 1$. Overall, our results offer a rigorous theoretical foundation showing that encoding group-invariant structures in neural networks leads to clear statistical advantages for symmetric target functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23474v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yahong Yang, Wei Zhu</dc:creator>
    </item>
    <item>
      <title>Revisiting Multivariate Time Series Forecasting with Missing Values</title>
      <link>https://arxiv.org/abs/2509.23494</link>
      <description>arXiv:2509.23494v1 Announce Type: cross 
Abstract: Missing values are common in real-world time series, and multivariate time series forecasting with missing values (MTSF-M) has become a crucial area of research for ensuring reliable predictions. To address the challenge of missing data, current approaches have developed an imputation-then-prediction framework that uses imputation modules to fill in missing values, followed by forecasting on the imputed data. However, this framework overlooks a critical issue: there is no ground truth for the missing values, making the imputation process susceptible to errors that can degrade prediction accuracy. In this paper, we conduct a systematic empirical study and reveal that imputation without direct supervision can corrupt the underlying data distribution and actively degrade prediction accuracy. To address this, we propose a paradigm shift that moves away from imputation and directly predicts from the partially observed time series. We introduce Consistency-Regularized Information Bottleneck (CRIB), a novel framework built on the Information Bottleneck principle. CRIB combines a unified-variate attention mechanism with a consistency regularization scheme to learn robust representations that filter out noise introduced by missing values while preserving essential predictive signals. Comprehensive experiments on four real-world datasets demonstrate the effectiveness of CRIB, which predicts accurately even under high missing rates. Our code is available in https://github.com/Muyiiiii/CRIB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23494v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Yang, Yifan Hu, Kexin Zhang, Luyang Niu, Yushun Dong, Philip S. Yu, Kaize Ding</dc:creator>
    </item>
    <item>
      <title>Learning single index model with gradient descent: spectral initialization and precise asymptotics</title>
      <link>https://arxiv.org/abs/2509.23527</link>
      <description>arXiv:2509.23527v1 Announce Type: cross 
Abstract: Non-convex optimization plays a central role in many statistics and machine learning problems. Despite the landscape irregularities for general non-convex functions, some recent work showed that for many learning problems with random data and large enough sample size, there exists a region around the true signal with benign landscape. Motivated by this observation, a widely used strategy is a two-stage algorithm, where we first apply a spectral initialization to plunge into the region, and then run gradient descent for further refinement. While this two-stage algorithm has been extensively analyzed for many non-convex problems, the precise distributional property of both its transient and long-time behavior remains to be understood. In this work, we study this two-stage algorithm in the context of single index models under the proportional asymptotics regime. We derive a set of dynamical mean field equations, which describe the precise behavior of the trajectory of spectral initialized gradient descent in the large system limit. We further show that when the spectral initialization successfully lands in a region of benign landscape, the above equation system is asymptotically time translation invariant and exponential converging, and thus admits a set of long-time fixed points that represents the mean field characterization of the limiting point of the gradient descent dynamic. As a proof of concept, we demonstrate our general theory in the example of regularized Wirtinger flow for phase retrieval.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23527v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Chen, Yandi Shen</dc:creator>
    </item>
    <item>
      <title>Bridging Discrete and Continuous RL: Stable Deterministic Policy Gradient with Martingale Characterization</title>
      <link>https://arxiv.org/abs/2509.23711</link>
      <description>arXiv:2509.23711v1 Announce Type: cross 
Abstract: The theory of discrete-time reinforcement learning (RL) has advanced rapidly over the past decades. Although primarily designed for discrete environments, many real-world RL applications are inherently continuous and complex. A major challenge in extending discrete-time algorithms to continuous-time settings is their sensitivity to time discretization, often leading to poor stability and slow convergence. In this paper, we investigate deterministic policy gradient methods for continuous-time RL. We derive a continuous-time policy gradient formula based on an analogue of the advantage function and establish its martingale characterization. This theoretical foundation leads to our proposed algorithm, CT-DDPG, which enables stable learning with deterministic policies in continuous-time environments. Numerical experiments show that the proposed CT-DDPG algorithm offers improved stability and faster convergence compared to existing discrete-time and continuous-time methods, across a wide range of control tasks with varying time discretizations and noise levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23711v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziheng Cheng, Xin Guo, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>FraudTransformer: Time-Aware GPT for Transaction Fraud Detection</title>
      <link>https://arxiv.org/abs/2509.23712</link>
      <description>arXiv:2509.23712v1 Announce Type: cross 
Abstract: Detecting payment fraud in real-world banking streams requires models that can exploit both the order of events and the irregular time gaps between them. We introduce FraudTransformer, a sequence model that augments a vanilla GPT-style architecture with (i) a dedicated time encoder that embeds either absolute timestamps or inter-event values, and (ii) a learned positional encoder that preserves relative order. Experiments on a large industrial dataset -- tens of millions of transactions and auxiliary events -- show that FraudTransformer surpasses four strong classical baselines (Logistic Regression, XGBoost and LightGBM) as well as transformer ablations that omit either the time or positional component. On the held-out test set it delivers the highest AUROC and PRAUC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23712v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gholamali Aminian, Andrew Elliott, Tiger Li, Timothy Cheuk Hin Wong, Victor Claude Dehon, Lukasz Szpruch, Carsten Maple, Christopher Read, Martin Brown, Gesine Reinert, Mo Mamouei</dc:creator>
    </item>
    <item>
      <title>Bayesian Mixture-of-Experts: Towards Making LLMs Know What They Don't Know</title>
      <link>https://arxiv.org/abs/2509.23830</link>
      <description>arXiv:2509.23830v1 Announce Type: cross 
Abstract: The Mixture-of-Experts (MoE) architecture has enabled the creation of massive yet efficient Large Language Models (LLMs). However, the standard deterministic routing mechanism presents a significant limitation: its inherent brittleness is a key contributor to model miscalibration and overconfidence, resulting in systems that often do not know what they don't know.
  This thesis confronts this challenge by proposing a structured \textbf{Bayesian MoE routing framework}. Instead of forcing a single, deterministic expert selection, our approach models a probability distribution over the routing decision itself. We systematically investigate three families of methods that introduce this principled uncertainty at different stages of the routing pipeline: in the \textbf{weight-space}, the \textbf{logit-space}, and the final \textbf{selection-space}.
  Through a series of controlled experiments on a 3-billion parameter MoE model, we demonstrate that this framework significantly improves routing stability, in-distribution calibration, and out-of-distribution (OoD) detection. The results show that by targeting this core architectural component, we can create a more reliable internal uncertainty signal. This work provides a practical and computationally tractable pathway towards building more robust and self-aware LLMs, taking a crucial step towards making them know what they don't know.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23830v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Albus Yizhuo Li</dc:creator>
    </item>
    <item>
      <title>Differentiable Sparsity via $D$-Gating: Simple and Versatile Structured Penalization</title>
      <link>https://arxiv.org/abs/2509.23898</link>
      <description>arXiv:2509.23898v1 Announce Type: cross 
Abstract: Structured sparsity regularization offers a principled way to compact neural networks, but its non-differentiability breaks compatibility with conventional stochastic gradient descent and requires either specialized optimizers or additional post-hoc pruning without formal guarantees. In this work, we propose $D$-Gating, a fully differentiable structured overparameterization that splits each group of weights into a primary weight vector and multiple scalar gating factors. We prove that any local minimum under $D$-Gating is also a local minimum using non-smooth structured $L_{2,2/D}$ penalization, and further show that the $D$-Gating objective converges at least exponentially fast to the $L_{2,2/D}$-regularized loss in the gradient flow limit. Together, our results show that $D$-Gating is theoretically equivalent to solving the original group sparsity problem, yet induces distinct learning dynamics that evolve from a non-sparse regime into sparse optimization. We validate our theory across vision, language, and tabular tasks, where $D$-Gating consistently delivers strong performance-sparsity tradeoffs and outperforms both direct optimization of structured penalties and conventional pruning baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23898v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chris Kolb, Laetitia Frost, Bernd Bischl, David R\"ugamer</dc:creator>
    </item>
    <item>
      <title>Asymptotic Expansion for Nonlinear Filtering in the Small System Noise Regime</title>
      <link>https://arxiv.org/abs/2509.23920</link>
      <description>arXiv:2509.23920v1 Announce Type: cross 
Abstract: We propose a new asymptotic expansion method for nonlinear filtering, based on a small parameter in the system noise. The conditional expectation is expanded as a power series in the noise level, with each coefficient computed by solving a system of ordinary differential equations. This approach mitigates the trade-off between computational efficiency and accuracy inherent in existing methods such as Gaussian approximations and particle filters. Moreover, by incorporating an Edgeworth-type expansion, our method captures complex features of the conditional distribution, such as multimodality, with significantly lower computational cost than conventional filtering algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23920v1</guid>
      <category>eess.SP</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masahiro Kurisaki</dc:creator>
    </item>
    <item>
      <title>Explore-Execute Chain: Towards an Efficient Structured Reasoning Paradigm</title>
      <link>https://arxiv.org/abs/2509.23946</link>
      <description>arXiv:2509.23946v1 Announce Type: cross 
Abstract: Chain-of-Thought (CoT) and its variants have markedly advanced the reasoning abilities of Large Language Models (LLMs), yet their monolithic and auto-regressive architecture inherently conflates high-level strategic planning with low-level step-by-step execution, leading to computational inefficiency, limited exploration of reasoning paths, and reduced interpretability. To overcome these issues, we propose the Explore-Execute Chain ($E^2C$), a structured reasoning framework that decouples reasoning into two distinct phases: an exploratory phase that stochastically generates succinct high-level plans, followed by an execution phase that deterministically carries out the chosen plan. Our approach incorporates a two-stage training methodology, which combines Supervised Fine-Tuning (SFT) - augmented by a novel data generation algorithm enforcing strict plan adherence - with a subsequent Reinforcement Learning (RL) stage that capitalizes on the informativeness of exploration and reinforces the determinism of execution.This decomposition enables an efficient test-time scaling strategy: on AIME'2024, $E^2C$ Test Time Scaling reaches 58.1% accuracy using &lt;10% of the decoding tokens required by comparable methods (e.g., Forest-of-Thought), sharply cutting self-consistency overhead. For cross-domain adaptation, our Exploration-Focused SFT (EF-SFT) fine-tunes with only 3.5% of the tokens used by standard SFT yet yields up to 14.5% higher accuracy than standard SFT on medical benchmarks, delivering state-of-the-art performance, strong generalization, and greater interpretability by separating planning from execution. The code and pre-trained models for the project are available at: https://github.com/yks23/Explore-Execute-Chain.git</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23946v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaisen Yang, Lixuan He, Rushi Shah, Kaicheng Yang, Qinwei Ma, Dianbo Liu, Alex Lamb</dc:creator>
    </item>
    <item>
      <title>Does Weak-to-strong Generalization Happen under Spurious Correlations?</title>
      <link>https://arxiv.org/abs/2509.24005</link>
      <description>arXiv:2509.24005v1 Announce Type: cross 
Abstract: We initiate a unified theoretical and algorithmic study of a key problem in weak-to-strong (W2S) generalization: when fine-tuning a strong pre-trained student with pseudolabels from a weaker teacher on a downstream task with spurious correlations, does W2S happen, and how to improve it upon failures? We consider two sources of spurious correlations caused by group imbalance: (i) a weak teacher fine-tuned on group-imbalanced labeled data with a minority group of fraction $\eta_\ell$, and (ii) a group-imbalanced unlabeled set pseudolabeled by the teacher with a minority group of fraction $\eta_u$. Theoretically, a precise characterization of W2S gain at the proportional asymptotic limit shows that W2S always happens with sufficient pseudolabels when $\eta_u = \eta_\ell$ but may fail when $\eta_u \ne \eta_\ell$, where W2S gain diminishes as $(\eta_u - \eta_\ell)^2$ increases. Our theory is corroborated by extensive experiments on various spurious correlation benchmarks and teacher-student pairs. To boost W2S performance upon failures, we further propose a simple, effective algorithmic remedy that retrains the strong student on its high-confidence data subset after W2S fine-tuning. Our algorithm is group-label-free and achieves consistent, substantial improvements over vanilla W2S fine-tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24005v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenruo Liu, Yijun Dong, Qi Lei</dc:creator>
    </item>
    <item>
      <title>On The Variability of Concept Activation Vectors</title>
      <link>https://arxiv.org/abs/2509.24058</link>
      <description>arXiv:2509.24058v1 Announce Type: cross 
Abstract: One of the most pressing challenges in artificial intelligence is to make models more transparent to their users. Recently, explainable artificial intelligence has come up with numerous method to tackle this challenge. A promising avenue is to use concept-based explanations, that is, high-level concepts instead of plain feature importance score. Among this class of methods, Concept Activation vectors (CAVs), Kim et al. (2018) stands out as one of the main protagonists. One interesting aspect of CAVs is that their computation requires sampling random examples in the train set. Therefore, the actual vectors obtained may vary from user to user depending on the randomness of this sampling. In this paper, we propose a fine-grained theoretical analysis of CAVs construction in order to quantify their variability. Our results, confirmed by experiments on several real-life datasets, point out towards an universal result: the variance of CAVs decreases as $1/N$, where $N$ is the number of random examples. Based on this we give practical recommendations for a resource-efficient application of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24058v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julia Wenkmann, Damien Garreau</dc:creator>
    </item>
    <item>
      <title>A Family of Kernelized Matrix Costs for Multiple-Output Mixture Neural Networks</title>
      <link>https://arxiv.org/abs/2509.24076</link>
      <description>arXiv:2509.24076v1 Announce Type: cross 
Abstract: Pairwise distance-based costs are crucial for self-supervised and contrastive feature learning. Mixture Density Networks (MDNs) are a widely used approach for generative models and density approximation, using neural networks to produce multiple centers that define a Gaussian mixture. By combining MDNs with contrastive costs, this paper proposes data density approximation using four types of kernelized matrix costs: the scalar cost, the vector-matrix cost, the matrix-matrix cost (the trace of Schur complement), and the SVD cost (the nuclear norm), for learning multiple centers required to define a mixture density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24076v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Hu, Jos\'e C. Pr\'incipe</dc:creator>
    </item>
    <item>
      <title>Demographic-Agnostic Fairness without Harm</title>
      <link>https://arxiv.org/abs/2509.24077</link>
      <description>arXiv:2509.24077v1 Announce Type: cross 
Abstract: As machine learning (ML) algorithms are increasingly used in social domains to make predictions about humans, there is a growing concern that these algorithms may exhibit biases against certain social groups. Numerous notions of fairness have been proposed in the literature to measure the unfairness of ML. Among them, one class that receives the most attention is \textit{parity-based}, i.e., achieving fairness by equalizing treatment or outcomes for different social groups. However, achieving parity-based fairness often comes at the cost of lowering model accuracy and is undesirable for many high-stakes domains like healthcare. To avoid inferior accuracy, a line of research focuses on \textit{preference-based} fairness, under which any group of individuals would experience the highest accuracy and collectively prefer the ML outcomes assigned to them if they were given the choice between various sets of outcomes. However, these works assume individual demographic information is known and fully accessible during training. In this paper, we relax this requirement and propose a novel \textit{demographic-agnostic fairness without harm (DAFH)} optimization algorithm, which jointly learns a group classifier that partitions the population into multiple groups and a set of decoupled classifiers associated with these groups. Theoretically, we conduct sample complexity analysis and show that our method can outperform the baselines when demographic information is known and used to train decoupled classifiers. Experiments on both synthetic and real data validate the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24077v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhongteng Cai, Mohammad Mahdi Khalili, Xueru Zhang</dc:creator>
    </item>
    <item>
      <title>GeoFunFlow: Geometric Function Flow Matching for Inverse Operator Learning over Complex Geometries</title>
      <link>https://arxiv.org/abs/2509.24117</link>
      <description>arXiv:2509.24117v1 Announce Type: cross 
Abstract: Inverse problems governed by partial differential equations (PDEs) are crucial in science and engineering. They are particularly challenging due to ill-posedness, data sparsity, and the added complexity of irregular geometries. Classical PDE-constrained optimization methods are computationally expensive, especially when repeated posterior sampling is required. Learning-based approaches improve efficiency and scalability, yet most are designed for regular domains or focus on forward modeling. Here, we introduce {\em GeoFunFlow}, a geometric diffusion model framework for inverse problems on complex geometries. GeoFunFlow combines a novel geometric function autoencoder (GeoFAE) and a latent diffusion model trained via rectified flow. GeoFAE employs a Perceiver module to process unstructured meshes of varying sizes and produces continuous reconstructions of physical fields, while the diffusion model enables posterior sampling from sparse and noisy data. Across five benchmarks, GeoFunFlow achieves state-of-the-art reconstruction accuracy over complex geometries, provides calibrated uncertainty quantification, and delivers efficient inference compared to operator-learning and diffusion model baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24117v1</guid>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sifan Wang, Zhikai Wu, David van Dijk, Lu Lu</dc:creator>
    </item>
    <item>
      <title>A signal separation view of classification</title>
      <link>https://arxiv.org/abs/2509.24140</link>
      <description>arXiv:2509.24140v1 Announce Type: cross 
Abstract: The problem of classification in machine learning has often been approached in terms of function approximation. In this paper, we propose an alternative approach for classification in arbitrary compact metric spaces which, in theory, yields both the number of classes, and a perfect classification using a minimal number of queried labels. Our approach uses localized trigonometric polynomial kernels initially developed for the point source signal separation problem in signal processing. Rather than point sources, we argue that the various classes come from different probability distributions. The localized kernel technique developed for separating point sources is then shown to separate the supports of these distributions. This is done in a hierarchical manner in our MASC algorithm to accommodate touching/overlapping class boundaries. We illustrate our theory on several simulated and real life datasets, including the Salinas and Indian Pines hyperspectral datasets and a document dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24140v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H. N. Mhaskar, Ryan O'Dowd</dc:creator>
    </item>
    <item>
      <title>From Headlines to Holdings: Deep Learning for Smarter Portfolio Decisions</title>
      <link>https://arxiv.org/abs/2509.24144</link>
      <description>arXiv:2509.24144v1 Announce Type: cross 
Abstract: Deep learning offers new tools for portfolio optimization. We present an end-to-end framework that directly learns portfolio weights by combining Long Short-Term Memory (LSTM) networks to model temporal patterns, Graph Attention Networks (GAT) to capture evolving inter-stock relationships, and sentiment analysis of financial news to reflect market psychology. Unlike prior approaches, our model unifies these elements in a single pipeline that produces daily allocations. It avoids the traditional two-step process of forecasting asset returns and then applying mean--variance optimization (MVO), a sequence that can introduce instability. We evaluate the framework on nine U.S. stocks spanning six sectors, chosen to balance sector diversity and news coverage. In this setting, the model delivers higher cumulative returns and Sharpe ratios than equal-weighted and CAPM-based MVO benchmarks. Although the stock universe is limited, the results underscore the value of integrating price, relational, and sentiment signals for portfolio management and suggest promising directions for scaling the approach to larger, more diverse asset sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24144v1</guid>
      <category>q-fin.PM</category>
      <category>q-fin.CP</category>
      <category>q-fin.ST</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yun Lin, Jiawei Lou, Jinghe Zhang</dc:creator>
    </item>
    <item>
      <title>Blockwise Missingness meets AI: A Tractable Solution for Semiparametric Inference</title>
      <link>https://arxiv.org/abs/2509.24158</link>
      <description>arXiv:2509.24158v1 Announce Type: cross 
Abstract: We consider parameter estimation and inference when data feature blockwise, non-monotone missingness. Our approach, rooted in semiparametric theory and inspired by prediction-powered inference, leverages off-the-shelf AI (predictive or generative) models to handle missing completely at random mechanisms, by finding an approximation of the optimal estimating equation through a novel and tractable Restricted Anova hierarchY (RAY) approximation. The resulting Inference for Blockwise Missingness(RAY), or IBM(RAY) estimator incorporates pre-trained AI models and carefully controls asymptotic variance by tuning model-specific hyperparameters. We then extend IBM(RAY) to a general class of estimators. We find the most efficient estimator in this class, which we call IBM(Adaptive), by solving a constrained quadratic programming problem. All IBM estimators are unbiased, and, crucially, asymptotically achieving guaranteed efficiency gains over a naive complete-case estimator, regardless of the predictive accuracy of the AI models used. We demonstrate the finite-sample performance and numerical stability of our method through simulation studies and an application to surface protein abundance estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24158v1</guid>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Xu, Lorenzo Testa, Jing Lei, Kathryn Roeder</dc:creator>
    </item>
    <item>
      <title>Semantic Editing with Coupled Stochastic Differential Equations</title>
      <link>https://arxiv.org/abs/2509.24223</link>
      <description>arXiv:2509.24223v1 Announce Type: cross 
Abstract: Editing the content of an image with a pretrained text-to-image model remains challenging. Existing methods often distort fine details or introduce unintended artifacts. We propose using coupled stochastic differential equations (coupled SDEs) to guide the sampling process of any pre-trained generative model that can be sampled by solving an SDE, including diffusion and rectified flow models. By driving both the source image and the edited image with the same correlated noise, our approach steers new samples toward the desired semantics while preserving visual similarity to the source. The method works out-of-the-box-without retraining or auxiliary networks-and achieves high prompt fidelity along with near-pixel-level consistency. These results position coupled SDEs as a simple yet powerful tool for controlled generative AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24223v1</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianxin Zhang, Clayton Scott</dc:creator>
    </item>
    <item>
      <title>AuON: A Linear-time Alternative to Semi-Orthogonal Momentum Updates</title>
      <link>https://arxiv.org/abs/2509.24320</link>
      <description>arXiv:2509.24320v1 Announce Type: cross 
Abstract: Orthogonal gradient updates have emerged as a promising direction in optimization for machine learning. However, traditional approaches such as SVD/QR decomposition incur prohibitive computational costs of O(n^3) and underperform compared to well-tuned SGD with momentum, since momentum is applied only after strict orthogonalization. Recent advances, such as Muon, improve efficiency by applying momentum before orthogonalization and producing semi-orthogonal matrices via Newton-Schulz iterations, reducing complexity to O(n^2). Nevertheless, quadratic costs remain a bottleneck.
  In this work, we study the semi-orthogonal properties of momentum-based updates and develop a method to bound momentum updates under a spectral-norm trust region, preserving directional information without requiring explicit semi-orthogonalization.
  We propose AuON (Alternative Unit-norm momentum updates by Normalized nonlinear scaling), a linear-time optimizer that achieves strong performance without constructing semi-orthogonal matrices, while preserving structural alignment and reconditioning ill-posed updates. Our approach combines hyperbolic-cosine RMS scaling transformations with normalization, demonstrating both effectiveness and computational efficiency compared to Newton-Schulz methods. We further introduce a hybrid variant (Hybrid-AuON) that applies a single Newton-Schulz iteration. Experiments across vision and language benchmarks show that AuON and its hybrid variant achieve performance comparable to strong baselines such as AdamW and Muon.
  Code is available at: https://github.com/ryyzn9/AuON</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24320v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dipan Maity</dc:creator>
    </item>
    <item>
      <title>Convergence of graph Dirichlet energies and graph Laplacians on intersecting manifolds of varying dimensions</title>
      <link>https://arxiv.org/abs/2509.24458</link>
      <description>arXiv:2509.24458v1 Announce Type: cross 
Abstract: We study $\Gamma$-convergence of graph Dirichlet energies and spectral convergence of graph Laplacians on unions of intersecting manifolds of potentially different dimensions. Our investigation is motivated by problems of machine learning, as real-world data often consist of parts or classes with different intrinsic dimensions. An important challenge is to understand which machine learning methods adapt to such varied dimensionalities. We investigate the standard unnormalized and the normalized graph Dirichlet energies. We show that the unnormalized energy and its associated graph Laplacian asymptotically only sees the variations within the manifold of the highest dimension. On the other hand, we prove that the normalized Dirichlet energy converges to a (tensorized) Dirichlet energy on the union of manifolds that adapts to all dimensions simultaneously. We also establish the related spectral convergence and present a few numerical experiments to illustrate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24458v1</guid>
      <category>math.AP</category>
      <category>math.SP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leon Bungert, Dejan Slep\v{c}ev</dc:creator>
    </item>
    <item>
      <title>Interpretable Kernel Representation Learning at Scale: A Unified Framework Utilizing Nystr\"om Approximation</title>
      <link>https://arxiv.org/abs/2509.24467</link>
      <description>arXiv:2509.24467v1 Announce Type: cross 
Abstract: Kernel methods provide a theoretically grounded framework for non-linear and non-parametric learning, with strong analytic foundations and statistical guarantees. Yet, their scalability has long been limited by prohibitive time and memory costs. While progress has been made in scaling kernel regression, no framework exists for scalable kernel-based representation learning, restricting their use in the era of foundation models where representations are learned from massive unlabeled data. We introduce KREPES -- a unified, scalable framework for kernel-based representation learning via Nystr\"om approximation. KREPES accommodates a wide range of unsupervised and self-supervised losses, and experiments on large image and tabular datasets demonstrate its efficiency. Crucially, KREPES enables principled interpretability of the learned representations, an immediate benefit over deep models, which we substantiate through dedicated analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24467v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maedeh Zarvandi, Michael Timothy, Theresa Wasserer, Debarghya Ghoshdastidar</dc:creator>
    </item>
    <item>
      <title>Training Agents Inside of Scalable World Models</title>
      <link>https://arxiv.org/abs/2509.24527</link>
      <description>arXiv:2509.24527v1 Announce Type: cross 
Abstract: World models learn general knowledge from videos and simulate experience for training behaviors in imagination, offering a path towards intelligent agents. However, previous world models have been unable to accurately predict object interactions in complex environments. We introduce Dreamer 4, a scalable agent that learns to solve control tasks by reinforcement learning inside of a fast and accurate world model. In the complex video game Minecraft, the world model accurately predicts object interactions and game mechanics, outperforming previous world models by a large margin. The world model achieves real-time interactive inference on a single GPU through a shortcut forcing objective and an efficient transformer architecture. Moreover, the world model learns general action conditioning from only a small amount of data, allowing it to extract the majority of its knowledge from diverse unlabeled videos. We propose the challenge of obtaining diamonds in Minecraft from only offline data, aligning with practical applications such as robotics where learning from environment interaction can be unsafe and slow. This task requires choosing sequences of over 20,000 mouse and keyboard actions from raw pixels. By learning behaviors in imagination, Dreamer 4 is the first agent to obtain diamonds in Minecraft purely from offline data, without environment interaction. Our work provides a scalable recipe for imagination training, marking a step towards intelligent agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24527v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danijar Hafner, Wilson Yan, Timothy Lillicrap</dc:creator>
    </item>
    <item>
      <title>Bandits roaming Hilbert space</title>
      <link>https://arxiv.org/abs/2509.24569</link>
      <description>arXiv:2509.24569v1 Announce Type: cross 
Abstract: This thesis studies the exploration and exploitation trade-off in online learning of properties of quantum states using multi-armed bandits. Given streaming access to an unknown quantum state, in each round we select an observable from a set of actions to maximize its expectation value. Using past information, we refine actions to minimize regret; the cumulative gap between current reward and the maximum possible. We derive information-theoretic lower bounds and optimal strategies with matching upper bounds, showing regret typically scales as the square root of rounds. As an application, we reframe quantum state tomography to both learn the state efficiently and minimize measurement disturbance. For pure states and continuous actions, we achieve polylogarithmic regret using a sample-optimal algorithm based on a weighted online least squares estimator. The algorithm relies on the optimistic principle and controls the eigenvalues of the design matrix. We also apply our framework to quantum recommender systems and thermodynamic work extraction from unknown states. In this last setting, our results demonstrate an exponential advantage in work dissipation over tomography-based protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24569v1</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Josep Lumbreras</dc:creator>
    </item>
    <item>
      <title>Evaluating classification performance across operating contexts: A comparison of decision curve analysis and cost curves</title>
      <link>https://arxiv.org/abs/2509.24608</link>
      <description>arXiv:2509.24608v1 Announce Type: cross 
Abstract: Classification models typically predict a score and use a decision threshold to produce a classification. Appropriate model evaluation should carefully consider the context in which a model will be used, including the relative value of correct classifications of positive versus negative examples, which affects the threshold that should be used. Decision curve analysis (DCA) and cost curves are model evaluation approaches that assess the expected utility and expected loss of prediction models, respectively, across decision thresholds. We compared DCA and cost curves to determine how they are related, and their strengths and limitations. We demonstrate that decision curves are closely related to a specific type of cost curve called a Brier curve. Both curves are derived assuming model scores are calibrated and setting the classification threshold using the relative value of correct positive and negative classifications, and the x-axis of both curves are equivalent. Net benefit (used for DCA) and Brier loss (used for Brier curves) will always choose the same model as optimal at any given threshold. Across thresholds, differences in Brier loss are comparable whereas differences in net benefit cannot be compared. Brier curves are more generally applicable (when a wider range of thresholds are plausible), and the area under the Brier curve is the Brier score. We demonstrate that reference lines common in each space can be included in either and suggest the upper envelope decision curve as a useful comparison for DCA showing the possible gain in net benefit that could be achieved through recalibration alone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24608v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Louise AC Millard, Peter A Flach</dc:creator>
    </item>
    <item>
      <title>Community detection robustness of graph neural networks</title>
      <link>https://arxiv.org/abs/2509.24662</link>
      <description>arXiv:2509.24662v1 Announce Type: cross 
Abstract: Graph neural networks (GNNs) are increasingly widely used for community detection in attributed networks. They combine structural topology with node attributes through message passing and pooling. However, their robustness or lack of thereof with respect to different perturbations and targeted attacks in conjunction with community detection tasks is not well understood. To shed light into latent mechanisms behind GNN sensitivity on community detection tasks, we conduct a systematic computational evaluation of six widely adopted GNN architectures: GCN, GAT, Graph- SAGE, DiffPool, MinCUT, and DMoN. The analysis covers three perturbation categories: node attribute manipulations, edge topology distortions, and adversarial attacks. We use element-centric similarity as the evaluation metric on synthetic benchmarks and real-world citation networks. Our findings indicate that supervised GNNs tend to achieve higher baseline accuracy, while unsupervised methods, particularly DMoN, maintain stronger resilience under targeted and adversarial pertur- bations. Furthermore, robustness appears to be strongly influenced by community strength, with well-defined communities reducing performance loss. Across all models, node attribute perturba- tions associated with targeted edge deletions and shift in attribute distributions tend to cause the largest degradation in community recovery. These findings highlight important trade-offs between accuracy and robustness in GNN-based community detection and offer new insights into selecting architectures resilient to noise and adversarial attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24662v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>physics.soc-ph</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaidev Goel, Pablo Moriano, Ramakrishnan Kannan, Yulia R. Gel</dc:creator>
    </item>
    <item>
      <title>Beyond Softmax: A Natural Parameterization for Categorical Random Variables</title>
      <link>https://arxiv.org/abs/2509.24728</link>
      <description>arXiv:2509.24728v1 Announce Type: cross 
Abstract: Latent categorical variables are frequently found in deep learning architectures. They can model actions in discrete reinforcement-learning environments, represent categories in latent-variable models, or express relations in graph neural networks. Despite their widespread use, their discrete nature poses significant challenges to gradient-descent learning algorithms. While a substantial body of work has offered improved gradient estimation techniques, we take a complementary approach. Specifically, we: 1) revisit the ubiquitous $\textit{softmax}$ function and demonstrate its limitations from an information-geometric perspective; 2) replace the $\textit{softmax}$ with the $\textit{catnat}$ function, a function composed of a sequence of hierarchical binary splits; we prove that this choice offers significant advantages to gradient descent due to the resulting diagonal Fisher Information Matrix. A rich set of experiments - including graph structure learning, variational autoencoders, and reinforcement learning - empirically show that the proposed function improves the learning efficiency and yields models characterized by consistently higher test performance. $\textit{Catnat}$ is simple to implement and seamlessly integrates into existing codebases. Moreover, it remains compatible with standard training stabilization techniques and, as such, offers a better alternative to the $\textit{softmax}$ function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24728v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Manenti, Cesare Alippi</dc:creator>
    </item>
    <item>
      <title>Fidel-TS: A High-Fidelity Benchmark for Multimodal Time Series Forecasting</title>
      <link>https://arxiv.org/abs/2509.24789</link>
      <description>arXiv:2509.24789v1 Announce Type: cross 
Abstract: The evaluation of time series forecasting models is hindered by a critical lack of high-quality benchmarks, leading to a potential illusion of progress. Existing datasets suffer from issues ranging from pre-training data contamination in the age of LLMs to the causal and description leakage prevalent in early multimodal designs. To address this, we formalize the core principles of high-fidelity benchmarking, focusing on data sourcing integrity, strict causal soundness, and structural clarity. We introduce Fidel-TS, a new large-scale benchmark built from the ground up on these principles by sourcing data from live APIs. Our extensive experiments validate this approach by exposing the critical biases and design limitations of prior benchmarks. Furthermore, we conclusively demonstrate that the causal relevance of textual information is the key factor in unlocking genuine performance gains in multimodal forecasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24789v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhijian Xu, Wanxu Cai, Xilin Dai, Zhaorong Deng, Qiang Xu</dc:creator>
    </item>
    <item>
      <title>A Greedy PDE Router for Blending Neural Operators and Classical Methods</title>
      <link>https://arxiv.org/abs/2509.24814</link>
      <description>arXiv:2509.24814v1 Announce Type: cross 
Abstract: When solving PDEs, classical numerical solvers are often computationally expensive, while machine learning methods can suffer from spectral bias, failing to capture high-frequency components. Designing an optimal hybrid iterative solver--where, at each iteration, a solver is selected from an ensemble of solvers to leverage their complementary strengths--poses a challenging combinatorial problem. While the greedy selection strategy is desirable for its constant-factor approximation guarantee to the optimal solution, it requires knowledge of the true error at each step, which is generally unavailable in practice. We address this by proposing an approximate greedy router that efficiently mimics a greedy approach to solver selection. Empirical results on the Poisson and Helmholtz equations demonstrate that our method outperforms single-solver baselines and existing hybrid solver approaches, such as HINTS, achieving faster and more stable convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24814v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sahana Rayan, Yash Patel, Ambuj Tewari</dc:creator>
    </item>
    <item>
      <title>Scaling Laws and Spectra of Shallow Neural Networks in the Feature Learning Regime</title>
      <link>https://arxiv.org/abs/2509.24882</link>
      <description>arXiv:2509.24882v1 Announce Type: cross 
Abstract: Neural scaling laws underlie many of the recent advances in deep learning, yet their theoretical understanding remains largely confined to linear models. In this work, we present a systematic analysis of scaling laws for quadratic and diagonal neural networks in the feature learning regime. Leveraging connections with matrix compressed sensing and LASSO, we derive a detailed phase diagram for the scaling exponents of the excess risk as a function of sample complexity and weight decay. This analysis uncovers crossovers between distinct scaling regimes and plateau behaviors, mirroring phenomena widely reported in the empirical neural scaling literature. Furthermore, we establish a precise link between these regimes and the spectral properties of the trained network weights, which we characterize in detail. As a consequence, we provide a theoretical validation of recent empirical observations connecting the emergence of power-law tails in the weight spectrum with network generalization performance, yielding an interpretation from first principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24882v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leonardo Defilippis, Yizhou Xu, Julius Girardin, Emanuele Troiani, Vittorio Erba, Lenka Zdeborov\'a, Bruno Loureiro, Florent Krzakala</dc:creator>
    </item>
    <item>
      <title>Overlap-Adaptive Regularization for Conditional Average Treatment Effect Estimation</title>
      <link>https://arxiv.org/abs/2509.24962</link>
      <description>arXiv:2509.24962v1 Announce Type: cross 
Abstract: The conditional average treatment effect (CATE) is widely used in personalized medicine to inform therapeutic decisions. However, state-of-the-art methods for CATE estimation (so-called meta-learners) often perform poorly in the presence of low overlap. In this work, we introduce a new approach to tackle this issue and improve the performance of existing meta-learners in the low-overlap regions. Specifically, we introduce Overlap-Adaptive Regularization (OAR) that regularizes target models proportionally to overlap weights so that, informally, the regularization is higher in regions with low overlap. To the best of our knowledge, our OAR is the first approach to leverage overlap weights in the regularization terms of the meta-learners. Our OAR approach is flexible and works with any existing CATE meta-learner: we demonstrate how OAR can be applied to both parametric and non-parametric second-stage models. Furthermore, we propose debiased versions of our OAR that preserve the Neyman-orthogonality of existing meta-learners and thus ensure more robust inference. Through a series of (semi-)synthetic experiments, we demonstrate that our OAR significantly improves CATE estimation in low-overlap settings in comparison to constant regularization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24962v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valentyn Melnychuk, Dennis Frauen, Jonas Schweisthal, Stefan Feuerriegel</dc:creator>
    </item>
    <item>
      <title>A multiscale analysis of mean-field transformers in the moderate interaction regime</title>
      <link>https://arxiv.org/abs/2509.25040</link>
      <description>arXiv:2509.25040v1 Announce Type: cross 
Abstract: In this paper, we study the evolution of tokens through the depth of encoder-only transformer models at inference time by modeling them as a system of particles interacting in a mean-field way and studying the corresponding dynamics. More specifically, we consider this problem in the moderate interaction regime, where the number $N$ of tokens is large and the inverse temperature parameter $\beta$ of the model scales together with $N$. In this regime, the dynamics of the system displays a multiscale behavior: a fast phase, where the token empirical measure collapses on a low-dimensional space, an intermediate phase, where the measure further collapses into clusters, and a slow one, where such clusters sequentially merge into a single one. We provide a rigorous characterization of the limiting dynamics in each of these phases and prove convergence in the above mentioned limit, exemplifying our results with some simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25040v1</guid>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Bruno, Federico Pasqualotto, Andrea Agazzi</dc:creator>
    </item>
    <item>
      <title>Learning in an Echo Chamber: Online Learning with Replay Adversary</title>
      <link>https://arxiv.org/abs/2509.25135</link>
      <description>arXiv:2509.25135v1 Announce Type: cross 
Abstract: As machine learning systems increasingly train on self-annotated data, they risk reinforcing errors and becoming echo chambers of their own beliefs. We model this phenomenon by introducing a learning-theoretic framework: Online Learning in the Replay Setting. In round $t$, the learner outputs a hypothesis $\hat{h}_t$; the adversary then reveals either the true label $f^\ast(x_t)$ or a replayed label $\hat{h}_i(x_t)$ from an earlier round $i &lt; t$. A mistake is counted only when the true label is shown, yet classical algorithms such as the SOA or the halving algorithm are easily misled by the replayed errors.
  We introduce the Extended Threshold dimension, $\mathrm{ExThD}(\mathcal{H})$, and prove matching upper and lower bounds that make $\mathrm{ExThD}(\mathcal{H})$ the exact measure of learnability in this model. A closure-based learner makes at most $\mathrm{ExThD}(\mathcal{H})$ mistakes against any adaptive adversary, and no algorithm can perform better. For stochastic adversaries, we prove a similar bound for every intersection-closed class. The replay setting is provably harder than the classical mistake bound setting: some classes have constant Littlestone dimension but arbitrarily large $\mathrm{ExThD}(\mathcal{H})$. Proper learning exhibits an even sharper separation: a class is properly learnable under replay if and only if it is (almost) intersection-closed. Otherwise, every proper learner suffers $\Omega(T)$ errors, whereas our improper algorithm still achieves the $\mathrm{ExThD}(\mathcal{H})$ bound. These results give the first tight analysis of learning against replay adversaries, based on new results for closure-type algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25135v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniil Dmitriev, Harald Eskelund Franck, Carolin Heinzler, Amartya Sanyal</dc:creator>
    </item>
    <item>
      <title>High-Dimensional Analysis of Single-Layer Attention for Sparse-Token Classification</title>
      <link>https://arxiv.org/abs/2509.25153</link>
      <description>arXiv:2509.25153v1 Announce Type: cross 
Abstract: When and how can an attention mechanism learn to selectively attend to informative tokens, thereby enabling detection of weak, rare, and sparsely located features? We address these questions theoretically in a sparse-token classification model in which positive samples embed a weak signal vector in a randomly chosen subset of tokens, whereas negative samples are pure noise. In the long-sequence limit, we show that a simple single-layer attention classifier can in principle achieve vanishing test error when the signal strength grows only logarithmically in the sequence length $L$, whereas linear classifiers require $\sqrt{L}$ scaling. Moving from representational power to learnability, we study training at finite $L$ in a high-dimensional regime, where sample size and embedding dimension grow proportionally. We prove that just two gradient updates suffice for the query weight vector of the attention classifier to acquire a nontrivial alignment with the hidden signal, inducing an attention map that selectively amplifies informative tokens. We further derive an exact asymptotic expression for the test error and training loss of the trained attention-based classifier, and quantify its capacity -- the largest dataset size that is typically perfectly separable -- thereby explaining the advantage of adaptive token selection over nonadaptive linear baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25153v1</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Barnfield, Hugo Cui, Yue M. Lu</dc:creator>
    </item>
    <item>
      <title>GLASS Flows: Transition Sampling for Alignment of Flow and Diffusion Models</title>
      <link>https://arxiv.org/abs/2509.25170</link>
      <description>arXiv:2509.25170v1 Announce Type: cross 
Abstract: The performance of flow matching and diffusion models can be greatly improved at inference time using reward alignment algorithms, yet efficiency remains a major limitation. While several algorithms were proposed, we demonstrate that a common bottleneck is the sampling method these algorithms rely on: many algorithms require to sample Markov transitions via SDE sampling, which is significantly less efficient and often less performant than ODE sampling. To remove this bottleneck, we introduce GLASS Flows, a new sampling paradigm that simulates a "flow matching model within a flow matching model" to sample Markov transitions. As we show in this work, this "inner" flow matching model can be retrieved from a pre-trained model without any re-training, combining the efficiency of ODEs with the stochastic evolution of SDEs. On large-scale text-to-image models, we show that GLASS Flows eliminate the trade-off between stochastic evolution and efficiency. Combined with Feynman-Kac Steering, GLASS Flows improve state-of-the-art performance in text-to-image generation, making it a simple, drop-in solution for inference-time scaling of flow and diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25170v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Holderrieth, Uriel Singer, Tommi Jaakkola, Ricky T. Q. Chen, Yaron Lipman, Brian Karrer</dc:creator>
    </item>
    <item>
      <title>Network inference via process motifs for lagged correlation in linear stochastic processes</title>
      <link>https://arxiv.org/abs/2208.08871</link>
      <description>arXiv:2208.08871v3 Announce Type: replace 
Abstract: A major challenge for causal inference from time-series data is the trade-off between computational feasibility and accuracy. Motivated by process motifs for lagged covariance in an autoregressive model with slow mean-reversion, we propose to infer networks of causal relations via pairwise edge measure (PEMs) that one can easily compute from lagged correlation matrices. Motivated by contributions of process motifs to covariance and lagged variance, we formulate two PEMs that correct for confounding factors and for reverse causation. To demonstrate the performance of our PEMs, we consider network interference from simulations of linear stochastic processes, and we show that our proposed PEMs can infer networks accurately and efficiently. Specifically, for slightly autocorrelated time-series data, our approach achieves accuracies higher than or similar to Granger causality, transfer entropy, and convergent crossmapping -- but with much shorter computation time than possible with any of these methods. Our fast and accurate PEMs are easy-to-implement methods for network inference with a clear theoretical underpinning. They provide promising alternatives to current paradigms for the inference of linear models from time-series data, including Granger causality, vector-autoregression, and sparse inverse covariance estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.08871v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>math.DS</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alice C. Schwarze, Sara M. Ichinaga, Bingni W. Brunton</dc:creator>
    </item>
    <item>
      <title>Off-Policy Evaluation in Markov Decision Processes under Weak Distributional Overlap</title>
      <link>https://arxiv.org/abs/2402.08201</link>
      <description>arXiv:2402.08201v2 Announce Type: replace 
Abstract: Doubly robust methods hold considerable promise for off-policy evaluation in Markov decision processes (MDPs) under sequential ignorability: They have been shown to converge as $1/\sqrt{T}$ with the horizon $T$, to be statistically efficient in large samples, and to allow for modular implementation where preliminary estimation tasks can be executed using standard reinforcement learning techniques. Existing results, however, make heavy use of a strong distributional overlap assumption whereby the stationary distributions of the target policy and the data-collection policy are within a bounded factor of each other -- and this assumption is typically only credible when the state space of the MDP is bounded. In this paper, we re-visit the task of off-policy evaluation in MDPs under a weaker notion of distributional overlap, and introduce a class of truncated doubly robust (TDR) estimators which we find to perform well in this setting. When the distribution ratio of the target and data-collection policies is square-integrable (but not necessarily bounded), our approach recovers the large-sample behavior previously established under strong distributional overlap. When this ratio is not square-integrable, TDR is still consistent but with a slower-than-$1/\sqrt{T}$-rate; furthermore, this rate of convergence is minimax over a class of MDPs defined only using mixing conditions. We validate our approach numerically and find that, in our experiments, appropriate truncation plays a major role in enabling accurate off-policy evaluation when strong distributional overlap does not hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08201v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Mehrabi, Stefan Wager</dc:creator>
    </item>
    <item>
      <title>SEMF: Supervised Expectation-Maximization Framework for Predicting Intervals</title>
      <link>https://arxiv.org/abs/2405.18176</link>
      <description>arXiv:2405.18176v5 Announce Type: replace 
Abstract: This work introduces the Supervised Expectation-Maximization Framework (SEMF), a versatile and model-agnostic approach for generating prediction intervals with any ML model. SEMF extends the Expectation-Maximization algorithm, traditionally used in unsupervised learning, to a supervised context, leveraging latent variable modeling for uncertainty estimation. Through extensive empirical evaluation of diverse simulated distributions and 11 real-world tabular datasets, SEMF consistently produces narrower prediction intervals while maintaining the desired coverage probability, outperforming traditional quantile regression methods. Furthermore, without using the quantile (pinball) loss, SEMF allows point predictors, including gradient-boosted trees and neural networks, to be calibrated with conformal quantile regression. The results indicate that SEMF enhances uncertainty quantification under diverse data distributions and is particularly effective for models that otherwise struggle with inherent uncertainty representation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18176v5</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ilia Azizi, Marc-Olivier Boldi, Val\'erie Chavez-Demoulin</dc:creator>
    </item>
    <item>
      <title>Optimal thresholds and algorithms for a model of multi-modal learning in high dimensions</title>
      <link>https://arxiv.org/abs/2407.03522</link>
      <description>arXiv:2407.03522v2 Announce Type: replace 
Abstract: This work explores multi-modal inference in a high-dimensional simplified model, analytically quantifying the performance gain of multi-modal inference over that of analyzing modalities in isolation. We present the Bayes-optimal performance and recovery thresholds in a model where the objective is to recover the latent structures from two noisy data matrices with correlated spikes. The paper derives the approximate message passing (AMP) algorithm for this model and characterizes its performance in the high-dimensional limit via the associated state evolution. The analysis holds for a broad range of priors and noise channels, which can differ across modalities. The linearization of AMP is compared numerically to the widely used partial least squares (PLS) and canonical correlation analysis (CCA) methods, which are both observed to suffer from a sub-optimal recovery threshold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03522v2</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1742-5468/ae0428</arxiv:DOI>
      <arxiv:journal_reference>J. Stat. Mech. (2025) 093302</arxiv:journal_reference>
      <dc:creator>Christian Keup, Lenka Zdeborov\'a</dc:creator>
    </item>
    <item>
      <title>Bayesian Autoregressive Online Change-Point Detection with Time-Varying Parameters</title>
      <link>https://arxiv.org/abs/2407.16376</link>
      <description>arXiv:2407.16376v2 Announce Type: replace 
Abstract: Change points in real-world systems mark significant regime shifts in system dynamics, possibly triggered by exogenous or endogenous factors. These points define regimes for the time evolution of the system and are crucial for understanding transitions in financial, economic, social, environmental, and technological contexts. Building upon the Bayesian approach introduced in \cite{c:07}, we devise a new method for online change point detection in the mean of a univariate time series, which is well suited for real-time applications and is able to handle the general temporal patterns displayed by data in many empirical contexts. We first describe time series as an autoregressive process of an arbitrary order. Second, the variance and correlation of the data are allowed to vary within each regime driven by a scoring rule that updates the value of the parameters for a better fit of the observations. Finally, a change point is detected in a probabilistic framework via the posterior distribution of the current regime length. By modeling temporal dependencies and time-varying parameters, the proposed approach enhances both the estimate accuracy and the forecasting power. Empirical validations using various datasets demonstrate the method's effectiveness in capturing memory and dynamic patterns, offering deeper insights into the non-stationary dynamics of real-world systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16376v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioanna-Yvonni Tsaknaki, Fabrizio Lillo, Piero Mazzarisi</dc:creator>
    </item>
    <item>
      <title>On the Effect of Instability on Learning Continuous-Time Linear Control Systems</title>
      <link>https://arxiv.org/abs/2409.11327</link>
      <description>arXiv:2409.11327v2 Announce Type: replace 
Abstract: We study the problem of system identification for stochastic continuous-time dynamics, based on a single finite-length state trajectory. We present a method for estimating the possibly unstable open-loop matrix by employing properly randomized control inputs. Then, we establish theoretical performance guarantees showing that the estimation error decays with trajectory length, a measure of excitability, and the signal-to-noise ratio, while it grows with dimension. Numerical illustrations that showcase the rates of learning the dynamics, will be provided as well. To perform the theoretical analysis, we develop new technical tools that are of independent interest. That includes non-asymptotic stochastic bounds for highly non-stationary martingales and generalized laws of iterated logarithms, among others.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11327v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Reza Sadeghi Hafshejani, Mohamad Kazem Shirani Fradonbeh</dc:creator>
    </item>
    <item>
      <title>Gaussian Process Priors for Boundary Value Problems of Linear Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2411.16663</link>
      <description>arXiv:2411.16663v2 Announce Type: replace 
Abstract: Working with systems of partial differential equations (PDEs) is a fundamental task in computational science. Well-posed systems are addressed by numerical solvers or neural operators, whereas systems described by data are often addressed by PINNs or Gaussian processes. In this work, we propose Boundary Ehrenpreis--Palamodov Gaussian Processes (B-EPGPs), a novel probabilistic framework for constructing GP priors that satisfy both general systems of linear PDEs with constant coefficients and linear boundary conditions and can be conditioned on a finite data set. We explicitly construct GP priors for representative PDE systems with practical boundary conditions. Formal proofs of correctness are provided and empirical results demonstrating significant accuracy and computational resource improvements over state-of-the-art approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16663v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.AC</category>
      <category>math.NA</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianlei Huang, Marc H\"ark\"onen, Markus Lange-Hegermann, Bogdan Rai\c{t}\u{a}</dc:creator>
    </item>
    <item>
      <title>Gaussian Universality for Diffusion Models</title>
      <link>https://arxiv.org/abs/2501.07741</link>
      <description>arXiv:2501.07741v3 Announce Type: replace 
Abstract: We investigate Gaussian Universality for data distributions generated via diffusion models. By Gaussian Universality we mean that the test error of a generalized linear model $f(\mathbf{W})$ trained for a classification task on the diffusion data matches the test error of $f(\mathbf{W})$ trained on the Gaussian Mixture with matching means and covariances per class.In other words, the test error depends only on the first and second order statistics of the diffusion-generated data in the linear setting. As a corollary, the analysis of the test error for linear classifiers can be reduced to Gaussian data from diffusion-generated data. Analysing the performance of models trained on synthetic data is a pertinent problem due to the surge of methods such as \cite{sehwag2024stretchingdollardiffusiontraining}. Moreover, we show that, for any $1$- Lipschitz scalar function $\phi$, $\phi(\mathbf{x})$ is close to $\mathbb{E} \phi(\mathbf{x})$ with high probability for $\mathbf{x}$ sampled from the conditional diffusion model corresponding to each class. Finally, we note that current approaches for proving universality do not apply to diffusion-generated data as the covariance matrices of the data tend to have vanishing minimum singular values, contrary to the assumption made in the literature. This leaves extending previous mathematical universality results as an intriguing open question.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07741v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Reza Ghane, Anthony Bao, Danil Akhtiamov, Babak Hassibi</dc:creator>
    </item>
    <item>
      <title>A Unified Information-Theoretic Framework for Meta-Learning Generalization</title>
      <link>https://arxiv.org/abs/2501.15559</link>
      <description>arXiv:2501.15559v2 Announce Type: replace 
Abstract: In recent years, information-theoretic generalization bounds have gained increasing attention for analyzing the generalization capabilities of meta-learning algorithms. However, existing results are confined to two-step bounds, failing to provide a sharper characterization of the meta-generalization gap that simultaneously accounts for environment-level and task-level dependencies. This paper addresses this fundamental limitation by developing a unified information-theoretic framework using a single-step derivation. The resulting meta-generalization bounds, expressed in terms of diverse information measures, exhibit substantial advantages over previous work, particularly in terms of tightness, scaling behavior associated with sampled tasks and samples per task, and computational tractability. Furthermore, through gradient covariance analysis, we provide new theoretical insights into the generalization properties of two classes of noisy and iterative meta-learning algorithms, where the meta-learner uses either the entire meta-training data (e.g., Reptile), or separate training and test data within the task (e.g., model agnostic meta-learning (MAML)). Numerical results validate the effectiveness of the derived bounds in capturing the generalization dynamics of meta-learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15559v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wen Wen, Tieliang Gong, Yuxin Dong, Zeyu Gao, Yong-Jin Liu</dc:creator>
    </item>
    <item>
      <title>Accelerated Parallel Tempering via Neural Transports</title>
      <link>https://arxiv.org/abs/2502.10328</link>
      <description>arXiv:2502.10328v3 Announce Type: replace 
Abstract: Markov Chain Monte Carlo (MCMC) algorithms are essential tools in computational statistics for sampling from unnormalised probability distributions, but can be fragile when targeting high-dimensional, multimodal, or complex target distributions. Parallel Tempering (PT) enhances MCMC's sample efficiency through annealing and parallel computation, propagating samples from tractable reference distributions to intractable targets via state swapping across interpolating distributions. The effectiveness of PT is limited by the often minimal overlap between adjacent distributions in challenging problems, which requires increasing the computational resources to compensate. We introduce a framework that accelerates PT by leveraging neural samplers -- including normalising flows, diffusion models, and controlled diffusions -- to reduce the required overlap. Our approach utilises neural samplers in parallel, circumventing the computational burden of neural samplers while preserving the asymptotic consistency of classical PT. We demonstrate theoretically and empirically on a variety of multimodal sampling problems that our method improves sample quality, reduces the computational cost compared to classical PT, and enables efficient free energy/normalising constant estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10328v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leo Zhang, Peter Potaptchik, Jiajun He, Yuanqi Du, Arnaud Doucet, Francisco Vargas, Hai-Dang Dau, Saifuddin Syed</dc:creator>
    </item>
    <item>
      <title>Finite-Sample Analysis of Policy Evaluation for Robust Average Reward Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2502.16816</link>
      <description>arXiv:2502.16816v3 Announce Type: replace 
Abstract: We present the first finite-sample analysis of policy evaluation in robust average-reward Markov Decision Processes (MDPs). Prior work in this setting have established only asymptotic convergence guarantees, leaving open the question of sample complexity. In this work, we address this gap by showing that the robust Bellman operator is a contraction under a carefully constructed semi-norm, and developing a stochastic approximation framework with controlled bias. Our approach builds upon Multi-Level Monte Carlo (MLMC) techniques to estimate the robust Bellman operator efficiently. To overcome the infinite expected sample complexity inherent in standard MLMC, we introduce a truncation mechanism based on a geometric distribution, ensuring a finite expected sample complexity while maintaining a small bias that decays exponentially with the truncation level. Our method achieves the order-optimal sample complexity of $\tilde{\mathcal{O}}(\epsilon^{-2})$ for robust policy evaluation and robust average reward estimation, marking a significant advancement in robust reinforcement learning theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16816v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Xu, Washim Uddin Mondal, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Conformal prediction of future insurance claims in the regression problem</title>
      <link>https://arxiv.org/abs/2503.03659</link>
      <description>arXiv:2503.03659v3 Announce Type: replace 
Abstract: In the current insurance literature, prediction of insurance claims in the regression problem is often performed with a statistical model. This model-based approach may potentially suffer from several drawbacks: (i) model misspecification, (ii) selection effect, and (iii) lack of finite-sample validity. This article addresses these three issues simultaneously by employing conformal prediction -- a general machine learning strategy for valid predictions. The proposed method is both model-free and tuning-parameter-free. It also guarantees finite-sample validity at a pre-assigned coverage probability level. Examples, based on both simulated and real data, are provided to demonstrate the excellent performance of the proposed method and its applications in insurance, especially regarding meeting the solvency capital requirement of European insurance regulation, Solvency II.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03659v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liang Hong</dc:creator>
    </item>
    <item>
      <title>Sobolev norm inconsistency of kernel interpolation</title>
      <link>https://arxiv.org/abs/2504.20617</link>
      <description>arXiv:2504.20617v2 Announce Type: replace 
Abstract: We study the consistency of minimum-norm interpolation in reproducing kernel Hilbert spaces corresponding to bounded kernels. Our main result give lower bounds for the generalization error of the kernel interpolation measured in a continuous scale of norms that interpolate between $L^2$ and the hypothesis space. These lower bounds imply that kernel interpolation is always inconsistent, when the smoothness index of the norm is larger than a constant that depends only on the embedding index of the hypothesis space and the decay rate of the eigenvalues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20617v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunfei Yang</dc:creator>
    </item>
    <item>
      <title>Flexible and Efficient Drift Detection without Labels</title>
      <link>https://arxiv.org/abs/2506.08734</link>
      <description>arXiv:2506.08734v2 Announce Type: replace 
Abstract: Machine learning models are being increasingly used to automate decisions in almost every domain, and ensuring the performance of these models is crucial for ensuring high quality machine learning enabled services. Ensuring concept drift is detected early is thus of the highest importance. A lot of research on concept drift has focused on the supervised case that assumes the true labels of supervised tasks are available immediately after making predictions. Controlling for false positives while monitoring the performance of predictive models used to make inference from extremely large datasets periodically, where the true labels are not instantly available, becomes extremely challenging. We propose a flexible and efficient concept drift detection algorithm that uses classical statistical process control in a label-less setting to accurately detect concept drifts. We show empirically that under computational constraints, our approach has better statistical power than previous known methods. Furthermore, we introduce a new semi-supervised drift detection framework to model the scenario of detecting drift (without labels) given prior detections, and show how our drift detection algorithm can be incorporated effectively into this framework. We demonstrate promising performance via numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08734v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nelvin Tan, Yu-Ching Shih, Dong Yang, Amol Salunkhe</dc:creator>
    </item>
    <item>
      <title>CLEAR: Calibrated Learning for Epistemic and Aleatoric Risk</title>
      <link>https://arxiv.org/abs/2507.08150</link>
      <description>arXiv:2507.08150v2 Announce Type: replace 
Abstract: Existing methods typically address either aleatoric uncertainty due to measurement noise or epistemic uncertainty resulting from limited data, but not both in a balanced manner. We propose CLEAR, a calibration method with two distinct parameters, $\gamma_1$ and $\gamma_2$, to combine the two uncertainty components and improve the conditional coverage of predictive intervals for regression tasks. CLEAR is compatible with any pair of aleatoric and epistemic estimators; we show how it can be used with (i) quantile regression for aleatoric uncertainty and (ii) ensembles drawn from the Predictability-Computability-Stability (PCS) framework for epistemic uncertainty. Across 17 diverse real-world datasets, CLEAR achieves an average improvement of 28.2% and 17.4% in the interval width compared to the two individually calibrated baselines while maintaining nominal coverage. Similar improvements are observed when applying CLEAR to Deep Ensembles (epistemic) and Simultaneous Quantile Regression (aleatoric). The benefits are especially evident in scenarios dominated by high aleatoric or epistemic uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08150v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ilia Azizi, Juraj Bodik, Jakob Heiss, Bin Yu</dc:creator>
    </item>
    <item>
      <title>Flow Matching for Efficient and Scalable Data Assimilation</title>
      <link>https://arxiv.org/abs/2508.13313</link>
      <description>arXiv:2508.13313v3 Announce Type: replace 
Abstract: Data assimilation (DA) estimates a dynamical system's state from noisy observations. Recent generative models like the ensemble score filter (EnSF) improve DA in high-dimensional nonlinear settings but are computationally expensive. We introduce the ensemble flow filter (EnFF), a training-free, flow matching (FM)-based framework that accelerates sampling and offers flexibility in flow design. EnFF uses Monte Carlo estimators for the marginal flow field, localized guidance for observation assimilation, and utilizes a novel flow that exploits the Bayesian DA formulation. It generalizes classical filters such as the bootstrap particle filter and ensemble Kalman filter. Experiments on high-dimensional benchmarks demonstrate EnFF's improved cost-accuracy tradeoffs and scalability, highlighting FM's potential for efficient, scalable DA. Code is available at https://github.com/Utah-Math-Data-Science/Data-Assimilation-Flow-Matching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13313v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taos Transue, Bohan Chen, So Takao, Bao Wang</dc:creator>
    </item>
    <item>
      <title>Diffusion Generative Models Meet Compressed Sensing, with Applications to Imaging and Finance</title>
      <link>https://arxiv.org/abs/2509.03898</link>
      <description>arXiv:2509.03898v2 Announce Type: replace 
Abstract: In this study we develop dimension-reduction techniques to accelerate diffusion model inference in the context of synthetic data generation. The idea is to integrate compressed sensing into diffusion models (hence, CSDM): First, compress the dataset into a latent space (from an ambient space), and train a diffusion model in the latent space; next, apply a compressed sensing algorithm to the samples generated in the latent space for decoding back to the original space; and the goal is to facilitate the efficiency of both model training and inference. Under certain sparsity assumptions on data, our proposed approach achieves provably faster convergence, via combining diffusion model inference with sparse recovery. It also sheds light on the best choice of the latent space dimension. To illustrate the effectiveness of this approach, we run numerical experiments on a range of datasets, including handwritten digits, medical and climate images, and financial time series for stress testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03898v2</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhengyi Guo, Jiatu Li, Wenpin Tang, David D. Yao</dc:creator>
    </item>
    <item>
      <title>Last-Iterate Convergence: Zero-Sum Games and Constrained Min-Max Optimization</title>
      <link>https://arxiv.org/abs/1807.04252</link>
      <description>arXiv:1807.04252v5 Announce Type: replace-cross 
Abstract: Motivated by applications in Game Theory, Optimization, and Generative Adversarial Networks, recent work of Daskalakis et al \cite{DISZ17} and follow-up work of Liang and Stokes \cite{LiangS18} have established that a variant of the widely used Gradient Descent/Ascent procedure, called "Optimistic Gradient Descent/Ascent (OGDA)", exhibits last-iterate convergence to saddle points in {\em unconstrained} convex-concave min-max optimization problems. We show that the same holds true in the more general problem of {\em constrained} min-max optimization under a variant of the no-regret Multiplicative-Weights-Update method called "Optimistic Multiplicative-Weights Update (OMWU)". This answers an open question of Syrgkanis et al \cite{SALS15}.
  The proof of our result requires fundamentally different techniques from those that exist in no-regret learning literature and the aforementioned papers. We show that OMWU monotonically improves the Kullback-Leibler divergence of the current iterate to the (appropriately normalized) min-max solution until it enters a neighborhood of the solution. Inside that neighborhood we show that OMWU is locally (asymptotically) stable converging to the exact solution. We believe that our techniques will be useful in the analysis of the last iterate of other learning algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:1807.04252v5</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Constantinos Daskalakis, Ioannis Panageas</dc:creator>
    </item>
    <item>
      <title>Last iterate convergence in no-regret learning: constrained min-max optimization for convex-concave landscapes</title>
      <link>https://arxiv.org/abs/2002.06768</link>
      <description>arXiv:2002.06768v3 Announce Type: replace-cross 
Abstract: In a recent series of papers it has been established that variants of Gradient Descent/Ascent and Mirror Descent exhibit last iterate convergence in convex-concave zero-sum games. Specifically, \cite{DISZ17, LiangS18} show last iterate convergence of the so called "Optimistic Gradient Descent/Ascent" for the case of \textit{unconstrained} min-max optimization. Moreover, in \cite{Metal} the authors show that Mirror Descent with an extra gradient step displays last iterate convergence for convex-concave problems (both constrained and unconstrained), though their algorithm does not follow the online learning framework; it uses extra information rather than \textit{only} the history to compute the next iteration. In this work, we show that "Optimistic Multiplicative-Weights Update (OMWU)" which follows the no-regret online learning framework, exhibits last iterate convergence locally for convex-concave games, generalizing the results of \cite{DP19} where last iterate convergence of OMWU was shown only for the \textit{bilinear case}. We complement our results with experiments that indicate fast convergence of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2002.06768v3</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Lei, Sai Ganesh Nagarajan, Ioannis Panageas, Xiao Wang</dc:creator>
    </item>
    <item>
      <title>CRAUM-Net: Contextual Recursive Attention with Uncertainty Modeling for Salient Object Detection</title>
      <link>https://arxiv.org/abs/2006.08453</link>
      <description>arXiv:2006.08453v5 Announce Type: replace-cross 
Abstract: Salient Object Detection (SOD) plays a crucial role in many computer vision applications, requiring accurate localization and precise boundary delineation of salient regions. In this work, we present a novel framework that integrates multi-scale context aggregation, advanced attention mechanisms, and an uncertainty-aware module for improved SOD performance. Our Adaptive Cross-Scale Context Module effectively fuses features from multiple levels, leveraging Recursive Channel Spatial Attention and Convolutional Block Attention to enhance salient feature representation. We further introduce an edge-aware decoder that incorporates a dedicated Edge Extractor for boundary refinement, complemented by Monte Carlo Dropout to estimate uncertainty in predictions. To train our network robustly, we employ a combination of boundary-sensitive and topology-preserving loss functions, including Boundary IoU, Focal Tversky, and Topological Saliency losses. Evaluation metrics such as uncertainty-calibrated error and Boundary F1 score, along with the standard SOD metrics, demonstrate our method's superior ability to produce accurate and reliable saliency maps. Extensive experiments validate the effectiveness of our approach in capturing fine-grained details while quantifying prediction confidence, advancing the state-of-the-art in salient object detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2006.08453v5</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhinav Sagar</dc:creator>
    </item>
    <item>
      <title>Combining Experimental and Observational Data for Identification and Estimation of Long-Term Causal Effects</title>
      <link>https://arxiv.org/abs/2201.10743</link>
      <description>arXiv:2201.10743v4 Announce Type: replace-cross 
Abstract: We study identifying and estimating the causal effect of a treatment variable on a long-term outcome using data from an observational and an experimental domain. The observational data are subject to unobserved confounding. Furthermore, subjects in the experiment are only followed for a short period; thus, long-term effects are unobserved, though short-term effects are available. Consequently, neither data source alone suffices for causal inference on the long-term outcome, necessitating a principled fusion of the two. We propose three approaches for data fusion for the purpose of identifying and estimating the causal effect. The first assumes equal confounding bias for short-term and long-term outcomes. The second weakens this assumption by leveraging an observed confounder for which the short-term and long-term potential outcomes share the same partial additive association with this confounder. The third approach employs proxy variables of the latent confounder of the treatment-outcome relationship, extending the proximal causal inference framework to the data fusion setting. For each approach, we develop influence function-based estimators and analyze their robustness properties. We illustrate our methods by estimating the effect of class size on 8th-grade SAT scores using data from the Project STAR experiment combined with observational data from the Early Childhood Longitudinal Study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.10743v4</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>AmirEmad Ghassami, Chang Liu, Alan Yang, David Richardson, Ilya Shpitser, Eric Tchetgen Tchetgen</dc:creator>
    </item>
    <item>
      <title>Causal inference for the expected number of recurrent events in the presence of a terminal event</title>
      <link>https://arxiv.org/abs/2306.16571</link>
      <description>arXiv:2306.16571v3 Announce Type: replace-cross 
Abstract: While recurrent event analyses have been extensively studied, limited attention has been given to causal inference within the framework of recurrent event analysis. We develop a multiply robust estimation framework for causal inference in recurrent event data with a terminal failure event. We define our estimand as the vector comprising both the expected number of recurrent events and the failure survival function evaluated along a sequence of landmark times. We show that the estimand can be identified under a weaker condition than conditionally independent censoring and derive the associated class of influence functions under general censoring and failure distributions (i.e., without assuming absolute continuity). We propose a particular estimator within this class for further study, conduct comprehensive simulation studies to evaluate the small-sample performance of our estimator, and illustrate the proposed estimator using a large Medicare dataset to assess the causal effect of PM$_{2.5}$ on recurrent cardiovascular hospitalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16571v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin R. Baer, Trang Bui, Daniel Mork, Robert L. Strawderman, Ashkan Ertefaie</dc:creator>
    </item>
    <item>
      <title>Two-Stage Nuisance Function Estimation for Causal Mediation Analysis</title>
      <link>https://arxiv.org/abs/2404.00735</link>
      <description>arXiv:2404.00735v3 Announce Type: replace-cross 
Abstract: Tchetgen Tchetgen and Shpitser (2012) introduced an efficient, debiased, and robust influence function-based estimator for the mediation functional, which is the key component in mediation analysis. This estimator relies on the treatment, mediator, and outcome mean mechanisms. However, treating these three mechanisms as nuisance functions and fitting them as accurately as possible may not be the most effective approach. Instead, it is essential to identify the specific functionals and aspects of these mechanisms that impact the estimation of the mediation functional. In this work, we consider a specific reparametrization of the likelihood function that requires four nuisance functions. To estimate them, we propose a two-stage estimation strategy guided by the role of the nuisance functions in the bias structure of the influence function-based estimator. In particular, two of the functions are estimated using a novel nonparametric weighted balancing approach that directly targets the bias of the final mediation functional estimator. We show that the resulting estimator is consistent and asymptotically normal under certain conditions and attains multiple robustness against misspecifications of the nuisance functions. In simulations, our estimator demonstrated better stability and reduced bias and mean squared error compared to the original influence function-based estimator and a naive estimator. In an application to NHANES 2013-2014 data, our approach suggests that obesity results in a 60% higher odds of coronary heart disease, with roughly 35% higher odds attributable to the direct pathway independent of Glycohemoglobin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00735v3</guid>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chang Liu, AmirEmad Ghassami</dc:creator>
    </item>
    <item>
      <title>Minimax Regret Learning for Data with Heterogeneous Subgroups</title>
      <link>https://arxiv.org/abs/2405.01709</link>
      <description>arXiv:2405.01709v2 Announce Type: replace-cross 
Abstract: Modern complex datasets often consist of various sub-populations with known group information. In the presence of sub-population heterogeneity, it is crucial to develop robust and generalizable learning methods that (1) can enjoy robust performance on each of the training populations, and (2) is generalizable to an unseen testing population. While various min-max formulations have been proposed to achieve (1) in the robust learning literature, their generalization to an unseen testing is less explored. Moreover, a general min-max formulation can be sensitive to the noise heterogeneity, and, in the extreme case, be degenerate such that a single high-noise population dominates. The min-max-regret (MMR) can mitigate these challenges. In this work, we consider a distribution-free robust hierarchical model for the generalization from multiple training populations to an unseen testing population. Under the robust hierarchical model, the empirical MMR can enjoy the regret guarantees on each of the training populations as well as the unseen testing population. We further specialize the general MMR framework to linear regression and generalized linear model, where we characterize the geometry of MMR and its distinction from other robust methods. We demonstrate the effectiveness of MMR through extensive simulation studies and an application to image recognition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01709v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weibin Mo, Weijing Tang, Songkai Xue, Yufeng Liu, Ji Zhu</dc:creator>
    </item>
    <item>
      <title>Precise Asymptotics of Bagging Regularized M-estimators</title>
      <link>https://arxiv.org/abs/2409.15252</link>
      <description>arXiv:2409.15252v3 Announce Type: replace-cross 
Abstract: We characterize the squared prediction risk of ensemble estimators obtained through subagging (subsample bootstrap aggregating) regularized M-estimators and construct a consistent estimator for the risk. Specifically, we consider a heterogeneous collection of $M \ge 1$ regularized M-estimators, each trained with (possibly different) subsample sizes, convex differentiable losses, and convex regularizers. We operate under the proportional asymptotics regime, where the sample size $n$, feature size $p$, and subsample sizes $k_m$ for $m \in [M]$ all diverge with fixed limiting ratios $n/p$ and $k_m/n$. Key to our analysis is a new result on the joint asymptotic behavior of correlations between the estimator and residual errors on overlapping subsamples, governed through a (provably) contractive nonlinear system of equations. Of independent interest, we also establish convergence of trace functionals related to degrees of freedom in the non-ensemble setting (with $M = 1$) along the way, extending previously known cases for squared loss with ridge and lasso regularizers.
  When specialized to homogeneous ensembles trained with a common loss, regularizer, and subsample size, the risk characterization sheds some light on the implicit regularization effect due to the ensemble and subsample sizes $(M,k)$. For any ensemble size $M$, optimally tuning subsample size yields sample-wise monotonic risk. For the full-ensemble estimator (when $M \to \infty$), the optimal subsample size $k^\star$ tends to be in the overparameterized regime $(k^\star \le \min\{n,p\})$, when explicit regularization is vanishing. Finally, joint optimization of subsample size, ensemble size, and regularization can significantly outperform regularizer optimization alone on the full data (without any subagging).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15252v3</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takuya Koriyama, Pratik Patil, Jin-Hong Du, Kai Tan, Pierre C. Bellec</dc:creator>
    </item>
    <item>
      <title>Sparse Covariance Neural Networks</title>
      <link>https://arxiv.org/abs/2410.01669</link>
      <description>arXiv:2410.01669v2 Announce Type: replace-cross 
Abstract: Covariance Neural Networks (VNNs) perform graph convolutions on the covariance matrix of input data to leverage correlation information as pairwise connections. They have achieved success in a multitude of applications such as neuroscience, financial forecasting, and sensor networks. However, the empirical covariance matrix on which VNNs operate typically contains spurious correlations, creating a mismatch with the actual covariance matrix that degrades VNNs' performance and computational efficiency. To tackle this issue, we put forth Sparse coVariance Neural Networks (S-VNNs), a framework that applies sparsification techniques on the sample covariance matrix and incorporates the latter into the VNN architecture. We investigate the S-VNN when the underlying data covariance matrix is both sparse and dense. When the true covariance matrix is sparse, we propose hard and soft thresholding to improve the covariance estimation and reduce the computational cost. Instead, when the true covariance is dense, we propose a stochastic sparsification where data correlations are dropped in probability according to principled strategies. Besides performance and computation improvements, we show that S-VNNs are more stable to finite-sample covariance estimations than nominal VNNs and the analogous sparse principal component analysis. By analyzing the impact of sparsification on their behavior, we tie the S-VNN stability to the data distribution and sparsification approach. We support our theoretical findings with experimental results on a variety of application scenarios, ranging from brain data to human action recognition, and show an improved task performance, improved stability, and reduced computational time compared to alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01669v2</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Cavallo, Zhan Gao, Elvin Isufi</dc:creator>
    </item>
    <item>
      <title>Deeper Insights into Deep Graph Convolutional Networks: Stability and Generalization</title>
      <link>https://arxiv.org/abs/2410.08473</link>
      <description>arXiv:2410.08473v2 Announce Type: replace-cross 
Abstract: Graph convolutional networks (GCNs) have emerged as powerful models for graph learning tasks, exhibiting promising performance in various domains. While their empirical success is evident, there is a growing need to understand their essential ability from a theoretical perspective. Existing theoretical research has primarily focused on the analysis of single-layer GCNs, while a comprehensive theoretical exploration of the stability and generalization of deep GCNs remains limited. In this paper, we bridge this gap by delving into the stability and generalization properties of deep GCNs, aiming to provide valuable insights by characterizing rigorously the associated upper bounds. Our theoretical results reveal that the stability and generalization of deep GCNs are influenced by certain key factors, such as the maximum absolute eigenvalue of the graph filter operators and the depth of the network. Our theoretical studies contribute to a deeper understanding of the stability and generalization properties of deep GCNs, potentially paving the way for developing more reliable and well-performing models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08473v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TPAMI.2025.3616350</arxiv:DOI>
      <dc:creator>Guangrui Yang, Ming Li, Han Feng, Xiaosheng Zhuang</dc:creator>
    </item>
    <item>
      <title>Haar-Laplacian for directed graphs</title>
      <link>https://arxiv.org/abs/2411.15527</link>
      <description>arXiv:2411.15527v2 Announce Type: replace-cross 
Abstract: This paper introduces a novel Laplacian matrix aiming to enable the construction of spectral convolutional networks and to extend the signal processing applications for directed graphs. Our proposal is inspired by a Haar-like transformation and produces a Hermitian matrix which is not only in one-to-one relation with the adjacency matrix, preserving both direction and weight information, but also enjoys desirable additional properties like scaling robustness, sensitivity, continuity, and directionality. We take a theoretical standpoint and support the conformity of our approach with the spectral graph theory. Then, we address two use-cases: graph learning (by introducing HaarNet, a spectral graph convolutional network built with our Haar-Laplacian) and graph signal processing. We show that our approach gives better results in applications like weight prediction and denoising on directed graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15527v2</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Theodor-Adrian Badea, Bogdan Dumitrescu</dc:creator>
    </item>
    <item>
      <title>Off-Policy Maximum Entropy RL with Future State and Action Visitation Measures</title>
      <link>https://arxiv.org/abs/2412.06655</link>
      <description>arXiv:2412.06655v3 Announce Type: replace-cross 
Abstract: Maximum entropy reinforcement learning integrates exploration into policy learning by providing additional intrinsic rewards proportional to the entropy of some distribution. In this paper, we propose a novel approach in which the intrinsic reward function is the relative entropy of the discounted distribution of states and actions (or features derived from these states and actions) visited during future time steps. This approach is motivated by two results. First, a policy maximizing the expected discounted sum of intrinsic rewards also maximizes a lower bound on the state-action value function of the decision process. Second, the distribution used in the intrinsic reward definition is the fixed point of a contraction operator. Existing algorithms can therefore be adapted to learn this fixed point off-policy and to compute the intrinsic rewards. We finally introduce an algorithm maximizing our new objective, and we show that resulting policies have good state-action space coverage and achieve high-performance control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06655v3</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Adrien Bolland, Gaspard Lambrechts, Damien Ernst</dc:creator>
    </item>
    <item>
      <title>Non-Expansive Mappings in Two-Time-Scale Stochastic Approximation: Finite-Time Analysis</title>
      <link>https://arxiv.org/abs/2501.10806</link>
      <description>arXiv:2501.10806v2 Announce Type: replace-cross 
Abstract: Two-time-scale stochastic approximation algorithms are iterative methods used in applications such as optimization, reinforcement learning, and control. Finite-time analysis of these algorithms has primarily focused on fixed point iterations where both time-scales have contractive mappings. In this work, we broaden the scope of such analyses by considering settings where the slower time-scale has a non-expansive mapping. For such algorithms, the slower time-scale can be viewed as a stochastic inexact Krasnoselskii-Mann iteration. We also study a variant where the faster time-scale has a projection step which leads to non-expansiveness in the slower time-scale. We show that the last-iterate mean square residual error for such algorithms decays at a rate $O(1/k^{1/4-\epsilon})$, where $\epsilon&gt;0$ is arbitrarily small. We further establish almost sure convergence of iterates to the set of fixed points. We demonstrate the applicability of our framework by applying our results to minimax optimization, linear stochastic approximation, and Lagrangian optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10806v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddharth Chandak</dc:creator>
    </item>
    <item>
      <title>DeepFRC: An End-to-End Deep Learning Model for Functional Registration and Classification</title>
      <link>https://arxiv.org/abs/2501.18116</link>
      <description>arXiv:2501.18116v3 Announce Type: replace-cross 
Abstract: Functional data, representing curves or trajectories, are ubiquitous in fields like biomedicine and motion analysis. A fundamental challenge is phase variability -- temporal misalignments that obscure underlying patterns and degrade model performance. Current methods often address registration (alignment) and classification as separate, sequential tasks. This paper introduces DeepFRC, an end-to-end deep learning framework that jointly learns diffeomorphic warping functions and a classifier within a unified architecture. DeepFRC combines a neural deformation operator for elastic alignment, a spectral representation using Fourier basis for smooth functional embedding, and a class-aware contrastive loss that promotes both intra-class coherence and inter-class separation. We provide the first theoretical guarantees for such a joint model, proving its ability to approximate optimal warpings and establishing a data-dependent generalization bound that formally links registration fidelity to classification performance. Extensive experiments on synthetic and real-world datasets demonstrate that DeepFRC consistently outperforms state-of-the-art methods in both alignment quality and classification accuracy, while ablation studies validate the synergy of its components. DeepFRC also shows notable robustness to noise, missing data, and varying dataset scales. Code is available at https://github.com/Drivergo-93589/DeepFRC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18116v3</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siyuan Jiang, Yihan Hu, Wenjie Li, Pengcheng Zeng</dc:creator>
    </item>
    <item>
      <title>Faster Convergence of Riemannian Stochastic Gradient Descent with Increasing Batch Size</title>
      <link>https://arxiv.org/abs/2501.18164</link>
      <description>arXiv:2501.18164v5 Announce Type: replace-cross 
Abstract: We theoretically analyzed the convergence behavior of Riemannian stochastic gradient descent (RSGD) and found that using an increasing batch size leads to faster convergence than using a constant batch size, not only with a constant learning rate but also with a decaying learning rate, such as cosine annealing decay and polynomial decay. The convergence rate improves from $O(T^{-1}+C)$ with a constant batch size to $O(T^{-1})$ with an increasing batch size, where $T$ denotes the total number of iterations and $C$ is a constant. Using principal component analysis and low-rank matrix completion, we investigated, both theoretically and numerically, how an increasing batch size affects computational time as quantified by stochastic first-order oracle (SFO) complexity. An increasing batch size was found to reduce the SFO complexity of RSGD. Furthermore, an increasing batch size was found to offer the advantages of both small and large constant batch sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18164v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kanata Oowada, Hideaki Iiduka</dc:creator>
    </item>
    <item>
      <title>DAL: A Practical Prior-Free Black-Box Framework for Non-Stationary Bandits</title>
      <link>https://arxiv.org/abs/2501.19401</link>
      <description>arXiv:2501.19401v4 Announce Type: replace-cross 
Abstract: We introduce a practical, black-box framework termed Detection Augmented Learning (DAL) for the problem of non-stationary bandits without prior knowledge of the underlying non-stationarity. DAL accepts any stationary bandit algorithm as input and augments it with a change detector, enabling applicability to all common bandit variants. Extensive experimentation demonstrates that DAL consistently surpasses current state-of-the-art methods across diverse non-stationary scenarios, including synthetic benchmarks and real-world datasets, underscoring its versatility and scalability. We provide theoretical insights into DAL's strong empirical performance, complemented by thorough experimental validation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19401v4</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Argyrios Gerogiannis, Yu-Han Huang, Subhonmesh Bose, Venugopal V. Veeravalli</dc:creator>
    </item>
    <item>
      <title>Half-order Fine-Tuning for Diffusion Model: A Recursive Likelihood Ratio Optimizer</title>
      <link>https://arxiv.org/abs/2502.00639</link>
      <description>arXiv:2502.00639v3 Announce Type: replace-cross 
Abstract: The probabilistic diffusion model (DM), generating content by inferencing through a recursive chain structure, has emerged as a powerful framework for visual generation. After pre-training on enormous data, the model needs to be properly aligned to meet requirements for downstream applications. How to efficiently align the foundation DM is a crucial task. Contemporary methods are either based on Reinforcement Learning (RL) or truncated Backpropagation (BP). However, RL and truncated BP suffer from low sample efficiency and biased gradient estimation, respectively, resulting in limited improvement or, even worse, complete training failure. To overcome the challenges, we propose the Recursive Likelihood Ratio (RLR) optimizer, a Half-Order (HO) fine-tuning paradigm for DM. The HO gradient estimator enables the computation graph rearrangement within the recursive diffusive chain, making the RLR's gradient estimator an unbiased one with lower variance than other methods. We theoretically investigate the bias, variance, and convergence of our method. Extensive experiments are conducted on image and video generation to validate the superiority of the RLR. Furthermore, we propose a novel prompt technique that is natural for the RLR to achieve a synergistic effect.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00639v3</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Ren, Zishi Zhang, Jingyang Jiang, Zehao Li, Shentao Qin, Yi Zheng, Guanghao Li, Qianyou Sun, Yan Li, Jiafeng Liang, Xinping Li, Yijie Peng</dc:creator>
    </item>
    <item>
      <title>InfoBridge: Mutual Information estimation via Bridge Matching</title>
      <link>https://arxiv.org/abs/2502.01383</link>
      <description>arXiv:2502.01383v3 Announce Type: replace-cross 
Abstract: Diffusion bridge models have recently become a powerful tool in the field of generative modeling. In this work, we leverage their power to address another important problem in machine learning and information theory, the estimation of the mutual information (MI) between two random variables. Neatly framing MI estimation as a domain transfer problem, we construct an unbiased estimator for data posing difficulties for conventional MI estimators. We showcase the performance of our estimator on three standard MI estimation benchmarks, i.e., low-dimensional, image-based and high MI, and on real-world data, i.e., protein language model embeddings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01383v3</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergei Kholkin, Ivan Butakov, Evgeny Burnaev, Nikita Gushchin, Alexander Korotin</dc:creator>
    </item>
    <item>
      <title>Stability and performance guarantees for misspecified multivariate score-driven filters</title>
      <link>https://arxiv.org/abs/2502.05021</link>
      <description>arXiv:2502.05021v5 Announce Type: replace-cross 
Abstract: Can stochastic gradient methods track a moving target? We address the problem of tracking multivariate time-varying parameters under noisy observations and potential model misspecification. Specifically, we examine implicit and explicit score-driven (ISD and ESD) filters, which update parameter predictions using the gradient of the logarithmic postulated observation density (commonly referred to as the score). For both filter types, we derive novel sufficient conditions that ensure the exponential stability of the filtered parameter path and the existence of a finite mean squared error (MSE) bound relative to the pseudo-true parameter path. Our (non-)asymptotic MSE bounds rely on mild moment conditions on the data-generating process, while our stability results are agnostic about the true process. For the ISD filter, concavity of the postulated log density combined with simple parameter restrictions is sufficient to guarantee stability. In contrast, the ESD filter additionally requires the score to be Lipschitz continuous and the learning rate to be sufficiently small. We validate our theoretical findings through simulation studies, showing that ISD filters outperform ESD filters in terms of accuracy and stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05021v5</guid>
      <category>stat.ME</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Donker van Heel, Rutger-Jan Lange, Bram van Os, Dick van Dijk</dc:creator>
    </item>
    <item>
      <title>Functional Complexity-adaptive Temporal Tensor Decomposition</title>
      <link>https://arxiv.org/abs/2502.06164</link>
      <description>arXiv:2502.06164v3 Announce Type: replace-cross 
Abstract: Tensor decomposition is a fundamental tool for analyzing multi-dimensional data by learning low-rank factors to represent high-order interactions. While recent works on temporal tensor decomposition have made significant progress by incorporating continuous timestamps in latent factors, they still struggle with general tensor data with continuous indexes not only in the temporal mode but also in other modes, such as spatial coordinates in climate data. Moreover, the challenge of self-adapting model complexity is largely unexplored in functional temporal tensor models, with existing methods being inapplicable in this setting. To address these limitations, we propose functional \underline{C}omplexity-\underline{A}daptive \underline{T}emporal \underline{T}ensor d\underline{E}composition (\textsc{Catte}).
  Our approach encodes continuous spatial indexes as learnable Fourier features and employs neural ODEs in latent space to learn the temporal trajectories of factors. To enable automatic adaptation of model complexity, we introduce a sparsity-inducing prior over the factor trajectories.
  We develop an efficient variational inference scheme with an analytical evidence lower bound, enabling sampling-free optimization. Through extensive experiments on both synthetic and real-world datasets, we demonstrate that \textsc{Catte} not only reveals the underlying ranks of functional temporal tensors but also significantly outperforms existing methods in prediction performance and robustness against noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06164v3</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Panqi Chen, Lei Cheng, Jianlong Li, Weichang Li, Weiqing Liu, Jiang Bian, Shikai Fang</dc:creator>
    </item>
    <item>
      <title>Recurrent Memory for Online Interdomain Gaussian Processes</title>
      <link>https://arxiv.org/abs/2502.08736</link>
      <description>arXiv:2502.08736v4 Announce Type: replace-cross 
Abstract: We propose a novel online Gaussian process (GP) model that is capable of capturing long-term memory in sequential data in an online learning setting. Our model, Online HiPPO Sparse Variational Gaussian Process (OHSVGP), leverages the HiPPO (High-order Polynomial Projection Operators) framework, which is popularized in the RNN domain due to its long-range memory modeling capabilities. We interpret the HiPPO time-varying orthogonal projections as inducing variables with time-dependent orthogonal polynomial basis functions, which allows the SVGP inducing variables to memorize the process history. We show that the HiPPO framework fits naturally into the interdomain GP framework and demonstrate that the kernel matrices can also be updated online in a recurrence form based on the ODE evolution of HiPPO. We evaluate OHSVGP with online prediction for 1D time series, continual learning in discriminative GP model for data with multidimensional inputs, and deep generative modeling with sparse Gaussian process variational autoencoder, showing that it outperforms existing online GP methods in terms of predictive performance, long-term memory preservation, and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08736v4</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wenlong Chen, Naoki Kiyohara, Harrison Bo Hua Zhu, Jacob Curran-Sebastian, Samir Bhatt, Yingzhen Li</dc:creator>
    </item>
    <item>
      <title>Optimal and Provable Calibration in High-Dimensional Binary Classification: Angular Calibration and Platt Scaling</title>
      <link>https://arxiv.org/abs/2502.15131</link>
      <description>arXiv:2502.15131v2 Announce Type: replace-cross 
Abstract: We study the fundamental problem of calibrating a linear binary classifier of the form $\sigma(\hat{w}^\top x)$, where the feature vector $x$ is Gaussian, $\sigma$ is a link function, and $\hat{w}$ is an estimator of the true linear weight $w^\star$. By interpolating with a noninformative $\textit{chance classifier}$, we construct a well-calibrated predictor whose interpolation weight depends on the angle $\angle(\hat{w}, w_\star)$ between the estimator $\hat{w}$ and the true linear weight $w_\star$. We establish that this angular calibration approach is provably well-calibrated in a high-dimensional regime where the number of samples and features both diverge, at a comparable rate. The angle $\angle(\hat{w}, w_\star)$ can be consistently estimated. Furthermore, the resulting predictor is uniquely $\textit{Bregman-optimal}$, minimizing the Bregman divergence to the true label distribution within a suitable class of calibrated predictors. Our work is the first to provide a calibration strategy that satisfies both calibration and optimality properties provably in high dimensions. Additionally, we identify conditions under which a classical Platt-scaling predictor converges to our Bregman-optimal calibrated solution. Thus, Platt-scaling also inherits these desirable properties provably in high dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15131v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yufan Li, Pragya Sur</dc:creator>
    </item>
    <item>
      <title>Joint Value Estimation and Bidding in Repeated First-Price Auctions</title>
      <link>https://arxiv.org/abs/2502.17292</link>
      <description>arXiv:2502.17292v2 Announce Type: replace-cross 
Abstract: We study regret minimization in repeated first-price auctions (FPAs), where a bidder observes only the realized outcome after each auction -- win or loss. This setup reflects practical scenarios in online display advertising where the actual value of an impression depends on the difference between two potential outcomes, such as clicks or conversion rates, when the auction is won versus lost. We analyze three outcome models: (1) adversarial outcomes without features, (2) linear potential outcomes with features, and (3) linear treatment effects in features. For each setting, we propose algorithms that jointly estimate private values and optimize bidding strategies, achieving near-optimal regret bounds. Notably, our framework enjoys a unique feature that the treatments are also actively chosen, and hence eliminates the need for the overlap condition commonly required in causal inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17292v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxiao Wen, Yanjun Han, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>What Makes a Reward Model a Good Teacher? An Optimization Perspective</title>
      <link>https://arxiv.org/abs/2503.15477</link>
      <description>arXiv:2503.15477v3 Announce Type: replace-cross 
Abstract: The success of Reinforcement Learning from Human Feedback (RLHF) critically depends on the quality of the reward model. However, while this quality is primarily evaluated through accuracy, it remains unclear whether accuracy fully captures what makes a reward model an effective teacher. We address this question from an optimization perspective. First, we prove that regardless of how accurate a reward model is, if it induces low reward variance, then the RLHF objective suffers from a flat landscape. Consequently, even a perfectly accurate reward model can lead to extremely slow optimization, underperforming less accurate models that induce higher reward variance. We additionally show that a reward model that works well for one language model can induce low reward variance, and thus a flat objective landscape, for another. These results establish a fundamental limitation of evaluating reward models solely based on accuracy or independently of the language model they guide. Experiments using models of up to 8B parameters corroborate our theory, demonstrating the interplay between reward variance, accuracy, and reward maximization rate. Overall, our findings highlight that beyond accuracy, a reward model needs to induce sufficient variance for efficient~optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15477v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noam Razin, Zixuan Wang, Hubert Strauss, Stanley Wei, Jason D. Lee, Sanjeev Arora</dc:creator>
    </item>
    <item>
      <title>Finite-Time Bounds for Two-Time-Scale Stochastic Approximation with Arbitrary Norm Contractions and Markovian Noise</title>
      <link>https://arxiv.org/abs/2503.18391</link>
      <description>arXiv:2503.18391v2 Announce Type: replace-cross 
Abstract: Two-time-scale Stochastic Approximation (SA) is an iterative algorithm with applications in reinforcement learning and optimization. Prior finite time analysis of such algorithms has focused on fixed point iterations with mappings contractive under Euclidean norm. Motivated by applications in reinforcement learning, we give the first mean square bound on non linear two-time-scale SA where the iterations have arbitrary norm contractive mappings and Markovian noise. We show that the mean square error decays at a rate of $O(1/n^{2/3})$ in the general case, and at a rate of $O(1/n)$ in a special case where the slower timescale is noiseless. Our analysis uses the generalized Moreau envelope to handle the arbitrary norm contractions and solutions of Poisson equation to deal with the Markovian noise. By analyzing the SSP Q-Learning algorithm, we give the first $O(1/n)$ bound for an algorithm for asynchronous control of MDPs under the average reward criterion. We also obtain a rate of $O(1/n)$ for Q-Learning with Polyak-averaging and provide an algorithm for learning Generalized Nash Equilibrium (GNE) for strongly monotone games which converges at a rate of $O(1/n^{2/3})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18391v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddharth Chandak, Shaan Ul Haque, Nicholas Bambos</dc:creator>
    </item>
    <item>
      <title>A Unified MDL-based Binning and Tensor Factorization Framework for PDF Estimation</title>
      <link>https://arxiv.org/abs/2504.18686</link>
      <description>arXiv:2504.18686v2 Announce Type: replace-cross 
Abstract: Reliable density estimation is fundamental for numerous applications in statistics and machine learning. In many practical scenarios, data are best modeled as mixtures of component densities that capture complex and multimodal patterns. However, conventional density estimators based on uniform histograms often fail to capture local variations, especially when the underlying distribution is highly nonuniform. Furthermore, the inherent discontinuity of histograms poses challenges for tasks requiring smooth derivatives, such as gradient-based optimization, clustering, and nonparametric discriminant analysis. In this work, we present a novel non-parametric approach for multivariate probability density function (PDF) estimation that utilizes minimum description length (MDL)-based binning with quantile cuts. Our approach builds upon tensor factorization techniques, leveraging the canonical polyadic decomposition (CPD) of a joint probability tensor. We demonstrate the effectiveness of our method on synthetic data and a challenging real dry bean classification dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18686v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mustafa Musab, Joseph K. Chege, Arie Yeredor, Martin Haardt</dc:creator>
    </item>
    <item>
      <title>Localized Diffusion Models</title>
      <link>https://arxiv.org/abs/2505.04417</link>
      <description>arXiv:2505.04417v2 Announce Type: replace-cross 
Abstract: Diffusion models are state-of-the-art tools for various generative tasks. Yet training these models involves estimating high-dimensional score functions, which in principle suffers from the curse of dimensionality. It is therefore important to understand how low-dimensional structure in the target distribution can be exploited in these models. Here we consider locality structure, which describes certain sparse conditional dependencies among the target random variables. Given some locality structure, the score function is effectively low-dimensional, so that it can be estimated by a localized neural network with significantly reduced sample complexity. This observation motivates the localized diffusion model, where a localized score matching loss is used to train the score function within a localized hypothesis space. We prove that such localization enables diffusion models to circumvent the curse of dimensionality, at the price of additional localization error. Under realistic sample size scaling, we then show both theoretically and numerically that a moderate localization radius can balance the statistical and localization errors, yielding better overall performance. Localized structure also facilitates parallel training, making localized diffusion models potentially more efficient for large-scale applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04417v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georg A. Gottwald, Shuigen Liu, Youssef Marzouk, Sebastian Reich, Xin T. Tong</dc:creator>
    </item>
    <item>
      <title>Generating Full-field Evolution of Physical Dynamics from Irregular Sparse Observations</title>
      <link>https://arxiv.org/abs/2505.09284</link>
      <description>arXiv:2505.09284v3 Announce Type: replace-cross 
Abstract: Modeling and reconstructing multidimensional physical dynamics from sparse and off-grid observations presents a fundamental challenge in scientific research. Recently, diffusion-based generative modeling shows promising potential for physical simulation. However, current approaches typically operate on on-grid data with preset spatiotemporal resolution, but struggle with the sparsely observed and continuous nature of real-world physical dynamics. To fill the gaps, we present SDIFT, Sequential DIffusion in Functional Tucker space, a novel framework that generates full-field evolution of physical dynamics from irregular sparse observations. SDIFT leverages the functional Tucker model as the latent space representer with proven universal approximation property, and represents observations as latent functions and Tucker core sequences. We then construct a sequential diffusion model with temporally augmented UNet in the functional Tucker space, denoising noise drawn from a Gaussian process to generate the sequence of core tensors.
  At the posterior sampling stage, we propose a Message-Passing Posterior Sampling mechanism, enabling conditional generation of the entire sequence guided by observations at limited time steps. We validate SDIFT on three physical systems spanning astronomical (supernova explosions, light-year scale), environmental (ocean sound speed fields, kilometer scale), and molecular (organic liquid, millimeter scale) domains, demonstrating significant improvements in both reconstruction accuracy and computational efficiency compared to state-of-the-art approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09284v3</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Panqi Chen, Yifan Sun, Lei Cheng, Yang Yang, Weichang Li, Yang Liu, Weiqing Liu, Jiang Bian, Shikai Fang</dc:creator>
    </item>
    <item>
      <title>ICYM2I: The illusion of multimodal informativeness under missingness</title>
      <link>https://arxiv.org/abs/2505.16953</link>
      <description>arXiv:2505.16953v2 Announce Type: replace-cross 
Abstract: Multimodal learning is of continued interest in artificial intelligence-based applications, motivated by the potential information gain from combining different types of data. However, modalities observed in the source environment may differ from the modalities observed in the target environment due to multiple factors, including cost, hardware failure, or the perceived informativeness of a given modality. This shift in missingness between the source and target environment has not been carefully studied. Naive estimation of the information gain associated with including an additional modality without accounting for missingness may result in improper estimates of that modality's value in the target environment. We formalize the problem of missingness, demonstrate its ubiquity, and show that the subsequent distribution shift results in bias when the missingness process is not explicitly accounted for. To address this issue, we introduce ICYM2I (In Case You Multimodal Missed It), a framework for the evaluation of predictive performance and information gain under missingness through inverse probability weighting-based correction. We demonstrate the importance of the proposed adjustment to estimate information gain under missingness on synthetic, semi-synthetic, and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16953v2</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Young Sang Choi, Vincent Jeanselme, Pierre Elias, Shalmali Joshi</dc:creator>
    </item>
    <item>
      <title>Improved Sample Complexity For Diffusion Model Training Without Empirical Risk Minimizer Access</title>
      <link>https://arxiv.org/abs/2505.18344</link>
      <description>arXiv:2505.18344v4 Announce Type: replace-cross 
Abstract: Diffusion models have demonstrated remarkable performance in generating high-dimensional samples across domains such as vision, language, and the sciences. Although continuous-state diffusion models have been extensively studied both empirically and theoretically, discrete-state diffusion models, essential for applications involving text, sequences, and combinatorial structures, they remain significantly less understood from a theoretical standpoint. In particular, all existing analyses of discrete-state models assume access to an empirical risk minimizer. In this work, we present a principled theoretical framework analyzing diffusion models, providing a state-of-the-art sample complexity bound of $\widetilde{\mathcal{O}}(\epsilon^{-4})$. Our structured decomposition of the score estimation error into statistical and optimization components offers critical insights into how diffusion models can be trained efficiently. This analysis addresses a fundamental gap in the literature and establishes the theoretical tractability and practical relevance of diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18344v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mudit Gaur, Prashant Trivedi, Sasidhar Kunapuli, Amrit Singh Bedi, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Variational Deep Learning via Implicit Regularization</title>
      <link>https://arxiv.org/abs/2505.20235</link>
      <description>arXiv:2505.20235v2 Announce Type: replace-cross 
Abstract: Modern deep learning models generalize remarkably well in-distribution, despite being overparametrized and trained with little to no explicit regularization. Instead, current theory credits implicit regularization imposed by the choice of architecture, hyperparameters and optimization procedure. However, deep neural networks can be surprisingly non-robust, resulting in overconfident predictions and poor out-of-distribution generalization. Bayesian deep learning addresses this via model averaging, but typically requires significant computational resources as well as carefully elicited priors to avoid overriding the benefits of implicit regularization. Instead, in this work, we propose to regularize variational neural networks solely by relying on the implicit bias of (stochastic) gradient descent. We theoretically characterize this inductive bias in overparametrized linear models as generalized variational inference and demonstrate the importance of the choice of parametrization. Empirically, our approach demonstrates strong in- and out-of-distribution performance without additional hyperparameter tuning and with minimal computational overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20235v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan Wenger, Beau Coker, Juraj Marusic, John P. Cunningham</dc:creator>
    </item>
    <item>
      <title>Reshaping Reasoning in LLMs: A Theoretical Analysis of RL Training Dynamics through Pattern Selection</title>
      <link>https://arxiv.org/abs/2506.04695</link>
      <description>arXiv:2506.04695v2 Announce Type: replace-cross 
Abstract: While reinforcement learning (RL) demonstrated remarkable success in enhancing the reasoning capabilities of language models, the training dynamics of RL in LLMs remain unclear. In this work, we provide an explanation of the RL training process through empirical analysis and rigorous theoretical modeling. First, through systematic reasoning-pattern-level and token-level analysis across the RL training process, we show that while different reasoning patterns exhibit relatively stable success rates during training, RL primarily optimizes a sparse subset of critical tokens, thereby reshaping reasoning pattern distributions to affect model performance. Building on these empirical insights, we develop a theoretical framework to understand the training dynamics of RL with two typical rewards: verifiable reward (RLVR) and model's internal feedback (RLIF). For RLVR, we analyze the training dynamics under two special cases: one where models readily converge to optimal reasoning strategies, and another where optimization becomes challenging, revealing that the base model's reasoning quality is crucial for determining convergence behavior. For RLIF, we examine how internal rewards initially improve model performance but can potentially lead to degradation with continued training. Extensive experiments validate our findings, advancing both theoretical understanding and practical applications of RL in language model enhancement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04695v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xingwu Chen, Tianle Li, Difan Zou</dc:creator>
    </item>
    <item>
      <title>Why Masking Diffusion Works: Condition on the Jump Schedule for Improved Discrete Diffusion</title>
      <link>https://arxiv.org/abs/2506.08316</link>
      <description>arXiv:2506.08316v2 Announce Type: replace-cross 
Abstract: Discrete diffusion models, like continuous diffusion models, generate high-quality samples by gradually undoing noise applied to datapoints with a Markov process. Gradual generation in theory comes with many conceptual benefits; for example, inductive biases can be incorporated into the noising Markov process, and access to improved sampling algorithms. In practice, however, the consistently best performing discrete diffusion model is, surprisingly, masking diffusion, which does not denoise gradually. Here we explain the superior performance of masking diffusion by noting that it makes use of a fundamental difference between continuous and discrete Markov processes: discrete Markov processes evolve by discontinuous jumps at a fixed rate and, unlike other discrete diffusion models, masking diffusion builds in the known distribution of jump times and only learns where to jump to. We show that we can similarly bake in the known distribution of jump times into any discrete diffusion model. The resulting models - schedule-conditioned discrete diffusion (SCUD) - generalize classical discrete diffusion and masking diffusion. By applying SCUD to models with noising processes that incorporate inductive biases on images, text, and protein data, we build models that outperform masking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08316v2</guid>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alan N. Amin, Nate Gruver, Andrew Gordon Wilson</dc:creator>
    </item>
    <item>
      <title>Muon Optimizes Under Spectral Norm Constraints</title>
      <link>https://arxiv.org/abs/2506.15054</link>
      <description>arXiv:2506.15054v2 Announce Type: replace-cross 
Abstract: The pursuit of faster optimization algorithms remains an active and important research direction in deep learning. Recently, the Muon optimizer [JJB+24] has demonstrated promising empirical performance, but its theoretical foundation remains less understood. In this paper, we bridge this gap and provide a theoretical analysis of Muon by placing it within the Lion-$\mathcal{K}$ family of optimizers [CLLL24]. Specifically, we show that Muon corresponds to Lion-$\mathcal{K}$ when equipped with the nuclear norm, and we leverage the theoretical results of Lion-$\mathcal{K}$ to establish that Muon (with decoupled weight decay) implicitly solves an optimization problem that enforces a constraint on the spectral norm of weight matrices. This perspective not only demystifies the implicit regularization effects of Muon but also leads to natural generalizations through varying the choice of convex map $\mathcal{K}$, allowing for the exploration of a broader class of implicitly regularized and constrained optimization algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15054v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lizhang Chen, Jonathan Li, Qiang Liu</dc:creator>
    </item>
    <item>
      <title>Data Uniformity Improves Training Efficiency and More, with a Convergence Framework Beyond the NTK Regime</title>
      <link>https://arxiv.org/abs/2506.24120</link>
      <description>arXiv:2506.24120v2 Announce Type: replace-cross 
Abstract: Data selection plays a crucial role in data-driven decision-making, including in large language models (LLMs), and is typically task-dependent. Properties such as data quality and diversity have been extensively studied and are known to enhance model performance. However, it remains unclear whether there exist other quantitative and general principles of data selection that can consistently improve performance, especially for complicated tasks. In this paper, we demonstrate that selecting more uniformly distributed data can improve training efficiency while enhancing performance. Specifically, we establish that more uniform (less biased) distribution leads to a larger minimum pairwise distance between data points, denoted by $h_{\min}$, and prove that a smaller $h_{\min}$ can slow down the training dynamics of gradient descent (GD). Moreover, we theoretically show that the approximation error of neural networks decreases as $h_{\min}$ increases. Our analysis introduces a convergence framework for GD beyond the Neural Tangent Kernel (NTK) regime, applicable to a broad class of architectures, including transformers, without requiring Lipschitz smoothness. This framework further provides theoretical justification for the use of residual connection and function composition in deep neural architectures. In the end, we conduct comprehensive experiments for supervised fine-tuning across various settings, including different optimization strategies, model sizes, and training datasets. The results consistently demonstrate that selecting data by maximizing pairwise distance significantly accelerates training and achieves comparable or better performance in LLMs across diverse datasets. Code and Datasets are available at the link: https://github.com/SafeRL-Lab/data-uniformity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.24120v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqing Wang, Shangding Gu</dc:creator>
    </item>
    <item>
      <title>Warm Starts Accelerate Conditional Diffusion</title>
      <link>https://arxiv.org/abs/2507.09212</link>
      <description>arXiv:2507.09212v2 Announce Type: replace-cross 
Abstract: Generative models like diffusion and flow-matching create high-fidelity samples by progressively refining noise. The refinement process is notoriously slow, often requiring hundreds of function evaluations. We introduce Warm-Start Diffusion (WSD), a method that uses a simple, deterministic model to dramatically accelerate conditional generation by providing a better starting point. Instead of starting generation from an uninformed $N(\boldsymbol{0}, I)$ prior, our deterministic warm-start model predicts an informed prior $N(\hat{\boldsymbol{\mu}}_C, \text{diag}(\hat{\boldsymbol{\sigma}}^2_C))$, whose moments are conditioned on the input context $C$. This warm start substantially reduces the distance the generative process must traverse, and therefore the number of diffusion steps required, particularly when the context $C$ is strongly informative. WSD is applicable to any standard diffusion or flow matching algorithm, is orthogonal to and synergistic with other fast sampling techniques like efficient solvers, and is simple to implement. We test WSD in a variety of settings, and find that it substantially outperforms standard diffusion in the efficient sampling regime, generating realistic samples using only 4-6 function evaluations, and saturating performance with 10-12.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09212v2</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Scholz, Richard E. Turner</dc:creator>
    </item>
    <item>
      <title>Differentiable Expectation-Maximisation and Applications to Gaussian Mixture Model Optimal Transport</title>
      <link>https://arxiv.org/abs/2509.02109</link>
      <description>arXiv:2509.02109v2 Announce Type: replace-cross 
Abstract: The Expectation-Maximisation (EM) algorithm is a central tool in statistics and machine learning, widely used for latent-variable models such as Gaussian Mixture Models (GMMs). Despite its ubiquity, EM is typically treated as a non-differentiable black box, preventing its integration into modern learning pipelines where end-to-end gradient propagation is essential. In this work, we present and compare several differentiation strategies for EM, from full automatic differentiation to approximate methods, assessing their accuracy and computational efficiency. As a key application, we leverage this differentiable EM in the computation of the Mixture Wasserstein distance $\mathrm{MW}_2$ between GMMs, allowing $\mathrm{MW}_2$ to be used as a differentiable loss in imaging and machine learning tasks. To complement our practical use of $\mathrm{MW}_2$, we contribute a novel stability result which provides theoretical justification for the use of $\mathrm{MW}_2$ with EM, and also introduce a novel unbalanced variant of $\mathrm{MW}_2$. Numerical experiments on barycentre computation, colour and style transfer, image generation, and texture synthesis illustrate the versatility of the proposed approach in different settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02109v2</guid>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Bo\"it\'e, Eloi Tanguy, Julie Delon, Agn\`es Desolneux, R\'emi Flamary</dc:creator>
    </item>
  </channel>
</rss>
