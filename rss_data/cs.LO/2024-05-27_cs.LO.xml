<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 May 2024 04:02:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 27 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Logic for conditional strong historical necessity in branching time and analyses of an argument for future determinism</title>
      <link>https://arxiv.org/abs/2405.15248</link>
      <description>arXiv:2405.15248v1 Announce Type: new 
Abstract: In this paper, we present a logic for conditional strong historical necessity in branching time and apply it to analyze a nontheological version of Lavenham's argument for future determinism. Strong historical necessity is motivated from a linguistical perspective, and an example of it is ``If I had not gotten away, I must have been dead''. The approach of the logic is as follows. The agent accepts ontic rules concerning how the world evolves over time. She takes some rules as indefeasible, which determine acceptable timelines. When evaluating a sentence with conditional strong historical necessity, we introduce its antecedent as an indefeasible ontic rule and then check whether its consequent holds for all acceptable timelines. The argument is not sound by the logic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15248v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fengkui Ju</dc:creator>
    </item>
    <item>
      <title>A Logic of Knowledge and Justifications, with an Application to Computational Trust</title>
      <link>https://arxiv.org/abs/2405.15647</link>
      <description>arXiv:2405.15647v1 Announce Type: new 
Abstract: We present a logical framework that enables us to define a formal theory of computational trust in which this notion is analysed in terms of epistemic attitudes towards the possible objects of trust and in relation to existing evidence in favour of the trustworthiness of these objects. The framework is based on a quantified epistemic and justification logic featuring a non-standard handling of identities. Thus, the theory is able to account for the hyperintensional nature of computational trust. We present a proof system and a frame semantics for the logic, we prove soundness and completeness results and we introduce the syntactical machinery required to define a theory of trust.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15647v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco A. Genco</dc:creator>
    </item>
    <item>
      <title>The Undecidability of Quantified Announcements</title>
      <link>https://arxiv.org/abs/2405.15671</link>
      <description>arXiv:2405.15671v1 Announce Type: new 
Abstract: This paper demonstrates the undecidability of a number of logics with quantification over public announcements: arbitrary public announcement logic (APAL), group announcement logic (GAL), and coalition announcement logic (CAL). In APAL we consider the informative consequences of any announcement, in GAL we consider the informative consequences of a group of agents (this group may be a proper subset of the set of all agents) all of which are simultaneously (and publicly) making known announcements. So this is more restrictive than APAL. Finally, CAL is as GAL except that we now quantify over anything the agents not in that group may announce simultaneously as well. The logic CAL therefore has some features of game logic and of ATL. We show that when there are multiple agents in the language, the satisfiability problem is undecidable for APAL, GAL, and CAL. In the single agent case, the satisfiability problem is decidable for all three logics. This paper corrects an error to the submitted version of Undecidability of Quantified Announcements, identified by Yuta Assami . The nature of the error was in the definition of the formula cga (X) (see Subsection 5.2) which is corrected in this version.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15671v1</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>The undecidability of quantified announcements. Studia Logica, 104(4) pages 597-640, 2016</arxiv:journal_reference>
      <dc:creator>Thomas {\AA}gotnes, Hans van Ditmarsch, Tim French</dc:creator>
    </item>
    <item>
      <title>Bisimulation Learning</title>
      <link>https://arxiv.org/abs/2405.15723</link>
      <description>arXiv:2405.15723v1 Announce Type: new 
Abstract: We introduce a data-driven approach to computing finite bisimulations for state transition systems with very large, possibly infinite state space. Our novel technique computes stutter-insensitive bisimulations of deterministic systems, which we characterize as the problem of learning a state classifier together with a ranking function for each class. Our procedure learns a candidate state classifier and candidate ranking functions from a finite dataset of sample states; then, it checks whether these generalise to the entire state space using satisfiability modulo theory solving. Upon the affirmative answer, the procedure concludes that the classifier constitutes a valid stutter-insensitive bisimulation of the system. Upon a negative answer, the solver produces a counterexample state for which the classifier violates the claim, adds it to the dataset, and repeats learning and checking in a counterexample-guided inductive synthesis loop until a valid bisimulation is found. We demonstrate on a range of benchmarks from reactive verification and software model checking that our method yields faster verification results than alternative state-of-the-art tools in practice. Our method produces succinct abstractions that enable an effective verification of linear temporal logic without next operator, and are interpretable for system diagnostics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15723v1</guid>
      <category>cs.LO</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Abate, Mirco Giacobbe, Yannik Schnitzer</dc:creator>
    </item>
    <item>
      <title>Counterexample-Guided Repair of Reinforcement Learning Systems Using Safety Critics</title>
      <link>https://arxiv.org/abs/2405.15430</link>
      <description>arXiv:2405.15430v1 Announce Type: cross 
Abstract: Naively trained Deep Reinforcement Learning agents may fail to satisfy vital safety constraints. To avoid costly retraining, we may desire to repair a previously trained reinforcement learning agent to obviate unsafe behaviour. We devise a counterexample-guided repair algorithm for repairing reinforcement learning systems leveraging safety critics. The algorithm jointly repairs a reinforcement learning agent and a safety critic using gradient-based constrained optimisation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15430v1</guid>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>David Boetius, Stefan Leue</dc:creator>
    </item>
    <item>
      <title>Decidability of Graph Neural Networks via Logical Characterizations</title>
      <link>https://arxiv.org/abs/2404.18151</link>
      <description>arXiv:2404.18151v3 Announce Type: replace 
Abstract: We present results concerning the expressiveness and decidability of a popular graph learning formalism, graph neural networks (GNNs), exploiting connections with logic. We use a family of recently-discovered decidable logics involving "Presburger quantifiers". We show how to use these logics to measure the expressiveness of classes of GNNs, in some cases getting exact correspondences between the expressiveness of logics and GNNs. We also employ the logics, and the techniques used to analyze them, to obtain decision procedures for verification problems over GNNs. We complement this with undecidability results for static analysis problems involving the logics, as well as for GNN verification problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18151v3</guid>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Benedikt, Chia-Hsuan Lu, Boris Motik, Tony Tan</dc:creator>
    </item>
    <item>
      <title>Network Abstractions for Characterizing Communication Requirements in Asynchronous Distributed Systems</title>
      <link>https://arxiv.org/abs/2310.12615</link>
      <description>arXiv:2310.12615v4 Announce Type: replace-cross 
Abstract: Whereas distributed computing research has been very successful in exploring the solvability/impossibility border of distributed computing problems like consensus in representative classes of computing models with respect to model parameters like failure bounds, this is not the case for characterizing necessary and sufficient communication requirements. In this paper, we introduce network abstractions as a novel approach for modeling communication requirements in asynchronous distributed systems. A network abstraction of a run is a sequence of directed graphs on the set of processes, where the $i$-th graph specifies some ``potential'' message chains that can be guaranteed to arise in the $i$-th portion of the run. Formally, they are defined via associating message sending times with the end-to-end delays that would arise if the message was indeed sent by the sender's protocol. Network abstractions also allow to reason about future causal cones that might arise in a run, hence also facilitate reasoning about liveness properties, and are inherently compatible with temporal epistemic reasoning frameworks. We demonstrate the utility of our approach by providing necessary and sufficient network abstractions for solving the canonical firing rebels with relay (FRR) problem, and variants thereof, in asynchronous message-passing systems with up to $f$ byzantine processes connected via point-to-point links. FRR is not only a basic primitive in clock synchronization and consensus algorithms, but also integrates several distributed computing problems, namely triggering events, agreement and even stabilizing agreement, in a single problem instance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12615v4</guid>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hugo Rincon Galeana, Ulrich Schmid</dc:creator>
    </item>
    <item>
      <title>Positional $\omega$-regular languages</title>
      <link>https://arxiv.org/abs/2401.15384</link>
      <description>arXiv:2401.15384v2 Announce Type: replace-cross 
Abstract: In the context of two-player games over graphs, a language $L$ is called positional if, in all games using $L$ as winning objective, the protagonist can play optimally using positional strategies, that is, strategies that do not depend on the history of the play. In this work, we describe the class of parity automata recognising positional languages, providing a complete characterisation of positionality for $\omega$-regular languages. As corollaries, we establish decidability of positionality in polynomial time, finite-to-infinite and 1-to-2-players lifts, and show the closure under union of prefix-independent positional objectives, answering a conjecture by Kopczy\'nski in the $\omega$-regular case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15384v2</guid>
      <category>cs.FL</category>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Casares, Pierre Ohlmann</dc:creator>
    </item>
    <item>
      <title>VerMCTS: Synthesizing Multi-Step Programs using a Verifier, a Large Language Model, and Tree Search</title>
      <link>https://arxiv.org/abs/2402.08147</link>
      <description>arXiv:2402.08147v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) can generate useful code, but often the code they generate cannot be trusted to be sound. In this paper, we present VerMCTS, an approach to begin to resolve this issue by generating verified programs in Dafny and Coq. VerMCTS uses a logical verifier in concert with an LLM to guide a modified Monte Carlo Tree Search (MCTS). This approach leverages the verifier to gain intermediate feedback inside the search algorithm by checking partial programs at each step to estimate an upper bound on the value function. To measure the performance of VerMCTS, we develop a new suite of multi-step verified programming problems in Dafny and Coq. In terms of pass@T, a new metric which computes the pass rate given a budget of T tokens sampled from the LLM, VerMCTS leads to more than a 30% absolute increase in average pass@5000 across the suite over repeated sampling from the base language model. Our code and benchmarks are available at https://github.com/namin/llm-verified-with-monte-carlo-tree-search .</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08147v2</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Brandfonbrener, Simon Henniger, Sibi Raja, Tarun Prasad, Chloe Loughridge, Federico Cassano, Sabrina Ruixin Hu, Jianang Yang, William E. Byrd, Robert Zinkov, Nada Amin</dc:creator>
    </item>
  </channel>
</rss>
