<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.BM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.BM</link>
    <description>q-bio.BM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.BM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Dec 2024 02:51:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Deep Neural Network-Based Prediction of B-Cell Epitopes for SARS-CoV and SARS-CoV-2: Enhancing Vaccine Design through Machine Learning</title>
      <link>https://arxiv.org/abs/2412.00109</link>
      <description>arXiv:2412.00109v1 Announce Type: cross 
Abstract: The accurate prediction of B-cell epitopes is critical for guiding vaccine development against infectious diseases, including SARS and COVID-19. This study explores the use of a deep neural network (DNN) model to predict B-cell epitopes for SARS-CoVandSARS-CoV-2,leveraging a dataset that incorporates essential protein and peptide features. Traditional sequence-based methods often struggle with large, complex datasets, but deep learning offers promising improvements in predictive accuracy. Our model employs regularization techniques, such as dropout and early stopping, to enhance generalization, while also analyzing key features, including isoelectric point and aromaticity, that influence epitope recognition. Results indicate an overall accuracy of 82% in predicting COVID-19 negative and positive cases, with room for improvement in detecting positive samples. This research demonstrates the applicability of deep learning in epitope mapping, suggesting that such approaches can enhance the speed and precision of vaccine design for emerging pathogens. Future work could incorporate structural data and diverse viral strains to further refine prediction capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00109v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>q-bio.BM</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinyu Shi, Yixin Tao, Shih-Chi Lin</dc:creator>
    </item>
    <item>
      <title>Generative Model for Synthesizing Ionizable Lipids: A Monte Carlo Tree Search Approach</title>
      <link>https://arxiv.org/abs/2412.00807</link>
      <description>arXiv:2412.00807v1 Announce Type: cross 
Abstract: Ionizable lipids are essential in developing lipid nanoparticles (LNPs) for effective messenger RNA (mRNA) delivery. While traditional methods for designing new ionizable lipids are typically time-consuming, deep generative models have emerged as a powerful solution, significantly accelerating the molecular discovery process. However, a practical challenge arises as the molecular structures generated can often be difficult or infeasible to synthesize. This project explores Monte Carlo tree search (MCTS)-based generative models for synthesizable ionizable lipids. Leveraging a synthetically accessible lipid building block dataset and two specialized predictors to guide the search through chemical space, we introduce a policy network guided MCTS generative model capable of producing new ionizable lipids with available synthesis pathways.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00807v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.BM</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingyi Zhao, Yuxuan Ou, Austin Tripp, Morteza Rasoulianboroujeni, Jos\'e Miguel Hern\'andez-Lobato</dc:creator>
    </item>
    <item>
      <title>Multi-Scale Representation Learning for Protein Fitness Prediction</title>
      <link>https://arxiv.org/abs/2412.01108</link>
      <description>arXiv:2412.01108v1 Announce Type: cross 
Abstract: Designing novel functional proteins crucially depends on accurately modeling their fitness landscape. Given the limited availability of functional annotations from wet-lab experiments, previous methods have primarily relied on self-supervised models trained on vast, unlabeled protein sequence or structure datasets. While initial protein representation learning studies solely focused on either sequence or structural features, recent hybrid architectures have sought to merge these modalities to harness their respective strengths. However, these sequence-structure models have so far achieved only incremental improvements when compared to the leading sequence-only approaches, highlighting unresolved challenges effectively leveraging these modalities together. Moreover, the function of certain proteins is highly dependent on the granular aspects of their surface topology, which have been overlooked by prior models. To address these limitations, we introduce the Sequence-Structure-Surface Fitness (S3F) model - a novel multimodal representation learning framework that integrates protein features across several scales. Our approach combines sequence representations from a protein language model with Geometric Vector Perceptron networks encoding protein backbone and detailed surface topology. The proposed method achieves state-of-the-art fitness prediction on the ProteinGym benchmark encompassing 217 substitution deep mutational scanning assays, and provides insights into the determinants of protein function. Our code is at https://github.com/DeepGraphLearning/S3F.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01108v1</guid>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zuobai Zhang, Pascal Notin, Yining Huang, Aur\'elie Lozano, Vijil Chenthamarakshan, Debora Marks, Payel Das, Jian Tang</dc:creator>
    </item>
    <item>
      <title>Tokenizing 3D Molecule Structure with Quantized Spherical Coordinates</title>
      <link>https://arxiv.org/abs/2412.01564</link>
      <description>arXiv:2412.01564v1 Announce Type: cross 
Abstract: The application of language models (LMs) to molecular structure generation using line notations such as SMILES and SELFIES has been well-established in the field of cheminformatics. However, extending these models to generate 3D molecular structures presents significant challenges. Two primary obstacles emerge: (1) the difficulty in designing a 3D line notation that ensures SE(3)-invariant atomic coordinates, and (2) the non-trivial task of tokenizing continuous coordinates for use in LMs, which inherently require discrete inputs. To address these challenges, we propose Mol-StrucTok, a novel method for tokenizing 3D molecular structures. Our approach comprises two key innovations: (1) We design a line notation for 3D molecules by extracting local atomic coordinates in a spherical coordinate system. This notation builds upon existing 2D line notations and remains agnostic to their specific forms, ensuring compatibility with various molecular representation schemes. (2) We employ a Vector Quantized Variational Autoencoder (VQ-VAE) to tokenize these coordinates, treating them as generation descriptors. To further enhance the representation, we incorporate neighborhood bond lengths and bond angles as understanding descriptors. Leveraging this tokenization framework, we train a GPT-2 style model for 3D molecular generation tasks. Results demonstrate strong performance with significantly faster generation speeds and competitive chemical stability compared to previous methods. Further, by integrating our learned discrete representations into Graphormer model for property prediction on QM9 dataset, Mol-StrucTok reveals consistent improvements across various molecular properties, underscoring the versatility and robustness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01564v1</guid>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaiyuan Gao, Yusong Wang, Haoxiang Guan, Zun Wang, Qizhi Pei, John E. Hopcroft, Kun He, Lijun Wu</dc:creator>
    </item>
    <item>
      <title>ProtFAD: Introducing function-aware domains as implicit modality towards protein function prediction</title>
      <link>https://arxiv.org/abs/2405.15158</link>
      <description>arXiv:2405.15158v2 Announce Type: replace 
Abstract: Protein function prediction is currently achieved by encoding its sequence or structure, where the sequence-to-function transcendence and high-quality structural data scarcity lead to obvious performance bottlenecks. Protein domains are "building blocks" of proteins that are functionally independent, and their combinations determine the diverse biological functions. However, most existing studies have yet to thoroughly explore the intricate functional information contained in the protein domains. To fill this gap, we propose a synergistic integration approach for a function-aware domain representation, and a domain-joint contrastive learning strategy to distinguish different protein functions while aligning the modalities. Specifically, we align the domain semantics with GO terms and text description to pre-train domain embeddings. Furthermore, we partition proteins into multiple sub-views based on continuous joint domains for contrastive training under the supervision of a novel triplet InfoNCE loss. Our approach significantly and comprehensively outperforms the state-of-the-art methods on various benchmarks, and clearly differentiates proteins carrying distinct functions compared to the competitor. Our implementation is available at https://github.com/AI-HPC-Research-Team/ProtFAD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15158v2</guid>
      <category>q-bio.BM</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingqing Wang, Zhiwei Nie, Yonghong He, Athanasios V. Vasilakos, Zhixiang Ren</dc:creator>
    </item>
    <item>
      <title>Liquid Hopfield model: retrieval and localization in multicomponent liquid mixtures</title>
      <link>https://arxiv.org/abs/2310.18853</link>
      <description>arXiv:2310.18853v5 Announce Type: replace-cross 
Abstract: Biological mixtures, such as the cellular cytoplasm, are composed of a large number of different components. From this heterogeneity, ordered mesoscopic structures emerge, such as liquid phases with controlled composition. These structures compete with each other for the same components. This raises several questions, such as what types of interactions allow the retrieval of multiple ordered mesoscopic structures, and what are the physical limitations for the retrieval of said structures. In this work, we develop an analytically tractable model for liquids capable of retrieving states with target compositions. We name this model the liquid Hopfield model in reference to corresponding work in the theory of associative neural networks. By solving this model, we show that non-linear repulsive interactions are necessary for retrieval of target structures. We demonstrate that this is because liquid mixtures at low temperatures tend to transition to phases with few components, a phenomenon that we term localization. Taken together, our results demonstrate a trade-off between retrieval and localization phenomena in liquid mixtures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18853v5</guid>
      <category>physics.bio-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.soft</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1073/pnas.2320504121</arxiv:DOI>
      <arxiv:journal_reference>Proc. Natl. Acad. Sci. U.S.A. 121 (48) e2320504121, (2024)</arxiv:journal_reference>
      <dc:creator>Rodrigo Braz Teixeira, Giorgio Carugno, Izaak Neri, Pablo Sartori</dc:creator>
    </item>
  </channel>
</rss>
