<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Nov 2025 02:47:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>How to Expand a Self-orthogonal Code</title>
      <link>https://arxiv.org/abs/2511.17503</link>
      <description>arXiv:2511.17503v1 Announce Type: new 
Abstract: In this paper, we show how to expand Euclidean/Hermitian self-orthogonal code preserving their orthogonal property. Our results show that every $k$-dimension Hermitian self-orthogonal code is contained in a $(k+1)$-dimensional Hermitian self-orthogonal code. Also, for $k&lt; n/2-1$, every $[n,k]$ Euclidean self-orthogonal code is contained in an $[n,k+1]$ Euclidean self-orthogonal code. Moreover, for $k=n/2-1$ and $p=2$, we can also fulfill the expanding process. But for $k=n/2-1$ and $p$ odd prime, the expanding process can be fulfilled if and only if an extra condition must be satisfied. We also propose two feasible algorithms on these expanding procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17503v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jon-Lark Kim, Hongwei Liu, Jinquan Luo</dc:creator>
    </item>
    <item>
      <title>Covert Communication and Key Generation Over Quantum State-Dependent Channels</title>
      <link>https://arxiv.org/abs/2511.17504</link>
      <description>arXiv:2511.17504v1 Announce Type: new 
Abstract: We study covert communication and covert secret key generation with positive rates over quantum state-dependent channels. Specifically, we consider fully quantum state-dependent channels when the transmitter shares an entangled state with the channel. We study this problem setting under two security metrics. For the first security metric, the transmitter aims to communicate covertly with the receiver while simultaneously generating a covert secret key, and for the second security metric, the transmitter aims to transmit a secure message covertly and generate a covert secret key with the receiver simultaneously. Our main results include one-shot and asymptotic achievable positive covert-secret key rate pairs for both security metrics. Our results recover as a special case the best-known results for covert communication over state-dependent classical channels. To the best of our knowledge, our results are the first instance of achieving a positive rate for covert secret key generation and the first instance of achieving a positive covert rate over a quantum channel. Additionally, we show that our results are optimal when the channel is classical and the state is available non-causally at both the transmitter and the receiver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17504v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hassan ZivariFard, R\'emi A. Chou, Xiaodong Wang</dc:creator>
    </item>
    <item>
      <title>Unified Error Analysis for Synchronous and Asynchronous Two-User Random Access</title>
      <link>https://arxiv.org/abs/2511.17718</link>
      <description>arXiv:2511.17718v1 Announce Type: new 
Abstract: We consider a two-user random access system in which each user independently selects a coding scheme from a finite set for every message, without sharing these choices with the other user or with the receiver. The receiver aims to decode only user 1 message but may also decode user 2 message when beneficial. In the synchronous setting, the receiver employs two parallel sub-decoders: one dedicated to decoding user 1 message and another that jointly decodes both users messages. Their outputs are synthesized to produce the final decoding or collision decision. For the asynchronous setting, we examine a time interval containing $L$ consecutive codewords from each user. The receiver deploys $2^{2L}$ parallel sub-decoders, each responsible for decoding a subset of the message-code index pairs. In both synchronous and asynchronous cases, every sub-decoder partitions the coding space into three disjoint regions: operation, margin, and collision, and outputs either decoded messages or a collision report according to the region in which the estimated code index vector lies. Error events are defined for each sub-decoder and for the overall receiver whenever the expected output is not produced. We derive achievable upper bounds on the generalized error performance, defined as a weighted sum of incorrect-decoding, collision, and miss-detection probabilities, for both synchronous and asynchronous scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17718v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nazanin Mirhosseini, Jie Luo</dc:creator>
    </item>
    <item>
      <title>Multi-Port Selection for FAMA: Massive Connectivity with Fewer RF Chains than Users</title>
      <link>https://arxiv.org/abs/2511.17897</link>
      <description>arXiv:2511.17897v1 Announce Type: new 
Abstract: Fluid antenna multiple access (FAMA) is an emerging technology in massive access designed to meet the demands of future wireless communication networks by naturally mitigating multiuser interference through the utilization of the fluid antenna system (FAS) at RF-chain-limited mobile device. The transition from single-active-port to multi-active-port on a shared RF chain for slow FAMA can greatly enhance its multiplexing capability but is not well understood. Motivated by this, this paper proposes and studies three port selection methods: the optimal exhaustive-search port selection (EPS) as a performance upper bound, and two suboptimal, low-complexity algorithms, namely incremental port selection (IPS) and decremental port selection (DPS). Then the performance of multi-active-port slow FAMA is analyzed, and the complexity of the proposed methods is compared. Simulation results indicate that the proposed methods outperform current state-of-the-art multi-port FAMA techniques. In particular, IPS achieves near-optimal performance while maintaining manageable computational complexity. This research provides a more general framework for port selection in FAMA systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17897v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanjiang Hong, Kai-Kit Wong, Xusheng Zhu, Hao Xu, Han Xiao, Farshad Rostami Ghadi, Hyundong Shin</dc:creator>
    </item>
    <item>
      <title>Asymptotic Performance Analysis of Fluid Antenna Systems: An Extreme Value Theory Perspective</title>
      <link>https://arxiv.org/abs/2511.17916</link>
      <description>arXiv:2511.17916v1 Announce Type: new 
Abstract: Fluid antenna systems (FAS) allow dynamic reconfiguration to achieve superior diversity gains and reliability. To quantify the performance scaling of FAS with a large number of antenna ports, this paper leverages extreme value theory (EVT) to conduct an asymptotic analysis of the outage probability (OP) and ergodic capacity (EC). The analysis reveals that the OP decays approximately exponentially with the number of antenna ports. Moreover, we establish upper and lower bounds for the asymptotic EC, uncovering its double-logarithmic scaling law. Furthermore, we re-substantiate these scaling laws by exploiting the fact that the mode of the Gumbel distribution scales logarithmically. Besides, we theoretically prove that spatial correlation among antenna ports degrades both OP and EC. All analytical findings are conclusively validated by numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17916v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Zhang, Jintao Wang, Zheng Shi, Xu Wang, Guanghua Yang, Shaodan Ma, Kai-Kit Wong</dc:creator>
    </item>
    <item>
      <title>A Reinforcement Learning Framework for Resource Allocation in Uplink Carrier Aggregation in the Presence of Self Interference</title>
      <link>https://arxiv.org/abs/2511.17931</link>
      <description>arXiv:2511.17931v1 Announce Type: new 
Abstract: Carrier aggregation (CA) is a technique that allows mobile networks to combine multiple carriers to increase user data rate. On the uplink, for power constrained users, this translates to the need for an efficient resource allocation scheme, where each user distributes its available power among its assigned uplink carriers. Choosing a good set of carriers and allocating appropriate power on the carriers is important. If the carrier allocation on the uplink is such that a harmonic of a user's uplink carrier falls on the downlink frequency of that user, it leads to a self coupling-induced sensitivity degradation of that user's downlink receiver. In this paper, we model the uplink carrier aggregation problem as an optimal resource allocation problem with the associated constraints of non-linearities induced self interference (SI). This involves optimization over a discrete variable (which carriers need to be turned on) and a continuous variable (what power needs to be allocated on the selected carriers) in dynamic environments, a problem which is hard to solve using traditional methods owing to the mixed nature of the optimization variables and the additional need to consider the SI constraint. We adopt a reinforcement learning (RL) framework involving a compound-action actor-critic (CA2C) algorithm for the uplink carrier aggregation problem. We propose a novel reward function that is critical for enabling the proposed CA2C algorithm to efficiently handle SI. The CA2C algorithm along with the proposed reward function learns to assign and activate suitable carriers in an online fashion. Numerical results demonstrate that the proposed RL based scheme is able to achieve higher sum throughputs compared to naive schemes. The results also demonstrate that the proposed reward function allows the CA2C algorithm to adapt the optimization both in the presence and absence of SI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17931v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaswanth Bodempudi, Batta Siva Sairam, Madepalli Haritha, Sandesh Rao Mattu, Ananthanarayanan Chockalingam</dc:creator>
    </item>
    <item>
      <title>Block Length Gain for Nanopore Channels</title>
      <link>https://arxiv.org/abs/2511.18027</link>
      <description>arXiv:2511.18027v1 Announce Type: new 
Abstract: DNA is an attractive candidate for data storage. Its millennial durability and nanometer scale offer exceptional data density and longevity. Its relevance to medical applications also drives advances in DNA-related biotechnology.
  To protect our data against errors, a straightforward approach uses one error-correcting code per DNA strand, with a Reed--Solomon code protecting the collection of strands. A downside is that current technology can only synthesize strands 200--300 nucleotides long. At this block length, the inner code rate suffers a significant finite-length penalty, making its effective capacity hard to characterize.
  Last year, we proposed $\textit{Geno-Weaving}$ in a JSAIT publication. The idea is to protect the same position across multiple strands using one code; this provably achieves capacity against substitution errors. In this paper, we extend the idea to combat deletion errors and show two more advantages of Geno-Weaving: (1) Because the number of strands is 3--4 orders of magnitude larger than the strand length, the finite-length penalty vanishes. (2) At realistic deletion rates $0.1\%$--$10\%$, Geno-Weaving designed for BSCs works well empirically, bypassing the need to tailor the design for deletion channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18027v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu-Ting Lin, Hsin-Po Wang, Venkatesan Guruswami</dc:creator>
    </item>
    <item>
      <title>Average Secrecy Capacity Maximization of Rotatable Antenna-Assisted Secure Communications</title>
      <link>https://arxiv.org/abs/2511.18097</link>
      <description>arXiv:2511.18097v1 Announce Type: new 
Abstract: A rotatable antenna, which is able to dynamically adjust its deflection angle, is promising to achieve better physical layer security performance for wireless communications. In this paper, considering practical scenarios with non-real-time rotatable antenna adjustment, we investigate the average secrecy rate maximization problem of a rotatable antenna-assisted secure communication system. We theoretically prove that the objective function of the average secrecy rate maximization problem is quasi-concave with respect to an adjustment factor of the rotatable antenna. Under this condition, the optimal solution can be found by the bisection search. Furthermore, we derive the closed-form optimal deflection angle for the secrecy capacity maximization problem, considering the existence of only line-of-sight components of wireless channels. This solution serves as a near optimal solution to the average secrecy rate maximization problem. Based on the closed-form near optimal solution, we obtain the system secrecy outage probability at high signal-to-noise ratio (SNR). It is shown through simulation results that the near optimal solution achieves almost the same average secrecy capacity as the optimal solution. It is also found that at high SNR, the theoretical secrecy outage probabilities match the simulation ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18097v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pengchuan Jiang, Quanzhong Li, Lifeng Mai, Qi Zhang</dc:creator>
    </item>
    <item>
      <title>On the Hamming Weight Functions of Linear Codes</title>
      <link>https://arxiv.org/abs/2511.18250</link>
      <description>arXiv:2511.18250v1 Announce Type: new 
Abstract: Currently known secondary construction techniques for linear codes mainly include puncturing, shortening, and extending. In this paper, we propose a novel method for the secondary construction of linear codes based on their weight functions. Specifically, we develop a general framework that constructs new linear codes from the set of codewords in a given code having a fixed Hamming weight. We analyze the dimension, number of weights, and weight distribution of the constructed codes, and establish connections with the extendability of the original codes as well as the partial weight distribution of the derived codes. As a new tool, this framework enables us to establish an upper bound on the minimum weight of two-weight codes and to characterize all two-weight codes attaining this bound. Moreover, several divisibility properties concerning the parameters of two-weight codes are derived. The proposed method not only generates new families of linear codes but also provides a powerful approach for exploring the intrinsic combinatorial and geometric structures of existing codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18250v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongmei Huang, Qunying Liao, Sihem Mesnager, Gaohua Tang, Haode Yan</dc:creator>
    </item>
    <item>
      <title>Function-Correcting Codes With Data Protection</title>
      <link>https://arxiv.org/abs/2511.18420</link>
      <description>arXiv:2511.18420v1 Announce Type: new 
Abstract: Function-correcting codes (FCCs) are designed to provide error protection for the value of a function computed on the data. Existing work typically focuses solely on protecting the function value and not the underlying data. In this work, we propose a general framework that offers protection for both the data and the function values. Since protecting the data inherently contributes to protecting the function value, we focus on scenarios where the function value requires stronger protection than the data itself. We first introduce a more general approach and a framework for function-correcting codes that incorporates data protection along with protection of function values. A two-step construction procedure for such codes is proposed, and bounds on the optimal redundancy of general FCCs with data protection are reported. Using these results, we exhibit examples that show that data protection can be added to existing FCCs without increasing redundancy. Using our two-step construction procedure, we present explicit constructions of FCCs with data protection for specific families of functions, such as locally bounded functions and the Hamming weight function. We associate a graph called minimum-distance graph to a code and use it to show that perfect codes and maximum distance separable (MDS) codes cannot provide additional protection to function values over and above the amount of protection for data for any function. Then we focus on linear FCCs and provide some results for linear functions, leveraging their inherent structural properties. To the best of our knowledge, this is the first instance of FCCs with a linear structure. Finally, we generalize the Plotkin and Hamming bounds well known in classical error-correcting coding theory to FCCs with data protection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18420v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charul Rajput, B. Sundar Rajan, Ragnar Freij-Hollanti, Camilla Hollanti</dc:creator>
    </item>
    <item>
      <title>Aerial Semantic Relay-Enabled SAGIN: Joint UAV Deployment and Resource Allocation</title>
      <link>https://arxiv.org/abs/2511.18456</link>
      <description>arXiv:2511.18456v1 Announce Type: new 
Abstract: Space-Air-Ground Integrated Networks (SAGINs) are pivotal for enabling ubiquitous connectivity in 6G systems, yet they face significant challenges due to severe satellite-to-ground link impairments. Although Unmanned Aerial Vehicles (UAVs) can function as relay nodes to compensate for air-to-ground channel degradation, the satellite-to-UAV link remains a critical bottleneck. Semantic Communication (SemCom) emerges as a promising solution to enhance spectral efficiency by transmitting essential semantic information. This paper proposes a novel multi-cluster UAV-aided SAGIN SemCom architecture that supports both semantic users (SemUsers) and conventional users (ConUsers). While SemCom is employed in the satellite-to-UAV link to improve transmission efficiency, the UAVs implement an intelligent adaptive relay strategy, capable of either directly forwarding semantic data to SemUsers or converting it into bit-level data for ConUsers. Compared to existing similar schemes, this design guarantees the high-efficiency advantages of SemCom while enabling network access for larger coverage area. A joint optimization problem is formulated to maximize the system's sum-rate through coordinated allocation of power, bandwidth, and UAV positions. To address this non-convex problem, we develop an efficient alternating optimization (AO) algorithm, which decomposes the original problem into tractable subproblems. Numerical results demonstrate that the proposed algorithm significantly outperforms baseline schemes in terms of both sum-rate and spectral efficiency across various channel conditions and user distributions, underscoring the importance of joint resource allocation and intelligent UAV deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18456v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanbo Yin, Dingzhu Wen, Changsheng You, XiaoWen Cao, Tat-Ming Lok, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>Performance Evaluation of Dual RIS-Assisted Received Space Shift Keying Modulation</title>
      <link>https://arxiv.org/abs/2511.18610</link>
      <description>arXiv:2511.18610v1 Announce Type: new 
Abstract: Reconfigurable intelligent surfaces (RISs) are gaining traction for their ability to reshape wireless environments with low energy consumption. However, prior studies primarily explore single-RIS deployments with static or semi-static reflection control. In this paper, we propose a novel dual-RIS-assisted architecture for smart indoor wireless signal routing, wherein the second RIS (RIS$_2$) is dynamically configured based on source data bits to steer signals toward specific receivers or indoor zones. The first RIS (RIS$_1$), positioned near a fed antenna or access point, passively reflects the incident signal. RIS$_2$, equipped with a lightweight controller, performs bit-driven spatial modulation to enable data-dependent direction selection at the physical layer. We develop a complete end-to-end system model, including multi-hop channel representation, RIS phase configuration mapping, and signal detection based on space shift keying (SSK). Performance analysis is evaluated in terms of achievable capacity and outage probability under varying inter-RIS distances and carrier frequencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18610v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ferhat Bayar, Haci Ilhan, Erdogan Aydin</dc:creator>
    </item>
    <item>
      <title>Understanding the Role of Phase and Position Design in Fluid Reconfigurable Intelligent Surfaces</title>
      <link>https://arxiv.org/abs/2511.18663</link>
      <description>arXiv:2511.18663v1 Announce Type: new 
Abstract: Fluid Reconfigurable Intelligent Surfaces (FRISs) are gaining momentum as an improved alternative over classical RIS. However, it remains unclear whether their performance gains can be entirely attributed to spatial flexibility, or instead to differences in equivalent aperture or phase design. In this work, we shed light onto this problem by benchmarking FRIS vs. RIS performances in two practical scenarios: conventional RIS (same number of active elements and same overall aperture) and compact RIS (same number of active elements, and smaller aperture with sub-{\lambda} inter-element spacing). Statistical analysis demonstrates that: (i) spatial position optimization in FRIS provides noticeable gains over conventional RIS in the absence of phase-shift design; (ii) such benefits vanish when FRIS and conventional RIS employ optimal beamforming (BF) and phase shift (PS) design, making position optimization irrelevant; (iii) FRIS consistently outperforms compact RIS with optimized BF and PS design, owing to spatial correlation and smaller aperture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18663v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>J. D. Vega-S\'anchez, V. H. Garz\'on Pacheco, N. V. Orozco Garz\'on, H. R. Carvajal Mora, F. J. L\'opez-Mart\'inez</dc:creator>
    </item>
    <item>
      <title>Study of Iterative Dynamic Channel Tracking for Multiple RIS-Assisted MIMO Systems</title>
      <link>https://arxiv.org/abs/2511.18669</link>
      <description>arXiv:2511.18669v1 Announce Type: new 
Abstract: The use of multiple Reconfigurable Intelligent Sur- faces (RIS) has gained attention in 6G networks to enhance coverage. However, the feasibility of deploying multiple RIS relies on efficient channel estimation and reduced pilot overhead. To address these challenges, this work proposes an iterative channel estimation scheme that exploits low-density parity-check (LDPC) codes, channel coherence time, and iterative processing to improve estimation accuracy while minimizing pilot length. Encoded pilots are used to strengthen the iterative processing, leveraging both pilot and parity bits, while previous estimates are incorporated to further reduce overhead. Simulations consider a sub-6 GHz scenario with non-sparse channels and multiple RIS under both LOS and NLOS conditions. The results show that the proposed method outperforms existing approaches, achieving significant gains with substantially lower pilot overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18669v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto C. G. Porto, Rodrigo C. de Lamare</dc:creator>
    </item>
    <item>
      <title>Exploring Spatial Flexibility and Phase Design in Fluid Reconfigurable Intelligent Surfaces: A Physical Layer Security Perspective</title>
      <link>https://arxiv.org/abs/2511.18675</link>
      <description>arXiv:2511.18675v1 Announce Type: new 
Abstract: This work examines the secrecy outage probability (SOP) in Fluid Reconfigurable Intelligent Surfaces (FRIS) and contrasts their performance against two alternative RIS architectures: a traditional planar RIS and a compact RIS layout. To characterize the end-to-end FRIS channel, a maximum likelihood estimation (MLE) approach is introduced, while a Q-learning algorithm is employed to adaptively select the spatial positions of FRIS elements. Numerical evaluations show that optimizing element placement in FRIS significantly improves SOP compared to conventional RIS without phase adaptation. However, these improvements become less evident once the conventional RIS implements optimized beamforming (BF) and phase-shift (PS) controlling. In addition, FRIS maintains a clear advantage over compact RIS designs with optimized BF and PS, mainly due to its lower spatial correlation. Results further indicate that reducing the inter-element distance negatively impacts SOP, highlighting the importance of spatial diversity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18675v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>J. D. Vega-S\'anchez, V. H. Garz\'on Pacheco, N. V. Orozco Garz\'on, D. A. Riofr\'io Almeida, D. P. Moya Osorio</dc:creator>
    </item>
    <item>
      <title>On Construction of Linear (Euclidean) Hull Codes over Finite Extensions Binary Fields</title>
      <link>https://arxiv.org/abs/2511.18779</link>
      <description>arXiv:2511.18779v1 Announce Type: new 
Abstract: The hull of a linear code is defined as the intersection of the code and its dual. This concept was initially introduced to classify finite projective planes. The hull plays a crucial role in determining the complexity of algorithms used to check the permutation equivalence of two linear codes and compute a linear code's automorphism group. Research has shown that these algorithms are very effective when the hull size is small. Linear complementary dual (LCD) codes have the smallest hulls, while codes with a one-dimensional hull have the second smallest.
  A recent notable paper that directs our investigation is authored by H. Chen, titled ``On the Hull-Variation Problem of Equivalent Linear Codes", published in IEEE Transactions on Information Theory, volume 69, issue 5, in 2023. In this paper, we first explore the one-dimensional hull of a linear code over finite fields. Additionally, we demonstrate that any LCD code over an extended binary field \( \FF_q \) (where \( q &gt; 3 \)) with a minimum distance of at least $2$ is equivalent to the one-dimensional hull of a linear code under a specific weak condition. Furthermore, we provide a construction for creating hulls with \( \ell + 1 \)-dimensionality from an \( \ell \)-dimensional hull of a linear code, again under a weak condition. This corresponds to a particularly challenging direction, as creating \( \ell \)-dimensional hulls from \( \ell + 1 \)-dimensional hulls. Finally, we derive several constructions for the \( \ell \)-dimensional hulls of linear codes as a consequence of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18779v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanjit Bhowmick, Deepak Kumar Dalai, Sihem Mesnager</dc:creator>
    </item>
    <item>
      <title>Detection of Number of Subcarriers of OFDM Systems using Eigen-Spectral Analysis</title>
      <link>https://arxiv.org/abs/2511.19020</link>
      <description>arXiv:2511.19020v1 Announce Type: new 
Abstract: Orthogonal Frequency-Division Multiplexing (OFDM) is widely used in modern wireless communication systems due to its robustness against time-dispersive channels. In this work, we consider a non-cooperative scenario where the receiver does not have prior knowledge of the OFDM parameters such as the number of subcarriers and the aim is to estimate them using the received data. Such a setup has applications in cognitive radio networks. For this blind OFDM parameter estimation problem, we provide a novel method based on eigen-spectral analysis of the covariance matrix corresponding to the received data. In particular, we show that the covariance matrix exhibits a distinctive rank property under correct segmentation of the received symbols, reflecting a characteristic behavior in its eigenvalue spectrum that facilitates accurate estimation of the number of subcarriers. The proposed method is more general than existing approaches in the literature, as it can detect an arbitrary number of subcarriers and its performance remains independent of the modulation scheme. The numerical results show that the proposed method accurately detects the number of subcarriers with high probability even at low SNR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19020v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vishnu Priya Chekuru, Ganapathiraju S S Ananya Varma, Arti Yardi, Praful Mankar</dc:creator>
    </item>
    <item>
      <title>On the Tail Transition of First Arrival Position Channels: From Cauchy to Exponential Decay</title>
      <link>https://arxiv.org/abs/2511.19074</link>
      <description>arXiv:2511.19074v1 Announce Type: new 
Abstract: While the zero-drift First Arrival Position (FAP) channel is rigorously known to be Cauchy-distributed, practical molecular communication systems typically operate with non-zero drift. This letter characterizes the transition from heavy-tailed Cauchy behavior to light-tailed exponential decay. Through asymptotic analysis, we identify a critical spatial scale $n_c=\sigma^2/v$ separating diffusion- and drift-dominated regimes, revealing that the channel effectively behaves as a ``Truncated Cauchy'' model. Numerical results show that Gaussian approximations severely underestimate capacity at low drift, while the zero-drift case provides the appropriate performance lower bound for systems where drift assists particle transport.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19074v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yen-Chi Lee</dc:creator>
    </item>
    <item>
      <title>Directional Pinching-Antenna Systems</title>
      <link>https://arxiv.org/abs/2511.19133</link>
      <description>arXiv:2511.19133v1 Announce Type: new 
Abstract: We propose a directional pinching-antenna system (DiPASS), a comprehensive framework that transitions PASS modeling from idealized abstraction to physical consistency. DiPASS introduces the first channel model that accurately captures the directional, pencil-like radiation of pinching antennas, incorporates a practical waveguide attenuation of 1.3 dB/m, and accounts for stochastic line-of-sight blockage. A key enabler of DiPASS is our new "equal quota division" power allocation strategy, which guarantees predetermined coupling lengths independent of antenna positions, thereby overcoming a critical barrier to practical deployment. Our analysis yields foundational insights: we derive closed-form solutions for optimal antenna placement and orientation in single-PA scenarios, quantifying the core trade-off between waveguide and free-space losses. For multi-PA systems, we develop a scalable optimization framework that leverages directional sparsity, revealing that waveguide diversity surpasses antenna density in enhancing system capacity. Extensive simulations validate our analysis and demonstrate that DiPASS provides a realistic performance benchmark, fundamentally reshaping the understanding and design principles for future PASS-enabled 6G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19133v1</guid>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runxin Zhang, Yulin Shao, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>Information Physics of Intelligence: Unifying Logical Depth and Entropy under Thermodynamic Constraints</title>
      <link>https://arxiv.org/abs/2511.19156</link>
      <description>arXiv:2511.19156v1 Announce Type: new 
Abstract: The rapid scaling of artificial intelligence models has revealed a fundamental tension between model capacity (storage) and inference efficiency (computation). While classical information theory focuses on transmission and storage limits, it lacks a unified physical framework to quantify the thermodynamic costs of generating information from compressed laws versus retrieving it from memory. In this paper, we propose a theoretical framework that treats information processing as an enabling mapping from ontological states to carrier states. We introduce a novel metric, Derivation Entropy, which quantifies the effective work required to compute a target state from a given logical depth. By analyzing the interplay between Shannon entropy (storage) and computational complexity (time/energy), we demonstrate the existence of a critical phase transition point. Below this threshold, memory retrieval is thermodynamically favorable; above it, generative computation becomes the optimal strategy. This "Energy-Time-Space" conservation law provides a physical explanation for the efficiency of generative models and offers a rigorous mathematical bound for designing next-generation, energy-efficient AI architectures. Our findings suggest that the minimization of Derivation Entropy is a governing principle for the evolution of both biological and artificial intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19156v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianfeng Xu, Zeyan Li</dc:creator>
    </item>
    <item>
      <title>Stitched Polar Codes</title>
      <link>https://arxiv.org/abs/2511.19249</link>
      <description>arXiv:2511.19249v1 Announce Type: new 
Abstract: In this paper, we introduce stitched polar codes, a novel generalization of Ar{\i}kan's regular polar codes. Our core methodology reconfigures the fundamental polarization process by stitching additional structures to enhance the reliability of less reliable information bits in the original code. This approach preserves the polar transformation structure and maintains the same encoding and decoding complexity. Thanks to the flexible configuration, stitched polar codes consistently outperform regular polar codes, effectively solving the performance degradation issue in rate-matched scenarios. Furthermore, we provide theoretical analysis on the weight spectrum and the polarization speed of stitched polar codes to prove their superiority.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19249v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Li, Zicheng Ye, Huazi Zhang, Jun Wang, Wen Tong, Guiying Yan, Zhiming Ma</dc:creator>
    </item>
    <item>
      <title>Leibniz's Monadology as Foundation for the Artificial Age Score: A Formal Architecture for Al Memory Evaluation</title>
      <link>https://arxiv.org/abs/2511.17541</link>
      <description>arXiv:2511.17541v1 Announce Type: cross 
Abstract: This paper develops a mathematically rigorous, philosophically grounded framework for evaluating artificial memory systems, rooted in the metaphysical structure of Leibniz's Monadology. Building on a previously formalized metric, the Artificial Age Score (AAS), the study maps twenty core propositions from the Monadology to an information-theoretic architecture. In this design, each monad functions as a modular unit defined by a truth score, a redundancy parameter, and a weighted contribution to a global memory penalty function. Smooth logarithmic transformations operationalize these quantities and yield interpretable, bounded metrics for memory aging, representational stability, and salience. Classical metaphysical notions of perception, apperception, and appetition are reformulated as entropy, gradient dynamics, and internal representation fidelity. Logical principles, including the laws of non-contradiction and sufficient reason, are encoded as regularization constraints guiding memory evolution. A central contribution is a set of first principles proofs establishing refinement invariance, structural decomposability, and monotonicity under scale transformation, aligned with the metaphysical structure of monads. The framework's formal organization is structured into six thematic bundles derived from Monadology, aligning each mathematical proof with its corresponding philosophical domain. Beyond evaluation, the framework offers a principled blueprint for building Al memory architectures that are modular, interpretable, and provably sound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17541v1</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LO</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seyma Yaman Kayadibi</dc:creator>
    </item>
    <item>
      <title>On the uniqueness of the coupled entropy</title>
      <link>https://arxiv.org/abs/2511.17684</link>
      <description>arXiv:2511.17684v1 Announce Type: cross 
Abstract: The coupled entropy is proven to uniquely satisfy the requirement that a generalized entropy be equivalent to the density at the scale for scale-shape distributions. Further, its maximizing distributions, the coupled stretched exponential distributions, are proven to quantify the linear uncertainty with the scale and the nonlinear uncertainty with the shape for a broad class of complex systems. Distributions of the coupled exponentials include the Pareto Types I-IV and Gosset's Student-t. For the Pareto Type II distribution, the Boltzmann-Gibbs-Shannon entropy has a linear dependence on the shape, which dominates over the logarithmic dependence on the scale, motivating the need for a generalization. The R\'enyi and Tsallis entropies are shown to be of historic importance but ultimately unsatisfactory generalizations. The coupled entropy of the coupled stretched exponential distribution isolates the nonlinear-shape dependence to a generalized logarithm of the partition function. The R\'enyi and Tsallis entropies retain a strong dependence on the nonlinear-shape such that they are not equivalent to the uncertainty at the scale. Lemmas for the composability and extensivity of the coupled entropy are proven in support of an axiomatic definition. The scope of the coupled entropy includes systems in which the growth of states is power-law, stretched exponential, or a combination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17684v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Kenric P. Nelson</dc:creator>
    </item>
    <item>
      <title>INT-DTT+: Low-Complexity Data-Dependent Transforms for Video Coding</title>
      <link>https://arxiv.org/abs/2511.17867</link>
      <description>arXiv:2511.17867v1 Announce Type: cross 
Abstract: Discrete trigonometric transforms (DTTs), such as the DCT-2 and the DST-7, are widely used in video codecs for their balance between coding performance and computational efficiency. In contrast, data-dependent transforms, such as the Karhunen-Lo\`eve transform (KLT) and graph-based separable transforms (GBSTs), offer better energy compaction but lack symmetries that can be exploited to reduce computational complexity. This paper bridges this gap by introducing a general framework to design low-complexity data-dependent transforms. Our approach builds on DTT+, a family of GBSTs derived from rank-one updates of the DTT graphs, which can adapt to signal statistics while retaining a structure amenable to fast computation. We first propose a graph learning algorithm for DTT+ that estimates the rank-one updates for rows and column graphs jointly, capturing the statistical properties of the overall block. Then, we exploit the progressive structure of DTT+ to decompose the kernel into a base DTT and a structured Cauchy matrix. By leveraging low-complexity integer DTTs and sparsifying the Cauchy matrix, we construct an integer approximation to DTT+, termed INT-DTT+. This approximation significantly reduces both computational and memory complexities with respect to the separable KLT with minimal performance loss. We validate our approach in the context of mode-dependent transforms for the VVC standard, following a rate-distortion optimized transform (RDOT) design approach. Integrated into the explicit multiple transform selection (MTS) framework of VVC in a rate-distortion optimization setup, INT-DTT+ achieves more than 3% BD-rate savings over the VVC MTS baseline, with complexity comparable to the integer DCT-2 once the base DTT coefficients are available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17867v1</guid>
      <category>eess.IV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Samuel Fern\'andez-Mendui\~na, Eduardo Pavez, Antonio Ortega, Tsung-Wei Huang, Thuong Nguyen Canh, Guan-Ming Su, Peng Yin</dc:creator>
    </item>
    <item>
      <title>Divergence-Minimization for Latent-Structure Models: Monotone Operators, Contraction Guarantees, and Robust Inference</title>
      <link>https://arxiv.org/abs/2511.17974</link>
      <description>arXiv:2511.17974v1 Announce Type: cross 
Abstract: We develop a divergence-minimization (DM) framework for robust and efficient inference in latent-mixture models. By optimizing a residual-adjusted divergence, the DM approach recovers EM as a special case and yields robust alternatives through different divergence choices. We establish that the sample objective decreases monotonically along the iterates, leading the DM sequence to stationary points under standard conditions, and that at the population level the operator exhibits local contractivity near the minimizer. Additionally, we verify consistency and $\sqrt{n}$-asymptotic normality of minimum-divergence estimators and of finitely many DM iterations, showing that under correct specification their limiting covariance matches the Fisher information. Robustness is analyzed via the residual-adjustment function, yielding bounded influence functions and a strictly positive breakdown bound for bounded-RAF divergences, and we contrast this with the non-robust behaviour of KL/EM. Next, we address the challenge of determining the number of mixture components by proposing a penalized divergence criterion combined with repeated sample splitting, which delivers consistent order selection and valid post-selection inference. Empirically, DM instantiations based on Hellinger and negative exponential divergences deliver accurate inference and remain stable under contamination in mixture and image-segmentation tasks. The results clarify connections to MM and proximal-point methods and offer practical defaults, making DM a drop-in alternative to EM for robust latent-structure inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17974v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Li, Anand N. Vidyashankar</dc:creator>
    </item>
    <item>
      <title>Accelerated optimization of measured relative entropies</title>
      <link>https://arxiv.org/abs/2511.17976</link>
      <description>arXiv:2511.17976v1 Announce Type: cross 
Abstract: The measured relative entropy and measured R\'enyi relative entropy are quantifiers of the distinguishability of two quantum states $\rho$ and $\sigma$. They are defined as the maximum classical relative entropy or R\'enyi relative entropy realizable by performing a measurement on $\rho$ and $\sigma$, and they have interpretations in terms of asymptotic quantum hypothesis testing. Crucially, they can be rewritten in terms of variational formulas involving the optimization of a concave or convex objective function over the set of positive definite operators. In this paper, we establish foundational properties of these objective functions by analyzing their matrix gradients and Hessian superoperators; namely, we prove that these objective functions are $\beta$-smooth and $\gamma$-strongly convex / concave, where $\beta$ and $\gamma$ depend on the max-relative entropies of $\rho$ and $\sigma$. A practical consequence of these properties is that we can conduct Nesterov accelerated projected gradient descent / ascent, a well known classical optimization technique, to calculate the measured relative entropy and measured R\'enyi relative entropy to arbitrary precision. These algorithms are generally more memory efficient than our previous algorithms based on semi-definite optimization [Huang and Wilde, arXiv:2406.19060], and for well conditioned states $\rho$ and $\sigma$, these algorithms are notably faster.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17976v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixin Huang, Mark M. Wilde</dc:creator>
    </item>
    <item>
      <title>Correlated-Sequence Differential Privacy</title>
      <link>https://arxiv.org/abs/2511.18025</link>
      <description>arXiv:2511.18025v1 Announce Type: cross 
Abstract: Data streams collected from multiple sources are rarely independent. Values evolve over time and influence one another across sequences. These correlations improve prediction in healthcare, finance, and smart-city control yet violate the record-independence assumption built into most Differential Privacy (DP) mechanisms. To restore rigorous privacy guarantees without sacrificing utility, we introduce Correlated-Sequence Differential Privacy (CSDP), a framework specifically designed for preserving privacy in correlated sequential data. CSDP addresses two linked challenges: quantifying the extra information an attacker gains from joint temporal and cross-sequence links, and adding just enough noise to hide that information while keeping the data useful. We model multivariate streams as a Coupling Markov Chain, yielding the derived loose leakage bound expressed with a few spectral terms and revealing a counterintuitive result: stronger coupling can actually decrease worst-case leakage by dispersing perturbations across sequences. Guided by these bounds, we build the Freshness-Regulated Adaptive Noise (FRAN) mechanism--combining data aging, correlation-aware sensitivity scaling, and Laplace noise--that runs in linear time. Tests on two-sequence datasets show that CSDP improves the privacy-utility trade-off by approximately 50% over existing correlated-DP methods and by two orders of magnitude compared to the standard DP approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18025v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ICCCN65249.2025.11133721</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 34th International Conference on Computer Communications and Networks (ICCCN 2025), IEEE, pp. 1-9, 2025</arxiv:journal_reference>
      <dc:creator>Yifan Luo, Meng Zhang, Jin Xu, Junting Chen, Jianwei Huang</dc:creator>
    </item>
    <item>
      <title>Delay-Optimal Transmission Scheduling Policies for Time-Correlated Fading Channels</title>
      <link>https://arxiv.org/abs/2511.18048</link>
      <description>arXiv:2511.18048v1 Announce Type: cross 
Abstract: Millimeter-wave (mmWave) networks have the potential to support high throughput and low-latency requirements of 5G-and-beyond communication standards. But transmissions in this band are highly vulnerable to attenuation and blockages from humans, buildings, and foliage, which increase end-to-end packet delays. This work designs dynamic scheduling policies that minimize end-to-end packet delays while keeping packet transmission costs low. Specifically, we consider a mmWave network that consists of a transmitter that transmits data packets over an unreliable communication channel modeled as a Gilbert-Elliott channel.The transmitter operates under an ACK/NACK feedback model and does not observe the channel state unless it attempts a transmission. The objective is to minimize a weighted average cost consisting of end-to-end packet delays and packet transmission costs. We pose this dynamic optimization problem as a partially observable Markov decision process (POMDP). To the best of our knowledge, this is the first POMDP formulation for mmWave network with partial channel state information that considers delay minimization. We show that the POMDP admits a solution that has a threshold structure, i.e., for each queue length, the belief (the conditional probability that the channel is in a good state) is partitioned into intervals, and the transmitter sends j packets when the belief lies in the j-th interval. We then consider the case when the system parameters such as the packet arrival rate, and the transition probabilities of the channel are not known, and leverage these structural results in order to use the actor-critic algorithm to efficiently search for a policy that is locally optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18048v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manali Dutta, Gourav Saha, Rahul Singh, Ness B. Shroff</dc:creator>
    </item>
    <item>
      <title>Lossy communication constrains iterated learning</title>
      <link>https://arxiv.org/abs/2511.18220</link>
      <description>arXiv:2511.18220v1 Announce Type: cross 
Abstract: Humans' distinctive role in the world can largely be attributed to our capacity for iterated learning, a process by which knowledge is expanded and refined over generations. A range of theories seek to explain why humans are so adept at iterated learning, many positing substantial evolutionary discontinuities in communication or cognition. Is it necessary to posit large differences in abilities between humans and other species, or could small differences in communication ability produce large differences in what a species can learn over generations? We investigate this question through a formal model based on information theory. We manipulate how much information individual learners can send each other and observe the effect on iterated learning performance. Incremental changes to the channel rate can lead to dramatic, non-linear changes to the eventual performance of the population. We complement this model with a theoretical result that describes how individual lossy communications constrain the global performance of iterated learning. Our results demonstrate that incremental, quantitative changes to communication abilities could be sufficient to explain large differences in what can be learned over many generations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18220v1</guid>
      <category>cs.SI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Prystawski, Dilip Arumugam, Noah D. Goodman</dc:creator>
    </item>
    <item>
      <title>The isotopy classes of Petit division algebras</title>
      <link>https://arxiv.org/abs/2511.18451</link>
      <description>arXiv:2511.18451v1 Announce Type: cross 
Abstract: Let $R=K[t;\sigma]$ be a skew polynomial ring, where $K$ is a cyclic Galois field extension of degree $n$ with Galois group generated by $\sigma$. We show that two irreducible similar skew polynomials $f,g\in R$ are similar if and only if they have the same bound. We prove that for two irreducible similar skew polynomials $f,g\in R$ the nonassociative Petit division algebras $R/Rf$ and $R/Rg$ are isotopic. We then refine this result and demonstrate that $f$ and $g$ also yield two isotopic nonassociative Petit algebras $R/Rf$ and $R/Rg$, when the two irreducible polynomials in $F[x]$ that define the minimal central left multiples of $f$ and $g$ have identical degree and lie in the same orbit of some group $G$. For finite field we explicitly compute the upper bound for the number of non-isotopic algebras $R/Rf$ obtained by Lavrauw and Sheekey.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18451v1</guid>
      <category>math.RA</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Susanne Pumpluen</dc:creator>
    </item>
    <item>
      <title>Misinformation Dynamics in Social Networks</title>
      <link>https://arxiv.org/abs/2511.18733</link>
      <description>arXiv:2511.18733v1 Announce Type: cross 
Abstract: Information transmitted across modern communication platforms is degraded not only by intentional manipulation (disinformation) but also by intrinsic cognitive decay and topology-dependent social averaging (misinformation). We develop a continuous-fidelity field theory on multiplex networks with distinct layers representing private chats, group interactions, and broadcast channels. Our analytic solutions reveal three universal mechanisms controlling information quality: (i) groupthink blending, where dense group coupling drives fidelity to the initial group mean; (ii) bridge-node bottlenecks, where cross-community flow produces irreversible dilution; and (iii) a network-wide fidelity landscape set by a competition between broadcast truth-injection and structural degradation pathways. These results demonstrate that connectivity can reduce information integrity and establish quantitative control strategies to enhance fidelity in large-scale communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18733v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.IT</category>
      <category>econ.TH</category>
      <category>hep-th</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeff Murugan</dc:creator>
    </item>
    <item>
      <title>On Instability of Minimax Optimal Optimism-Based Bandit Algorithms</title>
      <link>https://arxiv.org/abs/2511.18750</link>
      <description>arXiv:2511.18750v1 Announce Type: cross 
Abstract: Statistical inference from data generated by multi-armed bandit (MAB) algorithms is challenging due to their adaptive, non-i.i.d. nature. A classical manifestation is that sample averages of arm rewards under bandit sampling may fail to satisfy a central limit theorem. Lai and Wei's stability condition provides a sufficient, and essentially necessary criterion, for asymptotic normality in bandit problems. While the celebrated Upper Confidence Bound (UCB) algorithm satisfies this stability condition, it is not minimax optimal, raising the question of whether minimax optimality and statistical stability can be achieved simultaneously. In this paper, we analyze the stability properties of a broad class of bandit algorithms that are based on the optimism principle. We establish general structural conditions under which such algorithms violate the Lai-Wei stability criterion. As a consequence, we show that widely used minimax-optimal UCB-style algorithms, including MOSS, Anytime-MOSS, Vanilla-MOSS, ADA-UCB, OC-UCB, KL-MOSS, KL-UCB++, KL-UCB-SWITCH, and Anytime KL-UCB-SWITCH, are unstable. We further complement our theoretical results with numerical simulations demonstrating that, in all these cases, the sample means fail to exhibit asymptotic normality.
  Overall, our findings suggest a fundamental tension between stability and minimax optimal regret, raising the question of whether it is possible to design bandit algorithms that achieve both. Understanding whether such simultaneously stable and minimax optimal strategies exist remains an important open direction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18750v1</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samya Praharaj, Koulik Khamaru</dc:creator>
    </item>
    <item>
      <title>Scale What Counts, Mask What Matters: Evaluating Foundation Models for Zero-Shot Cross-Domain Wi-Fi Sensing</title>
      <link>https://arxiv.org/abs/2511.18792</link>
      <description>arXiv:2511.18792v1 Announce Type: cross 
Abstract: While Wi-Fi sensing offers a compelling, privacy-preserving alternative to cameras, its practical utility has been fundamentally undermined by a lack of robustness across domains. Models trained in one setup fail to generalize to new environments, hardware, or users, a critical "domain shift" problem exacerbated by modest, fragmented public datasets. We shift from this limited paradigm and apply a foundation model approach, leveraging Masked Autoencoding (MAE) style pretraining on the largest and most heterogeneous Wi-Fi CSI datasets collection assembled to date. Our study pretrains and evaluates models on over 1.3 million samples extracted from 14 datasets, collected using 4 distinct devices across the 2.4/5/6 GHz bands and bandwidths from 20 to 160 MHz. Our large-scale evaluation is the first to systematically disentangle the impacts of data diversity versus model capacity on cross-domain performance. The results establish scaling trends on Wi-Fi CSI sensing. First, our experiments show log-linear improvements in unseen domain performance as the amount of pretraining data increases, suggesting that data scale and diversity are key to domain generalization. Second, based on the current data volume, larger model can only provide marginal gains for cross-domain performance, indicating that data, rather than model capacity, is the current bottleneck for Wi-Fi sensing generalization. Finally, we conduct a series of cross-domain evaluations on human activity recognition, human gesture recognition and user identification tasks. The results show that the large-scale pretraining improves cross-domain accuracy ranging from 2.2% to 15.7%, compared to the supervised learning baseline. Overall, our findings provide insightful direction for designing future Wi-Fi sensing systems that can eventually be robust enough for real-world deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18792v1</guid>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Jiang, Yihe Yan, Yanxiang Wang, Chun Tung Chou, Wen Hu</dc:creator>
    </item>
    <item>
      <title>Robust Nonlinear Transform Coding: A Framework for Generalizable Joint Source-Channel Coding</title>
      <link>https://arxiv.org/abs/2511.18884</link>
      <description>arXiv:2511.18884v1 Announce Type: cross 
Abstract: This paper proposes robust nonlinear transform coding (Robust-NTC), a generalizable digital joint source-channel coding (JSCC) framework that couples variational latent modeling with channel adaptive transmission. Unlike learning-based JSCC methods that implicitly absorb channel variations, Robust-NTC explicitly models element-wise latent distributions via a variational objective with a Gaussian proxy for quantization and channel noise, allowing encoder-decoder to capture latent uncertainty without channel-specific training. Using the learned statistics, Robust-NTC also facilitates rate-distortion optimization to adaptively select element-wise quantizers and bit depths according to online channel condition. To support practical deployment, Robust-NTC is integrated into an orthogonal frequency-division multiplexing (OFDM) system, where a unified resource allocation framework jointly optimizes latent quantization, bit allocation, modulation order, and power allocation to minimize transmission latency while guaranteeing learned distortion targets. Simulation results demonstrate that for practical OFDM systems, Robust-NTC achieves superior rate-distortion efficiency and stable reconstruction fidelity compared to digital JSCC baselines across wide-ranging SNR conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18884v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jihun Park, Junyong Shin, Jinsung Park, Yo-Seb Jeon</dc:creator>
    </item>
    <item>
      <title>MIST: Mutual Information Via Supervised Training</title>
      <link>https://arxiv.org/abs/2511.18945</link>
      <description>arXiv:2511.18945v1 Announce Type: cross 
Abstract: We propose a fully data-driven approach to designing mutual information (MI) estimators. Since any MI estimator is a function of the observed sample from two random variables, we parameterize this function with a neural network (MIST) and train it end-to-end to predict MI values. Training is performed on a large meta-dataset of 625,000 synthetic joint distributions with known ground-truth MI. To handle variable sample sizes and dimensions, we employ a two-dimensional attention scheme ensuring permutation invariance across input samples. To quantify uncertainty, we optimize a quantile regression loss, enabling the estimator to approximate the sampling distribution of MI rather than return a single point estimate. This research program departs from prior work by taking a fully empirical route, trading universal theoretical guarantees for flexibility and efficiency. Empirically, the learned estimators largely outperform classical baselines across sample sizes and dimensions, including on joint distributions unseen during training. The resulting quantile-based intervals are well-calibrated and more reliable than bootstrap-based confidence intervals, while inference is orders of magnitude faster than existing neural baselines. Beyond immediate empirical gains, this framework yields trainable, fully differentiable estimators that can be embedded into larger learning pipelines. Moreover, exploiting MI's invariance to invertible transformations, meta-datasets can be adapted to arbitrary data modalities via normalizing flows, enabling flexible training for diverse target meta-distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18945v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>German Gritsai, Megan Richards, Maxime M\'eloux, Kyunghyun Cho, Maxime Peyrard</dc:creator>
    </item>
    <item>
      <title>Performance Guarantees for Quantum Neural Estimation of Entropies</title>
      <link>https://arxiv.org/abs/2511.19289</link>
      <description>arXiv:2511.19289v1 Announce Type: cross 
Abstract: Estimating quantum entropies and divergences is an important problem in quantum physics, information theory, and machine learning. Quantum neural estimators (QNEs), which utilize a hybrid classical-quantum architecture, have recently emerged as an appealing computational framework for estimating these measures. Such estimators combine classical neural networks with parametrized quantum circuits, and their deployment typically entails tedious tuning of hyperparameters controlling the sample size, network architecture, and circuit topology. This work initiates the study of formal guarantees for QNEs of measured (R\'enyi) relative entropies in the form of non-asymptotic error risk bounds. We further establish exponential tail bounds showing that the error is sub-Gaussian, and thus sharply concentrates about the ground truth value. For an appropriate sub-class of density operator pairs on a space of dimension $d$ with bounded Thompson metric, our theory establishes a copy complexity of $O(|\Theta(\mathcal{U})|d/\epsilon^2)$ for QNE with a quantum circuit parameter set $\Theta(\mathcal{U})$, which has minimax optimal dependence on the accuracy $\epsilon$. Additionally, if the density operator pairs are permutation invariant, we improve the dimension dependence above to $O(|\Theta(\mathcal{U})|\mathrm{polylog}(d)/\epsilon^2)$. Our theory aims to facilitate principled implementation of QNEs for measured relative entropies and guide hyperparameter tuning in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19289v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sreejith Sreekumar, Ziv Goldfeld, Mark M. Wilde</dc:creator>
    </item>
    <item>
      <title>Construction and Decoding of Error--Correcting Codes from Ideal Lattices of Finite Ternary Gamma Semirings</title>
      <link>https://arxiv.org/abs/2511.19378</link>
      <description>arXiv:2511.19378v1 Announce Type: cross 
Abstract: This paper introduces a new class of error-correcting codes constructed from the ideal lattices of finite commutative ternary Gamma-semirings (TGS). Unlike classical linear or ring-linear codes, which rely on binary operations, TGS codes arise from the intrinsic ternary operation $[x,y,z]$ and the op-plus order that governs coordinatewise absorption. The fundamental parameters of a TGS code are determined by the $k$-ideal structure of the underlying semiring: the dimension is given by the index $|T/I|$, while the minimum distance depends on the minimal nonzero elements of the distributive ideal lattice $L(T)$. This leads to parameter sets that are not achievable over finite fields, group algebras, or standard semiring frameworks.
  A quotient-based decoding method is developed in which the ternary syndrome $S(c) = Phi(c) + I$ lies in the quotient TGS $T/I$ and partitions the ambient space into cosets determined by ideal absorption. Minimal nonzero lattice elements yield canonical error representatives, producing a decoding procedure that resembles classical syndrome decoding but comes from higher-arity interactions. A concrete finite example illustrates the computation of parameters, the structure of syndrome classes, and the performance of the decoding method.
  These results show that ternary Gamma-semirings provide a new algebraic foundation for nonlinear, nonbinary, and higher-arity coding theory. Their ideal-lattice structure and ternary quotient behavior generate new decoding mechanisms and error profiles, expanding algebraic coding theory beyond the limitations of classical linear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19378v1</guid>
      <category>math.RA</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chandrasekhar Gokavarapu (Department of Mathematics, Government College), D. Madhusudhana Rao (Department of Mathematics, Government College for Women)</dc:creator>
    </item>
    <item>
      <title>PTF Testing Lower Bounds for Non-Gaussian Component Analysis</title>
      <link>https://arxiv.org/abs/2511.19398</link>
      <description>arXiv:2511.19398v1 Announce Type: cross 
Abstract: This work studies information-computation gaps for statistical problems. A common approach for providing evidence of such gaps is to show sample complexity lower bounds (that are stronger than the information-theoretic optimum) against natural models of computation. A popular such model in the literature is the family of low-degree polynomial tests. While these tests are defined in such a way that make them easy to analyze, the class of algorithms that they rule out is somewhat restricted. An important goal in this context has been to obtain lower bounds against the stronger and more natural class of low-degree Polynomial Threshold Function (PTF) tests, i.e., any test that can be expressed as comparing some low-degree polynomial of the data to a threshold. Proving lower bounds against PTF tests has turned out to be challenging. Indeed, we are not aware of any non-trivial PTF testing lower bounds in the literature.
  In this paper, we establish the first non-trivial PTF testing lower bounds for a range of statistical tasks. Specifically, we prove a near-optimal PTF testing lower bound for Non-Gaussian Component Analysis (NGCA). Our NGCA lower bound implies similar lower bounds for a number of other statistical problems. Our proof leverages a connection to recent work on pseudorandom generators for PTFs and recent techniques developed in that context. At the technical level, we develop several tools of independent interest, including novel structural results for analyzing the behavior of low-degree polynomials restricted to random directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19398v1</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilias Diakonikolas, Daniel M. Kane, Sihan Liu, Thanasis Pittas</dc:creator>
    </item>
    <item>
      <title>Quasi-cyclic Hermitian construction of binary quantum codes</title>
      <link>https://arxiv.org/abs/2210.04487</link>
      <description>arXiv:2210.04487v2 Announce Type: replace 
Abstract: In this paper, we propose a sufficient condition for a family of 2-generator self-orthogonal quasi-cyclic codes with respect to Hermitian inner product. Supported in the Hermitian construction, we show algebraic constructions of good quantum codes. 30 new binary quantum codes with good parameters improving the best-known lower bounds on minimum distance in Grassl's code tables \cite{Grassl:codetables} are constructed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.04487v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liangdong Lu, Gaochi Zhang, Ganyu Feng, Wenzheng Ma</dc:creator>
    </item>
    <item>
      <title>Enhanced Low-Complexity Receiver Design for Short Block Transmission Systems</title>
      <link>https://arxiv.org/abs/2404.10065</link>
      <description>arXiv:2404.10065v3 Announce Type: replace 
Abstract: This paper presents a comprehensive analysis and performance enhancement of short block length channel detection incorporating training information. The current communication systems' short block length channel detection typically consists of least squares channel estimation followed by quasi-coherent detection. By investigating the receiver structure, specifically the estimator-correlator, we show that the non-coherent term, often disregarded in conventional detection metrics, results in significant losses in performance and sensitivity in typical operating regimes of 5G and 6G systems. A comparison with the fully non-coherent receiver in multi-antenna configurations reveals substantial losses in low spectral efficiency operating areas. Additionally, we demonstrate that by employing an adaptive DMRS-data power adjustment, it is possible to reduce the performance loss gap, which is amenable to a more sensitive quasi-coherent receiver. However, both of the aforementioned ML detection strategies can result in substantial computational complexity when processing long bit-length codes. We propose an approach to tackle this challenge by introducing the principle of block or segment coding using First-Order RM Codes, which is amenable to low-cost decoding through block-based fast Hadamard transforms. The Block-based FHT has demonstrated to be cost-efficient with regards to decoding time, as it evolves from quadric to quasi-linear complexity with a manageable decline in performance. Additionally, by incorporating an adaptive DMRS-data power adjustment technique, we are able to bridge/reduce the performance gap with respect to the conventional maximum likelihood receiver and attain high sensitivity, leading to a good trade-off between performance and complexity to efficiently handle small payloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10065v3</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/PIMRC56721.2023.10293994</arxiv:DOI>
      <dc:creator>Mody Sy, Raymond Knopp</dc:creator>
    </item>
    <item>
      <title>Can Knowledge Improve Security? A Coding-Enhanced Jamming Approach for Semantic Communication</title>
      <link>https://arxiv.org/abs/2504.16960</link>
      <description>arXiv:2504.16960v5 Announce Type: replace 
Abstract: As semantic communication (SemCom) attracts growing attention as a novel communication paradigm, ensuring the security of transmitted semantic information over open wireless channels has become a critical issue. However, traditional encryption methods often introduce significant additional communication overhead to maintain reliability, and conventional learning-based secure SemCom methods typically rely on a channel capacity advantage for the legitimate receiver, which is challenging to guarantee in real-world scenarios. In this paper, we propose a coding-enhanced jamming method that eliminates the need to transmit a secret key by utilizing shared knowledge, which may be part of the training set of the SemCom system, between the legitimate receiver and the transmitter. Specifically, we leverage the shared private knowledge base to generate a set of private digital codebooks in advance using neural network (NN)-based encoders. For each transmission, we encode the transmitted data into a digital sequence Y1 and associate Y1 with a sequence randomly picked from the private codebook, denoted as Y2, through superposition coding. Here, Y1 serves as the outer code and Y2 as the inner code. By optimizing the power allocation between the inner and outer codes, the legitimate receiver can reconstruct the transmitted data using successive decoding based on the shared index of Y2, while the eavesdropper's decoding performance is severely degraded, potentially to the point of random guessing. Experimental results demonstrate that our method achieves security comparable to state-of-the-art approaches while significantly improving the reconstruction performance of the legitimate receiver by more than 1 dB across varying channel signal-to-noise ratios (SNRs) and compression ratios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16960v5</guid>
      <category>cs.IT</category>
      <category>eess.IV</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weixuan Chen (Sherman), Qianqian Yang (Sherman), Shuo Shao (Sherman), Zhiguo Shi (Sherman), Jiming Chen (Sherman),  Xuemin (Sherman),  Shen</dc:creator>
    </item>
    <item>
      <title>Rack-Aware MSR Codes with Linear Field Size and Smaller Sub-Packetization for Tolerating Multiple Erasures</title>
      <link>https://arxiv.org/abs/2506.18367</link>
      <description>arXiv:2506.18367v3 Announce Type: replace 
Abstract: In an $(n,k,d)$ rack-aware storage model, the system consists of $n$ nodes uniformly distributed across $\bar{n}$ successive racks, such that each rack contains $u$ nodes of equal capacity and the reconstructive degree satisfies $k=\bar{k}u+v$ where $0\leq v\leq u-1$. Suppose there are $h\geq1$ failed nodes in a rack (called the host rack). Then together with its surviving nodes, the host rack downloads recovery data from $\bar{d}$ helper racks and repairs its failed nodes. In this paper, we focus on studying the rack-aware minimum storage generating (MSR) codes for repairing $h$ failed nodes within the same rack. By using the coupled-layer construction with the alignment technique, we construct the first class of rack-aware MSR codes for all $\bar{k}+1\leq\bar{d}\leq\bar{n}-1$ which achieve the small sub-packetization $l=\bar{s}^{\lceil\bar{n}/\bar{s}\rceil}$ where the field size $q$ increases linearly with $n$ and $\bar{s}=\bar{d}-\bar{k}+1$. In addition, these codes achieve optimal repair bandwidth for $1\leq h\leq u-v$, and asymptotically optimal repair bandwidth for $u-v+1\leq h\leq u$. In particular, they achieve optimal access when $h=u-v$. It is worth noting that the existing rack-aware MSR codes which achieve the same sub-packetization $l=\bar{s}^{\lceil\bar{n}/\bar{s}\rceil}$ are only known for the special case of $\bar{d}=\bar{n}-1$, $h=1$, and the field size is much larger than ours. Then, based on our first construction we further develop another class of explicit rack-aware MSR codes with even smaller sub-packetization $l=\bar{s}^{\lceil\bar{n}/(\bar{s}+1)\rceil}$ for all admissible values of $\bar{d}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18367v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hengming Zhao, Dianhua Wu, Minquan Cheng</dc:creator>
    </item>
    <item>
      <title>One-weight codes in the sum-rank metric</title>
      <link>https://arxiv.org/abs/2508.04262</link>
      <description>arXiv:2508.04262v2 Announce Type: replace 
Abstract: One-weight codes, in which all nonzero codewords share the same weight, form a highly structured class of linear codes with deep connections to finite geometry. While their classification is well understood in the Hamming and rank metrics - being equivalent to (direct sums of) simplex codes - the sum-rank metric presents a far more intricate landscape. In this work, we explore the geometry of one-weight sum-rank metric codes, focusing on three distinct classes. First, we introduce and classify \emph{constant rank-list} sum-rank codes, where each nonzero codeword has the same tuple of ranks, extending results from the rank-metric setting. Next, we investigate the more general \emph{constant rank-profile} codes, where, up to reordering, each nonzero codeword has the same tuple of ranks. Although a complete classification remains elusive, we present the first examples and partial structural results for this class. Finally, we consider one-weight codes that are also MSRD (Maximum Sum-Rank Distance) codes. For dimension two, constructions arise from partitions of scattered linear sets on projective lines. For dimension three, we connect their existence to that of special $2$-fold blocking sets in the projective plane, leading to new bounds and nonexistence results over certain fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04262v2</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Usman Mushrraf, Ferdinando Zullo</dc:creator>
    </item>
    <item>
      <title>Newton-Flow Particle Filters based on Generalized Cram\'er Distance</title>
      <link>https://arxiv.org/abs/2509.00182</link>
      <description>arXiv:2509.00182v2 Announce Type: replace 
Abstract: We propose a recursive particle filter for high-dimensional problems that inherently never degenerates. The state estimate is represented by deterministic low-discrepancy particle sets. We focus on the measurement update step, where a likelihood function is used for representing the measurement and its uncertainty. This likelihood is progressively introduced into the filtering procedure by homotopy continuation over an artificial time. A generalized Cram\'er distance between particle sets is derived in closed form that is differentiable and invariant to particle order. A Newton flow then continually minimizes this distance over artificial time and thus smoothly moves particles from prior to posterior density. The new filter is surprisingly simple to implement and very efficient. It just requires a prior particle set and a likelihood function, never estimates densities from samples, and can be used as a plugin replacement for classic approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00182v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Uwe D. Hanebeck</dc:creator>
    </item>
    <item>
      <title>Indoor Fluid Antenna Systems Enabled by Layout-Specific Modeling and Group Relative Policy Optimization</title>
      <link>https://arxiv.org/abs/2509.15006</link>
      <description>arXiv:2509.15006v3 Announce Type: replace 
Abstract: Fluid antenna system (FAS) revolutionizes wireless communications via utilizing position-flexible antennas that dynamically optimize channel conditions and mitigate multipath fading. This innovation is particularly valuable in indoor environments, in which signal propagation is severely degraded due to structural obstructions and complex multipath reflections. In this paper, we investigate the channel modeling and the joint optimization of antenna positioning, beamforming, and power allocation for indoor FAS. In particular, we propose a layout-specific channel model, and employ the novel group relative policy optimization (GRPO) algorithm for tackling the optimization problem. Compared to the state-of-the-art Sionna model, our model achieves an 83.3% reduction in computation time with an approximately 3 dB increase in root-mean-square error (RMSE). When simplified to a two-ray model, our model allows for a closed-form antenna position solution with near-optimal performance. For the joint optimization problem, our GRPO algorithm outperforms proximal policy optimization (PPO) and other baselines in sum-rate, while requiring only 50.8% computational resources of PPO, thanks to its group advantage estimation. Simulation results show that increasing either the group size or trajectory length in GRPO does not yield significant improvements in sum-rate, suggesting that these parameters can be selected conservatively without sacrificing performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15006v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tong Zhang, Qianren Li, Shuai Wang, Wanli Ni, Jiliang Zhang, Rui Wang, Kai-Kit Wong, Chan-Byoung Chae</dc:creator>
    </item>
    <item>
      <title>A Universal Block Error Rate Bound for Fluid Antenna Systems</title>
      <link>https://arxiv.org/abs/2511.09929</link>
      <description>arXiv:2511.09929v2 Announce Type: replace 
Abstract: Fluid antenna systems (FASs) offer genuine simplicity for communication network design by eliminating expensive hardware overhead and reducing the complexity of access protocol architectures. Through the discovery of significant spatial diversity within a compact antenna space, FASs enable the implementation of reconfigurable-antenna-based architectures. However, current state-of-the-art studies rarely investigate the impact of finite blocklength constraints on FAS-based designs, leaving a gap in both analytical modeling and the establishment of a solid, universally applicable performance metric for finite blocklength fluid antenna systems (FBL-FAS). In this work, we focus on the study of FBL-FAS and, more importantly, derive a block error rate (BLER) bound that serves as a general and practical performance benchmark across various FAS architectures. The proposed BLER bound is computable both with and without an explicit statistical model, meaning that the BLER performance can be characterized analytically or empirically under model-aware or model-free system scenarios. Moreover, when the statistical model is known, the analytical results derived from the proposed BLER bound exhibit strong alignment with the empirical findings, demonstrating the remarkable simplicity, accuracy, and universality of the proposed BLER bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09929v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhentian Zhang, David Morales-Jimenez, Hao Jiang, Christos Masouros</dc:creator>
    </item>
    <item>
      <title>A Fast Binary Splitting Approach for Non-Adaptive Learning of Erd\H{o}s--R\'enyi Graphs</title>
      <link>https://arxiv.org/abs/2511.17240</link>
      <description>arXiv:2511.17240v2 Announce Type: replace 
Abstract: We study the problem of learning an unknown graph via group queries on node subsets, where each query reports whether at least one edge is present among the queried nodes. In general, learning arbitrary graphs with $n$ nodes and $k$ edges is hard in the non-adaptive setting, requiring $\Omega\big(\min\{k^2\log n,\,n^2\}\big)$ tests even when a small error probability is allowed. We focus on learning Erd\H{o}s--R\'enyi (ER) graphs $G\sim\mathrm{ER}(n,q)$ in the non-adaptive setting, where the expected number of edges is $\bar{k}=q\binom{n}{2}$, and we aim to design an efficient testing--decoding scheme achieving asymptotically vanishing error probability. Prior work (Li--Fresacher--Scarlett, NeurIPS 2019) presents a testing--decoding scheme that attains an order-optimal number of tests $O(\bar{k}\log n)$ but incurs $\Omega(n^2)$ decoding time, whereas their proposed sublinear-time algorithm incurs an extra $(\log \bar{k})(\log n)$ factor in the number of tests. We extend the binary splitting approach, recently developed for non-adaptive group testing, to the ER graph learning setting, and prove that the edge set can be recovered with high probability using $O(\bar{k}\log n)$ tests while attaining decoding time $O(\bar{k}^{1+\delta}\log n)$ for any fixed $\delta&gt;0$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17240v2</guid>
      <category>cs.IT</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Ta, Jonathan Scarlett</dc:creator>
    </item>
    <item>
      <title>Unifying Summary Statistic Selection for Approximate Bayesian Computation</title>
      <link>https://arxiv.org/abs/2206.02340</link>
      <description>arXiv:2206.02340v4 Announce Type: replace-cross 
Abstract: Extracting low-dimensional summary statistics from large datasets is essential for efficient (likelihood-free) inference. We characterize three different classes of summaries and demonstrate their importance for correctly analyzing dimensionality reduction algorithms. We demonstrate that minimizing the expected posterior entropy (EPE) under the prior predictive distribution of the model provides a unifying principle that subsumes many existing methods; they are shown to be equivalent to, or special or limiting cases of, minimizing the EPE. We offer a unifying framework for obtaining informative summaries and propose a practical method using conditional density estimation to learn high-fidelity summaries automatically. We evaluate this approach on diverse problems, including a challenging benchmark model with a multi-modal posterior, a population genetics model, and a dynamic network model of growing trees. The results show that EPE-minimizing summaries can lead to posterior inference that is competitive with, and in some cases superior to, dedicated likelihood-based approaches, providing a powerful and general tool for practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.02340v4</guid>
      <category>stat.ME</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Till Hoffmann, Jukka-Pekka Onnela</dc:creator>
    </item>
    <item>
      <title>Frostman random variables, entropy inequalities, and applications</title>
      <link>https://arxiv.org/abs/2507.15196</link>
      <description>arXiv:2507.15196v4 Announce Type: replace-cross 
Abstract: We introduce Frostman conditions for bivariate random variables and study discretized entropy sum-product phenomena in both independent and dependent settings. Fix $0 &lt; s &lt; 1$, and let $(X,Y)$ be a bivariate real random variable with bounded support, whose distribution satisfies a Frostman condition of dimension $s$. Let $\phi(x,y)$ be a polynomial obtained from a diagonal polynomial $\rho_1(x)+\rho_2(y)\in \mathbb{R}[x, y]$ of degree $d\ge 2$ by applying an invertible rational linear change of variables in $(x,y)$. We show that there exists $\epsilon = \epsilon(\phi,s)&gt;0$ such that $$ \max\{H_n(X+Y), H_n(\phi(X,Y))\} \geq n(s+\epsilon) $$ for all sufficiently large $n$, where the precise assumptions on $(X,Y)$ depend on the Frostman level. The proof introduces a novel multi-step entropy framework, combining the submodularity formula, the discretized entropy Balog-Szemer\'{e}di-Gowers theorem, and state-of-the-art results on the Falconer distance problem, to reduce general forms to a diagonal core case.
  As an application, we obtain discretized sum-product type estimates. In particular, for a $\delta$-separated set $A\subseteq [0, 1]$ of cardinality $\delta^{-s}$, satisfying certain non-concentration conditions, and a dense subset $G\subseteq A\times A$, there exists $\epsilon=\epsilon(s, \phi)&gt;0$ such that $$ E_\delta(A+_GA) + E_\delta(\phi_G(A, A)) \gg\delta^{-\epsilon}(\#A) $$ for all $\delta$ small enough. Here $E_\delta(A)$ denotes the $\delta$-covering number of $A$, $A+_GA:=\{x+y\colon (x, y)\in G\}$, and $\phi_G(A,A):=\{\phi(x, y)\colon (x, y)\in G\}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15196v4</guid>
      <category>math.CA</category>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Iosevich, Thang Pham, Nguyen Dac Quan, Steven Senger, Boqing Xue</dc:creator>
    </item>
    <item>
      <title>Why Does Stochastic Gradient Descent Slow Down in Low-Precision Training?</title>
      <link>https://arxiv.org/abs/2508.07142</link>
      <description>arXiv:2508.07142v3 Announce Type: replace-cross 
Abstract: Low-precision training has become crucial for reducing the computational and memory costs of large-scale deep learning. However, quantizing gradients introduces magnitude shrinkage, which can change how stochastic gradient descent (SGD) converges. In this study, we explore SGD convergence under a gradient shrinkage model, where each stochastic gradient is scaled by a factor \( q_k \in (0,1] \). We show that this shrinkage affect the usual stepsize \( \mu_k \) with an effective stepsize \( \mu_k q_k \), slowing convergence when \( q_{\min} &lt; 1 \). With typical smoothness and bounded-variance assumptions, we prove that low-precision SGD still converges, but at a slower pace set by \( q_{\min} \), and with a higher steady error level due to quantization effects. We analyze theoretically how lower numerical precision slows training by treating it as gradient shrinkage within the standard SGD convergence setup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07142v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Vincent-Daniel Yun</dc:creator>
    </item>
    <item>
      <title>Synthetic Counterfactual Labels for Efficient Conformal Counterfactual Inference</title>
      <link>https://arxiv.org/abs/2509.04112</link>
      <description>arXiv:2509.04112v2 Announce Type: replace-cross 
Abstract: This work addresses the problem of constructing reliable prediction intervals for individual counterfactual outcomes. Existing conformal counterfactual inference (CCI) methods provide marginal coverage guarantees but often produce overly conservative intervals, particularly under treatment imbalance when counterfactual samples are scarce. We introduce synthetic data-powered CCI (SP-CCI), a new framework that augments the calibration set with synthetic counterfactual labels generated by a pre-trained counterfactual model. To ensure validity, SP-CCI incorporates synthetic samples into a conformal calibration procedure based on risk-controlling prediction sets (RCPS) with a debiasing step informed by prediction-powered inference (PPI). We prove that SP-CCI achieves tighter prediction intervals while preserving marginal coverage, with theoretical guarantees under both exact and approximate importance weighting. Empirical results on different datasets confirm that SP-CCI consistently reduces interval width compared to standard CCI across all settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04112v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Amirmohammad Farzaneh, Matteo Zecchin, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Learning to Equalize: Data-Driven Frequency-Domain Signal Recovery in Molecular Communications</title>
      <link>https://arxiv.org/abs/2509.11327</link>
      <description>arXiv:2509.11327v3 Announce Type: replace-cross 
Abstract: In molecular communications (MC), inter-symbol interference (ISI) and noise are key factors that degrade communication reliability. Although time-domain equalization can effectively mitigate these effects, it often entails high computational complexity concerning the channel memory. In contrast, frequency-domain equalization (FDE) offers greater computational efficiency but typically requires prior knowledge of the channel model. To address this limitation, this letter proposes FDE techniques based on long short-term memory (LSTM) neural networks, enabling temporal correlation modeling in MC channels to improve ISI and noise suppression. To eliminate the reliance on prior channel information in conventional FDE methods, a supervised training strategy is employed for channel-adaptive equalization. Simulation results demonstrate that the proposed LSTM-FDE significantly reduces the bit error rate compared to traditional FDE and feedforward neural network-based equalizers. This performance gain is attributed to the LSTM's temporal modeling capabilities, which enhance noise suppression and accelerate model convergence, while maintaining comparable computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11327v3</guid>
      <category>q-bio.SC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Xiang, Yu Huang, Miaowen Wen, Weiqiang Tan, Chan-Byoung Chae</dc:creator>
    </item>
    <item>
      <title>Reducing measurements in quantum erasure correction by quantum local recovery</title>
      <link>https://arxiv.org/abs/2510.22890</link>
      <description>arXiv:2510.22890v2 Announce Type: replace-cross 
Abstract: As measurements are costly and prone to errors on certain quantum computing devices, we should reduce the number of measurements and the number of measured qudits as small as possible in quantum erasure correction. It is intuitively obvious that a decoder can omit measurements of stabilizers that are irrelevant to erased qudits, but this intuition has not been rigorously formalized as far as the author is aware. In this paper, we formalize relevant stabilizers sufficient to correct erased qudits with a quantum stabilizer code, by using a recent idea from quantum local recovery. The minimum required number of measured stabilizer observables is also clarified. As an application, we also show that correction of $\delta$ erasures on a generalized surface code proposed by Delfosse, Iyer and Poulin requires at most $\delta$ measurements of vertexes and at most $\delta$ measurements of faces, independently of its code parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22890v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryutaroh Matsumoto</dc:creator>
    </item>
  </channel>
</rss>
