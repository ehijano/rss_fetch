<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Nov 2025 02:43:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Quadrature for Singular Integrals over convex Polytopes</title>
      <link>https://arxiv.org/abs/2511.13974</link>
      <description>arXiv:2511.13974v1 Announce Type: new 
Abstract: A new algorithm for the efficient numerical approximation of weakly singular integrals over convex polytopes is introduced. Such integrals appear in the Galerkin discretizations of integral equations and nonlocal partial differential equations. The polytope is decomposed into a number of convex hulls of a singular and regular face. This expresses the singularity in a single variable which is effectively handled by Gauss-Jacobi quadrature. The decomposition algorithm is applicable to general finite polytopes. The Cartesian product of two simplices and two cubes will be discussed as special cases and numerical examples will be presented to illustrate the convergence of the resulting quadrature scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13974v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Tausch</dc:creator>
    </item>
    <item>
      <title>A CUR Krylov Solver for Large-Scale Linear Matrix Equations</title>
      <link>https://arxiv.org/abs/2511.14015</link>
      <description>arXiv:2511.14015v1 Announce Type: new 
Abstract: Developing efficient solvers for large-scale multi-term linear matrix equations remains a central challenge in numerical linear algebra and is still largely unresolved. This paper introduces a methodology leveraging CUR decomposition for solving large-scale generalized Sylvester as well as non-Sylvester multi-term equations on low-rank matrix manifolds. The approach decomposes the original equation into two smaller subproblems: one involving all columns with a small subset of rows, and the other involving all rows with a small subset of columns. The rows and columns are strategically selected using the discrete empirical interpolation method. We further utilize the CUR properties and propose a novel iterative scheme that removes the dependencies between selected and unselected rows (and likewise for columns), thereby enabling the subset problems to be solved independently. We present a Krylov-based scheme for solving the resulting subproblems, which scales effectively to large problems and does not rely on a Sylvester structure. The method incorporates rank adaptivity, dynamically adjusting computational rank to reach the desired accuracy. The methodology is demonstrated in three representative settings: (i) implicit time integration of matrix differential equations on low-rank manifolds, leading to multi-term linear matrix equations; (ii) large-scale steady-state generalized Lyapunov equations including cases of size up to $10^{13}$ unknown entries; and (iii) non-Sylvester linear matrix equations with Hadamard product terms, such as those arising in nonlinear partial differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14015v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saeed Akbari, Damiano Lombardi, Hessam Babaee</dc:creator>
    </item>
    <item>
      <title>A Phase-Field Model for Vesicle Membranes Incorporating Area-Difference Elasticity</title>
      <link>https://arxiv.org/abs/2511.14078</link>
      <description>arXiv:2511.14078v1 Announce Type: new 
Abstract: This paper presents a phase-field model for simulating the three-dimensional deformation of vesicle membranes, incorporating area-difference elasticity, with constraints on bulk volume and surface area. We develop efficient numerical schemes based on the Fourier-spectral method for spatial discretization and temporal evolution. The model successfully captures a wide variety of steady-state vesicle shapes. The numerical experiments demonstrate that by tuning the simulation parameters, the vesicle can transition from a simple discocyte shape to a complex, multi-armed starfish-like and nested configuration. These results highlight the crucial role of area-difference elasticity in determining vesicle morphology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14078v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihong Liang, Emine Celiker, Ping Lin</dc:creator>
    </item>
    <item>
      <title>High-order Nodal Space-time Flux Reconstruction Methods for Hyperbolic Conservation Laws on Curvilinear Moving Grids</title>
      <link>https://arxiv.org/abs/2511.14128</link>
      <description>arXiv:2511.14128v1 Announce Type: new 
Abstract: High-order nodal space-time flux reconstruction (STFR) methods have been developed to solve hyperbolic conservation laws on curvilinear moving grids. Unlike the method-of-lines approach for moving domain simulation, the grid velocity is implicitly embedded into the curvilinear geometric representation of space-time elements. Several key issues in moving domain simulation, including the discrete geometric conservation law (GCL), solution and flux approximation, and aliasing error control, are discussed in the context of the nodal STFR framework. Conditions and the corresponding numerical strategies to reduce aliasing errors due to the curvilinear space-time representation of moving domain problems, including the discrete GCL errors (i.e. one type of aliasing errors in the space-time framework), are then explained and examined. Since a space-time tensor product is used to construct the FR formulation in this study, all space-time schemes show the temporal superconvergence property, similar to that presented by the implicit Runge-Kutta discontinuous Galerkin (IRK-DG) schemes, in moving domain simulation. Specifically, a nominal $k$th order scheme can achieve a ($2k-1$)th order superconvergence rate when solutions on $k$ Gauss-Legendre points are used to construct polynomials in the time dimension. The robustness of temporal superconvergence in the existence of aliasing errors induced by the curvilinear space-time representation, and upon de-aliasing operations based on polynomial filtering, has been examined with numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14128v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meilin Yu</dc:creator>
    </item>
    <item>
      <title>Low-thrust Interplanetary Trajectories with Missed Thrust Events: a Numerical Approach</title>
      <link>https://arxiv.org/abs/2511.14274</link>
      <description>arXiv:2511.14274v1 Announce Type: new 
Abstract: The problem under consideration is to drive a spatial vehicle to a target at a given final time while minimizing fuel consumption. This is a classical optimal control problem in a deterministic setting. However temporary stochastic failures of the engine may prevent reaching the target after the engine usage is recovered. Therefore, a stochastic optimal control problem is formulated under the constraint of ensuring a minimal probability of hitting the target. This problem is modeled, improved and finally solved by dualizing the probability constraint and using an Arrow-Hurwicz stochastic algorithm. Numerical results concerning an interplanetary mission are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14274v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Philippe Chancelier (CERMICS), Pierre Carpentier (UMA), Guy Cohen (CERMICS), Thierry Dargent (CNES), Richard Epenoy (CNES)</dc:creator>
    </item>
    <item>
      <title>Some stability properties of Hamiltonian Poisson integrators</title>
      <link>https://arxiv.org/abs/2511.14303</link>
      <description>arXiv:2511.14303v1 Announce Type: new 
Abstract: Hamiltonian Poisson integrators are Poisson integrators that admit a modified Hamiltonian. In this article, we illustrate the importance of the existence of a modified Hamiltonian for Poisson integrators in the context of integrable and non-integrable systems. Examples of Hamiltonian systems are provided by Lotka-Volterra dynamics; in order to investigate stability properties of Hamiltonian Poisson integrators on non-integrable systems, we exhibit a non-integrable $5$-dimensional Lotka-Volterra system and pursue numerical investigations of it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14303v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.DG</category>
      <category>math.DS</category>
      <category>math.MP</category>
      <category>math.SG</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oscar Cosserat</dc:creator>
    </item>
    <item>
      <title>Unfitted Lattice Green's Function Method for Exterior Scattering in Complex Geometry</title>
      <link>https://arxiv.org/abs/2511.14346</link>
      <description>arXiv:2511.14346v1 Announce Type: new 
Abstract: This paper develops a finite-difference analogue of the boundary integral/element method for the numerical solution of two-dimensional exterior scattering from scatterers of arbitrary shapes. The discrete fundamental solution, known as the lattice Green's function (LGF), for the Helmholtz equation on an infinite lattice is derived and employed to construct boundary algebraic equations through the discrete potentials framework. Unlike the continuous fundamental solution used in boundary integral methods, the LGF introduces no singularity, which simplifies numerical implementation. Boundary conditions are incorporated through local Lagrange interpolation on unfitted cut cells. The resulting method retains key advantages of boundary integral approaches-including dimension reduction and the absence of artificial boundary conditions--while enabling finite differences for complex geometries. Numerical results demonstrate the accuracy and robustness of the method for various scatterers, including circular, triangular, and multiple-body configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14346v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siyuan Wang, Qing Xia</dc:creator>
    </item>
    <item>
      <title>Approximate Duals of B-splines for the Exact Representation of Splines on Coarse Knot Vectors</title>
      <link>https://arxiv.org/abs/2511.14443</link>
      <description>arXiv:2511.14443v1 Announce Type: new 
Abstract: Approximate duals of B-splines were first used by Chui et al. (2004) for the purpose of constructing tight wavelet frames on bounded intervals. They are splines with local support, whose inner product with a polynomial in the spline space provides the exact coefficient in the representation of the same polynomial in the B-spline basis. This implies that the associated integral operator is a quasi-projection in the sense of Jia (2004). Moreover, the approximation of smooth functions in Sobolev spaces by this quasi-projection yields the optimal approximation order. More recently, for applications in isogeometric analysis, the optimal approximation order should also be obtained for functions in a slightly larger space, the so-called bent Sobolev space defined in \cite{Bazilevsetal2006,daVeigaetal2014}. This requires the construction of enhanced approximate duals, whose corresponding integral operator provides the exact representation of all spline functions with respect to a coarse knot vector, using only few interior knots of the given knot vector. Our analysis provides an explicit construction and hints for an efficient computation of enhanced approximate duals. Explicit representations as linear combinations of B-splines are provided for $m=2$ and $m=3$, and two numerical examples for splines of order $3\le m\le 6$ demonstrate the optimal approximation order for functions in bent Sobolev spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14443v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Joachim St\"ockler</dc:creator>
    </item>
    <item>
      <title>A System Dynamics Approach to Evaluating Sludge Management Strategies in Vinasse Treatment: Cost-Benefit Analysis and Scenario Assessment</title>
      <link>https://arxiv.org/abs/2511.14607</link>
      <description>arXiv:2511.14607v1 Announce Type: new 
Abstract: In the Chilean local alcohol industry (pisco indus- try), for one liter of alcohol produced 10-15 liters of vinasse as the main wastewater of the process. To comply with industrial waste regulations, vinasse must be stored, which enables evaporation, leaving behind a residual sludge. However, treating vinasse remains an environmental and industrial challenge, having a high nutrient concentration and acidity that can degrade soil quality and harm surrounding vegetation. While previous studies have modeled sludge generation and transport in urban water systems, research on industrial wastewater, such as the alcohol industry, remains limited, affecting the search for opportunities to improve the treatment process.. This paper proposes a System Dynamics Model (SDM) to assess the costs associated with three management strategies: natural drying of vinasse, relocation to an alternative site, and implementation of a coagulation- flocculation treatment to accelerate sludge production. This paper makes two contributions. First, we describe a pioneer SDM applicable to sludge management, which includes variables such as sludge transport, coagulant quantity, and ambient temperature to make hypothetical scenarios that affect the treatment processes of vinasse. Second, we present the expected results of the associated costs of the scenarios proposed in the model, helping decision-makers to manage vinasse. The model is calibrated with historical data provided by a company in the North of Chile, helping to improve the decision-making for vinasse treatment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14607v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.OT</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Agustin Olivares, Paul Leger, Rodrigo Poblete</dc:creator>
    </item>
    <item>
      <title>Derivative of the truncated singular value and eigen decomposition</title>
      <link>https://arxiv.org/abs/2511.14651</link>
      <description>arXiv:2511.14651v1 Announce Type: new 
Abstract: Recently developed applications in the field of machine learning and computational physics rely on automatic differentiation techniques, that require stable and efficient linear algebra gradient computations. This technical note provides a comprehensive and detailed discussion of the derivative of the truncated singular and eigenvalue decomposition. It summarizes previous work and builds on them with an extensive description of how to derive the relevant terms. A main focus is correctly expressing the derivative in terms of the truncated part, despite lacking knowledge of the full decomposition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14651v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Naumann</dc:creator>
    </item>
    <item>
      <title>Optimal ${L^2}$ error estimates of fully discrete finite element methods for the 2D/3D diffuse interface two-phase MHD flows</title>
      <link>https://arxiv.org/abs/2511.14656</link>
      <description>arXiv:2511.14656v1 Announce Type: new 
Abstract: In this paper, we perform an optimal L2-norm error analysis of a fully discrete convex-splitting finite element method (FEM) for the two-phase diffuse interface magnetohydrodynamics (MHD) system. The method use the semi-implicit backward Euler scheme in time and use the standard inf-sup stable Taylor-Hood/Mini elements to discretize the velocity and pressure. The previous works provided the optimal H1-norm error estimates for all components, but not the optimal L2-norm estimates, which are caused by the nonlinear coupled terms. The optimal L2-norm error analysis is achieved through the novel Ritz and Stokes quasi-projections. In addition, the mass conservation and unconditional energy stability of the finite element convex-splitting scheme are ensured. Numerical examples are presented to validate the theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14656v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ke Zhang, Haiyan Su</dc:creator>
    </item>
    <item>
      <title>nlKrylov: A Unified Framework for Nonlinear GCR-type Krylov Subspace Methods</title>
      <link>https://arxiv.org/abs/2511.14713</link>
      <description>arXiv:2511.14713v1 Announce Type: new 
Abstract: In this paper, we introduce a unified framework for nonlinear Krylov subspace methods (nlKrylov) to solve systems of nonlinear equations. Building on classical GCR-like/type linear Krylov solvers such as GMRESR, we generalize these approaches to nonlinear problems via nested algorithmic structures. We present rigorous convergence results for problems, relying on relaxed assumptions that avoid the need for exact line searches. The framework is further extended to matrix-valued rootfinding problems using global nonlinear Krylov approaches. Extensive numerical experiments validate the theoretical insights and demonstrate the robustness and efficiency of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14713v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom Werner, Ning Wan, Agnieszka Miedlar</dc:creator>
    </item>
    <item>
      <title>Extended Physics Informed Neural Network for Hyperbolic Two-Phase Flow in Porous Media</title>
      <link>https://arxiv.org/abs/2511.13734</link>
      <description>arXiv:2511.13734v1 Announce Type: cross 
Abstract: The accurate solution of nonlinear hyperbolic partial differential equations (PDEs) remains a central challenge in computational science due to the presence of steep gradients, discontinuities, and multiscale structures that make conventional discretization-based solvers computationally demanding. Physics-Informed Neural Networks (PINNs) embed the governing equations into the learning process, enabling mesh-free solution of PDEs, yet they often struggle to capture steep gradients, discontinuities, and complex nonlinear wave interactions. To address these limitations, this study employs the Extended Physics-Informed Neural Network (XPINN) framework to solve the nonlinear Buckley-Leverett equation with a nonconvex flux function, which models immiscible two-phase flow in porous media. The computational domain is dynamically decomposed in space and time into evolving pre-shock and post-shock regions, allowing localized subnetworks to efficiently learn distinct flow behaviors. Coupling between subnetworks is achieved through the Rankine-Hugoniot jump condition, which enforces physically consistent flux continuity across the moving shock interface. Numerical experiments demonstrate that the proposed XPINN approach accurately captures discontinuous saturation fronts and compound wave interactions without requiring artificial diffusion or entropy corrections. Compared to standard PINNs, the XPINN framework achieves superior stability, faster convergence, and enhanced resolution of nonlinear wave dynamics using smaller, domain-specific models with fewer trainable parameters, establishing it as an effective and scalable tool for solving challenging hyperbolic PDEs in multiphase flow problems. The code of this work is available on github.com/saifkhanengr/XPINN-for-Buckley-Leverett.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13734v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saif Ur Rehman, Wajid Yousuf</dc:creator>
    </item>
    <item>
      <title>Synergizing Multigrid Algorithms with Vision Transformer: A Novel Approach to Enhance the Seismic Foundation Model</title>
      <link>https://arxiv.org/abs/2511.13800</link>
      <description>arXiv:2511.13800v1 Announce Type: cross 
Abstract: Due to the emergency and homogenization of Artificial Intelligence (AI) technology development, transformer-based foundation models have revolutionized scientific applications, such as drug discovery, materials research, and astronomy. However, seismic data presents unique characteristics that require specialized processing techniques for pretraining foundation models in seismic contexts with high- and low-frequency features playing crucial roles. Existing vision transformers (ViTs) with sequential tokenization ignore the intrinsic pattern and fail to grasp both the high- and low-frequency seismic information efficiently and effectively. This work introduces a novel adaptive two-grid foundation model training strategy (ADATG) with Hilbert encoding specifically tailored for seismogram data, leveraging the hierarchical structures inherent in seismic data. Specifically, our approach employs spectrum decomposition to separate high- and low-frequency components and utilizes hierarchical Hilbert encoding to represent the data effectively. Moreover, observing the frequency principle observed in ViTs, we propose an adaptive training strategy that initially emphasizes coarse-level information and then progressively refines the model's focus on fine-level features. Our extensive experiments demonstrate the effectiveness and efficiency of our training methods. This research highlights the importance of data encoding and training strategies informed by the distinct characteristics of high- and low-frequency features in seismic images, ultimately contributing to the enhancement of visual seismic foundation models pretraining.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13800v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Huiwen Wu, Shuo Zhang, Yi Liu, Hongbin Ye</dc:creator>
    </item>
    <item>
      <title>Convex relaxation approaches for high dimensional optimal transport</title>
      <link>https://arxiv.org/abs/2511.13847</link>
      <description>arXiv:2511.13847v1 Announce Type: cross 
Abstract: Optimal transport (OT) is a powerful tool in mathematics and data science but faces severe computational and statistical challenges in high dimensions. We propose convex relaxation approaches based on marginal and cluster moment relaxations that exploit locality and correlative sparsity in the distributions. These methods approximate high-dimensional couplings using low-order marginals and sparse moment statistics, yielding semidefinite programs that provide lower bounds on the OT cost with greatly reduced complexity. For Gaussian distributions with sparse correlations, we prove reductions in both computational and sample complexity, and experiments show the approach also works well for non-Gaussian cases. In addition, we demonstrate how to extract transport maps from our relaxations, offering a simpler and interpretable alternative to neural networks in generative modeling. Our results suggest that convex relaxations can provide a promising path for dimension reduction in high-dimensional OT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13847v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuehaw Khoo, Tianyun Tang</dc:creator>
    </item>
    <item>
      <title>Computational study of irrational rotations via exact discontinuity tracking</title>
      <link>https://arxiv.org/abs/2511.13879</link>
      <description>arXiv:2511.13879v1 Announce Type: cross 
Abstract: The discrepancy sum $D_N(x,\rho)$ for irrational rotations has been of interest to mathematicians for over a century. While historically studied in an ``almost-everywhere'' or asymptotic sense, $D_N$ for finite N is increasingly an object of interest for its nontrivial properties that depend on the Diophantine properties of $\rho$. This behavior is periodic in N with respect to the quotients of the continued fraction convergents, which grow quickly for some irrationals. Thus the stable computation of the sum is necessary for forming conjectures about its properties. However, computing the exact value of the sum and its corresponding probability density function (pdf) is notoriously difficult due to numerical instability in the sum itself and the failure of sampling methods to capture its jump discontinuities. This paper presents a novel computational algorithm that fully defines the discrepancy function and its associated pdf through its discontinuities. This allows the calculation of $D_N(x,\rho)$ to machine precision with minimal storage in O(N) time. This vast improvement in computability over the O(N^2) naive version enables, for the first time, the direct computation of the exact pdf up to machine precision in O(N log N) time, and with it, key properties of the discrepancy: $ \|D_N \|_{\infty}$ (half of the support of the pdf), $ \|D_N \|_{2}^2$ (the variance of the pdf), and the kurtosis of the pdf. A key strength of the algorithm lies in its ability to produce clear, exact figures, allowing the development of mathematical intuition and the quick testing of conjectures. As an example, a newly conjectured pattern is presented: when $\rho$ is well-approximated by rational $\frac{p_n}{q_n}$, the pdf exhibits a predictable spiked-trapezoidal pattern when $N=kq_n$. These shapes degrade as $k$ increases, at a speed depending on how well $\frac{p_n}{q_n}$ approximates $\rho$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13879v1</guid>
      <category>math.NT</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannah Kravitz</dc:creator>
    </item>
    <item>
      <title>Hessians in Birkhoff-Theoretic Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2511.13963</link>
      <description>arXiv:2511.13963v1 Announce Type: cross 
Abstract: This paper derives various Hessians associated with Birkhoff-theoretic methods for trajectory optimization. According to a theorem proved in this paper, approximately 80% of the eigenvalues are contained in the narrow interval [-2, 4] for all Birkhoff-discretized optimal control problems. A preliminary analysis of computational complexity is also presented with further discussions on the grand challenge of solving a million point trajectory optimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13963v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>cs.RO</category>
      <category>math.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.2514/1.G008778</arxiv:DOI>
      <arxiv:journal_reference>Journal of Guidance Control and Dynamics, Vol. 48, No. 9, September 2025, 2105--2112</arxiv:journal_reference>
      <dc:creator>I. M. Ross</dc:creator>
    </item>
    <item>
      <title>Efficient reconstruction of multidimensional random field models with heterogeneous data using stochastic neural networks</title>
      <link>https://arxiv.org/abs/2511.13977</link>
      <description>arXiv:2511.13977v1 Announce Type: cross 
Abstract: In this paper, we analyze the scalability of a recent Wasserstein-distance approach for training stochastic neural networks (SNNs) to reconstruct multidimensional random field models. We prove a generalization error bound for reconstructing multidimensional random field models on training stochastic neural networks with a limited number of training data. Our results indicate that when noise is heterogeneous across dimensions, the convergence rate of the generalization error may not depend explicitly on the model's dimensionality, partially alleviating the "curse of dimensionality" for learning multidimensional random field models from a finite number of data points. Additionally, we improve the previous Wasserstein-distance SNN training approach and showcase the robustness of the SNN. Through numerical experiments on different multidimensional uncertainty quantification tasks, we show that our Wasserstein-distance approach can successfully train stochastic neural networks to learn multidimensional uncertainty models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13977v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mingtao Xia, Qijing Shen</dc:creator>
    </item>
    <item>
      <title>Geometric integrators for adiabatically closed simple thermodynamic systems</title>
      <link>https://arxiv.org/abs/2511.14154</link>
      <description>arXiv:2511.14154v1 Announce Type: cross 
Abstract: A variational formulation for non-equilibrium thermodynamics was developed by Gay-Balmaz and Yoshimura. In a recent article, the first two authors of the present paper introduced partially cosymplectic structures as a geometric framework for thermodynamic systems, recovering the evolution equations obtained variationally. In this paper, we develop a discrete variational principle for adiabatically closed simple thermodynamic systems, which can be utilised to construct numerical integrators for the dynamics of such systems. The effectiveness of our method is illustrated with several examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14154v1</guid>
      <category>math-ph</category>
      <category>cs.NA</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <category>physics.class-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaime Bajo, Manuel de Le\'on, Asier L\'opez-Gord\'on</dc:creator>
    </item>
    <item>
      <title>A Unified Phase-Field Fourier Neural Network Framework for Topology Optimization</title>
      <link>https://arxiv.org/abs/2511.14623</link>
      <description>arXiv:2511.14623v1 Announce Type: cross 
Abstract: This paper presents a unified and physics-driven framework of alternating phase-field Fourier neural networks (APF-FNNs) for topology optimization. At its core, an alternating architecture decouples the optimization by parameterizing the state, adjoint and topology fields with three distinct Fourier Neural Networks (FNNs). These networks are trained through a collaborative and stable alternating optimization scheme applicable to both self-adjoint and non-self-adjoint systems. The Ginzburg-Landau energy functional is incorporated into the topology network's loss function, acting as an intrinsic regularizer that promotes well-defined designs with smooth and distinct interfaces. By employing physics-informed losses derived from either variational principles or strong-form PDE residuals, the broad applicability of the APF-FNNs is demonstrated across a spectrum of 2D and 3D multi-physics benchmarks, including compliance minimization, eigenvalue maximization, and Stokes/Navier-Stokes flow optimization. The proposed APF-FNNs consistently yield high-performance and high-resolution topologies, establishing a powerful and versatile foundation for physics-driven computational design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14623v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Li, Xindi Hu, Helin Gong, Wei Gong, Shengfeng Zhu</dc:creator>
    </item>
    <item>
      <title>Low regularity error estimates for the time integration of 2D NLS</title>
      <link>https://arxiv.org/abs/2301.10639</link>
      <description>arXiv:2301.10639v2 Announce Type: replace 
Abstract: A filtered Lie splitting scheme is proposed for the time integration of the cubic nonlinear Schr\"odinger equation on the two-dimensional torus $\mathbb{T}^2$. The scheme is analyzed in a framework of discrete Bourgain spaces, which allows us to consider initial data with low regularity; more precisely initial data in $H^s(\mathbb{T}^2)$ with $s&gt;0$. In this way, the usual stability restriction to smooth Sobolev spaces with index $s&gt;1$ is overcome. Rates of convergence of order $\tau^{s/2}$ in $L^2(\mathbb{T}^2)$ at this regularity level are proved. Numerical examples illustrate that these convergence results are sharp.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.10639v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1093/imanum/drae054</arxiv:DOI>
      <arxiv:journal_reference>IMA J. Numer. Anal., 45(4): 2023--2059 (2025)</arxiv:journal_reference>
      <dc:creator>Lun Ji, Alexander Ostermann, Fr\'ed\'eric Rousset, Katharina Schratz</dc:creator>
    </item>
    <item>
      <title>Nonlinear reduced basis using mixture Wasserstein barycenters: application to an eigenvalue problem inspired from quantum chemistry</title>
      <link>https://arxiv.org/abs/2307.15423</link>
      <description>arXiv:2307.15423v2 Announce Type: replace 
Abstract: The aim of this article is to propose a new reduced-order modelling approach for parametric eigenvalue problems arising in electronic structure calculations. Namely, we develop nonlinear reduced basis techniques for the approximation of parametric eigenvalue problems inspired from quantum chemistry applications. More precisely, we consider here a one-dimensional model which is a toy model for the computation of the electronic ground state wavefunction of a system of electrons within a molecule, solution to the many-body electronic Schr\"odinger equation, where the varying parameters are the positions of the nuclei in the molecule. We estimate the decay rate of the Kolmogorov n-width of the set of solutions for this parametric problem in several settings, including the standard L2-norm as well as with distances based on optimal transport. The fact that the latter decays much faster than in the traditional L2-norm setting motivates us to propose a practical nonlinear reduced basis method, which is based on an offline greedy algorithm, and an efficient stochastic energy minimization in the online phase. We finally provide numerical results illustrating the capabilities of the method and good approximation properties, both in the offline and the online phase.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15423v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maxime Dalery, Genevieve Dusson, Virginie Ehrlacher, Alexei Lozinski</dc:creator>
    </item>
    <item>
      <title>Numerical entropy production in finite volume $P_0P_M$ ADER schemes</title>
      <link>https://arxiv.org/abs/2501.05872</link>
      <description>arXiv:2501.05872v3 Announce Type: replace 
Abstract: We consider the numerical integration of conservation laws endowed with an entropy inequality and we study the residual of the scheme on this inequality, which represents the numerical entropy production. This idea has been introduced and exploited in Runge-Kutta finite volume methods, where the numerical entropy production has been used as an indicator in adaptive schemes, since it scales as the local truncation error of the method for smooth solutions and it highlights the presence of discontinuities and their kind.
  The aim of this work is to extend this idea to finite volume $P_0P_M$ ADER timestepping techniques. We show that the numerical entropy production can be defined also in this context and it provides a scalar quantity computable for each space-time volume which, under grid refinement, decays to zero with the same rate of convergence of the scheme for smooth solutions. Its size gradually increases when the local solution regularity lowers, remaining bounded up to contact discontinuities and divergent on shock waves. Theoretical results are proven in a multi-dimensional setting on arbitrary polygonal grids. We also present numerical evidence showing that it is essentially negative definite. Moreover, we propose an example of $p$-adaptive scheme that uses the numerical entropy production as a-posteriori smoothness indicator. The scheme locally modifies its order of convergence with the purpose of removing the oscillations due to the high-order of accuracy of the scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05872v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Semplice, Alessandra Zappa</dc:creator>
    </item>
    <item>
      <title>Fast and stable computation of highly oscillatory and/or exponentially decaying integrals using a Clenshaw-Curtis product-integration rule</title>
      <link>https://arxiv.org/abs/2503.08169</link>
      <description>arXiv:2503.08169v2 Announce Type: replace 
Abstract: We propose, analyze, and implement a quadrature method for evaluating integrals of the form $\int_0^2 f(s)\exp(zs)\, {\rm d}s$, where $z$ is a complex number with a possibly large negative real part. The integrand may exhibit exponential decay, highly oscillatory behavior, or both simultaneously, making standard quadrature rules computationally expensive. Our approach is based on a Clenshaw-Curtis product-integration rule: the smooth part of the integrand is interpolated using a polynomial at Chebyshev nodes, and the resulting integral is computed exactly. We analyze the convergence of the method with respect to both the number of nodes and the parameter $z$. Additionally, we provide a stable and efficient implementation whose computational cost is essentially independent of $z$ and scales linearly with $L$. Notably, our approach avoids the use of special functions, enhancing its numerical robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08169v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Dominguez</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of Adaptive Finite Element Algorithms for a Regularized Variational Model of Quasi-Static Brittle Fracture in "Strain-Limiting" Elastic Solids</title>
      <link>https://arxiv.org/abs/2505.19801</link>
      <description>arXiv:2505.19801v2 Announce Type: replace 
Abstract: The rigorous convergence analysis of adaptive finite element methods for regularized variational models of quasi-static brittle fracture in strain-limiting elastic solids is presented. This work introduces two novel adaptive mesh refinement algorithms, based on robust local error indicators, designed to solve the underlying energy minimization problem efficiently. A comprehensive convergence analysis is provided for minimizer sequences generated by these distinct adaptive strategies. It is rigorously demonstrated that sequences from the first algorithm converge to a prescribed tolerance. Notably, the second algorithm is proven to yield inherently convergent sequences without requiring an explicit stopping criterion. The practical efficacy of the proposed adaptive framework is validated through extensive numerical simulations, where critical comparisons of energy components (bulk, surface, and total) demonstrate the performance of the two adaptive algorithms in the case of an edge crack in a strain-limiting solid subjected to anti-plane shear-type loading.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19801v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ram Manohar, S. M. Mallikarjunaiah</dc:creator>
    </item>
    <item>
      <title>A Note on the Convergence of Symmetric Triangle Quadrature Rules</title>
      <link>https://arxiv.org/abs/2508.15133</link>
      <description>arXiv:2508.15133v2 Announce Type: replace 
Abstract: Symmetric polynomial quadrature rules for triangles are commonly used to efficiently integrate two-dimensional domains in finite-element-type problems. While the development of such rules focuses on the maximum degree a given number of points can exactly integrate, smooth integrands are generally not polynomials of finite degree. Therefore, for such integrands, one needs to balance integration accuracy and computational cost. A natural approach to this balance is to choose the number of points such that the convergence rate with respect to the mesh size $h$ matches that of the other properties of the scheme, such as the planar or curved triangles that approximate the geometry or the basis functions that approximate the solution.
  In general, it is expected that a quadrature rule capable of integrating polynomials up to degree $d$ yields an integration error that is $\mathcal{O}(h^p)$, where $p=d+1$. However, as we describe in this paper, for symmetric triangle quadrature rules, when $d$ is even, $p=d+2$; therefore, for a $p^\text{th}$-order-accurate quadrature rule, fewer quadrature points are necessary, reducing the time required for matrix assembly in finite-element-type problems. This reduction in cost is modest for local differential operators that yield sparse matrices but appreciable for global integral operators that yield dense matrices.
  In this paper, we briefly summarize the details of symmetric triangle quadrature rules, discuss error implications for quadrature rules for one dimension and triangles, and we provide numerical examples that support our observation that polynomials that exactly integrate even maximum degrees converge faster than the conventional expectation for sequences of regular meshes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15133v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian A. Freno, Neil R. Matula, Joseph E. Bishop</dc:creator>
    </item>
    <item>
      <title>Solving advection equations with reduction multigrids on GPUs</title>
      <link>https://arxiv.org/abs/2508.17517</link>
      <description>arXiv:2508.17517v3 Announce Type: replace 
Abstract: Methods for solving hyperbolic systems typically depend on unknown ordering (e.g., Gauss-Seidel, or sweep/wavefront/marching methods) to achieve good convergence. For many discretisations, mesh types or decompositions these methods do not scale well in parallel. In this work we demonstrate that the combination of AIRG (a reduction multigrid which uses GMRES polynomials) and PMISR DDC (a CF splitting algorithm which gives diagonally dominant submatrices) can be used to solve linear advection equations in parallel on GPUs with good weak scaling. We find that GMRES polynomials are well suited to GPUs when applied matrix-free, either as smoothers (at low order) or as an approximate coarse grid solver (at high order). To improve the parallel performance we automatically truncate the multigrid hierarchy given the quality of the polynomials as coarse grid solvers. Solving time-independent advection equations in 2D on structured grids, we find 66-101% weak scaling efficiency in the solve and 47-63% in the setup with AIRG, across the majority of Lumi-G, a pre-exascale GPU machine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.17517v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. Dargaville, R. P. Smedley-Stevenson, P. N. Smith, C. C. Pain</dc:creator>
    </item>
    <item>
      <title>Forward and backward error bounds for a mixed precision preconditioned conjugate gradient algorithm</title>
      <link>https://arxiv.org/abs/2510.11379</link>
      <description>arXiv:2510.11379v2 Announce Type: replace 
Abstract: The preconditioned conjugate gradient (PCG) algorithm is one of the most popular algorithms for solving large-scale linear systems Ax = b, where A is a symmetric positive definite matrix. Rather than computing residuals directly, it updates the residual vectors recursively. Current analyses of the conjugate gradient (CG) algorithm in finite precision typically assume that the norm of the recursively updated residual goes orders of magnitude below the machine precision, focusing mainly on bounding the residual gap thereafter. This work introduces a framework for the PCG algorithm and provides rigorous proofs that the relative backward and forward errors of the computed results of PCG can reach the levels O(u) and O(u)\kappa(A)^{1/2}, respectively, after a sufficient number of iterations without relying on an assumption concerning the norm of the recursively updated residual, where u represents the unit roundoff and \kappa(A) is the condition number of A. Our PCG framework further shows that applying preconditioners in low precision does not compromise the accuracy of the final results, provided that reasonable conditions are satisfied. Our theoretical results are illustrated through a set of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11379v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Bake, Erin Carson, Yuxin Ma</dc:creator>
    </item>
    <item>
      <title>Finite Elements with weighted bases for the fractional Laplacian</title>
      <link>https://arxiv.org/abs/2511.01727</link>
      <description>arXiv:2511.01727v2 Announce Type: replace 
Abstract: This work presents a numerical study of the Dirichlet problem for the fractional Laplacian $(-\Delta)^s$ with $s\in(0,1)$ using Finite Element methods with non-standard bases. Classical approaches based on piece-wise linear basis yield $h^{\frac 1 2}$ convergence rates in the Sobolev-Slobodeckij norm $H^s$ due to the limited boundary regularity of the solution $u(x)$, which behaves like $\operatorname{dist}(x,\mathbb{R}^d\setminus \Omega)^s$, where $h$ is the diameter of the mesh elements. To overcome this limitation, we propose a novel Finite Element basis of the form $\delta^s \times ($piece-wise linear functions$)$, where $\delta$ is any suitably smooth approximation of $\operatorname{dist}(x,\mathbb{R}^d\setminus \Omega)$. This exploits the improved regularity of $u/\delta^s$, achieving higher convergence rates. Under standard smoothness assumptions the method attains an order $h^{2-s}$ on quasi-uniform meshes, improving the rates with the piece-wise linear basis. We provide a rigorous theoretical error analysis with explicit rates and validate it through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01727v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>F\'elix del Teso, Stefano Fronzoni, David G\'omez-Castro</dc:creator>
    </item>
    <item>
      <title>Analyzing Smoothness and Dynamics in an SEIR$^{\text{T}}$R$^{\text{P}}$D Endemic Model with Distributed Delays</title>
      <link>https://arxiv.org/abs/2511.11246</link>
      <description>arXiv:2511.11246v2 Announce Type: replace 
Abstract: This article explores the properties of an SEIR$^{\text{T}}$R$^{\text{P}}$D endemic model expressed through delay-differential equations with distributed delays for latency and temporary immunity. Our research delves into the variability of latent periods and immunity durations across diseases, in particular, we introduce a class of delays defined by continuous integral kernels with compact support. The main result of the paper is a kind of smoothening property which the solution function posesses under mild conditions of the system parameter functions. Also, boundedness and non-negativity is proved. Numerical simulations indicates that the continuous model can be approximated with a discrete lag endemic models. The study contributes to understanding infectious disease dynamics and provides insights into the numerical approximation of exact solution for different delay scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11246v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tin Nwe Aye, Linus Carlsson</dc:creator>
    </item>
    <item>
      <title>Time-causal and time-recursive wavelets</title>
      <link>https://arxiv.org/abs/2510.05834</link>
      <description>arXiv:2510.05834v5 Announce Type: replace-cross 
Abstract: When to apply wavelet analysis to real-time temporal signals, where the future cannot be accessed, it is essential to base all the steps in the signal processing pipeline on computational mechanisms that are truly time-causal.
  This paper describes how a time-causal wavelet analysis can be performed based on concepts developed in the area of temporal scale-space theory, originating from a complete classification of temporal smoothing kernels that guarantee non-creation of new structures from finer to coarser temporal scale levels. By necessity, convolution with truncated exponential kernels in cascade constitutes the only permissable class of kernels, as well as their temporal derivatives as a natural complement to fulfil the admissibility conditions of wavelet representations. For a particular way of choosing the time constants in the resulting infinite convolution of truncated exponential kernels, to ensure temporal scale covariance and thus self-similarity over temporal scales, we describe how mother wavelets can be chosen as temporal derivatives of the resulting time-causal limit kernel.
  By developing connections between wavelet theory and scale-space theory, we characterize and quantify how the continuous scaling properties transfer to the discrete implementation, demonstrating how the proposed time-causal wavelet representation can reflect the duration of locally dominant temporal structures in the input signals.
  We propose that this notion of time-causal wavelet analysis could be a valuable tool for signal processing tasks, where streams of signals are to be processed in real time, specifically for signals that may contain local variations over a rich span of temporal scales, or more generally for analysing physical or biophysical temporal phenomena, where a fully time-causal analysis is called for to be physically realistic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05834v5</guid>
      <category>eess.SP</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.IV</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Lindeberg</dc:creator>
    </item>
  </channel>
</rss>
