<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Feb 2026 05:01:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Estimating the distance at which narwhal $(\textit{Monodon monoceros})$ respond to disturbance: a penalized threshold hidden Markov model</title>
      <link>https://arxiv.org/abs/2602.09267</link>
      <description>arXiv:2602.09267v1 Announce Type: new 
Abstract: Understanding behavioural responses to disturbances is vital for wildlife conservation. For example, in the Arctic, the decrease in sea ice has opened new shipping routes, increasing the need for impact assessments that quantify the distance at which marine mammals react to vessel presence. This information can then guide targeted mitigation policies, such as vessel slow-down regulations and delineation of avoidance areas. Using telemetry data to determine distances linked to deviations from normal behaviour requires advanced statistical models, such as threshold hidden Markov models (THMMs). While these are powerful tools, they do not assess whether the estimated threshold reflects a meaningful behavioural shift. We introduce a lasso-penalized THMM that builds on computationally efficient methods to impose penalties on HMMs and present a new, efficient penalized quasi-restricted maximum-likelihood estimator. Our framework is capable of estimating thresholds and assessing whether the disturbance effects are meaningful. With simulations, we demonstrate that our lasso method effectively shrinks spurious threshold effects towards zero. When applied to narwhal $\textit{(Monodon monoceros)}$ movement data, our analysis suggests that narwhal react to vessels up to 4 kilometres away by decreasing movement persistence and spending more time in deeper waters (average maximum depth of 356m). Overall, we provide a broadly applicable framework for quantifying behavioural responses to stimuli, with applications ranging from determining reaction thresholds to disturbance to estimating the distances at which terrestrial species, such as elephants, detect water.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09267v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fanny Dupont, Marianne Marcoux, Nigel E. Hussey, Jackie Dawson, Marie Auger-M\'eth\'e</dc:creator>
    </item>
    <item>
      <title>Bayesian network approach to building an affective module for a driver behavioural model</title>
      <link>https://arxiv.org/abs/2602.09632</link>
      <description>arXiv:2602.09632v1 Announce Type: new 
Abstract: This paper focuses on the affective component of a driver behavioural model (DBM). This component specifically models some drivers' mental states such as mental load and active fatigue, which may affect driving performance. We have used Bayesian networks (BNs) to explore the dependencies between various relevant random variables and assess the probability that a driver is in a particular mental state based on their physiological and demographic conditions. Through this approach, our goal is to improve our understanding of driver behaviour in dynamic environments, with potential applications in traffic safety and autonomous vehicle technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09632v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dorota M{\l}ynarczyk, Gabriel Calvo, Francisco Palmi-Perales, Carmen Armero, Virgilio G\'omez-Rubio, Ana de la Torre-Garc\'ia, Ricardo Bayona Salvador</dc:creator>
    </item>
    <item>
      <title>RAPID: Risk of Attribute Prediction-Induced Disclosure in Synthetic Microdata</title>
      <link>https://arxiv.org/abs/2602.09235</link>
      <description>arXiv:2602.09235v1 Announce Type: cross 
Abstract: Statistical data anonymization increasingly relies on fully synthetic microdata, for which classical identity disclosure measures are less informative than an adversary's ability to infer sensitive attributes from released data. We introduce RAPID (Risk of Attribute Prediction--Induced Disclosure), a disclosure risk measure that directly quantifies inferential vulnerability under a realistic attack model. An adversary trains a predictive model solely on the released synthetic data and applies it to real individuals' quasi-identifiers. For continuous sensitive attributes, RAPID reports the proportion of records whose predicted values fall within a specified relative error tolerance. For categorical attributes, we propose a baseline-normalized confidence score that measures how much more confident the attacker is about the true class than would be expected from class prevalence alone, and we summarize risk as the fraction of records exceeding a policy-defined threshold. This construction yields an interpretable, bounded risk metric that is robust to class imbalance, independent of any specific synthesizer, and applicable with arbitrary learning algorithms. We illustrate threshold calibration, uncertainty quantification, and comparative evaluation of synthetic data generators using simulations and real data. Our results show that RAPID provides a practical, attacker-realistic upper bound on attribute-inference disclosure risk that complements existing utility diagnostics and disclosure control frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09235v1</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Templ, Oscar Thees, Roman M\"uller</dc:creator>
    </item>
    <item>
      <title>Analyzing the retraining frequency of global forecasting models: towards more stable forecasting systems</title>
      <link>https://arxiv.org/abs/2506.05776</link>
      <description>arXiv:2506.05776v3 Announce Type: replace 
Abstract: Forecast stability, that is, the consistency of predictions over time, is essential in business settings where sudden shifts in forecasts can disrupt planning and erode trust in predictive systems. Despite its importance, stability is often overlooked in favor of accuracy. In this study, we evaluate the stability of point and probabilistic forecasts across several retraining scenarios using three large forecastingdatasets and ten different global forecasting models. To analyze stability in the probabilistic setting, we propose a new model-agnostic, distribution-free, and scale-free metric that measuresprobabilistic stability: the Scaled Multi-Quantile Change (SMQC). The results show that less frequent retraining not only preserves but often improves forecast stability, challenging the need for frequent retraining. Moreover, the study shows that accuracy and stability are not necessarily conflicting objectives when adopting a global modeling approach. The study promotes a shift toward stability-aware forecasting practices, proposing a new metric to evaluate forecast stability effectively in probabilistic settings, and offering practical guidelines for building more stable and sustainable forecasting systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05776v3</guid>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Zanotti</dc:creator>
    </item>
    <item>
      <title>Monotonic Path-Specific Effects: Application to Estimating Educational Returns</title>
      <link>https://arxiv.org/abs/2508.13366</link>
      <description>arXiv:2508.13366v2 Announce Type: replace 
Abstract: Conventional research on educational effects typically either employs a "years of schooling" measure of education, or dichotomizes attainment as a point-in-time treatment. Yet, such a conceptualization of education is misaligned with the sequential process by which individuals make educational transitions. In this paper, I propose a causal mediation framework for the study of educational effects on outcomes such as earnings. The framework considers the effect of a given educational transition as operating indirectly, via progression through subsequent transitions, as well as directly, net of these transitions. I demonstrate that the average treatment effect (ATE) of education can be additively decomposed into mutually exclusive components that capture these direct and indirect effects. The decomposition has several special properties which distinguish it from conventional mediation decompositions of the ATE, properties which facilitate less restrictive identification assumptions as well as identification of all causal paths in the decomposition. An analysis of the returns to high school completion in the NLSY97 cohort suggests that the payoff to a high school degree stems overwhelmingly from its direct labor market returns. Mediation via college attendance, completion and graduate school attendance is small because of individuals' low counterfactual progression rates through these subsequent transitions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13366v2</guid>
      <category>stat.AP</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.ME</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aleksei Opacic</dc:creator>
    </item>
    <item>
      <title>Measuring football fever through wearable technology: A case study on the German cup final</title>
      <link>https://arxiv.org/abs/2509.09569</link>
      <description>arXiv:2509.09569v2 Announce Type: replace 
Abstract: Football is the world's most popular sport, evoking strong physiological and emotional responses among its fans. Yet, the specific dynamics of fan attachment to matches have received little attention in the literature. In this paper, we quantify these dynamics through a unique case study from professional football: the 2025 cup final of the German Football Association (DFB) between first-division club VfB Stuttgart and third-division club Arminia Bielefeld. We collected high-resolution smartwatch data, including heart rate and stress level, from 229 Arminia Bielefeld fans over approximately 12 weeks, complemented by survey responses on club attachment, match attendance, and personal characteristics from a subset of 37 participants. By combining physiological data with survey information, we analyse variations in emotional engagement across individuals and contexts, as well as physiological reactions to key match events. This approach provides rare, data-driven insights into the football fever that captivates fans during high-stakes competitions. Furthermore, we compare the vital parameters recorded on the day of the match with baseline levels on non-matchdays throughout the entire observation period. Our findings reveal pronounced physiological responses among fans, beginning hours before the match and peaking at kick-off.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09569v2</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timo Adam, Jonas Bauer, Christian Deutscher, Christiane Fuchs, Tamara Schamberger, David Winkelmann</dc:creator>
    </item>
    <item>
      <title>Predicting Onsets and Dry Spells of the West African Monsoon Season Using Machine Learning Methods</title>
      <link>https://arxiv.org/abs/2512.01965</link>
      <description>arXiv:2512.01965v2 Announce Type: replace 
Abstract: The beginning of the rainy season and the occurrence of dry spells in West Africa is notoriously difficult to predict, however these are the key indicators farmers use to decide when to plant crops, having a major influence on their overall yield. While many studies have shown correlations between global sea surface temperatures and characteristics of the West African monsoon season, there are few that effectively implement this information into machine learning (ML) prediction models. In this study we investigated the best ways to define our target variables, onset and dry spell, and produced methods to predict them for upcoming seasons using sea surface temperature teleconnections. Defining our target variables required the use of a combination of two well known definitions of onset. We then applied custom statistical techniques -- like total variation regularization and predictor selection -- to the two models we constructed, the first being a linear model and the other an adaptive-threshold logistic regression model. We found mixed results for onset prediction, with spatial verification showing signs of significant skill, while temporal verification showed little to none. For dry spell though, we found significant accuracy through the analysis of multiple binary classification metrics. These models overcome some limitations that current approaches have, such as being computationally intensive and needing bias correction. We also introduce this study as a framework to use ML methods for targeted prediction of certain weather phenomenon using climatologically relevant variables. As we apply ML techniques to more problems, we see clear benefits for fields like meteorology and lay out a few new directions for further research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.01965v2</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Colin Bobocea, Yves Atchad\'e</dc:creator>
    </item>
    <item>
      <title>Feasible Dose-Response Curves for Continuous Treatments Under Positivity Violations</title>
      <link>https://arxiv.org/abs/2502.14566</link>
      <description>arXiv:2502.14566v3 Announce Type: replace-cross 
Abstract: Positivity violations can complicate estimation and interpretation of causal dose-response curves (CDRCs) for continuous interventions. Weighting-based methods are designed to handle limited overlap, but the resulting weighted targets can be hard to interpret scientifically. Modified treatment policies can be less sensitive to support limitations, yet they typically target policy-defined effects that may not align with the original dose-response question. We develop an approach that addresses limited overlap while remaining close to the scientific target of the CDRC. Our work is motivated by the CHAPAS-3 trial of HIV-positive children in Zambia and Uganda, where clinically relevant efavirenz concentration levels are not uniformly supported across covariate strata. We introduce a diagnostic, the non-overlap ratio, which quantifies, as a function of the target intervention level, the proportion of the population for whom that level is not supported given observed covariates. We also define an individualized most feasible intervention: for each child and target concentration, we retain the target when it is supported, and otherwise map it to the nearest supported concentration. The resulting feasible dose-response curve answers: if we try to set everyone to a given concentration, but it is not realistically attainable for some individuals, what outcome would be expected after shifting those individuals to their nearest attainable concentration? We propose a plug-in g-computation estimator that combines outcome regression with flexible conditional density estimation to learn supported regions and evaluate the feasible estimand. Simulations show reduced bias under positivity violations and recovery of the standard CDRC when support is adequate. An application to CHAPAS-3 yields a stable and interpretable concentration-response summary under realistic support constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14566v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Han Bao, Michael Schomaker</dc:creator>
    </item>
    <item>
      <title>Scalable Dynamic Origin-Destination Demand Estimation Enhanced by High-Resolution Satellite Imagery Data</title>
      <link>https://arxiv.org/abs/2506.22499</link>
      <description>arXiv:2506.22499v2 Announce Type: replace-cross 
Abstract: This study presents a novel integrated framework for dynamic origin-destination demand estimation (DODE) in multi-class mesoscopic network models, incorporating high-resolution satellite imagery together with conventional traffic data from local sensors. Unlike sparse local detectors, satellite imagery offers consistent, city-wide road and traffic information of both parking and moving vehicles, overcoming data availability limitations. To extract information from imagery data, we design a computer vision pipeline for class-specific vehicle detection and map matching, generating link-level traffic density observations by vehicle class. Building upon this information, we formulate a computational graph-based DODE framework that calibrates dynamic network states by jointly matching observed traffic counts/speeds from local sensors with density measurements derived from satellite imagery. To assess the accuracy and robustness of the proposed framework, we conduct a series of numerical experiments using both synthetic and real-world data. The results demonstrate that supplementing traditional data with satellite-derived density significantly improves estimation performance, especially for links without local sensors. Real-world experiments also show the framework's potential for practical deployment on large-scale networks. Sensitivity analysis further evaluates the impact of data quality related to satellite imagery data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22499v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiachao Liu, Pablo Guarda, Koichiro Niinuma, Sean Qian</dc:creator>
    </item>
    <item>
      <title>Robust estimation of polyserial correlation coefficients: A density power divergence approach</title>
      <link>https://arxiv.org/abs/2510.15632</link>
      <description>arXiv:2510.15632v2 Announce Type: replace-cross 
Abstract: The association between a continuous and an ordinal variable is commonly modeled through the polyserial correlation model. However, this model, which is based on a partially-latent normality assumption, may be misspecified in practice, due to, for example (but not limited to), outliers or careless responses. The typically used maximum likelihood (ML) estimator is highly susceptible to such misspecification: One single observation not generated by partially-latent normality can suffice to produce arbitrarily poor estimates. As a remedy, we propose a novel estimator of the polyserial correlation model designed to be robust against the adverse effects of observations discrepant to that model. The estimator leverages density power divergence estimation to achieve robustness by implicitly downweighting such observations; the ensuing weights constitute a useful tool for pinpointing potential sources of model misspecification. The proposed estimator generalizes ML and is consistent as well as asymptotically Gaussian. As price for robustness, some efficiency must be sacrificed, but substantial robustness can be gained while maintaining more than 98% of ML efficiency. We demonstrate our estimator's robustness and practical usefulness in simulation experiments and an empirical application in personality psychology where our estimator helps identify outliers. Finally, the proposed methodology is implemented in free open-source software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15632v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1017/psy.2026.10091</arxiv:DOI>
      <arxiv:journal_reference>Forthcoming in Psychometrika (2026+)</arxiv:journal_reference>
      <dc:creator>Max Welz</dc:creator>
    </item>
    <item>
      <title>The Impact of LLMs on Online News Consumption and Production</title>
      <link>https://arxiv.org/abs/2512.24968</link>
      <description>arXiv:2512.24968v3 Announce Type: replace-cross 
Abstract: Large language models (LLMs) change how consumers acquire information online; their bots also crawl news publishers' websites for training data and to answer consumer queries; and they provide tools that can lower the cost of content creation. These changes lead to predictions of adverse impact on news publishers in the form of lowered consumer demand, reduced demand for newsroom employees, and an increase in news "slop." Consequently, some publishers strategically responded by blocking LLM access to their websites using the robots.txt file standard.
  Using high-frequency granular data, we document four effects related to the predicted shifts in news publishing following the introduction of generative AI (GenAI). First, we find a moderate decline in traffic to news publishers occurring after August 2024. Second, using a difference-in-differences approach, we find that blocking GenAI bots can be associated with a reduction of total website traffic to large publishers compared to not blocking. Third, on the hiring side, we do not find evidence that LLMs are replacing editorial or content-production jobs yet. The share of new editorial and content-production job listings increases over time. Fourth, regarding content production, we find no evidence that large publishers increased text volume; instead, they significantly increased rich content and use more advertising and targeting technologies.
  Together, these findings provide early evidence of some unforeseen impacts of the introduction of LLMs on news production and consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.24968v3</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hangcheng Zhao, Ron Berman</dc:creator>
    </item>
  </channel>
</rss>
