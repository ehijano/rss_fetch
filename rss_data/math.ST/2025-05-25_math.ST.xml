<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 26 May 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On Fisher Consistency of Surrogate Losses for Optimal Dynamic Treatment Regimes with Multiple Categorical Treatments per Stage</title>
      <link>https://arxiv.org/abs/2505.17285</link>
      <description>arXiv:2505.17285v1 Announce Type: new 
Abstract: Patients with chronic diseases often receive treatments at multiple time points, or stages. Our goal is to learn the optimal dynamic treatment regime (DTR) from longitudinal patient data. When both the number of stages and the number of treatment levels per stage are arbitrary, estimating the optimal DTR reduces to a sequential, weighted, multiclass classification problem (Kosorok and Laber, 2019). In this paper, we aim to solve this classification problem simultaneously across all stages using Fisher consistent surrogate losses. Although computationally feasible Fisher consistent surrogates exist in special cases, e.g., the binary treatment setting, a unified theory of Fisher consistency remains largely unexplored. We establish necessary and sufficient conditions for DTR Fisher consistency within the class of non-negative, stagewise separable surrogate losses. To our knowledge, this is the first result in the DTR literature to provide necessary conditions for Fisher consistency within a non-trivial surrogate class. Furthermore, we show that many convex surrogate losses fail to be Fisher consistent for the DTR classification problem, and we formally establish this inconsistency for smooth, permutation equivariant, and relative-margin-based convex losses. Building on this, we propose SDSS (Simultaneous Direct Search with Surrogates), which uses smooth, non-concave surrogate losses to learn the optimal DTR. We develop a computationally efficient, gradient-based algorithm for SDSS. When the optimization error is small, we establish a sharp upper bound on SDSS's regret decay rate. We evaluate the numerical performance of SDSS through simulations and demonstrate its real-world applicability by estimating optimal fluid resuscitation strategies for severe septic patients using electronic health record data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17285v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nilanjana Laha, Nilson Chapagain, Victoria Cicherski, Aaron Sonabend-W</dc:creator>
    </item>
    <item>
      <title>Minimax Rate-Optimal Algorithms for High-Dimensional Stochastic Linear Bandits</title>
      <link>https://arxiv.org/abs/2505.17400</link>
      <description>arXiv:2505.17400v1 Announce Type: new 
Abstract: We study the stochastic linear bandit problem with multiple arms over $T$ rounds, where the covariate dimension $d$ may exceed $T$, but each arm-specific parameter vector is $s$-sparse. We begin by analyzing the sequential estimation problem in the single-arm setting, focusing on cumulative mean-squared error. We show that Lasso estimators are provably suboptimal in the sequential setting, exhibiting suboptimal dependence on $d$ and $T$, whereas thresholded Lasso estimators -- obtained by applying least squares to the support selected by thresholding an initial Lasso estimator -- achieve the minimax rate. Building on these insights, we consider the full linear contextual bandit problem and propose a three-stage arm selection algorithm that uses thresholded Lasso as the main estimation method. We derive an upper bound on the cumulative regret of order $s(\log s)(\log d + \log T)$, and establish a matching lower bound up to a $\log s$ factor, thereby characterizing the minimax regret rate up to a logarithmic term in $s$. Moreover, when a short initial period is excluded from the regret, the proposed algorithm achieves exact minimax optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17400v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingyu Liu, Yanglei Song</dc:creator>
    </item>
    <item>
      <title>Optimal Decision Rules for Composite Binary Hypothesis Testing under Neyman-Pearson Framework</title>
      <link>https://arxiv.org/abs/2505.17851</link>
      <description>arXiv:2505.17851v1 Announce Type: new 
Abstract: The composite binary hypothesis testing problem within the Neyman-Pearson framework is considered. The goal is to maximize the expectation of a nonlinear function of the detection probability, integrated with respect to a given probability measure, subject to a false-alarm constraint. It is shown that each power function can be realized by a generalized Bayes rule that maximizes an integrated rejection probability with respect to a finite signed measure. For a simple null hypothesis and a composite alternative, optimal single-threshold decision rules based on an appropriately weighted likelihood ratio are derived. The analysis is extended to composite null hypotheses, including both average and worst-case false-alarm constraints, resulting in modified optimal threshold rules. Special cases involving exponential family distributions and numerical examples are provided to illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17851v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanglei Song, Berkan Dulek, Sinan Gezici</dc:creator>
    </item>
    <item>
      <title>A new measure of dependence: Integrated $R^2$</title>
      <link>https://arxiv.org/abs/2505.18146</link>
      <description>arXiv:2505.18146v1 Announce Type: new 
Abstract: We propose a new measure of dependence that quantifies the degree to which a random variable $Y$ depends on a random vector $X$. This measure is zero if and only if $Y$ and $X$ are independent, and equals one if and only if $Y$ is a measurable function of $X$. We introduce a simple and interpretable estimator that is comparable in ease of computation to classical correlation coefficients such as Pearson's, Spearman's, or Chatterjee's. Building on this coefficient, we develop a model-free variable selection algorithm, feature ordering by dependence (FORD), inspired by FOCI. FORD requires no tuning parameters and is provably consistent under suitable sparsity assumptions. We demonstrate its effectiveness and improvements over FOCI through experiments on both synthetic and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18146v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mona Azadkia, Pouya Roudaki</dc:creator>
    </item>
    <item>
      <title>Liouville PDE-based sliced-Wasserstein flow for fair regression</title>
      <link>https://arxiv.org/abs/2505.17204</link>
      <description>arXiv:2505.17204v1 Announce Type: cross 
Abstract: The sliced Wasserstein flow (SWF), a nonparametric and implicit generative gradient flow, is applied to fair regression. We have improved the SWF in a few aspects. First, the stochastic diffusive term from the Fokker-Planck equation-based Monte Carlo is transformed to Liouville partial differential equation (PDE)-based transport with density estimation, however, without the diffusive term. Now, the computation of the Wasserstein barycenter is approximated by the SWF barycenter with the prescription of Kantorovich potentials for the induced gradient flow to generate its samples. These two efforts improve the convergence in training and testing SWF and SWF barycenters with reduced variance. Applying the generative SWF barycenter for fair regression demonstrates competent profiles in the accuracy-fairness Pareto curves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17204v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pilhwa Lee, Jayshawn Cooper</dc:creator>
    </item>
    <item>
      <title>Optimal Transport with Heterogeneously Missing Data</title>
      <link>https://arxiv.org/abs/2505.17291</link>
      <description>arXiv:2505.17291v1 Announce Type: cross 
Abstract: We consider the problem of solving the optimal transport problem between two empirical distributions with missing values. Our main assumption is that the data is missing completely at random (MCAR), but we allow for heterogeneous missingness probabilities across features and across the two distributions. As a first contribution, we show that the Wasserstein distance between empirical Gaussian distributions and linear Monge maps between arbitrary distributions can be debiased without significantly affecting the sample complexity. Secondly, we show that entropic regularized optimal transport can be estimated efficiently and consistently using iterative singular value thresholding (ISVT). We propose a validation set-free hyperparameter selection strategy for ISVT that leverages our estimator of the Bures-Wasserstein distance, which could be of independent interest in general matrix completion problems. Finally, we validate our findings on a wide range of numerical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17291v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linus Bleistein, Aur\'elien Bellet, Julie Josse</dc:creator>
    </item>
    <item>
      <title>Wasserstein Transfer Learning</title>
      <link>https://arxiv.org/abs/2505.17404</link>
      <description>arXiv:2505.17404v1 Announce Type: cross 
Abstract: Transfer learning is a powerful paradigm for leveraging knowledge from source domains to enhance learning in a target domain. However, traditional transfer learning approaches often focus on scalar or multivariate data within Euclidean spaces, limiting their applicability to complex data structures such as probability distributions. To address this, we introduce a novel framework for transfer learning in regression models, where outputs are probability distributions residing in the Wasserstein space. When the informative subset of transferable source domains is known, we propose an estimator with provable asymptotic convergence rates, quantifying the impact of domain similarity on transfer efficiency. For cases where the informative subset is unknown, we develop a data-driven transfer learning procedure designed to mitigate negative transfer. The proposed methods are supported by rigorous theoretical analysis and are validated through extensive simulations and real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17404v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaicheng Zhang, Sinian Zhang, Doudou Zhou, Yidong Zhou</dc:creator>
    </item>
    <item>
      <title>Efficient compression of neural networks and datasets</title>
      <link>https://arxiv.org/abs/2505.17469</link>
      <description>arXiv:2505.17469v1 Announce Type: cross 
Abstract: We compare, improve, and contribute methods that substantially decrease the number of parameters of neural networks while maintaining high test accuracy. When applying our methods to minimize description length, we obtain very effective data compression algorithms. In particular, we develop a probabilistic reformulation of $\ell_0$ regularized optimization for nonlinear models that does not require Monte-Carlo sampling and thus improves upon previous methods. We also improve upon methods involving smooth approximations to the $\ell_0$ norm, and investigate layerwise methods. We compare the methods on different architectures and datasets, including convolutional networks trained on image datasets and transformers trained on parts of Wikipedia. We also created a synthetic teacher-student setup to investigate compression in a controlled continuous setting. Finally, we conceptually relate compression algorithms to Solomonoff's theory of inductive inference and empirically verify the prediction that regularized models can exhibit more sample-efficient convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17469v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lukas Silvester Barth, Paulo von Petersenn</dc:creator>
    </item>
    <item>
      <title>$\mathcal{L}_{q}$-maximal inequality for high dimensional means under dependence</title>
      <link>https://arxiv.org/abs/2505.17800</link>
      <description>arXiv:2505.17800v1 Announce Type: cross 
Abstract: We derive an $\mathcal{L}_{q}$-maximal inequality for zero mean dependent random variables $\{x_{t}\}_{t=1}^{n}$ on $\mathbb{R}^{p}$, where $p$ $&gt;&gt;$ $% n $ is allowed. The upper bound is a familiar multiple of $\ln (p)$ and an $% l_{\infty }$ moment, as well as Kolmogorov distances based on Gaussian approximations $(\rho _{n},\tilde{\rho}_{n})$, derived with and without negligible truncation and sub-sample blocking. The latter arise due to a departure from independence and therefore a departure from standard symmetrization arguments. Examples are provided demonstrating $(\rho _{n},% \tilde{\rho}_{n})$ $\rightarrow $ $0$ under heterogeneous mixing and physical dependence conditions, where $(\rho _{n},\tilde{\rho}_{n})$ are multiples of $\ln (p)/n^{b}$ for some $b$ $&gt;$ $0$ that depends on memory, tail decay, the truncation level and block size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17800v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan B. Hill</dc:creator>
    </item>
    <item>
      <title>Federated Causal Inference from Multi-Site Observational Data via Propensity Score Aggregation</title>
      <link>https://arxiv.org/abs/2505.17961</link>
      <description>arXiv:2505.17961v1 Announce Type: cross 
Abstract: Causal inference typically assumes centralized access to individual-level data. Yet, in practice, data are often decentralized across multiple sites, making centralization infeasible due to privacy, logistical, or legal constraints. We address this by estimating the Average Treatment Effect (ATE) from decentralized observational data using federated learning, which enables inference through the exchange of aggregate statistics rather than individual-level data. We propose a novel method to estimate propensity scores in a (non-)parametric manner by computing a federated weighted average of local scores, using two theoretically grounded weighting schemes -- Membership Weights (MW) and Density Ratio Weights (DW) -- that balance communication efficiency and model flexibility. These federated scores are then used to construct two ATE estimators: the Federated Inverse Propensity Weighting estimator (Fed-IPW) and its augmented variant (Fed-AIPW). Unlike meta-analysis methods, which fail when any site violates positivity, our approach leverages heterogeneity in treatment assignment across sites to improve overlap. We show that Fed-IPW and Fed-AIPW perform well under site-level heterogeneity in sample sizes, treatment mechanisms, and covariate distributions, with theoretical analysis and experiments on simulated and real-world data highlighting their strengths and limitations relative to meta-analysis and related methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17961v1</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Khellaf R\'emi, Bellet Aur\'elien, Josse Julie</dc:creator>
    </item>
    <item>
      <title>Anytime-valid, Bayes-assisted,Prediction-Powered Inference</title>
      <link>https://arxiv.org/abs/2505.18000</link>
      <description>arXiv:2505.18000v1 Announce Type: cross 
Abstract: Given a large pool of unlabelled data and a smaller amount of labels, prediction-powered inference (PPI) leverages machine learning predictions to increase the statistical efficiency of standard confidence interval procedures based solely on labelled data, while preserving their fixed-time validity.
  In this paper, we extend the PPI framework to the sequential setting, where labelled and unlabelled datasets grow over time.
  Exploiting Ville's inequality and the method of mixtures, we propose prediction-powered confidence sequence procedures that are valid uniformly over time and naturally accommodate prior knowledge on the quality of the predictions to further boost efficiency.
  We carefully illustrate the design choices behind our method and demonstrate its effectiveness in real and synthetic examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18000v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Valentin Kilian, Stefano Cortinovis, Fran\c{c}ois Caron</dc:creator>
    </item>
    <item>
      <title>Loss Functions for Measuring the Accuracy of Nonnegative Cross-Sectional Predictions</title>
      <link>https://arxiv.org/abs/2505.18130</link>
      <description>arXiv:2505.18130v1 Announce Type: cross 
Abstract: Measuring the accuracy of cross-sectional predictions is a subjective problem. Generally, this problem is avoided. In contrast, this paper confronts subjectivity up front by eliciting an impartial decision-maker's preferences. These preferences are embedded into an axiomatically-derived loss function, the simplest version of which is described. The parameters of the loss function can be estimated by linear regression. Specification tests for this function are described. This framework is extended to weighted averages of estimates to find the optimal weightings. Rescalings to account for changes in control data or base year data are considered. A special case occurs when the predictions represent resource allocations: the apportionment literature is used to construct the Webster-Saint Lague Rule, a particular parametrization of the loss function. These loss functions are compared to those existing in the literature. Finally, a bias measure is created that uses signed versions of these loss functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18130v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Charles D. Coleman</dc:creator>
    </item>
    <item>
      <title>Higher-order approximation for uncertainty quantification in time series analysis</title>
      <link>https://arxiv.org/abs/2211.01108</link>
      <description>arXiv:2211.01108v3 Announce Type: replace 
Abstract: For time series with high temporal correlation, the empirical process converges rather slowly to its limiting distribution. Many statistics in change-point analysis, goodness-of-fit testing and uncertainty quantification admit a representation as functionals of the empirical process and therefore inherit its slow convergence. As a result, inference based on the asymptotic distribution of those quantities is significantly affected by relatively small sample sizes. We assess the quality of higher-order approximations of the empirical process by deriving the asymptotic distribution of the corresponding error terms. Based on the limiting distribution of the higher-order terms, we propose a novel approach to calculate confidence intervals for statistical quantities such as the median. In a simulation study, we compare coverage rates and lengths of these confidence intervals with those based on the asymptotic distribution of the empirical process and highlight some benefits of higher-order approximations of the empirical process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.01108v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Annika Betken, Marie-Christine D\"uker</dc:creator>
    </item>
    <item>
      <title>Consistency of Graphical Model-based Clustering: Robust Clustering using Bayesian Spanning Forest</title>
      <link>https://arxiv.org/abs/2409.19129</link>
      <description>arXiv:2409.19129v3 Announce Type: replace 
Abstract: Mixture model-based framework is very popular for statistical inference on clustering. On the one hand, the model-based framework is convenient for producing probabilistic estimates of cluster assignments and uncertainty. On the other hand, the specification of a mixture model is fraught with the danger of misspecification that could lead to inconsistent clustering estimates. Graphical model-based clustering takes a different model specification strategy, in which the likelihood treats the data as arising dependently from a disjoint union of component graphs. To counter the large uncertainty of the graph, recent work on Bayesian spanning forest proposes using the integrated posterior of the node partition, marginalized over the latent edge distribution, to produce probabilistic estimates for clustering. Despite strong empirical performance, it is not yet known whether the clustering estimator is consistent, especially when the data-generating mechanism is different from the specified graphical model. This article gives a positive answer in the asymptotic regime: when the data arise from an unknown mixture distribution, under mild conditions, the posterior concentrates on the ground-truth partition, producing correct clustering estimates, including the number of clusters. Our result holds for both cases when the number of clusters is fixed or diverging as the sample size increases, and further provides a statistical upper bound of the misclassification rate. These theoretical results are encouraging developments for the model-based clustering literature, demonstrating the use of graphical models as a robust alternative to mixture models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19129v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yu Zheng, Leo L. Duan, Arkaprava Roy</dc:creator>
    </item>
    <item>
      <title>Safety of particle filters: Some results on the time evolution of particle filter estimates</title>
      <link>https://arxiv.org/abs/2503.21334</link>
      <description>arXiv:2503.21334v4 Announce Type: replace 
Abstract: Particle filters (PFs) is a class of Monte Carlo algorithms that propagate over time a set of $N\in\mathbb{N}$ particles which can be used to estimate, in an online fashion, the sequence of filtering distributions $(\hat{\eta}_t)_{t\geq 1}$ defined by a state-space model. Despite the popularity of PFs, the study of the time evolution of their estimates has received barely attention in the literature. Denoting by $(\hat{\eta}_t^N)_{t\geq 1}$ the PF estimate of $(\hat{\eta}_t)_{t\geq 1}$ and letting $\kappa\in (0,1)$, in this work we first show that for any number of particles $N$ it holds that, with probability one, we have $\|\hat{\eta}_t^N- \hat{\eta}_t\|\geq \kappa$ for infinitely many $t\geq 1$, with $\|\cdot\|$ a measure of distance between probability distributions. Considering a simple filtering problem we then provide reassuring results concerning the ability of PFs to estimate jointly a finite set $\{\hat{\eta}_t\}_{t=1}^T$ of filtering distributions by studying $\mathbb{P}(\sup_{t\in\{1,\dots,T\}}\|\hat{\eta}_t^{N}-\hat{\eta}_t\|\geq \kappa)$. Finally, on the same toy filtering problem, we prove that sequential quasi-Monte Carlo, a randomized quasi-Monte Carlo version of PF algorithms, offers greater safety guarantees than PFs in the sense that, for this algorithm, it holds that $\lim_{N\rightarrow\infty}\sup_{t\geq 1}\|\hat{\eta}_t^N-\hat{\eta}_t\|=0$ with probability one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21334v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathieu Gerber</dc:creator>
    </item>
    <item>
      <title>ANPP: the Adapted Normalized Power Prior for Borrowing Information from Multiple Historical Datasets in Clinical Trials</title>
      <link>https://arxiv.org/abs/2404.02453</link>
      <description>arXiv:2404.02453v2 Announce Type: replace-cross 
Abstract: The power prior is a popular class of informative priors for incorporating information from historical data. It involves raising the likelihood for the historical data to a power, which acts as a discounting parameter. When the discounting parameter is modeled as random, the normalized power prior (NPP) is recommended. When there are multiple historical datasets, there has been limited research on how to choose priors for the multiple discounting parameters of the NPP to induce desirable information borrowing behavior. In this work, we address this question by investigating the analytical relationship between the NPP and the Bayesian hierarchical model (BHM), which is a widely used method for synthesizing information from different sources. We develop the adapted normalized power prior (ANPP), which establishes dependence between the dataset-specific discounting parameters of the NPP, leading to inferences that are identical to the BHM. We establish a direct relationship between the prior for the dataset-specific discounting parameters of the ANPP and the prior for the variance parameter of the BHM. Establishing this relationship not only justifies the NPP from the perspective of hierarchical modeling, but also achieves easy prior elicitation for the NPP for the purpose of dynamic borrowing. We examine the borrowing properties of the ANPP through simulations, and apply it to a case study for a pediatric lupus trial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02453v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yueqi Shen, Matthew A. Psioda, Luiz M. Carvalho, Joseph G. Ibrahim</dc:creator>
    </item>
    <item>
      <title>Model Selection for Gaussian-gated Gaussian Mixture of Experts Using Dendrograms of Mixing Measures</title>
      <link>https://arxiv.org/abs/2505.13052</link>
      <description>arXiv:2505.13052v2 Announce Type: replace-cross 
Abstract: Mixture of Experts (MoE) models constitute a widely utilized class of ensemble learning approaches in statistics and machine learning, known for their flexibility and computational efficiency. They have become integral components in numerous state-of-the-art deep neural network architectures, particularly for analyzing heterogeneous data across diverse domains. Despite their practical success, the theoretical understanding of model selection, especially concerning the optimal number of mixture components or experts, remains limited and poses significant challenges. These challenges primarily stem from the inclusion of covariates in both the Gaussian gating functions and expert networks, which introduces intrinsic interactions governed by partial differential equations with respect to their parameters. In this paper, we revisit the concept of dendrograms of mixing measures and introduce a novel extension to Gaussian-gated Gaussian MoE models that enables consistent estimation of the true number of mixture components and achieves the pointwise optimal convergence rate for parameter estimation in overfitted scenarios. Notably, this approach circumvents the need to train and compare a range of models with varying numbers of components, thereby alleviating the computational burden, particularly in high-dimensional or deep neural network settings. Experimental results on synthetic data demonstrate the effectiveness of the proposed method in accurately recovering the number of experts. It outperforms common criteria such as the Akaike information criterion, the Bayesian information criterion, and the integrated completed likelihood, while achieving optimal convergence rates for parameter estimation and accurately approximating the regression function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13052v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tuan Thai, TrungTin Nguyen, Dat Do, Nhat Ho, Christopher Drovandi</dc:creator>
    </item>
    <item>
      <title>A Linear Approach to Data Poisoning</title>
      <link>https://arxiv.org/abs/2505.15175</link>
      <description>arXiv:2505.15175v2 Announce Type: replace-cross 
Abstract: We investigate the theoretical foundations of data poisoning attacks in machine learning models. Our analysis reveals that the Hessian with respect to the input serves as a diagnostic tool for detecting poisoning, exhibiting spectral signatures that characterize compromised datasets. We use random matrix theory (RMT) to develop a theory for the impact of poisoning proportion and regularisation on attack efficacy in linear regression. Through QR stepwise regression, we study the spectral signatures of the Hessian in multi-output regression. We perform experiments on deep networks to show experimentally that this theory extends to modern convolutional and transformer networks under the cross-entropy loss. Based on these insights we develop preliminary algorithms to determine if a network has been poisoned and remedies which do not require further training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15175v2</guid>
      <category>stat.ML</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 26 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diego Granziol, Donald Flynn</dc:creator>
    </item>
  </channel>
</rss>
