<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.BM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.BM</link>
    <description>q-bio.BM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.BM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 23 Oct 2024 04:03:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Computational design of target-specific linear peptide binders with TransformerBeta</title>
      <link>https://arxiv.org/abs/2410.16302</link>
      <description>arXiv:2410.16302v1 Announce Type: new 
Abstract: The computational prediction and design of peptide binders targeting specific linear epitopes is crucial in biological and biomedical research, yet it remains challenging due to their highly dynamic nature and the scarcity of experimentally solved binding data. To address this problem, we built an unprecedentedly large-scale library of peptide pairs within stable secondary structures (beta sheets), leveraging newly available AlphaFold predicted structures. We then developed a machine learning method based on the Transformer architecture for the design of specific linear binders, in analogy to a language translation task. Our method, TransformerBeta, accurately predicts specific beta strand interactions and samples sequences with beta sheet-like molecular properties, while capturing interpretable physico-chemical interaction patterns. As such, it can propose specific candidate binders targeting linear epitope for experimental validation to inform protein design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16302v1</guid>
      <category>q-bio.BM</category>
      <category>cs.LG</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haowen Zhao, Francesco A. Aprile, Barbara Bravi</dc:creator>
    </item>
    <item>
      <title>QuickBind: A Light-Weight And Interpretable Molecular Docking Model</title>
      <link>https://arxiv.org/abs/2410.16474</link>
      <description>arXiv:2410.16474v1 Announce Type: new 
Abstract: Predicting a ligand's bound pose to a target protein is a key component of early-stage computational drug discovery. Recent developments in machine learning methods have focused on improving pose quality at the cost of model runtime. For high-throughput virtual screening applications, this exposes a capability gap that can be filled by moderately accurate but fast pose prediction. To this end, we developed QuickBind, a light-weight pose prediction algorithm. We assess QuickBind on widely used benchmarks and find that it provides an attractive trade-off between model accuracy and runtime. To facilitate virtual screening applications, we augment QuickBind with a binding affinity module and demonstrate its capabilities for multiple clinically-relevant drug targets. Finally, we investigate the mechanistic basis by which QuickBind makes predictions and find that it has learned key physicochemical properties of molecular docking, providing new insights into how machine learning models generate protein-ligand poses. By virtue of its simplicity, QuickBind can serve as both an effective virtual screening tool and a minimal test bed for exploring new model architectures and innovations. Model code and weights are available at https://github.com/aqlaboratory/QuickBind .</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16474v1</guid>
      <category>q-bio.BM</category>
      <category>cs.LG</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wojtek Treyde, Seohyun Chris Kim, Nazim Bouatta, Mohammed AlQuraishi</dc:creator>
    </item>
    <item>
      <title>MeMDLM: De Novo Membrane Protein Design with Masked Discrete Diffusion Protein Language Models</title>
      <link>https://arxiv.org/abs/2410.16735</link>
      <description>arXiv:2410.16735v1 Announce Type: new 
Abstract: Masked Diffusion Language Models (MDLMs) have recently emerged as a strong class of generative models, paralleling state-of-the-art (SOTA) autoregressive (AR) performance across natural language modeling domains. While there have been advances in AR as well as both latent and discrete diffusion-based approaches for protein sequence design, masked diffusion language modeling with protein language models (pLMs) is unexplored. In this work, we introduce MeMDLM, an MDLM tailored for membrane protein design, harnessing the SOTA pLM ESM-2 to de novo generate realistic membrane proteins for downstream experimental applications. Our evaluations demonstrate that MeMDLM-generated proteins exceed AR-based methods by generating sequences with greater transmembrane (TM) character. We further apply our design framework to scaffold soluble and TM motifs in sequences, demonstrating that MeMDLM-reconstructed sequences achieve greater biological similarity to their original counterparts compared to SOTA inpainting methods. Finally, we show that MeMDLM captures physicochemical membrane protein properties with similar fidelity as SOTA pLMs, paving the way for experimental applications. In total, our pipeline motivates future exploration of MDLM-based pLMs for protein design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16735v1</guid>
      <category>q-bio.BM</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shrey Goel, Vishrut Thoutam, Edgar Mariano Marroquin, Aaron Gokaslan, Arash Firouzbakht, Sophia Vincoff, Volodymyr Kuleshov, Huong T. Kratochvil, Pranam Chatterjee</dc:creator>
    </item>
    <item>
      <title>Optimizing First-Line Therapeutics in Non-Small Cell Lung Cancer: Insights from Joint Modeling and Large-Scale Data Analysis</title>
      <link>https://arxiv.org/abs/2410.16967</link>
      <description>arXiv:2410.16967v1 Announce Type: new 
Abstract: Non-small cell lung cancer (NSCLC) is often intrinsically resistant to several first- and second-line therapeutics and can rapidly acquire further resistance after a patient begins receiving treatment. Treatment outcomes are therefore significantly impacted by the optimization of therapeutic scheduling. Previous preclinical research has suggested scheduling bevacizumab in sequence with combination antiproliferatives could significantly improve clinical outcomes. Mathematical modeling is a well-suited tool for investigating this proposed scheduling modification. To address this critical need, individual patient tumor data from 11 clinical trials in NSCLC has been collated and used to develop a semi-mechanistic model of NSCLC growth and response to the various therapeutics represented in those trials. Precise estimates of clinical parameters fundamental to cancer modeling have been produced - such as the rate of acquired resistance to various pharmaceuticals, the relationship between drug concentration and cancer cell death, as well as the fine temporal dynamics of vascular remodeling in response to bevacizumab. In a reserved portion of the dataset, this model was used to predict the efficacy of individual treatment time courses with a mean error rate of 59.7% after a single tumor measurement and 11.7% after three successive tumor measurements. A delay of 9.6 hours between pemetrexed-cisplatin and bevacizumab administration is predicted to optimize the benefit of sequential administration. At this gap, approximately 93.5% of simulated patients benefited from a gap in sequential administration compared with concomitant administration. Of those simulated patients, the mean improvement in tumor reduction was 20.7%. This result suggests that scheduling a modest gap between the administration of bevacizumab and its partner antiproliferatives could meaningfully improve patient outcomes in NSCLC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16967v1</guid>
      <category>q-bio.BM</category>
      <category>q-bio.TO</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Benjamin K. Schneider, Sebastien Benzekry, Jonathan P. Mochel</dc:creator>
    </item>
    <item>
      <title>Higher-Order Message Passing for Glycan Representation Learning</title>
      <link>https://arxiv.org/abs/2409.13467</link>
      <description>arXiv:2409.13467v2 Announce Type: replace-cross 
Abstract: Glycans are the most complex biological sequence, with monosaccharides forming extended, non-linear sequences. As post-translational modifications, they modulate protein structure, function, and interactions. Due to their diversity and complexity, predictive models of glycan properties and functions are still insufficient. Graph Neural Networks (GNNs) are deep learning models designed to process and analyze graph-structured data. These architectures leverage the connectivity and relational information in graphs to learn effective representations of nodes, edges, and entire graphs. Iteratively aggregating information from neighboring nodes, GNNs capture complex patterns within graph data, making them particularly well-suited for tasks such as link prediction or graph classification across domains. This work presents a new model architecture based on combinatorial complexes and higher-order message passing to extract features from glycan structures into a latent space representation. The architecture is evaluated on an improved GlycanML benchmark suite, establishing a new state-of-the-art performance. We envision that these improvements will spur further advances in computational glycosciences and reveal the roles of glycans in biology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13467v2</guid>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <pubDate>Wed, 23 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roman Joeres, Daniel Bojar</dc:creator>
    </item>
  </channel>
</rss>
