<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 Jan 2025 02:37:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Covering Underwater Shadow Zones using Acoustic Reconfigurable Intelligent Surfaces</title>
      <link>https://arxiv.org/abs/2501.02256</link>
      <description>arXiv:2501.02256v1 Announce Type: new 
Abstract: To better explore the oceans, seamless communication coverage of the vast 3D underwater space is desired. Unlike terrestrial networks using radio signals, underwater acoustic communications face a unique challenge: nodes in underwater shadow zones cannot connect to the network, even within the line of sight. These shadow zones can extend for tens of kilometers, causing communication nodes to disconnect. Existing efforts focus on passive avoidance of shadow zones, but this strategy cannot ensure seamless coverage in dynamic ocean environments. This paper addresses the shadow zone problem by utilizing acoustic Reconfigurable Intelligent Surfaces (RIS) to actively control the underwater channel. Shadow zones are analytically modeled, and optimal RIS deployment strategies are developed for both deep-sea and shallow-sea environments. The acoustic RIS is redesigned considering practical engineering limitations and validated through pool tests. Bellhop-based simulations show that without RIS deployment, coverage is limited to less than 20%, regardless of source strength. However, with optimal RIS deployment, energy coverage can reach almost 100%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02256v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Longfei Zhao, Jingbo Tan, Jintao Wang, Ian F. Akyildiz, Zhi Sun</dc:creator>
    </item>
    <item>
      <title>LoRaConnect: Unlocking HTTP Potential on LoRa Backbones for Remote Areas and Ad-Hoc Networks</title>
      <link>https://arxiv.org/abs/2501.02469</link>
      <description>arXiv:2501.02469v1 Announce Type: new 
Abstract: The minimal infrastructure requirements of LoRa make it suitable for deployments in remote and disaster-stricken areas. Concomitantly, the modern era is witnessing the proliferation of web applications in all aspects of human life, including IoT and other network services. Contemporary IoT and network solutions heavily rely on web applications to render services. However, despite the recent research and development pivoted around LoRa, there is still a lack of studies focusing on web application access over LoRa networks. Specifically, technical challenges like payload size limitation, low data rate, and contentions in multi-user setups limit the applicability of LoRa for web applications. Hence, we propose LoRaWeb, which enables web access over LoRa networks. The LoRaWeb hardware tethers a WiFi hotspot to which the client devices connect and access the web pages using a web browser. LoRa backbone of the network handles the web page transmission from the requester and receiver devices. LoRaWeb implements a synchronization procedure to address the aforementioned challenges for effective message exchange between requesters and responders. The system implements a caching mechanism to reduce latency and contention. Additionally, it implements a message-slicing mechanism in the application layer to overcome the hardware limitations on the message length. The actual hardware-based implementation results indicate seamless deployment, and the results indicate an average access time of ~$0.95 S$ for a $1.5 KB$ and ~$6 S$ for a $10 KB$ size web page.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02469v1</guid>
      <category>cs.NI</category>
      <category>cs.CY</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Atonu Ghosh, Sudip Misra</dc:creator>
    </item>
    <item>
      <title>Spatial Network Calculus: Toward Deterministic Wireless Networking</title>
      <link>https://arxiv.org/abs/2501.02556</link>
      <description>arXiv:2501.02556v1 Announce Type: new 
Abstract: This paper extends the classical network calculus to spatial scenarios, focusing on wireless networks with heterogeneous traffic and varying transmit power levels. Building on spatial network calculus, a prior extension of network calculus to spatial settings, we propose a generalized framework by introducing spatial regulations for stationary marked point processes. The regulations correspond to two key constraints: the total transmit power within a spatial region and the cumulative received power at a receiver. Then we prove the equivalence of ball regulation and shot-noise regulation for stationary marked point processes and establish a universal lower bound on the performance of all network links under these constraints. This framework is applicable to diverse network scenarios, as demonstrated by the analysis of performance guarantees for networks with multi-class users. In addition, we propose an SINR-based power control scheme adapted to user traffic, which ensures differentiated quality of service (QoS) for different user classes. We derive deterministic performance guarantees for all links in complex and heterogeneous wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02556v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Zhong, Xiaohang Zhou, Ke Feng</dc:creator>
    </item>
    <item>
      <title>Energy Optimization of Multi-task DNN Inference in MEC-assisted XR Devices: A Lyapunov-Guided Reinforcement Learning Approach</title>
      <link>https://arxiv.org/abs/2501.02572</link>
      <description>arXiv:2501.02572v1 Announce Type: new 
Abstract: Extended reality (XR), blending virtual and real worlds, is a key application of future networks. While AI advancements enhance XR capabilities, they also impose significant computational and energy challenges on lightweight XR devices. In this paper, we developed a distributed queue model for multi-task DNN inference, addressing issues of resource competition and queue coupling. In response to the challenges posed by the high energy consumption and limited resources of XR devices, we designed a dual time-scale joint optimization strategy for model partitioning and resource allocation, formulated as a bi-level optimization problem. This strategy aims to minimize the total energy consumption of XR devices while ensuring queue stability and adhering to computational and communication resource constraints. To tackle this problem, we devised a Lyapunov-guided Proximal Policy Optimization algorithm, named LyaPPO. Numerical results demonstrate that the LyaPPO algorithm outperforms the baselines, achieving energy conservation of 24.79% to 46.14% under varying resource capacities. Specifically, the proposed algorithm reduces the energy consumption of XR devices by 24.29% to 56.62% compared to baseline algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02572v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanzan Sun, Jiacheng Qiu, Guangjin Pan, Shugong Xu, Shunqing Zhang, Xiaoyun Wang, Shuangfeng Han</dc:creator>
    </item>
    <item>
      <title>Constructing 4D Radio Map in LEO Satellite Networks with Limited Samples</title>
      <link>https://arxiv.org/abs/2501.02775</link>
      <description>arXiv:2501.02775v1 Announce Type: new 
Abstract: Recently, Low Earth Orbit (LEO) satellite networks (i.e., non-terrestrial network (NTN)), such as Starlink, have been successfully deployed to provide broader coverage than terrestrial networks (TN). Due to limited spectrum resources, TN and NTN may soon share the same spectrum. Therefore, fine-grained spectrum monitoring is crucial for spectrum sharing and interference avoidance. To this end, constructing a 4D radio map (RM) including three spatial dimensions and signal spectra is important. However, this requires the large deployment of sensors, and high-speed analog-to-digital converters for extensive spatial signal collection and wide power spectrum acquisition, respectively. To address these challenges, we propose a deep unsupervised learning framework without ground truths labeling requirement, DeepRM, comprised of neural compressive sensing (CS) and tensor decomposition (TD) algorithms. Firstly, we map the CS process into the optimization of a neural networksassociated loss function, and design a sparsity-performance balance training algorithm to reconstruct a wide power spectrum under limited sub-Nquist samples. Secondly, according to the output of neural CS algorithm, we also utilize neural networks to perform TD, and construct the 3D RM for each frequency, even under very sparse sensor deployment. Extensive evaluations show that DeepRM achieves lower error than its corresponding state-of-the-art baselines, especially with limited samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02775v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoxuan Yuan, Zhe Chen, Zheng Lin, Jinbo Peng, Yuhang Zhong, Xuanjie Hu, Songyan Xue, Wei Li, Yue Gao</dc:creator>
    </item>
    <item>
      <title>Joint Optimization of UAV-Carried IRS for Urban Low Altitude mmWave Communications with Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2501.02787</link>
      <description>arXiv:2501.02787v1 Announce Type: new 
Abstract: Emerging technologies in sixth generation (6G) of wireless communications, such as terahertz communication and ultra-massive multiple-input multiple-output, present promising prospects. Despite the high data rate potential of millimeter wave communications, millimeter wave (mmWave) communications in urban low altitude economy (LAE) environments are constrained by challenges such as signal attenuation and multipath interference. Specially, in urban environments, mmWave communication experiences significant attenuation due to buildings, owing to its short wavelength, which necessitates developing innovative approaches to improve the robustness of such communications in LAE networking. In this paper, we explore the use of an unmanned aerial vehicle (UAV)-carried intelligent reflecting surface (IRS) to support low altitude mmWave communication. Specifically, we consider a typical urban low altitude communication scenario where a UAV-carried IRS establishes a line-of-sight (LoS) channel between the mobile users and a source user (SU) despite the presence of obstacles. Subsequently, we formulate an optimization problem aimed at maximizing the transmission rates and minimizing the energy consumption of the UAV by jointly optimizing phase shifts of the IRS and UAV trajectory. Given the non-convex nature of the problem and its high dynamics, we propose a deep reinforcement learning-based approach incorporating neural episodic control, long short-term memory, and an IRS phase shift control method to enhance the stability and accelerate the convergence. Simulation results show that the proposed algorithm effectively resolves the problem and surpasses other benchmark algorithms in various performances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02787v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenwen Xie, Geng Sun, Bei Liu, Jiahui Li, Jiacheng Wang, Hongyang Du, Dusit Niyato, Dong In Kim</dc:creator>
    </item>
    <item>
      <title>Online Collaborative Resource Allocation and Task Offloading for Multi-access Edge Computing</title>
      <link>https://arxiv.org/abs/2501.02952</link>
      <description>arXiv:2501.02952v1 Announce Type: new 
Abstract: Multi-access edge computing (MEC) is emerging as a promising paradigm to provide flexible computing services close to user devices (UDs). However, meeting the computation-hungry and delay-sensitive demands of UDs faces several challenges, including the resource constraints of MEC servers, inherent dynamic and complex features in the MEC system, and difficulty in dealing with the time-coupled and decision-coupled optimization. In this work, we first present an edge-cloud collaborative MEC architecture, where the MEC servers and cloud collaboratively provide offloading services for UDs. Moreover, we formulate an energy-efficient and delay-aware optimization problem (EEDAOP) to minimize the energy consumption of UDs under the constraints of task deadlines and long-term queuing delays. Since the problem is proved to be non-convex mixed integer nonlinear programming (MINLP), we propose an online joint communication resource allocation and task offloading approach (OJCTA). Specifically, we transform EEDAOP into a real-time optimization problem by employing the Lyapunov optimization framework. Then, to solve the real-time optimization problem, we propose a communication resource allocation and task offloading optimization method by employing the Tammer decomposition mechanism, convex optimization method, bilateral matching mechanism, and dependent rounding method. Simulation results demonstrate that the proposed OJCTA can achieve superior system performance compared to the benchmark approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02952v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geng Sun, Minghua Yuan, Zemin Sun, Jiacheng Wang, Hongyang Du, Dusit Niyato, Zhu Han, Dong In Kim</dc:creator>
    </item>
    <item>
      <title>Simulation of entanglement based quantum networks for performance characterization</title>
      <link>https://arxiv.org/abs/2501.03210</link>
      <description>arXiv:2501.03210v1 Announce Type: new 
Abstract: Entanglement-based networks (EBNs) enable general-purpose quantum communication by combining entanglement and its swapping in a sequence that addresses the challenges of achieving long distance communication with high fidelity associated with quantum technologies. In this context, entanglement distribution refers to the process by which two nodes in a quantum network share an entangled state, serving as a fundamental resource for communication. In this paper, we study the performance of entanglement distribution mechanisms over a physical topology comprising end nodes and quantum switches, which are crucial for constructing large-scale links. To this end, we implemented a switch-based topology in NetSquid and conducted a series of simulation experiments to gain insight into practical and realistic quantum network engineering challenges. These challenges include, on the one hand, aspects related to quantum technology, such as memory technology, gate durations, and noise; and, on the other hand, factors associated with the distribution process, such as the number of switches, distances, purification, and error correction. All these factors significantly impact the end-to-end fidelity across a path, which supports communication between two quantum nodes. We use these experiments to derive some guidelines towards the design and configuration of future EBNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03210v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David P\'erez Castro, Juan Fern\'andez-Herrer\'in, Ana Fern\'andez-Vilas, Manuel Fern\'andez-Veigaa, Rebeca P. D\'iaz-Redondo</dc:creator>
    </item>
    <item>
      <title>Revelio: A Real-World Screen-Camera Communication System with Visually Imperceptible Data Embedding</title>
      <link>https://arxiv.org/abs/2501.02349</link>
      <description>arXiv:2501.02349v1 Announce Type: cross 
Abstract: We present `Revelio', a real-world screen-camera communication system leveraging temporal flicker fusion in the OKLAB color space. Using spatially-adaptive flickering and encoding information in pixel region shapes, Revelio achieves visually imperceptible data embedding while remaining robust against noise, asynchronicity, and distortions in screen-camera channels, ensuring reliable decoding by standard smartphone cameras. The decoder, driven by a two-stage neural network, uses a weighted differential accumulator for precise frame detection and symbol recognition. Initial experiments demonstrate Revelio's effectiveness in interactive television, offering an unobtrusive method for meta-information transmission.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02349v1</guid>
      <category>cs.MM</category>
      <category>cs.CR</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abbaas Alif Mohamed Nishar, Shrinivas Kudekar, Bernard Kintzing, Ashwin Ashok</dc:creator>
    </item>
    <item>
      <title>PM-Dedup: Secure Deduplication with Partial Migration from Cloud to Edge Servers</title>
      <link>https://arxiv.org/abs/2501.02350</link>
      <description>arXiv:2501.02350v1 Announce Type: cross 
Abstract: Currently, an increasing number of users and enterprises are storing their data in the cloud but do not fully trust cloud providers with their data in plaintext form. To address this concern, they encrypt their data before uploading it to the cloud. However, encryption with different keys means that even identical data will become different ciphertexts, making deduplication less effective. Encrypted deduplication avoids this issue by ensuring that identical data chunks generate the same ciphertext with content-based keys, enabling the cloud to efficiently identify and remove duplicates even in encrypted form. Current encrypted data deduplication work can be classified into two types: target-based and source-based. Target-based encrypted deduplication requires clients to upload all encrypted chunks (the basic unit of deduplication) to the cloud with high network bandwidth overhead. Source-based deduplication involves clients uploading fingerprints (hashes) of encrypted chunks for duplicate checking and only uploading unique encrypted chunks, which reduces network transfer but introduces high latency and potential side-channel attacks, which need to be mitigated by Proof of Ownership (PoW), and high computing overhead of the cloud. So, reducing the latency and the overheads of network and cloud while ensuring security has become a significant challenge for secure data deduplication in cloud storage. In response to this challenge, we present PM-Dedup, a novel secure source-based deduplication approach that relocates a portion of the deduplication checking process and PoW tasks from the cloud to the trusted execution environments (TEEs) in the client-side edge servers. We also propose various designs to enhance the security and efficiency of data deduplication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02350v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaokang Ke, Haoyu Gong, David H. C. Du</dc:creator>
    </item>
    <item>
      <title>Neural Reflectance Fields for Radio-Frequency Ray Tracing</title>
      <link>https://arxiv.org/abs/2501.02458</link>
      <description>arXiv:2501.02458v1 Announce Type: cross 
Abstract: Ray tracing is widely employed to model the propagation of radio-frequency (RF) signal in complex environment. The modelling performance greatly depends on how accurately the target scene can be depicted, including the scene geometry and surface material properties. The advances in computer vision and LiDAR make scene geometry estimation increasingly accurate, but there still lacks scalable and efficient approaches to estimate the material reflectivity in real-world environment. In this work, we tackle this problem by learning the material reflectivity efficiently from the path loss of the RF signal from the transmitters to receivers. Specifically, we want the learned material reflection coefficients to minimize the gap between the predicted and measured powers of the receivers. We achieve this by translating the neural reflectance field from optics to RF domain by modelling both the amplitude and phase of RF signals to account for the multipath effects. We further propose a differentiable RF ray tracing framework that optimizes the neural reflectance field to match the signal strength measurements. We simulate a complex real-world environment for experiments and our simulation results show that the neural reflectance field can successfully learn the reflection coefficients for all incident angles. As a result, our approach achieves better accuracy in predicting the powers of receivers with significantly less training data compared to existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02458v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haifeng Jia, Xinyi Chen, Yichen Wei, Yifei Sun, Yibo Pi</dc:creator>
    </item>
    <item>
      <title>CONTINUUM: Detecting APT Attacks through Spatial-Temporal Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2501.02981</link>
      <description>arXiv:2501.02981v2 Announce Type: cross 
Abstract: Advanced Persistent Threats (APTs) represent a significant challenge in cybersecurity due to their sophisticated and stealthy nature. Traditional Intrusion Detection Systems (IDS) often fall short in detecting these multi-stage attacks. Recently, Graph Neural Networks (GNNs) have been employed to enhance IDS capabilities by analyzing the complex relationships within networked data. However, existing GNN-based solutions are hampered by high false positive rates and substantial resource consumption. In this paper, we present a novel IDS designed to detect APTs using a Spatio-Temporal Graph Neural Network Autoencoder. Our approach leverages spatial information to understand the interactions between entities within a graph and temporal information to capture the evolution of the graph over time. This dual perspective is crucial for identifying the sequential stages of APTs. Furthermore, to address privacy and scalability concerns, we deploy our architecture in a federated learning environment. This setup ensures that local data remains on-premise while encrypted model-weights are shared and aggregated using homomorphic encryption, maintaining data privacy and security. Our evaluation shows that this system effectively detects APTs with lower false positive rates and optimized resource usage compared to existing methods, highlighting the potential of spatio-temporal analysis and federated learning in enhancing cybersecurity defenses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02981v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Atmane Ayoub Mansour Bahar, Kamel Soaid Ferrahi, Mohamed-Lamine Messai, Hamida Seba, Karima Amrouche</dc:creator>
    </item>
    <item>
      <title>RIS-Driven Resource Allocation Strategies for Diverse Network Environments: A Comprehensive Review</title>
      <link>https://arxiv.org/abs/2501.03075</link>
      <description>arXiv:2501.03075v1 Announce Type: cross 
Abstract: This comprehensive survey examines how Reconfigurable Intelligent Surfaces (RIS) revolutionize resource allocation in various network frameworks. It begins by establishing a theoretical foundation with an overview of RIS technologies, including passive RIS, active RIS, and Simultaneously Transmitting and Reflecting RIS (STAR-RIS). The core of the survey focuses on RIS's role in optimizing resource allocation within Single-Input Multiple-Output (SIMO), Multiple-Input Single-Output (MISO), and Multiple-Input Multiple-Output (MIMO) systems. It further explores RIS integration in complex network environments, such as Heterogeneous Wireless Networks (HetNets) and Non-Orthogonal Multiple Access (NOMA) frameworks. Additionally, the survey investigates RIS applications in advanced communication domains like Terahertz (THz) networks, Vehicular Communication (VC), and Unmanned Aerial Vehicle (UAV) communications, highlighting the synergy between RIS and Artificial Intelligence (AI) for enhanced network efficiency. Summary tables provide comparative insights into various schemes. The survey concludes with lessons learned, future research directions, and challenges, emphasizing critical open issues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03075v1</guid>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manzoor Ahmed, Fang Xu, Yuanlin Lyu, Aized Amin Soofi, Yongxiao Li, Feroz Khan, Wali Ullah Khan, Muhammad Sheraz, Teong Chee Chuah, Min Deng</dc:creator>
    </item>
    <item>
      <title>Prioritized Information Bottleneck Theoretic Framework with Distributed Online Learning for Edge Video Analytics</title>
      <link>https://arxiv.org/abs/2409.00146</link>
      <description>arXiv:2409.00146v3 Announce Type: replace 
Abstract: Collaborative perception systems leverage multiple edge devices, such surveillance cameras or autonomous cars, to enhance sensing quality and eliminate blind spots. Despite their advantages, challenges such as limited channel capacity and data redundancy impede their effectiveness. To address these issues, we introduce the Prioritized Information Bottleneck (PIB) framework for edge video analytics. This framework prioritizes the shared data based on the signal-to-noise ratio (SNR) and camera coverage of the region of interest (RoI), reducing spatial-temporal data redundancy to transmit only essential information. This strategy avoids the need for video reconstruction at edge servers and maintains low latency. It leverages a deterministic information bottleneck method to extract compact, relevant features, balancing informativeness and communication costs. For high-dimensional data, we apply variational approximations for practical optimization. To reduce communication costs in fluctuating connections, we propose a gate mechanism based on distributed online learning (DOL) to filter out less informative messages and efficiently select edge servers. Moreover, we establish the asymptotic optimality of DOL by proving the sublinearity of their regrets. To validate the effectiveness of the PIB framework, we conduct real-world experiments on three types of edge devices with varied computing capabilities. Compared to five coding methods for image and video compression, PIB improves mean object detection accuracy (MODA) while reducing 17.8% and reduces communication costs by 82.65% under poor channel conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00146v3</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TON.2025.3526148</arxiv:DOI>
      <dc:creator>Zhengru Fang, Senkang Hu, Jingjing Wang, Yiqin Deng, Xianhao Chen, Yuguang Fang</dc:creator>
    </item>
    <item>
      <title>A Comparative Study on Self-Organization in Wireless Sensor Networks</title>
      <link>https://arxiv.org/abs/2411.15690</link>
      <description>arXiv:2411.15690v2 Announce Type: replace 
Abstract: With advancements in microelectromechanical systems, low-power integrated circuits, and wireless communications, wireless sensor networks (WSNs) have become increasingly significant [1][2]. These distributed networks enable efficient resource utilization and open doors to numerous applications, including personal healthcare, home automation, environmental monitoring, industrial automation, and defense surveillance. However, WSNs are susceptible to environmental factors in their deployment areas and may suffer damage. In such cases, the network must be reconfigured or repaired. To address these challenges and adapt to resource constraints, WSN mechanisms must exhibit self-organizing capabilities. For instance, in tasks like allocation, cooperative communication, and dynamic data collection, self-organization enhances the efficiency and robustness of WSNs across the application, network, and physical layers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15690v2</guid>
      <category>cs.NI</category>
      <category>cs.CY</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Simon, Salwa M. Din, Raja Jamal Chib</dc:creator>
    </item>
    <item>
      <title>Overview of AI and Communication for 6G Network: Fundamentals, Challenges, and Future Research Opportunities</title>
      <link>https://arxiv.org/abs/2412.14538</link>
      <description>arXiv:2412.14538v3 Announce Type: replace 
Abstract: With the growing demand for seamless connectivity and intelligent communication, the integration of artificial intelligence (AI) and sixth-generation (6G) communication networks has emerged as a transformative paradigm. By embedding AI capabilities across various network layers, this integration enables optimized resource allocation, improved efficiency, and enhanced system robust performance, particularly in intricate and dynamic environments. This paper presents a comprehensive overview of AI and communication for 6G networks, with a focus on emphasizing their foundational principles, inherent challenges, and future research opportunities. We first review the integration of AI and communications in the context of 6G, exploring the driving factors behind incorporating AI into wireless communications, as well as the vision for the convergence of AI and 6G. The discourse then transitions to a detailed exposition of the envisioned integration of AI within 6G networks, delineated across three progressive developmental stages. The first stage, AI for Network, focuses on employing AI to augment network performance, optimize efficiency, and enhance user service experiences. The second stage, Network for AI, highlights the role of the network in facilitating and buttressing AI operations and presents key enabling technologies, such as digital twins for AI and semantic communication. In the final stage, AI as a Service, it is anticipated that future 6G networks will innately provide AI functions as services, supporting application scenarios like immersive communication and intelligent industrial robots. In addition, we conduct an in-depth analysis of the critical challenges faced by the integration of AI and communications in 6G. Finally, we outline promising future research opportunities that are expected to drive the development and refinement of AI and 6G communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14538v3</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qimei Cui, Xiaohu You, Wei Ni, Guoshun Nan, Xuefei Zhang, Jianhua Zhang, Xinchen Lyu, Ming Ai, Xiaofeng Tao, Zhiyong Feng, Ping Zhang, Qingqing Wu, Meixia Tao, Yongming Huang, Chongwen Huang, Guangyi Liu, Chenghui Peng, Zhiwen Pan, Tao Sun, Dusit Niyato, Tao Chen, Muhammad Khurram Khan, Abbas Jamalipour, Mohsen Guizani, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Joint Task Offloading and Routing in Wireless Multi-hop Networks Using Biased Backpressure Algorithm</title>
      <link>https://arxiv.org/abs/2412.15385</link>
      <description>arXiv:2412.15385v2 Announce Type: replace 
Abstract: A significant challenge for computation offloading in wireless multi-hop networks is the complex interaction among traffic flows in the presence of interference. Existing approaches often ignore these key effects and/or rely on outdated queueing and channel state information. To fill these gaps, we reformulate joint offloading and routing as a routing problem on an extended graph with physical and virtual links. We adopt the state-of-the-art shortest path-biased Backpressure routing algorithm, which allows the destination and the route of a job to be dynamically adjusted at every time step based on network-wide long-term information and real-time states of local neighborhoods. In large networks, our approach achieves smaller makespan than existing approaches, such as separated Backpressure offloading and joint offloading and routing based on linear programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15385v2</guid>
      <category>cs.NI</category>
      <category>cs.DC</category>
      <category>eess.SP</category>
      <pubDate>Tue, 07 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongyuan Zhao, Jake Perazzone, Gunjan Verma, Kevin Chan, Ananthram Swami, Santiago Segarra</dc:creator>
    </item>
  </channel>
</rss>
