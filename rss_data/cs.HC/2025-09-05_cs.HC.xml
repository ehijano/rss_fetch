<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Sep 2025 04:00:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Promisedland: An XR Narrative Attraction Integrating Diorama-to-Virtual Workflow and Elemental Storytelling</title>
      <link>https://arxiv.org/abs/2509.03678</link>
      <description>arXiv:2509.03678v1 Announce Type: new 
Abstract: Promisedland is a mixed-reality (MR) narrative attraction that combines cultural storytelling, ecological education, and an innovative hybrid production workflow. Set in a future Earth suffering from elemental imbalance, users embark on an interactive journey guided by symbolic characters to restore harmony through the collection of five classical elements: metal, wood, water, fire, and earth. To prototype this experience, we introduce a low-cost, high-fidelity Diorama-to-Virtual pipeline - handcrafting physical scale models, 3D scanning, and integrating them into Unreal Engine. This process enables rapid spatial prototyping while preserving the material expressiveness and narrative consistency of the physical environment. To further enhance immersion, the experience incorporates a Stewart Platform to provide motion feedback synchronized with the virtual ride dynamics, reinforcing spatial presence and embodied engagement. The final prototype runs on Meta Quest, supporting dynamic interactions and real-time visual feedback. Promisedland offers a replicable design blueprint for future XR narrative installations across museums, cultural exhibitions, and themed entertainment. It proposes a new framework for XR Narrative Attractions - where physical and digital elements converge to deepen immersion, agency, and emotional engagement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03678v1</guid>
      <category>cs.HC</category>
      <category>cs.MM</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xianghan Wang, Chingshuan Hsiao, Shimei Qiu</dc:creator>
    </item>
    <item>
      <title>Designing Effective AI Explanations for Misinformation Detection: A Comparative Study of Content, Social, and Combined Explanations</title>
      <link>https://arxiv.org/abs/2509.03693</link>
      <description>arXiv:2509.03693v1 Announce Type: new 
Abstract: In this paper, we study the problem of AI explanation of misinformation, where the goal is to identify explanation designs that help improve users' misinformation detection abilities and their overall user experiences. Our work is motivated by the limitations of current Explainable AI (XAI) approaches, which predominantly focus on content explanations that elucidate the linguistic features and sentence structures of the misinformation. To address this limitation, we explore various explanations beyond content explanation, such as "social explanation" that considers the broader social context surrounding misinformation, as well as a "combined explanation" where both the content and social explanations are presented in scenarios that are either aligned or misaligned with each other. To evaluate the comparative effectiveness of these AI explanations, we conduct two online crowdsourcing experiments in the COVID-19 (Study 1 on Prolific) and Politics domains (Study 2 on MTurk). Our results show that AI explanations are generally effective in aiding users to detect misinformation, with effectiveness significantly influenced by the alignment between content and social explanations. We also find that the order in which explanation types are presented - specifically, whether a content or social explanation comes first - can influence detection accuracy, with differences found between the COVID-19 and Political domains. This work contributes towards more effective design of AI explanations, fostering a deeper understanding of how different explanation types and their combinations influence misinformation detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03693v1</guid>
      <category>cs.HC</category>
      <category>cs.MM</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yeaeun Gong, Yifan Liu, Lanyu Shang, Na Wei, Dong Wang</dc:creator>
    </item>
    <item>
      <title>Designing Gaze Analytics for ELA Instruction: A User-Centered Dashboard with Conversational AI Support</title>
      <link>https://arxiv.org/abs/2509.03741</link>
      <description>arXiv:2509.03741v1 Announce Type: new 
Abstract: Eye-tracking offers rich insights into student cognition and engagement, but remains underutilized in classroom-facing educational technology due to challenges in data interpretation and accessibility. In this paper, we present the iterative design and evaluation of a gaze-based learning analytics dashboard for English Language Arts (ELA), developed through five studies involving teachers and students. Guided by user-centered design and data storytelling principles, we explored how gaze data can support reflection, formative assessment, and instructional decision-making. Our findings demonstrate that gaze analytics can be approachable and pedagogically valuable when supported by familiar visualizations, layered explanations, and narrative scaffolds. We further show how a conversational agent, powered by a large language model (LLM), can lower cognitive barriers to interpreting gaze data by enabling natural language interactions with multimodal learning analytics. We conclude with design implications for future EdTech systems that aim to integrate novel data modalities in classroom contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03741v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduardo Davalos, Yike Zhang, Shruti Jain, Namrata Srivastava, Trieu Truong, Nafees-ul Haque, Tristan Van, Jorge Salas, Sara McFadden, Sun-Joo Cho, Gautam Biswas, Amanda Goodwin</dc:creator>
    </item>
    <item>
      <title>Map as a By-product: Collective Landmark Mapping from IMU Data and User-provided Texts in Situated Tasks</title>
      <link>https://arxiv.org/abs/2509.03792</link>
      <description>arXiv:2509.03792v1 Announce Type: new 
Abstract: This paper presents Collective Landmark Mapper, a novel map-as-a-by-product system for generating semantic landmark maps of indoor environments. Consider users engaged in situated tasks that require them to navigate these environments and regularly take notes on their smartphones. Collective Landmark Mapper exploits the smartphone's IMU data and the user's free text input during these tasks to identify a set of landmarks encountered by the user. The identified landmarks are then aggregated across multiple users to generate a unified map representing the positions and semantic information of all landmarks. In developing the proposed system, we focused specifically on retail applications and conducted a formative interview with stakeholders to confirm their practical needs that motivate the map-as-a-byproduct approach. Our user study demonstrates the feasibility of the proposed system and its superior mapping performance in two different setups: creating a product availability map from restocking checklist tasks at a retail store and constructing a room usage map from office inspection tasks, further demonstrating the potential applicability to non-retail applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03792v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3749455</arxiv:DOI>
      <arxiv:journal_reference>Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 9, 3, Article 146 (September 2025)</arxiv:journal_reference>
      <dc:creator>Ryo Yonetani, Kotaro Hara</dc:creator>
    </item>
    <item>
      <title>Exploring the Integration of Extended Reality and Artificial Intelligence (AI) for Remote STEM Education and Assessment</title>
      <link>https://arxiv.org/abs/2509.03812</link>
      <description>arXiv:2509.03812v1 Announce Type: new 
Abstract: This paper presents a dynamic gamification architecture for an Extended Reality Artificial Intelligence virtual training environment designed to enhance STEM education through immersive adaptive, and kinesthetic learning. The proposed system can be introduced in four phases: Introduction Phase, Component Development Phase, Fault Introduction and Correction Phase and Generative AI XR scenarios Phase. Security and privacy are discussed via a defense-in-depth approach spanning client, middleware, and backend layers, incorporating AES 256 encryption, multi-factor authentication, role-based access control and GDPR or FERPA compliance. Risks such as sensor exploitation, perceptual manipulation, and virtual physical harm are identified, with mitigation strategies embedded at the design stage. Potential barriers to large scale adoption-including technical complexity, cost of deployment, and need for cybersecurity expertise are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03812v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shadeeb Hossain, Natalie Sommer, Neda Adib</dc:creator>
    </item>
    <item>
      <title>"Low Frequency Tweeters Have More to Say!" A New Approach to Identify Importance of Tweets</title>
      <link>https://arxiv.org/abs/2509.03931</link>
      <description>arXiv:2509.03931v1 Announce Type: new 
Abstract: Twitter is one of the most popular social media platforms.With a large number of tweets, the activity feed of users becomes noisy, challenging to read, and most importantly tweets often get lost. We present a new approach to personalise the ranking of the tweets toward solving the problem of information overload which is achieved by analysing the relationship between the importance of tweets to the frequency at which the author tweets. The hypothesis tested is that "low-frequency tweeters have more to say", i.e. if a user who tweets infrequently actually goes to the effort of tweeting, then it is more likely to be of more importance or contain more "meaning" than a tweet by a user who tweets continuously. We propose six new measures to evaluate the importance of tweets based on the ability of the tweet to drive interaction among its readers, which is measured through metrics such as retweets, favourites, and comments, and the extent of the author's network interacting with the tweet. Our study shows that users who tweeted less than ten tweets per week were more likely to be perceived as important by their followers and have the most important messages. This identified tweet-frequency band could be used to reorder the activity feed of users and such reordering would ensure the messages of low-frequency tweeters do not get lost in the stream of tweets. This could also serve as a scoring index for Twitter users to identify users frequently tweeting important messages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03931v1</guid>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gautam Khannaa, Yeliz Yesilada, Sukru Eraslan, Simon Harper</dc:creator>
    </item>
    <item>
      <title>Spiking Neural Network Decoders of Finger Forces from High-Density Intramuscular Microelectrode Arrays</title>
      <link>https://arxiv.org/abs/2509.04088</link>
      <description>arXiv:2509.04088v1 Announce Type: new 
Abstract: Restoring naturalistic finger control in assistive technologies requires the continuous decoding of motor intent with high accuracy, efficiency, and robustness. Here, we present a spike-based decoding framework that integrates spiking neural networks (SNNs) with motor unit activity extracted from high-density intramuscular microelectrode arrays. We demonstrate simultaneous and proportional decoding of individual finger forces from motor unit spike trains during isometric contractions at 15% of maximum voluntary contraction using SNNs. We systematically evaluated alternative SNN decoder configurations and compared two possible input modalities: physiologically grounded motor unit spike trains and spike-encoded intramuscular EMG signals. Through this comparison, we quantified trade-offs between decoding accuracy, memory footprint, and robustness to input errors. The results showed that shallow SNNs can reliably decode finger-level motor intent with competitive accuracy and minimal latency, while operating with reduced memory requirements and without the need for external preprocessing buffers. This work provides a practical blueprint for integrating SNNs into finger-level force decoding systems, demonstrating how the choice of input representation can be strategically tailored to meet application-specific requirements for accuracy, robustness, and memory efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04088v1</guid>
      <category>cs.HC</category>
      <category>eess.SP</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Farah Baracat, Agnese Grison, Dario Farina, Giacomo Indiveri, Elisa Donati</dc:creator>
    </item>
    <item>
      <title>Unobtrusive In-Situ Measurement of Behavior Change by Deep Metric Similarity Learning of Motion Patterns</title>
      <link>https://arxiv.org/abs/2509.04174</link>
      <description>arXiv:2509.04174v1 Announce Type: new 
Abstract: This paper introduces an unobtrusive in-situ measurement method to detect user behavior changes during arbitrary exposures in XR systems. Here, such behavior changes are typically associated with the Proteus effect or bodily affordances elicited by different avatars that the users embody in XR. We present a biometric user model based on deep metric similarity learning, which uses high-dimensional embeddings as reference vectors to identify behavior changes of individual users. We evaluate our model against two alternative approaches: a (non-learned) motion analysis based on central tendencies of movement patterns and subjective post-exposure embodiment questionnaires frequently used in various XR exposures. In a within-subject study, participants performed a fruit collection task while embodying avatars of different body heights (short, actual-height, and tall). Subjective assessments confirmed the effective manipulation of perceived body schema, while the (non-learned) objective analyses of head and hand movements revealed significant differences across conditions. Our similarity learning model trained on the motion data successfully identified the elicited behavior change for various query and reference data pairings of the avatar conditions. The approach has several advantages in comparison to existing methods: 1) In-situ measurement without additional user input, 2) generalizable and scalable motion analysis for various use cases, 3) user-specific analysis on the individual level, and 4) with a trained model, users can be added and evaluated in real time to study how avatar changes affect behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04174v1</guid>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Christian Merz, Lukas Schach, Marie Luisa Fiedler, Jean-Luc Lugrin, Carolin Wienrich, Marc Erich Latoschik</dc:creator>
    </item>
    <item>
      <title>Would I regret being different? The influence of social norms on attitudes toward AI usage</title>
      <link>https://arxiv.org/abs/2509.04241</link>
      <description>arXiv:2509.04241v1 Announce Type: new 
Abstract: Prior research shows that social norms can reduce algorithm aversion, but little is known about how such norms become established. Most accounts emphasize technological and individual determinants, yet AI adoption unfolds within organizational social contexts shaped by peers and supervisors. We ask whether the source of the norm-peers or supervisors-shapes AI usage behavior. This question is practically relevant for organizations seeking to promote effective AI adoption. We conducted an online vignette experiment, complemented by qualitative data on participants' feelings and justifications after (counter-)normative behavior. In line with the theory, counter-normative choices elicited higher regret than norm-adherent choices. On average, choosing AI increased regret compared to choosing an human. This aversion was weaker when AI use was presented as the prevailing norm, indicating a statistically significant interaction between AI use and an AI-favoring norm. Participants also attributed less blame to technology than to humans, which increased regret when AI was chosen over human expertise. Both peer and supervisor influence emerged as relevant factors, though contrary to expectations they did not significantly affect regret. Our findings suggest that regret aversion, embedded in social norms, is a central mechanism driving imitation in AI-related decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04241v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaroslaw Kornowicz, Maurice Pape, Kirsten Thommes</dc:creator>
    </item>
    <item>
      <title>MuMTAffect: A Multimodal Multitask Affective Framework for Personality and Emotion Recognition from Physiological Signals</title>
      <link>https://arxiv.org/abs/2509.04254</link>
      <description>arXiv:2509.04254v1 Announce Type: new 
Abstract: We present MuMTAffect, a novel Multimodal Multitask Affective Embedding Network designed for joint emotion classification and personality prediction (re-identification) from short physiological signal segments. MuMTAffect integrates multiple physiological modalities pupil dilation, eye gaze, facial action units, and galvanic skin response using dedicated, transformer-based encoders for each modality and a fusion transformer to model cross-modal interactions. Inspired by the Theory of Constructed Emotion, the architecture explicitly separates core affect encoding (valence/arousal) from higher-level conceptualization, thereby grounding predictions in contemporary affective neuroscience. Personality trait prediction is leveraged as an auxiliary task to generate robust, user-specific affective embeddings, significantly enhancing emotion recognition performance. We evaluate MuMTAffect on the AFFEC dataset, demonstrating that stimulus-level emotional cues (Stim Emo) and galvanic skin response substantially improve arousal classification, while pupil and gaze data enhance valence discrimination. The inherent modularity of MuMTAffect allows effortless integration of additional modalities, ensuring scalability and adaptability. Extensive experiments and ablation studies underscore the efficacy of our multimodal multitask approach in creating personalized, context-aware affective computing systems, highlighting pathways for further advancements in cross-subject generalisation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04254v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meisam Jamshidi Seikavandi, Fabricio Batista Narcizo, Ted Vucurevich, Andrew Burke Dittberner, Paolo Burelli</dc:creator>
    </item>
    <item>
      <title>HumAIne-Chatbot: Real-Time Personalized Conversational AI via Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2509.04303</link>
      <description>arXiv:2509.04303v1 Announce Type: new 
Abstract: Current conversational AI systems often provide generic, one-size-fits-all interactions that overlook individual user characteristics and lack adaptive dialogue management. To address this gap, we introduce \textbf{HumAIne-chatbot}, an AI-driven conversational agent that personalizes responses through a novel user profiling framework. The system is pre-trained on a diverse set of GPT-generated virtual personas to establish a broad prior over user types. During live interactions, an online reinforcement learning agent refines per-user models by combining implicit signals (e.g. typing speed, sentiment, engagement duration) with explicit feedback (e.g., likes and dislikes). This profile dynamically informs the chatbot dialogue policy, enabling real-time adaptation of both content and style. To evaluate the system, we performed controlled experiments with 50 synthetic personas in multiple conversation domains. The results showed consistent improvements in user satisfaction, personalization accuracy, and task achievement when personalization features were enabled. Statistical analysis confirmed significant differences between personalized and nonpersonalized conditions, with large effect sizes across key metrics. These findings highlight the effectiveness of AI-driven user profiling and provide a strong foundation for future real-world validation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04303v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Georgios Makridis, Georgios Fragiadakis, Jorge Oliveira, Tomaz Saraiva, Philip Mavrepis, Georgios Fatouros, Dimosthenis Kyriazis</dc:creator>
    </item>
    <item>
      <title>Write on Paper, Wrong in Practice: Why LLMs Still Struggle with Writing Clinical Notes</title>
      <link>https://arxiv.org/abs/2509.04340</link>
      <description>arXiv:2509.04340v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are often proposed as tools to streamline clinical documentation, a task viewed as both high-volume and low-risk. However, even seemingly straightforward applications of LLMs raise complex sociotechnical considerations to translate into practice. This case study, conducted at KidsAbility, a pediatric rehabilitation facility in Ontario, Canada examined the use of LLMs to support occupational therapists in reducing documentation burden.We conducted a qualitative study involving 20 clinicians who participated in pilot programs using two AI technologies: a general-purpose proprietary LLM and a bespoke model fine-tuned on proprietary historical documentation.
  Our findings reveal that documentation challenges are sociotechnical in nature, shaped by clinical workflows, organizational policies, and system constraints. Four key themes emerged: (1) the heterogeneity of workflows, (2) the documentation burden is systemic and not directly linked to the creation of any single type of documentation, (3) the need for flexible tools and clinician autonomy, and (4) effective implementation requires mutual learning between clinicians and AI systems.
  While LLMs show promise in easing documentation tasks, their success will depend on flexible, adaptive integration that supports clinician autonomy. Beyond technical performance, sustained adoption will require training programs and implementation strategies that reflect the complexity of clinical environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04340v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kristina L. Kupferschmidt, Kieran O'Doherty, Joshua A. Skorburg</dc:creator>
    </item>
    <item>
      <title>SRWToolkit: An Open Source Wizard of Oz Toolkit to Create Social Robotic Avatars</title>
      <link>https://arxiv.org/abs/2509.04356</link>
      <description>arXiv:2509.04356v1 Announce Type: new 
Abstract: We present SRWToolkit, an open-source Wizard of Oz toolkit designed to facilitate the rapid prototyping of social robotic avatars powered by local large language models (LLMs). Our web-based toolkit enables multimodal interaction through text input, button-activated speech, and wake-word command. The toolkit offers real-time configuration of avatar appearance, behavior, language, and voice via an intuitive control panel. In contrast to prior works that rely on cloud-based LLM services, SRWToolkit emphasizes modularity and ensures on-device functionality through local LLM inference. In our small-scale user study ($n=11$), participants created and interacted with diverse robotic roles (hospital receptionist, mathematics teacher, and driving assistant), which demonstrated positive outcomes in the toolkit's usability, trust, and user experience. The toolkit enables rapid and efficient development of robot characters customized to researchers' needs, supporting scalable research in human-robot interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04356v1</guid>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>2025 International Conference on Social Robotics (ICSR)</arxiv:journal_reference>
      <dc:creator>Atikkhan Faridkhan Nilgar, Kristof Van Laerhoven, Ayub Kinoti</dc:creator>
    </item>
    <item>
      <title>Privacy Perceptions in Robot-Assisted Well-Being Coaching: Examining the Roles of Information Transparency, User Control, and Proactivity</title>
      <link>https://arxiv.org/abs/2509.04358</link>
      <description>arXiv:2509.04358v1 Announce Type: new 
Abstract: Social robots are increasingly recognized as valuable supporters in the field of well-being coaching. They can function as independent coaches or provide support alongside human coaches, and healthcare professionals. In coaching interactions, these robots often handle sensitive information shared by users, making privacy a relevant issue. Despite this, little is known about the factors that shape users' privacy perceptions. This research aims to examine three key factors systematically: (1) the transparency about information usage, (2) the level of specific user control over how the robot uses their information, and (3) the robot's behavioral approach - whether it acts proactively or only responds on demand. Our results from an online study (N = 200) show that even when users grant the robot general access to personal data, they additionally expect the ability to explicitly control how that information is interpreted and shared during sessions. Experimental conditions that provided such control received significantly higher ratings for perceived privacy appropriateness and trust. Compared to user control, the effects of transparency and proactivity on privacy appropriateness perception were low, and we found no significant impact. The results suggest that merely informing users or proactive sharing is insufficient without accompanying user control. These insights underscore the need for further research on mechanisms that allow users to manage robots' information processing and sharing, especially when social robots take on more proactive roles alongside humans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04358v1</guid>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>2025 IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)</arxiv:journal_reference>
      <dc:creator>Atikkhan Faridkhan Nilgar, Manuel Dietrich, Kristof Van Laerhoven</dc:creator>
    </item>
    <item>
      <title>PG-Agent: An Agent Powered by Page Graph</title>
      <link>https://arxiv.org/abs/2509.03536</link>
      <description>arXiv:2509.03536v1 Announce Type: cross 
Abstract: Graphical User Interface (GUI) agents possess significant commercial and social value, and GUI agents powered by advanced multimodal large language models (MLLMs) have demonstrated remarkable potential. Currently, existing GUI agents usually utilize sequential episodes of multi-step operations across pages as the prior GUI knowledge, which fails to capture the complex transition relationship between pages, making it challenging for the agents to deeply perceive the GUI environment and generalize to new scenarios. Therefore, we design an automated pipeline to transform the sequential episodes into page graphs, which explicitly model the graph structure of the pages that are naturally connected by actions. To fully utilize the page graphs, we further introduce Retrieval-Augmented Generation (RAG) technology to effectively retrieve reliable perception guidelines of GUI from them, and a tailored multi-agent framework PG-Agent with task decomposition strategy is proposed to be injected with the guidelines so that it can generalize to unseen scenarios. Extensive experiments on various benchmarks demonstrate the effectiveness of PG-Agent, even with limited episodes for page graph construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03536v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weizhi Chen, Ziwei Wang, Leyang Yang, Sheng Zhou, Xiaoxuan Tang, Jiajun Bu, Yong Li, Wei Jiang</dc:creator>
    </item>
    <item>
      <title>PersonaTeaming: Exploring How Introducing Personas Can Improve Automated AI Red-Teaming</title>
      <link>https://arxiv.org/abs/2509.03728</link>
      <description>arXiv:2509.03728v1 Announce Type: cross 
Abstract: Recent developments in AI governance and safety research have called for red-teaming methods that can effectively surface potential risks posed by AI models. Many of these calls have emphasized how the identities and backgrounds of red-teamers can shape their red-teaming strategies, and thus the kinds of risks they are likely to uncover. While automated red-teaming approaches promise to complement human red-teaming by enabling larger-scale exploration of model behavior, current approaches do not consider the role of identity. As an initial step towards incorporating people's background and identities in automated red-teaming, we develop and evaluate a novel method, PersonaTeaming, that introduces personas in the adversarial prompt generation process to explore a wider spectrum of adversarial strategies. In particular, we first introduce a methodology for mutating prompts based on either "red-teaming expert" personas or "regular AI user" personas. We then develop a dynamic persona-generating algorithm that automatically generates various persona types adaptive to different seed prompts. In addition, we develop a set of new metrics to explicitly measure the "mutation distance" to complement existing diversity measurements of adversarial prompts. Our experiments show promising improvements (up to 144.1%) in the attack success rates of adversarial prompts through persona mutation, while maintaining prompt diversity, compared to RainbowPlus, a state-of-the-art automated red-teaming method. We discuss the strengths and limitations of different persona types and mutation methods, shedding light on future opportunities to explore complementarities between automated and human red-teaming approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03728v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wesley Hanwen Deng, Sunnie S. Y. Kim, Akshita Jha, Ken Holstein, Motahhare Eslami, Lauren Wilcox, Leon A Gatys</dc:creator>
    </item>
    <item>
      <title>Towards an Understanding of Developer Experience-Driven Transparency in Software Ecosystems</title>
      <link>https://arxiv.org/abs/2509.03848</link>
      <description>arXiv:2509.03848v1 Announce Type: cross 
Abstract: Software ecosystems (SECO) have become a dominant paradigm in the software industry, enabling third-party developers to co-create value through complementary components and services. While Developer Experience (DX) is increasingly recognized as critical for sustainable SECO, transparency remains an underexplored factor shaping how developers perceive and interact with ecosystems. Existing studies acknowledge transparency as essential for trust, fairness, and engagement, yet its relationship with DX has not been systematically conceptualized. Hence, this work aims to advance the understanding of transparency in SECO from a developer-centered perspective. To this end, we propose SECO-TransDX (Transparency in Software Ecosystems from a Developer Experience Perspective), a conceptual model that introduces the notion of DX-driven transparency. The model identifies 63 interrelated concepts, including conditioning factors, ecosystem procedures, artifacts, and relational dynamics that influence how transparency is perceived and constructed during developer interactions. SECO-TransDX was built upon prior research and refined through a Delphi study with experts from academia and industry. It offers a structured lens to examine how transparency mediates DX across technical, social, and organizational layers. For researchers, it lays the groundwork for future studies and tool development; for practitioners, it supports the design of trustworthy, developer-centered platforms that improve transparency and foster long-term engagement in SECO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03848v1</guid>
      <category>cs.SE</category>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rodrigo Oliveira Zacarias, Rodrigo Pereira dos Santos, Patricia Lago</dc:creator>
    </item>
    <item>
      <title>The MolecularWeb Universe: Web-Based, Immersive, Multiuser Molecular Graphics And Modeling, for Education and Work in Chemistry, Structural Biology, and Materials Sciences</title>
      <link>https://arxiv.org/abs/2509.04056</link>
      <description>arXiv:2509.04056v1 Announce Type: cross 
Abstract: Molecular visualization software has long supported research and education in chemical and structural sciences, but consumer devices constrained to 2D inputs and outputs pose two major challenges: they poorly convey 3D nature, and 3D manipulation is very difficult. eXtended Reality (XR, including AR and VR) offers new ways to see and interact with molecules in three dimensions. This chapter presents the "MolecularWeb" ecosystem (https://molecularweb.org), a set of web-based tools for immersive visualization, modeling, and simulations, already widely used in education and science communication and now expanding toward research applications. We cover moleculARweb, which provides AR educational activities via phones, tablets, and computers; MolecularWebXR, a multiuser WebXR platform accessible from both headsets and simpler devices, supporting immersive education, outreach, and scientific discussion; and PDB2AR, which enables users to generate custom content for MolecularWebXR and standalone AR/VR. Finally, we introduce a prototype and an upcoming version of HandMol, our latest WebXR software which allows concurrent multiuser immersive visualization and modeling of molecules with bare hands supported by real-time molecular mechanics, natural language input via a language model, and access through both high-end headsets or consumer devices like smartphones and laptops. Together, these tools demonstrate the present and near-future of accessible, interactive molecular science on the web.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04056v1</guid>
      <category>physics.chem-ph</category>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luciano A. Abriata</dc:creator>
    </item>
    <item>
      <title>Towards Stable and Personalised Profiles for Lexical Alignment in Spoken Human-Agent Dialogue</title>
      <link>https://arxiv.org/abs/2509.04104</link>
      <description>arXiv:2509.04104v1 Announce Type: cross 
Abstract: Lexical alignment, where speakers start to use similar words across conversation, is known to contribute to successful communication. However, its implementation in conversational agents remains underexplored, particularly considering the recent advancements in large language models (LLMs). As a first step towards enabling lexical alignment in human-agent dialogue, this study draws on strategies for personalising conversational agents and investigates the construction of stable, personalised lexical profiles as a basis for lexical alignment. Specifically, we varied the amounts of transcribed spoken data used for construction as well as the number of items included in the profiles per part-of-speech (POS) category and evaluated profile performance across time using recall, coverage, and cosine similarity metrics. It was shown that smaller and more compact profiles, created after 10 min of transcribed speech containing 5 items for adjectives, 5 items for conjunctions, and 10 items for adverbs, nouns, pronouns, and verbs each, offered the best balance in both performance and data efficiency. In conclusion, this study offers practical insights into constructing stable, personalised lexical profiles, taking into account minimal data requirements, serving as a foundational step toward lexical alignment strategies in conversational agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04104v1</guid>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-032-02548-7_5</arxiv:DOI>
      <dc:creator>Keara Schaaij, Roel Boumans, Tibor Bosse, Iris Hendrickx</dc:creator>
    </item>
    <item>
      <title>Psychologically Enhanced AI Agents</title>
      <link>https://arxiv.org/abs/2509.04343</link>
      <description>arXiv:2509.04343v1 Announce Type: cross 
Abstract: We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of Large Language Model (LLM) agents through psychologically grounded personality conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method primes agents with distinct personality archetypes via prompt engineering, enabling control over behavior along two foundational axes of human psychology, cognition and affect. We show that such personality priming yields consistent, interpretable behavioral biases across diverse tasks: emotionally expressive agents excel in narrative generation, while analytically primed agents adopt more stable strategies in game-theoretic settings. Our framework supports experimenting with structured multi-agent communication protocols and reveals that self-reflection prior to interaction improves cooperation and reasoning quality. To ensure trait persistence, we integrate the official 16Personalities test for automated verification. While our focus is on MBTI, we show that our approach generalizes seamlessly to other psychological frameworks such as Big Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior design, we establish a foundation for psychologically enhanced AI agents without any fine-tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04343v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.MA</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maciej Besta, Shriram Chandran, Robert Gerstenberger, Mathis Lindner, Marcin Chrapek, Sebastian Hermann Martschat, Taraneh Ghandi, Patrick Iff, Hubert Niewiadomski, Piotr Nyczyk, J\"urgen M\"uller, Torsten Hoefler</dc:creator>
    </item>
    <item>
      <title>No Thoughts Just AI: Biased LLM Recommendations Limit Human Agency in Resume Screening</title>
      <link>https://arxiv.org/abs/2509.04404</link>
      <description>arXiv:2509.04404v1 Announce Type: cross 
Abstract: In this study, we conduct a resume-screening experiment (N=528) where people collaborate with simulated AI models exhibiting race-based preferences (bias) to evaluate candidates for 16 high and low status occupations. Simulated AI bias approximates factual and counterfactual estimates of racial bias in real-world AI systems. We investigate people's preferences for White, Black, Hispanic, and Asian candidates (represented through names and affinity groups on quality-controlled resumes) across 1,526 scenarios and measure their unconscious associations between race and status using implicit association tests (IATs), which predict discriminatory hiring decisions but have not been investigated in human-AI collaboration. When making decisions without AI or with AI that exhibits no race-based preferences, people select all candidates at equal rates. However, when interacting with AI favoring a particular group, people also favor those candidates up to 90% of the time, indicating a significant behavioral shift. The likelihood of selecting candidates whose identities do not align with common race-status stereotypes can increase by 13% if people complete an IAT before conducting resume screening. Finally, even if people think AI recommendations are low quality or not important, their decisions are still vulnerable to AI bias under certain circumstances. This work has implications for people's autonomy in AI-HITL scenarios, AI and work, design and evaluation of AI hiring systems, and strategies for mitigating bias in collaborative decision-making tasks. In particular, organizational and regulatory policy should acknowledge the complex nature of AI-HITL decision making when implementing these systems, educating people who use them, and determining which are subject to oversight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04404v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kyra Wilson, Mattea Sim, Anna-Maria Gueorguieva, Aylin Caliskan</dc:creator>
    </item>
    <item>
      <title>DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation</title>
      <link>https://arxiv.org/abs/2509.04441</link>
      <description>arXiv:2509.04441v1 Announce Type: cross 
Abstract: We introduce perioperation, a paradigm for robotic data collection that sensorizes and records human manipulation while maximizing the transferability of the data to real robots. We implement this paradigm in DEXOP, a passive hand exoskeleton designed to maximize human ability to collect rich sensory (vision + tactile) data for diverse dexterous manipulation tasks in natural environments. DEXOP mechanically connects human fingers to robot fingers, providing users with direct contact feedback (via proprioception) and mirrors the human hand pose to the passive robot hand to maximize the transfer of demonstrated skills to the robot. The force feedback and pose mirroring make task demonstrations more natural for humans compared to teleoperation, increasing both speed and accuracy. We evaluate DEXOP across a range of dexterous, contact-rich tasks, demonstrating its ability to collect high-quality demonstration data at scale. Policies learned with DEXOP data significantly improve task performance per unit time of data collection compared to teleoperation, making DEXOP a powerful tool for advancing robot dexterity. Our project page is at https://dex-op.github.io.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04441v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hao-Shu Fang, Branden Romero, Yichen Xie, Arthur Hu, Bo-Ruei Huang, Juan Alvarez, Matthew Kim, Gabriel Margolis, Kavya Anbarasu, Masayoshi Tomizuka, Edward Adelson, Pulkit Agrawal</dc:creator>
    </item>
    <item>
      <title>Towards softerware: Enabling personalization of interactive data representations for users with disabilities</title>
      <link>https://arxiv.org/abs/2502.18348</link>
      <description>arXiv:2502.18348v3 Announce Type: replace 
Abstract: Accessible design for some may still produce barriers for others. This tension, called access friction, creates challenges for both designers and end-users with disabilities. To address this, we present the concept of softerware, a system design approach that provides end users with agency to meaningfully customize and adapt interfaces to their needs. To apply softerware to visualization, we assembled 195 data visualization customization options centered on the barriers we expect users with disabilities will experience. We built a prototype that applies a subset of these options and interviewed practitioners for feedback. Lastly, we conducted a design probe study with blind and low vision accessibility professionals to learn more about their challenges and visions for softerware. We observed access frictions between our participant's designs and they expressed that for softerware's success, current and future systems must be designed with accessible defaults, interoperability, persistence, and respect for a user's perceived effort-to-outcome ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18348v3</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frank Elavsky, Marita Vindedal, Ted Gies, Patrick Carrington, Dominik Moritz, {\O}ystein Moseng</dc:creator>
    </item>
    <item>
      <title>Human causal perception in a cube-stacking task</title>
      <link>https://arxiv.org/abs/2505.05923</link>
      <description>arXiv:2505.05923v2 Announce Type: replace 
Abstract: In intuitive physics the process of stacking cubes has become a paradigmatic, canonical task. Even though it gets employed in various shades and complexities, the very fundamental setting with two cubes has not been thoroughly investigated. Furthermore, the majority of settings feature only a reduced, one dimensional (1D) decision space. In this paper an experiment is conducted in which participants judge the stability of two cubes stacked on top of each other. It is performed in the full 3D setting which features a 2D decision surface. The analysis yield a shape of a rotated square for the perceived stability area instead of the commonly reported safety margin in 1D. This implies a more complex decision behavior in human than previously assumed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05923v2</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolai Bahr, Christoph Zetzsche</dc:creator>
    </item>
    <item>
      <title>StreetViewAI: Making Street View Accessible Using Context-Aware Multimodal AI</title>
      <link>https://arxiv.org/abs/2508.08524</link>
      <description>arXiv:2508.08524v3 Announce Type: replace 
Abstract: Interactive streetscape mapping tools such as Google Street View (GSV) and Meta Mapillary enable users to virtually navigate and experience real-world environments via immersive 360{\deg} imagery but remain fundamentally inaccessible to blind users. We introduce StreetViewAI, the first-ever accessible street view tool, which combines context-aware, multimodal AI, accessible navigation controls, and conversational speech. With StreetViewAI, blind users can virtually examine destinations, engage in open-world exploration, or virtually tour any of the over 220 billion images and 100+ countries where GSV is deployed. We iteratively designed StreetViewAI with a mixed-visual ability team and performed an evaluation with eleven blind users. Our findings demonstrate the value of an accessible street view in supporting POI investigations and remote route planning. We close by enumerating key guidelines for future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08524v3</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3746059.3747756</arxiv:DOI>
      <dc:creator>Jon E. Froehlich, Alexander Fiannaca, Nimer Jaber, Victor Tsaran, Shaun Kane</dc:creator>
    </item>
    <item>
      <title>Autonomation, Not Automation: Activities and Needs of European Fact-checkers as a Basis for Designing Human-Centered AI Systems</title>
      <link>https://arxiv.org/abs/2211.12143</link>
      <description>arXiv:2211.12143v3 Announce Type: replace-cross 
Abstract: To mitigate the negative effects of false information more effectively, the development of Artificial Intelligence (AI) systems to assist fact-checkers is needed. Nevertheless, the lack of focus on the needs of these stakeholders results in their limited acceptance and skepticism toward automating the whole fact-checking process. In this study, we conducted semi-structured in-depth interviews with Central European fact-checkers. Their activities and problems were analyzed using iterative content analysis. The most significant problems were validated with a survey of European fact-checkers, in which we collected 24 responses from 20 countries, i.e., 62% of active European signatories of the International Fact-Checking Network (IFCN). Our contributions include an in-depth examination of the variability of fact-checking work in non-English-speaking regions, which still remained largely uncovered. By aligning them with the knowledge from prior studies, we created conceptual models that help to understand the fact-checking processes. In addition, we mapped our findings on the fact-checkers' activities and needs to the relevant tasks for AI research, while providing a discussion on three AI tasks that were not covered by previous similar studies. The new opportunities identified for AI researchers and developers have implications for the focus of AI research in this domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.12143v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3764592</arxiv:DOI>
      <dc:creator>Andrea Hrckova, Robert Moro, Ivan Srba, Jakub Simko, Maria Bielikova</dc:creator>
    </item>
    <item>
      <title>Beyond-Voice: Towards Continuous 3D Hand Pose Tracking on Commercial Home Assistant Devices</title>
      <link>https://arxiv.org/abs/2306.17477</link>
      <description>arXiv:2306.17477v3 Announce Type: replace-cross 
Abstract: The surging popularity of home assistants and their voice user interface (VUI) have made them an ideal central control hub for smart home devices. However, current form factors heavily rely on VUI, which poses accessibility and usability issues; some latest ones are equipped with additional cameras and displays, which are costly and raise privacy concerns. These concerns jointly motivate Beyond-Voice, a novel high-fidelity acoustic sensing system that allows commodity home assistant devices to track and reconstruct hand poses continuously. It transforms the home assistant into an active sonar system using its existing onboard microphones and speakers. We feed a high-resolution range profile to the deep learning model that can analyze the motions of multiple body parts and predict the 3D positions of 21 finger joints, bringing the granularity for acoustic hand tracking to the next level. It operates across different environments and users without the need for personalized training data. A user study with 11 participants in 3 different environments shows that Beyond-Voice can track joints with an average mean absolute error of 16.47mm without any training data provided by the testing subject.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.17477v3</guid>
      <category>cs.SD</category>
      <category>cs.HC</category>
      <category>eess.AS</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/IPSN61024.2024.00017</arxiv:DOI>
      <dc:creator>Yin Li, Rohan Reddy, Cheng Zhang, Rajalakshmi Nandakumar</dc:creator>
    </item>
    <item>
      <title>(Ir)rationality in AI: State of the Art, Research Challenges and Open Questions</title>
      <link>https://arxiv.org/abs/2311.17165</link>
      <description>arXiv:2311.17165v4 Announce Type: replace-cross 
Abstract: The concept of rationality is central to the field of artificial intelligence (AI). Whether we are seeking to simulate human reasoning, or trying to achieve bounded optimality, our goal is generally to make artificial agents as rational as possible. Despite the centrality of the concept within AI, there is no unified definition of what constitutes a rational agent. This article provides a survey of rationality and irrationality in AI, and sets out the open questions in this area. We consider how the understanding of rationality in other fields has influenced its conception within AI, in particular work in economics, philosophy and psychology. Focusing on the behaviour of artificial agents, we examine irrational behaviours that can prove to be optimal in certain scenarios. Some methods have been developed to deal with irrational agents, both in terms of identification and interaction, however work in this area remains limited. Methods that have up to now been developed for other purposes, namely adversarial scenarios, may be adapted to suit interactions with artificial agents. We further discuss the interplay between human and artificial agents, and the role that rationality plays within this interaction; many questions remain in this area, relating to potentially irrational behaviour of both humans and artificial agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17165v4</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10462-025-11341-4</arxiv:DOI>
      <arxiv:journal_reference>Artificial Intelligence Review 58, 352 (2025)</arxiv:journal_reference>
      <dc:creator>Olivia Macmillan-Scott, Mirco Musolesi</dc:creator>
    </item>
    <item>
      <title>Fuzzy to Clear: Elucidating the Threat Hunter Cognitive Process and Cognitive Support Needs</title>
      <link>https://arxiv.org/abs/2408.04348</link>
      <description>arXiv:2408.04348v3 Announce Type: replace-cross 
Abstract: With security threats increasing in frequency and severity, it is critical that we consider the important role of threat hunters. These highly-trained security professionals learn to see, identify, and intercept security threats. Many recent works and existing tools in cybersecurity are focused on automating the threat hunting process, often overlooking the critical human element. Our study shifts this paradigm by emphasizing a human-centered approach to understanding the lived experiences of threat hunters. By observing threat hunters during hunting sessions and analyzing the rich insights they provide, we seek to advance the understanding of their cognitive processes and the tool support they need. Through an in-depth observational study of threat hunters, we introduce a model of how they build and refine their mental models during threat hunting sessions. We also present 23 themes that provide a foundation to better understand threat hunter needs and suggest five actionable design propositions to enhance the tools that support them. Through these contributions, our work enriches the theoretical understanding of threat hunting and provides practical insights for designing more effective, human-centered cybersecurity tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04348v3</guid>
      <category>cs.CR</category>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alessandra Maciel Paz Milani, Arty Starr, Samantha Hill, Callum Curtis, Norman Anderson, David Moreno-Lumbreras, Margaret-Anne Storey</dc:creator>
    </item>
    <item>
      <title>Emancipatory Information Retrieval</title>
      <link>https://arxiv.org/abs/2501.19241</link>
      <description>arXiv:2501.19241v5 Announce Type: replace-cross 
Abstract: Our world today is facing a confluence of several mutually reinforcing crises each of which intersects with concerns of social justice and emancipation. This paper is a provocation for the role of computer-mediated information access in our emancipatory struggles. We define emancipatory information retrieval as the study and development of information access methods that challenge various forms of human oppression, and situates its activities within broader collective emancipatory praxis. The term "emancipatory" here signifies the moral concerns of universal humanization of all peoples and the elimination of oppression to create the conditions under which we can collectively flourish. To develop an emancipatory research agenda for information retrieval (IR), in this paper we speculate about the practices that the community can adopt, enumerate some of the projects that the field should undertake, and discuss provocations to spark new ideas and directions for research. We challenge the field of IR research to embrace humanistic values and commit to universal emancipation and social justice. We also invite scholars from fields such as human-computer interaction, information sciences, media studies, design, science and technology studies, social and political sciences, philosophy, law, environmental sciences, public health, educational sciences, as well as legal and policy experts, civil rights advocates, social justice activists and movement organizers, and artists to join us in realizing this transformation. In this process, we must both imagine post-oppressive worlds, and reimagine the role of IR in that world and in the journey that leads us there.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19241v5</guid>
      <category>cs.IR</category>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bhaskar Mitra</dc:creator>
    </item>
    <item>
      <title>POET: Supporting Prompting Creativity and Personalization with Automated Expansion of Text-to-Image Generation</title>
      <link>https://arxiv.org/abs/2504.13392</link>
      <description>arXiv:2504.13392v2 Announce Type: replace-cross 
Abstract: State-of-the-art visual generative AI tools hold immense potential to assist users in the early ideation stages of creative tasks -- offering the ability to generate (rather than search for) novel and unprecedented (instead of existing) images of considerable quality that also adhere to boundless combinations of user specifications. However, many large-scale text-to-image systems are designed for broad applicability, yielding conventional output that may limit creative exploration. They also employ interaction methods that may be difficult for beginners. Given that creative end users often operate in diverse, context-specific ways that are often unpredictable, more variation and personalization are necessary. We introduce POET, a real-time interactive tool that (1) automatically discovers dimensions of homogeneity in text-to-image generative models, (2) expands these dimensions to diversify the output space of generated images, and (3) learns from user feedback to personalize expansions. An evaluation with 28 users spanning four creative task domains demonstrated POET's ability to generate results with higher perceived diversity and help users reach satisfaction in fewer prompts during creative tasks, thereby prompting them to deliberate and reflect more on a wider range of possible produced results during the co-creative process. Focusing on visual creativity, POET offers a first glimpse of how interaction techniques of future text-to-image generation tools may support and align with more pluralistic values and the needs of end users during the ideation stages of their work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13392v2</guid>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evans Xu Han, Alice Qian Zhang, Haiyi Zhu, Hong Shen, Paul Pu Liang, Jane Hsieh</dc:creator>
    </item>
    <item>
      <title>Pilot Study on Generative AI and Critical Thinking in Higher Education Classrooms</title>
      <link>https://arxiv.org/abs/2509.00167</link>
      <description>arXiv:2509.00167v2 Announce Type: replace-cross 
Abstract: Generative AI (GAI) tools have seen rapid adoption in educational settings, yet their role in fostering critical thinking remains underexplored. While previous studies have examined GAI as a tutor for specific lessons or as a tool for completing assignments, few have addressed how students critically evaluate the accuracy and appropriateness of GAI-generated responses. This pilot study investigates students' ability to apply structured critical thinking when assessing Generative AI outputs in introductory Computational and Data Science courses. Given that GAI tools often produce contextually flawed or factually incorrect answers, we designed learning activities that require students to analyze, critique, and revise AI-generated solutions. Our findings offer initial insights into students' ability to engage critically with GAI content and lay the groundwork for more comprehensive studies in future semesters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00167v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>stat.AP</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>W. F. Lamberti, S. R. Lawrence, D. White, S. Kim, S. Abdullah</dc:creator>
    </item>
    <item>
      <title>TimeCopilot</title>
      <link>https://arxiv.org/abs/2509.00616</link>
      <description>arXiv:2509.00616v2 Announce Type: replace-cross 
Abstract: We introduce TimeCopilot, the first open-source agentic framework for forecasting that combines multiple Time Series Foundation Models (TSFMs) with Large Language Models (LLMs) through a single unified API. TimeCopilot automates the forecasting pipeline: feature analysis, model selection, cross-validation, and forecast generation, while providing natural language explanations and supporting direct queries about the future. The framework is LLM-agnostic, compatible with both commercial and open-source models, and supports ensembles across diverse forecasting families. Results on the large-scale GIFT-Eval benchmark show that TimeCopilot achieves state-of-the-art probabilistic forecasting performance at low cost. Our framework provides a practical foundation for reproducible, explainable, and accessible agentic forecasting systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00616v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Azul Garza, Rene\'e Rosillo</dc:creator>
    </item>
    <item>
      <title>Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models</title>
      <link>https://arxiv.org/abs/2509.01909</link>
      <description>arXiv:2509.01909v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) typically deploy safety mechanisms to prevent harmful content generation. Most current approaches focus narrowly on risks posed by malicious actors, often framing risks as adversarial events and relying on defensive refusals. However, in real-world settings, risks also come from non-malicious users seeking help while under psychological distress (e.g., self-harm intentions). In such cases, the model's response can strongly influence the user's next actions. Simple refusals may lead them to repeat, escalate, or move to unsafe platforms, creating worse outcomes. We introduce Constructive Safety Alignment (CSA), a human-centric paradigm that protects against malicious misuse while actively guiding vulnerable users toward safe and helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic anticipation of user reactions, fine-grained risk boundary discovery, and interpretable reasoning control, turning safety into a trust-building process. Oy1 achieves state-of-the-art safety among open models while retaining high general capabilities. On our Constructive Benchmark, it shows strong constructive engagement, close to GPT-5, and unmatched robustness on the Strata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from refusal-first to guidance-first safety, CSA redefines the model-user relationship, aiming for systems that are not just safe, but meaningfully helpful. We release Oy1, code, and the benchmark to support responsible, user-centered AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01909v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.SC</category>
      <pubDate>Fri, 05 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ranjie Duan, Jiexi Liu, Xiaojun Jia, Shiji Zhao, Ruoxi Cheng, Fengxiang Wang, Cheng Wei, Yong Xie, Chang Liu, Defeng Li, Yinpeng Dong, Yichi Zhang, Yuefeng Chen, Chongwen Wang, Xingjun Ma, Xingxing Wei, Yang Liu, Hang Su, Jun Zhu, Xinfeng Li, Yitong Sun, Jie Zhang, Jinzhao Hu, Sha Xu, Yitong Yang, Jialing Tao, Hui Xue</dc:creator>
    </item>
  </channel>
</rss>
