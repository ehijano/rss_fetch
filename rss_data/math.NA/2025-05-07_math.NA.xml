<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 May 2025 01:43:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A variational multiscale approach to goal-oriented error estimation in finite element analysis of convection-diffusion-reaction equation problems</title>
      <link>https://arxiv.org/abs/2505.02946</link>
      <description>arXiv:2505.02946v1 Announce Type: new 
Abstract: This paper presents a goal-oriented a posteriori error estimation framework for linear functionals in the stabilized finite element discretization of the stationary convection-diffusion-reaction (CDR) equation. The theoretical framework for error estimation is based on the variational multiscale (VMS) concept, where the solution is decomposed into resolved (finite element) and unresolved (sub-grid) scales. In this work, we propose an orthogonal sub-grid scale (OSGS) method for a goal-oriented error estimation in VMS discretizations. In the OSGS approach, the space of the sub-grid scales (SGSs) is orthogonal to the finite element space. The error is estimated in the quantity of interest, given by the linear functional $Q(u)$ of the unknown $u$. If the SGS $u'$ is estimated, the error in the quantity of interest can be approximated by $Q(u')$. Our approach is compared with a duality-based a posteriori error estimation method, which requires the solution of an additional auxiliary problem. The results indicate that both methods yield similar error estimates, whereas the VMS-based explicit approach is computationally less expensive than the duality-based implicit approach. Numerical tests demonstrated the effectiveness of our proposed error estimation techniques in terms of the quantity of interest functionals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02946v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sheraz Ahmed Khan, Ramon Codina, Hauke Gravenkamp</dc:creator>
    </item>
    <item>
      <title>$\mathcal{H}_2$-optimal model reduction of linear quadratic-output systems by multivariate rational interpolation</title>
      <link>https://arxiv.org/abs/2505.03057</link>
      <description>arXiv:2505.03057v1 Announce Type: new 
Abstract: This paper addresses the $\mathcal{H}_2$-optimal approximation of linear dynamical systems with quadratic-output functions, also known as linear quadratic-output systems. Our major contributions are threefold. First, we derive interpolation-based first-order optimality conditions for the linear quadratic-output $\mathcal{H}_2$ minimization problem. These conditions correspond to the mixed-multipoint tangential interpolation of the full-order linear- and quadratic-output transfer functions, and generalize the Meier-Luenberger optimality framework for the $\mathcal{H}_2$-optimal model reduction of linear time-invariant systems. Second, given the interpolation data, we show how to enforce these mixed-multipoint tangential interpolation conditions explicitly by Petrov-Galerkin projection of the full-order model matrices. Third, to find the optimal interpolation data, we build on this projection framework and propose a generalization of the iterative rational Krylov algorithm for the $\mathcal{H}_2$-optimal model reduction of linear quadratic-output systems, called LQO-IRKA. Upon convergence, LQO-IRKA produces a reduced linear quadratic-output system that satisfies the interpolatory optimality conditions. The method only requires solving shifted linear systems and matrix-vector products, thus making it suitable for large-scale problems. Numerical examples are included to illustrate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03057v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sean Reiter, Ion Victor Gosea, Igor Pontes Duff, Serkan Gugercin</dc:creator>
    </item>
    <item>
      <title>Layer Potential Methods for Doubly-Periodic Harmonic Functions</title>
      <link>https://arxiv.org/abs/2505.03074</link>
      <description>arXiv:2505.03074v1 Announce Type: new 
Abstract: We develop and analyze layer potential methods to represent harmonic functions on finitely-connected tori (i.e., doubly-periodic harmonic functions). The layer potentials are expressed in terms of a doubly-periodic and non-harmonic Green's function that can be explicitly written in terms of the Jacobi theta function or a modified Weierstrass sigma function. Extending results for finitely-connected Euclidean domains, we prove that the single- and double-layer potential operators are compact linear operators and derive relevant limiting properties at the boundary. We show that when the boundary has more than one connected component, the Fredholm operator of the second kind associated with the double-layer potential operator has a non-trivial null space, which can be explicitly constructed. Finally, we apply our developed theory to obtain solutions to the Dirichlet and Neumann boundary value problems, as well as the Steklov eigenvalue problem. We implement the developed methods using Nystr\"om discretization and find approximate solutions for these problems in several numerical examples. Our method avoids a lattice sum of the free space Green's function, is shown to be spectrally convergent, and has a faster convergence rate than the method of particular solutions for problems on tori with irregularly shaped holes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03074v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bohyun Kim, Braxton Osting</dc:creator>
    </item>
    <item>
      <title>Analysis of beam hardening streaks in tomography</title>
      <link>https://arxiv.org/abs/2505.03095</link>
      <description>arXiv:2505.03095v1 Announce Type: new 
Abstract: The mathematical foundation of X-ray CT is based on the assumption that by measuring the attenuation of X-rays passing through an object, one can recover the integrals of the attenuation coefficient $\mu(x)$ along a sufficiently rich family of lines $L$, $\int_L \mu(x) \text{d} x$. This assumption is inaccurate because the energy spectrum of an X-ray beam in a typical CT scanner is wide. At the same time, the X-ray attenuation coefficient of most materials is energy-dependent, and this dependence varies among materials. Thus, reconstruction from X-ray CT data is a nonlinear problem. If the nonlinear nature of CT data is ignored and a conventional linear reconstruction formula is used, which is frequently the case, the resulting image contains beam-hardening artifacts such as streaks. In this work, we describe the nonlinearity of CT data using the conventional model accepted by all CT practitioners. Our main result is the characterization of streak artifacts caused by nonlinearity. We also obtain an explicit expression for the leading singular behavior of the artifacts. Finally, a numerical experiment is conducted to validate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03095v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Katsevich</dc:creator>
    </item>
    <item>
      <title>Well-balanced POD-based reduced-order models for finite volume approximation of hyperbolic balance laws</title>
      <link>https://arxiv.org/abs/2505.03237</link>
      <description>arXiv:2505.03237v1 Announce Type: new 
Abstract: This paper introduces a reduced-order modeling approach based on finite volume methods for hyperbolic systems, combining Proper Orthogonal Decomposition (POD) with the Discrete Empirical Interpolation Method (DEIM) and Proper Interval Decomposition (PID). Applied to systems such as the transport equation with source term, non-homogeneous Burgers equation, and shallow water equations with non-flat bathymetry and Manning friction, this method achieves significant improvements in computational efficiency and accuracy compared to previous time-averaging techniques. A theoretical result justifying the use of well-balanced Full-Order Models (FOMs) is presented. Numerical experiments validate the approach, demonstrating its accuracy and efficiency. Furthermore, the question of prediction of solutions for systems that depend on some physical parameters is also addressed, and a sensitivity analysis on POD parameters confirms the model's robustness and efficiency in this case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03237v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cam.2025.116735</arxiv:DOI>
      <dc:creator>I. G\'omez-Bueno, E. D. Fern\'andez-Nieto, S. Rubino</dc:creator>
    </item>
    <item>
      <title>Geometric means of HPD GLT matrix-sequences: a maximal result beyond invertibility assumptions on the GLT symbols</title>
      <link>https://arxiv.org/abs/2505.03256</link>
      <description>arXiv:2505.03256v1 Announce Type: new 
Abstract: In the current work, we consider the study of the spectral distribution of the geometric mean matrix-sequence of two matrix-sequences $\{G(A_n, B_n)\}_n$ formed by Hermitian Positive Definite (HPD) matrices,
  assuming that the two input matrix-sequences $\{A_n\}_n, \{B_n\}_n$ belong to the same $d$-level $r$-block Generalized Locally Toeplitz (GLT) $\ast$-algebra with $d,r\ge 1$ and with GLT symbols $\kappa, \xi$. Building on recent results in the literature, we examine whether the assumption that at least one of the input GLT symbols is invertible almost everywhere (a.e.) is necessary. Since inversion is mainly required due to the non-commutativity of the matrix product, it was conjectured that the hypothesis on the invertibility of the GLT symbols can be removed. In fact, we prove the conjectured statement that is \[ \{G(A_n, B_n)\}_n \sim_{\mathrm{GLT}} (\kappa \xi)^{1/2} \] when the symbols $\kappa, \xi$ commute, which implies the important case where $r=1$ and $d \geq 1 $, while the statement is generally false or even not well posed when the symbols are not invertible a.e. and do not commute. In fact, numerical experiments are conducted in the case where the two symbols do not commute, showing that the main results of the present work are maximal. Further numerical experiments, visualizations, and conclusions end the present contribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03256v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asiim Ilyas, Muhammad Faisal Khan, Valerio Loi, Stefano Serra-Capizzano</dc:creator>
    </item>
    <item>
      <title>Safer Prompts: Reducing IP Risk in Visual Generative AI</title>
      <link>https://arxiv.org/abs/2505.03338</link>
      <description>arXiv:2505.03338v1 Announce Type: new 
Abstract: Visual Generative AI models have demonstrated remarkable capability in generating high-quality images from simple inputs like text prompts. However, because these models are trained on images from diverse sources, they risk memorizing and reproducing specific content, raising concerns about intellectual property (IP) infringement. Recent advances in prompt engineering offer a cost-effective way to enhance generative AI performance. In this paper, we evaluate the effectiveness of prompt engineering techniques in mitigating IP infringement risks in image generation. Our findings show that Chain of Thought Prompting and Task Instruction Prompting significantly reduce the similarity between generated images and the training data of diffusion models, thereby lowering the risk of IP infringement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03338v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lena Reissinger, Yuanyuan Li, Anna-Carolina Haensch, Neeraj Sarna</dc:creator>
    </item>
    <item>
      <title>Variable projection framework for the reduced-rank matrix approximation problem by weighted least-squares</title>
      <link>https://arxiv.org/abs/2505.03347</link>
      <description>arXiv:2505.03347v1 Announce Type: new 
Abstract: In this monograph, we review and develop variable projection Gauss-Newton, Levenberg-Marquardt and Newton methods for the Weighted Low-Rank Approximation (WLRA) problem, which has now an increasing number of applications in many scientific fields. Particular attention is drawn at the robustness, efficiency and scalability of these variable projection second-order algorithms such that they can be used also on larger datasets now commonly found in many practical problems for which only first-order algorithms based on sequential repetitions of local optimization (e.g., majorization, Expectation-Maximization or alternating least-squares methods) or variations of gradient descent (e.g., conjugate, proximal or stochastic gradient descent methods), or hybrid algorithms from these two classes of methods, were only feasible due to their lower cost and memory requirement per iteration. In parallel with this review of variable projection algorithms, we develop new formulae for the Jacobian and Hessian matrices involved in these variable projection methods and demonstrate their very specific properties such as the uniform rank deficiency of the Jacobian matrix or the rank deficiency of the Hessian matrix at the (local) minimizers of the cost function associated with the WLRA problem. These systematic deficiencies must be taken into account in any practical implementations of the algorithms. These different properties and the very particular geometry of the WLRA problem have not been well appreciated in the past and have been the main obstacles in the development of robust variable projection second-order algorithms for solving the WLRA problem. In addition, we demonstrate that the variable projection framework gives original insights on the solvability, the landscape and the non-smoothness of the WLRA problem. It also helps to describe the tight links between previously unrelated methods, which have been proposed to solve it. Specifically, we illustrate the closed links between the variable projection framework and Riemannian optimization on the Grassmann manifold for the WLRA problem. We expect that software's developers and practitioners in different fields such as computer vision, signal processing, recommender systems, machine learning, multivariate statistics and geophysical sciences will benefit from the results in this monograph in order to devise more robust and accurate algorithms to solve the WLRA problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03347v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pascal Terray (LOCEAN, IRD)</dc:creator>
    </item>
    <item>
      <title>Hierarchical dynamic domain decomposition for the multiscale Boltzmann equation</title>
      <link>https://arxiv.org/abs/2505.03360</link>
      <description>arXiv:2505.03360v1 Announce Type: new 
Abstract: In this work, we present a hierarchical domain decomposition method for the multi-scale Boltzmann equation based on moment realizability matrices, a concept introduced by Levermore, Morokoff, and Nadiga in \cite{lev-mor-nad-1998}. This criterion is used to dynamically partition the two-dimensional spatial domain into three regimes: the Euler regime, an intermediate kinetic regime governed by the ES-BGK model, and the full Boltzmann regime. The key advantage of this approach lies in the use of Euler equations in regions where the flow is near hydrodynamic equilibrium, the ES-BGK model in moderately non-equilibrium regions where a fluid description is insufficient but full kinetic resolution is not yet necessary, and the full Boltzmann solver where strong non-equilibrium effects dominate, such as near shocks and boundary layers. This allows for both high accuracy and significant computational savings, as the Euler solver and the ES-BGK models are considerably cheaper than the full kinetic Boltzmann model.
  To ensure accurate and efficient coupling between regimes, we employ asymptotic-preserving (AP) numerical schemes and fast spectral solvers for evaluating the Boltzmann collision operator. Among the main novelties of this work are the use of a full 2D spatial and 3D velocity decomposition, the integration of three distinct physical regimes within a unified solver framework, and a parallelized implementation exploiting CPU multithreading. This combination enables robust and scalable simulation of multiscale kinetic flows with complex geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03360v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Domenico Caparello, Lorenzo Pareschi, Thomas Rey</dc:creator>
    </item>
    <item>
      <title>An Enriched Immersed Finite Element Method for 3D Interface Problems</title>
      <link>https://arxiv.org/abs/2505.03598</link>
      <description>arXiv:2505.03598v1 Announce Type: new 
Abstract: We introduce an enriched immersed finite element method for addressing interface problems characterized by general non-homogeneous jump conditions. Unlike many existing unfitted mesh methods, our approach incorporates a homogenization concept. The IFE trial function set is composed of two components: the standard homogeneous IFE space and additional enrichment IFE functions. These enrichment functions are directly determined by the jump data, without adding extra degrees of freedom to the system. Meanwhile, the homogeneous IFE space is isomorphic to the standard finite element space on the same mesh. This isomorphism remains stable regardless of interface location relative to the mesh, ensuring optimal $\mathcal{O}(h^2)$ conditioning that is independent of the interface location and facilitates an immediate development of a multigrid fast solver; namely the iteration numbers are independent of not only the mesh size but also the relative interface location. Theoretical analysis and extensive numerical experiments are carried out in the efforts to demonstrate these features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03598v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ruchi Guo, Xu Zhang</dc:creator>
    </item>
    <item>
      <title>Numerical Reconstruction and Analysis of Backward Semilinear Subdiffusion Problems</title>
      <link>https://arxiv.org/abs/2505.03625</link>
      <description>arXiv:2505.03625v1 Announce Type: new 
Abstract: This paper aims to develop and analyze a numerical scheme for solving the backward problem of semilinear subdiffusion equations. We establish the existence, uniqueness, and conditional stability of the solution to the inverse problem by applying the smoothing and asymptotic properties of solution operators and constructing a fixed-point iteration. This derived conditional stability further inspires a numerical reconstruction scheme. To address the mildly ill-posed nature of the problem, we employ the quasi-boundary value method for regularization. A fully discrete scheme is proposed, utilizing the finite element method for spatial discretization and convolution quadrature for temporal discretization. A thorough error analysis of the resulting discrete system is provided for both smooth and nonsmooth data. This analysis relies on the smoothing properties of discrete solution operators, some nonstandard error estimates optimal with respect to data regularity in the direct problem, and the arguments used in stability analysis. The derived a priori error estimate offers guidance for selecting the regularization parameter and discretization parameters based on the noise level. Moreover, we propose an easy-to-implement iterative algorithm for solving the fully discrete scheme and prove its linear convergence. Numerical examples are provided to illustrate the theoretical estimates and demonstrate the necessity of the assumption required in the analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03625v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xu Wu, Jiang Yang, Zhi Zhou</dc:creator>
    </item>
    <item>
      <title>Parallel GPU-Accelerated Randomized Construction of Approximate Cholesky Preconditioners</title>
      <link>https://arxiv.org/abs/2505.02977</link>
      <description>arXiv:2505.02977v1 Announce Type: cross 
Abstract: We introduce a parallel algorithm to construct a preconditioner for solving a large, sparse linear system where the coefficient matrix is a Laplacian matrix (a.k.a., graph Laplacian). Such a linear system arises from applications such as discretization of a partial differential equation, spectral graph partitioning, and learning problems on graphs. The preconditioner belongs to the family of incomplete factorizations and is purely algebraic. Unlike traditional incomplete factorizations, the new method employs randomization to determine whether or not to keep fill-ins, i.e., newly generated nonzero elements during Gaussian elimination. Since the sparsity pattern of the randomized factorization is unknown, computing such a factorization in parallel is extremely challenging, especially on many-core architectures such as GPUs. Our parallel algorithm dynamically computes the dependency among row/column indices of the Laplacian matrix to be factorized and processes the independent indices in parallel. Furthermore, unlike previous approaches, our method requires little pre-processing time. We implemented the parallel algorithm for multi-core CPUs and GPUs, and we compare their performance to other state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02977v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyu Liang, Chao Chen, Yotam Yaniv, Hengrui Luo, David Tench, Xiaoye S. Li, Aydin Buluc, James Demmel</dc:creator>
    </item>
    <item>
      <title>Asymptotically short generalizations of $t$-design curves</title>
      <link>https://arxiv.org/abs/2505.03056</link>
      <description>arXiv:2505.03056v1 Announce Type: cross 
Abstract: Ehler and Gr\"{o}chenig posed the question of finding $t$-design curves $\gamma_t$$\unicode{x2013}$curves whose associated line integrals exactly average all degree at most $t$ polynomials$\unicode{x2013}$on $S^d$ of asymptotically optimal arc length $\ell(\gamma_t)\asymp t^{d-1}$ as $t\to\infty$. This work investigates analogues of this question for $\textit{weighted}$ and $\textit{$\varepsilon_t$-approximate $t$-design curves}$, proving existence of such curves $\gamma_t$ on $S^d$ of arc length $\ell(\gamma_t)\asymp t^{d-1}$ as $t\to\infty$ for all $d\in\Bbb N_+$ in the weighted setting (in which case such curves are asymptotically optimal) and all odd $d\in\Bbb N_+$ in the approximate setting (where we have $\varepsilon_t\asymp1/t$ as $t\to\infty$). Formulas for such weighted $t$-design curves for $d\in\{2,3\}$ are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03056v1</guid>
      <category>math.MG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ayodeji Lindblad</dc:creator>
    </item>
    <item>
      <title>A Regeneration-based a Posteriori Error Bound for a Markov Chain Stationary Distribution Truncation Algorithm</title>
      <link>https://arxiv.org/abs/2505.03157</link>
      <description>arXiv:2505.03157v1 Announce Type: cross 
Abstract: When the state space of a discrete state space positive recurrent Markov chain is infinite or very large, it becomes necessary to truncate the state space in order to facilitate numerical computation of the stationary distribution. This paper develops a new approach for bounding the truncation error that arises when computing approximations to the stationary distribution. This rigorous a posteriori error bound exploits the regenerative structure of the chain and assumes knowledge of a Lyapunov function. Because the bound is a posteriori (and leverages the computations done to calculate the stationary distribution itself), it tends to be much tighter than a priori bounds. The bound decomposes the regenerative cycle into a random number of excursions from a set $K$ defined in terms of the Lyapunov function into the complement of the truncation set $A$. The bound can be easily computed, and does not (for example) involve a linear program, as do some other error bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03157v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter W. Glynn, Zeyu Zheng</dc:creator>
    </item>
    <item>
      <title>Transformers for Learning on Noisy and Task-Level Manifolds: Approximation and Generalization Insights</title>
      <link>https://arxiv.org/abs/2505.03205</link>
      <description>arXiv:2505.03205v1 Announce Type: cross 
Abstract: Transformers serve as the foundational architecture for large language and video generation models, such as GPT, BERT, SORA and their successors. Empirical studies have demonstrated that real-world data and learning tasks exhibit low-dimensional structures, along with some noise or measurement error. The performance of transformers tends to depend on the intrinsic dimension of the data/tasks, though theoretical understandings remain largely unexplored for transformers. This work establishes a theoretical foundation by analyzing the performance of transformers for regression tasks involving noisy input data on a manifold. Specifically, the input data are in a tubular neighborhood of a manifold, while the ground truth function depends on the projection of the noisy data onto the manifold. We prove approximation and generalization errors which crucially depend on the intrinsic dimension of the manifold. Our results demonstrate that transformers can leverage low-complexity structures in learning task even when the input data are perturbed by high-dimensional noise. Our novel proof technique constructs representations of basic arithmetic operations by transformers, which may hold independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03205v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaiming Shen, Alex Havrilla, Rongjie Lai, Alexander Cloninger, Wenjing Liao</dc:creator>
    </item>
    <item>
      <title>Fully discrete backward error analysis for the midpoint rule applied to the nonlinear Schroedinger equation</title>
      <link>https://arxiv.org/abs/2505.03271</link>
      <description>arXiv:2505.03271v1 Announce Type: cross 
Abstract: The use of symplectic numerical schemes on Hamiltonian systems is widely known to lead to favorable long-time behaviour. While this phenomenon is thoroughly understood in the context of finite-dimensional Hamiltonian systems, much less is known in the context of Hamiltonian PDEs. In this work we provide the first dimension-independent backward error analysis for a Runge-Kutta-type method, the midpoint rule, which shows the existence of a modified energy for this method when applied to nonlinear Schroedinger equations regardless of the level of spatial discretisation. We use this to establish long-time stability of the numerical flow for the midpoint rule.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03271v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erwan Faou (IRMAR, Inria, MINGUS), Georg Maierhofer (DAMTP), Katharina Schratz (LJLL)</dc:creator>
    </item>
    <item>
      <title>Physics-informed neural network estimation of active material properties in time-dependent cardiac biomechanical models</title>
      <link>https://arxiv.org/abs/2505.03382</link>
      <description>arXiv:2505.03382v1 Announce Type: cross 
Abstract: Active stress models in cardiac biomechanics account for the mechanical deformation caused by muscle activity, thus providing a link between the electrophysiological and mechanical properties of the tissue. The accurate assessment of active stress parameters is fundamental for a precise understanding of myocardial function but remains difficult to achieve in a clinical setting, especially when only displacement and strain data from medical imaging modalities are available. This work investigates, through an in-silico study, the application of physics-informed neural networks (PINNs) for inferring active contractility parameters in time-dependent cardiac biomechanical models from these types of imaging data. In particular, by parametrising the sought state and parameter field with two neural networks, respectively, and formulating an energy minimisation problem to search for the optimal network parameters, we are able to reconstruct in various settings active stress fields in the presence of noise and with a high spatial resolution. To this end, we also advance the vanilla PINN learning algorithm with the use of adaptive weighting schemes, ad-hoc regularisation strategies, Fourier features, and suitable network architectures. In addition, we thoroughly analyse the influence of the loss weights in the reconstruction of active stress parameters. Finally, we apply the method to the characterisation of tissue inhomogeneities and detection of fibrotic scars in myocardial tissue. This approach opens a new pathway to significantly improve the diagnosis, treatment planning, and management of heart conditions associated with cardiac fibrosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03382v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matthias H\"ofler, Francesco Regazzoni, Stefano Pagani, Elias Karabelas, Christoph Augustin, Gundolf Haase, Gernot Plank, Federica Caforio</dc:creator>
    </item>
    <item>
      <title>An Unfitted Interface Penalty DG--FE Method for Elliptic Interface Problems</title>
      <link>https://arxiv.org/abs/2312.15402</link>
      <description>arXiv:2312.15402v2 Announce Type: replace 
Abstract: We propose an unfitted interface penalty Discontinuous Galerkin-Finite Element Method (UIPDG-FEM) for elliptic interface problems. This hybrid method combines the interior penalty discontinuous Galerkin (IPDG) terms near the interface-enforcing jump conditions via Nitsche method-with standard finite elements away from the interface. The UIPDG-FEM retains the flexibilities of IPDG, particularly simplifying mesh generation around complex interfaces, while avoiding its drawback of excessive number of global degrees of freedom. We derive optimal convergence rates independent of interface location and establish uniform flux error estimates robust to discontinuous coefficients. To deal with conditioning issues caused by small cut elements, we develop a robust two-dimensional merging algorithm that eliminates such elements entirely, ensuring the condition number of the discretized system remains independent of interface position. A key feature of the algorithm is a novel quantification criterion linking the threshold for small cuts to the product of the maximum interface curvature and the local mesh size. Numerical experiments confirm the theoretical results and demonstrate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15402v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Han, Haijun Wu, Yuanming Xiao</dc:creator>
    </item>
    <item>
      <title>Perspectives on locally weighted ensemble Kalman methods</title>
      <link>https://arxiv.org/abs/2402.00027</link>
      <description>arXiv:2402.00027v3 Announce Type: replace 
Abstract: This manuscript derives locally weighted ensemble Kalman methods from the point of view of ensemble-based function approximation. This is done by using pointwise evaluations to build up a local linear or quadratic approximation of a function, tapering off the effect of distant particles via local weighting. This introduces a candidate method (the locally weighted Ensemble Kalman method for inversion) with the motivation of combining some of the strengths of the particle filter (ability to cope with nonlinear maps and non-Gaussian distributions) and the Ensemble Kalman filter (no filter degeneracy). We provide some numerical evidence for the accuracy of locally weighted ensemble methods, both in terms of approximation and inversion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00027v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philipp Wacker</dc:creator>
    </item>
    <item>
      <title>A sparse hierarchical $hp$-finite element method on disks and annuli</title>
      <link>https://arxiv.org/abs/2402.12831</link>
      <description>arXiv:2402.12831v2 Announce Type: replace 
Abstract: We develop a sparse hierarchical $hp$-finite element method ($hp$-FEM) for the Helmholtz equation with variable coefficients posed on a two-dimensional disk or annulus. The mesh is an inner disk cell (omitted if on an annulus domain) and concentric annuli cells. The discretization preserves the Fourier mode decoupling of rotationally invariant operators, such as the Laplacian, which manifests as block diagonal mass and stiffness matrices. Moreover, the matrices have a sparsity pattern independent of the order of the discretization and admit an optimal complexity factorization. The sparse $hp$-FEM can handle radial discontinuities in the right-hand side and in rotationally invariant Helmholtz coefficients. Rotationally anisotropic coefficients that are approximated by low-degree polynomials in Cartesian coordinates also result in sparse linear systems. We consider examples such as a high-frequency Helmholtz equation with radial discontinuities and rotationally anisotropic coefficients, singular source terms, the time-dependent Schr\"odinger equation, and an extension to a three-dimensional cylinder domain, with a quasi-optimal solve, via the Alternating Direction Implicit (ADI) algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12831v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis P. A. Papadopoulos, Sheehan Olver</dc:creator>
    </item>
    <item>
      <title>High-order Adaptive Rank Integrators for Multi-scale Linear Kinetic Transport Equations in the Hierarchical Tucker Format</title>
      <link>https://arxiv.org/abs/2406.19479</link>
      <description>arXiv:2406.19479v2 Announce Type: replace 
Abstract: In this paper, we present a new adaptive rank approximation technique for computing solutions to the high-dimensional linear kinetic transport equation. The approach we propose is based on a macro-micro decomposition of the kinetic model in which the angular domain is discretized with a tensor product quadrature rule under the discrete ordinates method. To address the challenges associated with the curse of dimensionality, the proposed low-rank method is cast in the framework of the hierarchical Tucker decomposition. The adaptive rank integrators we propose are built upon high-order discretizations for both time and space. In particular, this work considers implicit-explicit discretizations for time and finite-difference weighted-essentially non-oscillatory discretizations for space. The high-order singular value decomposition is used to perform low-rank truncation of the high-dimensional time-dependent distribution function. The methods are applied to several benchmark problems, where we compare the solution quality and measure compression achieved by the adaptive rank methods against their corresponding full-grid methods. We also demonstrate the benefits of high-order discretizations in the proposed low-rank framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19479v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William A. Sands, Wei Guo, Jing-Mei Qiu, Tao Xiong</dc:creator>
    </item>
    <item>
      <title>Sylvester-Preconditioned Adaptive-Rank Implicit Time Integrators for Advection-Diffusion Equations with Variable Coefficients</title>
      <link>https://arxiv.org/abs/2410.19662</link>
      <description>arXiv:2410.19662v2 Announce Type: replace 
Abstract: We consider the adaptive-rank integration of {2D and 3D} time-dependent advection-diffusion partial differential equations (PDEs) with variable coefficients. We employ a standard finite-difference method for spatial discretization coupled with diagonally implicit Runge-Kutta temporal schemes. The discrete equation is a generalized Sylvester equation (GSE), which we solve with an adaptive-rank algorithm structured around three key strategies: {(i) constructing dimension-wise subspaces based on an extended Krylov strategy, (ii) developing an effective preconditioner for the reduced coefficient matrix, and (iii) efficiently computing the residual of the equation without explicitly reverting to the full-rank form. {The low-rank decomposition is performed in 2D using SVD, and with high-order SVD (HOSVD) in 3D to represent the tensor in a compressed Tucker format.} The computational complexity of the proposed approach {is demonstrated numerically to} be comparable to the constant-coefficient case [El Kahza et al, J. Comput. Phys., 518 (2024)], scaling as $\mathcal{O}(N {r^2} + {r^{d+1}})$ for $d$-dimensional problems (here, $d = 2$ or $3$), with $N$ the resolution in one dimension and $r$ the maximal rank during the Krylov iteration (which we find to be largely independent of $N$). We present numerical examples that illustrate the computational efficacy and complexity of our algorithm.}</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19662v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hamad El Kahza, Jing-Mei Qiu, Luis Chacon, William Taitano</dc:creator>
    </item>
    <item>
      <title>Learning Memory and Material Dependent Constitutive Laws</title>
      <link>https://arxiv.org/abs/2502.05463</link>
      <description>arXiv:2502.05463v2 Announce Type: replace 
Abstract: We propose and study a neural operator framework for learning memory- and material microstructure-dependent constitutive laws for heterogeneous materials. We work in the two-scale setting where homogenization theory provides a systematic approach to deriving macroscale constitutive laws, obviating the need to resolve complex microstructure repeatedly. However, the unit cell problems defining these constitutive models are typically not amenable to explicit evaluation. It is therefore of interest to learn constitutive models from data generated by the unit cell problem. Our proposed framework models homogenized constitutive laws with both memory- and microstructure-dependence through the use of Markovian recurrent and Fourier neural operators. The homogenization problem for Kelvin-Voigt viscoelastic materials is studied to provide firm theoretical foundations for our model. The theoretical properties of the cell problem in this Kelvin-Voigt setting motivate the proposed learning framework; and are also used to prove a universal approximation theorem for the learned macroscale constitutive model. Numerical experiments show that the proposed learning framework accurately learns memory- and microstructure-dependent viscoelastic and elasto-viscoplastic constitutive models, beyond the setting of the theory. Furthermore, we show that the learned constitutive models can be successfully deployed in macroscale simulation of material deformation for different microstructures without retraining.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05463v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaushik Bhattacharya, Lianghao Cao, George Stepaniants, Andrew Stuart, Margaret Trautner</dc:creator>
    </item>
    <item>
      <title>A Machine Learning and Finite Element Framework for Inverse Elliptic PDEs via Dirichlet-to-Neumann Mapping</title>
      <link>https://arxiv.org/abs/2504.03895</link>
      <description>arXiv:2504.03895v2 Announce Type: replace 
Abstract: Inverse problems for partial differential equations (PDEs) are crucial in numerous applications such as geophysics, biomedical imaging, and material science, where unknown physical properties must be inferred from indirect measurements. In this work, we address the inverse problem for elliptic PDEs by leveraging the Dirichlet-to-Neumann (DtN) map, which captures the relationship between boundary inputs and flux responses. Thus, this approach enables to solve the inverse problem that seeks the material properties inside the domain by utilizing the boundary data. Our framework employs an unsupervised machine learning algorithm that integrates a finite element method (FEM) in the inner loop for the forward problem, ensuring high accuracy. Moreover our approach is flexible to utilize partial observations of the boundary data, which is often the case in real-world scenarios. By incorporating carefully designed loss functions that accommodate discontinuities, the method refines coefficient reconstructions iteratively. This combined FEM and machine learning approach offers a robust, accurate solution strategy for a broad range of inverse problems, enabling improved estimation of critical parameters in applications from medical diagnostics to subsurface exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03895v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dabin Park, Sanghyun Lee, Sunghwan Moon</dc:creator>
    </item>
    <item>
      <title>Provable algorithms for multi-reference alignment over $\SO(2)$</title>
      <link>https://arxiv.org/abs/2504.19140</link>
      <description>arXiv:2504.19140v2 Announce Type: replace 
Abstract: The multi-reference alignment (MRA) problem involves reconstructing a signal from multiple noisy observations, each transformed by a random group element. In this paper, we focus on the group \(\mathrm{SO}(2)\) of in-plane rotations and propose two computationally efficient algorithms with theoretical guarantees for accurate signal recovery under a non-uniform distribution over the group. The first algorithm exploits the spectral properties of the second moment of the data, while the second utilizes the frequency marching principle. Both algorithms achieve the optimal estimation rate in high-noise regimes, marking a significant advancement in the development of computationally efficient and statistically optimal methods for estimation problems over groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19140v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gil Drozatz, Tamir Bendory, Nir Sharon</dc:creator>
    </item>
    <item>
      <title>Sibuya probability distributions and numerical evaluation of fractional-order operators</title>
      <link>https://arxiv.org/abs/2504.21523</link>
      <description>arXiv:2504.21523v2 Announce Type: replace 
Abstract: In this work we explore the Sibuya discrete probability distribution, which serves as the basis and the main instrument for numerical simulations of Grunwald--Letnikov fractional derivatives by the Monte Carlo method. We provide three methods for simulating the Sibuya distribution. We also introduce the Sibuya-like sieved probability distributions, and apply them to numerical fractional-order differentiation. Additionally, we use the Monte Carlo method for evaluating fractional-order integrals, and suggest the notion of the continuous Sibuya probability distribution. The developed methods and tools are illustrated by examples of computation. We provide the MATLAB toolboxes for simulation of the Sibuya probability distribution, and for the numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21523v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nikolai Leonenko, Igor Podlubny</dc:creator>
    </item>
    <item>
      <title>Trinomials and Deterministic Complexity Limits for Real Solving</title>
      <link>https://arxiv.org/abs/2202.06115</link>
      <description>arXiv:2202.06115v2 Announce Type: replace-cross 
Abstract: We detail an algorithm that -- for all but a $\frac{1}{\Omega(\log(dH))}$ fraction of $f\in\mathbb{Z}[x]$ with exactly $3$ monomial terms, degree $d$, and all coefficients in $\{-H,\ldots, H\}$ -- produces an approximate root (in the sense of Smale) for each real root of $f$ in deterministic time $\log^{4+o(1)}(dH)$ in the classical Turing model. (Each approximate root is a rational with logarithmic height $O(\log(dH))$.) The best previous deterministic bit complexity bounds were exponential in $\log d$. We then relate this to Koiran's Trinomial Sign Problem (2017): Decide the sign of a degree $d$ trinomial $f\in\mathbb{Z}[x]$ with coefficients in $\{-H,\ldots,H\}$, at a point $r\!\in\!\mathbb{Q}$ of logarithmic height $\log H$, in (deterministic) time $\log^{O(1)}(dH)$. We show that Koiran's Trinomial Sign Problem admits a positive solution, at least for a fraction $1-\frac{1}{\Omega(\log(dH))}$ of the inputs $(f,r)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.06115v2</guid>
      <category>math.AG</category>
      <category>cs.CC</category>
      <category>cs.NA</category>
      <category>cs.SC</category>
      <category>math.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Emma Boniface, Weixun Deng, J. Maurice Rojas</dc:creator>
    </item>
    <item>
      <title>Almost conservation of the harmonic actions for fully discretized nonlinear Klein--Gordon equations at low regularity</title>
      <link>https://arxiv.org/abs/2406.12363</link>
      <description>arXiv:2406.12363v2 Announce Type: replace-cross 
Abstract: Close to the origin, the nonlinear Klein--Gordon equations on the circle are nearly integrable Hamiltonian systems which have infinitely many almost conserved quantities called harmonic actions or super-actions. We prove that, at low regularity and with a CFL number of size 1, this property is preserved if we discretize the nonlinear Klein--Gordon equations with the symplectic mollified impulse methods. This extends previous results of D. Cohen, E. Hairer and C. Lubich to non-smooth solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12363v2</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charbella Abou Khalil (Nantes Univ), Joackim Bernier (Nantes Univ)</dc:creator>
    </item>
    <item>
      <title>Weighted balanced truncation method for approximating kernel functions by exponentials</title>
      <link>https://arxiv.org/abs/2503.03183</link>
      <description>arXiv:2503.03183v2 Announce Type: replace-cross 
Abstract: Kernel approximation with exponentials is useful in many problems with convolution quadrature and particle interactions such as integral-differential equations, molecular dynamics and machine learning. This paper proposes a weighted balanced truncation to construct an optimal model reduction method for compressing the number of exponentials in the sum-of-exponentials approximation of kernel functions. This method shows great promise in approximating long-range kernels, achieving over 4 digits of accuracy improvement for the Ewald-splitting and inverse power kernels in comparison with the classical balanced truncation. Numerical results demonstrate its excellent performance and attractive features for practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03183v2</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanshen Lin, Zhenli Xu, Yusu Zhang, Qi Zhou</dc:creator>
    </item>
    <item>
      <title>dyGRASS: Dynamic Spectral Graph Sparsification via Localized Random Walks on GPUs</title>
      <link>https://arxiv.org/abs/2505.02741</link>
      <description>arXiv:2505.02741v2 Announce Type: replace-cross 
Abstract: This work presents dyGRASS, an efficient dynamic algorithm for spectral sparsification of large undirected graphs that undergo streaming edge insertions and deletions. At its core, dyGRASS employs a random-walk-based method to efficiently estimate node-to-node distances in both the original graph (for decremental update) and its sparsifier (for incremental update). For incremental updates, dyGRASS enables the identification of spectrally critical edges among the updates to capture the latest structural changes. For decremental updates, dyGRASS facilitates the recovery of important edges from the original graph back into the sparsifier. To further enhance computational efficiency, dyGRASS employs a GPU-based non-backtracking random walk scheme that allows multiple walkers to operate simultaneously across various target updates. This parallelization significantly improves both the performance and scalability of the proposed dyGRASS framework. Our comprehensive experimental evaluations reveal that dyGRASS achieves approximately a 10x speedup compared to the state-of-the-art incremental sparsification (inGRASS) algorithm while eliminating the setup overhead and improving solution quality in incremental spectral sparsification tasks. Moreover, dyGRASS delivers high efficiency and superior solution quality for fully dynamic graph sparsification, accommodating both edge insertions and deletions across a diverse range of graph instances originating from integrated circuit simulations, finite element analysis, and social networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02741v2</guid>
      <category>cs.SI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yihang Yuan, Ali Aghdaei, Zhuo Feng</dc:creator>
    </item>
  </channel>
</rss>
