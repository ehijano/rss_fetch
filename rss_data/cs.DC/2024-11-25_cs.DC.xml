<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Nov 2024 04:04:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Improving training time and GPU utilization in geo-distributed language model training</title>
      <link>https://arxiv.org/abs/2411.14458</link>
      <description>arXiv:2411.14458v1 Announce Type: new 
Abstract: The widespread adoption of language models (LMs) across multiple industries has caused huge surge in demand for GPUs. Training LMs requires tens of thousands of GPUs and housing them in the same datacenter (DCs) is becoming challenging. We focus on training such models across multiple DCs connected via Wide-Area-Network (WAN). We build ATLAS that speeds up such training time using novel temporal bandwidth sharing and many other design choices. While ATLAS improves the training time, it does not eliminate the bubbles (idle GPU cycles). We built BUBBLETEA that runs prefill-as-a-service (part of LM inference) during the bubbles that improves the GPU utilization substantially without any impact of training. Together, ATLAS and BUBBLETEA improve training time by up to 17X and achieve GPU utilization of up to 94%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14458v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator> Palak (Microsoft Research India), Rohan Gandhi (Microsoft Research India), Karan Tandon (Microsoft Research India), Debopam Bhattacherjee (Microsoft Research India), Venkata N. Padmanabhan (Microsoft Research India)</dc:creator>
    </item>
    <item>
      <title>LLOR: Automated Repair of OpenMP Programs</title>
      <link>https://arxiv.org/abs/2411.14590</link>
      <description>arXiv:2411.14590v1 Announce Type: new 
Abstract: In this paper, we present a technique for repairing data race errors in parallel programs written in C/C++ and Fortran using the OpenMP API. Our technique can also remove barriers that are deemed unnecessary for correctness. We implement these ideas in our tool called LLOR, which takes a language-independent approach to provide appropriate placements of synchronization constructs to avoid data races. To the best of our knowledge, LLOR is the only tool that can repair parallel programs that use the OpenMP API. We showcase the capabilities of LLOR by performing extensive experiments on 415 parallel programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14590v1</guid>
      <category>cs.DC</category>
      <category>cs.SE</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Utpal Bora, Saurabh Joshi, Gautam Muduganti, Ramakrishna Upadrasta</dc:creator>
    </item>
    <item>
      <title>OMP4Py: a pure Python implementation of OpenMP</title>
      <link>https://arxiv.org/abs/2411.14887</link>
      <description>arXiv:2411.14887v1 Announce Type: new 
Abstract: Python demonstrates lower performance in comparison to traditional high performance computing (HPC) languages such as C, C++, and Fortran. This performance gap is largely due to Python's interpreted nature and the Global Interpreter Lock (GIL), which hampers multithreading efficiency. However, the latest version of Python includes the necessary changes to make the interpreter thread-safe, allowing Python code to run without the GIL. This important update will enable users to fully exploit multithreading parallelism in Python. In order to facilitate that task, this paper introduces OMP4Py, the first pure Python implementation of OpenMP. We demonstrate that it is possible to bring OpenMP's familiar directive-based parallelization paradigm to Python, allowing developers to write parallel code with the same level of control and flexibility as in C, C++, or Fortran. The experimental evaluation shows that OMP4Py significantly impacts the performance of various types of applications, although the current threading limitation of Python's interpreter (v3.13) reduce its effectiveness for numerical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14887v1</guid>
      <category>cs.DC</category>
      <category>cs.PL</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>C\'esar Pi\~neiro, Juan C. Pichel</dc:creator>
    </item>
    <item>
      <title>Open Challenges in the Formal Verification of Autonomous Driving</title>
      <link>https://arxiv.org/abs/2411.14520</link>
      <description>arXiv:2411.14520v1 Announce Type: cross 
Abstract: In the realm of autonomous driving, the development and integration of highly complex and heterogeneous systems are standard practice. Modern vehicles are not monolithic systems; instead, they are composed of diverse hardware components, each running its own software systems. An autonomous vehicle comprises numerous independent components, often developed by different and potentially competing companies. This diversity poses significant challenges for the certification process, as it necessitates certifying components that may not disclose their internal behaviour (black-boxes). In this paper, we present a real-world case study of an autonomous driving system, identify key open challenges associated with its development and integration, and explore how formal verification techniques can address these challenges to ensure system reliability and safety.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14520v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.RO</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.411.13</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 411, 2024, pp. 191-200</arxiv:journal_reference>
      <dc:creator>Paolo Burgio (University of Modena,Reggio Emilia), Angelo Ferrando (University of Modena,Reggio Emilia), Marco Villani (University of Modena,Reggio Emilia)</dc:creator>
    </item>
    <item>
      <title>MSF-Model: Queuing-Based Analysis and Prediction of Metastable Failures in Replicated Storage Systems</title>
      <link>https://arxiv.org/abs/2309.16181</link>
      <description>arXiv:2309.16181v2 Announce Type: replace 
Abstract: Metastable failure is a recent abstraction of a pattern of failures that occurs frequently in real-world distributed storage systems. In this paper, we propose a formal analysis and modeling of metastable failures in replicated storage systems. We focus on a foundational problem in distributed systems -- the problem of consensus -- to have an impact on a large class of systems. Our main contribution is the development of a queuing-based analytical model, MSF-Model, that can be used to characterize and predict metastable failures. MSF-Model integrates novel modeling concepts that allow modeling metastable failures which was interactable to model prior to our work. We also perform real experiments to reproduce and validate our model. Our real experiments show that MSF-Model predicts metastable failures with high accuracy by comparing the real experiment with the predictions from the queuing-based model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.16181v2</guid>
      <category>cs.DC</category>
      <category>cs.DB</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Farzad Habibi, Tania Lorido-Botran, Ahmad Showail, Daniel C. Sturman, Faisal Nawab</dc:creator>
    </item>
    <item>
      <title>Canvas: End-to-End Kernel Architecture Search in Neural Networks</title>
      <link>https://arxiv.org/abs/2304.07741</link>
      <description>arXiv:2304.07741v3 Announce Type: replace-cross 
Abstract: The demands for higher performance and accuracy in neural networks (NNs) never end. Existing tensor compilation and Neural Architecture Search (NAS) techniques orthogonally optimize the two goals but actually share many similarities in their concrete strategies. We exploit such opportunities by combining the two into one and make a case for Kernel Architecture Search (KAS). KAS reviews NAS from a system perspective and zooms into a more fine-grained level to generate neural kernels with both high performance and good accuracy. To demonstrate the potential of KAS, we build an end-to-end framework, Canvas, to find high-quality kernels as convolution replacements. Canvas samples from a rich set of fine-grained primitives to stochastically and iteratively construct new kernels and evaluate them according to user-specified constraints. Canvas supports freely adjustable tensor dimension sizes inside the kernel and uses two levels of solvers to satisfy structural legality and fully utilize model budgets. The evaluation shows that by replacing standard convolutions with generated new kernels in common NNs, Canvas achieves average 1.5x speedups compared to the previous state-of-the-art with acceptable accuracy loss and search efficiency. Canvas verifies the practicability of KAS by rediscovering many manually designed kernels in the past and producing new structures that may inspire future machine learning innovations. For source code and implementation, we open-sourced Canvas at https://github.com/tsinghua-ideal/Canvas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.07741v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenggang Zhao, Genghan Zhang, Ao Shen, Mingyu Gao</dc:creator>
    </item>
    <item>
      <title>OCD-FL: A Novel Communication-Efficient Peer Selection-based Decentralized Federated Learning</title>
      <link>https://arxiv.org/abs/2403.04037</link>
      <description>arXiv:2403.04037v2 Announce Type: replace-cross 
Abstract: The conjunction of edge intelligence and the ever-growing Internet-of-Things (IoT) network heralds a new era of collaborative machine learning, with federated learning (FL) emerging as the most prominent paradigm. With the growing interest in these learning schemes, researchers started addressing some of their most fundamental limitations. Indeed, conventional FL with a central aggregator presents a single point of failure and a network bottleneck. To bypass this issue, decentralized FL where nodes collaborate in a peer-to-peer network has been proposed. Despite the latter's efficiency, communication costs and data heterogeneity remain key challenges in decentralized FL. In this context, we propose a novel scheme, called opportunistic communication-efficient decentralized federated learning, a.k.a., OCD-FL, consisting of a systematic FL peer selection for collaboration, aiming to achieve maximum FL knowledge gain while reducing energy consumption. Experimental results demonstrate the capability of OCD-FL to achieve similar or better performances than the fully collaborative FL, while significantly reducing consumed energy by at least 30% and up to 80%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04037v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Mon, 25 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nizar Masmoudi, Wael Jaafar</dc:creator>
    </item>
  </channel>
</rss>
