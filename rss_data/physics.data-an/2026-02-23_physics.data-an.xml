<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Feb 2026 05:01:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A response-matrix-centred approach to presenting cross-section measurements</title>
      <link>https://arxiv.org/abs/1903.06568</link>
      <description>arXiv:1903.06568v2 Announce Type: cross 
Abstract: The current canonical approach to publishing cross-section data is to unfold the reconstructed distributions. Detector effects like efficiency and smearing are undone mathematically, yielding distributions in true event properties. This is an ill-posed problem, as even small statistical variations in the reconstructed data can lead to large changes in the unfolded spectra.
  This work presents an alternative or complementary approach: the response-matrix-centred forward-folding approach. It offers a convenient way to forward-fold model expectations in truth space to reconstructed quantities. These can then be compared to the data directly, similar to what is usually done with full detector simulations within the experimental collaborations. For this, the detector response (efficiency and smearing) is parametrised as a matrix. The effects of the detector on the measurement of a given model is simulated by simply multiplying the binned truth expectation values by this response matrix.
  Systematic uncertainties in the detector response are handled by providing a set of matrices according to the prior distribution of the detector properties and marginalising over them. Background events can be included in the likelihood calculation by giving background events their own bins in truth space.
  To facilitate a straight-forward use of response matrices, a new software framework has been developed: the Response Matrix Utilities (ReMU). ReMU is a Python package distributed via the Python Package Index. It only uses widely available, standard scientific Python libraries and does not depend on any custom experiment-specific software. It offers all methods needed to build response matrices from Monte Carlo data sets, use the response matrix to forward-fold truth-level model predictions, and compare the predictions to real data using Bayesian or frequentist statistical inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:1903.06568v2</guid>
      <category>stat.CO</category>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <category>stat.ME</category>
      <category>stat.OT</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1088/1748-0221/14/09/P09013</arxiv:DOI>
      <dc:creator>Lukas Koch</dc:creator>
    </item>
    <item>
      <title>Hypothesis tests and model parameter estimation on data sets with missing correlation information</title>
      <link>https://arxiv.org/abs/2410.22333</link>
      <description>arXiv:2410.22333v4 Announce Type: cross 
Abstract: Ideally, all analyses of normally distributed data should include the full covariance information between all data points. In practice, the full covariance matrix between all data points is not always available. Either because a result was published without a covariance matrix, or because one tries to combine multiple results from separate publications. For simple hypothesis tests, it is possible to define robust test statistics that will behave conservatively in the presence on unknown correlations. For model parameter fits, one can inflate the variance by a factor to ensure that things remain conservative at least up to a chosen confidence level. This paper describes a class of robust test statistics for simple hypothesis tests, as well as an algorithm to determine the necessary inflation factor for model parameter fits and Goodness of Fit tests and composite hypothesis tests. It then presents some example applications of the methods to real neutrino interaction data and model comparisons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22333v4</guid>
      <category>stat.ME</category>
      <category>astro-ph.IM</category>
      <category>hep-ph</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevD.111.033002</arxiv:DOI>
      <dc:creator>Lukas Koch</dc:creator>
    </item>
    <item>
      <title>Covering Unknown Correlations in Bayesian Priors by Inflating Uncertainties</title>
      <link>https://arxiv.org/abs/2509.11821</link>
      <description>arXiv:2509.11821v2 Announce Type: cross 
Abstract: Bayesian analyses require that all variable model parameters are given a prior probability distribution. This can pose a challenge for analyses where multiple experiments are combined if these experiments use different parametrisations for their nuisance parameters. If the parameters in the two models describe exactly the same physics, they should be 100% correlated in the prior. If the parameters describe independent physics, they should be uncorrelated. But if they describe related or overlapping physics, it is not trivial to determine what the joint prior distribution should look like. Even if the priors for each experiment are well motivated, the unknown correlations between them can have unintended consequences for the posterior probability of the parameters of interest, potentially leading to underestimated uncertainties. In this paper we show that it is possible to choose a prior parametrisation that ensures conservative posterior uncertainties for the parameters of interest under some very general assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11821v2</guid>
      <category>stat.ME</category>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Koch</dc:creator>
    </item>
    <item>
      <title>Probabilistic Methods for Initial Orbit Determination and Orbit Determination in Cislunar Space</title>
      <link>https://arxiv.org/abs/2602.18058</link>
      <description>arXiv:2602.18058v1 Announce Type: cross 
Abstract: In orbital mechanics, Gauss's method for orbit determination (OD) is a popular, minimal assumption solution for obtaining the initial state estimate of a passing resident space object (RSO). Since much of the cislunar domain relies on three-body dynamics, a key assumption of Gauss's method is rendered incompatible, creating a need for a new, minimal assumption method for initial orbit determination (IOD). In this work, we present a framework for short and long term probabilistic target tracking in cislunar space which produces an initial state estimate with as few assumptions as possible. Specifically, we propose an IOD method involving the kinematic fitting of several series of noisy, consecutive ground-based observations. Once a probabilistic initial state estimate in the form of a particle cloud is formed, we apply the powerful Particle Gaussian Mixture (PGM) Filter to reduce the uncertainty of our state estimate over time. This combined IOD/OD framework is demonstrated for several classes of trajectories in cislunar space and compared to better-known filtering frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18058v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>physics.data-an</category>
      <category>physics.space-ph</category>
      <category>stat.AP</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ishan Paranjape, Tarun Hejmadi, Suman Chakravorty</dc:creator>
    </item>
    <item>
      <title>SpecTUS: Spectral Translator for Unknown Structures annotation from EI-MS spectra</title>
      <link>https://arxiv.org/abs/2502.05114</link>
      <description>arXiv:2502.05114v2 Announce Type: replace-cross 
Abstract: Compound identification and structure annotation from mass spectra is a well-established task widely applied in drug detection, criminal forensics, small molecule biomarker discovery and chemical engineering.
  We propose SpecTUS: Spectral Translator for Unknown Structures, a deep neural model that addresses the task of structural annotation of small molecules from low-resolution gas chromatography electron ionization mass spectra (GC-EI-MS). Our model analyzes the spectra in \textit{de novo} manner -- a direct translation from the spectra into 2D-structural representation. Our approach is particularly useful for analyzing compounds unavailable in spectral libraries.
  In a rigorous evaluation of our model on the novel structure annotation task across different libraries, we outperformed standard database search techniques by a wide margin. On a held-out testing set, including \numprint{28267} spectra from the NIST database, we show that our model's single suggestion perfectly reconstructs 43\% of the subset's compounds. This single suggestion is strictly better than the candidate of the database hybrid search (common method among practitioners)
  in 76\% of cases. In a~still affordable scenario of~10 suggestions, perfect reconstruction is achieved in 65\%, and 84\% are better than the hybrid search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05114v2</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Adam H\'ajek, Michal Star\'y, Elliott Price, Filip Jozefov, Helge Hecht, Ale\v{s} K\v{r}enek</dc:creator>
    </item>
    <item>
      <title>Assimilative Causal Inference</title>
      <link>https://arxiv.org/abs/2505.14825</link>
      <description>arXiv:2505.14825v2 Announce Type: replace-cross 
Abstract: Causal inference is fundamental across scientific disciplines, yet existing methods struggle to capture instantaneous, time-evolving causal relationships in complex, high-dimensional systems. In this paper, assimilative causal inference (ACI) is developed, which is a methodological framework that leverages Bayesian data assimilation to trace causes backward from observed effects. ACI solves the inverse problem rather than quantifying forward influence. It uniquely identifies dynamic causal interactions without requiring observations of candidate causes, accommodates short datasets, and, in principle, can be implemented in high-dimensional settings by employing efficient data assimilation algorithms. Crucially, it provides online tracking of causal roles that may reverse intermittently and facilitates a mathematically rigorous criterion for the causal influence range, revealing how far effects propagate. The effectiveness of ACI is demonstrated by complex dynamical systems showcasing intermittency and extreme events. ACI opens valuable pathways for studying complex systems, where transient causal structures are critical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14825v2</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>physics.data-an</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41467-026-68568-0</arxiv:DOI>
      <arxiv:journal_reference>Nature Communications 17, 1854 (2026)</arxiv:journal_reference>
      <dc:creator>Marios Andreou, Nan Chen, Erik Bollt</dc:creator>
    </item>
    <item>
      <title>Amortized Inference of Multi-Modal Posteriors using Likelihood-Weighted Normalizing Flows</title>
      <link>https://arxiv.org/abs/2512.04954</link>
      <description>arXiv:2512.04954v2 Announce Type: replace-cross 
Abstract: We present a novel technique for amortized posterior estimation using Normalizing Flows trained with likelihood-weighted importance sampling. This approach allows for the efficient inference of theoretical parameters in high-dimensional inverse problems without the need for posterior training samples. We implement the method on multi-modal benchmark tasks in 2D and 3D to check for the efficacy. A critical observation of our study is the impact of the topology of the base distributions on the modelled posteriors. We find that standard unimodal base distributions fail to capture disconnected support, resulting in spurious probability bridges between modes. We demonstrate that initializing the flow with a Gaussian Mixture Model that matches the cardinality of the target modes significantly improves reconstruction fidelity, as measured by some distance and divergence metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04954v2</guid>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <category>hep-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajneil Baruah</dc:creator>
    </item>
    <item>
      <title>CNN on `Top': In Search of Scalable &amp; Lightweight Image-based Jet Taggers</title>
      <link>https://arxiv.org/abs/2512.05031</link>
      <description>arXiv:2512.05031v2 Announce Type: replace-cross 
Abstract: While Transformer-based and standard Graph Neural Networks (GNNs) have proven to be the best performers in classifying different types of jets, they require substantial computational power. We explore the scope of using a lightweight and scalable version of EfficientNet architecture, along with global features of the jet. The end product is computationally inexpensive but is capable of competitive performance. We showcase the efficacy of our network in tagging top-quark jets in a sea of other light quark and gluon jets. The work also sheds light on the importance of global features for both the accuracy and the apparent redundancy of the network's complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05031v2</guid>
      <category>hep-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajneil Baruah, Subhadeep Mondal, Sunando Kumar Patra, Satyajit Roy</dc:creator>
    </item>
    <item>
      <title>Generating temporal networks with the Ascona model</title>
      <link>https://arxiv.org/abs/2512.16972</link>
      <description>arXiv:2512.16972v2 Announce Type: replace-cross 
Abstract: We introduce a queueing-based sampling framework for continuous-time temporal networks. We focus on a Markovian parametrization in which link start times follow a homogeneous Poisson process and link durations are exponentially distributed. We derive stochastic properties of the resulting link streams and exploit them to generate synthetic temporal networks with controllable smoothness and prescribed event patterns, relevant for the validation and interpretation of methods for community, scale, change-point, and periodicity detection. By coupling this temporal mechanism with block-structured endpoint distributions, we obtain a continuous-time analogue of stochastic block models. We also discuss extensions of the framework, including discrete-time and instantaneous-contact limits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.16972v2</guid>
      <category>physics.soc-ph</category>
      <category>math.PR</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Samuel Koovely</dc:creator>
    </item>
  </channel>
</rss>
