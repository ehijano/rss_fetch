<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Oct 2024 03:20:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Bayesian Inference of Multiple Ising Models for Heterogeneous Public Opinion Survey Networks</title>
      <link>https://arxiv.org/abs/2410.02880</link>
      <description>arXiv:2410.02880v1 Announce Type: new 
Abstract: In public opinion studies, the relationships between opinions on different topics are likely to shift based on the characteristics of the respondents. Thus, understanding the complexities of public opinion requires methods that can account for the heterogeneity in responses across different groups. Multiple graphs are used to study how external factors-such as time spent online or generational differences-shape the joint dependence relationships between opinions on various topics. Specifically, we propose a class of multiple Ising models where a set of graphs across different groups are able to capture these variations and to model the heterogeneity induced in a set of binary variables by external factors. The proposed Bayesian methodology is based on a Markov Random Field prior for the multiple graph setting. Such prior enables the borrowing of strength across the different groups to encourage common edges when supported by the data. Sparse inducing spike-and-slab priors are employed on the parameters that measure graph similarities to learn which subgroups have a shared graph structure. Two Bayesian approaches are developed for the inference of multiple Ising models with a special focus on model selection: (i) a Fully Bayesian method for low-dimensional graphs based on conjugate priors specified with respect to the exact likelihood, and (ii) an Approximate Bayesian method based on a quasi-likelihood approach for high-dimensional graphs where the normalization constant required in the exact method is computationally intractable. These methods are employed for the analysis of data from two public opinion studies in US. The obtained results display a good trade-off between identifying significant edges (both shared and group-specific) and having sparse networks, all while quantifying the uncertainty of the graph structure and the graphs' similarity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02880v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandra Avalos-Pacheco, Andrea Lazzerini, Monia Lupparelli, Francesco C. Stingo</dc:creator>
    </item>
    <item>
      <title>Evaluating WAIC and PSIS-LOO for Bayesian Diagnostic Classification Model Selection</title>
      <link>https://arxiv.org/abs/2410.02931</link>
      <description>arXiv:2410.02931v1 Announce Type: new 
Abstract: Bayesian diagnostic classification models (Bayesian DCMs) are effective for diagnosing students' skills. Research on the evaluation of relative model fit indices for DCMs using Bayesian estimation, however, is deficient. This study introduces the performance of Bayesian relative model fit indices, the widely applicable information criterion (WAIC) and leave-one-out cross-validation using Pareto-smoothed importance sampling (PSIS-LOO), in comparison to simpler and more widely used deviance information criterion (DIC). The simulation study evaluates the performance of WAIC and PSIS-LOO by detecting the true model with varying sample sizes, item qualities, and prior information levels. The results of the study indicate that WAIC and PSIS-LOO primarily favored the generating model; however, occasional inconsistencies were observed. This study recommends using WAIC and PSIS-LOO when the data is assumed to follow a simpler model and the models are estimated under uninformative priors, and DIC when the data is assumed to follow a more complex model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02931v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ae Kyong Jung, Jonathan Templin</dc:creator>
    </item>
    <item>
      <title>Latent Space-based Stochastic Model Updating</title>
      <link>https://arxiv.org/abs/2410.03150</link>
      <description>arXiv:2410.03150v1 Announce Type: new 
Abstract: Model updating of engineering systems inevitably involves handling both aleatory or inherent randomness and epistemic uncertainties or uncertainities arising from a lack of knowledge or information about the system. Addressing these uncertainties poses significant challenges, particularly when data and simulations are limited. This study proposes a novel latent space-based method for stochastic model updating that leverages limited data to effectively quantify uncertainties in engineering applications. By extending the latent space-based approach to multiobservation and multisimulation frameworks, the proposed method circumvents the need for probability estimations at each iteration of MCMC, relying instead on an amortized probabilistic model trained using a variational autoencoder (VAE). This method was validated through numerical experiments on a two-degree-of-freedom shear spring model, demonstrating superior efficiency and accuracy compared to existing methods in terms of uncertainty quantification (UQ) metrics, such as Bhattacharyya and Euclidean distances. Moreover, the applicability of the method to time-series data was verified using the model calibration problem of the NASA UQ Challenge 2019. The results underscore the potential of the latent space-based method in practical engineering applications, providing a robust framework for uncertainty quantification with fewer data requirements, and demonstrating its effectiveness in handling high-dimensional data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03150v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sangwon Lee, Taro Yaoyama, Masaru Kitahara, Tatsuya Itoi</dc:creator>
    </item>
    <item>
      <title>Implementing Response-Adaptive Randomisation in Stratified Rare-disease Trials: Design Challenges and Practical Solutions</title>
      <link>https://arxiv.org/abs/2410.03346</link>
      <description>arXiv:2410.03346v1 Announce Type: new 
Abstract: Although response-adaptive randomisation (RAR) has gained substantial attention in the literature, it still has limited use in clinical trials. Amongst other reasons, the implementation of RAR in the real world raises important practical questions, often neglected. Motivated by an innovative phase-II stratified RAR trial, this paper addresses two challenges: (1) How to ensure that RAR allocations are both desirable and faithful to target probabilities, even in small samples? and (2) What adaptations to trigger after interim analyses in the presence of missing data? We propose a Mapping strategy that discretises the randomisation probabilities into a vector of allocation ratios, resulting in improved frequentist errors. Under the implementation of Mapping, we analyse the impact of missing data on operating characteristics by examining selected scenarios. Finally, we discuss additional concerns including: pooling data across trial strata, analysing the level of blinding in the trial, and reporting safety results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03346v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajenki Das, Nina Deliu, Mark Toshner, Sof\'ia S Villar</dc:creator>
    </item>
    <item>
      <title>Forecasting and decisions in the birth-death-suppression Markov model for wildfires</title>
      <link>https://arxiv.org/abs/2410.02765</link>
      <description>arXiv:2410.02765v1 Announce Type: cross 
Abstract: As changing climates transform the landscape of wildfire management and suppression, agencies are faced with difficult resource allocation decisions. We analyze trade-offs in temporal resource allocation using a simple but robust Markov model of a wildfire under suppression: the birth-death-suppression process. Though the model is not spatial, its stochastic nature and rich temporal structure make it broadly applicable in describing the dynamic evolution of a fire including ignition, the effect of adverse conditions, and the effect of external suppression. With strong analytical and numerical control of the probabilities of outcomes, we construct classes of processes which analogize common wildfire suppression scenarios and determine aspects of optimal suppression allocations. We model problems which include resource management in changing conditions, the effect of resource mobilization delay, and allocation under uncertainty about future events. Our results are consistent with modern resource management and suppression practices in wildland fire.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02765v1</guid>
      <category>physics.soc-ph</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>George Hulsey, David L. Alderson, Jean Carlson</dc:creator>
    </item>
    <item>
      <title>Estimating the Unobservable Components of Electricity Demand Response with Inverse Optimization</title>
      <link>https://arxiv.org/abs/2410.02774</link>
      <description>arXiv:2410.02774v1 Announce Type: cross 
Abstract: Understanding and predicting the electricity demand responses to prices are critical activities for system operators, retailers, and regulators. While conventional machine learning and time series analyses have been adequate for the routine demand patterns that have adapted only slowly over many years, the emergence of active consumers with flexible assets such as solar-plus-storage systems, and electric vehicles, introduces new challenges. These active consumers exhibit more complex consumption patterns, the drivers of which are often unobservable to the retailers and system operators. In practice, system operators and retailers can only monitor the net demand (metered at grid connection points), which reflects the overall energy consumption or production exchanged with the grid. As a result, all "behind-the-meter" activities-such as the use of flexibility-remain hidden from these entities. Such behind-the-meter behavior may be controlled by third party agents or incentivized by tariffs; in either case, the retailer's revenue and the system loads would be impacted by these activities behind the meter, but their details can only be inferred. We define the main components of net demand, as baseload, flexible, and self-generation, each having nonlinear responses to market price signals. As flexible demand response and self generation are increasing, this raises a pressing question of whether existing methods still perform well and, if not, whether there is an alternative way to understand and project the unobserved components of behavior. In response to this practical challenge, we evaluate the potential of a data-driven inverse optimization (IO) methodology. This approach characterizes decomposed consumption patterns without requiring direct observation of behind-the-meter behavior or device-level metering [...]</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02774v1</guid>
      <category>eess.SP</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrian Esteban-Perez, Derek Bunn, Yashar Ghiassi-Farrokhfal</dc:creator>
    </item>
    <item>
      <title>Modelling the longevity of complex living systems</title>
      <link>https://arxiv.org/abs/2410.02838</link>
      <description>arXiv:2410.02838v1 Announce Type: cross 
Abstract: This extended abstract was presented at the Nectar Track of ECML PKDD 2024 in Vilnius, Lithuania. The content supplements a recently published paper "Laws of Macroevolutionary Expansion" in the Proceedings of the National Academy of Sciences (PNAS).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02838v1</guid>
      <category>q-bio.PE</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Indr\.e \v{Z}liobait\.e</dc:creator>
    </item>
    <item>
      <title>Multiscale Multi-Type Spatial Bayesian Analysis of Wildfires and Population Change That Avoids MCMC and Approximating the Posterior Distribution</title>
      <link>https://arxiv.org/abs/2410.02905</link>
      <description>arXiv:2410.02905v1 Announce Type: cross 
Abstract: In recent years, wildfires have significantly increased in the United States (U.S.), making certain areas harder to live in. This motivates us to jointly analyze active fires and population changes in the U.S. from July 2020 to June 2021. The available data are recorded on different scales (or spatial resolutions) and by different types of distributions (referred to as multi-type data). Moreover, wildfires are known to have feedback mechanism that creates signal-to-noise dependence. We analyze point-referenced remote sensing fire data from National Aeronautics and Space Administration (NASA) and county-level population change data provided by U.S. Census Bureau's Population Estimates Program (PEP). To do this, we develop a multiscale multi-type spatial Bayesian hierarchical model that assumes the average number of fires is zero-inflated normal, the incidence of fire as Bernoulli, and the percentage population change as normally distributed. This high-dimensional dataset makes Markov chain Monte Carlo (MCMC) implementation infeasible. We bypass MCMC by extending a computationally efficient Bayesian framework to directly sample from the exact posterior distribution, referred to as Exact Posterior Regression (EPR), which includes a term to model feedback. A simulation study is included to compare our new EPR method to the traditional Bayesian model fitted via MCMC. In our analysis, we obtained predictions of wildfire probabilities, identified several useful covariates, and found that regions with many fires were directly related to population change.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02905v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shijie Zhou, Jonathan R. Bradley</dc:creator>
    </item>
    <item>
      <title>Identifying Hierarchical Structures in Network Data</title>
      <link>https://arxiv.org/abs/2410.02929</link>
      <description>arXiv:2410.02929v1 Announce Type: cross 
Abstract: In this paper, we introduce a hierarchical extension of the stochastic blockmodel to identify multilevel community structures in networks. We also present a Markov chain Monte Carlo (MCMC) and a variational Bayes algorithm to fit the model and obtain approximate posterior inference. Through simulated and real datasets, we demonstrate that the model successfully identifies communities and supercommunities when they exist in the data. Additionally, we observe that the model returns a single supercommunity when there is no evidence of multilevel community structure. As expected in the case of the single-level stochastic blockmodel, we observe that the MCMC algorithm consistently outperforms its variational Bayes counterpart. Therefore, we recommend using MCMC whenever the network size allows for computational feasibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02929v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Regueiro, Abel Rodr\'iguez, Juan Sosa</dc:creator>
    </item>
    <item>
      <title>Parrondo's effects with aperiodic protocols</title>
      <link>https://arxiv.org/abs/2410.02987</link>
      <description>arXiv:2410.02987v1 Announce Type: cross 
Abstract: In this work, we study the effectiveness of employing archetypal aperiodic sequencing -- namely Fibonacci, Thue-Morse, and Rudin-Saphiro -- on the Parrondian effect. From a capital gain perspective, our results show that these series do yield a Parrondo's Paradox with the Thue-Morse based strategy outperforming not only the other two aperiodic strategies but benchmark Parrondian games with random and periodical ($AABBAABB\ldots$) switching as well. The least performing of the three aperiodic strategies is the Rudin-Shapiro. To elucidate the underlying causes of these results, we analyze the cross-correlation between the capital generated by the switching protocols and that of the isolated losing games. This analysis reveals that a pronounced anti-correlation (below -0.95) with both isolated games is typically required to achieve a robust manifestation of Parrondo's effect. We also study the influence of the sequencing on the capital using the lacunarity and persistence measures. In general, we observe that the switching protocols tend to become less performing in terms of the capital as one increases the persistence and thus approaches the features of an isolated losing game. For the (log-)lacunarity, a property related to heterogeneity, we notice that for small persistence (less than 0.5) the performance increases with the lacunarity with a maximum around 0.4. In respect of this, our work shows that the optimisation of a switching protocol is strongly dependent on a fine tune between persistence and heterogeneity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02987v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <category>stat.AP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcelo A. Pires, Erveton P. Pinto, Rone N. da Silva, S\'ilvio M. Duarte Queir\'os</dc:creator>
    </item>
    <item>
      <title>The Quadratic Optimization Bias Of Large Covariance Matrices</title>
      <link>https://arxiv.org/abs/2410.03053</link>
      <description>arXiv:2410.03053v1 Announce Type: cross 
Abstract: We describe a puzzle involving the interactions between an optimization of a multivariate quadratic function and a "plug-in" estimator of a spiked covariance matrix. When the largest eigenvalues (i.e., the spikes) diverge with the dimension, the gap between the true and the out-of-sample optima typically also diverges. We show how to "fine-tune" the plug-in estimator in a precise way to avoid this outcome. Central to our description is a "quadratic optimization bias" function, the roots of which determine this fine-tuning property. We derive an estimator of this root from a finite number of observations of a high dimensional vector. This leads to a new covariance estimator designed specifically for applications involving quadratic optimization. Our theoretical results have further implications for improving low dimensional representations of data, and principal component analysis in particular.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03053v1</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Hubeyb Gurdogan, Alex Shkolnik</dc:creator>
    </item>
    <item>
      <title>Robust Bond Risk Premia Predictability Test in the Quantiles</title>
      <link>https://arxiv.org/abs/2410.03557</link>
      <description>arXiv:2410.03557v1 Announce Type: cross 
Abstract: Different from existing literature on testing the macro-spanning hypothesis of bond risk premia, which only considers mean regressions, this paper investigates whether the yield curve represented by CP factor (Cochrane and Piazzesi, 2005) contains all available information about future bond returns in a predictive quantile regression with many other macroeconomic variables. In this study, we introduce the Trend in Debt Holding (TDH) as a novel predictor, testing it alongside established macro indicators such as Trend Inflation (TI) (Cieslak and Povala, 2015), and macro factors from Ludvigson and Ng (2009). A significant challenge in this study is the invalidity of traditional quantile model inference approaches, given the high persistence of many macro variables involved. Furthermore, the existing methods addressing this issue do not perform well in the marginal test with many highly persistent predictors. Thus, we suggest a robust inference approach, whose size and power performance are shown to be better than existing tests. Using data from 1980-2022, the macro-spanning hypothesis is strongly supported at center quantiles by the empirical finding that the CP factor has predictive power while all other macro variables have negligible predictive power in this case. On the other hand, the evidence against the macro-spanning hypothesis is found at tail quantiles, in which TDH has predictive power at right tail quantiles while TI has predictive power at both tails quantiles. Finally, we show the performance of in-sample and out-of-sample predictions implemented by the proposed method are better than existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03557v1</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaosai Liao, Xinjue Li, Qingliang Fan</dc:creator>
    </item>
    <item>
      <title>Functional Singular Value Decomposition</title>
      <link>https://arxiv.org/abs/2410.03619</link>
      <description>arXiv:2410.03619v1 Announce Type: cross 
Abstract: Heterogeneous functional data are commonly seen in time series and longitudinal data analysis. To capture the statistical structures of such data, we propose the framework of Functional Singular Value Decomposition (FSVD), a unified framework with structure-adaptive interpretability for the analysis of heterogeneous functional data. We establish the mathematical foundation of FSVD by proving its existence and providing its fundamental properties using operator theory. We then develop an implementation approach for noisy and irregularly observed functional data based on a novel joint kernel ridge regression scheme and provide theoretical guarantees for its convergence and estimation accuracy. The framework of FSVD also introduces the concepts of intrinsic basis functions and intrinsic basis vectors, which represent two fundamental statistical structures for random functions and connect FSVD to various tasks including functional principal component analysis, factor models, functional clustering, and functional completion. We compare the performance of FSVD with existing methods in several tasks through extensive simulation studies. To demonstrate the value of FSVD in real-world datasets, we apply it to extract temporal patterns from a COVID-19 case count dataset and perform data completion on an electronic health record dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03619v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jianbin Tan, Pixu Shi, Anru R. Zhang</dc:creator>
    </item>
    <item>
      <title>Spatial Hyperspheric Models for Compositional Data</title>
      <link>https://arxiv.org/abs/2410.03648</link>
      <description>arXiv:2410.03648v1 Announce Type: cross 
Abstract: Compositional data are an increasingly prevalent data source in spatial statistics. Analysis of such data is typically done on log-ratio transformations or via Dirichlet regression. However, these approaches often make unnecessarily strong assumptions (e.g., strictly positive components, exclusively negative correlations). An alternative approach uses square-root transformed compositions and directional distributions. Such distributions naturally allow for zero-valued components and positive correlations, yet they may include support outside the non-negative orthant and are not generative for compositional data. To overcome this challenge, we truncate the elliptically symmetric angular Gaussian (ESAG) distribution to the non-negative orthant. Additionally, we propose a spatial hyperspheric regression that contains fixed and random multivariate spatial effects. The proposed method also contains a term that can be used to propagate uncertainty that may arise from precursory stochastic models (i.e., machine learning classification). We demonstrate our method on a simulation study and on classified bioacoustic signals of the Dryobates pubescens (downy woodpecker).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03648v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael R. Schwob, Mevin B. Hooten, Nicholas M. Calzada</dc:creator>
    </item>
    <item>
      <title>The short-term association between environmental variables and mortality: evidence from Europe</title>
      <link>https://arxiv.org/abs/2405.18020</link>
      <description>arXiv:2405.18020v3 Announce Type: replace 
Abstract: Using fine-grained, publicly available data, this paper studies the short-term association between environmental factors, i.e., weather and air pollution characteristics, and weekly mortality rates in small geographical regions in Europe. Hereto, we develop a mortality modeling framework where a baseline model describes a region-specific, seasonal trend observed within the historical weekly mortality rates. Using a machine learning algorithm, we then explain deviations from this baseline using features constructed from environmental data that capture anomalies and extreme events. We illustrate our proposed modeling framework through a case study on more than 550 NUTS 3 regions (Nomenclature of Territorial Units for Statistics, level 3) in 20 European countries. Using interpretation tools, we unravel insights into which environmental features are most important when estimating excess or deficit mortality relative to the baseline and explore how these features interact. Moreover, we investigate harvesting effects through our constructed weekly mortality modeling framework. Our findings show that temperature-related features are most influential in explaining mortality deviations from the baseline over short time periods. Furthermore, we find that environmental features prove particularly beneficial in southern regions for explaining elevated levels of mortality, and we observe evidence of a harvesting effect related to heat waves.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18020v3</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jens Robben, Katrien Antonio, Torsten Kleinow</dc:creator>
    </item>
    <item>
      <title>Approximate Bayesian computation for Markovian binary trees in phylogenetics</title>
      <link>https://arxiv.org/abs/2309.00194</link>
      <description>arXiv:2309.00194v3 Announce Type: replace-cross 
Abstract: Phylogenetic trees describe the relationships between species in the evolutionary process, and provide information about the rates of diversification. To understand the mechanisms behind macroevolution, we consider a class of multitype branching processes called Markovian binary trees (MBTs). MBTs allow for trait-based variation in diversification rates, and provide a flexible and realistic probabilistic model for phylogenetic trees. We develop an approximate Bayesian computation (ABC) scheme to infer the rates of MBT parameters by exploiting the information in the shapes of phylogenetic trees. We evaluate the accuracy of this inference method using simulation studies, and find that our method is able to detect variation in the diversification rates, with accuracy comparable to, and generally better than, likelihood-based methods. In an application to a real-life phylogeny of squamata, we reinforce conclusions drawn from earlier studies, in particular supporting the existence of ovi-/viviparity transitions in both directions. Our method demonstrates the potential for more complex models of evolution to be employed in phylogenetic inference, in conjunction with likelihood-free schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.00194v3</guid>
      <category>q-bio.PE</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingqi He, Sophie Hautphenne, Yao-ban Chan</dc:creator>
    </item>
    <item>
      <title>Demystifying and avoiding the OLS "weighting problem": Unmodeled heterogeneity and straightforward solutions</title>
      <link>https://arxiv.org/abs/2403.03299</link>
      <description>arXiv:2403.03299v2 Announce Type: replace-cross 
Abstract: Researchers have long run regressions of an outcome variable (Y) on a treatment (D) and covariates (X) to estimate treatment effects. Even absent unobserved confounding, the regression coefficient on D in this setup reports a conditional variance weighted average of strata-wise average effects, not generally equal to the average treatment effect (ATE). Numerous proposals have been offered to cope with this "weighting problem", including interpretational tools to help characterize the weights and diagnostic aids to help researchers assess the potential severity of this problem. We make two contributions that together suggest an alternative direction for researchers and this literature. Our first contribution is conceptual, demystifying these weights. Simply put, under heterogeneous treatment effects (and varying probability of treatment), the linear regression of Y on D and X will be misspecified. The "weights" of regression offer one characterization for the coefficient from regression that helps to clarify how it will depart from the ATE. We also derive a more general expression for the weights than what is usually referenced. Our second contribution is practical: as these weights simply characterize misspecification bias, we suggest simply avoiding them through an approach that tolerate heterogeneous effects. A wide range of longstanding alternatives (regression-imputation/g-computation, interacted regression, and balancing weights) relax specification assumptions to allow heterogeneous effects. We make explicit the assumption of "separate linearity", under which each potential outcome is separately linear in X. This relaxation of conventional linearity offers a common justification for all of these methods and avoids the weighting problem, at an efficiency cost that will be small when there are few covariates relative to sample size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03299v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chad Hazlett, Tanvi Shinkre</dc:creator>
    </item>
    <item>
      <title>Priors from Envisioned Posterior Judgments: A Novel Elicitation Approach With Application to Bayesian Clinical Trials</title>
      <link>https://arxiv.org/abs/2409.05271</link>
      <description>arXiv:2409.05271v2 Announce Type: replace-cross 
Abstract: The uptake of formalized prior elicitation from experts in Bayesian clinical trials has been limited, largely due to the challenges associated with complex statistical modeling, the lack of practical tools, and the cognitive burden on experts required to quantify their uncertainty using probabilistic language. Additionally, existing methods do not address prior-posterior coherence, i.e., does the posterior distribution, obtained mathematically from combining the estimated prior with the trial data, reflect the expert's actual posterior beliefs? We propose a new elicitation approach that seeks to ensure prior-posterior coherence and reduce the expert's cognitive burden. This is achieved by eliciting responses about the expert's envisioned posterior judgments under various potential data outcomes and inferring the prior distribution by minimizing the discrepancies between these responses and the expected responses obtained from the posterior distribution. The feasibility and potential value of the new approach are illustrated through an application to a real trial currently underway.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05271v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yongdong Ouyang, Janice J Eng, Denghuang Zhan, Hubert Wong</dc:creator>
    </item>
    <item>
      <title>Estimating Interpretable Heterogeneous Treatment Effect with Causal Subgroup Discovery in Survival Outcomes</title>
      <link>https://arxiv.org/abs/2409.19241</link>
      <description>arXiv:2409.19241v2 Announce Type: replace-cross 
Abstract: Estimating heterogeneous treatment effect (HTE) for survival outcomes has gained increasing attention, as it captures the variation in treatment efficacy across patients or subgroups in delaying disease progression. However, most existing methods focus on post-hoc subgroup identification rather than simultaneously estimating HTE and selecting relevant subgroups. In this paper, we propose an interpretable HTE estimation framework that integrates three meta-learners that simultaneously estimate CATE for survival outcomes and identify predictive subgroups. We evaluated the performance of our method through comprehensive simulation studies across various randomized clinical trial (RCT) settings. Additionally, we demonstrated its application in a large RCT for age-related macular degeneration (AMD), a polygenic progressive eye disease, to estimate the HTE of an antioxidant and mineral supplement on time-to-AMD progression and to identify genetics-based subgroups with enhanced treatment effects. Our method offers a direct interpretation of the estimated HTE and provides evidence to support precision healthcare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19241v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Na Bo, Ying Ding</dc:creator>
    </item>
  </channel>
</rss>
