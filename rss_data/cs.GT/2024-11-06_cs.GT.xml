<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 Nov 2024 02:44:46 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fair and Welfare-Efficient Constrained Multi-matchings under Uncertainty</title>
      <link>https://arxiv.org/abs/2411.02654</link>
      <description>arXiv:2411.02654v1 Announce Type: new 
Abstract: We study fair allocation of constrained resources, where a market designer optimizes overall welfare while maintaining group fairness. In many large-scale settings, utilities are not known in advance, but are instead observed after realizing the allocation. We therefore estimate agent utilities using machine learning. Optimizing over estimates requires trading-off between mean utilities and their predictive variances. We discuss these trade-offs under two paradigms for preference modeling -- in the stochastic optimization regime, the market designer has access to a probability distribution over utilities, and in the robust optimization regime they have access to an uncertainty set containing the true utilities with high probability. We discuss utilitarian and egalitarian welfare objectives, and we explore how to optimize for them under stochastic and robust paradigms. We demonstrate the efficacy of our approaches on three publicly available conference reviewer assignment datasets. The approaches presented enable scalable constrained resource allocation under uncertainty for many combinations of objectives and preference models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02654v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elita Lobo, Justin Payan, Cyrus Cousins, Yair Zick</dc:creator>
    </item>
    <item>
      <title>Pricing and Competition for Generative AI</title>
      <link>https://arxiv.org/abs/2411.02661</link>
      <description>arXiv:2411.02661v1 Announce Type: new 
Abstract: Compared to classical machine learning (ML) models, generative models offer a new usage paradigm where (i) a single model can be used for many different tasks out-of-the-box; (ii) users interact with this model over a series of natural language prompts; and (iii) the model is ideally evaluated on binary user satisfaction with respect to model outputs. Given these characteristics, we explore the problem of how developers of new generative AI software can release and price their technology. We first develop a comparison of two different models for a specific task with respect to user cost-effectiveness. We then model the pricing problem of generative AI software as a game between two different companies who sequentially release their models before users choose their preferred model for each task. Here, the price optimization problem becomes piecewise continuous where the companies must choose a subset of the tasks on which to be cost-effective and forgo revenue for the remaining tasks. In particular, we reveal the value of market information by showing that a company who deploys later after knowing their competitor's price can always secure cost-effectiveness on at least one task, whereas the company who is the first-to-market must price their model in a way that incentivizes higher prices from the latecomer in order to gain revenue. Most importantly, we find that if the different tasks are sufficiently similar, the first-to-market model may become cost-ineffective on all tasks regardless of how this technology is priced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02661v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rafid Mahmood</dc:creator>
    </item>
    <item>
      <title>Constant Approximation for Weighted Nash Social Welfare with Submodular Valuations</title>
      <link>https://arxiv.org/abs/2411.02942</link>
      <description>arXiv:2411.02942v1 Announce Type: new 
Abstract: We study the problem of assigning items to agents so as to maximize the \emph{weighted} Nash Social Welfare (NSW) under submodular valuations. The best-known result for the problem is an $O(nw_{\max})$-approximation due to Garg, Husic, Li, Vega, and Vondrak~\cite{GHL23}, where $w_{\max}$ is the maximum weight over all agents. Obtaining a constant approximation algorithm is an open problem in the field that has recently attracted considerable attention.
  We give the first such algorithm for the problem, thus solving the open problem in the affirmative. Our algorithm is based on the natural Configuration LP for the problem, which was introduced recently by Feng and Li~\cite{FL24} for the additive valuation case. Our rounding algorithm is similar to that of Li \cite{Li25} developed for the unrelated machine scheduling problem to minimize weighted completion time. Roughly speaking, we designate the largest item in each configuration as a large item and the remaining items as small items. So, every agent gets precisely 1 fractional large item in the configuration LP solution. With the rounding algorithm in \cite{Li25}, we can ensure that in the obtained solution, every agent gets precisely 1 large item, and the assignments of small items are negatively correlated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02942v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuda Feng, Yang Hu, Shi Li, Ruilong Zhang</dc:creator>
    </item>
    <item>
      <title>On the Role of Constraints in the Complexity of Min-Max Optimization</title>
      <link>https://arxiv.org/abs/2411.03248</link>
      <description>arXiv:2411.03248v1 Announce Type: new 
Abstract: We investigate the role of constraints in the computational complexity of min-max optimization. First, we show that when the constraints are jointly convex (i.e., the min player and max player share the same constraints), computing a local min-max equilibrium with a nonconvex-concave objective is PPAD-hard. This improves the result of Daskalakis, Skoulakis, and Zampetakis [2021] along multiple directions: it applies to nonconvex-concave objectives (instead of nonconvex-nonconcave ones) that are degree-two polynomials, and it's essentially tight in the parameters. Second, we show that with general constraints (i.e., the min player and max player have different constraints), even convex-concave min-max optimization becomes PPAD-hard. Conversely, local min-max equilibria for nonconvex-concave and convex-concave objectives can be computed in polynomial time under simpler classes of constraints. Therefore, our results show that constraints are a key driver of the complexity of min-max optimization problems. Along the way, we also provide PPAD-membership of a general problem related to quasi-variational inequalities, which has applications beyond our problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03248v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martino Bernasconi, Matteo Castiglioni, Andrea Celli, Gabriele Farina</dc:creator>
    </item>
    <item>
      <title>Stable Matching with Ties: Approximation Ratios and Learning</title>
      <link>https://arxiv.org/abs/2411.03270</link>
      <description>arXiv:2411.03270v1 Announce Type: new 
Abstract: We study the problem of matching markets with ties, where one side of the market does not necessarily have strict preferences over members at its other side. For example, workers do not always have strict preferences over jobs, students can give the same ranking for different schools and more. In particular, assume w.l.o.g. that workers' preferences are determined by their utility from being matched to each job, which might admit ties. Notably, in contrast to classical two-sided markets with strict preferences, there is no longer a single stable matching that simultaneously maximizes the utility for all workers.
  We aim to guarantee each worker the largest possible share from the utility in her best possible stable matching. We call the ratio between the worker's best possible stable utility and its assigned utility the \emph{Optimal Stable Share} (OSS)-ratio. We first prove that distributions over stable matchings cannot guarantee an OSS-ratio that is sublinear in the number of workers. Instead, randomizing over possibly non-stable matchings, we show how to achieve a tight logarithmic OSS-ratio. Then, we analyze the case where the real utility is not necessarily known and can only be approximated. In particular, we provide an algorithm that guarantees a similar fraction of the utility compared to the best possible utility. Finally, we move to a bandit setting, where we select a matching at each round and only observe the utilities for matches we perform. We show how to utilize our results for approximate utilities to gracefully interpolate between problems without ties and problems with statistical ties (small suboptimality gaps).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03270v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shiyun Lin, Simon Mauras, Nadav Merlis, Vianney Perchet</dc:creator>
    </item>
    <item>
      <title>On the Computation of Equilibria in Discrete First-Price Auctions</title>
      <link>https://arxiv.org/abs/2402.12068</link>
      <description>arXiv:2402.12068v2 Announce Type: replace 
Abstract: We study the computational complexity of computing Bayes-Nash equilibria in first-price auctions with discrete value distributions and discrete bidding space, under general subjective beliefs. It is known that such auctions do not always have pure equilibria. In this paper, we prove that the problem of deciding their existence is NP-complete, even for approximate equilibria. On the other hand, it can be shown that mixed equilibria are guaranteed to exist; however, their computational complexity has not been studied before. We establish the PPAD-completeness of computing a mixed equilibrium and we complement this by an efficient algorithm for finding symmetric approximate equilibria in the special case of iid priors. En route to these results, we develop a computational equivalence framework between continuous and discrete first-price auctions, which can be of independent interest, and which allows us to transfer existing positive and negative results from one setting to the other. Finally, we show that correlated equilibria of the auction can be computed in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12068v2</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aris Filos-Ratsikas, Yiannis Giannakopoulos, Alexandros Hollender, Charalampos Kokkalis</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Posted Pricing for a Single Item</title>
      <link>https://arxiv.org/abs/2406.00819</link>
      <description>arXiv:2406.00819v2 Announce Type: replace 
Abstract: Selling a single item to $n$ self-interested buyers is a fundamental problem in economics, where the two objectives typically considered are welfare maximization and revenue maximization. Since the optimal mechanisms are often impractical and do not work for sequential buyers, posted pricing mechanisms, where fixed prices are set for the item for different buyers, have emerged as a practical and effective alternative. This paper investigates how many samples are needed from buyers' value distributions to find near-optimal posted prices, considering both independent and correlated buyer distributions, and welfare versus revenue maximization. We obtain matching upper and lower bounds (up to logarithmic factors) on the sample complexity for all these settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00819v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Billy Jin, Thomas Kesselheim, Will Ma, Sahil Singla</dc:creator>
    </item>
    <item>
      <title>GemNet: Menu-Based, Strategy-Proof Multi-Bidder Auctions Through Deep Learning</title>
      <link>https://arxiv.org/abs/2406.07428</link>
      <description>arXiv:2406.07428v3 Announce Type: replace 
Abstract: Automated mechanism design (AMD) uses computational methods for mechanism design. Differentiable economics is a form of AMD that uses deep learning to learn mechanism designs and has enabled strong progress in AMD in recent years. Nevertheless, a major open problem has been to learn multi-bidder, general, and fully strategy-proof (SP) auctions. We introduce GEneral Menu-based NETwork (GemNet), which significantly extends the menu-based approach of the single-bidder RochetNet (D\"utting et al., 2024) to the multi-bidder setting. The challenge in achieving SP is to learn bidder-independent menus that are feasible, so that the optimal menu choices for each bidder do not over-allocate items when taken together (we call this menu compatibility). GemNet penalizes the failure of menu compatibility during training, and transforms learned menus after training through price changes, by considering a set of discretized bidder values and reasoning about Lipschitz smoothness to guarantee menu compatibility on the entire value space. This approach is general, leaving trained menus that already satisfy menu compatibility undisturbed and reducing to RochetNet for a single bidder. Mixed-integer linear programs are used for menu transforms, and through a number of optimizations enabled by deep learning, including adaptive grids and methods to skip menu elements, we scale to large auction design problems. GemNet learns auctions with better revenue than affine maximization methods, achieves exact SP whereas previous general multi-bidder methods are approximately SP, and offers greatly enhanced interpretability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07428v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tonghan Wang, Yanchen Jiang, David C. Parkes</dc:creator>
    </item>
    <item>
      <title>Clock Auctions Augmented with Unreliable Advice</title>
      <link>https://arxiv.org/abs/2408.06483</link>
      <description>arXiv:2408.06483v2 Announce Type: replace 
Abstract: We provide the first analysis of (deferred acceptance) clock auctions in the learning-augmented framework. These auctions satisfy a unique list of appealing properties, including obvious strategyproofness, transparency, and unconditional winner privacy, making them particularly well-suited for real-world applications. However, early work that evaluated their performance from a worst-case analysis perspective concluded that no deterministic clock auction with $n$ bidders can achieve a $O(\log^{1-\epsilon} n)$ approximation of the optimal social welfare for any $\epsilon&gt;0$, even in very simple settings. This overly pessimistic impossibility result heavily depends on the assumption that the designer has no information regarding the bidders' values. Leveraging the learning-augmented framework, we instead consider a designer equipped with some (machine-learned) advice regarding the optimal solution; this advice can provide useful guidance if accurate, but it may be unreliable.
  Our main results are learning-augmented clock auctions that use this advice to achieve much stronger guarantees whenever the advice is accurate (consistency), while maintaining worst-case guarantees even if this advice is arbitrarily inaccurate (robustness). Our first clock auction achieves the best of both worlds: $(1+\epsilon)$-consistency for any $\epsilon&gt;0$ and $O(\log{n})$ robustness; we also extend this auction to achieve error tolerance. We then consider a much stronger notion of consistency, which we refer to as consistency$^\infty$, and provide auctions that achieves a near-optimal trade-off between consistency$^\infty$ and robustness. Finally, using our impossibility results regarding this trade-off, we prove lower bounds on the ``cost of smoothness,'' i.e., on the achievable robustness if we also require that the performance of the auction degrades smoothly as a function of the prediction error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06483v2</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vasilis Gkatzelis, Daniel Schoepflin, Xizhi Tan</dc:creator>
    </item>
    <item>
      <title>Randomized Strategic Facility Location with Predictions</title>
      <link>https://arxiv.org/abs/2409.07142</link>
      <description>arXiv:2409.07142v3 Announce Type: replace 
Abstract: In the strategic facility location problem, a set of agents report their locations in a metric space and the goal is to use these reports to open a new facility, minimizing an aggregate distance measure from the agents to the facility. However, agents are strategic and may misreport their locations to influence the facility's placement in their favor. The aim is to design truthful mechanisms, ensuring agents cannot gain by misreporting. This problem was recently revisited through the learning-augmented framework, aiming to move beyond worst-case analysis and design truthful mechanisms that are augmented with (machine-learned) predictions. The focus of this prior work was on mechanisms that are deterministic and augmented with a prediction regarding the optimal facility location. In this paper, we provide a deeper understanding of this problem by exploring the power of randomization as well as the impact of different types of predictions on the performance of truthful learning-augmented mechanisms. We study both the single-dimensional and the Euclidean case and provide upper and lower bounds regarding the achievable approximation of the optimal egalitarian social cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07142v3</guid>
      <category>cs.GT</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Balkanski, Vasilis Gkatzelis, Golnoosh Shahkarami</dc:creator>
    </item>
    <item>
      <title>Designing Equilibria in Concurrent Games with Social Welfare and Temporal Logic Constraints</title>
      <link>https://arxiv.org/abs/2306.03045</link>
      <description>arXiv:2306.03045v3 Announce Type: replace-cross 
Abstract: In game theory, mechanism design is concerned with the design of incentives so that a desired outcome of the game can be achieved. In this paper, we explore the concept of equilibrium design, where incentives are designed to obtain a desirable equilibrium that satisfies a specific temporal logic property. Our study is based on a framework where system specifications are represented as temporal logic formulae, games as quantitative concurrent game structures, and players' goals as mean-payoff objectives. We consider system specifications given by LTL and GR(1) formulae, and show that designing incentives to ensure that a given temporal logic property is satisfied on some/every Nash equilibrium of the game can be achieved in PSPACE for LTL properties and in NP/{\Sigma}P 2 for GR(1) specifications. We also examine the complexity of related decision and optimisation problems, such as optimality and uniqueness of solutions, as well as considering social welfare, and show that the complexities of these problems lie within the polynomial hierarchy. Equilibrium design can be used as an alternative solution to rational synthesis and verification problems for concurrent games with mean-payoff objectives when no solution exists or as a technique to repair concurrent games with undesirable Nash equilibria in an optimal way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03045v3</guid>
      <category>cs.LO</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Gutierrez, Muhammad Najib, Giuseppe Perelli, Michael Wooldridge</dc:creator>
    </item>
    <item>
      <title>Convergence of Decentralized Actor-Critic Algorithm in General-sum Markov Games</title>
      <link>https://arxiv.org/abs/2409.04613</link>
      <description>arXiv:2409.04613v3 Announce Type: replace-cross 
Abstract: Markov games provide a powerful framework for modeling strategic multi-agent interactions in dynamic environments. Traditionally, convergence properties of decentralized learning algorithms in these settings have been established only for special cases, such as Markov zero-sum and potential games, which do not fully capture real-world interactions. In this paper, we address this gap by studying the asymptotic properties of learning algorithms in general-sum Markov games. In particular, we focus on a decentralized algorithm where each agent adopts an actor-critic learning dynamic with asynchronous step sizes. This decentralized approach enables agents to operate independently, without requiring knowledge of others' strategies or payoffs. We introduce the concept of a Markov Near-Potential Function (MNPF) and demonstrate that it serves as an approximate Lyapunov function for the policy updates in the decentralized learning dynamics, which allows us to characterize the convergent set of strategies. We further strengthen our result under specific regularity conditions and with finite Nash equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04613v3</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 06 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chinmay Maheshwari, Manxi Wu, Shankar Sastry</dc:creator>
    </item>
  </channel>
</rss>
