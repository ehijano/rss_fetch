<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Mar 2025 05:00:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Causal language jumps in clinical practice guidelines for diabetes management</title>
      <link>https://arxiv.org/abs/2503.03557</link>
      <description>arXiv:2503.03557v1 Announce Type: new 
Abstract: Clinical practice guidelines are designed to guide clinical practice and involve causal language. Sometimes guidelines make or require stronger causal claims than those in the references they rely on, a phenomenon we refer to as 'causal language jump'. We evaluated the strength of expressed causation in diabetes guidelines and the evidence they reference to assess the pattern of jumps. We randomly sampled 300 guideline statements from four diabetes guidelines. We rated the causation strength in the statements and the dependence on causation in recommendations supported by these statements using existing scales. Among the causal statements, the cited original studies were similarly assessed. We also assessed how well they report target trial emulation (TTE) components as a proxy for reliability. Of the sampled statements, 114 (38.0%) were causal, and 76 (66.7%) expressed strong causation. 27.2% (31/114) of causal guideline statements demonstrated a "causal language jump", and 34.9% (29/83) of guideline recommendations cannot be effectively supported. Of the 53 eligible studies for TTE rating, most did not report treatment assignment and causal contrast in detail. Our findings suggest causal language jumps were common among diabetes guidelines. While these jumps are sometimes inevitable, they should always be supported by good causal inference practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03557v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Keling Wang, Chang Wei, Jeremy A. Labrecque</dc:creator>
    </item>
    <item>
      <title>A Theoretical Model for Grit in Pursuing Ambitious Ends</title>
      <link>https://arxiv.org/abs/2503.02952</link>
      <description>arXiv:2503.02952v1 Announce Type: cross 
Abstract: Ambition and risk-taking have been heralded as important ways for marginalized communities to get out of cycles of poverty. As a result, educational messaging often encourages individuals to strengthen their personal resolve and develop characteristics such as discipline and grit to succeed in ambitious ends. However, recent work in philosophy and sociology highlights that this messaging often does more harm than good for students in these situations. We study similar questions using a different epistemic approach and in simple theoretical models -- we provide a quantitative model of decision-making between stable and risky choices in the improving multi-armed bandits framework. We use this model to first study how individuals' "strategies" are affected by their level of grittiness and how this affects their accrued rewards. Then, we study the impact of various interventions, such as increasing grit or providing a financial safety net. Our investigation of rational decision making involves two different formal models of rationality, the competitive ratio between the accrued reward and the optimal reward and Bayesian quantification of uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02952v1</guid>
      <category>cs.CY</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>stat.AP</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Avrim Blum, Emily Diana, Kavya Ravichandran, Alexander Williams Tolbert</dc:creator>
    </item>
    <item>
      <title>Determine the Order of Functional Data</title>
      <link>https://arxiv.org/abs/2503.03000</link>
      <description>arXiv:2503.03000v1 Announce Type: cross 
Abstract: Dimension reduction is often necessary in functional data analysis, with functional principal component analysis being one of the most widely used techniques. A key challenge in applying these methods is determining the number of eigen-pairs to retain, a problem known as order determination. When a covariance function admits a finite representation, the challenge becomes estimating the rank of the associated covariance operator. While this problem is straightforward when the full trajectories of functional data are available, in practice, functional data are typically collected discretely and are subject to measurement error contamination. This contamination introduces a ridge to the empirical covariance function, which obscures the true rank of the covariance operator. We propose a novel procedure to identify the true rank of the covariance operator by leveraging the information of eigenvalues and eigenfunctions. By incorporating the nonparametric nature of functional data through smoothing techniques, the method is applicable to functional data collected at random, subject-specific points. Extensive simulation studies demonstrate the excellent performance of our approach across a wide range of settings, outperforming commonly used information-criterion-based methods and maintaining effectiveness even in high-noise scenarios. We further illustrate our method with two real-world data examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03000v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chi Zhang, Peijun Sang, Yingli Qin</dc:creator>
    </item>
    <item>
      <title>Optimal power procurement for green cellular wireless networks under uncertainty and chance constraints</title>
      <link>https://arxiv.org/abs/2503.03051</link>
      <description>arXiv:2503.03051v1 Announce Type: cross 
Abstract: Given the increasing global emphasis on sustainable energy usage and the rising energy demands of cellular wireless networks, this work seeks an optimal short-term, continuous-time power procurement schedule to minimize operating expenditure and the carbon footprint of cellular wireless networks equipped with energy storage capacity, and hybrid energy systems comprising uncertain renewable energy sources. Despite the stochastic nature of wireless fading channels, the network operator must ensure a certain quality-of-service (QoS) constraint with high probability. This probabilistic constraint prevents using the dynamic programming principle to solve the stochastic optimal control problem. This work introduces a novel time-continuous Lagrangian relaxation approach tailored for real-time, near-optimal energy procurement in cellular networks, overcoming tractability problems associated with the probabilistic QoS constraint. The numerical solution procedure includes an efficient upwind finite-difference solver for the Hamilton--Jacobi--Bellman equation corresponding to the relaxed problem, and an effective combination of the limited memory bundle method (LMBM) for handling nonsmooth optimization and the stochastic subgradient method (SSM) to navigate the stochasticity of the dual problem. Numerical results, based on the German power system and daily cellular traffic data, demonstrate the computational efficiency of the proposed numerical approach, providing a near-optimal policy in a practical timeframe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03051v1</guid>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadhir Ben Rached, Shyam Mohan Subbiah Pillai, Ra\'ul Tempone</dc:creator>
    </item>
    <item>
      <title>From Coverage to Prestige: A Comprehensive Assessment of Large-Scale Scientometric Data</title>
      <link>https://arxiv.org/abs/2503.03251</link>
      <description>arXiv:2503.03251v1 Announce Type: cross 
Abstract: As research in the Scientometric deepens, the impact of data quality on research outcomes has garnered increasing attention. This study, based on Web of Science (WoS) and Crossref datasets, systematically evaluates the differences between data sources and the effects of data merging through matching, comparison, and integration. Two core metrics were employed: Reference Coverage Rate (RCR) and Article Scientific Prestige (ASP), which respectively measure citation completeness (quantity) and academic influence (quality). The results indicate that the WoS dataset outperforms Crossref in its coverage of high-impact literature and ASP scores, while the Crossref dataset provides complementary value through its broader coverage of literature. Data merging significantly improves the completeness of the citation network, with particularly pronounced benefits in smaller disciplinary clusters such as Education and Arts. However, data merging also introduces some low-quality citations, resulting in a polarization of overall data quality. Moreover, the impact of data merging varies across disciplines; high-impact clusters such as Science, Biology, and Medicine benefit the most, whereas clusters like Social Sciences and Arts are more vulnerable to negative effects. This study highlights the critical role of data sources in Scientometric research and provides a framework for assessing and improving data quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03251v1</guid>
      <category>cs.DL</category>
      <category>stat.AP</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guoyang Rong, Ying Chen, Thorsten Koch, Keisuke Honda</dc:creator>
    </item>
    <item>
      <title>A Criterion for Extending Continuous-Mixture Identifiability Results</title>
      <link>https://arxiv.org/abs/2503.03536</link>
      <description>arXiv:2503.03536v1 Announce Type: cross 
Abstract: For continuous mixtures of random variables, we provide a simple criterion -- generating-function accessibility -- to extend previously known kernel-based identifiability (or unidentifiability) results to new kernel distributions. This criterion, based on functional relationships between the relevant kernels' moment-generating functions or Laplace transforms, may be applied to continuous mixtures of both discrete and continuous random variables. To illustrate the proposed approach, we present results for several specific kernels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03536v1</guid>
      <category>stat.ML</category>
      <category>math.PR</category>
      <category>stat.AP</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael R. Powers, Jiaxin Xu</dc:creator>
    </item>
    <item>
      <title>Finite-sample valid prediction of future insurance claims in the regression problem</title>
      <link>https://arxiv.org/abs/2503.03659</link>
      <description>arXiv:2503.03659v1 Announce Type: cross 
Abstract: In the current insurance literature, prediction of insurance claims in the regression problem is often performed with a statistical model. This model-based approach may suffer from several drawbacks: (i) model misspecification, (ii) selection effect, and (iii) lack of finite-sample validity. This article addresses these three issues simultaneously by employing conformal prediction-a general machine learning strategy for valid predictions. The proposed method is both model-free and tuning-parameter-free. It also guarantees finite-sample validity at a pre-assigned coverage probability level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03659v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liang Hong</dc:creator>
    </item>
    <item>
      <title>Correcting for bias due to mismeasured exposure in mediation analysis with a survival outcome</title>
      <link>https://arxiv.org/abs/2304.04868</link>
      <description>arXiv:2304.04868v4 Announce Type: replace-cross 
Abstract: Mediation analysis is widely used in health science research to evaluate the extent to which an intermediate variable explains an observed exposure-outcome relationship. However, the validity of analysis can be compromised when the exposure is measured with error. Motivated by the Health Professionals Follow-up Study (HPFS), we investigate the impact of exposure measurement error on assessing mediation with a survival outcome, based on the Cox proportional hazards outcome model. When the outcome is rare and there is no exposure-mediator interaction, we show that the uncorrected estimators of the natural indirect and direct effects can be biased into either direction, but the uncorrected estimator of the mediation proportion is approximately unbiased as long as the measurement error is not large or the mediator-exposure association is not strong. We develop ordinary regression calibration and risk set regression calibration approaches to correct the exposure measurement error-induced bias when estimating mediation effects and allowing for an exposure-mediator interaction in the Cox outcome model. The proposed approaches require a validation study to characterize the measurement error process. We apply the proposed approaches to the HPFS (1986-2016) to evaluate extent to which reduced body mass index mediates the protective effect of vigorous physical activity on the risk of cardiovascular diseases, and compare the finite-sample properties of the proposed estimators via simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.04868v4</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chao Cheng, Donna Spiegelman, Fan Li</dc:creator>
    </item>
    <item>
      <title>POMDP-Driven Cognitive Massive MIMO Radar: Joint Target Detection-Tracking In Unknown Disturbances</title>
      <link>https://arxiv.org/abs/2410.17967</link>
      <description>arXiv:2410.17967v2 Announce Type: replace-cross 
Abstract: The joint detection and tracking of a moving target embedded in an unknown disturbance represents a key feature that motivates the development of the cognitive radar paradigm. Building upon recent advancements in robust target detection with multiple-input multiple-output (MIMO) radars, this work explores the application of a Partially Observable Markov Decision Process (POMDP) framework to enhance the tracking and detection tasks in a statistically unknown environment. In the POMDP setup, the radar system is considered as an intelligent agent that continuously senses the surrounding environment, optimizing its actions to maximize the probability of detection $(P_D)$ and improve the target position and velocity estimation, all this while keeping a constant probability of false alarm $(P_{FA})$. The proposed approach employs an online algorithm that does not require any apriori knowledge of the noise statistics, and it relies on a much more general observation model than the traditional range-azimuth-elevation model employed by conventional tracking algorithms. Simulation results clearly show substantial performance improvement of the POMDP-based algorithm compared to the State-Action-Reward-State-Action (SARSA)-based one that has been recently investigated in the context of massive MIMO (MMIMO) radar systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17967v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.AP</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Imad Bouhou, Stefano Fortunati, Leila Gharsalli, Alexandre Renaux</dc:creator>
    </item>
    <item>
      <title>Chopin: An Open Source R-language Tool to Support Spatial Analysis on Parallelizable Infrastructure</title>
      <link>https://arxiv.org/abs/2412.11355</link>
      <description>arXiv:2412.11355v2 Announce Type: replace-cross 
Abstract: An increasing volume of studies utilize geocomputation methods in large spatial data. There is a bottleneck in scalable computation for general scientific use as the existing solutions require high-performance computing domain knowledge and are tailored for specific use cases. This study presents an R package `chopin` to reduce the technical burden for parallelization in geocomputation. Supporting popular spatial analysis packages in R, `chopin` leverages parallel computing by partitioning data that are involved in a computation task. The partitioning is implemented at regular grids, data hierarchies, and multiple file inputs with flexible input types for interoperability between different packages and efficiency. This approach makes the geospatial covariate calculation to the scale of the available processing power in a wide range of computing assets from laptop computers to high-performance computing infrastructure. Testing use cases in environmental exposure assessment demonstrated that the package reduced the execution time by order of processing units used. The work is expected to provide broader research communities using geospatial data with an efficient tool to process large scale data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11355v2</guid>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Insang Song, Kyle P. Messier</dc:creator>
    </item>
    <item>
      <title>Cheap Subsampling bootstrap confidence intervals for fast and robust inference</title>
      <link>https://arxiv.org/abs/2501.10289</link>
      <description>arXiv:2501.10289v3 Announce Type: replace-cross 
Abstract: Bootstrapping is often applied to get confidence limits for semiparametric inference of a target parameter in the presence of nuisance parameters. Bootstrapping with replacement can be computationally expensive and problematic when cross-validation is used in the estimation algorithm due to duplicate observations in the bootstrap samples. We provide a valid, fast, easy-to-implement subsampling bootstrap method for constructing confidence intervals for asymptotically linear estimators and discuss its application to semiparametric causal inference. Our method, inspired by the Cheap Bootstrap (Lam, 2022), leverages the quantiles of a t-distribution and has the desired coverage with few bootstrap replications. We show that the method is asymptotically valid if the subsample size is chosen appropriately as a function of the sample size. We illustrate our method with data from the LEADER trial (Marso et al., 2016), obtaining confidence intervals for a longitudinal targeted minimum loss-based estimator (van der Laan and Gruber, 2012). Through a series of empirical experiments, we also explore the impact of subsample size, sample size, and the number of bootstrap repetitions on the performance of the confidence interval.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10289v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johan Sebastian Ohlendorff, Anders Munch, Kathrine Kold S{\o}rensen, Thomas Alexander Gerds</dc:creator>
    </item>
    <item>
      <title>Fast exact recovery of noisy matrix from few entries: the infinity norm approach</title>
      <link>https://arxiv.org/abs/2501.19224</link>
      <description>arXiv:2501.19224v2 Announce Type: replace-cross 
Abstract: The matrix recovery (completion) problem, a central problem in data science and theoretical computer science, is to recover a matrix $A$ from a relatively small sample of entries.
  While such a task is impossible in general, it has been shown that one can recover $A$ exactly in polynomial time, with high probability, from a random subset of entries, under three (basic and necessary) assumptions: (1) the rank of $A$ is very small compared to its dimensions (low rank), (2) $A$ has delocalized singular vectors (incoherence), and (3) the sample size is sufficiently large.
  There are many different algorithms for the task, including convex optimization by Candes, Tao and Recht (2009), alternating projection by Hardt and Wooters (2014) and low rank approximation with gradient descent by Keshavan, Montanari and Oh (2009, 2010).
  In applications, it is more realistic to assume that data is noisy. In this case, these approaches provide an approximate recovery with small root mean square error. However, it is hard to transform such an approximate recovery to an exact one.
  Recently, results by Abbe et al. (2017) and Bhardwaj et al. (2023) concerning approximation in the infinity norm showed that we can achieve exact recovery even in the noisy case, given that the ground matrix has bounded precision. Beyond the three basic assumptions above, they required either the condition number of $A$ is small (Abbe et al.) or the gap between consecutive singular values is large (Bhardwaj et al.).
  In this paper, we remove these extra spectral assumptions. As a result, we obtain a simple algorithm for exact recovery in the noisy case, under only the three basic assumptions. This is the first such algorithm. To analyse this algorithm, we introduce a contour integration argument which is totally different from all previous methods and may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19224v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>BaoLinh Tran, Van Vu</dc:creator>
    </item>
    <item>
      <title>Generative Adversarial Networks for High-Dimensional Item Factor Analysis: A Deep Adversarial Learning Algorithm</title>
      <link>https://arxiv.org/abs/2502.10650</link>
      <description>arXiv:2502.10650v2 Announce Type: replace-cross 
Abstract: Advances in deep learning and representation learning have transformed item factor analysis (IFA) in the item response theory (IRT) literature by enabling more efficient and accurate parameter estimation. Variational Autoencoders (VAEs) have been one of the most impactful techniques in modeling high-dimensional latent variables in this context. However, the limited expressiveness of the inference model based on traditional VAEs can still hinder the estimation performance. We introduce Adversarial Variational Bayes (AVB) algorithms as an improvement to VAEs for IFA with improved flexibility and accuracy. By bridging the strengths of VAEs and Generative Adversarial Networks (GANs), AVB incorporates an auxiliary discriminator network to reframe the estimation process as a two-player adversarial game and removes the restrictive assumption of standard normal distributions in the inference model. Theoretically, AVB can achieve similar or higher likelihood compared to VAEs. A further enhanced algorithm, Importance-weighted Adversarial Variational Bayes (IWAVB) is proposed and compared with Importance-weighted Autoencoders (IWAE). In an exploratory analysis of empirical data, IWAVB demonstrated superior expressiveness by achieving a higher likelihood compared to IWAE. In confirmatory analysis with simulated data, IWAVB achieved similar mean-square error results to IWAE while consistently achieving higher likelihoods. When latent variables followed a multimodal distribution, IWAVB outperformed IWAE. With its innovative use of GANs, IWAVB is shown to have the potential to extend IFA to handle large-scale data, facilitating the potential integration of psychometrics and multimodal data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10650v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nanyu Luo, Feng Ji</dc:creator>
    </item>
  </channel>
</rss>
