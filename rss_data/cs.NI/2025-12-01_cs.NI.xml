<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Dec 2025 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Sensing and Understanding the World over Air: A Large Multimodal Model for Mobile Networks</title>
      <link>https://arxiv.org/abs/2511.21707</link>
      <description>arXiv:2511.21707v1 Announce Type: new 
Abstract: Large models (LMs), such as ChatGPT, have made a significant impact across diverse domains and hold great potential to facilitate the evolution of network intelligence. Wireless-native multi-modal large models (WMLMs) can sense and understand the physical world through multi-modal data, serving as a key enabler that integrates communication, sensing, and intelligence, and thus they can boost various smart services to billions of users. However, research on WMLMs remains in its infancy, and the construction of domain-specific multi-modal large models for wireless networks is still underexplored. In this paper, we outlines the key characteristics of WMLMs and summarizes existing methods, on the basis of which a wireless-native multimodal training paradigm is proposed. Specifically, we constructed a GPT-style WMLM model and trained it on a real-world large-scale dataset, leveraging wireless signals as an anchor modality for contrastive learning. Our approach demonstrates outstanding performance compared with existing small-scale models and large multi-modal models, validating the feasibility of using wireless signals as a universal modality and highlighting WMLM's potential to emerge as a new paradigm for future wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21707v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhuoran Duan, Yuhao Wei, Guoshun Nan, Zijun Wang, Yan Yan, Lihua Xiong, Yuhan Ran, Ji Zhang, Jian Li, Qimei Cui, Xiaofeng Tao, Tony Q. S. Quek</dc:creator>
    </item>
    <item>
      <title>Secure Command, Control and Communications Systems (C3) for Army UxVs</title>
      <link>https://arxiv.org/abs/2511.21936</link>
      <description>arXiv:2511.21936v1 Announce Type: new 
Abstract: Unmanned Vehicles (UxVs) are increasingly used in modern military operations for reconnaissance, surveillance, and strike missions, enhancing situational awareness while reducing risk to personnel. Their affordability and rapid deployment have encouraged the adoption of commercial solutions. However, many rely on insecure protocols such as MAVLink, which lack authentication and encryption mechanisms. This paper designed, implemented, and evaluated a new secure command-and-control architecture that ensures confidentiality, integrity, and authentication (CIA) while supporting real-time control delegation between Ground Control Stations (GCSs). The proposed solution, named New Command and Control System (NC2S), enforces a zero-trust model integrating hierarchical credential-based privileges to regulate access and control among Tactical Commanders (TC), GCSs, and UxVs. It employs mutual Transport Layer Security (mTLS) with Elliptic Curve Digital Signature Algorithm (ECDSA) certificates and Elliptic Curve Diffie-Hellman (ECDH) key exchange, while message integrity is ensured through Hash-based Message Authentication Codes (HMAC). Multiple lightweight protocols were developed for credential management, key renewal, and control handover. The NC2S prototype was experimentally validated over Wi-Fi and Rohde&amp;Schwarz HR-5000H tactical radios. Results showed that HR-5000H links introduce latencies roughly two orders of magnitude higher than broadband technologies (e.g., Wi-Fi or 5G&amp;Beyond technologies) but are still able to maintain stable communication with minimal message loss, making them suitable for the NC2S links among TC terminals and GCSs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21936v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>T. Rebolo, A. Grilo, C. Ribeiro</dc:creator>
    </item>
    <item>
      <title>Resilient and Reliable Cloud Network Control for Mission-Critical Latency-Sensitive Service Chains</title>
      <link>https://arxiv.org/abs/2511.21960</link>
      <description>arXiv:2511.21960v1 Announce Type: new 
Abstract: The proliferation of mission-critical latency-sensitive services has intensified the demand for next-generation cloud-integrated networks to guarantee both reliable and resilient service delivery. While reliability imposes timely-throughput requirements, i.e., percentage of packets to be delivered within a prescribed per-packet deadline, resilience relates to the network's ability to swiftly recover timely-throughput performance following an outage event, such as node or link failures. While recent studies have increasingly focused on designing reliable network control policies, a comprehensive solution that combines reliable and resilient network control has yet to be fully explored. This paper formulates the multi-commodity least-cost resilient and reliable network control (MC-LC-ResRNC) problem as a stochastic control problem with long and short-term timely throughput constraints. We then present a solution through the Multi-Commodity Resilient and Reliable Cloud Network Control (MC-ResRCNC) algorithm and show through numerical experiments that it jointly ensures reliability under normal conditions and resilience upon network failure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21960v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chin-Wei Huang, Jaime Llorca, Antonia M. Tulino, Andreas F. Molisch</dc:creator>
    </item>
    <item>
      <title>AutoRec: Accelerating Loss Recovery for Live Streaming in a Multi-Supplier Market</title>
      <link>https://arxiv.org/abs/2511.22046</link>
      <description>arXiv:2511.22046v1 Announce Type: new 
Abstract: Due to the limited permissions for upgrading dualside (i.e., server-side and client-side) loss tolerance schemes from the perspective of CDN vendors in a multi-supplier market, modern large-scale live streaming services are still using the automatic-repeat-request (ARQ) based paradigm for loss recovery, which only requires server-side modifications. In this paper, we first conduct a large-scale measurement study with up to 50 million live streams. We find that loss shows dynamics and live streaming contains frequent on-off mode switching in the wild. We further find that the recovery latency, enlarged by the ubiquitous retransmission loss, is a critical factor affecting live streaming's client-side QoE (e.g., video freezing). We then propose an enhanced recovery mechanism called AutoRec, which can transform the disadvantages of on-off mode switching into an advantage for reducing loss recovery latency without any modifications on the client side. AutoRec allows users to customize overhead tolerance and recovery latency tolerance and adaptively adjusts strategies as the network environment changes to ensure that recovery latency meets user demands whenever possible while keeping overhead under control. We implement AutoRec upon QUIC and evaluate it via testbed and real-world commercial services deployments. The experimental results demonstrate the practicability and profitability of AutoRec.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22046v1</guid>
      <category>cs.NI</category>
      <category>cs.MM</category>
      <category>eess.IV</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tong Li, Xu Yan, Bo Wu, Cheng Luo, Fuyu Wang, Jiuxiang Zhu, Haoyi Fang, Xinle Du, Ke Xu</dc:creator>
    </item>
    <item>
      <title>Optimizing NetGPT via Routing-Based Synergy and Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2511.22217</link>
      <description>arXiv:2511.22217v1 Announce Type: new 
Abstract: Large language model (LLM) agents at the network edge offer low-latency execution for routine queries. In contrast, complex requests often require the superior capability of cloud models, incurring higher latency and cost. To navigate this quality-cost trade-off under dynamic network conditions, we propose a cloud-edge synergy for NetGPT that integrates network-aware routing with on-edge self-improvement. Specifically, our framework routes structured tool-calling requests to cloud or edge agents via a novel scoring policy. We prove that, under mild regularity assumptions, the optimal routing rule admits a unique fallback threshold with monotone dependence on bandwidth and round-trip time (RTT). Concurrently, based on the dataset collected from requests routed to the cloud and corresponding responses, we instantiate a schema-preserving reinforcement learning (RL) to improve the capability of the edge agent. We analyze a supervised finetuning (SFT)-anchored composite objective that combines a reverse-KL trust-region step with a forward-KL realignment toward the SFT prior, explaining stability and constraining policy drift. Both the network-aware routing policy and the edge agent are updated coherently. Experiments across controlled network states and pricing schedules demonstrate smooth quality-cost frontiers, consistent gains of dynamic fallback thresholds over fixed policies, and sustained reductions in offloading while maintaining task success and schema-correct outputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22217v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxuan Chen, Rongpeng Li, Xianfu Chen, Celimuge Wu, Chenghui Peng, Zhifeng Zhao, Honggang Zhang</dc:creator>
    </item>
    <item>
      <title>Semantic-Aware Caching for Efficient Image Generation in Edge Computing</title>
      <link>https://arxiv.org/abs/2511.22421</link>
      <description>arXiv:2511.22421v1 Announce Type: new 
Abstract: Text-to-image generation employing diffusion models has attained significant popularity due to its capability to produce high-quality images that adhere to textual prompts. However, the integration of diffusion models faces critical challenges into resource-constrained mobile and edge environments because it requires multiple denoising steps from the original random noise. A practical way to speed up denoising is to initialize the process with a noised reference image that is similar to the target, since both images share similar layouts, structures, and details, allowing for fewer denoising steps. Based on this idea, we present CacheGenius, a hybrid image generation system in edge computing that accelerates generation by combining text-toimage and image-to-image workflows. It generates images from user text prompts using cached reference images. CacheGenius introduces a semantic-aware classified storage scheme and a request-scheduling algorithm that ensures semantic alignment between references and targets. To ensure sustained performance, it employs a cache maintenance policy that proactively evicts obsolete entries via correlation analysis. Evaluated in a distributed edge computing system, CacheGenius reduces generation latency by 41% and computational costs by 48% relative to baselines, while maintaining competitive evaluation metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22421v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanshuai Cui, Zhiqing Tang, Zhi Yao, Weijia Ji, Wei Zhao</dc:creator>
    </item>
    <item>
      <title>Day in the Life of RIPE Atlas: Operational Insights and Applications in Network Measurements</title>
      <link>https://arxiv.org/abs/2511.22474</link>
      <description>arXiv:2511.22474v1 Announce Type: new 
Abstract: Network measurement platforms are increasingly popular among researchers and operators alike due to their distributed nature, simplifying measuring the remote parts of the Internet. RIPE Atlas boasts over 12.9K vantage points in 178 countries worldwide and serves as a vital tool for analyzing anycast deployment, network latency, and topology, to name a few. Despite generating over a terabyte of measurement results per day, there is limited understanding of the underlying processes. This paper delves into one day in the life of RIPE Atlas, encompassing 50.9K unique measurements and over 1.3 billion results. While most daily measurements are user-defined, it is built-ins and anchor meshes that account for 89% of produced results. We extensively examine how different probes and measurements contribute to the daily operations of RIPE Atlas and consider any bias they may introduce. Furthermore, we demonstrate how existing measurements can be leveraged to investigate censorship, traceroute symmetry, and the usage of reserved address blocks, among others. Finally, we curate a set of recommendations for researchers using the RIPE Atlas platform to foster transparency, reproducibility, and ethics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22474v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yevheniya Nosyk, Malte Tashiro, Qasim Lone, Robert Kisteleki, Andrzej Duda, Maciej Korczy\'nski</dc:creator>
    </item>
    <item>
      <title>RetryGuard: Preventing Self-Inflicted Retry Storms in Cloud Microservices Applications</title>
      <link>https://arxiv.org/abs/2511.23278</link>
      <description>arXiv:2511.23278v1 Announce Type: new 
Abstract: Modern cloud applications are built on independent, diverse microservices, offering scalability, flexibility, and usage-based billing. However, the structural design of these varied services, along with their reliance on auto-scalers for dynamic internet traffic, introduces significant coordination challenges. As we demonstrate in this paper, common default retry patterns used between misaligned services can turn into retry storms which drive up resource usage and costs, leading to self-inflicted Denial-of-Wallet (DoW) scenarios. To overcome these problems we introduce RetryGuard, a distributed framework for productive control of retry patterns across interdependent microservices. By managing retry policy on a per-service basis and making parallel decisions, RetryGuard prevents retry storms, curbs resource contention, and mitigates escalating operational costs. RetryGuard makes its decisions based on an analytic model that captures the relationships among retries, throughput (rejections), delays, and costs. Experimental results show that RetryGuard significantly reduces resource usage and costs compared to AWS standard and advanced retry policies. We further demonstrate its scalability and superior performance in a more complex Kubernetes deployment with the Istio service mesh, where it achieves substantial improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23278v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jhonatan Tavori, Anat Bremler-Barr, Hanoch Levy, Ofek Lavi</dc:creator>
    </item>
    <item>
      <title>Performance Evaluation of Multi-Armed Bandit Algorithms for Wi-Fi Channel Access</title>
      <link>https://arxiv.org/abs/2511.23352</link>
      <description>arXiv:2511.23352v1 Announce Type: new 
Abstract: The adoption of dynamic, self-learning solutions for real-time wireless network optimization has recently gained significant attention due to the limited adaptability of existing protocols. This paper investigates multi-armed bandit (MAB) strategies as a data-driven approach for decentralized, online channel access optimization in Wi-Fi, targeting dynamic channel access settings: primary channel, channel width, and contention window (CW) adjustment. Key design aspects are examined, including the adoption of joint versus factorial action spaces, the inclusion of contextual information, and the nature of the action-selection strategy (optimism-driven, unimodal, or randomized). State-of-the-art algorithms and a proposed lightweight contextual approach, E-RLB, are evaluated through simulations. Results show that contextual and optimism-driven strategies consistently achieve the highest performance and fastest adaptation under recurrent conditions. Unimodal structures require careful graph construction to ensure that the unimodality assumption holds. Randomized exploration, adopted in the proposed E-RLB, can induce disruptive parameter reallocations, especially in multi-player settings. Decomposing the action space across several specialized agents accelerates convergence but increases sensitivity to randomized exploration and demands coordination under shared rewards to avoid correlated learning. Finally, despite its inherent inefficiencies from epsilon-greedy exploration, E-RLB demonstrates effective adaptation and learning, highlighting its potential as a viable low-complexity solution for realistic dynamic deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23352v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Miguel Casasnovas, Francesc Wilhelmi, Richard Combes, Maksymilian Wojnar, Katarzyna Kosek-Szott, Szymon Szott, Anders Jonsson, Luis Esteve, Boris Bellalta</dc:creator>
    </item>
    <item>
      <title>Joint Resource Allocation to Transparently Integrate 5G TDD Uplink with Time-Aware TSN</title>
      <link>https://arxiv.org/abs/2511.23373</link>
      <description>arXiv:2511.23373v1 Announce Type: new 
Abstract: To enable mobility in industrial communication systems, the seamless integration of 5G with Time-Sensitive Networking (TSN) is a promising approach. Deterministic communication across heterogeneous 5G-TSN systems requires joint scheduling between both domains. A key prerequisite for time-aware end-to-end scheduling is determining the forwarding delay for each TSN Traffic Class at every bridge, referred to as Bridge Delay (BD). Hence, to integrate 5G as a transparent TSN bridge, the 5G BD must be determined and guaranteed. Unlike wired bridges, the 5G BD relies on wireless resource management characteristics, such as the Time Division Duplex pattern and radio resource allocation procedure. In particular, traditional Uplink (UL) schedulers are optimized for throughput but often fail to meet the deadline requirements. To address this challenge, we propose a heterogeneous radio resource scheduler that integrates static and dynamic scheduling. The algorithm pre-allocates resources for time-sensitive periodic streams based on the reported BDs, ensuring alignment with the TSN mechanisms Time-Aware Shaper and Per-Stream Filtering and Policing. Meanwhile, remaining resources are dynamically allocated to non-deterministic flows using established strategies such as Proportional Fair, Max C/I, or a Quality of Service-aware priority-based scheduler. The scheduler's performance is evaluated through OMNeT++ simulations. The results demonstrate support for diverse TSN flows while ensuring deadline-aware scheduling of time-sensitive UL traffic in mobility scenarios. Periodic time-sensitive flows are end-to-end scheduled across domains, improving the resource efficiency by 28% compared to the Configured Grant baseline. While reliability is preserved, non-deterministic rate-sensitive flows benefit from the improved resource utilization, resulting in higher throughput</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23373v1</guid>
      <category>cs.NI</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laura Becker, Yash Deshpande, Wolfgang Kellerer</dc:creator>
    </item>
    <item>
      <title>ZipperChain: Transmuting Trusted Third-Party Services Into Trustless Atomic Broadcast</title>
      <link>https://arxiv.org/abs/2511.21969</link>
      <description>arXiv:2511.21969v1 Announce Type: cross 
Abstract: Distributed ledger technologies (DLTs) rely on distributed consensus mechanisms to reach agreement over the order of transactions and to provide immutability and availability of transaction data. Distributed consensus suffers from performance limitations of network communication between participating nodes. BLOCKY ZipperChain guarantees immutability, agreement, and availability of transaction data, but without relying on distributed consensus. Instead, its construction process transfers trust from widely-used, third-party services onto ZipperChains's correctness guarantees. ZipperChain blocks are built by a pipeline of specialized services deployed on a small number of nodes connected by a fast data center network. As a result, ZipperChain transaction throughput approaches network line speeds and block finality is on the order of 500 ms. Finally, ZipperChain infrastructure creates blocks centrally and so does not need a native token to incentivize a community of verifiers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21969v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matteo Bjornsson, Taylor Hardin, Taylor Heinecke, Marcin Furtak, David L. Millman, Mike P. Wittie</dc:creator>
    </item>
    <item>
      <title>Silence Speaks Volumes: A New Paradigm for Covert Communication via History Timing Patterns</title>
      <link>https://arxiv.org/abs/2511.22259</link>
      <description>arXiv:2511.22259v1 Announce Type: cross 
Abstract: A Covert Channel (CC) exploits legitimate communication mechanisms to stealthily transmit information, often bypassing traditional security controls. Among these, a novel paradigm called History Covert Channels (HCC) leverages past network events as reference points to embed covert messages. Unlike traditional timing- or storage-based CCs, which directly manipulate traffic patterns or packet contents, HCCs minimize detectability by encoding information through small pointers to historical data. This approach enables them to amplify the size of transmitted covert data by referring to more bits than are actually embedded. Recent research has explored the feasibility of such methods, demonstrating their potential to evade detection by repurposing naturally occurring network behaviors as a covert transmission medium.
  This paper introduces a novel method for establishing and maintaining covert communication links using relative pointers to network timing patterns, which minimizes the reliance of the HCC on centralized timekeeping and reduces the likelihood of being detected by standard network monitoring tools. We also explore the tailoring of HCCs to optimize their robustness and undetectability characteristics. Our experiments reveal a better bitrate compared to previous work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22259v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christoph Weissenborn, Steffen Wendzel</dc:creator>
    </item>
    <item>
      <title>RELiQ: Scalable Entanglement Routing via Reinforcement Learning in Quantum Networks</title>
      <link>https://arxiv.org/abs/2511.22321</link>
      <description>arXiv:2511.22321v1 Announce Type: cross 
Abstract: Quantum networks are becoming increasingly important because of advancements in quantum computing and quantum sensing, such as recent developments in distributed quantum computing and federated quantum machine learning. Routing entanglement in quantum networks poses several fundamental as well as technical challenges, including the high dynamicity of quantum network links and the probabilistic nature of quantum operations. Consequently, designing hand-crafted heuristics is difficult and often leads to suboptimal performance, especially if global network topology information is unavailable.
  In this paper, we propose RELiQ, a reinforcement learning-based approach to entanglement routing that only relies on local information and iterative message exchange. Utilizing a graph neural network, RELiQ learns graph representations and avoids overfitting to specific network topologies - a prevalent issue for learning-based approaches. Our approach, trained on random graphs, consistently outperforms existing local information heuristics and learning-based approaches when applied to random and real-world topologies. When compared to global information heuristics, our method achieves similar or superior performance because of its rapid response to topology changes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22321v1</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tobias Meuser, Jannis Weil, Aninda Lahiri, Marius Paraschiv</dc:creator>
    </item>
    <item>
      <title>Quantum Private Distributed Matrix Multiplication With Degree Tables</title>
      <link>https://arxiv.org/abs/2511.23406</link>
      <description>arXiv:2511.23406v1 Announce Type: cross 
Abstract: In this paper, we explore how quantum resources can be used to increase the rate of private distributed matrix multiplication (PDMM). In PDMM, a user who has two high-dimensional matrices, $A$ and $B$, and lacks the computational capabilities to apply matrix multiplication locally, divides the matrices $A$ and $B$ into $K$ and $L$ sub-blocks, respectively. Then, the user sends them to $N$ servers to apply the required multiplication privately from any $T$ servers. The goal is to reduce the number of servers needed to perform the required matrix multiplication. In the quantum setting, we allow the servers to share an entangled state and respond over quantum channels. Upon receiving the qudits, the user applies measurements to obtain the required multiplication. There are two main regimes in the PDMM literature: The high-privacy regime and the low-privacy regime where $T$ is less than $K$ and $L$.
  First, in the high-privacy regime, the state-of-the-art classical code is called the gap additive secure polynomial (GASP) code. We define a feasibility requirement in the quantum setting for the GASP code such that the highest performance is achieved when it is satisfied. When it is not satisfied, we address two main concerns. The first is to find a relation between the minimum privacy requirement and the dimensions of the two matrices needed for the feasibility condition to be satisfied. Second, we develop a new family of codes that can work in the quantum setting.
  Second, since GASP does not work efficiently in the low-privacy regimes compared to cyclic-addition degree tables (CAT) and discretely optimized GASP (DOG), we show that the feasibility condition developed for GASP can be adopted for both CAT and DOG codes as well. In addition, we propose another set of codes that can be used in the low privacy regime in the quantum setting when the feasibility requirement is not satisfied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23406v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Nomeir, Alptug Aytekin, Lei Hu, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>A Layered Protocol Architecture for the Internet of Agents</title>
      <link>https://arxiv.org/abs/2511.19699</link>
      <description>arXiv:2511.19699v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated remarkable performance improvements and the ability to learn domain-specific languages (DSLs), including APIs and tool interfaces. This capability has enabled the creation of AI agents that can perform preliminary computations and act through tool calling, now being standardized via protocols like MCP. However, LLMs face fundamental limitations: their context windows cannot grow indefinitely, constraining their memory and computational capacity. Agent collaboration emerges as essential for solving increasingly complex problems, mirroring how computational systems rely on different types of memory to scale. The "Internet of Agents" (IoA) represents the communication stack that enables agents to scale by distributing computation across collaborating entities. Current network architectural stacks (OSI and TCP/IP) were designed for data delivery between hosts and processes, not for agent collaboration with semantic understanding. To address this gap, we propose two new layers: an Agent Communication Layer (L8) and an Agent Semantic Negotiation Layer (L9). L8 formalizes the structure of communication, standardizing message envelopes, speech-act performatives (e.g., REQUEST, INFORM), and interaction patterns (e.g., request-reply, publish-subscribe), building on protocols like MCP. L9, which does not exist today, formalizes the meaning of communication, enabling agents to discover, negotiate, and lock a "Shared Context" -- a formal schema defining the concepts, tasks, and parameters relevant to their interaction. Together, these layers provide the foundation for scalable, distributed agent collaboration, enabling the next generation of multi-agentic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19699v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles Fleming, Vijoy Pandey, Luca Muscariello, Ramana Kompella</dc:creator>
    </item>
    <item>
      <title>JANUS: Resilient and Adaptive Data Transmission for Enabling Timely and Efficient Cross-Facility Scientific Workflows</title>
      <link>https://arxiv.org/abs/2506.17084</link>
      <description>arXiv:2506.17084v2 Announce Type: replace-cross 
Abstract: In modern science, the growing complexity of large-scale scientific projects has led to an increasing reliance on cross-facility scientific workflows, where resources and expertise from multiple institutions and geographic locations are leveraged to accelerate scientific discovery. These workflows often require transmitting huge amounts of scientific data through wide-area networks. Although high-speed networks like ESnet and transfer services such as Globus have improved data mobility, several challenges remain. The sheer volume of data can overwhelm network bandwidth, widely used transport protocols such as TCP suffer from inefficiencies due to retransmissions triggered by packet loss, and existing fault-tolerance mechanisms like erasure coding introduce substantial overhead.
  In this paper, we propose JANUS, a resilient and adaptable data transmission approach designed for cross-facility scientific workflows. Unlike traditional TCP-based methods, JANUSleverages UDP, integrates erasure coding for fault tolerance, and combines it with error-bounded lossy compression to reduce overhead. This novel design allows users to balance data transmission time and accuracy, optimizing transfer performance based on specific scientific requirements. Additionally, JANUS dynamically adjusts erasure coding parameters in response to real-time network conditions, ensuring efficient data transfers even in fluctuating environments. We develop optimization models for determining ideal configurations and implement adaptive data transfer protocols to enhance reliability. Through extensive simulations and real-network experiments, we demonstrate that JANUS significantly improves transfer efficiency while maintaining data fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17084v2</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vladislav Esaulov, Jieyang Chen, Norbert Podhorszki, Fred Suter, Scott Klasky, Anu G Bourgeois, Lipeng Wan</dc:creator>
    </item>
  </channel>
</rss>
