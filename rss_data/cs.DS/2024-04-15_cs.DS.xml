<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 16 Apr 2024 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Improved Approximations for Flexible Network Design</title>
      <link>https://arxiv.org/abs/2404.08972</link>
      <description>arXiv:2404.08972v1 Announce Type: new 
Abstract: Flexible network design deals with building a network that guarantees some connectivity requirements between its vertices, even when some of its elements (like vertices or edges) fail. In particular, the set of edges (resp. vertices) of a given graph are here partitioned into safe and unsafe. The goal is to identify a minimum size subgraph that is 2-edge-connected (resp. 2-vertex-connected), and stay so whenever any of the unsafe elements gets removed.
  In this paper, we provide improved approximation algorithms for flexible network design problems, considering both edge-connectivity and vertex-connectivity, as well as connectivity values higher than 2. For the vertex-connectivity variant, in particular, our algorithm is the first with approximation factor strictly better than 2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08972v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dylan Hyatt-Denesik, Afrouz Jabal Ameli, Laura Sanita</dc:creator>
    </item>
    <item>
      <title>Better space-time-robustness trade-offs for set reconciliation</title>
      <link>https://arxiv.org/abs/2404.09607</link>
      <description>arXiv:2404.09607v1 Announce Type: new 
Abstract: We consider the problem of reconstructing the symmetric difference between similar sets from their representations (sketches) of size linear in the number of differences. Exact solutions to this problem are based on error-correcting coding techniques and suffer from a large decoding time. Existing probabilistic solutions based on Invertible Bloom Lookup Tables (IBLTs) are time-efficient but offer insufficient success guarantees for many applications. Here we propose a tunable trade-off between the two approaches combining the efficiency of IBLTs with exponentially decreasing failure probability. The proof relies on a refined analysis of IBLTs proposed in (Baek Tejs Houen et al. SOSA 2023) which has an independent interest. We also propose a modification of our algorithm that enables telling apart the elements of each set in the symmetric difference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09607v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Djamal Belazzougui, Gregory Kucherov, Stefan Walzer</dc:creator>
    </item>
    <item>
      <title>A Circus of Circuits: Connections Between Decision Diagrams, Circuits, and Automata</title>
      <link>https://arxiv.org/abs/2404.09674</link>
      <description>arXiv:2404.09674v1 Announce Type: new 
Abstract: This document is an introduction to two related formalisms to define Boolean functions: binary decision diagrams, and Boolean circuits. It presents these formalisms and several of their variants studied in the setting of knowledge compilation. Last, it explains how these formalisms can be connected to the notions of automata over words and trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09674v1</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <category>cs.FL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antoine Amarilli, Marcelo Arenas, YooJung Choi, Mika\"el Monet, Guy Van den Broeck, Benjie Wang</dc:creator>
    </item>
    <item>
      <title>Online Multi-level Aggregation with Delays and Stochastic Arrivals</title>
      <link>https://arxiv.org/abs/2404.09711</link>
      <description>arXiv:2404.09711v1 Announce Type: new 
Abstract: This paper presents a new research direction for online Multi-Level Aggregation (MLA) with delays. In this problem, we are given an edge-weighted rooted tree $T$, and we have to serve a sequence of requests arriving at its vertices in an online manner. Each request $r$ is characterized by two parameters: its arrival time $t(r)$ and location $l(r)$ (a vertex). Once a request $r$ arrives, we can either serve it immediately or postpone this action until any time $t &gt; t(r)$. We can serve several pending requests at the same time, and the service cost of a service corresponds to the weight of the subtree that contains all the requests served and the root of $T$. Postponing the service of a request $r$ to time $t &gt; t(r)$ generates an additional delay cost of $t - t(r)$. The goal is to serve all requests in an online manner such that the total cost (i.e., the total sum of service and delay costs) is minimized. The current best algorithm for this problem achieves a competitive ratio of $O(d^2)$ (Azar and Touitou, FOCS'19), where $d$ denotes the depth of the tree.
  Here, we consider a stochastic version of MLA where the requests follow a Poisson arrival process. We present a deterministic online algorithm which achieves a constant ratio of expectations, meaning that the ratio between the expected costs of the solution generated by our algorithm and the optimal offline solution is bounded by a constant. Our algorithm is obtained by carefully combining two strategies. In the first one, we plan periodic oblivious visits to the subset of frequent vertices, whereas in the second one, we greedily serve the pending requests in the remaining vertices. This problem is complex enough to demonstrate a very rare phenomenon that ``single-minded" or ``sample-average" strategies are not enough in stochastic optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09711v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathieu Mari, Micha{\l} Paw{\l}owski, Runtian Ren, Piotr Sankowski</dc:creator>
    </item>
    <item>
      <title>Search-Space Reduction Via Essential Vertices Revisited: Vertex Multicut and Cograph Deletion</title>
      <link>https://arxiv.org/abs/2404.09769</link>
      <description>arXiv:2404.09769v1 Announce Type: new 
Abstract: For an optimization problem $\Pi$ on graphs whose solutions are vertex sets, a vertex $v$ is called $c$-essential for $\Pi$ if all solutions of size at most $c \cdot OPT$ contain $v$. Recent work showed that polynomial-time algorithms to detect $c$-essential vertices can be used to reduce the search space of fixed-parameter tractable algorithms solving such problems parameterized by the size $k$ of the solution. We provide several new upper- and lower bounds for detecting essential vertices. For example, we give a polynomial-time algorithm for $3$-Essential detection for Vertex Multicut, which translates into an algorithm that finds a minimum multicut of an undirected $n$-vertex graph $G$ in time $2^{O(\ell^3)} \cdot n^{O(1)}$, where $\ell$ is the number of vertices in an optimal solution that are not $3$-essential. Our positive results are obtained by analyzing the integrality gaps of certain linear programs. Our lower bounds show that for sufficiently small values of $c$, the detection task becomes NP-hard assuming the Unique Games Conjecture. For example, we show that ($2-\varepsilon$)-Essential detection for Directed Feedback Vertex Set is NP-hard under this conjecture, thereby proving that the existing algorithm that detects $2$-essential vertices is best-possible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09769v1</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bart M. P. Jansen, Ruben F. A. Verhaegh</dc:creator>
    </item>
    <item>
      <title>Asynchronous Opinion Dynamics in Social Networks</title>
      <link>https://arxiv.org/abs/2201.12923</link>
      <description>arXiv:2201.12923v2 Announce Type: replace 
Abstract: Opinion spreading in a society decides the fate of elections, the success of products, and the impact of political or social movements. The model by Hegselmann and Krause is a well-known theoretical model to study such opinion formation processes in social networks. In contrast to many other theoretical models, it does not converge towards a situation where all agents agree on the same opinion. Instead, it assumes that people find an opinion reasonable if and only if it is close to their own. The system converges towards a stable situation where agents sharing the same opinion form a cluster, and agents in different clusters do not \mbox{influence each other.}
  We focus on the social variant of the Hegselmann-Krause model where agents are connected by a social network and their opinions evolve in an iterative process. When activated, an agent adopts the average of the opinions of its neighbors having a similar opinion. By this, the set of influencing neighbors of an agent may change over time. To the best of our knowledge, social Hegselmann-Krause systems with asynchronous opinion updates have only been studied with the complete graph as social network. We show that such opinion dynamics with random agent activation are guaranteed to converge for any social network. We provide an upper bound of $\mathcal{O}(n|E|^2 (\varepsilon/\delta)^2)$ on the expected number of opinion updates until convergence, where $|E|$ is the number of edges of the social network. For the complete social network we show a bound of $\mathcal{O}(n^3(n^2 + (\varepsilon/\delta)^2))$ that represents a major improvement over the previously best upper bound of $\mathcal{O}(n^9 (\varepsilon/\delta)^2)$. Our bounds are complemented by simulations that indicate asymptotically matching lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.12923v2</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Petra Berenbrink, Martin Hoefer, Dominik Kaaser, Pascal Lenzner, Malin Rau, Daniel Schmand</dc:creator>
    </item>
    <item>
      <title>A Fair and Memory/Time-efficient Hashmap</title>
      <link>https://arxiv.org/abs/2307.11355</link>
      <description>arXiv:2307.11355v2 Announce Type: replace 
Abstract: Hashmap is a fundamental data structure in computer science. There has been extensive research on constructing hashmaps that minimize the number of collisions leading to efficient lookup query time. Recently, the data-dependant approaches, construct hashmaps tailored for a target data distribution that guarantee to uniformly distribute data across different buckets and hence minimize the collisions. Still, to the best of our knowledge, none of the existing technique guarantees group fairness among different groups of items stored in the hashmap.
  Therefore, in this paper, we introduce FairHash, a data-dependant hashmap that guarantees uniform distribution at the group-level across hash buckets, and hence, satisfies the statistical parity notion of group fairness. We formally define, three notions of fairness and, unlike existing work, FairHash satisfies all three of them simultaneously. We propose three families of algorithms to design fair hashmaps, suitable for different settings. Our ranking-based algorithms reduce the unfairness of data-dependant hashmaps without any memory-overhead. The cut-based algorithms guarantee zero-unfairness in all cases, irrespective of how the data is distributed, but those introduce an extra memory-overhead. Last but not least, the discrepancy-based algorithms enable trading off between various fairness notions. In addition to the theoretical analysis, we perform extensive experiments to evaluate the efficiency and efficacy of our algorithms on real datasets. Our results verify the superiority of FairHash compared to the other baselines on fairness at almost no performance cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.11355v2</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:journal_reference>SIGMOD 2024</arxiv:journal_reference>
      <dc:creator>Abolfazl Asudeh, Nima Shahbazi, Stavros Sintos</dc:creator>
    </item>
    <item>
      <title>On Sparse Covers of Minor Free Graphs, Low Dimensional Metric Embeddings, and other applications</title>
      <link>https://arxiv.org/abs/2401.14060</link>
      <description>arXiv:2401.14060v2 Announce Type: replace 
Abstract: Given a metric space $(X,d_X)$, a $(\beta,s,\Delta)$-sparse cover is a collection of clusters $\mathcal{C}\subseteq P(X)$ with diameter at most $\Delta$, such that for every point $x\in X$, the ball $B_X(x,\frac\Delta\beta)$ is fully contained in some cluster $C\in \mathcal{C}$, and $x$ belongs to at most $s$ clusters in $\mathcal{C}$. Our main contribution is to show that the shortest path metric of every $K_r$-minor free graphs admits $(O(r),O(r^2),\Delta)$-sparse cover, and for every $\epsilon&gt;0$, $(4+\epsilon,O(\frac1\epsilon)^r,\Delta)$-sparse cover (for arbitrary $\Delta&gt;0$). We then use this sparse cover to show that every $K_r$-minor free graph embeds into $\ell_\infty^{\tilde{O}(\frac1\epsilon)^{r+1}\cdot\log n}$ with distortion $3+\eps$ (resp. into $\ell_\infty^{\tilde{O}(r^2)\cdot\log n}$ with distortion $O(r)$). Further, we provide applications of these sparse covers into padded decompositions, sparse partitions, universal TSP / Steiner tree, oblivious buy at bulk, name independent routing, and path reporting distance oracles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14060v2</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnold Filtser</dc:creator>
    </item>
    <item>
      <title>Minimum sum vertex cover: kernelization and parameterized algorithms</title>
      <link>https://arxiv.org/abs/2403.18497</link>
      <description>arXiv:2403.18497v2 Announce Type: replace 
Abstract: Given an ordering of the vertices of a graph, the cost of covering an edge is the smaller number of its two ends. The minimum sum vertex cover problem asks for an ordering that minimizes the total cost of covering all edges. We consider parameterized complexity of this problem, using the largest cost~$k$ of covering a single edge as the parameter. Note that the first $k$ vertices form a (not necessarily minimal) vertex cover of the graph, and the ordering of vertices after $k$ is irrelevant. We present a $(k^2 + 2 k)$-vertex kernel and an $O(m + 2^kk! k^4)$-time algorithm for the minimum sum vertex cover problem, where $m$ is the size of the input graph. Since our parameter~$k$ is polynomially bounded by the vertex cover number of the input graph, our results also apply to that parameterization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18497v2</guid>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yixin Cao, Ling Gai, Jingyi Liu, Jianxin Wang</dc:creator>
    </item>
    <item>
      <title>Facility Location Games Beyond Single-Peakedness: the Entrance Fee Model</title>
      <link>https://arxiv.org/abs/2204.11282</link>
      <description>arXiv:2204.11282v2 Announce Type: replace-cross 
Abstract: The facility location game has been studied extensively in mechanism design. In the classical model, each agent's cost is solely determined by her distance to the nearest facility. In this paper, we introduce a novel model where each facility charges an entrance fee. Thus, the cost of each agent is determined by both the distance to the facility and the entrance fee of the facility. In our model, the entrance fee function is allowed to be an arbitrary function, causing agents' preferences may no longer be single-peaked anymore: This departure from the classical model introduces additional challenges. We systematically delve into the intricacies of the model, designing strategyproof mechanisms with favorable approximation ratios. Additionally, we complement these ratios with nearly-tight impossibility results. Specifically, for one-facility and two-facility games, we provide upper and lower bounds for the approximation ratios given by deterministic and randomized mechanisms with respect to utilitarian and egalitarian objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.11282v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mengfan Ma, Mingyu Xiao, Tian Bai, Bakh Khoussainov</dc:creator>
    </item>
    <item>
      <title>Computing Brascamp-Lieb Constants through the lens of Thompson Geometry</title>
      <link>https://arxiv.org/abs/2208.05013</link>
      <description>arXiv:2208.05013v3 Announce Type: replace-cross 
Abstract: This paper studies algorithms for efficiently computing Brascamp-Lieb constants, a task that has recently received much interest. In particular, we reduce the computation to a nonlinear matrix-valued iteration, whose convergence we analyze through the lens of fixed-point methods under the well-known Thompson metric. This approach permits us to obtain (weakly) polynomial time guarantees, and it offers an efficient and transparent alternative to previous state-of-the-art approaches based on Riemannian optimization and geodesic convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.05013v3</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.FA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Melanie Weber, Suvrit Sra</dc:creator>
    </item>
    <item>
      <title>Alon-Tarsi Number of Some Regular Graphs</title>
      <link>https://arxiv.org/abs/2304.04531</link>
      <description>arXiv:2304.04531v4 Announce Type: replace-cross 
Abstract: The Alon-Tarsi number of a polynomial is a parameter related to the exponents of its monomials. For graphs, their Alon-Tarsi number is the Alon-Tarsi number of their graph polynomials. As such, it provides an upper bound on their choice and online choice numbers. In this paper, we obtain the Alon-Tarsi number of some complete multipartite graphs, line graphs of some complete graphs of even order, and line graphs of some other regular graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.04531v4</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>S. Prajnanaswaroopa</dc:creator>
    </item>
    <item>
      <title>Approximation Algorithms to Enhance Social Sharing of Fresh Point-of-Interest Information</title>
      <link>https://arxiv.org/abs/2308.13260</link>
      <description>arXiv:2308.13260v2 Announce Type: replace-cross 
Abstract: In location-based social networks (LBSNs), such as Gowalla and Waze, users sense urban point-of-interest (PoI) information (e.g., restaurants' queue length and real-time traffic conditions) in the vicinity and share such information with friends in online social networks. Given each user's social connections and the severe lags in disseminating fresh PoI to all users, major LBSNs aim to enhance users' social PoI sharing by selecting $k$ out of $m$ users as hotspots and broadcasting their PoI information to the entire user community. This motivates us to study a new combinatorial optimization problem by integrating two urban sensing and online social networks. We prove that this problem is NP-hard and also renders existing approximation solutions not viable. Through analyzing the interplay effects between the sensing and social networks, we successfully transform the involved PoI-sharing process across two networks to matrix computations for deriving a closed-form objective, {\color{black}which we find holds desirable properties (e.g., submodularity and monotonicity).} This finding enables us to develop a polynomial-time algorithm that guarantees a ($1-\frac{m-2}{m}(\frac{k-1}{k})^k$) approximation of the optimum. Furthermore, we allow each selected user to move around and sense more PoI information to share. To this end, we propose an augmentation-adaptive algorithm, which benefits from a resource-augmented technique and achieves bounded approximation, ranging from $\frac{1}{k}(1-\frac{1}{e})$ to $1-\frac{1}{e}&gt; 0.632$ by adjusting our augmentation factors. Finally, our theoretical results are corroborated by our simulation findings using both synthetic and real-world datasets across different network topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13260v2</guid>
      <category>cs.SI</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Songhua Li, Lingjie Duan</dc:creator>
    </item>
    <item>
      <title>Aleph Filter: To Infinity in Constant Time</title>
      <link>https://arxiv.org/abs/2404.04703</link>
      <description>arXiv:2404.04703v2 Announce Type: replace-cross 
Abstract: Filter data structures are widely used in various areas of computer science to answer approximate set-membership queries. In many applications, the data grows dynamically, requiring their filters to expand along with the data that they represent. However, existing methods for expanding filters cannot maintain stable performance, memory footprint, and false positive rate at the same time. We address this problem with Aleph Filter, which makes the following contributions. (1) It supports all operations (insertions, queries, deletes, etc.) in constant time, no matter how much the data grows. (2) Given any rough estimate of how much the data will ultimately grow, Aleph Filter provides far superior memory vs. false positive rate trade-offs, even if the estimate is off by orders of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04703v2</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niv Dayan, Ioana Bercea, Rasmus Pagh</dc:creator>
    </item>
  </channel>
</rss>
