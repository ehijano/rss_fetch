<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 02 Jul 2025 01:32:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Verifying Properties of Index Arrays in a Purely-Functional Data-Parallel Language</title>
      <link>https://arxiv.org/abs/2506.23058</link>
      <description>arXiv:2506.23058v1 Announce Type: new 
Abstract: This paper presents a novel approach to automatically verify properties of pure data-parallel programs with non-linear indexing -- expressed as pre- and post-conditions on functions. Programs consist of nests of second-order array combinators (e.g., map, scan, and scatter) and loops. The key idea is to represent arrays as index functions: programs are index function transformations over which properties are propagated and inferred. Our framework proves properties on index functions by distilling them into algebraic (in)equalities and discharging them to a Fourier-Motzkin-based solver. The framework is practical and accessible: properties are not restricted to a decidable logic, but instead are carefully selected to express practically useful guarantees that can be automatically reasoned about and inferred. These guarantees extend beyond program correctness and can be exploited by the entire compiler pipeline for optimization. We implement our system in the pure data-parallel language Futhark and demonstrate its practicality on seven applications, reporting an average verification time of 1 second. Two case studies show how eliminating dynamic verification in GPU programs results in significant speedups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23058v1</guid>
      <category>cs.PL</category>
      <category>cs.DC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nikolaj Hey Hinnerskov, Robert Schenck, Cosmin E. Oancea</dc:creator>
    </item>
    <item>
      <title>A Denotational Semantics for Quantum Loops</title>
      <link>https://arxiv.org/abs/2506.23320</link>
      <description>arXiv:2506.23320v1 Announce Type: new 
Abstract: Programming a quantum computer, i.e., implementing quantum algorithms on a quantum processor-based copmputer architecture, is a task that can be addressed (just as for classical computers) at different levels of abstraction. This paper proposes a denotational semantics for high-level quantum programming constructs, focusing on the conceptual meaning of quantum-controlled branching and iteration. We introduce a denotational domain where a mathematical meaning of a quantum control flow with loops can be defined, which reflects the coherent evolution of the quantum system implementing the program.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23320v1</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicola Assolini, Alessandra Di Pierro</dc:creator>
    </item>
    <item>
      <title>Compiling a Q# Subset to QASM 3.0 in TypeScript via a JSON Based IR</title>
      <link>https://arxiv.org/abs/2506.23407</link>
      <description>arXiv:2506.23407v1 Announce Type: new 
Abstract: We implement a compile toolchain from Q# to QASM 3.0 including a full-featured lexer and parser implementation, as well as a compiler that supports a subset of Q# features. The lexer, parser and compiler are shown to work with various input Q# programs and the implementation is compared against existing Q# compile tools. Unlike the Microsoft implementation of the official Q# compile toolchain, our implementation is written in TypeScript in order to port functionality to web environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23407v1</guid>
      <category>cs.PL</category>
      <category>quant-ph</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcus Edwards</dc:creator>
    </item>
    <item>
      <title>Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation</title>
      <link>https://arxiv.org/abs/2506.22776</link>
      <description>arXiv:2506.22776v1 Announce Type: cross 
Abstract: Quantization has emerged as a mainstream method for compressing Large Language Models (LLMs), reducing memory requirements and accelerating inference without architectural modifications. While existing research primarily focuses on evaluating the effectiveness of quantized LLMs compared to their original counterparts, the impact on robustness remains largely unexplored.In this paper, we present the first systematic investigation of how quantization affects the robustness of LLMs in code generation tasks. Through extensive experiments across four prominent LLM families (LLaMA, DeepSeek, CodeGen, and StarCoder) with parameter scales ranging from 350M to 33B, we evaluate robustness from dual perspectives: adversarial attacks on input prompts and noise perturbations on model architecture. Our findings challenge conventional wisdom by demonstrating that quantized LLMs often exhibit superior robustness compared to their full-precision counterparts, with 51.59% versus 42.86% of our adversarial experiments showing better resilience in quantized LLMs. Similarly, our noise perturbation experiments also confirm that LLMs after quantitation generally withstand higher levels of weight disturbances. These results suggest that quantization not only reduces computational requirements but can actually enhance LLMs' reliability in code generation tasks, providing valuable insights for developing more robust and efficient LLM deployment strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22776v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sen Fang, Weiyuan Ding, Antonio Mastropaolo, Bowen Xu</dc:creator>
    </item>
    <item>
      <title>On the Feasibility of Deduplicating Compiler Bugs with Bisection</title>
      <link>https://arxiv.org/abs/2506.23281</link>
      <description>arXiv:2506.23281v1 Announce Type: cross 
Abstract: Random testing has proven to be an effective technique for compiler validation. However, the debugging of bugs identified through random testing presents a significant challenge due to the frequent occurrence of duplicate test programs that expose identical compiler bugs. The process to identify duplicates is a practical research problem known as bug deduplication. Prior methodologies for compiler bug deduplication primarily rely on program analysis to extract bug-related features for duplicate identification, which can result in substantial computational overhead and limited generalizability. This paper investigates the feasibility of employing bisection, a standard debugging procedure largely overlooked in prior research on compiler bug deduplication, for this purpose. Our study demonstrates that the utilization of bisection to locate failure-inducing commits provides a valuable criterion for deduplication, albeit one that requires supplementary techniques for more accurate identification. Building on these results, we introduce BugLens, a novel deduplication method that primarily uses bisection, enhanced by the identification of bug-triggering optimizations to minimize false negatives. Empirical evaluations conducted on four real-world datasets demonstrate that BugLens significantly outperforms the state-of-the-art analysis-based methodologies Tamer and D3 by saving an average of 26.98% and 9.64% human effort to identify the same number of distinct bugs. Given the inherent simplicity and generalizability of bisection, it presents a highly practical solution for compiler bug deduplication in real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23281v1</guid>
      <category>cs.SE</category>
      <category>cs.PL</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xintong Zhou, Zhenyang Xu, Chengnian Sun</dc:creator>
    </item>
    <item>
      <title>What Challenges Do Developers Face When Using Verification-Aware Programming Languages?</title>
      <link>https://arxiv.org/abs/2506.23696</link>
      <description>arXiv:2506.23696v1 Announce Type: cross 
Abstract: Software reliability is critical in ensuring that the digital systems we depend on function correctly. In software development, increasing software reliability often involves testing. However, for complex and critical systems, developers can use Design by Contract (DbC) methods to define precise specifications that software components must satisfy. Verification-Aware (VA) programming languages support DbC and formal verification at compile-time or run-time, offering stronger correctness guarantees than traditional testing. However, despite the strong guarantees provided by VA languages, their adoption remains limited. In this study, we investigate the barriers to adopting VA languages by analyzing developer discussions on public forums using topic modeling techniques. We complement this analysis with a developer survey to better understand the practical challenges associated with VA languages. Our findings reveal key obstacles to adoption, including steep learning curves and usability issues. Based on these insights, we identify actionable recommendations to improve the usability and accessibility of VA languages. Our findings suggest that simplifying tool interfaces, providing better educational materials, and improving integration with everyday development environments could improve the usability and adoption of these languages. Our work provides actionable insights for improving the usability of VA languages and making verification tools more accessible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23696v1</guid>
      <category>cs.SE</category>
      <category>cs.PL</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francisco Oliveira, Alexandra Mendes, Carolina Carreira</dc:creator>
    </item>
    <item>
      <title>The Cyan Language</title>
      <link>https://arxiv.org/abs/1306.1870</link>
      <description>arXiv:1306.1870v2 Announce Type: replace 
Abstract: This is the manual of Cyan, a prototype-based object-oriented language. Cyan supports gradual typing (both static and dynamic typing), single inheritance, anonymous functions, generic prototypes with concepts, non-nullable types, partially safe object initialization, an object-oriented exception handling system, and a powerful Metaobject Protocol for metaprogramming at compile-time (this is described elsewhere).</description>
      <guid isPermaLink="false">oai:arXiv.org:1306.1870v2</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jos\'e de Oliveira Guimar\~aes</dc:creator>
    </item>
    <item>
      <title>Full Version: (De/Re)-Composition of Data-Parallel Computations via Multi-Dimensional Homomorphisms</title>
      <link>https://arxiv.org/abs/2405.05118</link>
      <description>arXiv:2405.05118v4 Announce Type: replace 
Abstract: We formally introduce a systematic (de/re)-composition approach, based on the algebraic formalism of "Multi-Dimensional Homomorphisms (MDHs)". Our approach is designed as general enough to be applicable to a wide range of data-parallel computations and for various kinds of target parallel architectures. To efficiently target the deep and complex memory and core hierarchies of contemporary architectures, we exploit our introduced (de/re)-composition approach for a correct-by-construction, parametrized cache blocking and parallelization strategy. We show that our approach is powerful enough to express, in the same formalism, the (de/re)-composition strategies of different classes of state-of-the-art approaches (scheduling-based, polyhedral, etc), and we demonstrate that the parameters of our strategies enable systematically generating code that can be fully automatically optimized (auto-tuned) for the particular target architecture and characteristics of the input and output data (e.g., their sizes and memory layouts). Particularly, our experiments confirm that via auto-tuning, we achieve higher performance than state-of-the-art approaches, including hand-optimized solutions provided by vendors (such as NVIDIA cuBLAS/cuDNN and Intel oneMKL/oneDNN), on real-world data sets and for a variety of data-parallel computations, including: linear algebra routines, stencil and quantum chemistry computations, data mining algorithms, and computations that recently gained high attention due to their relevance for deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05118v4</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3665643</arxiv:DOI>
      <arxiv:journal_reference>ACM Trans. Program. Lang. Syst. (May 2024)</arxiv:journal_reference>
      <dc:creator>Ari Rasch</dc:creator>
    </item>
    <item>
      <title>Using Read Promotion and Mixed Isolation Levels for Performant Yet Serializable Execution of Transaction Programs</title>
      <link>https://arxiv.org/abs/2501.18377</link>
      <description>arXiv:2501.18377v3 Announce Type: replace-cross 
Abstract: We propose a theory that can determine the lowest isolation level that can be allocated to each transaction program in an application in a mixed-isolation-level setting, to guarantee that all executions will be serializable and thus preserve all integrity constraints, even those that are not explicitly declared. This extends prior work applied to completely known transactions, to deal with the realistic situation where transactions are generated by running programs with parameters that are not known in advance. Using our theory, we propose an optimization method that allows for high throughput while ensuring that all executions are serializable. Our method is based on searching for application code modifications that are semantics-preserving while improving the isolation level allocation. We illustrate our approach to the SmallBank benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18377v3</guid>
      <category>cs.DB</category>
      <category>cs.PL</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brecht Vandevoort, Alan Fekete, Bas Ketsman, Frank Neven, Stijn Vansummeren</dc:creator>
    </item>
    <item>
      <title>Can Large Language Models Help Students Prove Software Correctness? An Experimental Study with Dafny</title>
      <link>https://arxiv.org/abs/2506.22370</link>
      <description>arXiv:2506.22370v2 Announce Type: replace-cross 
Abstract: Students in computing education increasingly use large language models (LLMs) such as ChatGPT. Yet, the role of LLMs in supporting cognitively demanding tasks, like deductive program verification, remains poorly understood. This paper investigates how students interact with an LLM when solving formal verification exercises in Dafny, a language that supports functional correctness, by allowing programmers to write formal specifications and automatically verifying that the implementation satisfies the specification. We conducted a mixed-methods study with master's students enrolled in a formal methods course. Each participant completed two verification problems, one with access to a custom ChatGPT interface that logged all interactions, and the other without. We identified strategies used by successful students and assessed the level of trust students place in LLMs. Our findings show that students perform significantly better when using ChatGPT; however, performance gains are tied to prompt quality. We conclude with practical recommendations for integrating LLMs into formal methods courses more effectively, including designing LLM-aware challenges that promote learning rather than substitution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22370v2</guid>
      <category>cs.SE</category>
      <category>cs.PL</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carolina Carreira, \'Alvaro Silva, Alexandre Abreu, Alexandra Mendes</dc:creator>
    </item>
  </channel>
</rss>
