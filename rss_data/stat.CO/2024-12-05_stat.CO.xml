<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Dec 2024 02:43:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Coherent forecast combination for linearly constrained multiple time series</title>
      <link>https://arxiv.org/abs/2412.03429</link>
      <description>arXiv:2412.03429v1 Announce Type: cross 
Abstract: Linearly constrained multiple time series may be encountered in many practical contexts, such as the National Accounts (e.g., GDP disaggregated by Income, Expenditure and Output), and multilevel frameworks where the variables are organized according to hierarchies or groupings, like the total energy consumption of a country disaggregated by region and energy sources. In these cases, when multiple incoherent base forecasts for each individual variable are available, a forecast combination-and-reconciliation approach, that we call coherent forecast combination, may be used to improve the accuracy of the base forecasts and achieve coherence in the final result. In this paper, we develop an optimization-based technique that combines multiple unbiased base forecasts while assuring the constraints valid for the series. We present closed form expressions for the coherent combined forecast vector and its error covariance matrix in the general case where a different number of forecasts is available for each variable. We also discuss practical issues related to the covariance matrix that is part of the optimal solution. Through simulations and a forecasting experiment on the daily Australian electricity generation hierarchical time series, we show that the proposed methodology, in addition to adhering to sound statistical principles, may yield in significant improvement on base forecasts, single-task combination and single-expert reconciliation approaches as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03429v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniele Girolimetto, Tommaso Di Fonzo</dc:creator>
    </item>
    <item>
      <title>The Lifebelt Particle Filter for robust estimation from low-valued count data</title>
      <link>https://arxiv.org/abs/2212.04400</link>
      <description>arXiv:2212.04400v3 Announce Type: replace 
Abstract: Particle filtering methods can be applied to estimation problems in discrete spaces on bounded domains, to sample from and marginalise over unknown hidden states. As in continuous settings, problems such as particle degradation can arise: proposed particles can be incompatible with the data, lying in low probability regions or outside the boundary constraints, and the discrete system could result in all particles having weights of zero. In this paper we introduce the Lifebelt Particle Filter (LBPF), a novel method for robust likelihood estimation in low-valued count problems. The LBPF combines a standard particle filter with one (or more) lifebelt particles which, by construction, lie within the boundaries of the discrete random variables, and therefore are compatible with the data. A mixture of resampled and non-resampled particles allows for the preservation of the lifebelt particle, which, together with the remaining particle swarm, provides samples from the filtering distribution, and can be used to generate unbiased estimates of the likelihood. The main benefit of the LBPF is that only one or few, wisely chosen, particles are sufficient to prevent particle collapse. Differently from other methods, there is no need to increase the number of particles, and therefore the computational effort, in regions of the parameter space that generate less likely hidden states. The LBPF can be used within a pseudo-marginal scheme to draw inferences on static parameters, $ \boldsymbol{\theta} $, governing the system. We address here the estimation of a parameter governing probabilities of deaths and recoveries of hospitalised patients during an epidemic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.04400v3</guid>
      <category>stat.CO</category>
      <pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Alice Corbella, Trevelyan J. McKinley, Paul J. Birrell, Daniela De Angelis, Anne M. Presanis, Gareth O. Roberts, Simon E. F. Spencer</dc:creator>
    </item>
    <item>
      <title>Quantifying the effectiveness of linear preconditioning in Markov chain Monte Carlo</title>
      <link>https://arxiv.org/abs/2312.04898</link>
      <description>arXiv:2312.04898v2 Announce Type: replace 
Abstract: We study linear preconditioning in Markov chain Monte Carlo. We consider the class of well-conditioned distributions, for which several mixing time bounds depend on the condition number $\kappa$. First we show that well-conditioned distributions exist for which $\kappa$ can be arbitrarily large and yet no linear preconditioner can reduce it. We then impose two sets of extra assumptions under which a linear preconditioner can significantly reduce $\kappa$. For the random walk Metropolis we further provide upper and lower bounds on the spectral gap with tight $1/\kappa$ dependence. This allows us to give conditions under which linear preconditioning can provably increase the gap. We then study popular preconditioners such as the covariance, its diagonal approximation, the hessian at the mode, and the QR decomposition. We show conditions under which each of these reduce $\kappa$ to near its minimum. We also show that the diagonal approach can in fact \textit{increase} the condition number. This is of interest as diagonal preconditioning is the default choice in well-known software packages. We conclude with a numerical study comparing preconditioners in different models, and showing how proper preconditioning can greatly reduce compute time in Hamiltonian Monte Carlo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.04898v2</guid>
      <category>stat.CO</category>
      <category>math.ST</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Max Hird, Samuel Livingstone</dc:creator>
    </item>
    <item>
      <title>Likelihood Based Inference for ARMA Models</title>
      <link>https://arxiv.org/abs/2310.01198</link>
      <description>arXiv:2310.01198v5 Announce Type: replace-cross 
Abstract: Autoregressive moving average (ARMA) models are widely used for analyzing time series data. However, standard likelihood-based inference methodology for ARMA models has avoidable limitations. We show that common ARMA likelihood maximization strategies often lead to sub-optimal parameter estimates. While this possibility has been previously identified, no routinely applicable algorithm has been developed to resolve the issue. We introduce a novel random initialization algorithm, designed to take advantage of the structure of the ARMA likelihood function, which overcomes these optimization problems. Additionally, we show that profile confidence intervals provide superior confidence intervals to those based on the Fisher information matrix. The efficacy of the proposed methodology is demonstrated through a data analysis example and a series of simulation studies. This work makes a significant contribution to statistical practice by identifying and resolving under-recognized shortcomings of existing procedures that frequently arise in scientific and industrial applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01198v5</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jesse Wheeler, Edward L. Ionides</dc:creator>
    </item>
    <item>
      <title>Fast Computation of Leave-One-Out Cross-Validation for $k$-NN Regression</title>
      <link>https://arxiv.org/abs/2405.04919</link>
      <description>arXiv:2405.04919v2 Announce Type: replace-cross 
Abstract: We describe a fast computation method for leave-one-out cross-validation (LOOCV) for $k$-nearest neighbours ($k$-NN) regression. We show that, under a tie-breaking condition for nearest neighbours, the LOOCV estimate of the mean square error for $k$-NN regression is identical to the mean square error of $(k+1)$-NN regression evaluated on the training data, multiplied by the scaling factor $(k+1)^2/k^2$. Therefore, to compute the LOOCV score, one only needs to fit $(k+1)$-NN regression only once, and does not need to repeat training-validation of $k$-NN regression for the number of training data. Numerical experiments confirm the validity of the fast computation method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04919v2</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Motonobu Kanagawa</dc:creator>
    </item>
  </channel>
</rss>
