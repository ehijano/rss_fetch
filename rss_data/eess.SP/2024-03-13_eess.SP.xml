<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 13 Mar 2024 04:03:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 13 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Physics Sensor Based Deep Learning Fall Detection System</title>
      <link>https://arxiv.org/abs/2403.06994</link>
      <description>arXiv:2403.06994v1 Announce Type: new 
Abstract: Fall detection based on embedded sensor is a practical and popular research direction in recent years. In terms of a specific application: fall detection methods based upon physics sensors such as [gyroscope and accelerator] have been exploited using traditional hand crafted features and feed them in machine learning models like Markov chain or just threshold based classification methods. In this paper, we build a complete system named TSFallDetect including data receiving device based on embedded sensor, mobile deep-learning model deploying platform, and a simple server, which will be used to gather models and data for future expansion. On the other hand, we exploit the sequential deep-learning methods to address this falling motion prediction problem based on data collected by inertial and film pressure sensors. We make a empirical study based on existing datasets and our datasets collected from our system separately, which shows that the deep-learning model has more potential advantage than other traditional methods, and we proposed a new deep-learning model based on the time series data to predict the fall, and it may be superior to other sequential models in this particular field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06994v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyuan Qu, Tiange Huang, Yuxin Ji, Yongjun Li</dc:creator>
    </item>
    <item>
      <title>High-speed Low-consumption sEMG-based Transient-state micro-Gesture Recognition by Spiking Neural Network</title>
      <link>https://arxiv.org/abs/2403.06998</link>
      <description>arXiv:2403.06998v1 Announce Type: new 
Abstract: Gesture recognition on wearable devices is extensively applied in human-computer interaction. Electromyography (EMG) has been used in many gesture recognition systems for its rapid perception of muscle signals. However, analyzing EMG signals on devices, like smart wristbands, usually needs inference models to have high performances, such as low inference latency, low power consumption, and low memory occupation. Therefore, this paper proposes an improved spiking neural network (SNN) to achieve these goals. We propose an adaptive multi-delta coding as a spiking coding method to improve recognition accuracy. We propose two additive solvers for SNN, which can reduce inference energy consumption and amount of parameters significantly, and improve the robustness of temporal differences. In addition, we propose a linear action detection method TAD-LIF, which is suitable for SNNs. TAD-LIF is an improved LIF neuron that can detect transient-state gestures quickly and accurately. We collected two datasets from 20 subjects including 6 micro gestures. The collection devices are two designed lightweight consumer-level EMG wristbands (3 and 8 electrode channels respectively). Compared to CNN, FCN, and normal SNN-based methods, the proposed SNN has higher recognition accuracy. The accuracy of the proposed SNN is 83.85% and 93.52% on the two datasets respectively. In addition, the inference latency of the proposed SNN is about 1% of CNN, the power consumption is about 0.1% of CNN, and the memory occupation is about 20% of CNN. The proposed methods can be used for precise, high-speed, and low-power micro-gesture recognition tasks, and are suitable for consumer-level intelligent wearable devices, which is a general way to achieve ubiquitous computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06998v1</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youfang Han, Wei Zhao, Xiangjin Chen, Xin Meng</dc:creator>
    </item>
    <item>
      <title>Physics-constrained Active Learning for Soil Moisture Estimation and Optimal Sensor Placement</title>
      <link>https://arxiv.org/abs/2403.07228</link>
      <description>arXiv:2403.07228v1 Announce Type: new 
Abstract: Soil moisture is a crucial hydrological state variable that has significant importance to the global environment and agriculture. Precise monitoring of soil moisture in crop fields is critical to reducing agricultural drought and improving crop yield. In-situ soil moisture sensors, which are buried at pre-determined depths and distributed across the field, are promising solutions for monitoring soil moisture. However, high-density sensor deployment is neither economically feasible nor practical. Thus, to achieve a higher spatial resolution of soil moisture dynamics using a limited number of sensors, we integrate a physics-based agro-hydrological model based on Richards' equation in a physics-constrained deep learning framework to accurately predict soil moisture dynamics in the soil's root zone. This approach ensures that soil moisture estimates align well with sensor observations while obeying physical laws at the same time. Furthermore, to strategically identify the locations for sensor placement, we introduce a novel active learning framework that combines space-filling design and physics residual-based sampling to maximize data acquisition potential with limited sensors. Our numerical results demonstrate that integrating Physics-constrained Deep Learning (P-DL) with an active learning strategy within a unified framework--named the Physics-constrained Active Learning (P-DAL) framework--significantly improves the predictive accuracy and effectiveness of field-scale soil moisture monitoring using in-situ sensors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07228v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jianxin Xie, Bing Yao, Zheyu Jiang</dc:creator>
    </item>
    <item>
      <title>Deep Learning-Assisted Parallel Interference Cancellation for Grant-Free NOMA in Machine-Type Communication</title>
      <link>https://arxiv.org/abs/2403.07255</link>
      <description>arXiv:2403.07255v1 Announce Type: new 
Abstract: In this paper, we present a novel approach for joint activity detection (AD), channel estimation (CE), and data detection (DD) in uplink grant-free non-orthogonal multiple access (NOMA) systems. Our approach employs an iterative and parallel interference removal strategy inspired by parallel interference cancellation (PIC), enhanced with deep learning to jointly tackle the AD, CE, and DD problems. Based on this approach, we develop three PIC frameworks, each of which is designed for either coherent or non-coherence schemes. The first framework performs joint AD and CE using received pilot signals in the coherent scheme. Building upon this framework, the second framework utilizes both the received pilot and data signals for CE, further enhancing the performances of AD, CE, and DD in the coherent scheme. The third framework is designed to accommodate the non-coherent scheme involving a small number of data bits, which simultaneously performs AD and DD. Through joint loss functions and interference cancellation modules, our approach supports end-to-end training, contributing to enhanced performances of AD, CE, and DD for both coherent and non-coherent schemes. Simulation results demonstrate the superiority of our approach over traditional techniques, exhibiting enhanced performances of AD, CE, and DD while maintaining lower computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07255v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongjeong Oh, Jaehong Jo, Byonghyo Shim, Yo-Seb Jeon</dc:creator>
    </item>
    <item>
      <title>Advancements in Continuous Glucose Monitoring: Integrating Deep Learning and ECG Signal</title>
      <link>https://arxiv.org/abs/2403.07296</link>
      <description>arXiv:2403.07296v1 Announce Type: new 
Abstract: This paper presents a novel approach to noninvasive hyperglycemia monitoring utilizing electrocardiograms (ECG) from an extensive database comprising 1119 subjects. Previous research on hyperglycemia or glucose detection using ECG has been constrained by challenges related to generalization and scalability, primarily due to using all subjects' ECG in training without considering unseen subjects as a critical factor for developing methods with effective generalization. We designed a deep neural network model capable of identifying significant features across various spatial locations and examining the interdependencies among different features within each convolutional layer. To expedite processing speed, we segment the ECG of each user to isolate one heartbeat or one cycle of the ECG. Our model was trained using data from 727 subjects, while 168 were used for validation. The testing phase involved 224 unseen subjects, with a dataset consisting of 9,000 segments. The result indicates that the proposed algorithm effectively detects hyperglycemia with a 91.60% area under the curve (AUC), 81.05% sensitivity, and 85.54% specificity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07296v1</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>MohammadReza Hosseinzadehketilateh, Banafsheh Adami, Nima Karimian</dc:creator>
    </item>
    <item>
      <title>Discrete-Time Modeling and Handover Analysis of Intelligent Reflecting Surface-Assisted Networks</title>
      <link>https://arxiv.org/abs/2403.07323</link>
      <description>arXiv:2403.07323v1 Announce Type: new 
Abstract: Owning to the reflection gain and double path loss featured by intelligent reflecting surface (IRS) channels, handover (HO) locations become irregular and the signal strength fluctuates sharply with variations in IRS connections during HO, the risk of HO failures (HOFs) is exacerbated and thus HO parameters require reconfiguration. However, existing HO models only assume monotonic negative exponential path loss and cannot obtain sound HO parameters. This paper proposes a discrete-time model to explicitly track the HO process with variations in IRS connections, where IRS connections and HO process are discretized as finite states by measurement intervals, and transitions between states are modeled as stochastic processes. Specifically, to capture signal fluctuations during HO, IRS connection state-dependent distributions of the user-IRS distance are modified by the correlation between measurement intervals. In addition, states of the HO process are formed with Time-to-Trigger and HO margin whose transition probabilities are integrated concerning all IRS connection states. Trigger location distributions and probabilities of HO, HOF, and ping-pong (PP) are obtained by tracing user HO states. Results show IRSs mitigate PPs by 48% but exacerbate HOFs by 90% under regular parameters. Optimal parameters are mined ensuring probabilities of HOF and PP are both less than 0.1%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07323v1</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongtao Zhang, Haoyan Wei</dc:creator>
    </item>
    <item>
      <title>Analysis of Intelligent Reflecting Surface-Enhanced Mobility Through a Line-of-Sight State Transition Model</title>
      <link>https://arxiv.org/abs/2403.07337</link>
      <description>arXiv:2403.07337v1 Announce Type: new 
Abstract: Rapid signal fluctuations due to blockage effects cause excessive handovers (HOs) and degrade mobility performance. By reconfiguring line-of-sight (LoS) Links through passive reflections, intelligent reflective surface (IRS) has the potential to address this issue. Due to the lack of introducing blocking effects, existing HO analyses cannot capture excessive HOs or exploit enhancements via IRSs. This paper proposes an LoS state transition model enabling analysis of mobility enhancement achieved by IRS-reconfigured LoS links, where LoS link blocking and reconfiguration utilizing IRS during user movement are explicitly modeled as stochastic processes. Specifically, the condition for blocking LoS links is characterized as a set of possible blockage locations, the distribution of available IRSs is thinned by the criteria for reconfiguring LoS links. In addition, BSs potentially handed over are categorized by probabilities of LoS states to enable HO decision analysis. By projecting distinct gains of LoS states onto a uniform equivalent distance criterion, mobility enhanced by IRS is quantified through the compact expression of HO probability. Results show the probability of dropping into non-LoS decreases by 70% when deploying IRSs with the density of 93/km$^2$, and HOs decrease by 67% under the optimal IRS distributed deployment parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07337v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongtao Zhang, Haoyan Wei</dc:creator>
    </item>
    <item>
      <title>Vector Quantization for Deep-Learning-Based CSI Feedback in Massive MIMO Systems</title>
      <link>https://arxiv.org/abs/2403.07355</link>
      <description>arXiv:2403.07355v1 Announce Type: new 
Abstract: This paper presents a finite-rate deep-learning (DL)-based channel state information (CSI) feedback method for massive multiple-input multiple-output (MIMO) systems. The presented method provides a finite-bit representation of the latent vector based on a vector-quantized variational autoencoder (VQ-VAE) framework while reducing its computational complexity based on shape-gain vector quantization. In this method, the magnitude of the latent vector is quantized using a non-uniform scalar codebook with a proper transformation function, while the direction of the latent vector is quantized using a trainable Grassmannian codebook. A multi-rate codebook design strategy is also developed by introducing a codeword selection rule for a nested codebook along with the design of a loss function. Simulation results demonstrate that the proposed method reduces the computational complexity associated with VQ-VAE while improving CSI reconstruction performance under a given feedback overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07355v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyong Shin, Yujin Kang, Yo-Seb Jeon</dc:creator>
    </item>
    <item>
      <title>Broadened-beam Uniform Rectangular Array Coefficient Design in LEO SatComs Under Quality of Service and Constant Modulus Constraints</title>
      <link>https://arxiv.org/abs/2403.07435</link>
      <description>arXiv:2403.07435v1 Announce Type: new 
Abstract: Satellite communications (SatComs) are anticipated to provide global Internet access. Low Earth orbit (LEO) satellites (SATs) have the advantage of providing higher downlink capacity owing to their smaller link budget compared with medium Earth orbit (MEO) and geostationary Earth orbit (GEO) SATs. In this paper, beam-broadening algorithms for uniform rectangular arrays (URAs) in LEO SatComs were studied. The proposed method is the first of its kind that jointly considers the path loss variation from SAT to user terminal (UT) due to the Earth's curvature to guarantee quality of service (QoS) inspired by the synthesis of isoflux radiation patterns in the literature, constant modulus constraint (CMC) favored for maximizing power amplifier (PA) efficiency, and out-of-beam radiation suppression to avoid interference. A URA design problem is formulated and decomposed into two uniform linear array (ULA) design subproblems utilizing the idea of Kronecker product beamforming to reduce the computational complexity of designing URA.The non-convex ULA subproblems are solved by a convex iterative algorithm. Simulation results reveal the advantages of the proposed method for suppressing out-of-beam radiation and achieving design criteria. In addition, channel capacity evaluation is carried out and shows that the proposed ``broadened-beam" beamformers can offer capacities that are at least four times greater than ``narrow-beam" beamformers employing an array steering vector when beam transition time is taken into account. The proposed method holds potential for LEO broadcasting applications such as digital video broadcasting (DVB).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07435v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiting Lin, Yuchieh Wu, Borching Su</dc:creator>
    </item>
    <item>
      <title>Experimental analysis of the TRC benchmark system</title>
      <link>https://arxiv.org/abs/2403.07438</link>
      <description>arXiv:2403.07438v1 Announce Type: new 
Abstract: The Tribomechadynamics Research Challenge (TRC) was a blind prediction of the vibration behavior of a thin plate clamped on two sides using bolted joints. The first bending mode's natural frequency and damping ratio were requested as function of the amplitude, starting from the linear regime until high levels, where both frictional contact and nonlinear bending-stretching coupling become relevant. The predictions were confronted with experimental results in a companion paper; the present article addresses the experimental analysis of this benchmark system. Amplitude-dependent modal data was obtained from phase resonance and response controlled tests. An original variant of response controlled testing is proposed: Instead of a fixed frequency interval, a fixed phase interval is analyzed. This way, the high excitation levels required outside resonance, which could activate unwanted exciter nonlinearity, are avoided. Consistency of testing methods is carefully analyzed. Overall, these measures have permitted to gain high confidence in the acquired modal data. The different sources of the remaining uncertainty were further analyzed. A low reassembly-variability but a moderate time-variability were identified, where the latter is attributed to some thermal sensitivity of the system. Two nominally identical plates were analyzed, which both have an appreciable initial curvature, and a significant effect on the vibration behavior was found depending on whether the plate is aligned/misaligned with the support structure. Further, a 1:2 nonlinear modal interaction with the first torsion mode was observed, which only occurs in the aligned configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07438v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arati Bhattu, Svenja Hermann, Nidhal Jamia, Florian M\"uller, Maren Scheel, Christoph Schwingshackl, H. Nevzat \"Ozg\"uven, Malte Krack</dc:creator>
    </item>
    <item>
      <title>Exploring Challenges in Deep Learning of Single-Station Ground Motion Records</title>
      <link>https://arxiv.org/abs/2403.07569</link>
      <description>arXiv:2403.07569v1 Announce Type: new 
Abstract: Contemporary deep learning models have demonstrated promising results across various applications within seismology and earthquake engineering. These models rely primarily on utilizing ground motion records for tasks such as earthquake event classification, localization, earthquake early warning systems, and structural health monitoring. However, the extent to which these models effectively learn from these complex time-series signals has not been thoroughly analyzed. In this study, our objective is to evaluate the degree to which auxiliary information, such as seismic phase arrival times or seismic station distribution within a network, dominates the process of deep learning from ground motion records, potentially hindering its effectiveness. We perform a hyperparameter search on two deep learning models to assess their effectiveness in deep learning from ground motion records while also examining the impact of auxiliary information on model performance. Experimental results reveal a strong reliance on the highly correlated P and S phase arrival information. Our observations highlight a potential gap in the field, indicating an absence of robust methodologies for deep learning of single-station ground motion recordings independent of any auxiliary information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07569v1</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\"Umit Mert \c{C}a\u{g}lar, Baris Yilmaz, Melek T\"urkmen, Erdem Akag\"und\"uz, Salih Tileylioglu</dc:creator>
    </item>
    <item>
      <title>Enhancing Physical Layer Security in Dual-Function Radar-Communication Systems with Hybrid Beamforming Architecture</title>
      <link>https://arxiv.org/abs/2403.07655</link>
      <description>arXiv:2403.07655v1 Announce Type: new 
Abstract: In this letter, we investigate enhancing the physical layer security (PLS) for the dual-function radar-communication (DFRC) system with hybrid beamforming (HBF) architecture, where the base station (BS) achieves downlink communication and radar target detection simultaneously. We consider an eavesdropper intercepting the information transmitted from the BS to the downlink communication users with imperfectly known channel state information. Additionally, the location of the radar target is also imperfectly known by the BS. To enhance PLS in the considered DFRC system, we propose a novel HBF architecture, which introduces a new integrated sensing and security (I2S) symbol. The secure HBF design problem for DFRC is formulated by maximizing the minimum legitimate user communication rate subject to radar interference-plus-noise ratio, eavesdropping rate, hardware and power constraints. To solve this non-convex problem, we propose an alternating optimization based method to jointly optimize transmit and receive beamformers. Numerical simulation results validate the effectiveness of the proposed algorithm and show the superiority of the proposed I2S-aided HBF architecture for achieving DFRC and enhancing PLS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07655v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lingyun Xu, Bowen Wang, Jieming Shi, Huiyong Li, Ziyang Cheng</dc:creator>
    </item>
    <item>
      <title>HermEIS: A Parallel Multichannel Approach to Rapid Spectral Characterization of Neural MEAs</title>
      <link>https://arxiv.org/abs/2403.07758</link>
      <description>arXiv:2403.07758v1 Announce Type: new 
Abstract: The promise of increasing channel counts in high density ($&gt; 10^4$) neural Microelectrode Arrays (MEAs) for high resolution recording comes with the curse of developing faster characterization strategies for concurrent acquisition of multichannel electrode integrities over a wide frequency spectrum. To circumvent the latency associated with the current multiplexed technique for impedance acquisition, it is common practice to resort to the single frequency impedance measurement (i.e. $Z_{1 \text{kHz}}$). This, however, does not offer sufficient spectral impedance information crucial for determining the capacity of electrodes at withstanding slow and fast-changing stimulus and recordings. In this work, we present \textit{HermEIS}, a novel approach that leverages single cycle in-phase and quadrature signal integrations for reducing the massive data throughput characteristic of such high density acquisition systems. As an initial proof-of-concept, we demonstrate over $6$ decades of impedance bandwidth ($5\times10^{-2} - 5\times10^{4}\text{ Hz}$) in a parallel $4$-channel potentiostatic setup composed of a custom PCB with off-the-shelf electronics working in tandem with an FPGA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07758v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akwasi Akwaboah, Ralph Etienne-Cummings</dc:creator>
    </item>
    <item>
      <title>Explainable Learning with Gaussian Processes</title>
      <link>https://arxiv.org/abs/2403.07072</link>
      <description>arXiv:2403.07072v1 Announce Type: cross 
Abstract: The field of explainable artificial intelligence (XAI) attempts to develop methods that provide insight into how complicated machine learning methods make predictions. Many methods of explanation have focused on the concept of feature attribution, a decomposition of the model's prediction into individual contributions corresponding to each input feature. In this work, we explore the problem of feature attribution in the context of Gaussian process regression (GPR). We take a principled approach to defining attributions under model uncertainty, extending the existing literature. We show that although GPR is a highly flexible and non-parametric approach, we can derive interpretable, closed-form expressions for the feature attributions. When using integrated gradients as an attribution method, we show that the attributions of a GPR model also follow a Gaussian process distribution, which quantifies the uncertainty in attribution arising from uncertainty in the model. We demonstrate, both through theory and experimentation, the versatility and robustness of this approach. We also show that, when applicable, the exact expressions for GPR attributions are both more accurate and less computationally expensive than the approximations currently used in practice. The source code for this project is freely available under MIT license at https://github.com/KurtButler/2024_attributions_paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07072v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kurt Butler, Guanchao Feng, Petar M. Djuric</dc:creator>
    </item>
    <item>
      <title>Graph learning methods to extract empathy supporting regions in a naturalistic stimuli fMRI</title>
      <link>https://arxiv.org/abs/2403.07089</link>
      <description>arXiv:2403.07089v1 Announce Type: cross 
Abstract: Functional MRI (fMRI) research, employing naturalistic stimuli like movies, explores brain network interactions in complex cognitive processes such as empathy. The empathy network encompasses multiple brain areas, including the Insula, PFC, ACC, and parietal regions. Our novel processing pipeline applies graph learning methods to whole-brain timeseries signals, incorporating high-pass filtering, voxel-level clustering, and windowed graph learning with a sparsity-based approach. The study involves two short movies shown to 14 healthy volunteers, considering 54 regions extracted from the AAL Atlas. The sparsity-based graph learning consistently outperforms, achieving over 88% accuracy in capturing emotion contagion variations. Temporal analysis reveals a gradual induction of empathy, supported by the method's effectiveness in capturing dynamic connectomes through graph clustering. Edge-weight dynamics analysis underscores sparsity-based learning's superiority, while connectome-network analysis highlights the pivotal role of the Insula, Amygdala, and Thalamus in empathy. Spectral filtering analysis emphasizes the band-pass filter's significance in isolating regions linked to emotional and empathetic processing during empathy HIGH states. Key regions like Amygdala, Insula, and Angular Gyrus consistently activate, supporting their critical role in immediate emotional responses. Strong similarities across movies in graph cluster labels, connectome-network analysis, and spectral filtering-based analyses reveal robust neural correlates of empathy. These findings advance our understanding of empathy-related neural dynamics and identify specific regions in empathetic responses, offering insights for targeted interventions and treatments associated with empathetic processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07089v1</guid>
      <category>q-bio.NC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sasanka GRS (Signal Processing and Communication Research Center, IIIT Hyderabad), Ayushi Agrawal (Cognitive Science Lab, IIIT Hyderabad), Santosh Nannuru (Signal Processing and Communication Research Center, IIIT Hyderabad), Kavita Vemuri (Cognitive Science Lab, IIIT Hyderabad)</dc:creator>
    </item>
    <item>
      <title>Anderson acceleration for iteratively reweighted $\ell_1$ algorithm</title>
      <link>https://arxiv.org/abs/2403.07271</link>
      <description>arXiv:2403.07271v1 Announce Type: cross 
Abstract: Iteratively reweighted L1 (IRL1) algorithm is a common algorithm for solving sparse optimization problems with nonconvex and nonsmooth regularization. The development of its acceleration algorithm, often employing Nesterov acceleration, has sparked significant interest. Nevertheless, the convergence and complexity analysis of these acceleration algorithms consistently poses substantial challenges. Recently, Anderson acceleration has gained prominence owing to its exceptional performance for speeding up fixed-point iteration, with numerous recent studies applying it to gradient-based algorithms. Motivated by the powerful impact of Anderson acceleration, we propose an Anderson-accelerated IRL1 algorithm and establish its local linear convergence rate. We extend this convergence result, typically observed in smooth settings, to a nonsmooth scenario. Importantly, our theoretical results do not depend on the Kurdyka-Lojasiewicz condition, a necessary condition in existing Nesterov acceleration-based algorithms. Furthermore, to ensure global convergence, we introduce a globally convergent Anderson accelerated IRL1 algorithm by incorporating a classical nonmonotone line search condition. Experimental results indicate that our algorithm outperforms existing Nesterov acceleration-based algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07271v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kexin Li</dc:creator>
    </item>
    <item>
      <title>Achievable Rate Analysis and Optimization of Double-RIS Assisted Spatially Correlated MIMO with Statistical CSI</title>
      <link>https://arxiv.org/abs/2403.07274</link>
      <description>arXiv:2403.07274v1 Announce Type: cross 
Abstract: Reconfigurable intelligent surface (RIS) is a novel meta-material which can form a smart radio environment by dynamically altering reflection directions of the impinging electromagnetic waves. In the prior literature, the inter-RIS links which also contribute to the performance of the whole system are usually neglected when multiple RISs are deployed. In this paper we investigate a general double-RIS assisted multiple-input multiple-output (MIMO) wireless communication system under spatially correlated non line-of-sight propagation channels, where the cooperation of the double RISs is also considered. The design objective is to maximize the achievable ergodic rate based on full statistical channel state information (CSI). Specifically, we firstly present a closed-form asymptotic expression for the achievable ergodic rate by utilizing replica method from statistical physics. Then a full statistical CSI-enabled optimal design is proposed which avoids high pilot training overhead compared to instantaneous CSI-enabled design. To further reduce the signal processing overhead and lower the complexity for practical realization, a common-phase scheme is proposed to design the double RISs. Simulation results show that the derived asymptotic ergodic rate is quite accurate even for small-sized antenna arrays. And the proposed optimization algorithm can achieve substantial gain at the expense of a low overhead and complexity. Furthermore, the cooperative double-RIS assisted MIMO framework is proven to achieve superior ergodic rate performance and high communication reliability under harsh propagation environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07274v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaizhe Xu, Jiajia Guo, Jun Zhang, Shi Jin, Shaodan Ma</dc:creator>
    </item>
    <item>
      <title>Integrated Communications and Localization for Massive MIMO LEO Satellite Systems</title>
      <link>https://arxiv.org/abs/2403.07305</link>
      <description>arXiv:2403.07305v1 Announce Type: cross 
Abstract: Integrated communications and localization (ICAL) will play an important part in future sixth generation (6G) networks for the realization of Internet of Everything (IoE) to support both global communications and seamless localization. Massive multiple-input multiple-output (MIMO) low earth orbit (LEO) satellite systems have great potential in providing wide coverage with enhanced gains, and thus are strong candidates for realizing ubiquitous ICAL. In this paper, we develop a wideband massive MIMO LEO satellite system to simultaneously support wireless communications and localization operations in the downlink. In particular, we first characterize the signal propagation properties and derive a localization performance bound. Based on these analyses, we focus on the hybrid analog/digital precoding design to achieve high communication capability and localization precision. Numerical results demonstrate that the proposed ICAL scheme supports both the wireless communication and localization operations for typical system setups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07305v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Li You, Xiaoyu Qiang, Yongxiang Zhu, Fan Jiang, Christos G. Tsinos, Wenjin Wang, Henk Wymeersch, Xiqi Gao, Bj\"orn Ottersten</dc:creator>
    </item>
    <item>
      <title>Approaching Rate-Distortion Limits in Neural Compression with Lattice Transform Coding</title>
      <link>https://arxiv.org/abs/2403.07320</link>
      <description>arXiv:2403.07320v1 Announce Type: cross 
Abstract: Neural compression has brought tremendous progress in designing lossy compressors with good rate-distortion (RD) performance at low complexity. Thus far, neural compression design involves transforming the source to a latent vector, which is then rounded to integers and entropy coded. While this approach has been shown to be optimal in a one-shot sense on certain sources, we show that it is highly sub-optimal on i.i.d. sequences, and in fact always recovers scalar quantization of the original source sequence. We demonstrate that the sub-optimality is due to the choice of quantization scheme in the latent space, and not the transform design. By employing lattice quantization instead of scalar quantization in the latent space, we demonstrate that Lattice Transform Coding (LTC) is able to recover optimal vector quantization at various dimensions and approach the asymptotically-achievable rate-distortion function at reasonable complexity. On general vector sources, LTC improves upon standard neural compressors in one-shot coding performance. LTC also enables neural compressors that perform block coding on i.i.d. vector sources, which yields coding gain over optimal one-shot coding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07320v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Lei, Hamed Hassani, Shirin Saeedi Bidokhti</dc:creator>
    </item>
    <item>
      <title>D$^2$-JSCC: Digital Deep Joint Source-channel Coding for Semantic Communications</title>
      <link>https://arxiv.org/abs/2403.07338</link>
      <description>arXiv:2403.07338v1 Announce Type: cross 
Abstract: Semantic communications (SemCom) have emerged as a new paradigm for supporting sixth-generation applications, where semantic features of data are transmitted using artificial intelligence algorithms to attain high communication efficiencies. Most existing SemCom techniques utilize deep neural networks (DNNs) to implement analog source-channel mappings, which are incompatible with existing digital communication architectures. To address this issue, this paper proposes a novel framework of digital deep joint source-channel coding (D$^2$-JSCC) targeting image transmission in SemCom. The framework features digital source and channel codings that are jointly optimized to reduce the end-to-end (E2E) distortion. First, deep source coding with an adaptive density model is designed to encode semantic features according to their distributions. Second, digital channel coding is employed to protect encoded features against channel distortion. To facilitate their joint design, the E2E distortion is characterized as a function of the source and channel rates via the analysis of the Bayesian model and Lipschitz assumption on the DNNs. Then to minimize the E2E distortion, a two-step algorithm is proposed to control the source-channel rates for a given channel signal-to-noise ratio. Simulation results reveal that the proposed framework outperforms classic deep JSCC and mitigates the cliff and leveling-off effects, which commonly exist for separation-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07338v1</guid>
      <category>cs.IT</category>
      <category>cs.MM</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianhao Huang, Kai Yuan, Chuan Huang, Kaibin Huang</dc:creator>
    </item>
    <item>
      <title>A Survey on Federated Learning in Intelligent Transportation Systems</title>
      <link>https://arxiv.org/abs/2403.07444</link>
      <description>arXiv:2403.07444v1 Announce Type: cross 
Abstract: The development of Intelligent Transportation System (ITS) has brought about comprehensive urban traffic information that not only provides convenience to urban residents in their daily lives but also enhances the efficiency of urban road usage, leading to a more harmonious and sustainable urban life. Typical scenarios in ITS mainly include traffic flow prediction, traffic target recognition, and vehicular edge computing. However, most current ITS applications rely on a centralized training approach where users upload source data to a cloud server with high computing power for management and centralized training. This approach has limitations such as poor real-time performance, data silos, and difficulty in guaranteeing data privacy. To address these limitations, federated learning (FL) has been proposed as a promising solution. In this paper, we present a comprehensive review of the application of FL in ITS, with a particular focus on three key scenarios: traffic flow prediction, traffic target recognition, and vehicular edge computing. For each scenario, we provide an in-depth analysis of its key characteristics, current challenges, and specific manners in which FL is leveraged. Moreover, we discuss the benefits that FL can offer as a potential solution to the limitations of the centralized training approach currently used in ITS applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07444v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rongqing Zhang, Hanqiu Wang, Bing Li, Xiang Cheng, Liuqing Yang</dc:creator>
    </item>
    <item>
      <title>Visual Decoding and Reconstruction via EEG Embeddings with Guided Diffusion</title>
      <link>https://arxiv.org/abs/2403.07721</link>
      <description>arXiv:2403.07721v1 Announce Type: cross 
Abstract: How to decode human vision through neural signals has attracted a long-standing interest in neuroscience and machine learning. Modern contrastive learning and generative models improved the performance of fMRI-based visual decoding and reconstruction. However, the high cost and low temporal resolution of fMRI limit their applications in brain-computer interfaces (BCIs), prompting a high need for EEG-based visual reconstruction. In this study, we present an EEG-based visual reconstruction framework. It consists of a plug-and-play EEG encoder called the Adaptive Thinking Mapper (ATM), which is aligned with image embeddings, and a two-stage EEG guidance image generator that first transforms EEG features into image priors and then reconstructs the visual stimuli with a pre-trained image generator. Our approach allows EEG embeddings to achieve superior performance in image classification and retrieval tasks. Our two-stage image generation strategy vividly reconstructs images seen by humans. Furthermore, we analyzed the impact of signals from different time windows and brain regions on decoding and reconstruction. The versatility of our framework is demonstrated in the magnetoencephalogram (MEG) data modality. We report that EEG-based visual decoding achieves SOTA performance, highlighting the portability, low cost, and high temporal resolution of EEG, enabling a wide range of BCI applications. The code of ATM is available at https://anonymous.4open.science/status/EEG_Image_decode-DEEF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07721v1</guid>
      <category>cs.HC</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongyang Li, Chen Wei, Shiying Li, Jiachen Zou, Quanying Liu</dc:creator>
    </item>
    <item>
      <title>Beyond the Labels: Unveiling Text-Dependency in Paralinguistic Speech Recognition Datasets</title>
      <link>https://arxiv.org/abs/2403.07767</link>
      <description>arXiv:2403.07767v1 Announce Type: cross 
Abstract: Paralinguistic traits like cognitive load and emotion are increasingly recognized as pivotal areas in speech recognition research, often examined through specialized datasets like CLSE and IEMOCAP. However, the integrity of these datasets is seldom scrutinized for text-dependency. This paper critically evaluates the prevalent assumption that machine learning models trained on such datasets genuinely learn to identify paralinguistic traits, rather than merely capturing lexical features. By examining the lexical overlap in these datasets and testing the performance of machine learning models, we expose significant text-dependency in trait-labeling. Our results suggest that some machine learning models, especially large pre-trained models like HuBERT, might inadvertently focus on lexical characteristics rather than the intended paralinguistic features. The study serves as a call to action for the research community to reevaluate the reliability of existing datasets and methodologies, ensuring that machine learning models genuinely learn what they are designed to recognize.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07767v1</guid>
      <category>eess.AS</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jan Pe\v{s}\'an, Santosh Kesiraju, Luk\'a\v{s} Burget, Jan ''Honza'' \v{C}ernock\'y</dc:creator>
    </item>
    <item>
      <title>Mental Workload Estimation with Electroencephalogram Signals by Combining Multi-Space Deep Models</title>
      <link>https://arxiv.org/abs/2308.02409</link>
      <description>arXiv:2308.02409v2 Announce Type: replace 
Abstract: The human brain remains continuously active, whether an individual is working or at rest. Mental activity is a daily process, and if the brain becomes excessively active, known as overload, it can adversely affect human health. Recently, advancements in early prediction of mental health conditions have emerged, aiming to prevent serious consequences and enhance the overall quality of life. Consequently, the estimation of mental status has garnered significant attention from diverse researchers due to its potential benefits. While various signals are employed to assess mental state, the electroencephalogram, containing extensive information about the brain, is widely utilized by researchers. In this paper, we categorize mental workload into three states (low, middle, and high) and estimate a continuum of mental workload levels. Our method leverages information from multiple spatial dimensions to achieve optimal results in mental estimation. For the time domain approach, we employ Temporal Convolutional Networks. In the frequency domain, we introduce a novel architecture based on combining residual blocks, termed the Multi-Dimensional Residual Block. The integration of these two domains yields significant results compared to individual estimates in each domain. Our approach achieved a 74.98% accuracy in the three-class classification, surpassing the provided data results at 69.00%. Specially, our method demonstrates efficacy in estimating continuous levels, evidenced by a corresponding Concordance Correlation Coefficient (CCC) result of 0.629. The combination of time and frequency domain analysis in our approach highlights the exciting potential to improve healthcare applications in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.02409v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hong-Hai Nguyen, Ngumimi Karen Iyortsuun, Seungwon Kim, Hyung-Jeong Yang, Soo-Hyung Kim</dc:creator>
    </item>
    <item>
      <title>Companding and Predistortion Techniques for Improved Efficiency and Performance in SWIPT</title>
      <link>https://arxiv.org/abs/2308.06189</link>
      <description>arXiv:2308.06189v3 Announce Type: replace 
Abstract: In this work, we analyze how the use of companding techniques, together with digital predistortion (DPD), can be leveraged to improve system efficiency and performance in simultaneous wireless information and power transfer (SWIPT) systems based on power splitting. By taking advantage of the benefits of each of these well-known techniques to mitigate non-linear effects due to power amplifier (PA) and energy harvesting (EH) operation, we illustrate how DPD and companding can be effectively combined to improve the EH efficiency while keeping unalterable the information transfer performance. We establish design criteria that allow the PA to operate in a higher efficiency region so that the reduction in peak-to-average power ratio over the transmitted signal is translated into an increase in the average radiated power and EH efficiency. The performance of DPD and companding techniques is evaluated in a number of scenarios, showing that a combination of both techniques allows to significantly increase the power transfer efficiency in SWIPT systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.06189v3</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Santiago Fern\'andez-Ferrer, Francisco Javier L\'opez-Mart\'inez, Fernando H. Gregorio, Juan E. Cousseau</dc:creator>
    </item>
    <item>
      <title>A Novel Tree Model-based DNN to Achieve a High-Resolution DOA Estimation via Massive MIMO receive array</title>
      <link>https://arxiv.org/abs/2311.08758</link>
      <description>arXiv:2311.08758v4 Announce Type: replace 
Abstract: To satisfy the high-resolution requirements of direction-of-arrival (DOA) estimation, conventional deep neural network (DNN)-based methods using grid idea need to significantly increase the number of output classifications and also produce a huge high model complexity. To address this problem, a multi-level tree-based DNN model (TDNN) is proposed as an alternative, where each level takes small-scale multi-layer neural networks (MLNNs) as nodes to divide the target angular interval into multiple sub-intervals, and each output class is associated to a MLNN at the next level. Then the number of MLNNs is gradually increasing from the first level to the last level, and so increasing the depth of tree will dramatically raise the number of output classes to improve the estimation accuracy. More importantly, this network is extended to make a multi-emitter DOA estimation. Simulation results show that the proposed TDNN performs much better than conventional DNN and root-MUSIC at extremely low signal-to-noise ratio (SNR), and can achieve Cramer-Rao lower bound (CRLB). Additionally, in the multi-emitter scenario, the proposed Q-TDNN has also made a substantial performance enhancement over DNN and Root-MUSIC, and this gain grows as the number of emitters increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.08758v4</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yifan Li, Feng Shu, Jun Zou, Wei Gao, Yaoliang Song, Jiangzhou Wang</dc:creator>
    </item>
    <item>
      <title>A Non-Intrusive Neural Quality Assessment Model for Surface Electromyography Signals</title>
      <link>https://arxiv.org/abs/2402.05482</link>
      <description>arXiv:2402.05482v2 Announce Type: replace 
Abstract: In practical scenarios involving the measurement of surface electromyography (sEMG) in muscles, particularly those areas near the heart, one of the primary sources of contamination is the presence of electrocardiogram (ECG) signals. To assess the quality of real-world sEMG data more effectively, this study proposes QASE-net, a new non-intrusive model that predicts the SNR of sEMG signals. QASE-net combines CNN-BLSTM with attention mechanisms and follows an end-to-end training strategy. Our experimental framework utilizes real-world sEMG and ECG data from two open-access databases, the Non-Invasive Adaptive Prosthetics Database and the MIT-BIH Normal Sinus Rhythm Database, respectively. The experimental results demonstrate the superiority of QASE-net over the previous assessment model, exhibiting significantly reduced prediction errors and notably higher linear correlations with the ground truth. These findings show the potential of QASE-net to substantially enhance the reliability and precision of sEMG quality assessment in practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05482v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cho-Yuan Lee, Kuan-Chen Wang, Kai-Chun Liu, Xugang Lu, Ping-Cheng Yeh, Yu Tsao</dc:creator>
    </item>
    <item>
      <title>WiMANS: A Benchmark Dataset for WiFi-based Multi-user Activity Sensing</title>
      <link>https://arxiv.org/abs/2402.09430</link>
      <description>arXiv:2402.09430v2 Announce Type: replace 
Abstract: WiFi-based human sensing has exhibited remarkable potential to analyze user behaviors in a non-intrusive and device-free manner, benefiting applications as diverse as smart homes and healthcare. However, most previous works focus on single-user sensing, which has limited practicability in scenarios involving multiple users. Although recent studies have begun to investigate WiFi-based multi-user sensing, there remains a lack of benchmark datasets to facilitate reproducible and comparable research. To bridge this gap, we present WiMANS, to our knowledge, the first dataset for multi-user sensing based on WiFi. WiMANS contains over 9.4 hours of dual-band WiFi Channel State Information (CSI), as well as synchronized videos, monitoring simultaneous activities of multiple users. We exploit WiMANS to benchmark the performance of state-of-the-art WiFi-based human sensing models and video-based models, posing new challenges and opportunities for future work. We believe WiMANS can push the boundaries of current studies and catalyze the research on WiFi-based multi-user sensing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09430v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.MM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shuokang Huang, Kaihan Li, Di You, Yichong Chen, Arvin Lin, Siying Liu, Xiaohui Li, Julie A. McCann</dc:creator>
    </item>
    <item>
      <title>Progress in artificial intelligence applications based on the combination of self-driven sensors and deep learning</title>
      <link>https://arxiv.org/abs/2402.09442</link>
      <description>arXiv:2402.09442v3 Announce Type: replace 
Abstract: In the era of Internet of Things, how to develop a smart sensor system with sustainable power supply, easy deployment and flexible use has become a difficult problem to be solved. The traditional power supply has problems such as frequent replacement or charging when in use, which limits the development of wearable devices. The contact-to-separate friction nanogenerator (TENG) was prepared by using polychotomy thy lene (PTFE) and aluminum (AI) foils. Human motion energy was collected by human body arrangement, and human motion posture was monitored according to the changes of output electrical signals. In 2012, Academician Wang Zhong lin and his team invented the triboelectric nanogenerator (TENG), which uses Maxwell displacement current as a driving force to directly convert mechanical stimuli into electrical signals, so it can be used as a self-driven sensor. Teng-based sensors have the advantages of simple structure and high instantaneous power density, which provides an important means for building intelligent sensor systems. At the same time, machine learning, as a technology with low cost, short development cycle, strong data processing ability and prediction ability, has a significant effect on the processing of a large number of electrical signals generated by TENG, and the combination with TENG sensors will promote the rapid development of intelligent sensor networks in the future. Therefore, this paper is based on the intelligent sound monitoring and recognition system of TENG, which has good sound recognition capability, and aims to evaluate the feasibility of the sound perception module architecture in ubiquitous sensor networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09442v3</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weixiang Wan, Wenjian Sun, Qiang Zeng, Linying Pan, Jingyu Xu, Bo Liu</dc:creator>
    </item>
    <item>
      <title>LiDAR Point Cloud-based Multiple Vehicle Tracking with Probabilistic Measurement-Region Association</title>
      <link>https://arxiv.org/abs/2403.06423</link>
      <description>arXiv:2403.06423v2 Announce Type: replace 
Abstract: Multiple extended target tracking (ETT) has gained increasing attention due to the development of high-precision LiDAR and radar sensors in automotive applications. For LiDAR point cloud-based vehicle tracking, this paper presents a probabilistic measurement-region association (PMRA) ETT model, which can describe the complex measurement distribution by partitioning the target extent into different regions. The PMRA model overcomes the drawbacks of previous data-region association (DRA) models by eliminating the approximation error of constrained estimation and using continuous integrals to more reliably calculate the association probabilities. Furthermore, the PMRA model is integrated with the Poisson multi-Bernoulli mixture (PMBM) filter for tracking multiple vehicles. Simulation results illustrate the superior estimation accuracy of the proposed PMRA-PMBM filter in terms of both positions and extents of the vehicles comparing with PMBM filters using the gamma Gaussian inverse Wishart and DRA implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06423v2</guid>
      <category>eess.SP</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanhua Ding, Jianan Liu, Yuxuan Xia, Tao Huang, Bing Zhu, Jinping Sun</dc:creator>
    </item>
    <item>
      <title>Deep Joint Source Channel Coding With Attention Modules Over MIMO Channels</title>
      <link>https://arxiv.org/abs/2311.07041</link>
      <description>arXiv:2311.07041v2 Announce Type: replace-cross 
Abstract: In this paper, we propose two deep joint source and channel coding (DJSCC) structures with attention modules for the multi-input multi-output (MIMO) channel, including a serial structure and a parallel structure. With singular value decomposition (SVD)-based precoding scheme, the MIMO channel can be decomposed into various sub-channels, and the feature outputs will experience sub-channels with different channel qualities. In the serial structure, one single network is used at both the transmitter and the receiver to jointly process data streams of all MIMO subchannels, while data steams of different MIMO subchannels are processed independently via multiple sub-networks in the parallel structure. The attention modules in both serial and parallel architectures enable the system to adapt to varying channel qualities and adjust the quantity of information outputs in accordance with the channel qualities. Experimental results demonstrate the proposed DJSCC structures have improved image transmission performance, and reveal the phenomenon via non-parameter entropy estimation that the learned DJSCC transceivers tend to transmit more information over better sub-channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07041v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiran Jiang, Wei Chen, Bo Ai</dc:creator>
    </item>
    <item>
      <title>Multimodal Indoor Localization Using Crowdsourced Radio Maps</title>
      <link>https://arxiv.org/abs/2311.10601</link>
      <description>arXiv:2311.10601v2 Announce Type: replace-cross 
Abstract: Indoor Positioning Systems (IPS) traditionally rely on odometry and building infrastructures like WiFi, often supplemented by building floor plans for increased accuracy. However, the limitation of floor plans in terms of availability and timeliness of updates challenges their wide applicability. In contrast, the proliferation of smartphones and WiFi-enabled robots has made crowdsourced radio maps - databases pairing locations with their corresponding Received Signal Strengths (RSS) - increasingly accessible. These radio maps not only provide WiFi fingerprint-location pairs but encode movement regularities akin to the constraints imposed by floor plans. This work investigates the possibility of leveraging these radio maps as a substitute for floor plans in multimodal IPS. We introduce a new framework to address the challenges of radio map inaccuracies and sparse coverage. Our proposed system integrates an uncertainty-aware neural network model for WiFi localization and a bespoken Bayesian fusion technique for optimal fusion. Extensive evaluations on multiple real-world sites indicate a significant performance enhancement, with results showing ~ 25% improvement over the best baseline</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10601v2</guid>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoguang Yi, Xiangyu Wen, Qiyue Xia, Peize Li, Francisco Zampella, Firas Alsehly, Chris Xiaoxuan Lu</dc:creator>
    </item>
    <item>
      <title>Decoupled Data Consistency with Diffusion Purification for Image Restoration</title>
      <link>https://arxiv.org/abs/2403.06054</link>
      <description>arXiv:2403.06054v2 Announce Type: replace-cross 
Abstract: Diffusion models have recently gained traction as a powerful class of deep generative priors, excelling in a wide range of image restoration tasks due to their exceptional ability to model data distributions. To solve image restoration problems, many existing techniques achieve data consistency by incorporating additional likelihood gradient steps into the reverse sampling process of diffusion models. However, the additional gradient steps pose a challenge for real-world practical applications as they incur a large computational overhead, thereby increasing inference time. They also present additional difficulties when using accelerated diffusion model samplers, as the number of data consistency steps is limited by the number of reverse sampling steps. In this work, we propose a novel diffusion-based image restoration solver that addresses these issues by decoupling the reverse process from the data consistency steps. Our method involves alternating between a reconstruction phase to maintain data consistency and a refinement phase that enforces the prior via diffusion purification. Our approach demonstrates versatility, making it highly adaptable for efficient problem-solving in latent space. Additionally, it reduces the necessity for numerous sampling steps through the integration of consistency models. The efficacy of our approach is validated through comprehensive experiments across various image restoration tasks, including image denoising, deblurring, inpainting, and super-resolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06054v2</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiang Li, Soo Min Kwon, Ismail R. Alkhouri, Saiprasad Ravishanka, Qing Qu</dc:creator>
    </item>
  </channel>
</rss>
