<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Mar 2025 02:15:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Offset Finding of Beamline Parameters on the METRIXS Beamline at BESSY II Using Machine Learning</title>
      <link>https://arxiv.org/abs/2503.17396</link>
      <description>arXiv:2503.17396v1 Announce Type: cross 
Abstract: Beamline alignment is challenging as the beamline components must be set up ideally so that the rays follow the desired optical path. Automated methods using a digital twin allow for faster diagnostics and improved beam properties compared to manual tuning. We introduce an automated method of finding the offsets to improve this digital twin model. These offsets represent the unknown but constant differences between the beamline parameter positions as set up at the physical beamline and the corresponding parameter positions of its digital twin. Our method assumes the capability to execute precise relative movements with a known step size for these parameters, although the absolute position information is unknown. By combining the surrogate model with a global optimizer, we successfully determine offsets for 34 beamline parameters on a simulated METRIXS beamline at the BESSY II synchrotron radiation source in Berlin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17396v1</guid>
      <category>physics.acc-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David Meier, Thomas Zeschke, Peter Feuer-Forson, Bernhard Sick, Jens Viefhaus, Gregor Hartmann</dc:creator>
    </item>
    <item>
      <title>Deep learning-based identification of precipitation clouds from all-sky camera data for observatory safety</title>
      <link>https://arxiv.org/abs/2503.18670</link>
      <description>arXiv:2503.18670v1 Announce Type: cross 
Abstract: For monitoring the night sky conditions, wide-angle all-sky cameras are used in most astronomical observatories to monitor the sky cloudiness. In this manuscript, we apply a deep-learning approach for automating the identification of precipitation clouds in all-sky camera data as a cloud warning system. We construct our original training and test sets using the all-sky camera image archive of the Iranian National Observatory (INO). The training and test set images are labeled manually based on their potential rainfall and their distribution in the sky. We train our model on a set of roughly 2445 images taken by the INO all-sky camera through the deep learning method based on the EfficientNet network. Our model reaches an average accuracy of 99\% in determining the cloud rainfall's potential and an accuracy of 96\% for cloud coverage. To enable a comprehensive comparison and evaluate the performance of alternative architectures for the task, we additionally trained three models LeNet, DeiT, and AlexNet. This approach can be used for early warning of incoming dangerous clouds toward telescopes and harnesses the power of deep learning to automatically analyze vast amounts of all-sky camera data and accurately identify precipitation clouds formations. Our trained model can be deployed for real-time analysis, enabling the rapid identification of potential threats, and offering a scaleable solution that can improve our ability to safeguard telescopes and instruments in observatories. This is important now that numerous small and medium-sized telescopes are increasingly integrated with smart control systems to reduce manual operation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18670v1</guid>
      <category>astro-ph.IM</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.mlwa.2025.100640</arxiv:DOI>
      <arxiv:journal_reference>Machine Learning with Applications Volume 20, June 2025, 100640</arxiv:journal_reference>
      <dc:creator>Mohammad H. Zhoolideh Haghighi, Alireza Ghasrimanesh, Habib Khosroshahi</dc:creator>
    </item>
    <item>
      <title>Local wind speed forecasting at short time horizons relying on both Numerical Weather Prediction and observations from surrounding station</title>
      <link>https://arxiv.org/abs/2503.18797</link>
      <description>arXiv:2503.18797v1 Announce Type: cross 
Abstract: This study presents a hybrid neural network model for short-term (1-6 hours ahead) surface wind speed forecasting, combining Numerical Weather Prediction (NWP) with observational data from ground weather stations. It relies on the MeteoNet dataset, which includes data from global (ARPEGE) and regional (AROME) NWP models of the French weather service and meteorological observations from ground stations in the French Mediterranean. The proposed neural network architecture integrates recent past station observations (over last few hours) and AROME and ARPEGE predictions on a small subgrid around the target location. The model is designed to provide both deterministic and probabilistic forecasts, with the latter predicting the parameters of a suitable probability distribution that notably allows us to capture extreme wind events. Our results demonstrate that the hybrid model significantly outperforms baseline methods, including raw NWP predictions, persistence models, and linear regression, across all forecast horizons. For instance, the model reduces RMSE by up 30\% compared to AROME predictions. Probabilistic forecasting further enhances performance, particularly for extreme quantiles, by estimating conditional quantiles rather than relying solely on the conditional mean. Fine-tuning the model for specific stations, such as those in the Mediterranean island of Corsica, further improves forecasting accuracy. Our study highlights the importance of integrating multiple data sources and probabilistic approaches to improve short-term wind speed forecasting. It defines an effective approach, even in a complex terrain like Corsica where localized wind variations are significant</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18797v1</guid>
      <category>physics.ao-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberta Baggio, Killian Pujol, Florian Pantillon, Dominique Lambert, Jean-Baptiste Filippi, Jean-Fran\c{c}ois Muzy</dc:creator>
    </item>
    <item>
      <title>Bounds on the rates of statistical divergences and mutual information via stochastic thermodynamics</title>
      <link>https://arxiv.org/abs/2308.05597</link>
      <description>arXiv:2308.05597v3 Announce Type: replace 
Abstract: Statistical divergences are important tools in data analysis, information theory, and statistical physics, and there exist well known inequalities on their bounds. However, in many circumstances involving temporal evolution, one needs limitations on the rates of such quantities, instead. Here, several general upper bounds on the rates of some f-divergences are derived, valid for any type of stochastic dynamics (both Markovian and non-Markovian), in terms of information-like and/or thermodynamic observables. As special cases, the analytical bounds on the rate of mutual information are obtained. The major role in all those limitations is played by temporal Fisher information, characterizing the speed of global system dynamics, and some of them contain entropy production, suggesting a link with stochastic thermodynamics. Indeed, the derived inequalities can be used for estimation of minimal dissipation and global speed in thermodynamic stochastic systems. Specific applications of these inequalities in physics and neuroscience are given, which include the bounds on the rates of free energy and work in nonequilibrium systems, limits on the speed of information gain in learning synapses, as well as the bounds on the speed of predictive inference and learning rate. Overall, the derived bounds can be applied to any complex network of interacting elements, where predictability and thermodynamics of network dynamics are of prime concern.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.05597v3</guid>
      <category>physics.data-an</category>
      <category>cond-mat.stat-mech</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevE.109.054126</arxiv:DOI>
      <arxiv:journal_reference>Physical Review E 109, 054126 (2024)</arxiv:journal_reference>
      <dc:creator>Jan Karbowski</dc:creator>
    </item>
    <item>
      <title>Error evaluation of partial scattering functions obtained from contrast variation small-angle neutron scattering</title>
      <link>https://arxiv.org/abs/2406.00311</link>
      <description>arXiv:2406.00311v2 Announce Type: replace-cross 
Abstract: Contrast variation small-angle neutron scattering (CV-SANS) is a powerful tool to evaluate the structure of multi-component systems by decomposing scattering intensities $I$ measured with different scattering contrasts into partial scattering functions $S$ of self- and cross-correlations between components. The measured $I$ contains a measurement error, $\Delta I$, and $\Delta I$ results in an uncertainty of partial scattering functions, $\Delta S$. However, the error propagation from $\Delta I$ to $\Delta S$ has not been quantitatively clarified. In this work, we have established deterministic and statistical approaches to determine $\Delta S$ from $\Delta I$. We have applied the two methods to (i) computational data of a core-shell sphere and experimental CV-SANS data of (ii) clay/polyethylene glycol (PEG) aqueous solutions and (iii) polyrotaxane solutions, and have successfully estimated the errors of \(S\). The quantitative error estimation of \(S\) offers us a strategy to optimize the combination of scattering contrasts to minimize error propagation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00311v2</guid>
      <category>cond-mat.soft</category>
      <category>physics.chem-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koichi Mayumi, Tatsuro Oda, Shinya Miyajima, Ippei Obayashi, Kazuaki Tanaka</dc:creator>
    </item>
    <item>
      <title>Universal emergence of local Zipf's law</title>
      <link>https://arxiv.org/abs/2407.15946</link>
      <description>arXiv:2407.15946v2 Announce Type: replace-cross 
Abstract: A plethora of natural and socio-economic phenomena share a striking statistical regularity, that is the magnitude of elements decreases with a power law as a function of their position in a ranking of magnitude. Such regularity is known as Zipf-Mandelbrot law (ZM), and plenty of problem-specific explanations for its emergence have been provided in different fields. Yet, an explanation for ZM ubiquity is currently lacking. In this paper we first provide an analytical expression for the cumulants of any ranked sample of i.i.d. random variables once sorted in decreasing order. Then we make use of this result to rigorously demonstrate that, whenever a small fraction of such ranked dataset is considered, it becomes statistically indistinguishable from a ZM law. We finally validate our results against several relevant examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15946v2</guid>
      <category>physics.soc-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Cugini, Andr\'e Timpanaro, Giacomo Livan, Giacomo Guarnieri</dc:creator>
    </item>
    <item>
      <title>Analysis of the inference of ratings and rankings in complex networks using discrete exterior calculus on higher--order networks</title>
      <link>https://arxiv.org/abs/2411.02434</link>
      <description>arXiv:2411.02434v2 Announce Type: replace-cross 
Abstract: The inference of rankings plays a central role in the theory of social choice, which seeks to establish preferences from collectively generated data, such as pairwise comparisons. Examples include political elections, ranking athletes based on competition results, ordering web pages in search engines using hyperlink networks, and generating recommendations in online stores based on user behavior. Various methods have been developed to infer rankings from incomplete or conflicting data. One such method, HodgeRank, introduced by Jiang {\em et al.}~[Math. Program. {\bf 127}, 203 (2011)], utilizes Hodge decomposition of cochains in higher--order networks to disentangle gradient and cyclical components contributing to rating scores, enabling a parsimonious inference of ratings and rankings for lists of items. This paper presents a systematic study of HodgeRank's performance under the influence of quenched disorder and across networks with complex topologies generated by four different network models. The results reveal a transition from a regime of perfect retrieval of true rankings to one of imperfect retrieval as the strength of the quenched disorder increases. A range of observables are analyzed, and their scaling behavior with respect to the network model parameters is characterized. This work advances the understanding of social choice theory and the inference of ratings and rankings within complex network structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02434v2</guid>
      <category>cs.SI</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevE.111.034306</arxiv:DOI>
      <dc:creator>Juan Ignacio Perotti</dc:creator>
    </item>
    <item>
      <title>Inconsistency and Acausality in Bayesian Inference for Physical Problems</title>
      <link>https://arxiv.org/abs/2411.13570</link>
      <description>arXiv:2411.13570v2 Announce Type: replace-cross 
Abstract: Bayesian inference is used to estimate continuous parameter values given measured data in many fields of science. The method relies on conditional probability densities to describe information about both data and parameters, yet the notion of conditional densities is inadmissible: probabilities of the same physical event, computed from conditional densities under different parameterizations, may be inconsistent. We show that this inconsistency, together with acausality in hierarchical methods, invalidate a variety of commonly applied Bayesian methods when applied to problems in the physical world, including trans-dimensional inference, general Bayesian dimensionality reduction methods, and hierarchical and empirical Bayes. Models in parameter spaces of different dimensionalities cannot be compared, invalidating the concept of natural parsimony, the probabilistic counterpart to Occams Razor. Bayes theorem itself is inadmissible, and Bayesian inference applied to parameters that characterize physical properties requires reformulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13570v2</guid>
      <category>stat.ME</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Klaus Mosegaard, Andrew Curtis</dc:creator>
    </item>
    <item>
      <title>Fine-tuning machine-learned particle-flow reconstruction for new detector geometries in future colliders</title>
      <link>https://arxiv.org/abs/2503.00131</link>
      <description>arXiv:2503.00131v2 Announce Type: replace-cross 
Abstract: We demonstrate transfer learning capabilities in a machine-learned algorithm trained for particle-flow reconstruction in high energy particle colliders. This paper presents a cross-detector fine-tuning study, where we initially pre-train the model on a large full simulation dataset from one detector design, and subsequently fine-tune the model on a sample with a different collider and detector design. Specifically, we use the Compact Linear Collider detector (CLICdet) model for the initial training set, and demonstrate successful knowledge transfer to the CLIC-like detector (CLD) proposed for the Future Circular Collider in electron-positron mode (FCC-ee). We show that with an order of magnitude less samples from the second dataset, we can achieve the same performance as a costly training from scratch, across particle-level and event-level performance metrics, including jet and missing transverse momentum resolution. Furthermore, we find that the fine-tuned model achieves comparable performance to the traditional rule-based particle-flow approach on event-level metrics after training on 100,000 CLD events, whereas a model trained from scratch requires at least 1 million CLD events to achieve similar reconstruction performance. To our knowledge, this represents the first full-simulation cross-detector transfer learning study for particle-flow reconstruction. These findings offer valuable insights towards building large foundation models that can be fine-tuned across different detector designs and geometries, helping to accelerate the development cycle for new detectors and opening the door to rapid detector design and optimization using machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00131v2</guid>
      <category>hep-ex</category>
      <category>cs.LG</category>
      <category>hep-ph</category>
      <category>physics.data-an</category>
      <category>physics.ins-det</category>
      <pubDate>Tue, 25 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Farouk Mokhtar, Joosep Pata, Dolores Garcia, Eric Wulff, Mengke Zhang, Michael Kagan, Javier Duarte</dc:creator>
    </item>
  </channel>
</rss>
