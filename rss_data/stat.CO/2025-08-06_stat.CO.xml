<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 06 Aug 2025 04:01:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Precision Profile Weighted Deming Regression for Methods Comparison</title>
      <link>https://arxiv.org/abs/2508.02888</link>
      <description>arXiv:2508.02888v1 Announce Type: new 
Abstract: Errors in variables (Deming) regression of measurements spanning a wide range of values requires appropriate weighting to reflect nonconstant variance. Precision profile models, mathematical relationships between measurement variance and mean, are a route to these weights. The paper describes a methodology combining general precision profile models with Deming regression and described R routines for the resulting calculations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02888v1</guid>
      <category>stat.CO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Douglas M Hawkins, Jessica J Kraker</dc:creator>
    </item>
    <item>
      <title>Polynomial complexity sampling from multimodal distributions using Sequential Monte Carlo</title>
      <link>https://arxiv.org/abs/2508.02763</link>
      <description>arXiv:2508.02763v1 Announce Type: cross 
Abstract: We study a sequential Monte Carlo algorithm to sample from the Gibbs measure with a non-convex energy function at a low temperature. We use the practical and popular geometric annealing schedule, and use a Langevin diffusion at each temperature level. The Langevin diffusion only needs to run for a time that is long enough to ensure local mixing within energy valleys, which is much shorter than the time required for global mixing. Our main result shows convergence of Monte Carlo estimators with time complexity that, approximately, scales like the forth power of the inverse temperature, and the square of the inverse allowed error. We also study this algorithm in an illustrative model scenario where more explicit estimates can be given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02763v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiyu Han, Gautam Iyer, Dejan Slep\v{c}ev</dc:creator>
    </item>
    <item>
      <title>LLM-based IR-system for Bank Supervisors</title>
      <link>https://arxiv.org/abs/2508.02945</link>
      <description>arXiv:2508.02945v1 Announce Type: cross 
Abstract: Bank supervisors face the complex task of ensuring that new measures are consistently aligned with historical precedents. To address this challenge, we introduce a novel Information Retrieval (IR) System tailored to assist supervisors in drafting both consistent and effective measures. This system ingests findings from on-site investigations. It then retrieves the most relevant historical findings and their associated measures from a comprehensive database, providing a solid basis for supervisors to write well-informed measures for new findings. Utilizing a blend of lexical, semantic, and Capital Requirements Regulation (CRR) fuzzy set matching techniques, the IR system ensures the retrieval of findings that closely align with current cases. The performance of this system, particularly in scenarios with partially labeled data, is validated through a Monte Carlo methodology, showcasing its robustness and accuracy. Enhanced by a Transformer-based Denoising AutoEncoder for fine-tuning, the final model achieves a Mean Average Precision (MAP@100) of 0.83 and a Mean Reciprocal Rank (MRR@100) of 0.92. These scores surpass those of both standalone lexical models such as BM25 and semantic BERT-like models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02945v1</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.knosys.2024.112914</arxiv:DOI>
      <arxiv:journal_reference>Journal-ref: Knowledge-Based Systems 310 (2025) 112914</arxiv:journal_reference>
      <dc:creator>Ilias Aarab</dc:creator>
    </item>
    <item>
      <title>Injecting Measurement Information Yields a Fast and Noise-Robust Diffusion-Based Inverse Problem Solver</title>
      <link>https://arxiv.org/abs/2508.02964</link>
      <description>arXiv:2508.02964v1 Announce Type: cross 
Abstract: Diffusion models have been firmly established as principled zero-shot solvers for linear and nonlinear inverse problems, owing to their powerful image prior and iterative sampling algorithm. These approaches often rely on Tweedie's formula, which relates the diffusion variate $\mathbf{x}_t$ to the posterior mean $\mathbb{E} [\mathbf{x}_0 | \mathbf{x}_t]$, in order to guide the diffusion trajectory with an estimate of the final denoised sample $\mathbf{x}_0$. However, this does not consider information from the measurement $\mathbf{y}$, which must then be integrated downstream. In this work, we propose to estimate the conditional posterior mean $\mathbb{E} [\mathbf{x}_0 | \mathbf{x}_t, \mathbf{y}]$, which can be formulated as the solution to a lightweight, single-parameter maximum likelihood estimation problem. The resulting prediction can be integrated into any standard sampler, resulting in a fast and memory-efficient inverse solver. Our optimizer is amenable to a noise-aware likelihood-based stopping criteria that is robust to measurement noise in $\mathbf{y}$. We demonstrate comparable or improved performance against a wide selection of contemporary inverse solvers across multiple datasets and tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02964v1</guid>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Patsenker, Henry Li, Myeongseob Ko, Ruoxi Jia, Yuval Kluger</dc:creator>
    </item>
    <item>
      <title>Stereographic Multi-Try Metropolis Algorithms for Heavy-tailed Sampling</title>
      <link>https://arxiv.org/abs/2505.12487</link>
      <description>arXiv:2505.12487v2 Announce Type: replace 
Abstract: Markov chain Monte Carlo (MCMC) methods for sampling from heavy-tailed distributions present unique challenges, particularly in high dimensions. Multi-proposal MCMC algorithms have recently gained attention for their potential to improve performance, especially through parallel implementation on modern hardware. This paper introduces a novel family of gradient-free MCMC algorithms that combine the multi-try Metropolis (MTM) with stereographic MCMC framework, specifically designed for efficient sampling from heavy-tailed targets. The proposed stereographic multi-try Metropolis (SMTM) algorithm not only outperforms traditional Euclidean MTM and existing stereographic random-walk Metropolis methods, but also avoids the pathological convergence behavior often observed in MTM and demonstrates strong robustness to tuning. These properties are supported by scaling analysis and extensive simulation studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12487v2</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhihao Wang, Jun Yang</dc:creator>
    </item>
    <item>
      <title>A Hybrid Mixture of $t$-Factor Analyzers for Clustering High-dimensional Data</title>
      <link>https://arxiv.org/abs/2504.21120</link>
      <description>arXiv:2504.21120v2 Announce Type: replace-cross 
Abstract: This paper develops a novel hybrid approach for estimating the mixture model of $t$-factor analyzers (MtFA) that employs multivariate $t$-distribution and factor model to cluster and characterize grouped data. The traditional estimation method for MtFA faces computational challenges, particularly in high-dimensional settings, where the eigendecomposition of large covariance matrices and the iterative nature of Expectation-Maximization (EM) algorithms lead to scalability issues. We propose a computational scheme that integrates a profile likelihood method into the EM framework to efficiently obtain the model parameter estimates. The effectiveness of our approach is demonstrated through simulations showcasing its superior computational efficiency compared to the existing method, while preserving clustering accuracy and resilience against outliers. Our method is applied to cluster the Gamma-ray bursts, reinforcing several claims in the literature that Gamma-ray bursts have heterogeneous subpopulations and providing characterizations of the estimated groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21120v2</guid>
      <category>stat.ME</category>
      <category>astro-ph.HE</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kazeem Kareem, Fan Dai</dc:creator>
    </item>
    <item>
      <title>Filtrated Kinematic Connectivity Analysis for Lower-limb Joint Effective Age Evaluation</title>
      <link>https://arxiv.org/abs/2506.11369</link>
      <description>arXiv:2506.11369v3 Announce Type: replace-cross 
Abstract: To understand and communicate the risk of chronic lower-limb joint diseases associated with aging, it is crucial to investigate the relationship between age and gait dynamics, particularly through angular kinematics. One key challenge is that angular kinematic trajectories are highly interconnected, and the structures of the interconnections vary across different components. Neglecting the interconnections and the variability in the connectivity structures impairs the understanding of age-associated gait coordination. To this end, we develop a novel kinematic connectivity analysis framework, grounded in multiple functional regression, to evaluate lower-limb joint effective age and uncover age-related kinematic features. The proposed approach is built upon the concept of filtration, a widely used tool in network analysis and topological data analysis for multi-resolution exploration. Specifically, we develop a forest-structured covariate grouping framework in which different kinematic trajectories are aggregated hierarchically to capture both (partially) shared and idiosyncratic motion signatures which are strongly associated with aging. We also develop a novel filtrated functional partial least squares approach for model estimation and feature extraction. Compared to existing approaches, our proposed approach demonstrates superior predictive power while providing novel insights into the coordinated evolution of angular kinematics during aging. In addition, the proposed framework is broadly applicable and can be readily extended in other scientific domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11369v3</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuhao Jiao, Hernando Ombao, Ian W. McKeague</dc:creator>
    </item>
  </channel>
</rss>
