<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>astro-ph.IM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/astro-ph.IM</link>
    <description>astro-ph.IM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/astro-ph.IM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Jul 2024 01:45:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An efficient pipeline for joint gravitational wave searches from individual binaries and a gravitational wave background with Hamiltonian sampling</title>
      <link>https://arxiv.org/abs/2407.11135</link>
      <description>arXiv:2407.11135v1 Announce Type: new 
Abstract: The pulsar timing array community has recently reported the first evidence of a low-frequency stochastic gravitational wave background. With longer observational timespans we expect to be able to resolve individual gravitational wave sources in our data alongside the background signal. The statistical modeling and Bayesian searches for such individual signals is a computationally taxing task that is the focus of many different avenues of methods development. We present a pipeline for performing efficient joint searches for gravitational waves originating from individual supermassive black hole binaries as well as a gravitational wave background using a Hamiltonian Monte Carlo sampling scheme. Hamiltonian sampling proposes samples based on the gradients of the model likelihood, and can both converge faster to more complicated and high-dimensional distributions as well as efficiently explore highly covariant parameter spaces such as the joint gravitational wave background and individual binary model. We show the effectiveness of our scheme by demonstrating accurate parameter estimation for simulated datasets containing low- (6 nHz) or high- (60 nHz) frequency binary sources. Additionally we show that our method is capable at more efficiently generating skymaps for individual binary sources -- maps displaying the upper limits on the gravitational wave strain of the source, $h_{0}$, as a function of sky location -- by sampling over larger portions of the full sky. Comparing against results for the NANOGrav 12.5-year dataset, we find similar reconstructed upper limits on the gravitational wave strain while simultaneously reducing the number of required analyses from 72 independent binned searches down to a single run.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11135v1</guid>
      <category>astro-ph.IM</category>
      <category>gr-qc</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel E. Freedman, Sarah J. Vigeland</dc:creator>
    </item>
    <item>
      <title>The future looks dark: improving high contrast imaging with hyper-parameter optimization for data-driven predictive wavefront control</title>
      <link>https://arxiv.org/abs/2407.11187</link>
      <description>arXiv:2407.11187v1 Announce Type: new 
Abstract: The direct imaging and characterization of exoplanets requires extreme adaptive optics (XAO), achieving exquisite wavefront correction (upwards of 90$\%$ Strehl) over a narrow field of view (a few arcseconds). For these XAO systems the temporal error is often a leading term in the error budget, wherein the wavefront evolves faster than the lag between wavefront sensing and control. For atmospheres with high-velocity wind layers, this can result in a wind-driven halo in the coronagraphic dark-zone, limiting sensitivity to faint, close-in companions. The AO system's lag-time is often limited by the wavefront sensor exposure time, especially in the case of fainter guidestars. Predictive control mitigates the temporal error by predicting the shape of the wavefront by time the system correction is applied. One such method of prediction is empirical orthogonal functions (EOF), wherein previous states in the wavefront sensor history are used to learn linear correlations with a minimization problem. This method has been demonstrated on-sky at Subaru/SCExAO and Keck/NIRC2, but has yet to be optimized. With this work as a starting point, we explore the optimal filter hyper-parameter space for implementing EOF on-sky, study its stability under varying atmospheric parameters, and discuss future paths for facilitization of predictive control. This work not only offers a pathway to optimize Keck and Subaru observing, but also acts as a pathfinder for predictive control methods with extremely large telescopes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11187v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.EP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. Fowler, Rebecca Jensen-Clem, Maaike A. M. van Kooten, Vincent Chambouleyron, Sylvain Cetre</dc:creator>
    </item>
    <item>
      <title>AstroMLab 1: Who Wins Astronomy Jeopardy!?</title>
      <link>https://arxiv.org/abs/2407.11194</link>
      <description>arXiv:2407.11194v1 Announce Type: new 
Abstract: We present a comprehensive evaluation of proprietary and open-weights large language models using the first astronomy-specific benchmarking dataset. This dataset comprises 4,425 multiple-choice questions curated from the Annual Review of Astronomy and Astrophysics, covering a broad range of astrophysical topics. Our analysis examines model performance across various astronomical subfields and assesses response calibration, crucial for potential deployment in research environments. Claude-3.5-Sonnet outperforms competitors by up to 4.6 percentage points, achieving 85.0% accuracy. For proprietary models, we observed a universal reduction in cost every 3-to-12 months to achieve similar score in this particular astronomy benchmark. Open-source models have rapidly improved, with LLaMA-3-70b (80.6%) and Qwen-2-72b (77.7%) now competing with some of the best proprietary models. We identify performance variations across topics, with non-English-focused models generally struggling more in exoplanet-related fields, stellar astrophysics, and instrumentation related questions. These challenges likely stem from less abundant training data, limited historical context, and rapid recent developments in these areas. This pattern is observed across both open-weights and proprietary models, with regional dependencies evident, highlighting the impact of training data diversity on model performance in specialized scientific domains. Top-performing models demonstrate well-calibrated confidence, with correlations above 0.9 between confidence and correctness, though they tend to be slightly underconfident. The development for fast, low-cost inference of open-weights models presents new opportunities for affordable deployment in astronomy. The rapid progress observed suggests that LLM-driven research in astronomy may become feasible in the near future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11194v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.EP</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.SR</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuan-Sen Ting, Tuan Dung Nguyen, Tirthankar Ghosal, Rui Pan, Hardik Arora, Zechang Sun, Tijmen de Haan, Nesar Ramachandra, Azton Wells, Sandeep Madireddy, Alberto Accomazzi</dc:creator>
    </item>
    <item>
      <title>In-lab and On-sky Closed-loop Results of Adaptive Secondary Mirrors with TNO's Hybrid Variable Reluctance Actuators</title>
      <link>https://arxiv.org/abs/2407.11289</link>
      <description>arXiv:2407.11289v1 Announce Type: new 
Abstract: We performed closed-loop lab testing of large-format deformable mirrors (DMs) with hybrid variable reluctance actuators. TNO has been developing the hybrid variable reluctance actuators in support for a new generation of adaptive secondary mirrors (ASMs), which aim to be more robust and reliable. Compared to the voice coil actuators, this new actuator technology has a higher current to force efficiency, and thus can support DMs with thicker facesheets. Before putting this new technology on-sky, it is necessary to understand how to control it and how it behaves in closed-loop. We performed closed-loop tests with the Shack-Hartmann wavefront sensor with three large-format deformable mirrors that use the TNO actuators: DM3, FLASH, and IRTF-ASM-1 ASM. The wavefront sensor and the real-time control systems were developed for the NASA Infrared Telescope Facility (IRTF) and the UH 2.2-meter telescope ASMs. We tested IRTF-ASM-1 on-sky and proved that it meets all of our performance requirements. This work presents our lab setup for the experiments, the techniques we have employed to drive these new ASMs, the results of our closed-loop lab tests for FLASH and IRTF-ASM-1, and the on-sky closed-loop results of IRTF-ASM-1 ASM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11289v1</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruihan Zhang, Max Baeten, Mark R. Chun, Ellen Lee, Michael Connelley, Olivier Lai, Stefan Kuiper, Alan Ryan, Arjo Bos, Rachel Bowens-Rubin, Philip M. Hinz</dc:creator>
    </item>
    <item>
      <title>X-ray Sources Classification Using Machine Learning: A Study with EP-WXT Pathfinder LEIA</title>
      <link>https://arxiv.org/abs/2407.11462</link>
      <description>arXiv:2407.11462v1 Announce Type: new 
Abstract: X-ray observations play a crucial role in time-domain astronomy. The Einstein Probe (EP), a recently launched X-ray astronomical satellite, emerges as a forefront player in the field of time-domain astronomy and high-energy astrophysics. With a focus on systematic surveys in the soft X-ray band, EP aims to discover high-energy transients and monitor variable sources in the universe. To achieve these objectives, a quick and reliable classification of observed sources is essential. In this study, we developed a machine learning classifier for autonomous source classification using data from the EP-WXT Pathfinder Lobster Eye Imager for Astronomy (LEIA) and EP-WXT simulations. The proposed Random Forest classifier, built on selected features derived from light curves, energy spectra, and location information, achieves an accuracy of approximately 95% on EP simulation data and 98% on LEIA observational data. The classifier is integrated into the LEIA data processing pipeline, serving as a tool for manual validation and rapid classification during observations. This paper presents an efficient method for the classification of X-ray sources based on single observations, along with implications of most effective features for the task. This work facilitates rapid source classification for the EP mission and also provides valuable insights into feature selection and classification techniques for enhancing the efficiency and accuracy of X-ray source classification that can be adapted to other X-ray telescope data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11462v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1088/1674-4527/ad634f</arxiv:DOI>
      <dc:creator>Xiaoxiong Zuo, Yihan Tao, Yuan Liu, Yunfei Xu, Wenda Zhang, Haiwu Pan, Hui Sun, Zhen Zhang, Chenzhou Cui, Weimin Yuan</dc:creator>
    </item>
    <item>
      <title>PECCARY: A novel approach for characterizing orbital complexity, stochasticity, and regularity</title>
      <link>https://arxiv.org/abs/2407.11970</link>
      <description>arXiv:2407.11970v1 Announce Type: new 
Abstract: Permutation Entropy and statistiCal Complexity Analysis for astRophysics (PECCARY) is a computationally inexpensive, statistical method by which any time-series can be characterized as predominately regular, complex, or stochastic. Elements of the PECCARY method have been used in a variety of physical, biological, economic, and mathematical scenarios, but have not yet gained traction in the astrophysical community. This study introduces the PECCARY technique with the specific aims to motivate its use in and optimize it for the analysis of astrophysical orbital systems. PECCARY works by decomposing a time-dependent measure, such as the x-coordinate or orbital angular momentum time-series, into ordinal patterns. Due to its unique approach and statistical nature, PECCARY is well-suited for detecting preferred and forbidden patterns (a signature of chaos), even when the chaotic behavior is short-lived or when working with a relatively short duration time-series or small sets of time-series data. A variety of examples are used to demonstrate the capabilities of PECCARY. These include mathematical examples (sine waves, varieties of noise, sums of sine waves, well-known chaotic functions), a double pendulum system, and astrophysical tracer particle simulations with potentials of varying intricacies. Since the adopted timescale used to diagnose a given time-series can affect the outcome, a method is presented to identify an ideal sampling scheme, constrained by the overall duration and the natural timescale of the system. The accompanying PECCARY Python package and its usage are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11970v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.GA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\'oley \'O. Hyman, Kathryne J. Daniel, David A. Schaffner</dc:creator>
    </item>
    <item>
      <title>Precise and Efficient Orbit Prediction in LEO with Machine Learning using Exogenous Variables</title>
      <link>https://arxiv.org/abs/2407.11026</link>
      <description>arXiv:2407.11026v1 Announce Type: cross 
Abstract: The increasing volume of space objects in Earth's orbit presents a significant challenge for Space Situational Awareness (SSA). And in particular, accurate orbit prediction is crucial to anticipate the position and velocity of space objects, for collision avoidance and space debris mitigation. When performing Orbit Prediction (OP), it is necessary to consider the impact of non-conservative forces, such as atmospheric drag and gravitational perturbations, that contribute to uncertainty around the future position of spacecraft and space debris alike. Conventional propagator methods like the SGP4 inadequately account for these forces, while numerical propagators are able to model the forces at a high computational cost. To address these limitations, we propose an orbit prediction algorithm utilizing machine learning. This algorithm forecasts state vectors on a spacecraft using past positions and environmental variables like atmospheric density from external sources. The orbital data used in the paper is gathered from precision ephemeris data from the International Laser Ranging Service (ILRS), for the period of almost a year. We show how the use of machine learning and time-series techniques can produce low positioning errors at a very low computational cost, thus significantly improving SSA capabilities by providing faster and reliable orbit determination for an ever increasing number of space objects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11026v1</guid>
      <category>cs.LG</category>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>cs.AI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Francisco Caldas, Cl\'audia Soares</dc:creator>
    </item>
    <item>
      <title>Neutron stars and the dense matter equation of state: from microscopic theory to macroscopic observations</title>
      <link>https://arxiv.org/abs/2407.11153</link>
      <description>arXiv:2407.11153v1 Announce Type: cross 
Abstract: The past years have witnessed tremendous progress in understanding the properties of neutron stars and of the dense matter in their cores, made possible by electromagnetic observations of neutron stars and the detection of gravitational waves from their mergers. These observations provided novel constraints on neutron-star structure, that is intimately related to the properties of dense neutron-rich matter described by the nuclear equation of state. Nevertheless, constraining the equation of state over the wide range of densities probed by astrophysical observations is still challenging, as the physics involved is very broad and the system spans many orders of magnitude in densities. Here, we review theoretical approaches to calculate and model the neutron-star equation of state in various regimes of densities, and discuss the related consequent properties of neutron stars. We describe how the equation of state can be calculated from nuclear interactions that are constrained and benchmarked by nuclear experiments. We review neutron-star observations, with particular emphasis on information provided by gravitational-wave signals and electromagnetic observations. Finally, we discuss future challenges and opportunities in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11153v1</guid>
      <category>nucl-th</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Katerina Chatziioannou, H. Thankful Cromartie, Stefano Gandolfi, Ingo Tews, David Radice, Andrew W. Steiner, Anna L. Watts</dc:creator>
    </item>
    <item>
      <title>End-to-end simulations of photonic phase correctors for adaptive optics systems</title>
      <link>https://arxiv.org/abs/2407.11171</link>
      <description>arXiv:2407.11171v1 Announce Type: cross 
Abstract: Optical beams and starlight distorted by atmospheric turbulence can be corrected with adaptive optics systems to enable efficient coupling into single-mode fibers. Deformable mirrors, used to flatten the wavefront in astronomical telescopes, are costly, sensitive, and complex mechanical components that require careful calibration to enable high-quality imaging in astronomy, microscopy, and vision science. They are also impractical to deploy in large numbers for non-imaging applications like free-space optical communication. Here, we propose a photonic integrated c rcuit capable of spatially sampling the wavefront collected by the telescope and co-phasing the subapertures to maximize the flux delivered to an output single-mode fiber as the integrated photonic implementation of a deformable mirror. We present the results of end-to-end simulations to quantify the performance of the proposed photonic solution under varying atmospheric conditions toward realizing an adaptive optics system without a deformable mirror for free-space optical receivers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11171v1</guid>
      <category>physics.optics</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1364/OE.530879</arxiv:DOI>
      <dc:creator>Dhwanil Patel (Dunlap Institute for Astronomy and Astrophysics, University of Toronto, Toronto, Ontario, Canada), Momen Diab (Dunlap Institute for Astronomy and Astrophysics, University of Toronto, Toronto, Ontario, Canada), Ross Cheriton (Quantum and Nanotechnologies Research Centre, National Research Council Canada, Ottawa, Ontario, Canada), Jacob Taylor (Dunlap Institute for Astronomy and Astrophysics, University of Toronto, Toronto, Ontario, Canada, David A. Dunlap Department of Astronomy and Astrophysics, University of Toronto, Toronto, Ontario, Canada), Libertad Rojas (Dunlap Institute for Astronomy and Astrophysics, University of Toronto, Toronto, Ontario, Canada), Martin Vachon (Quantum and Nanotechnologies Research Centre, National Research Council Canada, Ottawa, Ontario, Canada), Dan-Xia Xu (Quantum and Nanotechnologies Research Centre, National Research Council Canada, Ottawa, Ontario, Canada), Jens H. Schmid (Quantum and Nanotechnologies Research Centre, National Research Council Canada, Ottawa, Ontario, Canada), Pavel Cheben (Quantum and Nanotechnologies Research Centre, National Research Council Canada, Ottawa, Ontario, Canada), Siegfried Janz (Quantum and Nanotechnologies Research Centre, National Research Council Canada, Ottawa, Ontario, Canada), Suresh Sivanandam (Dunlap Institute for Astronomy and Astrophysics, University of Toronto, Toronto, Ontario, Canada, David A. Dunlap Department of Astronomy and Astrophysics, University of Toronto, Toronto, Ontario, Canada)</dc:creator>
    </item>
    <item>
      <title>Modeling Foreground Spatial Variations in 21 cm Gaussian Process Component Separation</title>
      <link>https://arxiv.org/abs/2407.11296</link>
      <description>arXiv:2407.11296v1 Announce Type: cross 
Abstract: Gaussian processes (GPs) have been extensively utilized as nonparametric models for component separation in 21 cm data analyses. This exploits the distinct spectral behavior of the cosmological and foreground signals, which are modeled through the GP covariance kernel. Previous approaches have employed a global GP kernel along all lines of sight (LoS). In this work, we study Bayesian approaches that allow for spatial variations in foreground kernel parameters, testing them against simulated HI intensity mapping observations. We consider a no-pooling (NP) model, which treats each LoS independently by fitting for separate covariance kernels, and a hierarchical Gaussian Process (HGP) model that allows for variation in kernel parameters between different LoS, regularized through a global hyperprior. We find that accounting for spatial variations in the GP kernel parameters results in a significant improvement in cosmological signal recovery, achieving up to a 30% reduction in the standard deviation of the residual distribution and improved model predictive performance. Allowing for spatial variations in GP kernel parameters also improves the recovery of the HI power spectra and wavelet scattering transform coefficients. Whilst the NP model achieves superior recovery as measured by the residual distribution, it demands extensive computational resources, faces formidable convergence challenges, and is prone to overfitting. Conversely, the HGP model strikes a balance between the accuracy and robustness of the signal recovery. Further improvements to the HGP model will require more physically motivated modeling of foreground spatial variations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11296v1</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kangning Diao, Richard D. P. Grumitt, Yi Mao</dc:creator>
    </item>
    <item>
      <title>Epsilon Sagittarii: An Extreme Rapid Rotator with a Decretion Disk</title>
      <link>https://arxiv.org/abs/2407.11352</link>
      <description>arXiv:2407.11352v1 Announce Type: cross 
Abstract: We report high-precision multi-wavelength linear-polarization observations of the bright B9 (or A0) star $\epsilon$ Sagittarii. The polarization shows the distinctive wavelength dependence expected for a rapidly rotating star. Analysis of the polarization data reveals an angular rotation rate $\omega$ (= $\Omega/\Omega_{crit})$ of 0.995 or greater, the highest yet measured for a star in our galaxy. An additional wavelength-independent polarization component is attributed to electron scattering in a low-density edge-on gas disk that also produces the narrow absorption components seen in the spectrum. Several properties of the star (polarization due to a disk, occasional weak H$\alpha$ emission, and multiple periodicities seen in space photometry) resemble those of Be stars, but the level of activity in all cases is much lower than that of typical Be stars. The stellar properties are inconsistent with single rotating-star evolutionary tracks, indicating that it is most likely a product of binary interaction. The star is an excellent candidate for observation by interferometry, optical spectropolarimetry to detect the \"{O}hman effect, and UV polarimetry; any of which would allow its extreme rotation to be tested and its stellar properties to be refined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11352v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy Bailey, Fiona Lewis, Ian D. Howarth, Daniel V. Cotton, Jonathan P. Marshall, Lucyna Kedziora-Chudczer</dc:creator>
    </item>
    <item>
      <title>The impact of lossy data compression on the power spectrum of the high redshift 21-cm signal with LOFAR</title>
      <link>https://arxiv.org/abs/2407.11557</link>
      <description>arXiv:2407.11557v1 Announce Type: cross 
Abstract: Current radio interferometers output multi-petabyte-scale volumes of data per year making the storage, transfer, and processing of this data a sizeable challenge. This challenge is expected to grow with the next-generation telescopes such as the Square Kilometre Array. Lossy compression of interferometric data post-correlation can abate this challenge. However, since high-redshift 21-cm studies impose strict precision requirements, the impact of such lossy data compression on the 21-cm signal power spectrum statistic should be understood. We apply Dysco visibility compression, a technique to normalize and quantize specifically designed for radio interferometric data. We establish the level of the compression noise in the power spectrum in comparison to the thermal noise as well as its coherency behavior. Finally, for optimal compression results, we compare the compression noise obtained from different compression settings to a nominal 21-cm signal power. From a single night of observation, we find that the noise introduced due to the compression is more than five orders of magnitude lower than the thermal noise level in the power spectrum. The noise does not affect calibration. The compression noise shows no correlation with the sky signal and has no measurable coherent component. The level of compression error in the power spectrum ultimately depends on the compression settings. Dysco visibility compression is found to be of insignificant concern for 21-cm power spectrum studies. Hence, data volumes can be safely reduced by factors of $\sim 4$ and with insignificant bias to the final power spectrum. Data from SKA-low will likely be compressible by the same factor as LOFAR, owing to the similarities of the two instruments. The same technique can be used to compress data from other telescopes, but a small adjustment of the compression parameters might be required.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11557v1</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J. K. Chege, L. V. E. Koopmans, A. R. Offringa, B. K. Gehlot, S. A. Brackenhoff, E. Ceccotti, S. Ghosh, C. H\"ofer, F. G. Mertens, M. Mevius, S. Munshi</dc:creator>
    </item>
    <item>
      <title>Toward an efficient second-order method for computing the surface gravitational potential on spherical-polar meshes</title>
      <link>https://arxiv.org/abs/2407.11648</link>
      <description>arXiv:2407.11648v1 Announce Type: cross 
Abstract: Astrophysical accretion discs that carry a significant mass compared with their central object are subject to the effect of self-gravity. In the context of circumstellar discs, this can, for instance, cause fragmentation of the disc gas, and -- under suitable conditions -- lead to the direct formation of gas-giant planets. If one wants to study these phenomena, the disc's gravitational potential needs to be obtained by solving the Poisson equation. This requires to specify suitable boundary conditions. In the case of a spherical-polar computational mesh, a standard multipole expansion for obtaining boundary values is not practicable. We hence compare two alternative methods for overcoming this limitation. The first method is based on a known Green's function expansion (termed "CCGF") of the potential, while the second (termed "James' method") uses a surface screening mass approach with a suitable discrete Green's function. We demonstrate second-order convergence for both methods and test the weak scaling behaviour when using thousands of computational cores. Overall, James' method is found superior owing to its favourable algorithmic complexity of $\sim \mathcal{O}(n^3)$ compared with the $\sim\mathcal{O}(n^4)$ scaling of the CCGF method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11648v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Oliver Gressel, Udo Ziegler</dc:creator>
    </item>
    <item>
      <title>Magnetogram-to-Magnetogram: Generative Forecasting of Solar Evolution</title>
      <link>https://arxiv.org/abs/2407.11659</link>
      <description>arXiv:2407.11659v1 Announce Type: cross 
Abstract: Investigating the solar magnetic field is crucial to understand the physical processes in the solar interior as well as their effects on the interplanetary environment. We introduce a novel method to predict the evolution of the solar line-of-sight (LoS) magnetogram using image-to-image translation with Denoising Diffusion Probabilistic Models (DDPMs). Our approach combines "computer science metrics" for image quality and "physics metrics" for physical accuracy to evaluate model performance. The results indicate that DDPMs are effective in maintaining the structural integrity, the dynamic range of solar magnetic fields, the magnetic flux and other physical features such as the size of the active regions, surpassing traditional persistence models, also in flaring situation. We aim to use deep learning not only for visualisation but as an integrative and interactive tool for telescopes, enhancing our understanding of unexpected physical events like solar flares. Future studies will aim to integrate more diverse solar data to refine the accuracy and applicability of our generative model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11659v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Francesco Pio Ramunno, Hyun-Jin Jeong, Stefan Hackstein, Andr\'e Csillaghy, Svyatoslav Voloshynovskiy, Manolis K. Georgoulis</dc:creator>
    </item>
    <item>
      <title>mochi_class: Modelling Optimisation to Compute Horndeski In class</title>
      <link>https://arxiv.org/abs/2407.11968</link>
      <description>arXiv:2407.11968v1 Announce Type: cross 
Abstract: We introduce mochi_class, an extension of the Einstein-Boltzmann solver hi_class, designed to unlock the full phenomenological potential of Horndeski gravity. This extension allows for general input functions of time without the need for hard-coded parametrisations or covariant Lagrangians. By replacing the traditional $\alpha$-parametrisation with a set of stable basis functions, mochi_class ensures that the resulting effective theories are inherently free from gradient and ghost instabilities. Additionally, mochi_class features a quasi-static approximation implemented at the level of modified metric potentials, enhancing prediction accuracy, especially for models transitioning between a super- and sub-Compton regime. mochi_class can robustly handle a wide range of models without fine-tuning, and introduces a new approximation scheme that activates modifications to the standard cosmology deep in the matter-dominated era. Furthermore, it incorporates viability conditions on the equation of motion for the scalar field fluctuations, aiding in the identification of numerical instabilities. Through comprehensive validation against other Einstein-Boltzmann solvers, mochi_class demonstrates excellent performance and accuracy, broadening the scope of hi_class by facilitating the study of specific modified gravity models and enabling exploration of previously inaccessible regions of the Horndeski landscape. The code is publicly available at https://github.com/mcataneo/mochi_class_public</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11968v1</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Cataneo, Emilio Bellini</dc:creator>
    </item>
    <item>
      <title>Exploring Large-Volume GAGG Scintillators for use in MeV Gamma-Ray Astrophysics</title>
      <link>https://arxiv.org/abs/2405.06815</link>
      <description>arXiv:2405.06815v4 Announce Type: replace 
Abstract: Gamma-ray astrophysics in the MeV band is an exciting field in astronomy due to its potential for multi-messenger astrophysics. It has, however, remained under-explored when compared to other wavelengths. One reason for this observational gap is the difficulties with measuring these high-energy photons and the requirement of large amounts of detection material. In this work, we investigate the usage of large-volume GAGG scintillators for use as a calorimeter in future MeV telescopes. We developed a $5\times5$ array calorimeter utilizing $1\times1\times6 \ \mathrm{cm}^3$ GAGG crystals with onsemi C-series SiPM readout. We tested the calorimeter at the High Intensity Gamma-ray Facility (HIGS) with monoenergetic beams ranging from $2-25 \ \mathrm{MeV}$. Finally, we also investigate larger $1\times1\times8 \ \mathrm{cm}^3$ crystals and characterize their response across their depth when their surface treatment is either polished or frosted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06815v4</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Daniel Shy, Richard Woolf, Bernard Phlips, Mary Johnson-Rambert, Emily Kong</dc:creator>
    </item>
    <item>
      <title>A Robust Bayesian Meta-Analysis for Estimating the Hubble Constant via Time Delay Cosmography</title>
      <link>https://arxiv.org/abs/2308.13018</link>
      <description>arXiv:2308.13018v2 Announce Type: replace-cross 
Abstract: We propose a Bayesian meta-analysis to infer the current expansion rate of the Universe, called the Hubble constant ($H_0$), via time delay cosmography. Inputs of the meta-analysis are estimates of two properties for each pair of gravitationally lensed images; time delay and Fermat potential difference estimates with their standard errors. A meta-analysis can be appealing in practice because obtaining each estimate from even a single lens system involves substantial human efforts, and thus estimates are often separately obtained and published. Moreover, numerous estimates are expected to be available once the Rubin Observatory starts monitoring thousands of strong gravitational lens systems. This work focuses on combining these estimates from independent studies to infer $H_0$ in a robust manner. The robustness is crucial because currently up to eight lens systems are used to infer $H_0$, and thus any biased input can severely affect the resulting $H_0$ estimate. For this purpose, we adopt Student's $t$ error for the input estimates. We investigate properties of the resulting $H_0$ estimate via two simulation studies with realistic imaging data. It turns out that the meta-analysis can infer $H_0$ with sub-percent bias and about 1% level of coefficient of variation, even when 30% of inputs are manipulated to be outliers. We also apply the meta-analysis to three gravitationally lensed systems to obtain an $H_0$ estimate and compare it with existing estimates. An R package, h0, is publicly available for fitting the proposed meta-analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13018v2</guid>
      <category>stat.AP</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyungsuk Tak, Xuheng Ding</dc:creator>
    </item>
    <item>
      <title>High-Precision Transition Energy Measurements of Neon-like Fe XVII Ions</title>
      <link>https://arxiv.org/abs/2401.08395</link>
      <description>arXiv:2401.08395v3 Announce Type: replace-cross 
Abstract: We improve by a factor of 4-20 the energy accuracy of the strongest soft X-ray transitions of Fe XVII ions by resonantly exciting them in an electron beam ion trap with a monochromatic beam at the P04 beamline of the PETRA III synchrotron facility. By simultaneously tracking instantaneous photon-energy fluctuations with a high-resolution photoelectron spectrometer, we minimize systematic uncertainties down to 10-15 meV, or velocity equivalent $\pm\sim$5 km s$^{-1}$ in their rest energies, substantially improving our knowledge of this key astrophysical ion. Our large-scale configuration-interaction computations include more than four million relativistic configurations and agree with the experiment at a level without precedent for a 10-electron system. Thereby, theoretical uncertainties for interelectronic correlations become far smaller than those of quantum electrodynamics (QED) corrections. The present QED benchmark strengthens our trust in future calculations of many other complex atomic ions of interest to astrophysics, plasma physics, and for the development of optical clocks with highly charged ions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08395v3</guid>
      <category>physics.atom-ph</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <category>physics.plasm-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3847/1538-4357/ad454b</arxiv:DOI>
      <arxiv:journal_reference>The Astrophysical Journal, 969, 52 (2024)</arxiv:journal_reference>
      <dc:creator>Chintan Shah, Moto Togawa, Marc Botz, Jonas Danisch, Joschka J. Goes, Sonja Bernitt, Marleen Maxton, Kai K\"obnick, Jen Buck, J\"orn Seltmann, Moritz Hoesch, Ming Feng Gu, F. Scott Porter, Thomas Pfeifer, Maurice A. Leutenegger, Charles Cheung, Marianna S. Safronova, Jos\'e R. Crespo L\'opez-Urrutia</dc:creator>
    </item>
    <item>
      <title>Markov Walk Exploration of Model Spaces: Bayesian Selection of Dark Energy Models with Supernovae</title>
      <link>https://arxiv.org/abs/2407.06259</link>
      <description>arXiv:2407.06259v2 Announce Type: replace-cross 
Abstract: Central to model selection is a trade-off between performing a good fit and low model complexity: A model of higher complexity should only be favoured over a simpler model if it provides significantly better fits. In Bayesian terms, this can be achieved by considering the evidence ratio, enabling choices between two competing models. We generalise this concept by constructing Markovian random walks for exploring the entire model spaces governed by the logarithmic evidence ratio, in analogy to the logarithmic likelihood ratio in parameter estimation problems. The theory of Markovian model exploration has an analytical description with partition functions, which we derive for both the canonical and macrocanonical case. We apply our methodology to selecting a polynomial for the dark energy equation of state function $w(a)$ fulfilling sensible physical priors, on the basis of data for the supernova distance-redshift relation. We conclude by commenting on Jeffreys' scale for Bayesian evidence ratios, choices of model priors and derived quantities like Shannon entropies for posterior model probabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06259v2</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benedikt Schosser, Tobias R\"ospel, Bjoern Malte Schaefer</dc:creator>
    </item>
  </channel>
</rss>
