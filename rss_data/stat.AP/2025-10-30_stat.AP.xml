<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 Oct 2025 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>How can methods for classifying and clustering trajectories be used for prevention trials? An example in Alzheimer's disease area</title>
      <link>https://arxiv.org/abs/2510.24751</link>
      <description>arXiv:2510.24751v1 Announce Type: new 
Abstract: Background: Clinical trials are designed to prove the efficacy of an intervention by means of model-based approaches involving parametric hypothesis testing. Issues arise when no effect is observed in the study population. Indeed, an effect may be present in a subgroup and the statistical test cannot detect it. To investigate this possibility, we proposed to change the paradigm to a data-driven approach. We selected exploratory methods to provide another perspective on the data and to identify particular homogeneous subgroups of subjects within which an effect might be detected. In the setting of prevention trials, the endpoint is a trajectory of repeated measures. In the settings of prevention trials, the endpoint is a trajectory of repeated measures, which requires the use of methods that can take data autocorrelation into account. The primary aim of this work was to explore the applicability of different methods for clustering and classifying trajectories. Methods: The Multidomain Alzheimer Preventive Trial (MAPT) was a three-year randomized controlled trial with four parallel arms (NCT00672685). The primary outcome was a composite Z-score combining four cognitive tests. The data were analyzed by quadratic mixed effects model. This study was inconclusive. Exploratory analysis is therefore relevant to investigate the use of data-driven methods for trajectory classification. The methods used were unsupervised: k-means for longitudinal data, Hierarchical Cluster Analysis (HCA), graphic semiology, and supervised analysis with dichotomous classification according to responder status. Results: Using k-means for longitudinal data, three groups were obtained and one of these groups showed cognitive decline over the three years of follow-up. This method could be applied directly to the primary outcome, the composite Z-score with repeated observations over time. With the two others unsupervised methods, we were unable to process longitudinal data directly. It was therefore necessary to choose an indicator of change in trajectories and to consider the rate of change between two measurements. For the HCA method, Ward's aggregation was performed. The Euclidean distance and rates of change were applied for the graphic semiology method. Lastly, as there were no objective criteria to define responder status, we defined our responders based on clinical criteria. Discussion: In the princeps study, the prevention trial was found to be inconclusive, likely due to the heterogeneity of the population, which may have masked a treatment effect later identified in a refined subgroup of high Beta Amyloid subjects. So, we have adopted an alternative unsupervised approach to subject stratification based on their trajectories. We could then identify patterns of similar trajectories of cognitive decline and also highlight the potential problem of a large heterogeneity of the profiles, maybe due to the final endpoint considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24751v1</guid>
      <category>stat.AP</category>
      <category>q-bio.NC</category>
      <category>stat.ME</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'eline Bougel (CERPOP), S\'ebastien D\'ejean (IMT, UT3), Caroline Giulioli (CERPOP), Philippe Saint-Pierre (IMT, UT3), Nicolas Savy (IMT, UT3), Sandrine Andrieu (CERPOP)</dc:creator>
    </item>
    <item>
      <title>Forecasting Australian Electricity Generation by Fuel Mix</title>
      <link>https://arxiv.org/abs/2510.25185</link>
      <description>arXiv:2510.25185v1 Announce Type: new 
Abstract: Electricity demand and generation have become increasingly unpredictable with the growing share of variable renewable energy sources in the power system. Forecasting electricity supply by fuel mix is crucial for market operation, ensuring grid stability, optimizing costs, integrating renewable energy sources, and supporting sustainable energy planning. We introduce two statistical methods, centering on forecast reconciliation and compositional data analysis, to forecast short-term electricity supply by different types of fuel mix. Using data for five electricity markets in Australia, we study the forecast accuracy of these techniques. The bottom-up hierarchical forecasting method consistently outperforms the other approaches. Moreover, fuel mix forecasting is most accurate in power systems with a higher share of stable fossil fuel generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25185v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Han Lin Shang, Lin Han, Stefan Tr\"uck</dc:creator>
    </item>
    <item>
      <title>Inferring Mobility Reductions from COVID-19 Disease Spread along the Urban-Rural Gradient</title>
      <link>https://arxiv.org/abs/2510.25424</link>
      <description>arXiv:2510.25424v1 Announce Type: new 
Abstract: The COVID-19 pandemic reshaped human mobility through policy interventions and voluntary behavioral changes. Mobility adaptions helped mitigate pandemic spread, however our knowledge which environmental, social, and demographic factors helped mobility reduction and pandemic mitigation is patchy. We introduce a Bayesian hierarchical model to quantify heterogeneity in mobility responses across time and space in Germany's 400 districts using anonymized mobile phone data. Decomposing mobility into a disease-responsive component and disease-independent factors (temperature, school vacations, public holidays) allows us to quantify the impact of each factor. We find significant differences in reaction to disease spread along the urban-rural gradient, with large cities reducing mobility most strongly. Employment sectors further help explain variance in reaction strength during the first wave, while political variables gain significance during the second wave. However, reduced mobility only partially translates to lower peak incidence, indicating the influence of other hidden factors. Our results identify key drivers of mobility reductions and demonstrate that mobility behavior can serve as an operational proxy for population response.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25424v1</guid>
      <category>stat.AP</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sydney Paltra, Jonas Dehning, Viola Priesemann, Kai Nagel</dc:creator>
    </item>
    <item>
      <title>General model for estimating range variances of terrestrial laser scanners based on (un-)scaled intensity values</title>
      <link>https://arxiv.org/abs/2510.25587</link>
      <description>arXiv:2510.25587v1 Announce Type: new 
Abstract: Recent advancements in technology have established terrestrial laser scanners (TLS) as a powerful instrument in geodetic deformation analysis. As TLS becomes increasingly integrated into this field, it is essential to develop a comprehensive stochastic model that accurately captures the measurement uncertainties. A key component of this model is the construction of a complete and valid variance-covariance matrix (VCM) for TLS polar measurements, which requires the estimation of variances for range, vertical, and horizontal angles, as well as their correlations. While angular variances can be obtained from manufacturer specifications, the range variance varies with different intensity measurements. As a primary contribution, this study presents an effective methodology for measuring and estimating TLS range variances using both raw and scaled intensity values. A two-dimensional scanning approach is applied to both controlled targets and arbitrary objects using TLS instruments that provide raw intensity values (e.g., Z+F~Imager~5016A) and those that output scaled intensities (e.g., Leica~ScanStation~P50). The methodology is further evaluated using field observations on a water dam surface. Overall, this work introduces a comprehensive workflow for modeling range uncertainties in high-end TLS systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25587v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Omar AbdelGafar, Selin Palaz, Yihui Yang, Christoph Holst</dc:creator>
    </item>
    <item>
      <title>COBASE: A new copula-based shuffling method for ensemble weather forecast postprocessing</title>
      <link>https://arxiv.org/abs/2510.25610</link>
      <description>arXiv:2510.25610v1 Announce Type: new 
Abstract: Weather predictions are often provided as ensembles generated by repeated runs of numerical weather prediction models. These forecasts typically exhibit bias and inaccurate dependence structures due to numerical and dispersion errors, requiring statistical postprocessing for improved precision. A common correction strategy is the two-step approach: first adjusting the univariate forecasts, then reconstructing the multivariate dependence. The second step is usually handled with nonparametric methods, which can underperform when historical data are limited. Parametric alternatives, such as the Gaussian Copula Approach (GCA), offer theoretical advantages but often produce poorly calibrated multivariate forecasts due to random sampling of the corrected univariate margins. In this work, we introduce COBASE, a novel copula-based postprocessing framework that preserves the flexibility of parametric modeling while mimicking the nonparametric techniques through a rank-shuffling mechanism. This design ensures calibrated margins and realistic dependence reconstruction. We evaluate COBASE on multi-site 2-meter temperature forecasts from the ALADIN-LAEF ensemble over Austria and on joint forecasts of temperature and dew point temperature from the ECMWF system in the Netherlands. Across all regions, COBASE variants consistently outperform traditional copula-based approaches, such as GCA, and achieve performance on par with state-of-the-art nonparametric methods like SimSchaake and ECC, with only minimal differences across settings. These results position COBASE as a competitive and robust alternative for multivariate ensemble postprocessing, offering a principled bridge between parametric and nonparametric dependence reconstruction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25610v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maurits Flos, Bastien Fran\c{c}ois, Irene Schicker, Kirien Whan, Elisa Perrone</dc:creator>
    </item>
    <item>
      <title>Modelling Real-Life Cycling Decisions in Real Urban Settings Through Psychophysiology and LLM-Derived Contextual Data</title>
      <link>https://arxiv.org/abs/2510.24726</link>
      <description>arXiv:2510.24726v1 Announce Type: cross 
Abstract: Measuring emotional states in transportation contexts is an emerging field. Methods based on self-reported emotions are limited by their low granularity and their susceptibility to memory bias. In contrast, methods based on physiological indicators provide continuous data, enabling researchers to measure changes in emotional states with high detail and accuracy. Not only are emotions important in the analysis, but understanding what triggers emotional changes is equally important. Uncontrolled variables such as traffic conditions, pedestrian interactions, and infrastructure remain a significant challenge, as they can have a great impact on emotional states. Explaining the reasons behind these emotional states requires gathering sufficient and proper contextual data, which can be extremely difficult in real-world environments. This paper addresses these challenges by applying an innovative approach, extracting contextual data (expert annotator level) from recorded multimedia using large language models (LLMs). In this paper, data are collected from an urban cycling case study of the City of Santiago, Chile. The applied models focus on understanding how different environments and traffic situations affect the emotional states and behaviors of the participants using physiological data. Sequences of images, extracted from the recorded videos, are processed by LLMs to obtain semantic descriptions of the environment. These discrete, although dense and detailed, contextual data are integrated into a hybrid model, where fatigue and arousal serve as latent variables influencing observed cycling behaviors (inferred from GPS data) like waiting, accelerating, braking, etc. The study confirms that cycling decisions are influenced by stress-related emotions and highlights the strong impact of urban characteristics and traffic conditions on cyclist behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24726v1</guid>
      <category>eess.SP</category>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Maximiliano Rosadio Z., Angel Jimenez-Molina, Basti\'an Henr\'iquez, Paulina Leiva, Ricardo Hurtubia, Ricardo De La Paz Guala, Leandro Gayozo, C. Angelo Guevara</dc:creator>
    </item>
    <item>
      <title>Dynamic Spatial Treatment Effects and Network Fragility: Theory and Evidence from European Banking</title>
      <link>https://arxiv.org/abs/2510.24775</link>
      <description>arXiv:2510.24775v1 Announce Type: cross 
Abstract: This paper develops and empirically implements a continuous functional framework for analyzing systemic risk in financial networks, building on the dynamic spatial treatment effect methodology established in our previous studies. We extend the Navier-Stokes-based approach from our previous studies to characterize contagion dynamics in the European banking system through the spectral properties of network evolution operators. Using high-quality bilateral exposure data from the European Banking Authority Transparency Exercise (2014-2023), we estimate the causal impact of the COVID-19 pandemic on network fragility using spatial difference-in-differences methods adapted from our previous studies. Our empirical analysis reveals that COVID-19 elevated network fragility, measured by the algebraic connectivity $\lambda_2$ of the system Laplacian, by 26.9% above pre-pandemic levels (95% CI: [7.4%, 46.5%], p&lt;0.05), with effects persisting through 2023. Paradoxically, this occurred despite a 46% reduction in the number of banks, demonstrating that consolidation increased systemic vulnerability by intensifying interconnectedness-consistent with theoretical predictions from continuous spatial dynamics. Our findings validate the key predictions from \citet{kikuchi2024dynamical}: treatment effects amplify over time through spatial spillovers, consolidation increases fragility when coupling strength rises, and systems exhibit structural hysteresis preventing automatic reversion to pre-shock equilibria. The results demonstrate the empirical relevance of continuous functional methods for financial stability analysis and provide new insights for macroprudential policy design. We propose network-based capital requirements targeting spectral centrality and stress testing frameworks incorporating diffusion dynamics to address the coupling externalities identified in our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24775v1</guid>
      <category>econ.EM</category>
      <category>q-fin.GN</category>
      <category>q-fin.RM</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatsuru Kikuchi</dc:creator>
    </item>
    <item>
      <title>Dual-Channel Technology Diffusion: Spatial Decay and Network Contagion in Supply Chain Networks</title>
      <link>https://arxiv.org/abs/2510.24781</link>
      <description>arXiv:2510.24781v1 Announce Type: cross 
Abstract: This paper develops a dual-channel framework for analyzing technology diffusion that integrates spatial decay mechanisms from continuous functional analysis with network contagion dynamics from spectral graph theory. Building on our previous studies, which establish Navier-Stokes-based approaches to spatial treatment effects and financial network fragility, we demonstrate that technology adoption spreads simultaneously through both geographic proximity and supply chain connections. Using comprehensive data on six technologies adopted by 500 firms over 2010-2023, we document three key findings. First, technology adoption exhibits strong exponential geographic decay with spatial decay rate $\kappa \approx 0.043$ per kilometer, implying a spatial boundary of $d^* \approx 69$ kilometers beyond which spillovers are negligible (R-squared = 0.99). Second, supply chain connections create technology-specific networks whose algebraic connectivity ($\lambda_2$) increases 300-380 percent as adoption spreads, with correlation between $\lambda_2$ and adoption exceeding 0.95 across all technologies. Third, traditional difference-in-differences methods that ignore spatial and network structure exhibit 61 percent bias in estimated treatment effects. An event study around COVID-19 reveals that network fragility increased 24.5 percent post-shock, amplifying treatment effects through supply chain spillovers in a manner analogous to financial contagion documented in our recent study. Our framework provides micro-foundations for technology policy: interventions have spatial reach of 69 kilometers and network amplification factor of 10.8, requiring coordinated geographic and supply chain targeting for optimal effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24781v1</guid>
      <category>econ.EM</category>
      <category>econ.TH</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatsuru Kikuchi</dc:creator>
    </item>
    <item>
      <title>Bayesian Spatial Point Process Modeling for Cluster Randomized Trials</title>
      <link>https://arxiv.org/abs/2510.24969</link>
      <description>arXiv:2510.24969v1 Announce Type: cross 
Abstract: Cluster randomized trials (CRTs) offer a practical alternative for addressing logistical challenges and ensuring feasibility in community health, education, and prevention studies, even though randomized controlled trials are considered the gold standard in evaluating therapeutic interventions. Despite their utility, CRTs are often criticized for limited precision and complex modeling requirements. Advances in robust Bayesian methods and the incorporation of spatial correlation into CRT design and analysis remain relatively underdeveloped. This paper introduces a Bayesian spatial point process framework that models individuals nested within geographic clusters while explicitly accounting for spatial dependence. We demonstrate that conventional non-spatial models consistently underestimate uncertainty and lead to misleading inferences, whereas our spatial approach improves estimation stability, controls type I error, and enhances statistical power. Our results underscore the value and need for wider adoption of spatial methods in CRT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24969v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jooyeon Lee, M. S., Evan Kwiatkowski, Ph. D</dc:creator>
    </item>
    <item>
      <title>Stable Emotional Co-occurrence Patterns Revealed by Network Analysis of Social Media</title>
      <link>https://arxiv.org/abs/2510.25204</link>
      <description>arXiv:2510.25204v1 Announce Type: cross 
Abstract: Examining emotion interactions as an emotion network in social media offers key insights into human psychology, yet few studies have explored how fluctuations in such emotion network evolve during crises and normal times. This study proposes a novel computational approach grounded in network theory, leveraging large-scale Japanese social media data spanning varied crisis events (earthquakes and COVID-19 vaccination) and non-crisis periods over the past decade. Our analysis identifies and evaluates links between emotions through the co-occurrence of emotion-related concepts (words), revealing a stable structure of emotion network across situations and over time at the population level. We find that some emotion links (represented as link strength) such as emotion links associated with Tension are significantly strengthened during earthquake and pre-vaccination periods. However, the rank of emotion links remains highly intact. These findings challenge the assumption that emotion co-occurrence is context-based and offer a deeper understanding of emotions' intrinsic structure. Moreover, our network-based framework offers a systematic, scalable method for analyzing emotion co-occurrence dynamics, opening new avenues for psychological research using large-scale textual data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25204v1</guid>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qianyun Wu, Orr Levy, Yoed N. Kenett, Yukie Sano, Hideki Takayasu, Shlomo Havlin, Misako Takayasu</dc:creator>
    </item>
    <item>
      <title>Statistical Process Monitoring based on Functional Data Analysis</title>
      <link>https://arxiv.org/abs/2510.25742</link>
      <description>arXiv:2510.25742v1 Announce Type: cross 
Abstract: In modern industrial settings, advanced acquisition systems allow for the collection of data in the form of profiles, that is, as functional relationships linking responses to explanatory variables. In this context, statistical process monitoring (SPM) aims to assess the stability of profiles over time in order to detect unexpected behavior. This review focuses on SPM methods that model profiles as functional data, i.e., smooth functions defined over a continuous domain, and apply functional data analysis (FDA) tools to address limitations of traditional monitoring techniques. A reference framework for monitoring multivariate functional data is first presented. This review then offers a focused survey of several recent FDA-based profile monitoring methods that extend this framework to address common challenges encountered in real-world applications. These include approaches that integrate additional functional covariates to enhance detection power, a robust method designed to accommodate outlying observations, a real-time monitoring technique for partially observed profiles, and two adaptive strategies that target the characteristics of the out-of-control distribution. These methods are all implemented in the R package funcharts, available on CRAN. Finally, a review of additional existing FDA-based profile monitoring methods is also presented, along with suggestions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.25742v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio Centofanti</dc:creator>
    </item>
    <item>
      <title>Simultaneous Reconstruction of Spatial Frequency Fields and Sample Locations via Bayesian Semi-Modular Inference</title>
      <link>https://arxiv.org/abs/2412.05763</link>
      <description>arXiv:2412.05763v2 Announce Type: replace 
Abstract: Traditional methods for spatial inference estimate smooth interpolating fields based on features measured at well-located points. When the spatial locations of some observations are missing, joint inference of the fields and locations is possible as the fields inform the locations and vice versa. If the number of missing locations is large, conventional Bayesian Inference fails if the generative model for the data is even slightly mis-specified, due to feedback between estimated fields and the imputed locations. Semi-Modular Inference (SMI) offers a solution by controlling the feedback between different modular components of the joint model using a hyper-parameter called the influence parameter. Our work is motivated by linguistic studies on a large corpus of late-medieval English textual dialects. We simultaneously learn dialect fields using dialect features observed in ``anchor texts'' with known location and estimate the location of origin for ``floating'' textual dialects of unknown origin. The optimal influence parameter minimises a loss measuring the accuracy of held-out anchor data. We compute a (flow-based) variational approximation to the SMI posterior for our model. This allows efficient computation of the optimal influence. MCMC-based approaches, feasible on small subsets of the data, are used to check the variational approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05763v2</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chris U. Carmona, Ross A. Haines, Max Anderson Loake, Michael Benskin, Geoff K. Nicholls</dc:creator>
    </item>
    <item>
      <title>Estimation of Piecewise Continuous Regression Function in Finite Dimension using Oblique Regression Tree with Applications in Image Denoising</title>
      <link>https://arxiv.org/abs/2503.16007</link>
      <description>arXiv:2503.16007v2 Announce Type: replace 
Abstract: Decision trees are one of the most widely used nonparametric methods for regression and classification. In existing literature, decision tree-based methods have been used for estimating continuous functions or piecewise-constant functions. However, they are not flexible enough to estimate the complex shapes of jump location curves (JLCs) in two-dimensional regression functions. In this article, we explore the Oblique-axis Regression Tree (ORT) and propose a method to efficiently estimate piece-wise continuous functions in a general finite dimension with fixed design points. The central idea involves clustering the local pixel intensities by recursive tree partitioning and using the local leaf-only averaging for estimation of the regression function at a given pixel. The proposed method can preserve complex shapes of the JLCs well in a finite-dimensional regression function. Due to a different set of assumptions on the underlying regression function, the overall framework of the proofs is different from what is available in the literature on regression trees. Theoretical analysis and numerical results, particularly on image denoising, indicate that the proposed method effectively preserves complicated edge structures while efficiently removing noise from piecewise continuous regression surfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16007v2</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.5705/ss.202025.0120</arxiv:DOI>
      <dc:creator>Subhasish Basak, Anik Roy, Partha Sarathi Mukherjee</dc:creator>
    </item>
    <item>
      <title>Hierarchical additive interaction modelling with Gaussian process prior and its efficient implementation for multidimensional grid data</title>
      <link>https://arxiv.org/abs/2305.07073</link>
      <description>arXiv:2305.07073v4 Announce Type: replace-cross 
Abstract: Additive Gaussian process (GP) models offer flexible tools for modelling complex non-linear relationships and interaction effects among covariates. While most studies have focused on predictive performance, relatively little attention has been given to identifying the underlying interaction structure, which may be of scientific interest in many applications. In practice, the use of additive GP models in this context has been limited by the cubic computational cost and quadratic storage requirements of GP inference. This paper presents a fast hierarchical additive interaction GP model for multi-dimensional grid data. A hierarchical ANOVA decomposition kernel forms the foundation of our model, which incorporate main and interaction effects under the principle of marginality. Kernel centring ensures identifiability and provides a unique, interpretable decomposition of lower- and higher-order effects. For datasets forming a multi-dimensional grid, efficient implementation is achieved by exploiting the Kronecker product structure of the covariance matrix. Our contribution is to extend Kronecker-based computation to handle any interaction structure within the proposed class of hierarchical additive GP models, whereas previous methods were limited to separable or fully saturated cases. The benefits of the proposed approach are demonstrated through simulation studies and an application to high-frequency nitrogen dioxide concentration data in London.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.07073v4</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sahoko Ishida, Francesca Panero, Wicher Bergsma</dc:creator>
    </item>
    <item>
      <title>Latent Factor Analysis in Short Panels</title>
      <link>https://arxiv.org/abs/2306.14004</link>
      <description>arXiv:2306.14004v3 Announce Type: replace-cross 
Abstract: We develop a pseudo maximum likelihood method for latent factor analysis in short panels without imposing sphericity nor Gaussianity. We derive an asymptotically uniformly most powerful invariant test for the number of factors. On a large panel of monthly U.S. stock returns, we separate month after month systematic and idiosyncratic risks in short subperiods of bear vs. bull market. We observe an uptrend in the paths of total and idiosyncratic volatilities. The systematic risk explains a large part of the cross-sectional total variance in bear markets but is not driven by a single factor and not spanned by observed factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14004v3</guid>
      <category>econ.EM</category>
      <category>q-fin.PR</category>
      <category>q-fin.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alain-Philippe Fortin, Patrick Gagliardini, Olivier Scaillet</dc:creator>
    </item>
    <item>
      <title>Replicable Bandits for Digital Health Interventions</title>
      <link>https://arxiv.org/abs/2407.15377</link>
      <description>arXiv:2407.15377v5 Announce Type: replace-cross 
Abstract: Adaptive treatment assignment algorithms, such as bandit algorithms, are increasingly used in digital health intervention clinical trials. Frequently, the data collected from these trials is used to conduct causal inference and related data analyses to decide how to refine the intervention, and whether to roll-out the intervention more broadly. This work studies inference for estimands that depend on the adaptive algorithm itself; a simple example is the mean reward under the adaptive algorithm. Specifically, we investigate the replicability of statistical analyses concerning such estimands when using data from trials deploying adaptive treatment assignment algorithms. We demonstrate that many standard statistical estimators can be inconsistent and fail to be replicable across repetitions of the clinical trial, even as the sample size grows large. We show that this non-replicability is intimately related to properties of the adaptive algorithm itself. We introduce a formal definition of a "replicable bandit algorithm" and prove that under such algorithms, a wide variety of common statistical estimators are guaranteed to be consistent and asymptotically normal. We present both theoretical results and simulation studies based on a mobile health oral health self-care intervention. Our findings underscore the importance of designing adaptive algorithms with replicability in mind, especially for settings like digital health, where deployment decisions rely heavily on replicated evidence. We conclude by discussing open questions on the connections between algorithm design, statistical inference, and experimental replicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15377v5</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 30 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:journal_reference>Statistical Science, 2025</arxiv:journal_reference>
      <dc:creator>Kelly W. Zhang, Nowell Closser, Anna L. Trella, Susan A. Murphy</dc:creator>
    </item>
  </channel>
</rss>
