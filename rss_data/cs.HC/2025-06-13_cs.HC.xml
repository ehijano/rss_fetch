<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Jun 2025 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Cybernetic Marionette: Channeling Collective Agency Through a Wearable Robot in a Live Dancer-Robot Duet</title>
      <link>https://arxiv.org/abs/2506.10079</link>
      <description>arXiv:2506.10079v1 Announce Type: new 
Abstract: We describe DANCE^2, an interactive dance performance in which audience members channel their collective agency into a dancer-robot duet by voting on the behavior of a wearable robot affixed to the dancer's body. At key moments during the performance, the audience is invited to either continue the choreography or override it, shaping the unfolding interaction through real-time collective input. While post-performance surveys revealed that participants felt their choices meaningfully influenced the performance, voting data across four public performances exhibited strikingly consistent patterns. This tension between what audience members do, what they feel, and what actually changes highlights a complex interplay between agentive behavior, the experience of agency, and power. We reflect on how choreography, interaction design, and the structure of the performance mediate this relationship, offering a live analogy for algorithmically curated digital systems where agency is felt, but not exercised.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10079v1</guid>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3715336.3735828</arxiv:DOI>
      <arxiv:journal_reference>DIS 2025</arxiv:journal_reference>
      <dc:creator>Anup Sathya, Jiasheng Li, Zeyu Yan, Adriane Fang, Bill Kules, Jonathan David Martin, Huaishu Peng</dc:creator>
    </item>
    <item>
      <title>Mastery Learning Improves Performance on Complex Tasks on PCP Literacy Test</title>
      <link>https://arxiv.org/abs/2506.10164</link>
      <description>arXiv:2506.10164v1 Announce Type: new 
Abstract: Developing literacy with unfamiliar data visualization techniques such as Parallel Coordinate Plots (PCPs) can be a significant challenge for students. We adopted the Revised Bloom's taxonomy to instruct students on Parallel Coordinate Plots (PCPs) using Mastery Learning in the classroom. To evaluate Mastery Learning's impact, we conducted an intervention in a Data Visualization course to teach students about PCPs using the Revised Bloom's taxonomy with and without Mastery Learning. Based on our intervention, we found that while students in both groups performed similarly on the first two (Remember, Understand) modules, the students in the Mastery Learning group performed better on modules that required more advanced thinking (Analyze, Evaluate) and demonstrated a better comprehension of PCPs. We provide all the materials developed including the six-module Bloom's Taxonomy PCP literacy (BTPL) test for full reproducibility on our website at https://vis-graphics.github.io/PCP-Literacy-Test/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10164v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chandana Srinivas, Elif E. Firat, Robert S. Laramee, Alark Joshi</dc:creator>
    </item>
    <item>
      <title>Intergenerational AI Literacy in Korean Immigrant Families: Interpretive Gatekeeping Meets Convenient Critical Deferment</title>
      <link>https://arxiv.org/abs/2506.10197</link>
      <description>arXiv:2506.10197v1 Announce Type: new 
Abstract: As artificial intelligence (AI) becomes deeply integrated into family life, immigrant families must navigate unique intergenerational, linguistic, and cultural challenges. This study examines how Korean immigrant families in the United States negotiate the use of AI tools such as ChatGPT and smart assistants in their homes. Through 20 semi-structured interviews with parents and teens, we identify two key practices that shape their engagement: interpretive gatekeeping, where parents mediate their children's AI use through a lens of cultural and ethical values, and convenient critical deferment, where teens strategically postpone critical evaluation of AI for immediate academic and social utility. These intertwined practices challenge conventional, skills-based models of AI literacy, revealing it instead as a dynamic and relational practice co-constructed through ongoing family negotiation. We contribute to information science and HCI by offering a new conceptual extension for intergenerational AI literacy and providing design implications for more equitable, culturally attuned, and family-centered AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10197v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeongone Seo, Ryan Womack, Tawfiq Ammari</dc:creator>
    </item>
    <item>
      <title>Speculative Design in Spiraling Time: Methods and Indigenous HCI</title>
      <link>https://arxiv.org/abs/2506.10229</link>
      <description>arXiv:2506.10229v1 Announce Type: new 
Abstract: In this position paper, we first discuss the uptake of speculative design as a method for Indigenous HCI. Then, we outline how a key assumption about temporality threatens to undermine the usefulness of speculative design in this context. Finally, we briefly sketch out a possible alternative understanding of speculative design, based on the concept of "spiraling time," which could be better suited for Indigenous HCI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10229v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Eschrich, Cole McMullen, Sarah Sterman</dc:creator>
    </item>
    <item>
      <title>Extended Creativity: A Conceptual Framework for Understanding Human-AI Creative Relations</title>
      <link>https://arxiv.org/abs/2506.10249</link>
      <description>arXiv:2506.10249v1 Announce Type: new 
Abstract: Artificial Intelligence holds significant potential to enhance human creativity. However, achieving this vision requires a clearer understanding of how such enhancement can be effectively realized. Adopting the perspective of distributed creativity, we identify three primary modes through which AI can contribute to creative processes: Support, where AI acts as a tool; Synergy, where AI and humans collaborate in complementary ways; and Symbiosis, where human and AI cognition become so integrated that they form a unified creative system. These modes are defined along two key dimensions: the level of technical autonomy exhibited by the AI system and the degree of perceived agency attributed to it. We examine how each configuration influences different levels of creativity - from everyday problem-solving to paradigm-shifting innovation - and discuss the theoretical, ethical, and design implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10249v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Gaggioli, Sabrina Bartolotta, Andrea Ubaldi, Katusha Gerardini, Eleonora Diletta Sarcinella, Alice Chirico</dc:creator>
    </item>
    <item>
      <title>Beyond Compliance: A User-Autonomy Framework for Inclusive and Customizable Web Accessibility</title>
      <link>https://arxiv.org/abs/2506.10324</link>
      <description>arXiv:2506.10324v1 Announce Type: new 
Abstract: This paper proposes a shift from compliance-centered web accessibility to a care-driven model that prioritizes user autonomy, using neurodivergent users as a catalyst case for broader personalization needs. While accessibility standards offer a flexible framework, they are often interpreted and implemented as static compliance checklists, our approach reframes it as a flexible, user-centered process. We introduce a customizable Comfort Mode framework that allows users to adapt interface settings, such as contrast, typography, motion, and scaling, according to their individual needs, while retaining the brand's core visual identity. Grounded in psychological and cognitive accessibility principles, our design supports personalization without sacrificing creative freedom. We present both minimal and advanced implementation models with mock-ups, demonstrating how inclusive design can be seamlessly integrated at minimal cost. This approach aims to broaden digital inclusivity by offering autonomy to those who require it, without imposing changes on those who do not. The proposed system is adaptable, scalable, and suitable for a wide range of users and brands, offering a new paradigm where user autonomy, aesthetic integrity, and accessibility converge not through compromise, but through choice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10324v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lalitha A R</dc:creator>
    </item>
    <item>
      <title>IDEA: Augmenting Design Intelligence through Design Space Exploration</title>
      <link>https://arxiv.org/abs/2506.10587</link>
      <description>arXiv:2506.10587v1 Announce Type: new 
Abstract: Design spaces serve as a conceptual framework that enables designers to explore feasible solutions through the selection and combination of design elements. However, effective decision-making remains heavily dependent on the designer's experience, and the absence of mathematical formalization prevents computational support for automated design processes. To bridge this gap, we introduce a structured representation that models design spaces with orthogonal dimensions and discrete selectable elements. Building on this model, we present IDEA, a decision-making framework for augmenting design intelligence through design space exploration to generate effective outcomes. Specifically, IDEA leverages large language models (LLMs) for constraint generation, incorporates a Monte Carlo Tree Search (MCTS) algorithm guided by these constraints to explore the design space efficiently, and instantiates abstract decisions into domain-specific implementations. We validate IDEA in two design scenarios: data-driven article composition and pictorial visualization generation, supported by example results, expert interviews, and a user study. The evaluation demonstrates the IDEA's adaptability across domains and its capability to produce superior design outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10587v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuer Chen, Xiaoke Yan, Xiaoyu Qi, Nan Cao</dc:creator>
    </item>
    <item>
      <title>Accessible Design in Integrated Development Environments: A Think Aloud Study Exploring the Experiences of Students with ADHD</title>
      <link>https://arxiv.org/abs/2506.10598</link>
      <description>arXiv:2506.10598v1 Announce Type: new 
Abstract: Coding forms a key part of computer science education in universities. As part of this education, Integrated Development Environments (IDEs) are essential tools for coding. However, it is currently unknown how the design of an IDE's interface impacts on students with Attention Deficit Hyperactivity Disorder (ADHD).
  In this study we investigated the use of IDEs by students with ADHD. We conducted a think aloud study with nine university computing students, followed by qualitative observational interviews to analyse their learning and engagement with the Visual Studio Code IDE. The paper reports on these experiences and seeks to understand the role IDEs play in the educational setting.
  Our work also examines how digital accessibility and usability are considered in the current design of IDEs. We analysed the qualitative data using a thematic analysis and identified three primary themes: self-confidence, interaction, and learning as well as various sub-themes.
  The themes and their sub-themes illustrate key areas of consideration when designing IDEs for students with ADHD. The primary findings highlight experiences of frustration and barriers in the current design and layout of IDEs.
  Through our participatory approach we provide a rare insight into ADHD user experiences around usability and accessibility, and describe the need for better design of development environments to ensure a positive learning experience for the students.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10598v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke Halpin, Phillip Benachour, Tracy Hall, Ann-Marie Houghton, Emily Winter</dc:creator>
    </item>
    <item>
      <title>Integrating Large Language Models into Text Animation: An Intelligent Editing System with Inline and Chat Interaction</title>
      <link>https://arxiv.org/abs/2506.10762</link>
      <description>arXiv:2506.10762v1 Announce Type: new 
Abstract: Text animation, a foundational element in video creation, enables efficient and cost-effective communication, thriving in advertisements, journalism, and social media. However, traditional animation workflows present significant usability barriers for non-professionals, with intricate operational procedures severely hindering creative productivity. To address this, we propose a Large Language Model (LLM)-aided text animation editing system that enables real-time intent tracking and flexible editing. The system introduces an agent-based dual-stream pipeline that integrates context-aware inline suggestions and conversational guidance as well as employs a semantic-animation mapping to facilitate LLM-driven creative intent translation. Besides, the system supports synchronized text-animation previews and parametric adjustments via unified controls to improve editing workflow. A user study evaluates the system, highlighting its ability to help non-professional users complete animation workflows while validating the pipeline. The findings encourage further exploration of integrating LLMs into a comprehensive video creation workflow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10762v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bao Zhang, Zihan Li, Zhenglei Liu, Huanchen Wang, Yuxin Ma</dc:creator>
    </item>
    <item>
      <title>Grasp Prediction based on Local Finger Motion Dynamics</title>
      <link>https://arxiv.org/abs/2506.10818</link>
      <description>arXiv:2506.10818v1 Announce Type: new 
Abstract: The ability to predict the object the user intends to grasp offers essential contextual information and may help to leverage the effects of point-to-point latency in interactive environments. This paper explores the feasibility and accuracy of real-time recognition of uninstrumented objects based on hand kinematics during reach-to-grasp actions. In a data collection study, we recorded the hand motions of 16 participants while reaching out to grasp and then moving real and synthetic objects. Our results demonstrate that even a simple LSTM network can predict the time point at which the user grasps an object with a precision better than 21 ms and the current distance to this object with a precision better than 1 cm. The target's size can be determined in advance with an accuracy better than 97%. Our results have implications for designing adaptive and fine-grained interactive user interfaces in ubiquitous and mixed-reality environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10818v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Dimitar Valkov, Pascal Kockwelp, Florian Daiber, Antonio Kr\"uger</dc:creator>
    </item>
    <item>
      <title>(De)composing Craft: An Elementary Grammar for Sharing Expertise in Craft Workflows</title>
      <link>https://arxiv.org/abs/2506.10891</link>
      <description>arXiv:2506.10891v1 Announce Type: new 
Abstract: Craft practices rely on evolving archives of skill and knowledge, developed through generations of craftspeople experimenting with designs, materials, and techniques. Better documentation of these practices enables the sharing of knowledge and expertise between sites and generations. However, most documentation focuses solely on the linear steps leading to final artifacts, neglecting the tacit knowledge necessary to improvise, or adapt workflows to meet the unique demands of each craft project. This omission limits knowledge sharing and reduces craft to a mechanical endeavor, rather than a sophisticated way of seeing, thinking, and doing. Drawing on expert interviews and literature from HCI, CSCW and the social sciences, we develop an elementary grammar to document improvisational actions of real-world craft practices. We demonstrate the utility of this grammar with an interface called CraftLink that can be used to analyze expert videos and semi-automatically generate documentation to convey material and contextual variations of craft practices. Our user study with expert crocheters (N=7) using this interface evaluates our grammar's effectiveness in capturing and sharing expert knowledge with other craftspeople, offering new pathways for computational systems to support collaborative archives of knowledge and practice within communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10891v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ritik Batra, Lydia Kim, Ilan Mandel, Amritansh Kwatra, Jane L. E., Steven J. Jackson, Thijs Roumen</dc:creator>
    </item>
    <item>
      <title>The Role of Generative AI in Facilitating Social Interactions: A Scoping Review</title>
      <link>https://arxiv.org/abs/2506.10927</link>
      <description>arXiv:2506.10927v1 Announce Type: new 
Abstract: Reduced social connectedness increasingly poses a threat to mental health, life expectancy, and general well-being. Generative AI (GAI) technologies, such as large language models (LLMs) and image generation tools, are increasingly integrated into applications aimed at enhancing human social experiences. Despite their growing presence, little is known about how these technologies influence social interactions. This scoping review investigates how GAI-based applications are currently designed to facilitate social interaction, what forms of social engagement they target, and which design and evaluation methodologies designers use to create and evaluate them. Through an analysis of 30 studies published since 2020, we identify key trends in application domains including storytelling, socio-emotional skills training, reminiscence, collaborative learning, music making, and general conversation. We highlight the role of participatory and co-design approaches in fostering both effective technology use and social engagement, while also examining socio-ethical concerns such as cultural bias and accessibility. This review underscores the potential of GAI to support dynamic and personalized interactions, but calls for greater attention to equitable design practices and inclusive evaluation strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10927v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>T. T. J. E. Arets, G. Perugia, M. Houben, W. A. IJsselsteijn</dc:creator>
    </item>
    <item>
      <title>Video-Mediated Emotion Disclosure: A Study of Mental Health Vlogging by People with Schizophrenia on YouTube</title>
      <link>https://arxiv.org/abs/2506.10932</link>
      <description>arXiv:2506.10932v1 Announce Type: new 
Abstract: Individuals with schizophrenia frequently experience intense emotions and often turn to vlogging as a medium for emotional expression. While previous research has predominantly focused on text based disclosure, little is known about how individuals construct narratives around emotions and emotional experiences in video blogs. Our study addresses this gap by analyzing 200 YouTube videos created by individuals with schizophrenia. Drawing on media research and self presentation theories, we developed a visual analysis framework to disentangle these videos. Our analysis revealed diverse practices of emotion disclosure through both verbal and visual channels, highlighting the dynamic interplay between these modes of expression. We found that the deliberate construction of visual elements, including environmental settings and specific aesthetic choices, appears to foster more supportive and engaged viewer responses. These findings underscore the need for future large scale quantitative research examining how visual features shape video mediated communication on social media platforms. Such investigations would inform the development of care centered video sharing platforms that better support individuals managing illness experiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10932v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.MM</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ASIS&amp;T 2025</arxiv:journal_reference>
      <dc:creator>Jiaying Lizzy Liu, Yan Zhang</dc:creator>
    </item>
    <item>
      <title>Instance-Based Transfer Learning with Similarity-Aware Subject Selection for Cross-Subject SSVEP-Based BCIs</title>
      <link>https://arxiv.org/abs/2506.10933</link>
      <description>arXiv:2506.10933v1 Announce Type: new 
Abstract: Steady-state visual evoked potential (SSVEP)-based brain-computer interfaces (BCIs) can achieve high recognition accuracy with sufficient training data. Transfer learning presents a promising solution to alleviate data requirements for the target subject by leveraging data from source subjects; however, effectively addressing individual variability among both target and source subjects remains a challenge. This paper proposes a novel transfer learning framework, termed instance-based task-related component analysis (iTRCA), which leverages knowledge from source subjects while considering their individual contributions. iTRCA extracts two types of features: (1) the subject-general feature, capturing shared information between source and target subjects in a common latent space, and (2) the subject-specific feature, preserving the unique characteristics of the target subject. To mitigate negative transfer, we further design an enhanced framework, subject selection-based iTRCA (SS-iTRCA), which integrates a similarity-based subject selection strategy to identify appropriate source subjects for transfer based on their task-related components (TRCs). Comparative evaluations on the Benchmark, BETA, and a self-collected dataset demonstrate the effectiveness of the proposed iTRCA and SS-iTRCA frameworks. This study provides a potential solution for developing high-performance SSVEP-based BCIs with reduced target subject data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10933v1</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/JBHI.2025.3577813</arxiv:DOI>
      <dc:creator>Ziwen Wang, Yue Zhang, Zhiqiang Zhang, Sheng Quan Xie, Alexander Lanzon, William P. Heath, Zhenhong Li</dc:creator>
    </item>
    <item>
      <title>Mind the Gap: Revealing Security Barriers through Situational Awareness of Small and Medium Business Key Decision-Makers</title>
      <link>https://arxiv.org/abs/2506.10025</link>
      <description>arXiv:2506.10025v1 Announce Type: cross 
Abstract: Key decision-makers in small and medium businesses (SMBs) often lack the awareness and knowledge to implement cybersecurity measures effectively. To gain a deeper understanding of how SMB executives navigate cybersecurity decision-making, we deployed a mixed-method approach, conducting semi-structured interviews (n=21) and online surveys (n=322) with SMB key decision-makers. Using thematic analysis, we revealed SMB decision-makers' perceived risks in terms of the digital assets they valued, and found reasons for their choice of defense measures and factors impacting security perception. We employed the situational awareness model to characterize decision-makers based on cybersecurity awareness, identifying those who have comparatively low awareness in the fight against adversaries. We further explored the relationship between awareness and business attributes, and constructed a holistic structural equation model to understand how awareness can be improved. Finally, we proposed interventions to help SMBs overcome potential challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10025v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuanhaur Chang, Oren Heller, Yaniv Shlomo, Iddo Bar-Noy, Ella Bokobza, Michal Grinstein-Weiss, Ning Zhang</dc:creator>
    </item>
    <item>
      <title>Multiverse Privacy Theory for Contextual Risks in Complex User-AI Interactions</title>
      <link>https://arxiv.org/abs/2506.10042</link>
      <description>arXiv:2506.10042v1 Announce Type: cross 
Abstract: In an era of increasing interaction with artificial intelligence (AI), users face evolving privacy decisions shaped by complex, uncertain factors. This paper introduces Multiverse Privacy Theory, a novel framework in which each privacy decision spawns a parallel universe, representing a distinct potential outcome based on user choices over time. By simulating these universes, this theory provides a foundation for understanding privacy through the lens of contextual integrity, evolving preferences, and probabilistic decision-making. Future work will explore its application using real-world, scenario-based survey data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10042v1</guid>
      <category>cs.CR</category>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ece Gumusel</dc:creator>
    </item>
    <item>
      <title>When Large Language Models are Reliable for Judging Empathic Communication</title>
      <link>https://arxiv.org/abs/2506.10150</link>
      <description>arXiv:2506.10150v1 Announce Type: cross 
Abstract: Large language models (LLMs) excel at generating empathic responses in text-based conversations. But, how reliably do they judge the nuances of empathic communication? We investigate this question by comparing how experts, crowdworkers, and LLMs annotate empathic communication across four evaluative frameworks drawn from psychology, natural language processing, and communications applied to 200 real-world conversations where one speaker shares a personal problem and the other offers support. Drawing on 3,150 expert annotations, 2,844 crowd annotations, and 3,150 LLM annotations, we assess inter-rater reliability between these three annotator groups. We find that expert agreement is high but varies across the frameworks' sub-components depending on their clarity, complexity, and subjectivity. We show that expert agreement offers a more informative benchmark for contextualizing LLM performance than standard classification metrics. Across all four frameworks, LLMs consistently approach this expert level benchmark and exceed the reliability of crowdworkers. These results demonstrate how LLMs, when validated on specific tasks with appropriate benchmarks, can support transparency and oversight in emotionally sensitive applications including their use as conversational companions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10150v1</guid>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aakriti Kumar, Nalin Poungpeth, Diyi Yang, Erina Farrell, Bruce Lambert, Matthew Groh</dc:creator>
    </item>
    <item>
      <title>Ground Reaction Force Estimation via Time-aware Knowledge Distillation</title>
      <link>https://arxiv.org/abs/2506.10265</link>
      <description>arXiv:2506.10265v1 Announce Type: cross 
Abstract: Human gait analysis with wearable sensors has been widely used in various applications, such as daily life healthcare, rehabilitation, physical therapy, and clinical diagnostics and monitoring. In particular, ground reaction force (GRF) provides critical information about how the body interacts with the ground during locomotion. Although instrumented treadmills have been widely used as the gold standard for measuring GRF during walking, their lack of portability and high cost make them impractical for many applications. As an alternative, low-cost, portable, wearable insole sensors have been utilized to measure GRF; however, these sensors are susceptible to noise and disturbance and are less accurate than treadmill measurements. To address these challenges, we propose a Time-aware Knowledge Distillation framework for GRF estimation from insole sensor data. This framework leverages similarity and temporal features within a mini-batch during the knowledge distillation process, effectively capturing the complementary relationships between features and the sequential properties of the target and input data. The performance of the lightweight models distilled through this framework was evaluated by comparing GRF estimations from insole sensor data against measurements from an instrumented treadmill. Empirical results demonstrated that Time-aware Knowledge Distillation outperforms current baselines in GRF estimation from wearable sensor data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10265v1</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/JIOT.2025.3578012</arxiv:DOI>
      <arxiv:journal_reference>IEEE Internet of Things Journal, 2025</arxiv:journal_reference>
      <dc:creator>Eun Som Jeon, Sinjini Mitra, Jisoo Lee, Omik M. Save, Ankita Shukla, Hyunglae Lee, Pavan Turaga</dc:creator>
    </item>
    <item>
      <title>Collective Bargaining in the Information Economy Can Address AI-Driven Power Concentration</title>
      <link>https://arxiv.org/abs/2506.10272</link>
      <description>arXiv:2506.10272v1 Announce Type: cross 
Abstract: This position paper argues that there is an urgent need to restructure markets for the information that goes into AI systems. Specifically, producers of information goods (such as journalists, researchers, and creative professionals) need to be able to collectively bargain with AI product builders in order to receive reasonable terms and a sustainable return on the informational value they contribute. We argue that without increased market coordination or collective bargaining on the side of these primary information producers, AI will exacerbate a large-scale "information market failure" that will lead not only to undesirable concentration of capital, but also to a potential "ecological collapse" in the informational commons. On the other hand, collective bargaining in the information economy can create market frictions and aligned incentives necessary for a pro-social, sustainable AI future. We provide concrete actions that can be taken to support a coalition-based approach to achieve this goal. For example, researchers and developers can establish technical mechanisms such as federated data management tools and explainable data value estimations, to inform and facilitate collective bargaining in the information economy. Additionally, regulatory and policy interventions may be introduced to support trusted data intermediary organizations representing guilds or syndicates of information producers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10272v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Vincent, Matthew Prewitt, Hanlin Li</dc:creator>
    </item>
    <item>
      <title>MLLM-Based UI2Code Automation Guided by UI Layout Information</title>
      <link>https://arxiv.org/abs/2506.10376</link>
      <description>arXiv:2506.10376v1 Announce Type: cross 
Abstract: Converting user interfaces into code (UI2Code) is a crucial step in website development, which is time-consuming and labor-intensive. The automation of UI2Code is essential to streamline this task, beneficial for improving the development efficiency. There exist deep learning-based methods for the task; however, they heavily rely on a large amount of labeled training data and struggle with generalizing to real-world, unseen web page designs. The advent of Multimodal Large Language Models (MLLMs) presents potential for alleviating the issue, but they are difficult to comprehend the complex layouts in UIs and generate the accurate code with layout preserved. To address these issues, we propose LayoutCoder, a novel MLLM-based framework generating UI code from real-world webpage images, which includes three key modules: (1) Element Relation Construction, which aims at capturing UI layout by identifying and grouping components with similar structures; (2) UI Layout Parsing, which aims at generating UI layout trees for guiding the subsequent code generation process; and (3) Layout-Guided Code Fusion, which aims at producing the accurate code with layout preserved. For evaluation, we build a new benchmark dataset which involves 350 real-world websites named Snap2Code, divided into seen and unseen parts for mitigating the data leakage issue, besides the popular dataset Design2Code. Extensive evaluation shows the superior performance of LayoutCoder over the state-of-the-art approaches. Compared with the best-performing baseline, LayoutCoder improves 10.14% in the BLEU score and 3.95% in the CLIP score on average across all datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10376v1</guid>
      <category>cs.SE</category>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3728925</arxiv:DOI>
      <dc:creator>Fan Wu, Cuiyun Gao, Shuqing Li, Xin-Cheng Wen, Qing Liao</dc:creator>
    </item>
    <item>
      <title>Primender Sequence: A Novel Mathematical Construct for Testing Symbolic Inference and AI Reasoning</title>
      <link>https://arxiv.org/abs/2506.10585</link>
      <description>arXiv:2506.10585v1 Announce Type: cross 
Abstract: This paper introduces the Primender sequence, a novel integer sequence defined by a hybrid rule that combines classical primality with modular digit-based conditions. Specifically, a number n is included in the sequence if it is prime or ends with a prime number of unit digit or any length. In other words, numbers which are primes or have at least one prime suffix. The resulting sequence exhibits a deterministic yet non-trivial structure, blending number-theoretic properties with symbolic patterning. We propose the Primender sequence as a benchmark for evaluating the symbolic reasoning capabilities of Large Language Models (LLMs). The study is motivated by the need for interpretable, rule-based testbeds that can assess an LLM's ability to infer hidden rules, validate mathematical hypotheses, and generalize symbolic logic at scale. A key hypothesis explored is: Whenever a number in the Primender sequence is exactly one more than the largest prime less than or equal to it, the difference between it and the previous number in the sequence is also 1. We design a structured prompt and evaluation framework to test this hypothesis across multiple state-of-the-art LLMs, including ChatGPT, Copilot, DeepSeek, Gemini, Grok, and LLaMA. The models are tasked with identifying the underlying rule, validating the hypothesis, and generating the next 100,000 terms of the sequence. Comparative metrics such as rule inference accuracy, hypothesis evaluation, sequence validity, and symbolic explanation quality are used to assess model performance. This work contributes a novel mathematical construct and a reproducible methodology for benchmarking LLMs in symbolic reasoning, hypothesis testing, and scalable pattern generalization - bridging the domains of number theory, artificial intelligence, and software engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10585v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.SC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohd Anwar Jamal Faiz</dc:creator>
    </item>
    <item>
      <title>Agentic Semantic Control for Autonomous Wireless Space Networks: Extending Space-O-RAN with MCP-Driven Distributed Intelligence</title>
      <link>https://arxiv.org/abs/2506.10925</link>
      <description>arXiv:2506.10925v1 Announce Type: cross 
Abstract: Lunar surface operations impose stringent requirements on wireless communication systems, including autonomy, robustness to disruption, and the ability to adapt to environmental and mission-driven context. While Space-O-RAN provides a distributed orchestration model aligned with 3GPP standards, its decision logic is limited to static policies and lacks semantic integration. We propose a novel extension incorporating a semantic agentic layer enabled by the Model Context Protocol (MCP) and Agent-to-Agent (A2A) communication protocols, allowing context-aware decision making across real-time, near-real-time, and non-real-time control layers. Distributed cognitive agents deployed in rovers, landers, and lunar base stations implement wireless-aware coordination strategies, including delay-adaptive reasoning and bandwidth-aware semantic compression, while interacting with multiple MCP servers to reason over telemetry, locomotion planning, and mission constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10925v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eduardo Baena, Paolo Testolina, Michele Polese, Sergi Aliaga, Andrew Benincasa, Dimitrios Koutsonikolas, Josep Jornet, Tommaso Melodia</dc:creator>
    </item>
    <item>
      <title>The Urban Model Platform: A Public Backbone for Modeling and Simulation in Urban Digital Twins</title>
      <link>https://arxiv.org/abs/2506.10964</link>
      <description>arXiv:2506.10964v1 Announce Type: cross 
Abstract: Urban digital twins are increasingly perceived as a way to pool the growing digital resources of cities for the purpose of a more sustainable and integrated urban planning. Models and simulations are central to this undertaking: They enable "what if?" scenarios, create insights and describe relationships between the vast data that is being collected. However, the process of integrating and subsequently using models in urban digital twins is an inherently complex undertaking. It raises questions about how to represent urban complexity, how to deal with uncertain assUrban Model Platformtions and modeling paradigms, and how to capture underlying power relations. Existent approaches in the domain largely focus on monolithic and centralized solutions in the tradition of neoliberal city-making, oftentimes prohibiting pluralistic and open interoperable models. Using a participatory design for participatory systems approach together with the City of Hamburg, Germany, we find that an open Urban Model Platform can function both as a public technological backbone for modeling and simulation in urban digital twins and as a socio-technical framework for a collaborative and pluralistic representation of urban processes. Such a platform builds on open standards, allows for a decentralized integration of models, enables communication between models and supports a multi-model approach to representing urban systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10964v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rico H Herzog, Till Degkwitz, Trivik Verma</dc:creator>
    </item>
    <item>
      <title>AutoMind: Adaptive Knowledgeable Agent for Automated Data Science</title>
      <link>https://arxiv.org/abs/2506.10974</link>
      <description>arXiv:2506.10974v1 Announce Type: cross 
Abstract: Large Language Model (LLM) agents have shown great potential in addressing real-world data science problems. LLM-driven data science agents promise to automate the entire machine learning pipeline, yet their real-world effectiveness remains limited. Existing frameworks depend on rigid, pre-defined workflows and inflexible coding strategies; consequently, they excel only on relatively simple, classical problems and fail to capture the empirical expertise that human practitioners bring to complex, innovative tasks. In this work, we introduce AutoMind, an adaptive, knowledgeable LLM-agent framework that overcomes these deficiencies through three key advances: (1) a curated expert knowledge base that grounds the agent in domain expert knowledge, (2) an agentic knowledgeable tree search algorithm that strategically explores possible solutions, and (3) a self-adaptive coding strategy that dynamically tailors code generation to task complexity. Evaluations on two automated data science benchmarks demonstrate that AutoMind delivers superior performance versus state-of-the-art baselines. Additional analyses confirm favorable effectiveness, efficiency, and qualitative solution quality, highlighting AutoMind as an efficient and robust step toward fully automated data science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10974v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixin Ou, Yujie Luo, Jingsheng Zheng, Lanning Wei, Shuofei Qiao, Jintian Zhang, Da Zheng, Huajun Chen, Ningyu Zhang</dc:creator>
    </item>
    <item>
      <title>Distortion-Aware Brushing for Reliable Cluster Analysis in Multidimensional Projections</title>
      <link>https://arxiv.org/abs/2201.06379</link>
      <description>arXiv:2201.06379v2 Announce Type: replace 
Abstract: Brushing is a common interaction technique in 2D scatterplots, allowing users to select clustered points within a continuous, enclosed region for further analysis or filtering. However, applying conventional brushing to 2D representations of multidimensional (MD) data, i.e., Multidimensional Projections (MDPs), can lead to unreliable cluster analysis due to MDP-induced distortions that inaccurately represent the cluster structure of the original MD data. To alleviate this problem, we introduce a novel brushing technique for MDPs called Distortion-aware brushing. As users perform brushing, Distortion-aware brushing corrects distortions around the currently brushed points by dynamically relocating points in the projection, pulling data points close to the brushed points in MD space while pushing distant ones apart. This dynamic adjustment helps users brush MD clusters more accurately, leading to more reliable cluster analysis. Our user studies with 24 participants show that Distortion-aware brushing significantly outperforms previous brushing techniques for MDPs in accurately separating clusters in the MD space and remains robust against distortions. We further demonstrate the effectiveness of our technique through two use cases: (1) conducting cluster analysis of geospatial data and (2) interactively labeling MD clusters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.06379v2</guid>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hyeon Jeon, Micha\"el Aupetit, Soohyun Lee, Kwon Ko, Youngtaek Kim, Ghulam Jilani Quadri, Jinwook Seo</dc:creator>
    </item>
    <item>
      <title>Visualizationary: Automating Design Feedback for Visualization Designers using LLMs</title>
      <link>https://arxiv.org/abs/2409.13109</link>
      <description>arXiv:2409.13109v3 Announce Type: replace 
Abstract: Interactive visualization editors empower users to author visualizations without writing code, but do not provide guidance on the art and craft of effective visual communication. In this paper, we explore the potential of using an off-the-shelf large language models (LLMs) to provide actionable and customized feedback to visualization designers. Our implementation, VISUALIZATIONARY, demonstrates how ChatGPT can be used for this purpose through two key components: a preamble of visualization design guidelines and a suite of perceptual filters that extract salient metrics from a visualization image. We present findings from a longitudinal user study involving 13 visualization designers-6 novices, 4 intermediates, and 3 experts-who authored a new visualization from scratch over several days. Our results indicate that providing guidance in natural language via an LLM can aid even seasoned designers in refining their visualizations. All our supplemental materials are available at https://osf.io/v7hu8.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13109v3</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sungbok Shin, Sanghyun Hong, Niklas Elmqvist</dc:creator>
    </item>
    <item>
      <title>A review of theories and models utilized by empirical studies about mental health help-seeking and implications for future research</title>
      <link>https://arxiv.org/abs/2502.14082</link>
      <description>arXiv:2502.14082v2 Announce Type: replace 
Abstract: Purpose: With the rise of mental health risks globally, it is urgent to provide effective mental health support. However, a holistic understanding of how people seek help for mental health problems remains limited, impeding the development of evidence-based intervention programs to facilitate help-seeking behavior. This study reviews current theories that guide empirical research on young adults' help-seeking behavior using technologies, identifies limitations in existing frameworks, and proposes directions for future research.
  Methods: We searched databases that are most likely to contain mental health help-seeking practices in relation to information technology, including PubMed, ACM Digital Library, Web of Science, PsycInfo, ScienceDirect, EBSCO, and Cochrane Library.
  Results: Of 2443 abstracts reviewed, 43 studies met the criteria and were included in the analysis. We identified 16 theories and models. They represent seven perspectives to view mental health help-seeking and reveal factors such as accessibility, stigma, and social support as key factors influencing help-seeking.
  Limitations: We summarized the theories and models and categorized them based on their primary perspectives. Cross-perspective connections could be explored in future reviews.
  Conclusions: A holistic approach to creating culturally sensitive multi-level interventions that consider individual, interpersonal, and community factors is needed to advance effective mental health help-seeking support strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14082v2</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaying "Lizzy" Liu, Yongjie Sha, Yan Zhang</dc:creator>
    </item>
    <item>
      <title>Enhancing Critical Thinking in Generative AI Search with Metacognitive Prompts</title>
      <link>https://arxiv.org/abs/2505.24014</link>
      <description>arXiv:2505.24014v2 Announce Type: replace 
Abstract: The growing use of Generative AI (GenAI) conversational search tools has raised concerns about their effects on people's metacognitive engagement, critical thinking, and learning. As people increasingly rely on GenAI to perform tasks such as analyzing and applying information, they may become less actively engaged in thinking and learning. This study examines whether metacognitive prompts - designed to encourage people to pause, reflect, assess their understanding, and consider multiple perspectives - can support critical thinking during GenAI-based search. We conducted a user study (N=40) with university students to investigate the impact of metacognitive prompts on their thought processes and search behaviors while searching with a GenAI tool. We found that these prompts led to more active engagement, prompting students to explore a broader range of topics and engage in deeper inquiry through follow-up queries. Students reported that the prompts were especially helpful for considering overlooked perspectives, promoting evaluation of AI responses, and identifying key takeaways. Additionally, the effectiveness of these prompts was influenced by students' metacognitive flexibility. Our findings highlight the potential of metacognitive prompts to foster critical thinking and provide insights for designing and implementing metacognitive support in human-AI interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.24014v2</guid>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anjali Singh, Zhitong Guan, Soo Young Rieh</dc:creator>
    </item>
    <item>
      <title>LLM-D12: A Dual-Dimensional Scale of Instrumental and Relational Dependencies on Large Language Models</title>
      <link>https://arxiv.org/abs/2506.06874</link>
      <description>arXiv:2506.06874v2 Announce Type: replace 
Abstract: There is growing interest in understanding how people interact with large language models (LLMs) and whether such models elicit dependency or even addictive behaviour. Validated tools to assess the extent to which individuals may become dependent on LLMs are scarce and primarily build on classic behavioral addiction symptoms, adapted to the context of LLM use. We view this as a conceptual limitation, as the LLM-human relationship is more nuanced and warrants a fresh and distinct perspective. To address this gap, we developed and validated a new 12-item questionnaire to measure LLM dependency, referred to as LLM-D12. The scale was based on the authors' prior theoretical work, with items developed accordingly and responses collected from 526 participants in the UK. Exploratory and confirmatory factor analyses, performed on separate halves of the total sample using a split-sample approach, supported a two-factor structure: Instrumental Dependency (six items) and Relationship Dependency (six items). Instrumental Dependency reflects the extent to which individuals rely on LLMs to support or collaborate in decision-making and cognitive tasks. Relationship Dependency captures the tendency to perceive LLMs as socially meaningful, sentient, or companion-like entities. The two-factor structure demonstrated excellent internal consistency and clear discriminant validity. External validation confirmed both the conceptual foundation and the distinction between the two subscales. The psychometric properties and structure of our LLM-D12 scale were interpreted in light of the emerging view that dependency on LLMs does not necessarily indicate dysfunction but may still reflect reliance levels that could become problematic in certain contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06874v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ala Yankouskaya, Areej B. Babiker, Syeda W. F. Rizvi, Sameha Alshakhsi, Magnus Liebherr, Raian Ali</dc:creator>
    </item>
    <item>
      <title>Help or Hindrance: Understanding the Impact of Robot Communication in Action Teams</title>
      <link>https://arxiv.org/abs/2506.08892</link>
      <description>arXiv:2506.08892v2 Announce Type: replace 
Abstract: The human-robot interaction (HRI) field has recognized the importance of enabling robots to interact with teams. Human teams rely on effective communication for successful collaboration in time-sensitive environments. Robots can play a role in enhancing team coordination through real-time assistance. Despite significant progress in human-robot teaming research, there remains an essential gap in how robots can effectively communicate with action teams using multimodal interaction cues in time-sensitive environments. This study addresses this knowledge gap in an experimental in-lab study to investigate how multimodal robot communication in action teams affects workload and human perception of robots. We explore team collaboration in a medical training scenario where a robotic crash cart (RCC) provides verbal and non-verbal cues to help users remember to perform iterative tasks and search for supplies. Our findings show that verbal cues for object search tasks and visual cues for task reminders reduce team workload and increase perceived ease of use and perceived usefulness more effectively than a robot with no feedback. Our work contributes to multimodal interaction research in the HRI field, highlighting the need for more human-robot teaming research to understand best practices for integrating collaborative robots in time-sensitive environments such as in hospitals, search and rescue, and manufacturing applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08892v2</guid>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tauhid Tanjim, Jonathan St. George, Kevin Ching, Angelique Taylor</dc:creator>
    </item>
    <item>
      <title>Constrained Human-AI Cooperation: An Inclusive Embodied Social Intelligence Challenge</title>
      <link>https://arxiv.org/abs/2411.01796</link>
      <description>arXiv:2411.01796v3 Announce Type: replace-cross 
Abstract: We introduce Constrained Human-AI Cooperation (CHAIC), an inclusive embodied social intelligence challenge designed to test social perception and cooperation in embodied agents. In CHAIC, the goal is for an embodied agent equipped with egocentric observations to assist a human who may be operating under physical constraints -- e.g., unable to reach high places or confined to a wheelchair -- in performing common household or outdoor tasks as efficiently as possible. To achieve this, a successful helper must: (1) infer the human's intents and constraints by following the human and observing their behaviors (social perception), and (2) make a cooperative plan tailored to the human partner to solve the task as quickly as possible, working together as a team (cooperative planning). To benchmark this challenge, we create four new agents with real physical constraints and eight long-horizon tasks featuring both indoor and outdoor scenes with various constraints, emergency events, and potential risks. We benchmark planning- and learning-based baselines on the challenge and introduce a new method that leverages large language models and behavior modeling. Empirical evaluations demonstrate the effectiveness of our benchmark in enabling systematic assessment of key aspects of machine social intelligence. Our benchmark and code are publicly available at https://github.com/UMass-Embodied-AGI/CHAIC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01796v3</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weihua Du, Qiushi Lyu, Jiaming Shan, Zhenting Qi, Hongxin Zhang, Sunli Chen, Andi Peng, Tianmin Shu, Kwonjoon Lee, Behzad Dariush, Chuang Gan</dc:creator>
    </item>
    <item>
      <title>Towards Scalable Defenses against Intimate Partner Infiltrations</title>
      <link>https://arxiv.org/abs/2502.03682</link>
      <description>arXiv:2502.03682v2 Announce Type: replace-cross 
Abstract: Intimate Partner Infiltration (IPI)--a type of Intimate Partner Violence (IPV) that typically requires physical access to a victim's device--is a pervasive concern around the world, often manifesting through digital surveillance, control, and monitoring. Unlike conventional cyberattacks, IPI perpetrators leverage close proximity and personal knowledge to circumvent standard protections, underscoring the need for targeted interventions. While security clinics and other human-centered approaches effectively tailor solutions for victims, their scalability remains constrained by resource limitations and the need for specialized counseling. We present AID, an Automated IPI Detection system that continuously monitors for unauthorized access and suspicious behaviors on smartphones. AID employs a unified architecture to process multimodal signals stealthily and preserve user privacy. A brief calibration phase upon installation enables AID to adapt to each user's behavioral patterns, achieving high accuracy with minimal false alarms. Our 27-participant user study demonstrates that AID achieves highly accurate detection of non-owner access and fine-grained IPI-related activities, attaining a false positive rate of 1.6%, which is 11x lower than existing methods, and an end-to-end F1 score of 0.981. These findings suggest that AID can serve as a forensic tool that security clinics can deploy to scale their ability to identify IPI tactics and deliver personalized, far-reaching support to survivors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03682v2</guid>
      <category>cs.CR</category>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Weisi Yang, Shinan Liu, Feng Xiao, Nick Feamster, Stephen Xia</dc:creator>
    </item>
    <item>
      <title>The Automated but Risky Game: Modeling Agent-to-Agent Negotiations and Transactions in Consumer Markets</title>
      <link>https://arxiv.org/abs/2506.00073</link>
      <description>arXiv:2506.00073v2 Announce Type: replace-cross 
Abstract: AI agents are increasingly used in consumer-facing applications to assist with tasks such as product search, negotiation, and transaction execution. In this paper, we explore a future scenario where both consumers and merchants authorize AI agents to fully automate negotiations and transactions. We aim to answer two key questions: (1) Do different LLM agents vary in their ability to secure favorable deals for users? (2) What risks arise from fully automating deal-making with AI agents in consumer markets? To address these questions, we develop an experimental framework that evaluates the performance of various LLM agents in real-world negotiation and transaction settings. Our findings reveal that AI-mediated deal-making is an inherently imbalanced game -- different agents achieve significantly different outcomes for their users. Moreover, behavioral anomalies in LLMs can result in financial losses for both consumers and merchants, such as overspending or accepting unreasonable deals. These results underscore that while automation can improve efficiency, it also introduces substantial risks. Users should exercise caution when delegating business decisions to AI agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00073v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.MA</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shenzhe Zhu, Jiao Sun, Yi Nian, Tobin South, Alex Pentland, Jiaxin Pei</dc:creator>
    </item>
    <item>
      <title>Future of Work with AI Agents: Auditing Automation and Augmentation Potential across the U.S. Workforce</title>
      <link>https://arxiv.org/abs/2506.06576</link>
      <description>arXiv:2506.06576v2 Announce Type: replace-cross 
Abstract: The rapid rise of compound AI systems (a.k.a., AI agents) is reshaping the labor market, raising concerns about job displacement, diminished human agency, and overreliance on automation. Yet, we lack a systematic understanding of the evolving landscape. In this paper, we address this gap by introducing a novel auditing framework to assess which occupational tasks workers want AI agents to automate or augment, and how those desires align with the current technological capabilities. Our framework features an audio-enhanced mini-interview to capture nuanced worker desires and introduces the Human Agency Scale (HAS) as a shared language to quantify the preferred level of human involvement. Using this framework, we construct the WORKBank database, building on the U.S. Department of Labor's O*NET database, to capture preferences from 1,500 domain workers and capability assessments from AI experts across over 844 tasks spanning 104 occupations. Jointly considering the desire and technological capability divides tasks in WORKBank into four zones: Automation "Green Light" Zone, Automation "Red Light" Zone, R&amp;D Opportunity Zone, Low Priority Zone. This highlights critical mismatches and opportunities for AI agent development. Moving beyond a simple automate-or-not dichotomy, our results reveal diverse HAS profiles across occupations, reflecting heterogeneous expectations for human involvement. Moreover, our study offers early signals of how AI agent integration may reshape the core human competencies, shifting from information-focused skills to interpersonal ones. These findings underscore the importance of aligning AI agent development with human desires and preparing workers for evolving workplace dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06576v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijia Shao, Humishka Zope, Yucheng Jiang, Jiaxin Pei, David Nguyen, Erik Brynjolfsson, Diyi Yang</dc:creator>
    </item>
    <item>
      <title>Investigating the Relationship Between Physical Activity and Tailored Behavior Change Messaging: Connecting Contextual Bandit with Large Language Models</title>
      <link>https://arxiv.org/abs/2506.07275</link>
      <description>arXiv:2506.07275v2 Announce Type: replace-cross 
Abstract: Machine learning approaches, such as contextual multi-armed bandit (cMAB) algorithms, offer a promising strategy to reduce sedentary behavior by delivering personalized interventions to encourage physical activity. However, cMAB algorithms typically require large participant samples to learn effectively and may overlook key psychological factors that are not explicitly encoded in the model. In this study, we propose a hybrid approach that combines cMAB for selecting intervention types with large language models (LLMs) to personalize message content. We evaluate four intervention types: behavioral self-monitoring, gain-framed, loss-framed, and social comparison, each delivered as a motivational message aimed at increasing motivation for physical activity and daily step count. Message content is further personalized using dynamic contextual factors including daily fluctuations in self-efficacy, social influence, and regulatory focus. Over a seven-day trial, participants receive daily messages assigned by one of four models: cMAB alone, LLM alone, combined cMAB with LLM personalization (cMABxLLM), or equal randomization (RCT). Outcomes include daily step count and message acceptance, assessed via ecological momentary assessments (EMAs). We apply a causal inference framework to evaluate the effects of each model. Our findings offer new insights into the complementary roles of LLM-based personalization and cMAB adaptation in promoting physical activity through personalized behavioral messaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07275v2</guid>
      <category>cs.LG</category>
      <category>cs.HC</category>
      <category>stat.AP</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haochen Song, Dominik Hofer, Rania Islambouli, Laura Hawkins, Ananya Bhattacharjee, Meredith Franklin, Joseph Jay Williams</dc:creator>
    </item>
    <item>
      <title>Understanding Human-AI Trust in Education</title>
      <link>https://arxiv.org/abs/2506.09160</link>
      <description>arXiv:2506.09160v2 Announce Type: replace-cross 
Abstract: As AI chatbots become increasingly integrated in education, students are turning to these systems for guidance, feedback, and information. However, the anthropomorphic characteristics of these chatbots create ambiguity regarding whether students develop trust toward them as they would a human peer or instructor, based in interpersonal trust, or as they would any other piece of technology, based in technology trust. This ambiguity presents theoretical challenges, as interpersonal trust models may inappropriately ascribe human intentionality and morality to AI, while technology trust models were developed for non-social technologies, leaving their applicability to anthropomorphic systems unclear. To address this gap, we investigate how human-like and system-like trusting beliefs comparatively influence students' perceived enjoyment, trusting intention, behavioral intention to use, and perceived usefulness of an AI chatbot - factors associated with students' engagement and learning outcomes. Through partial least squares structural equation modeling, we found that human-like and system-like trust significantly influenced student perceptions, with varied effects. Human-like trust more strongly predicted trusting intention, while system-like trust better predicted behavioral intention and perceived usefulness. Both had similar effects on perceived enjoyment. Given the partial explanatory power of each type of trust, we propose that students develop a distinct form of trust with AI chatbots (human-AI trust) that differs from human-human and human-technology models of trust. Our findings highlight the need for new theoretical frameworks specific to human-AI trust and offer practical insights for fostering appropriately calibrated trust, which is critical for the effective adoption and pedagogical impact of AI in education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09160v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <pubDate>Fri, 13 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Griffin Pitts, Sanaz Motamedi</dc:creator>
    </item>
  </channel>
</rss>
