<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.CP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.CP</link>
    <description>q-fin.CP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.CP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 Jan 2026 05:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Breaking the Dimensional Barrier: Dynamic Portfolio Choice with Parameter Uncertainty via Pontryagin Projection</title>
      <link>https://arxiv.org/abs/2601.03175</link>
      <description>arXiv:2601.03175v1 Announce Type: new 
Abstract: We study continuous-time portfolio choice in diffusion markets with parameter $\theta \in \Theta$ and uncertainty law $q(d\theta)$. Nature draws latent $\theta \sim q$ at time 0; the investor cannot observe it and must deploy a single $\theta$-blind feedback policy maximizing an ex-ante CRRA objective averaged over diffusion noise and $\theta$. Our methods access $q$ only by sampling and assume no parametric form. We extend Pontryagin-Guided Direct Policy Optimization (PG-DPO) by sampling $\theta$ inside the simulator and computing discrete-time gradients via backpropagation through time (BPTT), and we propose projected PG-DPO (P-PGDPO) that projects costate estimates to satisfy the $q$-aggregated Pontryagin first-order condition, yielding a deployable rule. We prove a BPTT-PMP correspondence uniform on compacts and a residual-based $\theta$-blind policy-gap bound under local stability with explicit discretization/Monte Carlo errors; experiments show projection-driven stability and accurate decision-time benchmark recovery in high dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03175v1</guid>
      <category>q-fin.CP</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeonggyu Huh, Hyeng Keun Koo</dc:creator>
    </item>
  </channel>
</rss>
