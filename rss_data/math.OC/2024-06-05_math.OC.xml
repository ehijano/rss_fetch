<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Jun 2024 04:00:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Asymptotic synchronization of Kuramoto oscillators with time delay and non-universal interaction</title>
      <link>https://arxiv.org/abs/2406.01703</link>
      <description>arXiv:2406.01703v1 Announce Type: new 
Abstract: We study the emergence of synchronization in the Kuramoto model on a digraph in the presence of time delays. Assuming the digraph is strongly connected, we first establish a uniform bound on the phase diameter and subsequently prove the asymptotic frequency synchronization of the oscillators under suitable assumptions on the initial configurations. In the case of an all-to-all connection, we obtain an exponential synchronization estimate. Additionally, we present numerical simulations, providing further insights into the synchronization and oscillatory behaviors of the oscillator frequencies depending on the network structure and the magnitude of the time delay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01703v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Conor Carty, Young-Pil Choi, Chiara Cicolani, Cristina Pignotti</dc:creator>
    </item>
    <item>
      <title>Provably Feasible and Stable White-Box Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2406.01763</link>
      <description>arXiv:2406.01763v1 Announce Type: new 
Abstract: We study the problem of Trajectory Optimization (TO) for a general class of stiff and constrained dynamic systems. We establish a set of mild assumptions, under which we show that TO converges numerically stably to a locally optimal and feasible solution up to arbitrary user-specified error tolerance. Our key observation is that all prior works use SQP as a black-box solver, where a TO problem is formulated as a Nonlinear Program (NLP) and the underlying SQP solver is not allowed to modify the NLP. Instead, we propose a white-box TO solver, where the SQP solver is informed with characteristics of the objective function and the dynamic system. It then uses these characteristics to derive approximate dynamic systems and customize the discretization schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01763v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zherong Pan, Yifan Zhu</dc:creator>
    </item>
    <item>
      <title>Nonlinear Eigen-approach ADMM for Sparse Optimization on Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2406.01885</link>
      <description>arXiv:2406.01885v1 Announce Type: new 
Abstract: With the growing interest and applications in machine learning and data science, finding an efficient method to sparse analysis the high-dimensional data and optimizing a dimension reduction model to extract lower dimensional features has becoming more and more important. Orthogonal constraints (Stiefel manifold) is a commonly met constraint in these applications, and the sparsity is usually enforced through the element-wise L1 norm. Many applications can be found on optimization over Stiefel manifold within the area of physics and machine learning. In this paper, we propose a novel idea by tackling the Stiefel manifold through an nonlinear eigen-approach by first using ADMM to split the problem into smooth optimization over manifold and convex non-smooth optimization, and then transforming the former into the form of nonlinear eigenvalue problem with eigenvector dependency (NEPv) which is solved by self-consistent field (SCF) iteration, and the latter can be found to have an closed-form solution through proximal gradient. Compared with existing methods, our proposed algorithm takes the advantage of specific structure of the objective function, and has efficient convergence results under mild assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01885v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawei Wang, Rencang Li, Richard Yi Da Xu</dc:creator>
    </item>
    <item>
      <title>The Role of Level-Set Geometry on the Performance of PDHG for Conic Linear Optimization</title>
      <link>https://arxiv.org/abs/2406.01942</link>
      <description>arXiv:2406.01942v1 Announce Type: new 
Abstract: We consider solving huge-scale instances of (convex) conic linear optimization problems, at the scale where matrix-factorization-free methods are attractive or necessary. The restarted primal-dual hybrid gradient method (rPDHG) -- with heuristic enhancements and GPU implementation -- has been very successful in solving huge-scale linear programming (LP) problems; however its application to more general conic convex optimization problems is not so well-studied. We analyze the theoretical and practical performance of rPDHG for general (convex) conic linear optimization, and LP as a special case thereof. We show a relationship between the geometry of the primal-dual (sub-)level sets $W_\varepsilon$ and the convergence rate of rPDHG. Specifically, we prove a bound on the convergence rate of rPDHG that improves when there is a primal-dual (sub-)level set $W_\varepsilon$ for which (i) $W_\varepsilon$ is close to the optimal solution set (in Hausdorff distance), and (ii) the ratio of the diameter to the "conic radius" of $W_\varepsilon$ is small. And in the special case of LP problems, the performance of rPDHG is bounded only by this ratio applied to the (sub-)level set corresponding to the best non-optimal extreme point. Depending on the problem instance, this ratio can take on extreme values and can result in poor performance of rPDHG both in theory and in practice. To address this issue, we show how central-path-based linear transformations -- including conic rescaling -- can markedly enhance the convergence rate of rPDHG. Furthermore, we present computational results that demonstrate how such rescalings can accelerate convergence to high-accuracy solutions, and lead to more efficient methods for huge-scale linear optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01942v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zikai Xiong, Robert M. Freund</dc:creator>
    </item>
    <item>
      <title>Recursive Polynomial Method for Fast Collision Avoidance Maneuver Design</title>
      <link>https://arxiv.org/abs/2406.01949</link>
      <description>arXiv:2406.01949v1 Announce Type: new 
Abstract: A simple and reliable algorithm for collision avoidance maneuvers (CAMs), capable of computing impulsive, multi-impulsive, and low-thrust maneuvers, is proposed. The probability of collision (PoC) is approximated by a polynomial of arbitrary order as a function of the control, transforming the CAM designinto a polynomial program. The solution procedure is initiated by computing the CAM via a first-order greedy optimization approach, wherein the control action is applied in the direction of the gradient of PoC to maximize its change. Successively, the polynomial is truncated at higher orders, and the solution of the previous order is used to linearize the constraint. This enables achieving accurate solutions even for highly nonlinear safety metrics and dynamics. Since the optimization process comprises only polynomial evaluations, the method is computationally efficient, with run times typically below 1 s. Moreover, no restrictions on the considered dynamics are necessary; therefore, results are shown for Keplerian, J2, and circular restricted three-body problem dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01949v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeno Pavanello, Laura Pirovano, Roberto Armellin</dc:creator>
    </item>
    <item>
      <title>Adaptive Variance Reduction for Stochastic Optimization under Weaker Assumptions</title>
      <link>https://arxiv.org/abs/2406.01959</link>
      <description>arXiv:2406.01959v1 Announce Type: new 
Abstract: This paper explores adaptive variance reduction methods for stochastic optimization based on the STORM technique. Existing adaptive extensions of STORM rely on strong assumptions like bounded gradients and bounded function values, or suffer an additional $\mathcal{O}(\log T)$ term in the convergence rate. To address these limitations, we introduce a novel adaptive STORM method that achieves an optimal convergence rate of $\mathcal{O}(T^{-1/3})$ for non-convex functions with our newly designed learning rate strategy. Compared with existing approaches, our method requires weaker assumptions and attains the optimal convergence rate without the additional $\mathcal{O}(\log T)$ term. We also extend the proposed technique to stochastic compositional optimization, obtaining the same optimal rate of $\mathcal{O}(T^{-1/3})$. Furthermore, we investigate the non-convex finite-sum problem and develop another innovative adaptive variance reduction method that achieves an optimal convergence rate of $\mathcal{O}(n^{1/4} T^{-1/2} )$, where $n$ represents the number of component functions. Numerical experiments across various tasks validate the effectiveness of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01959v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Jiang, Sifan Yang, Yibo Wang, Lijun Zhang</dc:creator>
    </item>
    <item>
      <title>Subspace Quasi-Newton Method with Gradient Approximation</title>
      <link>https://arxiv.org/abs/2406.01965</link>
      <description>arXiv:2406.01965v1 Announce Type: new 
Abstract: In recent years, various subspace algorithms have been developed to handle large-scale optimization problems. Although existing subspace Newton methods require fewer iterations to converge in practice, the matrix operations and full gradient computation are bottlenecks when dealing with large-scale problems. %In this study, We propose a subspace quasi-Newton method that is restricted to a deterministic-subspace together with a gradient approximation based on random matrix theory. Our method does not require full gradients, let alone Hessian matrices. Yet, it achieves the same order of the worst-case iteration complexities in average for convex and nonconvex cases, compared to existing subspace methods. In numerical experiments, we confirm the superiority of our algorithm in terms of computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01965v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taisei Miyaishi, Ryota Nozawa, Pierre-Louis Poirion, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Overcoming Lower-Level Constraints in Bilevel Optimization: A Novel Approach with Regularized Gap Functions</title>
      <link>https://arxiv.org/abs/2406.01992</link>
      <description>arXiv:2406.01992v1 Announce Type: new 
Abstract: Constrained bilevel optimization tackles nested structures present in constrained learning tasks like constrained meta-learning, adversarial learning, and distributed bilevel optimization. However, existing bilevel optimization methods mostly are typically restricted to specific constraint settings, such as linear lower-level constraints. In this work, we overcome this limitation and develop a new single-loop, Hessian-free constrained bilevel algorithm capable of handling more general lower-level constraints. We achieve this by employing a doubly regularized gap function tailored to the constrained lower-level problem, transforming constrained bilevel optimization into an equivalent single-level optimization problem with a single smooth constraint. We rigorously establish the non-asymptotic convergence analysis of the proposed algorithm under the convexity of lower-level problem, avoiding the need for strong convexity assumptions on the lower-level objective or coupling convexity assumptions on lower-level constraints found in existing literature. Additionally, the generality of our method allows for its extension to bilevel optimization with minimax lower-level problem. We evaluate the effectiveness and efficiency of our algorithm on various synthetic problems, typical hyperparameter learning tasks, and generative adversarial network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01992v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Yao, Haian Yin, Shangzhi Zeng, Jin Zhang</dc:creator>
    </item>
    <item>
      <title>Laplace Meets Moreau: Smooth Approximation to Infimal Convolutions Using Laplace's Method</title>
      <link>https://arxiv.org/abs/2406.02003</link>
      <description>arXiv:2406.02003v1 Announce Type: new 
Abstract: We study approximations to the Moreau envelope -- and infimal convolutions more broadly -- based on Laplace's method, a classical tool in analysis which ties certain integrals to suprema of their integrands. We believe the connection between Laplace's method and infimal convolutions is generally deserving of more attention in the study of optimization and partial differential equations, since it bears numerous potentially important applications, from proximal-type algorithms to solving Halmiton-Jacobi equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02003v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan J. Tibshirani, Samy Wu Fung, Howard Heaton, Stanley Osher</dc:creator>
    </item>
    <item>
      <title>ODE-based Learning to Optimize</title>
      <link>https://arxiv.org/abs/2406.02006</link>
      <description>arXiv:2406.02006v1 Announce Type: new 
Abstract: Recent years have seen a growing interest in understanding acceleration methods through the lens of ordinary differential equations (ODEs). Despite the theoretical advancements, translating the rapid convergence observed in continuous-time models to discrete-time iterative methods poses significant challenges. In this paper, we present a comprehensive framework integrating the inertial systems with Hessian-driven damping equation (ISHD) and learning-based approaches for developing optimization methods through a deep synergy of theoretical insights. We first establish the convergence condition for ensuring the convergence of the solution trajectory of ISHD. Then, we show that provided the stability condition, another relaxed requirement on the coefficients of ISHD, the sequence generated through the explicit Euler discretization of ISHD converges, which gives a large family of practical optimization methods. In order to select the best optimization method in this family for certain problems, we introduce the stopping time, the time required for an optimization method derived from ISHD to achieve a predefined level of suboptimality. Then, we formulate a novel learning to optimize (L2O) problem aimed at minimizing the stopping time subject to the convergence and stability condition. To navigate this learning problem, we present an algorithm combining stochastic optimization and the penalty method (StoPM). The convergence of StoPM using the conservative gradient is proved. Empirical validation of our framework is conducted through extensive numerical experiments across a diverse set of optimization problems. These experiments showcase the superior performance of the learned optimization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02006v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhonglin Xie, Wotao Yin, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>Adaptive and Optimal Second-order Optimistic Methods for Minimax Optimization</title>
      <link>https://arxiv.org/abs/2406.02016</link>
      <description>arXiv:2406.02016v1 Announce Type: new 
Abstract: We propose adaptive, line search-free second-order methods with optimal rate of convergence for solving convex-concave min-max problems. By means of an adaptive step size, our algorithms feature a simple update rule that requires solving only one linear system per iteration, eliminating the need for line search or backtracking mechanisms. Specifically, we base our algorithms on the optimistic method and appropriately combine it with second-order information. Moreover, distinct from common adaptive schemes, we define the step size recursively as a function of the gradient norm and the prediction error in the optimistic update. We first analyze a variant where the step size requires knowledge of the Lipschitz constant of the Hessian. Under the additional assumption of Lipschitz continuous gradients, we further design a parameter-free version by tracking the Hessian Lipschitz constant locally and ensuring the iterates remain bounded. We also evaluate the practical performance of our algorithm by comparing it to existing second-order algorithms for minimax optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02016v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruichen Jiang, Ali Kavis, Qiujiang Jin, Sujay Sanghavi, Aryan Mokhtari</dc:creator>
    </item>
    <item>
      <title>Long-Time Behavior of Zero-Sum Linear-Quadratic Stochastic Differential Games</title>
      <link>https://arxiv.org/abs/2406.02089</link>
      <description>arXiv:2406.02089v1 Announce Type: new 
Abstract: The paper investigates the long-time behavior of zero-sum linear-quadratic stochastic differential games, aiming to demonstrate that, under appropriate conditions, both the saddle strategy and the optimal state process exhibit the exponential turnpike property. Namely, for the majority of the time horizon, the distributions of the saddle strategy and the optimal state process closely stay near certain (time-invariant) distributions $\nu_1^*$, $\nu_2^*$ and $\mu^*$, respectively. Additionally, as a byproduct, we solve the infinite horizon version of the differential game and derive closed-loop representations for its open-loop saddle strategy, which has not been proved in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02089v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingrui Sun, Jiongmin Yong</dc:creator>
    </item>
    <item>
      <title>Riemannian coordinate descent algorithms on matrix manifolds</title>
      <link>https://arxiv.org/abs/2406.02225</link>
      <description>arXiv:2406.02225v1 Announce Type: new 
Abstract: Many machine learning applications are naturally formulated as optimization problems on Riemannian manifolds. The main idea behind Riemannian optimization is to maintain the feasibility of the variables while moving along a descent direction on the manifold. This results in updating all the variables at every iteration. In this work, we provide a general framework for developing computationally efficient coordinate descent (CD) algorithms on matrix manifolds that allows updating only a few variables at every iteration while adhering to the manifold constraint. In particular, we propose CD algorithms for various manifolds such as Stiefel, Grassmann, (generalized) hyperbolic, symplectic, and symmetric positive (semi)definite. While the cost per iteration of the proposed CD algorithms is low, we further develop a more efficient variant via a first-order approximation of the objective function. We analyze their convergence and complexity, and empirically illustrate their efficacy in several applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02225v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andi Han, Pratik Jawanpuria, Bamdev Mishra</dc:creator>
    </item>
    <item>
      <title>A KL-based Analysis Framework with Applications to Non-Descent Optimization Methods</title>
      <link>https://arxiv.org/abs/2406.02273</link>
      <description>arXiv:2406.02273v1 Announce Type: new 
Abstract: We propose a novel analysis framework for non-descent-type optimization methodologies in nonconvex scenarios based on the Kurdyka-Lojasiewicz property. Our framework allows covering a broad class of algorithms, including those commonly employed in stochastic and distributed optimization. Specifically, it enables the analysis of first-order methods that lack a sufficient descent property and do not require access to full (deterministic) gradient information. We leverage this framework to establish, for the first time, iterate convergence and the corresponding rates for the decentralized gradient method and federated averaging under mild assumptions. Furthermore, based on the new analysis techniques, we show the convergence of the random reshuffling and stochastic gradient descent method without necessitating typical a priori bounded iterates assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02273v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junwen Qiu, Bohao Ma, Xiao Li, Andre Milzarek</dc:creator>
    </item>
    <item>
      <title>Gradient-free algorithm for saddle point problems under overparametrization</title>
      <link>https://arxiv.org/abs/2406.02308</link>
      <description>arXiv:2406.02308v1 Announce Type: new 
Abstract: This paper focuses on solving a stochastic saddle point problem (SPP) under an overparameterized regime for the case, when the gradient computation is impractical. As an intermediate step, we generalize Same-sample Stochastic Extra-gradient algorithm (Gorbunov et al., 2022) to a biased oracle and estimate novel convergence rates. As the result of the paper we introduce an algorithm, which uses gradient approximation instead of a gradient oracle. We also conduct an analysis to find the maximum admissible level of adversarial noise and the optimal number of iterations at which our algorithm can guarantee achieving the desired accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02308v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.chaos.2024.115048</arxiv:DOI>
      <arxiv:journal_reference>Chaos, Solitons &amp; Fractals Chaos, Solitons &amp; Fractals Volume 185 August 2024 115048</arxiv:journal_reference>
      <dc:creator>Ekaterina Statkevich, Sofiya Bondar, Darina Dvinskikh, Alexander Gasnikov, Aleksandr Lobanov</dc:creator>
    </item>
    <item>
      <title>Second-order optimality conditions for the sparse optimal control of nonviscous Cahn-Hilliard systems</title>
      <link>https://arxiv.org/abs/2406.02384</link>
      <description>arXiv:2406.02384v1 Announce Type: new 
Abstract: In this paper we study the optimal control of an initial-boundary value problem for the classical nonviscous Cahn-Hilliard system with zero Neumann boundary conditions. Phase field systems of this type govern the evolution of diffusive phase transition processes with conserved order parameter. For such systems, optimal control problems have been studied in the past. We focus here on the situation when the cost functional of the optimal control problem contains a sparsity-enhancing nondifferentiable term like the L1-norm. For such cases, we establish first-order necessary and second-order sufficient optimality conditions for locally optimal controls, where in the approach to second-order sufficient conditions we employ a technique introduced by E. Casas, C. Ryll and F. Tr\"oltzsch in the paper [SIAM J. Control Optim. 53 (2015), 2168-2202]. The main novelty of this paper is that this method, which has recently been successfully applied to systems of viscous Cahn-Hilliard type, can be adapted also to the classical nonviscous case. Since in the case without viscosity the solutions to the state and adjoint systems turn out to be considerably less regular than in the viscous case, numerous additional technical difficulties have to be overcome, and additional conditions have to be imposed. In particular, we have to restrict ourselves to the case when the nonlinearity driving the phase separation is regular, while in the presence of a viscosity term also nonlinearities of logarithmic type turn could be admitted. In addition, the implicit function theorem, which was employed to establish the needed differentiability properties of the control-to-state operator in the viscous case, does not apply in our situation and has to be substituted by other arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02384v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierluigi Colli, J\"urgen Sprekels</dc:creator>
    </item>
    <item>
      <title>Online Fair Allocation of Perishable Resources</title>
      <link>https://arxiv.org/abs/2406.02402</link>
      <description>arXiv:2406.02402v1 Announce Type: new 
Abstract: We consider a practically motivated variant of the canonical online fair allocation problem: a decision-maker has a budget of perishable resources to allocate over a fixed number of rounds. Each round sees a random number of arrivals, and the decision-maker must commit to an allocation for these individuals before moving on to the next round. The goal is to construct a sequence of allocations that is envy-free and efficient. Our work makes two important contributions toward this problem: we first derive strong lower bounds on the optimal envy-efficiency trade-off that demonstrate that a decision-maker is fundamentally limited in what she can hope to achieve relative to the no-perishing setting; we then design an algorithm achieving these lower bounds which takes as input $(i)$ a prediction of the perishing order, and $(ii)$ a desired bound on envy. Given the remaining budget in each period, the algorithm uses forecasts of future demand and perishing to adaptively choose one of two carefully constructed guardrail quantities. We demonstrate our algorithm's strong numerical performance - and state-of-the-art, perishing-agnostic algorithms' inefficacy - on simulations calibrated to a real-world dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02402v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddhartha Banerjee, Chamsi Hssaine, Sean R. Sinclair</dc:creator>
    </item>
    <item>
      <title>Accelerated Variance-Reduced Forward-Reflected Methods for Root-Finding Problems</title>
      <link>https://arxiv.org/abs/2406.02413</link>
      <description>arXiv:2406.02413v1 Announce Type: new 
Abstract: We propose a novel class of Nesterov's stochastic accelerated forward-reflected-based methods with variance reduction to solve root-finding problems under $\frac{1}{L}$-co-coerciveness. Our algorithm is single-loop and leverages a new family of unbiased variance-reduced estimators specifically designed for root-finding problems. It achieves both $\mathcal{O}(L^2/k^2)$ and $o(1/k^2)$-last-iterate convergence rates in terms of expected operator squared norm, where $k$ denotes the iteration counter. We instantiate our framework for two prominent estimators: SVRG and SAGA. By an appropriate choice of parameters, both variants attain an oracle complexity of $\mathcal{O}( n + Ln^{2/3}\epsilon^{-1})$ to reach an $\epsilon$-solution, where $n$ represents the number of summands in the finite-sum operator. Furthermore, under $\mu$-strong quasi-monotonicity, our method achieves a linear convergence rate and an oracle complexity of $\mathcal{O}(n+ \kappa n^{2/3}\log(\epsilon^{-1}))$, where $\kappa := \frac{L}{\mu}$. We extend our approach to solve a class of finite-sum monotone inclusions, demonstrating that our schemes retain the same theoretical guarantees as in the equation setting. Finally, numerical experiments validate our algorithms and demonstrate their promising performance compared to state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02413v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quoc Tran-Dinh</dc:creator>
    </item>
    <item>
      <title>Contextual Optimization under Covariate Shift: A Robust Approach by Intersecting Wasserstein Balls</title>
      <link>https://arxiv.org/abs/2406.02426</link>
      <description>arXiv:2406.02426v1 Announce Type: new 
Abstract: In contextual optimization, a decision-maker observes historical samples of uncertain variables and associated concurrent covariates, without knowing their joint distribution. Given an additional covariate observation, the goal is to choose a decision that minimizes some operational costs. A prevalent issue here is covariate shift, where the marginal distribution of the new covariate differs from historical samples, leading to decision performance variations with nonparametric or parametric estimators. To address this, we propose a distributionally robust approach that uses an ambiguity set by the intersection of two Wasserstein balls, each centered on typical nonparametric or parametric distribution estimators. Computationally, we establish the tractable reformulation of this distributionally robust optimization problem. Statistically, we provide guarantees for our Wasserstein ball intersection approach under covariate shift by analyzing the measure concentration of the estimators. Furthermore, to reduce computational complexity, we employ a surrogate objective that maintains similar generalization guarantees. Through synthetic and empirical case studies on income prediction and portfolio optimization, we demonstrate the strong empirical performance of our proposed models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02426v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianyu Wang, Ningyuan Chen, Chun Wang</dc:creator>
    </item>
    <item>
      <title>The Multi-Commodity Flow Problem with Outsourcing Decisions</title>
      <link>https://arxiv.org/abs/2406.02439</link>
      <description>arXiv:2406.02439v1 Announce Type: new 
Abstract: We address a new prize-collecting problem of routing commodities in a given network with hub and non-hub nodes, in which the service of the non-hub nodes will be outsourced to third-party carriers. The problem is modeled as a Stackelberg game: there is a major firm (leader) that decides to serve a subset of commodities. The leader aims to outsource first and third legs of transportation services to smaller carriers (who act as followers) by allocating at most one carrier to each non-hub node. The carriers try to maximize their own profits, which are influenced by the leader's offers. The goal of the leader is to determine the optimal outsourcing fees, along with the allocation of carriers to the non-hub nodes, so that the profit from the routed commodities is maximized. The optimal response of the followers must be taken into account, as the followers might refuse to serve some legs in case they are negative or do not maximize their profit. We also study two alternative settings: one in which the outsourcing fees are fixed, and the other one in which the carriers accept any offer, as long as the resulting profit is non-negative. We prove that the set of possible outsourcing fees can be discretized and formulate the problem as a single-level mixed-integer nonlinear program. For all considered problem variants, we prove NP-hardness and propose and computationally investigate several MIP formulations. We study the computational scalability of these MIP formulations and analyze solutions obtained by varying the reservation prices of the carriers. Finally, by comparing the introduced problem variants, we derive some interesting managerial insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02439v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elena Fernandez, Ivana Ljubic, Nicolas Zerega</dc:creator>
    </item>
    <item>
      <title>Wasserstein Distributionally Robust Control and State Estimation for Partially Observable Linear Systems</title>
      <link>https://arxiv.org/abs/2406.01723</link>
      <description>arXiv:2406.01723v1 Announce Type: cross 
Abstract: This paper presents a novel Wasserstein distributionally robust control and state estimation algorithm for partially observable linear stochastic systems, where the probability distributions of disturbances and measurement noises are unknown. Our method consists of the control and state estimation phases to handle distributional ambiguities of system disturbances and measurement noises, respectively. Leveraging tools from modern distributionally robust optimization, we consider an approximation of the control problem with an arbitrary nominal distribution and derive its closed-form optimal solution. We show that the separation principle holds, thereby allowing the state estimator to be designed separately. A novel distributionally robust Kalman filter is then proposed as an optimal solution to the state estimation problem with Gaussian nominal distributions. Our key contribution is the combination of distributionally robust control and state estimation into a unified algorithm. This is achieved by formulating a tractable semidefinite programming problem that iteratively determines the worst-case covariance matrices of all uncertainties, leading to a scalable and efficient algorithm. Our method is also shown to enjoy a guaranteed cost property as well as a probabilistic out-of-sample performance guarantee. The results of our numerical experiments demonstrate the performance and computational efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01723v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Minhyuk Jang, Astghik Hakobyan, Insoon Yang</dc:creator>
    </item>
    <item>
      <title>On the completeness of several fortification-interdiction games in the Polynomial Hierarchy</title>
      <link>https://arxiv.org/abs/2406.01756</link>
      <description>arXiv:2406.01756v1 Announce Type: cross 
Abstract: Fortification-interdiction games are tri-level adversarial games where two opponents act in succession to protect, disrupt and simply use an infrastructure for a specific purpose. Many such games have been formulated and tackled in the literature through specific algorithmic methods, however very few investigations exist on the completeness of such fortification problems in order to locate them rigorously in the polynomial hierarchy. We clarify the completeness status of several well-known fortification problems, such as the Tri-level Interdiction Knapsack Problem with unit fortification and attack weights, the Max-flow Interdiction Problem and Shortest Path Interdiction Problem with Fortification, the Multi-level Critical Node Problem with unit weights, as well as a well-studied electric grid defence planning problem. For all of these problems, we prove their completeness either for the $\Sigma^p_2$ or the $\Sigma^p_3$ class of the polynomial hierarchy. We also prove that the Multi-level Fortification-Interdiction Knapsack Problem with an arbitrary number of protection and interdiction rounds and unit fortification and attack weights is complete for any level of the polynomial hierarchy, therefore providing a useful basis for further attempts at proving the completeness of protection-interdiction games at any level of said hierarchy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01756v1</guid>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Boggio Tomasaz, Margarida Carvalho, Roberto Cordone, Pierre Hosteins</dc:creator>
    </item>
    <item>
      <title>Online Control in Population Dynamics</title>
      <link>https://arxiv.org/abs/2406.01799</link>
      <description>arXiv:2406.01799v1 Announce Type: cross 
Abstract: The study of population dynamics originated with early sociological works (Malthus, 1872) but has since extended into many fields, including biology, epidemiology, evolutionary game theory, and economics. Most studies on population dynamics focus on the problem of prediction rather than control. Existing mathematical models for population control are often restricted to specific, noise-free dynamics, while real-world population changes can be complex and adversarial.
  To address this gap, we propose a new framework based on the paradigm of online control. We first characterize a set of linear dynamical systems that can naturally model evolving populations. We then give an efficient gradient-based controller for these systems, with near-optimal regret bounds with respect to a broad class of linear policies. Our empirical evaluations demonstrate the effectiveness of the proposed algorithm for population control even in non-linear models such as SIR and replicator dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01799v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noah Golowich, Elad Hazan, Zhou Lu, Dhruv Rohatgi, Y. Jennifer Sun</dc:creator>
    </item>
    <item>
      <title>On Approximation of Robust Max-Cut and Related Problems using Randomized Rounding Algorithms</title>
      <link>https://arxiv.org/abs/2406.01856</link>
      <description>arXiv:2406.01856v1 Announce Type: cross 
Abstract: Goemans and Williamson proposed a randomized rounding algorithm for the MAX-CUT problem with a 0.878 approximation bound in expectation. The 0.878 approximation bound remains the best-known approximation bound for this APX-hard problem. Their approach was subsequently applied to other related problems such as Max-DiCut, MAX-SAT, and Max-2SAT, etc. We show that the randomized rounding algorithm can also be used to achieve a 0.878 approximation bound for the robust and distributionally robust counterparts of the max-cut problem. We also show that the approximation bounds for the other problems are maintained for their robust and distributionally robust counterparts if the randomization projection framework is used.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01856v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Haoyan Shi, Sanjay Mehrotra</dc:creator>
    </item>
    <item>
      <title>Annealing-Assisted Column Generation for Inequality-Constrained Combinatorial Optimization Problems</title>
      <link>https://arxiv.org/abs/2406.01887</link>
      <description>arXiv:2406.01887v1 Announce Type: cross 
Abstract: Ising machines are expected to solve combinatorial optimization problems faster than the existing integer programming solvers. These problems, particularly those encountered in practical situations, typically involve inequality constraints. However, owing to the hardware limitations of the current Ising machines, solving combinatorial optimization problems with inequality constraints remains challenging. The Capacitated Vehicle Routing Problem (CVRP) is a typical example of a problem with inequality constraints. The objective function of the CVRP is to minimize the total distance traveled by each vehicle while limiting the total demand of customers served by a single vehicle to the vehicle's capacity. The CVRP is classified as NP-hard and, thus, is commonly solved using heuristic algorithms, such as column generation. Column generation attempts to iteratively generate only the promising routes, as the number of feasible routes increases exponentially. Within this framework, the CVRP is formulated as a set cover problem. The corresponding dual solutions are used to define the pricing subproblem, which is intended to create a new route. By applying Ising machines to this pricing subproblem, the overall computation time can be reduced. This study aims to solve combinatorial optimization problems with inequality constraints using a hybrid algorithm that combines column generation and Ising machines, thereby extending the applications of the latter. We parameterize the difficulty of the inequality constraints and demonstrate that our annealing-assisted column generation can converge to a better lower bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01887v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroshi Kanai, Masashi Yamashita, Kotaro Tanahashi, Shu Tanaka</dc:creator>
    </item>
    <item>
      <title>PDHG-Unrolled Learning-to-Optimize Method for Large-Scale Linear Programming</title>
      <link>https://arxiv.org/abs/2406.01908</link>
      <description>arXiv:2406.01908v1 Announce Type: cross 
Abstract: Solving large-scale linear programming (LP) problems is an important task in various areas such as communication networks, power systems, finance and logistics. Recently, two distinct approaches have emerged to expedite LP solving: (i) First-order methods (FOMs); (ii) Learning to optimize (L2O). In this work, we propose an FOM-unrolled neural network (NN) called PDHG-Net, and propose a two-stage L2O method to solve large-scale LP problems. The new architecture PDHG-Net is designed by unrolling the recently emerged PDHG method into a neural network, combined with channel-expansion techniques borrowed from graph neural networks. We prove that the proposed PDHG-Net can recover PDHG algorithm, thus can approximate optimal solutions of LP instances with a polynomial number of neurons. We propose a two-stage inference approach: first use PDHG-Net to generate an approximate solution, and then apply PDHG algorithm to further improve the solution. Experiments show that our approach can significantly accelerate LP solving, achieving up to a 3$\times$ speedup compared to FOMs for large-scale LP problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01908v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bingheng Li, Linxin Yang, Yupeng Chen, Senmiao Wang, Qian Chen, Haitao Mao, Yao Ma, Akang Wang, Tian Ding, Jiliang Tang, Ruoyu Sun</dc:creator>
    </item>
    <item>
      <title>Minimum-norm solutions of the non-symmetric semidefinite Procrustes problem</title>
      <link>https://arxiv.org/abs/2406.02203</link>
      <description>arXiv:2406.02203v1 Announce Type: cross 
Abstract: Given two matrices $X,B\in \mathbb{R}^{n\times m}$ and a set $\mathcal{A}\subseteq \mathbb{R}^{n\times n}$, a Procrustes problem consists in finding a matrix $A \in \mathcal{A}$ such that the Frobenius norm of $AX-B$ is minimized. When $\mathcal{A}$ is the set of the matrices whose symmetric part is positive semidefinite, we obtain the so-called non-symmetric positive semidefinite Procrustes (NSPDSP) problem. The NSPDSP problem arises in the estimation of compliance or stiffness matrix in solid and elastic structures. If $X$ has rank $r$, Baghel et al. (Lin. Alg. Appl., 2022) proposed a three-step semi-analytical approach: (1) construct a reduced NSPDSP problem in dimension $r\times r$, (2) solve the reduced problem by means of a fast gradient method with a linear rate of convergence, and (3) post-process the solution of the reduced problem to construct a solution of the larger original NSPDSP problem. In this paper, we revisit this approach of Baghel et al. and identify an unnecessary assumption used by the authors leading to cases where their algorithm cannot attain a minimum and produces solutions with unbounded norm. In fact, revising the post-processing phase of their semi-analytical approach, we show that the infimum of the NSPDSP problem is always attained, and we show how to compute a minimum-norm solution. We also prove that the symmetric part of the computed solution has minimum rank bounded by $r$, and that the skew-symmetric part has rank bounded by $2r$. Several numerical examples show the efficiency of this algorithm, both in terms of computational speed and of finding optimal minimum-norm solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02203v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Gillis, Stefano Sicilia</dc:creator>
    </item>
    <item>
      <title>Learning-Rate-Free Stochastic Optimization over Riemannian Manifolds</title>
      <link>https://arxiv.org/abs/2406.02296</link>
      <description>arXiv:2406.02296v1 Announce Type: cross 
Abstract: In recent years, interest in gradient-based optimization over Riemannian manifolds has surged. However, a significant challenge lies in the reliance on hyperparameters, especially the learning rate, which requires meticulous tuning by practitioners to ensure convergence at a suitable rate. In this work, we introduce innovative learning-rate-free algorithms for stochastic optimization over Riemannian manifolds, eliminating the need for hand-tuning and providing a more robust and user-friendly approach. We establish high probability convergence guarantees that are optimal, up to logarithmic factors, compared to the best-known optimally tuned rate in the deterministic setting. Our approach is validated through numerical experiments, demonstrating competitive performance against learning-rate-dependent algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02296v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Dodd, Louis Sharrock, Christopher Nemeth</dc:creator>
    </item>
    <item>
      <title>Dynamic Population Games: A Tractable Intersection of Mean-Field Games and Population Games</title>
      <link>https://arxiv.org/abs/2104.14662</link>
      <description>arXiv:2104.14662v3 Announce Type: replace 
Abstract: In many real-world large-scale decision problems, self-interested agents have individual dynamics and optimize their own long-term payoffs. Important examples include the competitive access to shared resources (e.g., roads, energy, or bandwidth) but also non-engineering domains like epidemic propagation and control. These problems are natural to model as mean-field games. Existing mathematical formulations of mean field games have had limited applicability in practice, since they require solving non-standard initial-terminal-value problems that are tractable only in limited special cases. In this letter, we propose a novel formulation, along with computational tools, for a practically relevant class of Dynamic Population Games (DPGs), which correspond to discrete-time, finite-state-and-action, stationary mean-field games. Our main contribution is a mathematical reduction of Stationary Nash Equilibria (SNE) in DPGs to standard Nash Equilibria (NE) in static population games. This reduction is leveraged to guarantee the existence of a SNE, develop an evolutionary dynamics-based SNE computation algorithm, and derive simple conditions that guarantee stability and uniqueness of the SNE. We provide two examples of applications: fair resource allocation with heterogeneous agents and control of epidemic propagation. Open source software for SNE computation: https://gitlab.ethz.ch/elokdae/dynamic-population-games</description>
      <guid isPermaLink="false">oai:arXiv.org:2104.14662v3</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>econ.TH</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2024.3406947</arxiv:DOI>
      <dc:creator>Ezzat Elokda, Saverio Bolognani, Andrea Censi, Florian D\"orfler, Emilio Frazzoli</dc:creator>
    </item>
    <item>
      <title>Robust Data-driven Prescriptiveness Optimization</title>
      <link>https://arxiv.org/abs/2306.05937</link>
      <description>arXiv:2306.05937v2 Announce Type: replace 
Abstract: The abundance of data has led to the emergence of a variety of optimization techniques that attempt to leverage available side information to provide more anticipative decisions. The wide range of methods and contexts of application have motivated the design of a universal unitless measure of performance known as the coefficient of prescriptiveness. This coefficient was designed to quantify both the quality of contextual decisions compared to a reference one and the prescriptive power of side information. To identify policies that maximize the former in a data-driven context, this paper introduces a distributionally robust contextual optimization model where the coefficient of prescriptiveness substitutes for the classical empirical risk minimization objective. We present a bisection algorithm to solve this model, which relies on solving a series of linear programs when the distributional ambiguity set has an appropriate nested form and polyhedral structure. Studying a contextual shortest path problem, we evaluate the robustness of the resulting policies against alternative methods when the out-of-sample dataset is subject to varying amounts of distribution shift.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.05937v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehran Poursoltani, Erick Delage, Angelos Georghiou</dc:creator>
    </item>
    <item>
      <title>On the Sublinear Convergence of Projected Policy Gradient for Any Constant Step Sizes</title>
      <link>https://arxiv.org/abs/2311.01104</link>
      <description>arXiv:2311.01104v5 Announce Type: replace 
Abstract: Projected policy gradient (PPG) is a basic policy optimization method in reinforcement learning. Given access to exact policy evaluations, previous studies have established the sublinear convergence of PPG for sufficiently small step sizes based on the smoothness and the gradient domination properties of the value function. However, as the step size goes to infinity, PPG reduces to the classic policy iteration method, which suggests the convergence of PPG even for large step sizes. In this paper, we fill this gap and show that PPG admits a sublinear convergence for any constant step sizes. Due to the existence of the state-wise visitation measure in the expression of policy gradient, the existing optimization-based analysis framework for a preconditioned version of PPG (i.e., projected Q-ascent) is not applicable, to the best of our knowledge. Instead, we proceed the proof by computing the state-wise improvement lower bound of PPG based on its inherent structure. In addition, the finite iteration convergence of PPG for any constant step size is further established, which is also new.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.01104v5</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiacai Liu, Wenye Li, Dachao Lin, Ke Wei, Zhihua Zhang</dc:creator>
    </item>
    <item>
      <title>Speed limits in traffic emission models using multi-objective optimization</title>
      <link>https://arxiv.org/abs/2311.12744</link>
      <description>arXiv:2311.12744v2 Announce Type: replace 
Abstract: Climate change compels a reduction of greenhouse gas emissions, yet vehicular traffic still contributes significantly to the emission of air pollutants. Hence, in this paper we focus on the optimization of traffic flow while simultaneously minimizing air pollution using speed limits as controllable parameters. We introduce a framework of traffic emission models to simulate the traffic dynamic as well as the production and spread of air pollutants. We formulate a multi-objective optimization problem for the optimization of multiple aspects of vehicular traffic. The results show that multi-objective optimization can be a valuable tool in traffic emission modeling as it allows to find optimal compromises between ecological and economic objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.12744v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simone G\"ottlich, Michael Herty, Alena Ulke</dc:creator>
    </item>
    <item>
      <title>Piecewise Polynomial Regression of Tame Functions via Integer Programming</title>
      <link>https://arxiv.org/abs/2311.13544</link>
      <description>arXiv:2311.13544v3 Announce Type: replace 
Abstract: Tame functions are a class of nonsmooth, nonconvex functions, which feature in a wide range of applications: functions encountered in the training of deep neural networks with all common activations, value functions of mixed-integer programs, or wave functions of small molecules. We consider approximating tame functions with piecewise polynomial functions. We bound the quality of approximation of a tame function by a piecewise polynomial function with a given number of segments on any full-dimensional cube. We also present the first mixed-integer programming formulation of piecewise polynomial regression. Together, these can be used to estimate tame functions. We demonstrate promising computational results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13544v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gilles Bareilles, Johannes Aspman, Jiri Nemecek, Jakub Marecek</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of Fractional Gradient Descent</title>
      <link>https://arxiv.org/abs/2311.18426</link>
      <description>arXiv:2311.18426v5 Announce Type: replace 
Abstract: Fractional derivatives are a well-studied generalization of integer order derivatives. Naturally, for optimization, it is of interest to understand the convergence properties of gradient descent using fractional derivatives. Convergence analysis of fractional gradient descent is currently limited both in the methods analyzed and the settings analyzed. This paper aims to fill in these gaps by analyzing variations of fractional gradient descent in smooth and convex, smooth and strongly convex, and smooth and non-convex settings. First, novel bounds will be established bridging fractional and integer derivatives. Then, these bounds will be applied to the aforementioned settings to prove linear convergence for smooth and strongly convex functions and $O(1/T)$ convergence for smooth and convex functions. Additionally, we prove $O(1/T)$ convergence for smooth and non-convex functions using an extended notion of smoothness - H\"older smoothness - that is more natural for fractional derivatives. Finally, empirical results will be presented on the potential speed up of fractional gradient descent over standard gradient descent as well as some preliminary theoretical results explaining this speed up.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18426v5</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ashwani Aggarwal</dc:creator>
    </item>
    <item>
      <title>SLS-BRD: A system-level approach to seeking generalised feedback Nash equilibria</title>
      <link>https://arxiv.org/abs/2404.03809</link>
      <description>arXiv:2404.03809v2 Announce Type: replace 
Abstract: This work proposes a policy learning algorithm for seeking generalised feedback Nash equilibria in $N_P$-players non-cooperative dynamic games. We consider linear-quadratic games with stochastic dynamics and design a best-response dynamics in which players update and communicate a parametrisation of their state-feedback policies. Our approach leverages the System Level Synthesis framework to formulate each player's update rule as the solution to a tractable robust optimisation problem. Under certain conditions, rates of convergence to a feedback Nash equilibrium can be established. The algorithm is showcased in exemplary problems ranging from the decentralised control of unstable systems to competition in oligopolistic markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03809v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Otacilio B. L. Neto, Michela Mulas, Francesco Corona</dc:creator>
    </item>
    <item>
      <title>An excursion onto Schr\"odinger's bridges: Stochastic flows with spatio-temporal marginals</title>
      <link>https://arxiv.org/abs/2404.07402</link>
      <description>arXiv:2404.07402v3 Announce Type: replace 
Abstract: The purpose of the present work is to expand substantially the type of control and estimation problems that can be addressed following the paradigm of Schr\"odinger bridges, by incorporating termination (killing) of stochastic flows. Specifically, in the context of estimation, we seek the most likely evolution realizing measured spatio-temporal marginals of killed particles. In the context of control, we seek a suitable control action directing the killed process toward spatio-temporal probabilistic constraints. To this end, we derive a new Schr\"odinger system of coupled, in space and time, partial differential equations to construct the solution of the proposed problem. Further, we show that a Fortet-Sinkhorn type of algorithm is available to attain the associated bridge. A key feature of our framework is that the obtained bridge retains the Markovian structure in the prior process, and thereby, the corresponding controller takes the form of state feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07402v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asmaa Eldesoukey, Olga Movilla Miangolarra, Tryphon T. Georgiou</dc:creator>
    </item>
    <item>
      <title>Getting to the Root of the Problem: Sums of Squares for Infinite Trees</title>
      <link>https://arxiv.org/abs/2404.12838</link>
      <description>arXiv:2404.12838v2 Announce Type: replace 
Abstract: The inducibility of a graph represents its maximum density as an induced subgraph over all possible sequences of graphs of size growing to infinity. This invariant of graphs has been extensively studied since its introduction in $1975$ by Pippenger and Golumbic. In $2017$, Czabarka, Sz\'ekely and Wagner extended this notion to leaf-labeled rooted binary trees, which are objects widely studied in the field of phylogenetics. They obtain the first results and bounds for the densities and inducibilities of such trees. Following up on their work, we apply Razborov's flag algebra theory to this setting, introducing the flag algebra of rooted leaf-labeled binary trees. This framework allows us to use polynomial optimization methods, based on semidefinite programming, to efficiently obtain new upper bounds for the inducibility of trees and to improve existing ones. Additionally, we obtain the first outer approximations of profiles of trees, which represent all possible simultaneous densities of a pair of trees. Finally, we are able to prove the non-convexity of some of these profiles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12838v2</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Brosch, Diane Puges</dc:creator>
    </item>
    <item>
      <title>The Power of Extrapolation in Federated Learning</title>
      <link>https://arxiv.org/abs/2405.13766</link>
      <description>arXiv:2405.13766v3 Announce Type: replace 
Abstract: We propose and study several server-extrapolation strategies for enhancing the theoretical and empirical convergence properties of the popular federated learning optimizer FedProx [Li et al., 2020]. While it has long been known that some form of extrapolation can help in the practice of FL, only a handful of works provide any theoretical guarantees. The phenomenon seems elusive, and our current theoretical understanding remains severely incomplete. In our work, we focus on smooth convex or strongly convex problems in the interpolation regime. In particular, we propose Extrapolated FedProx (FedExProx), and study three extrapolation strategies: a constant strategy (depending on various smoothness parameters and the number of participating devices), and two smoothness-adaptive strategies; one based on the notion of gradient diversity (FedExProx-GraDS), and the other one based on the stochastic Polyak stepsize (FedExProx-StoPS). Our theory is corroborated with carefully constructed numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13766v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanmin Li, Kirill Acharya, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Inference of Utilities and Time Preference in Sequential Decision-Making</title>
      <link>https://arxiv.org/abs/2405.15975</link>
      <description>arXiv:2405.15975v2 Announce Type: replace 
Abstract: This paper introduces a novel stochastic control framework to enhance the capabilities of automated investment managers, or robo-advisors, by accurately inferring clients' investment preferences from past activities. Our approach leverages a continuous-time model that incorporates utility functions and a generic discounting scheme of a time-varying rate, tailored to each client's risk tolerance, valuation of daily consumption, and significant life goals. We address the resulting time inconsistency issue through state augmentation and the establishment of the dynamic programming principle and the verification theorem. Additionally, we provide sufficient conditions for the identifiability of client investment preferences. To complement our theoretical developments, we propose a learning algorithm based on maximum likelihood estimation within a discrete-time Markov Decision Process framework, augmented with entropy regularization. We prove that the log-likelihood function is locally concave, facilitating the fast convergence of our proposed algorithm. Practical effectiveness and efficiency are showcased through two numerical examples, including Merton's problem and an investment problem with unhedgeable risks.
  Our proposed framework not only advances financial technology by improving personalized investment advice but also contributes broadly to other fields such as healthcare, economics, and artificial intelligence, where understanding individual preferences is crucial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15975v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoyang Cao, Zhengqi Wu, Renyuan Xu</dc:creator>
    </item>
    <item>
      <title>Analysis of Multiscale Reinforcement Q-Learning Algorithms for Mean Field Control Games</title>
      <link>https://arxiv.org/abs/2405.17017</link>
      <description>arXiv:2405.17017v3 Announce Type: replace 
Abstract: Mean Field Control Games (MFCG), introduced in [Angiuli et al., 2022a], represent competitive games between a large number of large collaborative groups of agents in the infinite limit of number and size of groups. In this paper, we prove the convergence of a three-timescale Reinforcement Q-Learning (RL) algorithm to solve MFCG in a model-free approach from the point of view of representative agents. Our analysis uses a Q-table for finite state and action spaces updated at each discrete time-step over an infinite horizon. In [Angiuli et al., 2023], we proved convergence of two-timescale algorithms for MFG and MFC separately highlighting the need to follow multiple population distributions in the MFC case. Here, we integrate this feature for MFCG as well as three rates of update decreasing to zero in the proper ratios. Our technique of proof uses a generalization to three timescales of the two-timescale analysis in [Borkar, 1997]. We give a simple example satisfying the various hypothesis made in the proof of convergence and illustrating the performance of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17017v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Angiuli, Jean-Pierre Fouque, Mathieu Lauri\`ere, Mengrui Zhang</dc:creator>
    </item>
    <item>
      <title>The Power of Sampling: Dimension-free Risk Bounds in Private ERM</title>
      <link>https://arxiv.org/abs/2105.13637</link>
      <description>arXiv:2105.13637v4 Announce Type: replace-cross 
Abstract: Differentially private empirical risk minimization (DP-ERM) is a fundamental problem in private optimization. While the theory of DP-ERM is well-studied, as large-scale models become prevalent, traditional DP-ERM methods face new challenges, including (1) the prohibitive dependence on the ambient dimension, (2) the highly non-smooth objective functions, (3) costly first-order gradient oracles. Such challenges demand rethinking existing DP-ERM methodologies. In this work, we show that the regularized exponential mechanism combined with existing samplers can address these challenges altogether: under the standard unconstrained domain and low-rank gradients assumptions, our algorithm can achieve rank-dependent risk bounds for non-smooth convex objectives using only zeroth order oracles, which was not accomplished by prior methods. This highlights the power of sampling in differential privacy. We further construct lower bounds, demonstrating that when gradients are full-rank, there is no separation between the constrained and unconstrained settings. Our lower bound is derived from a general black-box reduction from unconstrained to the constrained domain and an improved lower bound in the constrained setting, which might be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.13637v4</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yin Tat Lee, Daogao Liu, Zhou Lu</dc:creator>
    </item>
    <item>
      <title>Temporal Difference Learning with Compressed Updates: Error-Feedback meets Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2301.00944</link>
      <description>arXiv:2301.00944v3 Announce Type: replace-cross 
Abstract: In large-scale distributed machine learning, recent works have studied the effects of compressing gradients in stochastic optimization to alleviate the communication bottleneck. These works have collectively revealed that stochastic gradient descent (SGD) is robust to structured perturbations such as quantization, sparsification, and delays. Perhaps surprisingly, despite the surge of interest in multi-agent reinforcement learning, almost nothing is known about the analogous question: Are common reinforcement learning (RL) algorithms also robust to similar perturbations? We investigate this question by studying a variant of the classical temporal difference (TD) learning algorithm with a perturbed update direction, where a general compression operator is used to model the perturbation. Our work makes three important technical contributions. First, we prove that compressed TD algorithms, coupled with an error-feedback mechanism used widely in optimization, exhibit the same non-asymptotic theoretical guarantees as their SGD counterparts. Second, we show that our analysis framework extends seamlessly to nonlinear stochastic approximation schemes that subsume Q-learning. Third, we prove that for multi-agent TD learning, one can achieve linear convergence speedups with respect to the number of agents while communicating just $\tilde{O}(1)$ bits per iteration. Notably, these are the first finite-time results in RL that account for general compression operators and error-feedback in tandem with linear function approximation and Markovian sampling. Our proofs hinge on the construction of novel Lyapunov functions that capture the dynamics of a memory variable introduced by error-feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.00944v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aritra Mitra, George J. Pappas, Hamed Hassani</dc:creator>
    </item>
    <item>
      <title>Arcade Processes for Informed Martingale Interpolation</title>
      <link>https://arxiv.org/abs/2301.05936</link>
      <description>arXiv:2301.05936v2 Announce Type: replace-cross 
Abstract: Arcade processes are a class of continuous stochastic processes that interpolate in a strong sense, i.e., omega by omega, between zeros at fixed pre-specified times. Their additive randomization allows one to match any finite sequence of target random variables, indexed by the given fixed dates, on the whole probability space. The randomized arcade processes (RAPs) can thus be interpreted as a generalization of anticipative stochastic bridges. The filtrations generated by these processes are utilized to construct a class of martingales which interpolate between the given target random variables. These so-called filtered arcade martingales (FAMs) are almost-sure solutions to the martingale interpolation problem and reveal an underlying stochastic filtering structure. In the special case of conditionally-Markov randomized arcade processes, the dynamics of FAMs are informed by Bayesian updating. The same ideas are applied to filtered arcade reverse-martingales, which are constructed in a similar fashion, using reverse-filtrations of RAPs, instead. As a potential application of this theory, optimal transportation is explored: FAMs may be used to introduce noise in martingale optimal transport, in a similar fashion to how Schr\"odinger's problem introduces noise in optimal transport. This information-based approach to transport is concerned with selecting an optimal martingale coupling for the target random variables under the influence of the noise that is generated by an arcade process, and suggests application in finance or climate science, for instance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.05936v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georges Kassis, Andrea Macrina</dc:creator>
    </item>
    <item>
      <title>Prophet Inequalities: Separating Random Order from Order Selection</title>
      <link>https://arxiv.org/abs/2304.04024</link>
      <description>arXiv:2304.04024v4 Announce Type: replace-cross 
Abstract: Prophet inequalities are a central object of study in optimal stopping theory. A gambler is sent values in an online fashion, sampled from an instance of independent distributions, in an adversarial, random or selected order, depending on the model. When observing each value, the gambler either accepts it as a reward or irrevocably rejects it and proceeds to observe the next value. The goal of the gambler, who cannot see the future, is maximising the expected value of the reward while competing against the expectation of a prophet (the offline maximum). In other words, one seeks to maximise the gambler-to-prophet ratio of the expectations.
  The model, in which the gambler selects the arrival order first, and then observes the values, is known as Order Selection. In this model a ratio of $0.7251$ has been proved to be attainable for any instance. In very recent work, this has been improved up to $0.7258$. If the gambler chooses the arrival order (uniformly) at random, we obtain the Random Order model. The worst case ratio over all possible instances has been extensively studied for at least $40$ years. In the recent work aforementioned, through simulations, this ratio has been shown to be at most $0.7254$ for the Random Order model, thus establishing for the first time that carefully choosing the order, instead of simply taking it at random, benefits the gambler. We give an alternative, non-simulation-assisted proof of this fact, by showing mathematically that in the Random Order model, no algorithm can achieve a ratio larger than $0.7235$. This sets a new state-of-the-art hardness for this model, and establishes more formally that there is a real benefit in choosing the order.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.04024v4</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giordano Giambartolomei, Frederik Mallmann-Trenn, Raimundo Saona</dc:creator>
    </item>
    <item>
      <title>Improving the Validity of Decision Trees as Explanations</title>
      <link>https://arxiv.org/abs/2306.06777</link>
      <description>arXiv:2306.06777v5 Announce Type: replace-cross 
Abstract: In classification and forecasting with tabular data, one often utilizes tree-based models. Those can be competitive with deep neural networks on tabular data and, under some conditions, explainable. The explainability depends on the depth of the tree and the accuracy in each leaf of the tree. We point out that decision trees containing leaves with unbalanced accuracy can provide misleading explanations. Low-accuracy leaves give less valid explanations, which could be interpreted as unfairness among subgroups utilizing these explanations. Here, we train a shallow tree with the objective of minimizing the maximum misclassification error across all leaf nodes. The shallow tree provides a global explanation, while the overall statistical performance of the shallow tree can become comparable to state-of-the-art methods (e.g., well-tuned XGBoost) by extending the leaves with further models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.06777v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiri Nemecek, Tomas Pevny, Jakub Marecek</dc:creator>
    </item>
    <item>
      <title>Towards a Better Theoretical Understanding of Independent Subnetwork Training</title>
      <link>https://arxiv.org/abs/2306.16484</link>
      <description>arXiv:2306.16484v2 Announce Type: replace-cross 
Abstract: Modern advancements in large-scale machine learning would be impossible without the paradigm of data-parallel distributed computing. Since distributed computing with large-scale models imparts excessive pressure on communication channels, significant recent research has been directed toward co-designing communication compression strategies and training algorithms with the goal of reducing communication costs. While pure data parallelism allows better data scaling, it suffers from poor model scaling properties. Indeed, compute nodes are severely limited by memory constraints, preventing further increases in model size. For this reason, the latest achievements in training giant neural network models also rely on some form of model parallelism. In this work, we take a closer theoretical look at Independent Subnetwork Training (IST), which is a recently proposed and highly effective technique for solving the aforementioned problems. We identify fundamental differences between IST and alternative approaches, such as distributed methods with compressed communication, and provide a precise analysis of its optimization performance on a quadratic model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16484v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Egor Shulgin, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Convex and Bilevel Optimization for Neuro-Symbolic Inference and Learning</title>
      <link>https://arxiv.org/abs/2401.09651</link>
      <description>arXiv:2401.09651v2 Announce Type: replace-cross 
Abstract: We leverage convex and bilevel optimization techniques to develop a general gradient-based parameter learning framework for neural-symbolic (NeSy) systems. We demonstrate our framework with NeuPSL, a state-of-the-art NeSy architecture. To achieve this, we propose a smooth primal and dual formulation of NeuPSL inference and show learning gradients are functions of the optimal dual variables. Additionally, we develop a dual block coordinate descent algorithm for the new formulation that naturally exploits warm-starts. This leads to over 100x learning runtime improvements over the current best NeuPSL inference method. Finally, we provide extensive empirical evaluations across 8 datasets covering a range of tasks and demonstrate our learning framework achieves up to a 16% point prediction performance improvement over alternative learning methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09651v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles Dickens, Changyu Gao, Connor Pryor, Stephen Wright, Lise Getoor</dc:creator>
    </item>
    <item>
      <title>Challenges in Training PINNs: A Loss Landscape Perspective</title>
      <link>https://arxiv.org/abs/2402.01868</link>
      <description>arXiv:2402.01868v2 Announce Type: replace-cross 
Abstract: This paper explores challenges in training Physics-Informed Neural Networks (PINNs), emphasizing the role of the loss landscape in the training process. We examine difficulties in minimizing the PINN loss function, particularly due to ill-conditioning caused by differential operators in the residual term. We compare gradient-based optimizers Adam, L-BFGS, and their combination Adam+L-BFGS, showing the superiority of Adam+L-BFGS, and introduce a novel second-order optimizer, NysNewton-CG (NNCG), which significantly improves PINN performance. Theoretically, our work elucidates the connection between ill-conditioned differential operators and ill-conditioning in the PINN loss and shows the benefits of combining first- and second-order optimization methods. Our work presents valuable insights and more powerful optimization strategies for training PINNs, which could improve the utility of PINNs for solving difficult partial differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01868v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pratik Rathore, Weimu Lei, Zachary Frangella, Lu Lu, Madeleine Udell</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Algorithm Selection Using Neural Networks and Its Applications to Branch-and-Cut</title>
      <link>https://arxiv.org/abs/2402.02328</link>
      <description>arXiv:2402.02328v3 Announce Type: replace-cross 
Abstract: Data-driven algorithm design is a paradigm that uses statistical and machine learning techniques to select from a class of algorithms for a computational problem an algorithm that has the best expected performance with respect to some (unknown) distribution on the instances of the problem. We build upon recent work in this line of research by considering the setup where, instead of selecting a single algorithm that has the best performance, we allow the possibility of selecting an algorithm based on the instance to be solved, using neural networks. In particular, given a representative sample of instances, we learn a neural network that maps an instance of the problem to the most appropriate algorithm for that instance. We formalize this idea and derive rigorous sample complexity bounds for this learning problem, in the spirit of recent work in data-driven algorithm design. We then apply this approach to the problem of making good decisions in the branch-and-cut framework for mixed-integer optimization (e.g., which cut to add?). In other words, the neural network will take as input a mixed-integer optimization instance and output a decision that will result in a small branch-and-cut tree for that instance. Our computational results provide evidence that our particular way of using neural networks for cut selection can make a significant impact in reducing branch-and-cut tree sizes, compared to previous data-driven approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02328v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyu Cheng, Sammy Khalife, Barbara Fiedorowicz, Amitabh Basu</dc:creator>
    </item>
    <item>
      <title>Can We Remove the Square-Root in Adaptive Gradient Methods? A Second-Order Perspective</title>
      <link>https://arxiv.org/abs/2402.03496</link>
      <description>arXiv:2402.03496v4 Announce Type: replace-cross 
Abstract: Adaptive gradient optimizers like Adam(W) are the default training algorithms for many deep learning architectures, such as transformers. Their diagonal preconditioner is based on the gradient outer product which is incorporated into the parameter update via a square root. While these methods are often motivated as approximate second-order methods, the square root represents a fundamental difference. In this work, we investigate how the behavior of adaptive methods changes when we remove the root, i.e. strengthen their second-order motivation. Surprisingly, we find that such square-root-free adaptive methods close the generalization gap to SGD on convolutional architectures, while maintaining their root-based counterpart's performance on transformers. The second-order perspective also has practical benefits for the development of non-diagonal adaptive methods through the concept of preconditioner invariance. In contrast to root-based methods like Shampoo, the root-free counterparts do not require numerically unstable matrix root decompositions and inversions, thus work well in half precision. Our findings provide new insights into the development of adaptive methods and raise important questions regarding the currently overlooked role of adaptivity for their success.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03496v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Wu Lin, Felix Dangel, Runa Eschenhagen, Juhan Bae, Richard E. Turner, Alireza Makhzani</dc:creator>
    </item>
    <item>
      <title>Robust Safety-Critical Control for Systems with Sporadic Measurements and Dwell Time Constraints</title>
      <link>https://arxiv.org/abs/2403.03663</link>
      <description>arXiv:2403.03663v3 Announce Type: replace-cross 
Abstract: This paper presents extensions of control barrier function (CBF) theory to systems with disturbances wherein a controller only receives measurements infrequently and operates open-loop between measurements, while still satisfying state constraints. The paper considers both impulsive and continuous actuators, and models the actuators, measurements, disturbances, and timing constraints as a hybrid dynamical system. We then design an open-loop observer that bounds the worst-case uncertainty between measurements. We develop definitions of CBFs for both actuation cases, and corresponding conditions on the control input to guarantee satisfaction of the state constraints. We apply these conditions to simulations of a satellite rendezvous in an elliptical orbit and autonomous orbit stationkeeping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03663v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joseph Breeden, Luca Zaccarian, Dimitra Panagou</dc:creator>
    </item>
    <item>
      <title>Nonsmooth Implicit Differentiation: Deterministic and Stochastic Convergence Rates</title>
      <link>https://arxiv.org/abs/2403.11687</link>
      <description>arXiv:2403.11687v3 Announce Type: replace-cross 
Abstract: We study the problem of efficiently computing the derivative of the fixed-point of a parametric nondifferentiable contraction map. This problem has wide applications in machine learning, including hyperparameter optimization, meta-learning and data poisoning attacks. We analyze two popular approaches: iterative differentiation (ITD) and approximate implicit differentiation (AID). A key challenge behind the nonsmooth setting is that the chain rule does not hold anymore. We build upon the work by Bolte et al. (2022), who prove linear convergence of nonsmooth ITD under a piecewise Lipschitz smooth assumption. In the deterministic case, we provide a linear rate for AID and an improved linear rate for ITD which closely match the ones for the smooth setting. We further introduce NSID, a new stochastic method to compute the implicit derivative when the contraction map is defined as the composition of an outer map and an inner map which is accessible only through a stochastic unbiased estimator. We establish rates for the convergence of NSID, encompassing the best available rates in the smooth setting. We also present illustrative experiments confirming our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11687v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Grazzi, Massimiliano Pontil, Saverio Salzo</dc:creator>
    </item>
    <item>
      <title>Effect of constraint relaxation on dynamic critical phenomena in minimum vertex cover problem</title>
      <link>https://arxiv.org/abs/2404.02564</link>
      <description>arXiv:2404.02564v3 Announce Type: replace-cross 
Abstract: The effects of constraint relaxation on dynamic critical phenomena in the Minimum Vertex Cover (MVC) problem on Erd\H{o}s-R\'enyi random graphs are investigated using Markov chain Monte Carlo simulations. Following our previous work that revealed the reduction of the critical temperature by constraint relaxation based on the penalty function method, this study focuses on investigating the critical properties of the relaxation time along its phase boundary. It is found that the dynamical correlation function of MVC with respect to the problem size and the constraint strength follows a universal scaling function. The analysis shows that the relaxation time decreases as the constraints are relaxed. This decrease is more pronounced for the critical amplitude than for the critical exponent, and this result is interpreted in terms of the system's microscopic energy barriers due to the constraint relaxation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02564v3</guid>
      <category>cond-mat.stat-mech</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1209/0295-5075/ad5102</arxiv:DOI>
      <dc:creator>Aki Dote, Koji Hukushima</dc:creator>
    </item>
    <item>
      <title>Existence and nonexistence of solutions for underdetermined generalized absolute value equations</title>
      <link>https://arxiv.org/abs/2405.16172</link>
      <description>arXiv:2405.16172v2 Announce Type: replace-cross 
Abstract: Underdetermined generalized absolute value equations (GAVE) has real applications. The underdetermined GAVE may have no solution, one solution, finitely multiple solutions or infinitely many solutions. This paper aims to give some sufficient conditions which guarantee the existence or nonexistence of solutions for the underdetermined GAVE. Particularly, sufficient conditions under which certain or each sign pattern possesses infinitely many solutions of the underdetermined GAVE are given. In addition, iterative methods are developed to solve a solution of the underdetermined GAVE. Some existing results about the square GAVE are extended.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16172v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cairong Chen, Xuehua Li, Ren-Cang Li</dc:creator>
    </item>
  </channel>
</rss>
