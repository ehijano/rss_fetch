<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Aug 2024 04:00:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 16 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A discrete-time survival model to handle interval-censored covariates</title>
      <link>https://arxiv.org/abs/2408.07738</link>
      <description>arXiv:2408.07738v1 Announce Type: new 
Abstract: Methods are lacking to handle the problem of survival analysis in the presence of an interval-censored covariate, specifically the case in which the conditional hazard of the primary event of interest depends on the occurrence of a secondary event, the observation time of which is subject to interval censoring. We propose and study a flexible class of discrete-time parametric survival models that handle the censoring problem through joint modeling of the interval-censored secondary event, the outcome, and the censoring mechanism. We apply this model to the research question that motivated the methodology, estimating the effect of HIV status on all-cause mortality in a prospective cohort study in South Africa.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07738v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Avi Kenny, Stephen Olivier, James P. Hughes, Mark J. Siedner</dc:creator>
    </item>
    <item>
      <title>Combined p-value functions for meta-analysis</title>
      <link>https://arxiv.org/abs/2408.08135</link>
      <description>arXiv:2408.08135v1 Announce Type: new 
Abstract: P-value functions are modern statistical tools that unify effect estimation and hypothesis testing and can provide alternative point and interval estimates compared to standard meta-analysis methods, using any of the many p-value combination procedures available (Xie et al., 2011, JASA). We provide a systematic comparison of different combination procedures, both from a theoretical perspective and through simulation. We show that many prominent p-value combination methods (e.g. Fisher's method) are not invariant to the orientation of the underlying one-sided p-values. Only Edgington's method, a lesser-known combination method based on the sum of p-values, is orientation-invariant and provides confidence intervals not restricted to be symmetric around the point estimate. Adjustments for heterogeneity can also be made and results from a simulation study indicate that the approach can compete with more standard meta-analytic methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08135v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonhard Held, Felix Hofmann, Samuel Pawel</dc:creator>
    </item>
    <item>
      <title>Localized Sparse Principal Component Analysis of Multivariate Time Series in Frequency Domain</title>
      <link>https://arxiv.org/abs/2408.08177</link>
      <description>arXiv:2408.08177v1 Announce Type: new 
Abstract: Principal component analysis has been a main tool in multivariate analysis for estimating a low dimensional linear subspace that explains most of the variability in the data. However, in high-dimensional regimes, naive estimates of the principal loadings are not consistent and difficult to interpret. In the context of time series, principal component analysis of spectral density matrices can provide valuable, parsimonious information about the behavior of the underlying process, particularly if the principal components are interpretable in that they are sparse in coordinates and localized in frequency bands. In this paper, we introduce a formulation and consistent estimation procedure for interpretable principal component analysis for high-dimensional time series in the frequency domain. An efficient frequency-sequential algorithm is developed to compute sparse-localized estimates of the low-dimensional principal subspaces of the signal process. The method is motivated by and used to understand neurological mechanisms from high-density resting-state EEG in a study of first episode psychosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08177v1</guid>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jamshid Namdari, Amita Manatunga, Fabio Ferrarelli, Robert Krafty</dc:creator>
    </item>
    <item>
      <title>Analysing kinematic data from recreational runners using functional data analysis</title>
      <link>https://arxiv.org/abs/2408.08200</link>
      <description>arXiv:2408.08200v1 Announce Type: new 
Abstract: We present a multivariate functional mixed effects model for kinematic data from a large number of recreational runners. The runners' sagittal plane hip and knee angles are modelled jointly as a bivariate function with random effects functions used to account for the dependence among measurements from either side of the body. The model is fitted by first applying multivariate functional principal component analysis (mv-FPCA) and then modelling the mv-FPCA scores using scalar linear mixed effects models. Simulation and bootstrap approaches are introduced to construct simultaneous confidence bands for the fixed effects functions, and covariance functions are reconstructed to summarise the variability structure in the data and thoroughly investigate the suitability of the proposed model. In our scientific application, we observe a statistically significant effect of running speed on both the hip and knee angles. We also observe strong within-subject correlations, reflecting the highly idiosyncratic nature of running technique. Our approach is more generally applicable to modelling multiple streams of smooth kinematic or kinetic data measured repeatedly for multiple subjects in complex experimental designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08200v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edward Gunning, Steven Golovkine, Andrew J. Simpkin, Aoife Burke, Sarah Dillon, Shane Gore, Kieran Moran, Siobhan O'Connor, Enda Whyte, Norma Bargary</dc:creator>
    </item>
    <item>
      <title>Incorporating Local Step-Size Adaptivity into the No-U-Turn Sampler using Gibbs Self Tuning</title>
      <link>https://arxiv.org/abs/2408.08259</link>
      <description>arXiv:2408.08259v1 Announce Type: new 
Abstract: Adapting the step size locally in the no-U-turn sampler (NUTS) is challenging because the step-size and path-length tuning parameters are interdependent. The determination of an optimal path length requires a predefined step size, while the ideal step size must account for errors along the selected path. Ensuring reversibility further complicates this tuning problem. In this paper, we present a method for locally adapting the step size in NUTS that is an instance of the Gibbs self-tuning (GIST) framework. Our approach guarantees reversibility with an acceptance probability that depends exclusively on the conditional distribution of the step size. We validate our step-size-adaptive NUTS method on Neal's funnel density and a high-dimensional normal distribution, demonstrating its effectiveness in challenging scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08259v1</guid>
      <category>stat.ME</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nawaf Bou-Rabee, Bob Carpenter, Tore Selland Kleppe, Milo Marsden</dc:creator>
    </item>
    <item>
      <title>A Bayesian Classification Trees Approach to Treatment Effect Variation with Noncompliance</title>
      <link>https://arxiv.org/abs/2408.07765</link>
      <description>arXiv:2408.07765v1 Announce Type: cross 
Abstract: Estimating varying treatment effects in randomized trials with noncompliance is inherently challenging since variation comes from two separate sources: variation in the impact itself and variation in the compliance rate. In this setting, existing frequentist and flexible machine learning methods are highly sensitive to the weak instruments problem, in which the compliance rate is (locally) close to zero. Bayesian approaches, on the other hand, can naturally account for noncompliance via imputation. We propose a Bayesian machine learning approach that combines the best features of both approaches. Our main methodological contribution is to present a Bayesian Causal Forest model for binary response variables in scenarios with noncompliance by repeatedly imputing individuals' compliance types, allowing us to flexibly estimate varying treatment effects among compliers. Simulation studies demonstrate the usefulness of our approach when compliance and treatment effects are heterogeneous. We apply the method to detect and analyze heterogeneity in the treatment effects in the Illinois Workplace Wellness Study, which not only features heterogeneous and one-sided compliance but also several binary outcomes of interest. We demonstrate the methodology on three outcomes one year after intervention. We confirm a null effect on the presence of a chronic condition, discover meaningful heterogeneity in a "bad health" outcome that cancels out to null in classical partial effect estimates, and find substantial heterogeneity in individuals' perception of management prioritization of health and safety.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07765v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jared D. Fisher, David W. Puelz, Sameer K. Deshpande</dc:creator>
    </item>
    <item>
      <title>A tree perspective on stick-breaking models in covariate-dependent mixtures</title>
      <link>https://arxiv.org/abs/2208.02806</link>
      <description>arXiv:2208.02806v4 Announce Type: replace 
Abstract: Stick-breaking (SB) processes are often adopted in Bayesian mixture models for generating mixing weights. When covariates influence the sizes of clusters, SB mixtures are particularly convenient as they can leverage their connection to binary regression to ease both the specification of covariate effects and posterior computation. Existing SB models are typically constructed based on continually breaking a single remaining piece of the unit stick. We view this from a dyadic tree perspective in terms of a lopsided bifurcating tree that extends only in one side. We show that two unsavory characteristics of SB models are in fact largely due to this lopsided tree structure. We consider a generalized class of SB models with alternative bifurcating tree structures and examine the influence of the underlying tree topology on the resulting Bayesian analysis in terms of prior assumptions, posterior uncertainty, and computational effectiveness. In particular, we provide evidence that a balanced tree topology, which corresponds to continually breaking all remaining pieces of the unit stick, can resolve or mitigate these undesirable properties of SB models that rely on a lopsided tree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.02806v4</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akira Horiguchi, Cliburn Chan, Li Ma</dc:creator>
    </item>
    <item>
      <title>A new clustering framework</title>
      <link>https://arxiv.org/abs/2305.00578</link>
      <description>arXiv:2305.00578v2 Announce Type: replace 
Abstract: Detecting clusters is a critical task in various fields, including statistics, engineering and bioinformatics. Our focus is primarily on the modern high-dimensional scenario, where traditional methods often fail due to the curse of dimensionality. In this study, we introduce a non-parametric framework for clustering that is applicable to any number of dimensions. Simulation results demonstrate that this new framework surpasses existing methods across a wide range of settings. We illustrate the proposed method with real data applications in distinguishing cancer tissues from normal tissues through gene expression data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00578v2</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Chen, Xiancheng Lin</dc:creator>
    </item>
    <item>
      <title>On Doubly Robust Estimation with Nonignorable Missing Data Using Instrumental Variables</title>
      <link>https://arxiv.org/abs/2311.08691</link>
      <description>arXiv:2311.08691v3 Announce Type: replace 
Abstract: Suppose we are interested in the mean of an outcome that is subject to nonignorable nonresponse. This paper develops new semiparametric estimation methods with instrumental variables which affect nonresponse, but not the outcome. The proposed estimators remain consistent and asymptotically normal even under partial model misspecifications for two variation independent nuisance components. We evaluate the performance of the proposed estimators via a simulation study, and apply them in adjusting for missing data induced by HIV testing refusal in the evaluation of HIV seroprevalence in Mochudi, Botswana, using interviewer experience as an instrumental variable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.08691v3</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baoluo Sun, Wang Miao, Deshanee S. Wickramarachchi</dc:creator>
    </item>
    <item>
      <title>Extreme-value modelling of migratory bird arrival dates: Insights from citizen science data</title>
      <link>https://arxiv.org/abs/2312.01870</link>
      <description>arXiv:2312.01870v4 Announce Type: replace 
Abstract: Citizen science mobilises many observers and gathers huge datasets but often without strict sampling protocols, resulting in observation biases due to heterogeneous sampling effort, which can lead to biased statistical inferences. We develop a spatiotemporal Bayesian hierarchical model for bias-corrected estimation of arrival dates of the first migratory bird individuals at a breeding site. Higher sampling effort could be correlated with earlier observed dates. We implement data fusion of two citizen-science datasets with fundamentally different protocols (BBS, eBird) and map posterior distributions of the latent process, which contains four spatial components with Gaussian process priors: species niche; sampling effort; position and scale parameters of annual first arrival date. The data layer includes four response variables: counts of observed eBird locations (Poisson); presence-absence at observed eBird locations (Binomial); BBS occurrence counts (Poisson); first arrival dates (Generalised Extreme-Value). We devise a Markov Chain Monte Carlo scheme and check by simulation that the latent process components are identifiable. We apply our model to several migratory bird species in the northeastern US for 2001--2021 and find that the sampling effort significantly modulates the observed first arrival date. We exploit this relationship to effectively bias-correct predictions of the true first arrivals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01870v4</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan Koh, Thomas Opitz</dc:creator>
    </item>
    <item>
      <title>Inverting estimating equations for causal inference on quantiles</title>
      <link>https://arxiv.org/abs/2401.00987</link>
      <description>arXiv:2401.00987v2 Announce Type: replace 
Abstract: The causal inference literature frequently focuses on estimating the mean of the potential outcome, whereas quantiles of the potential outcome may carry important additional information. We propose a unified approach, based on the inverse estimating equations, to generalize a class of causal inference solutions from estimating the mean of the potential outcome to its quantiles. We assume that a moment function is available to identify the mean of the threshold-transformed potential outcome, based on which a convenient construction of the estimating equation of quantiles of potential outcome is proposed. In addition, we give a general construction of the efficient influence functions of the mean and quantiles of potential outcomes, and explicate their connection. We motivate estimators for the quantile estimands with the efficient influence function, and develop their asymptotic properties when either parametric models or data-adaptive machine learners are used to estimate the nuisance functions. A broad implication of our results is that one can rework the existing result for mean causal estimands to facilitate causal inference on quantiles. Our general results are illustrated by several analytical and numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00987v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chao Cheng, Fan Li</dc:creator>
    </item>
  </channel>
</rss>
