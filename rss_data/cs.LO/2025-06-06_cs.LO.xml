<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Jun 2025 04:00:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Redefining Functionality and Construction-Defining Capacity: Functions as Principles of Syntactic and Semantic Generation</title>
      <link>https://arxiv.org/abs/2506.04278</link>
      <description>arXiv:2506.04278v1 Announce Type: new 
Abstract: This study redefines the notion of functionality-traditionally understood as a property of mappings or structure preservation-from a more fundamental and generative perspective. Introducing the concept of a Construction-Defining function (CDF), we formalize functionality as a dual capacity to generate both syntactic terms and semantic interpretations. We provide an explicit axiomatization of CDF based on syntactic generativity and semantic compositionality, and further construct categorical models using initial algebras and endofunctors to validate the generality of this concept. Through comparative analysis with type theory, model theory, and formal semantics, we demonstrate that functionality, in this enriched sense, serves as a foundational principle for structural generation across diverse theoretical domains. By reexamining the very nature of functions and their role in structure formation, this work contributes to a unified understanding of logic,semantics, and computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04278v1</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yumiko Nishiyama</dc:creator>
    </item>
    <item>
      <title>Logical Inferentialism &amp; Attacks on Classical Logic</title>
      <link>https://arxiv.org/abs/2506.04295</link>
      <description>arXiv:2506.04295v1 Announce Type: new 
Abstract: This paper undertakes a foundational inquiry into logical inferentialism with particular emphasis on the normative standards it establishes and the implications these pose for classical logic. The central question addressed herein is: 'What is Logical Inferentialism &amp; How do its Standards challenge Classical Logic?' In response, the study begins with a survey of the three principal proof systems that is, David Hilbert's axiomatic systems and Gerhard Gentzen's natural deduction and his sequent calculus, thus situating logical inferentialism within a broader proof-theoretic landscape. The investigation then turns to the core tenets of logical inferentialism by focusing on the role of introduction and elimination rules in determining the meaning of logical constants. Through this framework, natural deduction is evaluated as a system that satisfies key inferentialist virtues including harmony, conservativeness and the subformula property. Ultimately, the paper presents challenges to classical logic from intuitionist and revisionist perspectives by arguing that certain classical principles fail to uphold inferentialist standards, consequently undermining their legitimacy within a meaning-theoretic framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04295v1</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Khashayar Irani</dc:creator>
    </item>
    <item>
      <title>Trustworthiness Preservation by Copies of Machine Learning Systems</title>
      <link>https://arxiv.org/abs/2506.05203</link>
      <description>arXiv:2506.05203v1 Announce Type: new 
Abstract: A common practice of ML systems development concerns the training of the same model under different data sets, and the use of the same (training and test) sets for different learning models. The first case is a desirable practice for identifying high quality and unbiased training conditions. The latter case coincides with the search for optimal models under a common dataset for training. These differently obtained systems have been considered akin to copies. In the quest for responsible AI, a legitimate but hardly investigated question is how to verify that trustworthiness is preserved by copies. In this paper we introduce a calculus to model and verify probabilistic complex queries over data and define four distinct notions: Justifiably, Equally, Weakly and Almost Trustworthy which can be checked analysing the (partial) behaviour of the copy with respect to its original. We provide a study of the relations between these notions of trustworthiness, and how they compose with each other and under logical operations. The aim is to offer a computational tool to check the trustworthiness of possibly complex systems copied from an original whose behavour is known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05203v1</guid>
      <category>cs.LO</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonardo Ceragioli, Giuseppe Primiero</dc:creator>
    </item>
    <item>
      <title>Proceedings of the 19th International Workshop on Logical and Semantic Frameworks, with Applications</title>
      <link>https://arxiv.org/abs/2506.05219</link>
      <description>arXiv:2506.05219v1 Announce Type: new 
Abstract: This volume contains the post-proceedings of the 19th LSFA, which was held in Goi\^ania, the capital of Goi\'as state in Brazil, from September 18 to September 20, 2024.
  Logical and semantic frameworks are formal languages used to represent logics, languages and systems. These frameworks provide foundations for the formal specification of systems and programming languages, supporting tool development and reasoning. 
  The aim of this series is bringing together theoreticians and practitioners to promote new techniques and results, from the theoretical side, and feedback on the implementation and use of such techniques and results, from the practical side. LSFA includes areas such as proof and type theory, equational deduction and rewriting systems, automated reasoning and concurrency theory.
</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05219v1</guid>
      <category>cs.LO</category>
      <category>cs.SC</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.421</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 421, 2025</arxiv:journal_reference>
      <dc:creator>Cynthia Kop (Radboud Universiteit Nijmegen), Helida Salles Santos (Universidade Federal do Rio Grande)</dc:creator>
    </item>
    <item>
      <title>On Top-Down Pseudo-Boolean Model Counting</title>
      <link>https://arxiv.org/abs/2506.05232</link>
      <description>arXiv:2506.05232v1 Announce Type: new 
Abstract: Pseudo-Boolean model counting involves computing the number of satisfying assignments of a given pseudo-Boolean (PB) formula. In recent years, PB model counting has seen increased interest partly owing to the succinctness of PB formulas over typical propositional Boolean formulas in conjunctive normal form (CNF) at describing problem constraints. In particular, the research community has developed tools to tackle exact PB model counting. These recently developed counters follow one of the two existing major designs for model counters, namely the bottom-up model counter design. A natural question would be whether the other major design, the top-down model counter paradigm, would be effective at PB model counting, especially when the top-down design offered superior performance in CNF model counting literature.
  In this work, we investigate the aforementioned top-down design for PB model counting and introduce the first exact top-down PB model counter, PBMC. PBMC is a top-down search-based counter for PB formulas, with a new variable decision heuristic that considers variable coefficients. Through our evaluations, we highlight the superior performance of PBMC at PB model counting compared to the existing state-of-the-art counters PBCount, PBCounter, and Ganak. In particular, PBMC could count for 1849 instances while the next-best competing method, PBCount, could only count for 1773 instances, demonstrating the potential of a top-down PB counter design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05232v1</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Suwei Yang, Yong Lai, Kuldeep S. Meel</dc:creator>
    </item>
    <item>
      <title>An Expansion-Based Approach for Quantified Integer Programming</title>
      <link>https://arxiv.org/abs/2506.04452</link>
      <description>arXiv:2506.04452v1 Announce Type: cross 
Abstract: Quantified Integer Programming (QIP) bridges multiple domains by extending Quantified Boolean Formulas (QBF) to incorporate general integer variables and linear constraints while also generalizing Integer Programming through variable quantification. As a special case of Quantified Constraint Satisfaction Problems (QCSP), QIP provides a versatile framework for addressing complex decision-making scenarios. Additionally, the inclusion of a linear objective function enables QIP to effectively model multistage robust discrete linear optimization problems, making it a powerful tool for tackling uncertainty in optimization.
  While two primary solution paradigms exist for QBF -- search-based and expansion-based approaches -- only search-based methods have been explored for QIP and QCSP. We introduce an expansion-based approach for QIP using Counterexample-Guided Abstraction Refinement (CEGAR), adapting techniques from QBF. We extend this methodology to tackle multistage robust discrete optimization problems with linear constraints and further embed it in an optimization framework, enhancing its applicability. Our experimental results highlight the advantages of this approach, demonstrating superior performance over existing search-based solvers for QIP in specific instances. Furthermore, the ability to model problems using linear constraints enables notable performance gains over state-of-the-art expansion-based solvers for QBF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04452v1</guid>
      <category>cs.DM</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Hartisch, Leroy Chew</dc:creator>
    </item>
    <item>
      <title>Judicial Permission</title>
      <link>https://arxiv.org/abs/2506.04610</link>
      <description>arXiv:2506.04610v1 Announce Type: cross 
Abstract: This paper examines the significance of weak permissions in criminal trials (\emph{judicial permission}). It introduces a dialogue game model to systematically address judicial permissions, considering different standards of proof and argumentation semantics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04610v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LO</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guido Governatori, Antonino Rotolo</dc:creator>
    </item>
    <item>
      <title>Dissecting Logical Reasoning in LLMs: A Fine-Grained Evaluation and Supervision Study</title>
      <link>https://arxiv.org/abs/2506.04810</link>
      <description>arXiv:2506.04810v1 Announce Type: cross 
Abstract: Logical reasoning is a core capability for many applications of large language models (LLMs), yet existing benchmarks often rely solely on final-answer accuracy, failing to capture the quality and structure of the reasoning process. We propose FineLogic, a fine-grained evaluation framework that assesses logical reasoning across three dimensions: overall benchmark accuracy, stepwise soundness, and representation-level alignment. In addition, to better understand how reasoning capabilities emerge, we conduct a comprehensive study on the effects of supervision format during fine-tuning. We construct four supervision styles (one natural language and three symbolic variants) and train LLMs under each. Our findings reveal that natural language supervision yields strong generalization even on out-of-distribution and long-context tasks, while symbolic reasoning styles promote more structurally sound and atomic inference chains. Further, our representation-level probing shows that fine-tuning primarily improves reasoning behaviors through step-by-step generation, rather than enhancing shortcut prediction or internalized correctness. Together, our framework and analysis provide a more rigorous and interpretable lens for evaluating and improving logical reasoning in LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04810v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yujun Zhou, Jiayi Ye, Zipeng Ling, Yufei Han, Yue Huang, Haomin Zhuang, Zhenwen Liang, Kehan Guo, Taicheng Guo, Xiangqi Wang, Xiangliang Zhang</dc:creator>
    </item>
    <item>
      <title>Classical notions of computation and the Hasegawa-Thielecke theorem</title>
      <link>https://arxiv.org/abs/2502.13033</link>
      <description>arXiv:2502.13033v2 Announce Type: replace 
Abstract: In the spirit of the Curry-Howard correspondence between proofs and programs, we define and study a syntax and semantics for classical logic equipped with a computationally involutive negation, using a polarised effect calculus. A main challenge in designing a denotational semantics is to accommodate both call-by-value and call-by-name evaluation strategies, which leads to a failure of associativity of composition. Building on the work of the third author, we devise the notion of dialogue duploid, which provides a non-associative and effectful counterpart to the notion of dialogue category introduced by the second author in his 2-categorical account, based on adjunctions, of logical polarities and continuations. We show that the syntax of the polarised calculus can be interpreted in any dialogue duploid, and that it defines in fact a syntactic dialogue duploid. As an application, we establish, by semantic as well as syntactic means, the Hasegawa-Thielecke theorem, which states that the notions of central map and of thunkable map coincide in any dialogue duploid (in particular, for any double negation monad on a symmetric monoidal category).</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13033v2</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <category>math.CT</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>\'El\'eonore Mangel, Paul-Andr\'e Melli\`es, Guillaume Munch-Maccagnoni</dc:creator>
    </item>
    <item>
      <title>Information Science Principles of Machine Learning: A Causal Chain Meta-Framework Based on Formalized Information Mapping</title>
      <link>https://arxiv.org/abs/2505.13182</link>
      <description>arXiv:2505.13182v5 Announce Type: replace 
Abstract: [Objective] This study focuses on addressing the current lack of a unified formal theoretical framework in machine learning, as well as the deficiencies in interpretability and ethical safety assurance. [Methods] A formal information model is first constructed, utilizing sets of well-formed formulas to explicitly define the ontological states and carrier mappings of typical components in machine learning. Learnable and processable predicates, along with learning and processing functions, are introduced to analyze the logical deduction and constraint rules of the causal chains within models. [Results] A meta-framework for machine learning theory (MLT-MF) is established. Based on this framework, universal definitions for model interpretability and ethical safety are proposed. Furthermore, three key theorems are proved: the equivalence of model interpretability and information recoverability, the assurance of ethical safety, and the estimation of generalization error. [Limitations] The current framework assumes ideal conditions with noiseless information-enabling mappings and primarily targets model learning and processing logic in static scenarios. It does not yet address information fusion and conflict resolution across ontological spaces in multimodal or multi-agent systems. [Conclusions] This work overcomes the limitations of fragmented research and provides a unified theoretical foundation for systematically addressing the critical challenges currently faced in machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13182v5</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianfeng Xu</dc:creator>
    </item>
  </channel>
</rss>
