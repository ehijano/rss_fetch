<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.TO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.TO</link>
    <description>q-bio.TO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.TO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Jul 2025 01:47:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Intestinal villi and crypts density maximizing nutrient absorption</title>
      <link>https://arxiv.org/abs/2507.03472</link>
      <description>arXiv:2507.03472v1 Announce Type: new 
Abstract: The villi and crypts of the gastrointestinal tract increase the effective surface area of the intestinal mucosa, potentially enhancing nutrient absorption. It is commonly assumed that this is their primary function, and that a higher villi density necessarily leads to improved absorption. However, when villi are packed too closely together, diffusion can be hindered, potentially offsetting this benefit. In this work, we investigate the relationship between the density of these structures and the overall efficiency of absorption. In three different simplified geometries, approximating crypts, leaf-like villi, and finger-like villi we calculate analytically the concentration profile and the absorption flux, assuming that there is only diffusion between these structures while the lumen is well mixed. When plotting the absorption flux per unit of gut length as a function of the structures' density, we observe that there is a density maximizing absorption. We study numerically this optimum. It depends weakly on the absorption properties of the given nutrient, so that a geometry optimal for one nutrient is close to optimum for another nutrient. Physiological data from various animal species align with this predicted optimal range and potentially reflect evolutionary selection for efficient nutrient uptake, supporting the model's validity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03472v1</guid>
      <category>q-bio.TO</category>
      <category>physics.bio-ph</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Garic, Rohan Vernekar, D\'acil I. Y\'anez Mart\'in, St\'ephane Tanguy, Cl\'ement de Loubens, Claude Loverdo</dc:creator>
    </item>
    <item>
      <title>Establishing Causal Relationship Between Whole Slide Image Predictions and Diagnostic Evidence Subregions in Deep Learning</title>
      <link>https://arxiv.org/abs/2407.17157</link>
      <description>arXiv:2407.17157v3 Announce Type: replace-cross 
Abstract: Due to the lack of fine-grained annotation guidance, current Multiple Instance Learning (MIL) struggles to establish a robust causal relationship between Whole Slide Image (WSI) diagnosis and evidence sub-images, just like fully supervised learning. So many noisy images can undermine the network's prediction. The proposed Causal Inference Multiple Instance Learning (CI-MIL), uses out-of-distribution generalization to reduce the recognition confusion of sub-images by MIL network, without requiring pixelwise annotations. Specifically, feature distillation is introduced to roughly identify the feature representation of lesion patches. Then, in the random Fourier feature space, these features are re-weighted to minimize the cross-correlation, effectively correcting the feature distribution deviation. These processes reduce the uncertainty when tracing the prediction results back to patches. Predicted diagnoses are more direct and reliable because the causal relationship between them and diagnostic evidence images is more clearly recognized by the network. Experimental results demonstrate that CI-MIL outperforms state-of-the-art methods, achieving 92.25% accuracy and 95.28% AUC on the Camelyon16 dataset (breast cancer), while 94.29% accuracy and 98.07% AUC on the TCGA-NSCLC dataset (non-small cell lung cancer). Additionally, CI-MIL exhibits superior interpretability, as its selected regions demonstrate high consistency with ground truth annotations, promising more reliable diagnostic assistance for pathologists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17157v3</guid>
      <category>cs.CV</category>
      <category>q-bio.TO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tianhang Nan, Yong Ding, Hao Quan, Deliang Li, Lisha Li, Guanghong Zhao, Xiaoyu Cui</dc:creator>
    </item>
    <item>
      <title>Distilling High Diagnostic Value Patches for Whole Slide Image Classification Using Attention Mechanism</title>
      <link>https://arxiv.org/abs/2407.19821</link>
      <description>arXiv:2407.19821v3 Announce Type: replace-cross 
Abstract: Multiple Instance Learning (MIL) has garnered widespread attention in the field of Whole Slide Image (WSI) classification as it replaces pixel-level manual annotation with diagnostic reports as labels, significantly reducing labor costs. Recent research has shown that bag-level MIL methods often yield better results because they can consider all patches of the WSI as a whole. However, a drawback of such methods is the incorporation of more redundant patches, leading to interference. To extract patches with high diagnostic value while excluding interfering patches to address this issue, we developed an attention-based feature distillation multi-instance learning (AFD-MIL) approach. This approach proposed the exclusion of redundant patches as a preprocessing operation in weakly supervised learning, directly mitigating interference from extensive noise. It also pioneers the use of attention mechanisms to distill features with high diagnostic value, as opposed to the traditional practice of indiscriminately and forcibly integrating all patches. Additionally, we introduced global loss optimization to finely control the feature distillation module. AFD-MIL is orthogonal to many existing MIL methods, leading to consistent performance improvements. This approach has surpassed the current state-of-the-art method, achieving 91.47% ACC (accuracy) and 94.29% AUC (area under the curve) on the Camelyon16 (Camelyon Challenge 2016, breast cancer), while 93.33% ACC and 98.17% AUC on the TCGA-NSCLC (The Cancer Genome Atlas Program: non-small cell lung cancer). Different feature distillation methods were used for the two datasets, tailored to the specific diseases, thereby improving performance and interpretability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19821v3</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>q-bio.TO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tianhang Nan, Hao Quan, Yong Ding, Xingyu Li, Kai Yang, Xiaoyu Cui</dc:creator>
    </item>
    <item>
      <title>A Novel Automatic Real-time Motion Tracking Method in MRI-guided Radiotherapy Using Enhanced Tracking-Learning-Detection Framework with Automatic Segmentation</title>
      <link>https://arxiv.org/abs/2411.07503</link>
      <description>arXiv:2411.07503v3 Announce Type: replace-cross 
Abstract: Background and Purpose: Accurate motion tracking in MRI-guided Radiotherapy (MRIgRT) is essential for effective treatment delivery. This study aimed to enhance motion tracking precision in MRIgRT through an automatic real-time markerless tracking method using an enhanced Tracking-Learning-Detection (ETLD) framework with automatic segmentation. Materials and Methods: We developed a novel MRIgRT motion tracking and segmentation method by integrating the ETLD framework with an improved Chan-Vese model (ICV), named ETLD+ICV. The ETLD framework was upgraded for real-time cine MRI, including advanced image preprocessing, no-reference image quality assessment, an enhanced median-flow tracker, and a refined detector with dynamic search region adjustments. ICV was used for precise target volume coverage, refining the segmented region frame by frame using tracking results, with key parameters optimized. The method was tested on 3.5D MRI scans from 10 patients with liver metastases. Results: Evaluation of 106,000 frames across 77 treatment fractions showed sub-millimeter tracking errors of less than 0.8mm, with over 99% precision and 98% recall for all subjects in the Beam Eye View(BEV)/Beam Path View(BPV) orientation. The ETLD+ICV method achieved a dice global score of more than 82% for all subjects, demonstrating the method's extensibility and precise target volume coverage. Conclusion: This study successfully developed an automatic real-time markerless motion tracking method for MRIgRT that significantly outperforms current methods. The novel method not only delivers exceptional precision in tracking and segmentation but also shows enhanced adaptability to clinical demands, making it an indispensable asset in improving the efficacy of radiotherapy treatments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07503v3</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>physics.med-ph</category>
      <category>q-bio.TO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengqi Chen, Zilin Wang, Jianrong Dai, Shirui Qin, Ying Cao, Ruiao Zhao, Jiayun Chen, Guohua Wu, Yuan Tang</dc:creator>
    </item>
  </channel>
</rss>
