<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 10 Oct 2024 04:07:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Navigating Inflation in Ghana: How Can Machine Learning Enhance Economic Stability and Growth Strategies</title>
      <link>https://arxiv.org/abs/2410.05630</link>
      <description>arXiv:2410.05630v1 Announce Type: new 
Abstract: Inflation remains a persistent challenge for many African countries. This research investigates the critical role of machine learning (ML) in understanding and managing inflation in Ghana, emphasizing its significance for the country's economic stability and growth. Utilizing a comprehensive dataset spanning from 2010 to 2022, the study aims to employ advanced ML models, particularly those adept in time series forecasting, to predict future inflation trends. The methodology is designed to provide accurate and reliable inflation forecasts, offering valuable insights for policymakers and advocating for a shift towards data-driven approaches in economic decision-making. This study aims to significantly advance the academic field of economic analysis by applying machine learning (ML) and offering practical guidance for integrating advanced technological tools into economic governance, ultimately demonstrating ML's potential to enhance Ghana's economic resilience and support sustainable development through effective inflation management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05630v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Theophilus G. Baidoo, Ashley Obeng</dc:creator>
    </item>
    <item>
      <title>The Transmission of Monetary Policy via Common Cycles in the Euro Area</title>
      <link>https://arxiv.org/abs/2410.05741</link>
      <description>arXiv:2410.05741v1 Announce Type: new 
Abstract: We use a FAVAR model with proxy variables and sign restrictions to investigate the role of the euro area common output and inflation cycles in the transmission of monetary policy shocks. We find that common cycles explain most of the variation in output and inflation across member countries, while Southern European economies show larger deviations from the cycles in the aftermath of the financial crisis. Building on this evidence, we show that monetary policy is homogeneously propagated to member countries via the common cycles. In contrast, country-specific transmission channels lead to heterogeneous country responses to monetary policy shocks. Consequently, our empirical results suggest that the divergent effects of ECB monetary policy are due to heterogeneous country-specific exposures to financial markets and not due to dis-synchronized economies of the euro area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05741v1</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lukas Berend, Jan Pr\"user</dc:creator>
    </item>
    <item>
      <title>Green bubbles: a four-stage paradigm for detection and propagation</title>
      <link>https://arxiv.org/abs/2410.06564</link>
      <description>arXiv:2410.06564v1 Announce Type: new 
Abstract: Climate change has emerged as a significant global concern, attracting increasing attention worldwide. While green bubbles may be examined through a social bubble hypothesis, it is essential not to neglect a Climate Minsky moment triggered by sudden asset price changes. The significant increase in green investments highlights the urgent need for a comprehensive understanding of these market dynamics. Therefore, the current paper introduces a novel paradigm for studying such phenomena. Focusing on the renewable energy sector, Statistical Process Control (SPC) methodologies are employed to identify green bubbles within time series data. Furthermore, search volume indexes and social factors are incorporated into established econometric models to reveal potential implications for the financial system. Inspired by Joseph Schumpeter's perspectives on business cycles, this study recognizes green bubbles as a necessary evil for facilitating a successful transition towards a more sustainable future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06564v1</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gian Luca Vriz, Luigi Grossi</dc:creator>
    </item>
    <item>
      <title>Group Shapley Value and Counterfactual Simulations in a Structural Model</title>
      <link>https://arxiv.org/abs/2410.06875</link>
      <description>arXiv:2410.06875v1 Announce Type: new 
Abstract: We propose a variant of the Shapley value, the group Shapley value, to interpret counterfactual simulations in structural economic models by quantifying the importance of different components. Our framework compares two sets of parameters, partitioned into multiple groups, and applying group Shapley value decomposition yields unique additive contributions to the changes between these sets. The relative contributions sum to one, enabling us to generate an importance table that is as easily interpretable as a regression table. The group Shapley value can be characterized as the solution to a constrained weighted least squares problem. Using this property, we develop robust decomposition methods to address scenarios where inputs for the group Shapley value are missing. We first apply our methodology to a simple Roy model and then illustrate its usefulness by revisiting two published papers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06875v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongchan Kwon, Sokbae Lee, Guillaume A. Pouliot</dc:creator>
    </item>
    <item>
      <title>Collusion Detection with Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2410.07091</link>
      <description>arXiv:2410.07091v1 Announce Type: new 
Abstract: Collusion is a complex phenomenon in which companies secretly collaborate to engage in fraudulent practices. This paper presents an innovative methodology for detecting and predicting collusion patterns in different national markets using neural networks (NNs) and graph neural networks (GNNs). GNNs are particularly well suited to this task because they can exploit the inherent network structures present in collusion and many other economic problems. Our approach consists of two phases: In Phase I, we develop and train models on individual market datasets from Japan, the United States, two regions in Switzerland, Italy, and Brazil, focusing on predicting collusion in single markets. In Phase II, we extend the models' applicability through zero-shot learning, employing a transfer learning approach that can detect collusion in markets in which training data is unavailable. This phase also incorporates out-of-distribution (OOD) generalization to evaluate the models' performance on unseen datasets from other countries and regions. In our empirical study, we show that GNNs outperform NNs in detecting complex collusive patterns. This research contributes to the ongoing discourse on preventing collusion and optimizing detection methodologies, providing valuable guidance on the use of NNs and GNNs in economic applications to enhance market fairness and economic welfare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07091v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Gomes, Jannis Kueck, Mara Mattes, Martin Spindler, Alexey Zaytsev</dc:creator>
    </item>
    <item>
      <title>Identification and estimation for matrix time series CP-factor models</title>
      <link>https://arxiv.org/abs/2410.05634</link>
      <description>arXiv:2410.05634v1 Announce Type: cross 
Abstract: We investigate the identification and the estimation for matrix time series CP-factor models. Unlike the generalized eigenanalysis-based method of Chang et al. (2023) which requires the two factor loading matrices to be full-ranked, the newly proposed estimation can handle rank-deficient factor loading matrices. The estimation procedure consists of the spectral decomposition of several matrices and a matrix joint diagonalization algorithm, resulting in low computational cost. The theoretical guarantee established without the stationarity assumption shows that the proposed estimation exhibits a faster convergence rate than that of Chang et al. (2023). In fact the new estimator is free from the adverse impact of any eigen-gaps, unlike most eigenanalysis-based methods such as that of Chang et al. (2023). Furthermore, in terms of the error rates of the estimation, the proposed procedure is equivalent to handling a vector time series of dimension $\max(p,q)$ instead of $p \times q$, where $(p, q)$ are the dimensions of the matrix time series concerned. We have achieved this without assuming the "near orthogonality" of the loadings under various incoherence conditions often imposed in the CP-decomposition literature, see Han and Zhang (2022), Han et al. (2024) and the references within. Illustration with both simulated and real matrix time series data shows the usefulness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05634v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinyuan Chang, Yue Du, Guanglin Huang, Qiwei Yao</dc:creator>
    </item>
    <item>
      <title>Persistence-Robust Break Detection in Predictive Quantile and CoVaR Regressions</title>
      <link>https://arxiv.org/abs/2410.05861</link>
      <description>arXiv:2410.05861v1 Announce Type: cross 
Abstract: Forecasting risk (as measured by quantiles) and systemic risk (as measured by Adrian and Brunnermeiers's (2016) CoVaR) is important in economics and finance. However, past research has shown that predictive relationships may be unstable over time. Therefore, this paper develops structural break tests in predictive quantile and CoVaR regressions. These tests can detect changes in the forecasting power of covariates, and are based on the principle of self-normalization. We show that our tests are valid irrespective of whether the predictors are stationary or near-stationary, rendering the tests suitable for a range of practical applications. Simulations illustrate the good finite-sample properties of our tests. Two empirical applications concerning equity premium and systemic risk forecasting models show the usefulness of the tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05861v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yannick Hoga</dc:creator>
    </item>
    <item>
      <title>Finitely Heterogeneous Treatment Effect in Event-study</title>
      <link>https://arxiv.org/abs/2204.02346</link>
      <description>arXiv:2204.02346v5 Announce Type: replace 
Abstract: A key assumption of the differences-in-differences designs is that the average evolution of untreated potential outcomes is the same across different treatment cohorts: a parallel trends assumption. In this paper, we relax the parallel trend assumption by assuming a latent type variable and developing a type-specific parallel trend assumption. With a finite support assumption on the latent type variable and long pretreatment time periods, we show that an extremum classifier consistently estimates the type assignment. Based on the classification result, we propose a type-specific diff-in-diff estimator for type-specific ATT. By estimating the type-specific ATT, we study heterogeneity in treatment effect, in addition to heterogeneity in baseline outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.02346v5</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Myungkou Shin</dc:creator>
    </item>
    <item>
      <title>Double Robust Bayesian Inference on Average Treatment Effects</title>
      <link>https://arxiv.org/abs/2211.16298</link>
      <description>arXiv:2211.16298v5 Announce Type: replace 
Abstract: We propose a double robust Bayesian inference procedure on the average treatment effect (ATE) under unconfoundedness. For our new Bayesian approach, we first adjust the prior distributions of the conditional mean functions, and then correct the posterior distribution of the resulting ATE. Both adjustments make use of pilot estimators motivated by the semiparametric influence function for ATE estimation. We prove asymptotic equivalence of our Bayesian procedure and efficient frequentist ATE estimators by establishing a new semiparametric Bernstein-von Mises theorem under double robustness; i.e., the lack of smoothness of conditional mean functions can be compensated by high regularity of the propensity score and vice versa. Consequently, the resulting Bayesian credible sets form confidence intervals with asymptotically exact coverage probability. In simulations, our method provides precise point estimates of the ATE through the posterior mean and credible intervals that closely align with the nominal coverage probability. Furthermore, our approach achieves a shorter interval length in comparison to existing methods. We illustrate our method in an application to the National Supported Work Demonstration following LaLonde [1986] and Dehejia and Wahba [1999].</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.16298v5</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Breunig, Ruixuan Liu, Zhengfei Yu</dc:creator>
    </item>
    <item>
      <title>Digital Divide: Empirical Study of CIUS 2020</title>
      <link>https://arxiv.org/abs/2301.07855</link>
      <description>arXiv:2301.07855v3 Announce Type: replace 
Abstract: As Canada and other major economies consider implementing "digital money" or Central Bank Digital Currencies, understanding how demographic and geographic factors influence public engagement with digital technologies becomes increasingly important. This paper uses data from the 2020 Canadian Internet Use Survey and employs survey-adapted Lasso inference methods to identify individual socio-economic and demographic characteristics determining the digital divide in Canada. We also introduce a score to measure and compare the digital literacy of various segments of Canadian population. Our findings reveal that disparities in the use of e.g. online banking, emailing, and digital payments exist across different demographic and socio-economic groups. In addition, we document the effects of COVID-19 pandemic on internet use in Canada and describe changes in the characteristics of Canadian internet users over the last decade.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.07855v3</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joann Jasiak, Peter MacKenzie, Purevdorj Tuvaandorj</dc:creator>
    </item>
    <item>
      <title>Difference-in-Differences with Unpoolable Data</title>
      <link>https://arxiv.org/abs/2403.15910</link>
      <description>arXiv:2403.15910v2 Announce Type: replace 
Abstract: Difference-in-differences (DID) is commonly used to estimate treatment effects but is infeasible in settings where data are unpoolable due to privacy concerns or legal restrictions on data sharing, particularly across jurisdictions. In this study, we identify and relax the assumption of data poolability in DID estimation. We propose an innovative approach to estimate DID with unpoolable data (UN-DID) which can accommodate covariates, multiple groups, and staggered adoption. Through analytical proofs and Monte Carlo simulations, we show that UN-DID and conventional DID estimates of the average treatment effect and standard errors are equal and unbiased in settings without covariates. With covariates, both methods produce estimates that are unbiased, equivalent, and converge to the true value. The estimates differ slightly but the statistical inference and substantive conclusions remain the same. Two empirical examples with real-world data further underscore UN-DID's utility. The UN-DID method allows the estimation of cross-jurisdictional treatment effects with unpoolable data, enabling better counterfactuals to be used and new research questions to be answered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15910v2</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sunny Karim, Matthew D. Webb, Nichole Austin, Erin Strumpf</dc:creator>
    </item>
    <item>
      <title>Efficient Asymmetric Causality Tests</title>
      <link>https://arxiv.org/abs/2408.03137</link>
      <description>arXiv:2408.03137v4 Announce Type: replace 
Abstract: Asymmetric causality tests are increasingly gaining popularity in different scientific fields. This approach corresponds better to reality since logical reasons behind asymmetric behavior exist and need to be considered in empirical investigations. Hatemi-J (2012) introduced the asymmetric causality tests via partial cumulative sums for positive and negative components of the variables operating within the vector autoregressive (VAR) model. However, since the residuals across the equations in the VAR model are not independent, the ordinary least squares method for estimating the parameters is not efficient. Additionally, asymmetric causality tests mean having different causal parameters (i.e., for positive or negative components), thus, it is crucial to assess not only if these causal parameters are individually statistically significant, but also if their difference is statistically significant. Consequently, tests of difference between estimated causal parameters should explicitly be conducted, which are neglected in the existing literature. The purpose of the current paper is to deal with these issues explicitly. An application is provided, and ten different hypotheses pertinent to the asymmetric causal interaction between two largest financial markets worldwide are efficiently tested within a multivariate setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03137v4</guid>
      <category>econ.EM</category>
      <category>q-fin.ST</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abdulnasser Hatemi-J</dc:creator>
    </item>
    <item>
      <title>Optimal Treatment Allocation Strategies for A/B Testing in Partially Observable Time Series Experiments</title>
      <link>https://arxiv.org/abs/2408.05342</link>
      <description>arXiv:2408.05342v2 Announce Type: replace 
Abstract: Time series experiments, in which experimental units receive a sequence of treatments over time, are frequently employed in many technological companies to evaluate the performance of a newly developed policy, product, or treatment relative to a baseline control. Many existing A/B testing solutions assume a fully observable experimental environment that satisfies the Markov condition, which often does not hold in practice. This paper studies the optimal design for A/B testing in partially observable environments. We introduce a controlled (vector) autoregressive moving average model to capture partial observability. We introduce a small signal asymptotic framework to simplify the analysis of asymptotic mean squared errors of average treatment effect estimators under various designs. We develop two algorithms to estimate the optimal design: one utilizing constrained optimization and the other employing reinforcement learning. We demonstrate the superior performance of our designs using a dispatch simulator and two real datasets from a ride-sharing company. A Python implementation of our proposal is available at https://github.com/datake/ARMADesign.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05342v2</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ke Sun, Linglong Kong, Hongtu Zhu, Chengchun Shi</dc:creator>
    </item>
  </channel>
</rss>
