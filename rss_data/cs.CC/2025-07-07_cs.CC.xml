<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Jul 2025 04:01:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Complexity of learning matchings and half graphs via edge queries</title>
      <link>https://arxiv.org/abs/2507.03151</link>
      <description>arXiv:2507.03151v1 Announce Type: new 
Abstract: The problem of learning or reconstructing an unknown graph from a known family via partial-information queries arises as a mathematical model in various contexts. The most basic type of access to the graph is via \emph{edge queries}, where an algorithm may query the presence/absence of an edge between a pair of vertices of its choosing, at unit cost.
  While more powerful query models have been extensively studied in the context of graph reconstruction, the basic model of edge queries seems to have not attracted as much attention. In this paper we study the edge query complexity of learning a hidden bipartite graph, or equivalently its bipartite adjacency matrix, in the classical as well as quantum settings. We focus on learning matchings and half graphs, which are graphs whose bipartite adjacency matrices are a row/column permutation of the identity matrix and the lower triangular matrix with all entries on and below the principal diagonal being 1, respectively.
  \begin{itemize}
  \item For matchings of size $n$, we show a tight deterministic bound of $n(n-1)/2$ and an asymptotically tight randomized bound of $\Theta(n^2)$. A quantum bound of $\Theta(n^{1.5})$ was shown in a recent work of van Apeldoorn et al.~[ICALP'21].
  \item For half graphs whose bipartite adjacency matrix is a column-permutation of the $n \times n$ lower triangular matrix,
  we give tight $\Theta(n \log n)$ bounds in both deterministic and randomized settings, and an $\Omega(n)$ quantum lower bound. \item For general half graphs,
  we observe that the problem is equivalent to a natural generalization of the famous nuts-and-bolts problem, leading to a tight $\Theta(n \log n)$ randomized bound.
  We also present a simple quicksort-style method that instantiates to a $O(n \log^2 n)$ randomized algorithm and a tight $O(n \log n)$ quantum algorithm.
  \end{itemize}</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03151v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhil S. Mande, Swagato Sanyal, Viktor Zamaraev</dc:creator>
    </item>
    <item>
      <title>A Near-Optimal Polynomial Distance Lemma Over Boolean Slices</title>
      <link>https://arxiv.org/abs/2507.03193</link>
      <description>arXiv:2507.03193v1 Announce Type: new 
Abstract: The celebrated Ore-DeMillo-Lipton-Schwartz-Zippel (ODLSZ) lemma asserts that n-variate non-zero polynomial functions of degree d over a field $\mathbb{F}$ are non-zero over any "grid" $S^n$ for finite subset $S \subseteq \mathbb{F}$, with probability at least $\max\{|S|^{-d/(|S|-1)},1-d/|S|\}$ over the choice of random point from the grid. In particular, over the Boolean cube ($S = \{0,1\} \subseteq \mathbb{F}$), the lemma asserts non-zero polynomials are non-zero with probability at least $2^{-d}$. In this work we extend the ODLSZ lemma optimally (up to lower-order terms) to "Boolean slices" i.e., points of Hamming weight exactly $k$. We show that non-zero polynomials on the slice are non-zero with probability $(t/n)^{d}(1 - o_{n}(1))$ where $t = \min\{k,n-k\}$ for every $d\leq k\leq (n-d)$. As with the ODLSZ lemma, our results extend to polynomials over Abelian groups. This bound is tight (upto the error term) as evidenced by degree d multilinear monomials. A particularly interesting case is the "balanced slice" ($k=n/2$) where our lemma asserts that non-zero polynomials are non-zero with roughly the same probability on the slice as on the whole cube.
  The behaviour of low-degree polynomials over Boolean slices has received much attention in recent years. However, the problem of proving a tight version of the ODLSZ lemma does not seem to have been considered before, except for a recent work of Amireddy, Behera, Paraashar, Srinivasan and Sudan (SODA 2025) who established a sub-optimal bound of approximately $((k/n)\cdot(1-(k/n)))^d$ using a proof similar to that of the standard ODLSZ lemma.
  While the statement of our result mimics that of the ODLSZ lemma, our proof is significantly more intricate and involves spectral reasoning which is employed to show that a natural way of embedding a copy of the Boolean cube inside a balanced Boolean slice is a good sampler.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03193v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prashanth Amireddy, Amik Raj Behera, Srikanth Srinivasan, Madhu Sudan</dc:creator>
    </item>
    <item>
      <title>Are Depth-2 Regular Expressions Hard to Intersect?</title>
      <link>https://arxiv.org/abs/2507.03593</link>
      <description>arXiv:2507.03593v1 Announce Type: new 
Abstract: We study the basic regular expression intersection testing problem, which asks to determine whether the intersection of the languages of two regular expressions is nonempty. A textbook solution to this problem is to construct the nondeterministic finite automaton that accepts the language of both expressions. This procedure results in a $\Theta(mn)$ running time, where $m$ and $n$ are the sizes of the two expressions, respectively. Following the approach of Backurs and Indyk [FOCS'16] and Bringmann, Gr{\o}nlund, and Larsen [FOCS'17] on regular expression matching and membership testing, we study the complexity of intersection testing for homogeneous regular expressions of bounded depth involving concatenation, OR, Kleene star, and Kleene plus. Specifically, we consider all combinations of types of depth-2 regular expressions and classify the time complexity of intersection testing as either linear or quadratic, assuming SETH. The most interesting result is a quadratic conditional lower bound for testing the intersection of a ''concatenation of +s'' expression with a ''concatenation of ORs'' expression: this is the only hard case that does not involve the Kleene star operator and is not implied by existing lower bounds for the simpler membership testing problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03593v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rocco Ascone, Giulia Bernardini, Alessio Conte, Veronica Guerrini, Giulia Punzi</dc:creator>
    </item>
    <item>
      <title>Quantum Computation with Correlated Measurements: Implications for the Complexity Landscape</title>
      <link>https://arxiv.org/abs/2507.03692</link>
      <description>arXiv:2507.03692v1 Announce Type: new 
Abstract: In 2004, Aaronson introduced the complexity class $\mathsf{PostBQP}$ ($\mathsf{BQP}$ with postselection) and showed that it is equal to $\mathsf{PP}$. In this paper, we define a new complexity class, $\mathsf{CorrBQP}$, a modification of $\mathsf{BQP}$ which has the power to perform correlated measurements, i.e. measurements that output the same value across a partition of registers. We show that $\mathsf{CorrBQP}$ is exactly equal to $\mathsf{BPP}^{\mathsf{PP}}$, placing it "just above" $\mathsf{PP}$. In fact, we show that other metaphysical modifications of $\mathsf{BQP}$, such as $\mathsf{CBQP}$ (i.e. $\mathsf{BQP}$ with the ability to clone arbitrary quantum states), are also equal to $\mathsf{BPP}^{\mathsf{PP}}$. Furthermore, we show that $\mathsf{CorrBQP}$ is self-low with respect to classical queries. In contrast, if it were self-low under quantum queries, the counting hierarchy ($\mathsf{CH}$) would collapse to $\mathsf{BPP}^{\mathsf{PP}}$. Finally, we introduce a variant of rational degree that lower-bounds the query complexity of $\mathsf{BPP}^{\mathsf{PP}}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03692v1</guid>
      <category>cs.CC</category>
      <category>quant-ph</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Miloschewsky, Supartha Podder</dc:creator>
    </item>
    <item>
      <title>Low sets for counting functions</title>
      <link>https://arxiv.org/abs/2507.04110</link>
      <description>arXiv:2507.04110v1 Announce Type: new 
Abstract: In this paper, we characterize the classes of languages and functions that are low for counting function classes. The classes #P and GapP have their low classes exactly characterized: Low(#P) = UP $\cap$ coUP and Low(GapP) = SPP. We prove that Low(TotP) = P, Low(SpanP) = NP $\cap$ coNP, and give characterizations of low function classes for #P, GapP, TotP, and SpanP. We establish the relations between NPSVt, UPSVt, and the counting function classes. For each of the inclusions between these classes we give an equivalent inclusion between language classes. We also prove that SpanP $\subseteq$ GapP if and only if NP $\subseteq$ SPP, and the inclusion GapP+ $\subseteq$ SpanP implies PH = $\Sigma_{2}^{P}$. For the classes #P, GapP, TotP, and SpanP we summarize the known results and prove that each of these classes is closed under left composition with FP+ if and only if it collapses to its low class of functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04110v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yaroslav Ivanashev</dc:creator>
    </item>
    <item>
      <title>On the Approximability of Train Routing and the Min-Max Disjoint Paths Problem</title>
      <link>https://arxiv.org/abs/2507.03687</link>
      <description>arXiv:2507.03687v1 Announce Type: cross 
Abstract: In train routing, the headway is the minimum distance that must be maintained between successive trains for safety and robustness. We introduce a model for train routing that requires a fixed headway to be maintained between trains, and study the problem of minimizing the makespan, i.e., the arrival time of the last train, in a single-source single-sink network. For this problem, we first show that there exists an optimal solution where trains move in convoys, that is, the optimal paths for any two trains are either the same or are arc-disjoint. Via this insight, we are able to reduce the approximability of our train routing problem to that of the min-max disjoint paths problem, which asks for a collection of disjoint paths where the maximum length of any path in the collection is as small as possible. While min-max disjoint paths inherits a strong inapproximability result on directed acyclic graphs from the multi-level bottleneck assignment problem, we show that a natural greedy composition approach yields a logarithmic approximation in the number of disjoint paths for series-parallel graphs. We also present an alternative analysis of this approach that yields a guarantee depending on how often the decomposition tree of the series-parallel graph alternates between series and parallel compositions on any root-leaf path.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03687v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Umang Bhaskar, Katharina Eickhoff, Lennart Kauther, Jannik Matuschke, Britta Peis, Laura Vargas Koch</dc:creator>
    </item>
    <item>
      <title>PFCS: Prime Factorization Cache System for Deterministic Data Relationship Discovery</title>
      <link>https://arxiv.org/abs/2507.03919</link>
      <description>arXiv:2507.03919v1 Announce Type: cross 
Abstract: Cache systems fundamentally limit modern computing performance due to their inability to precisely capture data relationships. While achieving 85-92% hit rates, traditional systems rely on statistical heuristics that cannot guarantee relationship discovery, leading to suboptimal prefetching and resource waste. We present PFCS (Prime Factorization Cache System), which leverages the mathematical uniqueness of prime factorization to achieve deterministic relationship discovery with zero false positives. PFCS assigns unique primes to data elements and represents relationships as composite numbers, enabling the recovery of perfect relationships through factorization. A comprehensive evaluation across database, ML, and HPC workloads demonstrates an average performance improvement of x 6.2, 98.9% hit rates, and a 38% power reduction compared to state-of-the-art systems. The mathematical foundation provides formal guarantees impossible with approximation-based approaches, establishing a new paradigm for cache system design</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03919v1</guid>
      <category>cs.DB</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Duy Le</dc:creator>
    </item>
    <item>
      <title>Testing for Renamability to Classes of Clause Sets</title>
      <link>https://arxiv.org/abs/2507.05044</link>
      <description>arXiv:2507.05044v1 Announce Type: cross 
Abstract: This paper investigates the problem of testing clause sets for membership in classes known from literature. In particular, we are interested in classes defined via renaming: Is it possible to rename the predicates in a way such that positive and negative literals satisfy certain conditions? We show that for classes like Horn or OCC1N, the existence of such renamings can be decided in polynomial time, whereas the same problem is NP-complete for class PVD. The decision procedures are based on hyper-resolution; if a renaming exists, it can be extracted from the final saturated clause set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05044v1</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>In Proc. Int. Workshop on First-Order Theorem Proving (FTP'97), Maria Paola Bonacina and Ulrich Fuhrbach, editors. RISC-Linz Report Series No. 97-50, pages 34--39. Johannes Kepler Universit\"at, Linz, Austria, 1997</arxiv:journal_reference>
      <dc:creator>Albert Brandl, Christian G. Ferm\"uller, Gernot Salzer</dc:creator>
    </item>
    <item>
      <title>A proof of P != NP (New symmetric encryption algorithm against any linear attacks and differential attacks)</title>
      <link>https://arxiv.org/abs/2203.05022</link>
      <description>arXiv:2203.05022v5 Announce Type: replace 
Abstract: P vs NP problem is the most important unresolved problem in the field of computational complexity. Its impact has penetrated into all aspects of algorithm design, especially in the field of cryptography. The security of cryptographic algorithms based on short keys depends on whether P is equal to NP. In fact, Shannon[1] strictly proved that the one-time-pad system meets unconditional security, but because the one-time-pad system requires the length of key to be at least the length of plaintext, how to transfer the key is a troublesome problem that restricts the use of the one-time-pad system in practice. Cryptography algorithms used in practice are all based on short key, and the security of the short key mechanism is ultimately based on "one-way" assumption, that is, it is assumed that a one-way function exists. In fact, the existence of one-way function can directly lead to the important conclusion P != NP. In this paper, we originally constructed a short-key block cipher algorithm. The core feature of this algorithm is that for any block, when a plaintext-ciphertext pair is known, any key in the key space can satisfy the plaintext-ciphertext pair, that is, for each block, the plaintext-ciphertext pair and the key are independence, and the independence between blocks is also easy to construct. This feature is completely different from all existing short-key cipher algorithms. Based on the above feature, we construct a problem and theoretically prove that the problem satisfies the properties of one-way functions, thereby solving the problem of the existence of one-way functions, that is, directly proving that P != NP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.05022v5</guid>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gao Ming</dc:creator>
    </item>
    <item>
      <title>Sharp Thresholds for the Overlap Gap Property: Ising $p$-Spin Glass and Random $k$-SAT</title>
      <link>https://arxiv.org/abs/2309.09913</link>
      <description>arXiv:2309.09913v2 Announce Type: replace-cross 
Abstract: The Ising $p$-spin glass and random $k$-SAT are two canonical examples of disordered systems that play a central role in understanding the link between geometric features of optimization landscapes and computational tractability. Both models exhibit hard regimes where all known polynomial-time algorithms fail and possess the multi Overlap Gap Property ($m$-OGP), an intricate geometrical property that rigorously rules out a broad class of algorithms exhibiting input stability.
  We establish that, in both models, the symmetric $m$-OGP undergoes a sharp phase transition, and we pinpoint its exact threshold. For the Ising $p$-spin glass, our results hold for all sufficiently large $p$; for the random $k$-SAT, they apply to all $k$ growing mildly with the number of Boolean variables. Notably, our findings yield qualitative insights into the power of OGP-based arguments. A particular consequence for the Ising $p$-spin glass is that the strength of the $m$-OGP in establishing algorithmic hardness grows without bound as $m$ increases.
  These are the first sharp threshold results for the $m$-OGP. Our analysis hinges on a judicious application of the second moment method, enhanced by concentration. While a direct second moment calculation fails, we overcome this via a refined approach that leverages an argument of~\cite{frieze1990independence} and exploiting concentration properties of carefully constructed random variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09913v2</guid>
      <category>math.PR</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eren C. K{\i}z{\i}lda\u{g}</dc:creator>
    </item>
    <item>
      <title>Learning unitaries with quantum statistical queries</title>
      <link>https://arxiv.org/abs/2310.02254</link>
      <description>arXiv:2310.02254v2 Announce Type: replace-cross 
Abstract: We propose several algorithms for learning unitary operators from quantum statistical queries with respect to their Choi-Jamiolkowski state. Quantum statistical queries capture the capabilities of a learner with limited quantum resources, which receives as input only noisy estimates of expected values of measurements. Our approach leverages quantum statistical queries to estimate the Fourier mass of a unitary on a subset of Pauli strings, generalizing previous techniques developed for uniform quantum examples. Specifically, we show that the celebrated quantum Goldreich-Levin algorithm can be implemented with quantum statistical queries, whereas the prior version of the algorithm involves oracle access to the unitary and its inverse. As an application, we prove that quantum Boolean functions with constant total influence or with constant degree are efficiently learnable in our model. Moreover, we prove that $\mathcal{O}(\log n)$-juntas are efficiently learnable and constant-depth circuits are learnable query-efficiently with quantum statistical queries. On the other hand, all previous algorithms for these tasks demand significantly greater resources, such as oracle access to the unitary or direct access to the Choi-Jamiolkowski state. We also demonstrate that, despite these positive results, quantum statistical queries lead to an exponentially larger query complexity for certain tasks, compared to separable measurements to the Choi-Jamiolkowski state. In particular, we show an exponential lower bound for learning a class of phase-oracle unitaries and a double exponential lower bound for testing the unitarity of channels. Taken together, our results indicate that quantum statistical queries offer a unified framework for various unitary learning tasks, with potential applications in quantum machine learning, many-body physics and benchmarking of near-term devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02254v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Armando Angrisani</dc:creator>
    </item>
    <item>
      <title>Quantum PCPs: on Adaptivity, Multiple Provers and Reductions to Local Hamiltonians</title>
      <link>https://arxiv.org/abs/2403.04841</link>
      <description>arXiv:2403.04841v2 Announce Type: replace-cross 
Abstract: We define a general formulation of quantum PCPs, which captures adaptivity and multiple unentangled provers, and give a detailed construction of the quantum reduction to a local Hamiltonian with a constant promise gap. The reduction turns out to be a versatile subroutine to prove properties of quantum PCPs, allowing us to show: (i) Non-adaptive quantum PCPs can simulate adaptive quantum PCPs when the number of proof queries is constant. In fact, this can even be shown to hold when the non-adaptive quantum PCP picks the proof indices simply uniformly at random from a subset of all possible index combinations, answering an open question by Aharonov, Arad, Landau and Vazirani (STOC '09). (ii) If the $q$-local Hamiltonian problem with constant promise gap can be solved in $\mathsf{QCMA}$, then $\mathsf{QPCP}[q] \subseteq \mathsf{QCMA}$ for any $q \in O(1)$. (iii) If $\mathsf{QMA}(k)$ has a quantum PCP for any $k \leq \text{poly}(n)$, then $\mathsf{QMA}(2) = \mathsf{QMA}$, connecting two of the longest-standing open problems in quantum complexity theory. Moreover, we also show that there exist (quantum) oracles relative to which certain quantum PCP statements are false. Hence, any attempt to prove the quantum PCP conjecture requires, just as was the case for the classical PCP theorem, (quantumly) non-relativizing techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04841v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harry Buhrman, Jonas Helsen, Jordi Weggemans</dc:creator>
    </item>
    <item>
      <title>On classical advice, sampling advise and complexity assumptions for learning separations</title>
      <link>https://arxiv.org/abs/2408.13880</link>
      <description>arXiv:2408.13880v4 Announce Type: replace-cross 
Abstract: In this paper, we study the relationship between advice in the form of a training set and classical advice. We do this by analyzing the class $\mathsf{BPP/samp}$ and certain variants of it. Specifically, our main result demonstrates that $\mathsf{BPP/samp}$ is a proper subset of the class $\mathsf{P/poly}$, which implies that advice in the form of a training set is strictly weaker than classical advice. This result remains valid when considering quantum advice and a quantum generalization of the training set. Finally, leveraging the insights from our proofs, we identify both sufficient and necessary complexity-theoretic assumptions for the existence of concept classes that exhibit a quantum learning speed-up. We consider both the worst-case setting, where accurate results are required for all inputs, and the average-case setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13880v4</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jordi P\'erez-Guijarro</dc:creator>
    </item>
    <item>
      <title>Classical Algorithms for Constant Approximation of the Ground State Energy of Local Hamiltonians</title>
      <link>https://arxiv.org/abs/2410.21833</link>
      <description>arXiv:2410.21833v3 Announce Type: replace-cross 
Abstract: We construct classical algorithms computing an approximation of the ground state energy of an arbitrary $k$-local Hamiltonian acting on $n$ qubits.
  We first consider the setting where a good ``guiding state'' is available, which is the main setting where quantum algorithms are expected to achieve an exponential speedup over classical methods. We show that a constant approximation (i.e., an approximation with constant relative accuracy) of the ground state energy can be computed classically in $\mathrm{poly}\left(1/\chi,n\right)$ time and $\mathrm{poly}(n)$ space, where $\chi$ denotes the overlap between the guiding state and the ground state (as in prior works in dequantization, we assume sample-and-query access to the guiding state). This gives a significant improvement over the recent classical algorithm by Gharibian and Le Gall (SICOMP 2023), and matches (up a to polynomial overhead) both the time and space complexities of quantum algorithms for constant approximation of the ground state energy. We also obtain classical algorithms for higher-precision approximation.
  For the setting where no guided state is given (i.e., the standard version of the local Hamiltonian problem), we obtain a classical algorithm computing a constant approximation of the ground state energy in $2^{O(n)}$ time and $\mathrm{poly}(n)$ space. To our knowledge, before this work it was unknown how to classically achieve these bounds simultaneously, even for constant approximation. We also discuss complexity-theoretic aspects of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21833v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Le Gall</dc:creator>
    </item>
    <item>
      <title>Unstructured Adiabatic Quantum Optimization: Optimality with Limitations</title>
      <link>https://arxiv.org/abs/2411.05736</link>
      <description>arXiv:2411.05736v3 Announce Type: replace-cross 
Abstract: In the circuit model of quantum computing, amplitude amplification techniques can be used to find solutions to NP-hard problems defined on $n$-bits in time $\text{poly}(n) 2^{n/2}$. In this work, we investigate whether such general statements can be made for adiabatic quantum optimization, as provable results regarding its performance are mostly unknown. Although a lower bound of $\Omega(2^{n/2})$ has existed in such a setting for over a decade, a purely adiabatic algorithm with this running time has been absent. We show that adiabatic quantum optimization using an unstructured search approach results in a running time that matches this lower bound (up to a polylogarithmic factor) for a broad class of classical local spin Hamiltonians. For this, it is necessary to bound the spectral gap throughout the adiabatic evolution and compute beforehand the position of the avoided crossing with sufficient precision so as to adapt the adiabatic schedule accordingly. However, we show that the position of the avoided crossing is approximately given by a quantity that depends on the degeneracies and inverse gaps of the problem Hamiltonian and is NP-hard to compute even within a low additive precision. Furthermore, computing it exactly (or nearly exactly) is \#P-hard. Our work indicates a possible limitation of adiabatic quantum optimization algorithms, leaving open the question of whether provable Grover-like speed-ups can be obtained for any optimization problem using this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05736v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arthur Braida, Shantanav Chakraborty, Alapan Chaudhuri, Joseph Cunningham, Rutvij Menavlikar, Leonardo Novo, J\'er\'emie Roland</dc:creator>
    </item>
    <item>
      <title>Characterizing the Distinguishability of Product Distributions through Multicalibration</title>
      <link>https://arxiv.org/abs/2412.03562</link>
      <description>arXiv:2412.03562v4 Announce Type: replace-cross 
Abstract: Given a sequence of samples $x_1, \dots , x_k$ promised to be drawn from one of two distributions $X_0, X_1$, a well-studied problem in statistics is to decide $\textit{which}$ distribution the samples are from. Information theoretically, the maximum advantage in distinguishing the two distributions given $k$ samples is captured by the total variation distance between $X_0^{\otimes k}$ and $X_1^{\otimes k}$. However, when we restrict our attention to $\textit{efficient distinguishers}$ (i.e., small circuits) of these two distributions, exactly characterizing the ability to distinguish $X_0^{\otimes k}$ and $X_1^{\otimes k}$ is more involved and less understood.
  In this work, we give a general way to reduce bounds on the computational indistinguishability of $X_0$ and $X_1$ to bounds on the $\textit{information-theoretic}$ indistinguishability of some specific, related variables $\widetilde{X}_0$ and $\widetilde{X}_1$. As a consequence, we prove a new, tight characterization of the number of samples $k$ needed to efficiently distinguish $X_0^{\otimes k}$ and $X_1^{\otimes k}$ with constant advantage as
  \[
  k = \Theta\left(d_H^{-2}\left(\widetilde{X}_0, \widetilde{X}_1\right)\right),
  \] which is the inverse of the squared Hellinger distance $d_H$ between two distributions $\widetilde{X}_0$ and $\widetilde{X}_1$ that are computationally indistinguishable from $X_0$ and $X_1$. Likewise, our framework can be used to re-derive a result of Halevi and Rabin (TCC 2008) and Geier (TCC 2022), proving nearly-tight bounds on how computational indistinguishability scales with the number of samples for arbitrary product distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03562v4</guid>
      <category>cs.CR</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Cassandra Marcussen, Aaron Putterman, Salil Vadhan</dc:creator>
    </item>
    <item>
      <title>Induced Minor Models. II. Sufficient conditions for polynomial-time detection of induced minors</title>
      <link>https://arxiv.org/abs/2501.00161</link>
      <description>arXiv:2501.00161v3 Announce Type: replace-cross 
Abstract: The $H$-Induced Minor Containment problem ($H$-IMC) consists in deciding if a fixed graph $H$ is an induced minor of a graph $G$ given as input, that is, whether $H$ can be obtained from $G$ by deleting vertices and contracting edges. Equivalently, the problem asks if there exists an induced minor model of $H$ in $G$, that is, a collection of disjoint subsets of vertices of $G$, each inducing a connected subgraph, such that contracting each subgraph into a single vertex results in $H$.
  It is known that $H$-IMC is NP-complete for several graphs $H$, even when $H$ is a tree. In this work, we investigate which properties of $H$ guarantee the existence of an induced minor model whose structure can be leveraged to solve the problem in polynomial time. This allows us to identify four infinite families of graphs $H$ that enjoy such properties. Moreover, we show that if the input graph $G$ excludes long induced paths, then $H$-IMC is polynomial-time solvable for any fixed graph $H$. As a byproduct of our results, this implies that $H$-IMC is polynomial-time solvable for all graphs $H$ with at most $5$ vertices, except for three open cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00161v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ement Dallard, Ma\"el Dumas, Claire Hilaire, Anthony Perez</dc:creator>
    </item>
    <item>
      <title>On estimating the quantum $\ell_{\alpha}$ distance</title>
      <link>https://arxiv.org/abs/2505.00457</link>
      <description>arXiv:2505.00457v2 Announce Type: replace-cross 
Abstract: We study the computational complexity of estimating the quantum $\ell_{\alpha}$ distance ${\mathrm{T}_\alpha}(\rho_0,\rho_1)$, defined via the Schatten $\alpha$-norm $\|A\|_{\alpha} = \mathrm{tr}(|A|^{\alpha})^{1/\alpha}$, given $\operatorname{poly}(n)$-size state-preparation circuits of $n$-qubit quantum states $\rho_0$ and $\rho_1$. This quantity serves as a lower bound on the trace distance for $\alpha &gt; 1$. For any constant $\alpha &gt; 1$, we develop an efficient rank-independent quantum estimator for ${\mathrm{T}_\alpha}(\rho_0,\rho_1)$ with time complexity $\operatorname{poly}(n)$, achieving an exponential speedup over the prior best results of $\exp(n)$ due to Wang, Guan, Liu, Zhang, and Ying (TIT 2024). Our improvement leverages efficiently computable uniform polynomial approximations of signed positive power functions within quantum singular value transformation, thereby eliminating the dependence on the rank of the quantum states.
  Our quantum algorithm reveals a dichotomy in the computational complexity of the Quantum State Distinguishability Problem with Schatten $\alpha$-norm (QSD$_{\alpha}$), which involves deciding whether ${\mathrm{T}_\alpha}(\rho_0,\rho_1)$ is at least $2/5$ or at most $1/5$. This dichotomy arises between the cases of constant $\alpha &gt; 1$ and $\alpha=1$:
  - For any $1+\Omega(1) \leq \alpha \leq O(1)$, QSD$_{\alpha}$ is $\mathsf{BQP}$-complete.
  - For any $1 \leq \alpha \leq 1+\frac{1}{n}$, QSD$_{\alpha}$ is $\mathsf{QSZK}$-complete, implying that no efficient quantum estimator for $\mathrm{T}_\alpha(\rho_0,\rho_1)$ exists unless $\mathsf{BQP} = \mathsf{QSZK}$.
  The hardness results follow from reductions based on new rank-dependent inequalities for the quantum $\ell_{\alpha}$ distance with $1\leq \alpha \leq \infty$, which are of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00457v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yupan Liu, Qisheng Wang</dc:creator>
    </item>
    <item>
      <title>Collapses in quantum-classical probabilistically checkable proofs and the quantum polynomial hierarchy</title>
      <link>https://arxiv.org/abs/2506.19792</link>
      <description>arXiv:2506.19792v2 Announce Type: replace-cross 
Abstract: We investigate the structure of quantum proof systems by establishing collapse results that reveal simplifications in their complexity landscape. By extending classical theorems such as the Karp-Lipton theorem to quantum settings and analyzing uniqueness in quantum-classical PCPs, we clarify how various constraints influence computational power.
  Our main contributions are:
  (1) We show that restricting quantum-classical PCPs to unique proofs does not reduce their power: $\mathsf{UniqueQCPCP} = \mathsf{QCPCP}$ under $\mathsf{BQ}$-operator and randomized reductions. This parallels the known $\mathsf{UniqueQCMA} = \mathsf{QCMA}$ result, indicating robustness of uniqueness even in quantum PCP-type systems.
  (2) We prove a non-uniform quantum analogue of the Karp-Lipton theorem: if $\mathsf{QMA} \subseteq \mathsf{BQP}/\mathsf{qpoly}$, then $\mathsf{QPH} \subseteq \mathsf{Q\Sigma}_2/\mathsf{qpoly}$. This conditional collapse suggests limits on quantum advice for $\mathsf{QMA}$-complete problems.
  (3) We define a bounded-entanglement version of the quantum polynomial hierarchy, $\mathsf{BEQPH}$, and prove that it collapses above the fourth level. We also introduce the separable hierarchy $\mathsf{SepQPH}$ (zero entanglement), for which the same collapse result holds. These collapses stem not from entanglement, as in prior work, but from the convex structure of the protocols, which renders higher levels tractable.
  Collectively, these results offer new insights into the structure of quantum proof systems and the role of entanglement, uniqueness, and advice in defining their complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19792v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kartik Anand, Kabgyun Jeong, Junseo Lee</dc:creator>
    </item>
    <item>
      <title>Tight Success Probabilities for Quantum Period Finding and Phase Estimation</title>
      <link>https://arxiv.org/abs/2506.20527</link>
      <description>arXiv:2506.20527v2 Announce Type: replace-cross 
Abstract: Period finding and phase estimation are fundamental in quantum computing. Prior work has established lower bounds on their success probabilities. Such quantum algorithms measure a state $|\hat\ell\rangle$ in an $n$-qubit computational basis, $\hat\ell \in [0, 2^n - 1]$, and then post-process this measurement to produce the final output, in the case of period finding, a divisor of the period $r$. We consider a general post-processing algorithm which succeeds whenever the measured $\hat\ell$ is within some tolerance $M$ of a positive integer multiple of $2^n / r$. We give new (tight) lower and upper bounds on the success probability that converge to 1. The parameter $n$ captures the complexity of the quantum circuit. The parameter $M$ can be tuned by varying the post-processing algorithm (e.g., additional brute-force search, lattice methods). Our tight analysis allows for the careful exploitation of the tradeoffs between the complexity of the quantum circuit and the effort spent in classical processing when optimizing the probability of success. We note that the most recent prior work in most recent work does not give tight bounds for general $M$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20527v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Malik Magdon-Ismail, Khai Dong</dc:creator>
    </item>
    <item>
      <title>Dominating Set Knapsack: Profit Optimization on Dominating Sets</title>
      <link>https://arxiv.org/abs/2506.24032</link>
      <description>arXiv:2506.24032v2 Announce Type: replace-cross 
Abstract: In a large-scale network, we want to choose some influential nodes to make a profit by paying some cost within a limited budget so that we do not have to spend more budget on some nodes adjacent to the chosen nodes; our problem is the graph-theoretic representation of it. We define our problem Dominating Set Knapsack by attaching Knapsack Problem with Dominating Set on graphs. Each vertex is associated with a cost factor and a profit amount. We aim to choose some vertices within a fixed budget that gives maximum profit so that we do not need to choose their 1-hop neighbors. We show that the Dominating Set Knapsack problem is strongly NP-complete even when restricted to Bipartite graphs but weakly NP-complete for Star graphs. We present a pseudo-polynomial time algorithm for Trees in time $O(n\cdot min\{s^2, (\alpha(V))^2\})$. We show that Dominating Set Knapsack is very unlikely to be Fixed Parameter Tractable(FPT) by proving that it is in W[2]-hard parameterized by the solution size. We developed FPT algorithms with running time $O(4^{tw}\cdot n^{O(1)} \cdot min\{s^2, ((\alpha(V))^2\})$ and $O(2^{vck-1}\cdot n^{O(1)} \cdot min\{s^2,(\alpha(V))^2\})$, where $tw$ represents the treewidth of the given graph, $vck$ is the solution size of the Vertex Cover Knapsack, $s$ is the size of the knapsack and $\alpha(V)=\sum_{v\in V}\alpha(v)$. We obtained similar results for other variants k-Dominating Set Knapsack and Minimal Dominating Set Knapsack. We obtained similar results for other variants k-Dominating Set Knapsack and Minimal Dominating Set Knapsack.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.24032v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sipra Singh</dc:creator>
    </item>
  </channel>
</rss>
