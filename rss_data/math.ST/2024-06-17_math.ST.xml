<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Jun 2024 02:48:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 17 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>New algorithms for sampling and diffusion models</title>
      <link>https://arxiv.org/abs/2406.09665</link>
      <description>arXiv:2406.09665v1 Announce Type: new 
Abstract: Drawing from the theory of stochastic differential equations, we introduce a novel sampling method for known distributions and a new algorithm for diffusion generative models with unknown distributions. Our approach is inspired by the concept of the reverse diffusion process, widely adopted in diffusion generative models. Additionally, we derive the explicit convergence rate based on the smooth ODE flow. For diffusion generative models and sampling, we establish a {\it dimension-free} particle approximation convergence result. Numerical experiments demonstrate the effectiveness of our method. Notably, unlike the traditional Langevin method, our sampling method does not require any regularity assumptions about the density function of the target distribution. Furthermore, we also apply our method to optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09665v1</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Xicheng Zhang</dc:creator>
    </item>
    <item>
      <title>Stable network inference in high-dimensional graphical model using single-linkage</title>
      <link>https://arxiv.org/abs/2406.09865</link>
      <description>arXiv:2406.09865v1 Announce Type: new 
Abstract: Stability, akin to reproducibility, is crucial in statistical analysis. This paper examines the stability of sparse network inference in high-dimensional graphical models, where selected edges should remain consistent across different samples. Our study focuses on the Graphical Lasso and its decomposition into two steps, with the first step involving hierarchical clustering using single linkage.We provide theoretical proof that single linkage is stable, evidenced by controlled distances between two dendrograms inferred from two samples. Practical experiments further illustrate the stability of the Graphical Lasso's various steps, including dendrograms, variable clusters, and final networks. Our results, validated through both theoretical analysis and practical experiments using simulated and real datasets, demonstrate that single linkage is more stable than other methods when a modular structure is present.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09865v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emilie Devijver (APTIKAL), R\'emi Molinier (IF), M\'elina Gallopin (I2BC)</dc:creator>
    </item>
    <item>
      <title>Optimal Rates for Functional Linear Regression with General Regularization</title>
      <link>https://arxiv.org/abs/2406.10005</link>
      <description>arXiv:2406.10005v1 Announce Type: new 
Abstract: Functional linear regression is one of the fundamental and well-studied methods in functional data analysis. In this work, we investigate the functional linear regression model within the context of reproducing kernel Hilbert space by employing general spectral regularization to approximate the slope function with certain smoothness assumptions. We establish optimal convergence rates for estimation and prediction errors associated with the proposed method under a H\"{o}lder type source condition, which generalizes and sharpens all the known results in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10005v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naveen Gupta, S. Sivananthan, Bharath K. Sriperumbudur</dc:creator>
    </item>
    <item>
      <title>Statistical inference for rough volatility: Central limit theorems</title>
      <link>https://arxiv.org/abs/2210.01216</link>
      <description>arXiv:2210.01216v3 Announce Type: replace 
Abstract: In recent years, there has been a substantive interest in rough volatility models. In this class of models, the local behavior of stochastic volatility is much more irregular than semimartingales and resembles that of a fractional Brownian motion with Hurst parameter $H &lt; 0.5$. In this paper, we derive a consistent and asymptotically mixed normal estimator of $H$ based on high-frequency price observations. In contrast to previous works, we work in a semiparametric setting and do not assume any a priori relationship between volatility estimators and true volatility. Furthermore, our estimator attains a rate of convergence that is known to be optimal in a minimax sense in parametric rough volatility models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.01216v3</guid>
      <category>math.ST</category>
      <category>q-fin.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1214/23-AAP2002</arxiv:DOI>
      <arxiv:journal_reference>The Annals of Applied Probability, Vol. 34, No. 3, 2600-2649, 2024</arxiv:journal_reference>
      <dc:creator>Carsten Chong, Marc Hoffmann, Yanghui Liu, Mathieu Rosenbaum, Gr\'egoire Szymanski</dc:creator>
    </item>
    <item>
      <title>Testing mean and variance by e-processes</title>
      <link>https://arxiv.org/abs/2301.12480</link>
      <description>arXiv:2301.12480v5 Announce Type: replace 
Abstract: We address the problem of testing conditional mean and conditional variance for non-stationary data. We build e-values and p-values for four types of non-parametric composite hypotheses with specified mean and variance as well as other conditions on the shape of the data-generating distribution. These shape conditions include symmetry, unimodality, and their combination. Using the obtained e-values and p-values, we construct tests via e-processes, also known as testing by betting, as well as some tests based on combining p-values for comparison. Although we mainly focus on one-sided tests, the two-sided test for the mean is also studied. Simulation and empirical studies are conducted under a few settings, and they illustrate features of the methods based on e-processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.12480v5</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yixuan Fan, Zhanyi Jiao, Ruodu Wang</dc:creator>
    </item>
    <item>
      <title>Covariance Estimation under Missing Observations and $L_4-L_2$ Moment Equivalence</title>
      <link>https://arxiv.org/abs/2305.12981</link>
      <description>arXiv:2305.12981v2 Announce Type: replace 
Abstract: We consider the problem of estimating the covariance matrix of a random vector by observing i.i.d samples and each entry of the sampled vector is missed with probability $p$. Under the standard $L_4-L_2$ moment equivalence assumption, we construct the first estimator that simultaneously achieves optimality with respect to the parameter $p$ and it recovers the optimal convergence rate for the classical covariance estimation problem when $p=1$</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12981v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Pedro Abdalla</dc:creator>
    </item>
    <item>
      <title>No need for an oracle: the nonparametric maximum likelihood decision in the compound decision problem is minimax</title>
      <link>https://arxiv.org/abs/2309.11401</link>
      <description>arXiv:2309.11401v2 Announce Type: replace 
Abstract: We discuss the asymptotics of the nonparametric maximum likelihood estimator (NPMLE) in the normal mixture model. We then prove the convergence rate of the NPMLE decision in the empirical Bayes problem with normal observations. We point to (and heavily use) the connection between the NPMLE decision and Stein unbiased risk estimator (\sure).
  Next, we prove that the same solution is optimal in the compound decision problem where the unobserved parameters are not assumed to be random.
  Similar results are usually claimed using an oracle-based argument. However, we contend that the standard oracle argument is not valid. It was only partially proved that it can be fixed, and the existing proofs of these partial results are tedious. Our approach, on the other hand, is straightforward and short.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.11401v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ya'acov Ritov</dc:creator>
    </item>
    <item>
      <title>On the Efficiency of Finely Stratified Experiments</title>
      <link>https://arxiv.org/abs/2307.15181</link>
      <description>arXiv:2307.15181v3 Announce Type: replace-cross 
Abstract: This paper examines finely stratified designs for the efficient estimation of treatment effect parameters in randomized experiments. In such designs, units are divided into groups of fixed size, with a proportion within each group randomly assigned to a binary treatment. We focus on parameters defined using moment conditions constructed from known functions of the observed data. We establish that the naive method of moments estimator under a finely stratified design achieves the same asymptotic variance as that obtained using ex post covariate adjustment in i.i.d. designs, and further that this variance achieves the efficiency bound in a large class of designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15181v3</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuehao Bai, Jizhou Liu, Azeem M. Shaikh, Max Tabord-Meehan</dc:creator>
    </item>
    <item>
      <title>Metric Entropy-Free Sample Complexity Bounds for Sample Average Approximation in Convex Stochastic Programming</title>
      <link>https://arxiv.org/abs/2401.00664</link>
      <description>arXiv:2401.00664v3 Announce Type: replace-cross 
Abstract: This paper studies sample average approximation (SAA) in solving convex or strongly convex stochastic programming problems. Under some common regularity conditions, we show -- perhaps for the first time -- that SAA's sample complexity can be completely free from any quantification of metric entropy (such as the logarithm of the covering number), leading to a significantly more efficient rate with dimensionality $d$ than most existing results. From the newly established complexity bounds, an important revelation is that SAA and the canonical stochastic mirror descent (SMD) method, two mainstream solution approaches to SP, entail almost identical rates of sample efficiency, rectifying a persistent theoretical discrepancy of SAA from SMD by the order of $O(d)$. Furthermore, this paper explores non-Lipschitzian scenarios where SAA maintains provable efficacy but the corresponding results for SMD remain mostly unexplored, indicating the potential of SAA's better applicability in some irregular settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00664v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongcheng Liu, Jindong Tong</dc:creator>
    </item>
    <item>
      <title>Estimating the linear relation between variables that are never jointly observed</title>
      <link>https://arxiv.org/abs/2403.00140</link>
      <description>arXiv:2403.00140v2 Announce Type: replace-cross 
Abstract: This work is motivated by in vivo experiments in which measurement are destructive so that the variables of interest can never be observed simultaneously when the aim is to estimate the regression coefficients of a linear regression. Assuming that the global experiment can be decomposed into sub experiments (corresponding for example to different doses) with distinct first moments, we propose different estimators of the linear regression which take account of that additional information. We consider estimators based on moments as well as estimators based optimal transport theory. These estimators are proved to be consistent as well as asymptotically Gaussian under weak hypotheses. The asymptotic variance has no explicit expression, except in some particular cases, and specific bootstrap approaches are developed to build confidence intervals for the estimated parameter. A Monte Carlo study is conducted to assess and compare the finite sample performances of the different approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00140v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Polina Arsenteva, Mohamed Amine Benadjaoud, Herv\'e Cardot</dc:creator>
    </item>
  </channel>
</rss>
