<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Mar 2025 04:01:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Short-Term Load Forecasting for AI-Data Center</title>
      <link>https://arxiv.org/abs/2503.07756</link>
      <description>arXiv:2503.07756v1 Announce Type: new 
Abstract: Recent research shows large-scale AI-centric data centers could experience rapid fluctuations in power demand due to varying computation loads, such as sudden spikes from inference or interruption of training large language models (LLMs). As a consequence, such huge and fluctuating power demand pose significant challenges to both data center and power utility operation. Accurate short-term power forecasting allows data centers and utilities to dynamically allocate resources and power large computing clusters as required. However, due to the complex data center power usage patterns and the black-box nature of the underlying AI algorithms running in data centers, explicit modeling of AI-data center is quite challenging. Alternatively, to deal with this emerging load forecasting problem, we propose a data-driven workflow to model and predict the short-term electricity load in an AI-data center, and such workflow is compatible with learning-based algorithms such as LSTM, GRU, 1D-CNN. We validate our framework, which achieves decent accuracy on data center GPU short-term power consumption. This provides opportunity for improved power management and sustainable data center operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07756v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mariam Mughees, Yuzhuo Li, Yize Chen, Yunwei Ryan Li</dc:creator>
    </item>
    <item>
      <title>A Survey of Challenges and Sensing Technologies in Autonomous Retail Systems</title>
      <link>https://arxiv.org/abs/2503.07997</link>
      <description>arXiv:2503.07997v1 Announce Type: new 
Abstract: Autonomous stores leverage advanced sensing technologies to enable cashier-less shopping, real-time inventory tracking, and seamless customer interactions. However, these systems face significant challenges, including occlusion in vision-based tracking, scalability of sensor deployment, theft prevention, and real-time data processing. To address these issues, researchers have explored multi-modal sensing approaches, integrating computer vision, RFID, weight sensing, vibration-based detection, and LiDAR to enhance accuracy and efficiency. This survey provides a comprehensive review of sensing technologies used in autonomous retail environments, highlighting their strengths, limitations, and integration strategies. We categorize existing solutions across inventory tracking, environmental monitoring, people-tracking, and theft detection, discussing key challenges and emerging trends. Finally, we outline future directions for scalable, cost-efficient, and privacy-conscious autonomous store systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07997v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.IV</category>
      <category>eess.SY</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shimmy Rukundo, David Wang, Front Wongnonthawitthaya, Youssouf Sidib\'e, Minsik Kim, Emily Su, Jiale Zhang</dc:creator>
    </item>
    <item>
      <title>How Does CP Length Affect the Sensing Range for OFDM-ISAC?</title>
      <link>https://arxiv.org/abs/2503.08062</link>
      <description>arXiv:2503.08062v1 Announce Type: new 
Abstract: Orthogonal frequency division multiplexing (OFDM), which has been the dominating waveform for contemporary wireless communications, is also regarded as a competitive candidate for future integrated sensing and communication (ISAC) systems. Existing works on OFDM-ISAC usually assume that the maximum sensing range should be limited by the cyclic prefix (CP) length since inter-symbol interference (ISI) and inter-carrier interference (ICI) should be avoided. However, in this paper, we provide rigorous analysis to reveal that the random data embedded in OFDM-ISAC signal can actually act as a free ``mask" for ISI, which makes ISI/ICI random and hence greatly attenuated after radar signal processing. The derived signal-to-interference-plus-noise ratio (SINR) in the range profile demonstrates that the maximum sensing range of OFDM-ISAC can greatly exceed the ISI-free distance that is limited by the CP length, which is validated by simulation results. To further mitigate power degradation for long-range targets, a novel sliding window sensing method is proposed, which iteratively detects and cancels short-range targets before shifting the detection window. The shifted detection window can effectively compensate the power degradation due to insufficient CP length for long-range targets. Such results provide valuable guidance for the CP length design in OFDM-ISAC systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08062v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoli Xu, Zhiwen Zhou, Yong Zeng</dc:creator>
    </item>
    <item>
      <title>Intelligent Joint Security and Delay Determinacy Performance Guarantee Strategy in RIS-Assisted IIoT Communication Systems</title>
      <link>https://arxiv.org/abs/2503.08086</link>
      <description>arXiv:2503.08086v1 Announce Type: new 
Abstract: With the advancement of the Industrial Internet of Things (IIoT), IIoT services now exhibit diverse Quality of Service (QoS) requirements in terms of delay, determinacy, and security, which pose significant challenges for alignment with existing network resources. Reconfigurable Intelligent Surface (RIS), a key enabling technology for IIoT, not only optimizes signal propagation and enhances network performance but also ensures secure communication and deterministic delays to mitigate threats such as data leakage and eavesdropping. In this paper, we conduct a deterministic delay analysis under a specified decoding error rate for RIS-assisted IIoT communication systems using Stochastic Network Calculus (SNC). We propose an on-demand joint strategy to maximize delay determinacy while guaranteeing secure transmission performance. This is achieved by jointly optimizing the transmit power, channel blocklength (CBL) at the user end, and the phase shift matrix at the RIS. Furthermore, we introduce a State Interdependence-Driven Parameterized Deep Q-Network (SID-PDQN) algorithm to intelligently enforce on-demand performance guarantees. Simulation results demonstrate that the proposed SID-PDQN algorithm significantly enhances network performance compared to baseline methods such as DQN, Dueling-DQN, and DDPG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08086v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Meng, Zhuo Meng, Jiaqi Lu, Xiaodong Xu, Jingxuan Zhang, Xiqi Cheng, Chen Dong</dc:creator>
    </item>
    <item>
      <title>Revolution of Wireless Signal Recognition for 6G: Recent Advances, Challenges and Future Directions</title>
      <link>https://arxiv.org/abs/2503.08091</link>
      <description>arXiv:2503.08091v1 Announce Type: new 
Abstract: Wireless signal recognition (WSR) is a crucial technique for intelligent communications and spectrum sharing in the next six-generation (6G) wireless communication networks. It can be utilized to enhance network performance and efficiency, improve quality of service (QoS), and improve network security and reliability. Additionally, WSR can be applied for military applications such as signal interception, signal race, and signal abduction. In the past decades, great efforts have been made for the research of WSR. Earlier works mainly focus on model-based methods, including likelihood-based (LB) and feature-based (FB) methods, which have taken the leading position for many years. With the emergence of artificial intelligence (AI), intelligent methods including machine learning-based (ML-based) and deep learning-based (DL-based) methods have been developed to extract the features of the received signals and perform the classification. In this work, we provide a comprehensive review of WSR from the view of applications, main tasks, recent advances, datasets and evaluation metrics, challenges, and future directions. Specifically, intelligent WSR methods are introduced from the perspective of model, data, learning and implementation. Moreover, we analyze the challenges for WSR from the view of complex, dynamic, and open 6G wireless environments and discuss the future directions for WSR. This survey is expected to provide a comprehensive overview of the state-of-the-art WSR techniques and inspire new research directions for WSR in 6G networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08091v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Zhang, Fuhui Zhou, Hongyang Du, Qihui Wu, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Quantization Design for Deep Learning-Based CSI Feedback</title>
      <link>https://arxiv.org/abs/2503.08125</link>
      <description>arXiv:2503.08125v1 Announce Type: new 
Abstract: Deep learning-based autoencoders have been employed to compress and reconstruct channel state information (CSI) in frequency-division duplex systems. Practical implementations require judicious quantization of encoder outputs for digital transmission. In this paper, we propose a novel quantization module with bit allocation among encoder outputs and develop a method for joint training the module and the autoencoder. To enhance learning performance, we design a loss function that adaptively weights the quantization loss and the logarithm of reconstruction loss. Simulation results show the performance gain of the proposed method over existing baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08125v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manru Yin, Shengqian Han, Chenyang Yang</dc:creator>
    </item>
    <item>
      <title>THz Beam Squint Mitigation via 3D Rotatable Antennas</title>
      <link>https://arxiv.org/abs/2503.08134</link>
      <description>arXiv:2503.08134v1 Announce Type: new 
Abstract: Analog beamforming holds great potential for future terahertz (THz) communications due to its ability to generate high-gain directional beams with low-cost phase shifters.However, conventional analog beamforming may suffer substantial performance degradation in wideband systems due to the beam-squint effects. Instead of relying on high-cost true time delayers, we propose in this paper an efficient three-dimensional (3D) rotatable antenna technology to mitigate the beam-squint effects, motivated by the fact that beam squint disappears along the boresight direction. In particular, we focus on a wideband wide-beam coverage problem in this paper, aiming to maximize the minimum beamforming gain within a given angle and frequency range by jointly optimizing the analog beamforming vector and the 3D rotation angles of the antenna array. However, this problem is non-convex and difficult to be optimally solved due to the coupling of the spatial and frequency domains and that of the antenna weights and rotation. To tackle this issue, we first reformulate the problem into an equivalent form by merging the spatial and frequency domains into a single composite domain. Next, we combine alternating optimization (AO) and successive convex approximation (SCA) algorithms to optimize the analog beamforming and rotation angles within this composite domain. Simulation results demonstrate that the proposed scheme can significantly outperform conventional schemes without antenna rotation, thus offering a cost-effective solution for wideband transmission over THz bands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08134v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yike Xie, Weidong Mei, Dong Wang, Boyu Ning, Zhi Chen, Jun Fang, Wei Guo</dc:creator>
    </item>
    <item>
      <title>Reconfigurable Intelligent Sensing Surface enables Wireless Powered Communication Networks: Interference Suppression and Massive Wireless Energy Transfer</title>
      <link>https://arxiv.org/abs/2503.08198</link>
      <description>arXiv:2503.08198v1 Announce Type: new 
Abstract: Recently, a novel structures of reconfigurable intelligent surface (RIS) integrating both passive and active elements, termed reconfigurable intelligent sensing surface (RISS), efficiently addresses challenges in RIS channel estimation and mitigates issues related to multiplicative path loss by processing the signal at the RISS. In this paper, we propose a sensing-assisted wirelessly powered communication network (WPCN) that utilizes RISS's sensing capabilities to maximize the channel capacity in uplink wireless information transfer (WIT) and assist in massive wireless energy transmission (WET) for downlink. For the WIT in the uplink, the sensing information is utilized to design an interference suppression passive reflection phase shift for the RISS, and take the imperfect sensing results and sharp null into consideration, we also propose a robust scheme. For the WET in the downlink, the massive WET scheme is adopted and benefits from a period of sensing results. The massive WET scheme including beam selection and rotation order optimization to enhance the lower bound of energy harvest for massive users and optimize waiting costs. Numerical results demonstrate the optimal interference suppression threshold for uplink WIT and underscore the achieved fairness in downlink WET. Collectively, by utilizing sensing information, the uplink channel capacity is improved by 20\%, and the worst energy performance and waiting costs for massive WET are effectively optimized, with improvements ranging from 19\% to 59\% and 27\% to 29\%, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08198v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Luo, Jie Hu, Luping Xiang, Kun Yang</dc:creator>
    </item>
    <item>
      <title>Low-Complexity Beamforming Design for Null Space-based Simultaneous Wireless Information and Power Transfer Systems</title>
      <link>https://arxiv.org/abs/2503.08202</link>
      <description>arXiv:2503.08202v1 Announce Type: new 
Abstract: Simultaneous wireless information and power transfer (SWIPT) is a promising technology for the upcoming sixth-generation (6G) communication networks, enabling internet of things (IoT) devices and sensors to extend their operational lifetimes. In this paper, we propose a SWIPT scheme by projecting the interference signals from both intra-wireless information transfer (WIT) and inter-wireless energy transfer (WET) into the null space, simplifying the system into a point-to-point WIT and WET problem. Upon further analysis, we confirm that dedicated energy beamforming is unnecessary. In addition, we develop a low-complexity algorithm to solve the problem efficiently, further reducing computational overhead. Numerical results validate our analysis, showing that the computational complexity is reduced by 97.5\% and 99.96\% for the cases of $K^I = K^E = 2$, $M = 4$ and $K^I = K^E = 16$, $M = 64$, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08202v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Luo, Jie Hu, Luping Xiang, Kun Yang</dc:creator>
    </item>
    <item>
      <title>Bedrock Models in Communication and Sensing: Advancing Generalization, Transferability, and Performance</title>
      <link>https://arxiv.org/abs/2503.08220</link>
      <description>arXiv:2503.08220v1 Announce Type: new 
Abstract: Deep learning (DL) has emerged as a powerful tool for addressing the intricate challenges inherent in communication and sensing systems, significantly enhancing the intelligence of future sixth-generation (6G) networks. A substantial body of research has highlighted the promise of DL-based techniques in these domains. However, in addition to improving accuracy, new challenges must be addressed regarding the generalization and transferability of DL-based systems. To tackle these issues, this paper introduces a series of mathematically grounded and modularized models, referred to as bedrock models, specifically designed for integration into both communication and sensing systems. Due to their modular architecture, these models can be seamlessly incorporated into existing communication and sensing frameworks. For communication systems, the proposed models demonstrate substantial performance improvements while also exhibit strong transferability, enabling direct parameter sharing across different tasks, which greatly facilitates practical deployment. In sensing applications, the integration of the bedrock models into existing systems results in superior performance, reducing delay and Doppler estimation errors by an order of magnitude compared to traditional methods. Additionally, a pre-equalization strategy based on the bedrock models is proposed for the transmitter. By leveraging sensing information, the transmitted communication signal is dynamically adjusted without altering the communication model pre-trained in AWGN channels. This adaptation enables the system to effectively cope with doubly dispersive channels, restoring the received signal to an AWGN-like condition and achieving near-optimal performance. Simulation results substantiate the effectiveness and transferability of the proposed bedrock models, underscoring their potential to advance both communication and sensing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08220v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng Luo, Luping Xiang, Jie Hu, Kun Yang</dc:creator>
    </item>
    <item>
      <title>Reduced-latency DL-based Fractional Channel Estimation in OTFS Receivers</title>
      <link>https://arxiv.org/abs/2503.08234</link>
      <description>arXiv:2503.08234v1 Announce Type: new 
Abstract: In this work, we propose a deep learning (DL)-based approach that integrates a state-of-the-art algorithm with a time-frequency (TF) learning framework to minimize overall latency. Meeting the stringent latency requirements of 6G orthogonal time-frequency space (OTFS) systems necessitates low-latency designs. The performance of the proposed approach is evaluated under challenging conditions: low delay and Doppler resolutions caused by limited time and frequency resources, and significant interpath interference (IPI) due to poor separability of propagation paths in the delay-Doppler (DD) domain. Simulation results demonstrate that the proposed method achieves high estimation accuracy while reducing latency by approximately 55\% during the maximization process. However, a performance trade-off is observed, with a maximum loss of 3 dB at high pilot SNR values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08234v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mauro Marchese, Henk Wymeersch, Paolo Spallaccini, Stefano Chinnici, Pietro Savazzi</dc:creator>
    </item>
    <item>
      <title>MT-NAM: An Efficient and Adaptive Model for Epileptic Seizure Detection</title>
      <link>https://arxiv.org/abs/2503.08251</link>
      <description>arXiv:2503.08251v1 Announce Type: new 
Abstract: Enhancing the accuracy and efficiency of machine learning algorithms employed in neural interface systems is crucial for advancing next-generation intelligent therapeutic devices. However, current systems often utilize basic machine learning models that do not fully exploit the natural structure of brain signals. Additionally, existing learning models used for neural signal processing often demonstrate low speed and efficiency during inference. To address these challenges, this study introduces Micro Tree-based NAM (MT-NAM), a distilled model based on the recently proposed Neural Additive Models (NAM). The MT-NAM achieves a remarkable 100$\times$ improvement in inference speed compared to standard NAM, without compromising accuracy. We evaluate our approach on the CHB-MIT scalp EEG dataset, which includes recordings from 24 patients with varying numbers of sessions and seizures. NAM achieves an 85.3\% window-based sensitivity and 95\% specificity. Interestingly, our proposed MT-NAM shows only a 2\% reduction in sensitivity compared to the original NAM. To regain this sensitivity, we utilize a test-time template adjuster (T3A) as an update mechanism, enabling our model to achieve higher sensitivity during test time by accommodating transient shifts in neural signals. With this online update approach, MT-NAM achieves the same sensitivity as the standard NAM while achieving approximately 50$\times$ acceleration in inference speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08251v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arshia Afzal, Volkan Cevher, Mahsa Shoaran</dc:creator>
    </item>
    <item>
      <title>On Digital Optimization of Analog Self-Interference Cancellation for Full-Duplex Wireless Systems</title>
      <link>https://arxiv.org/abs/2503.08357</link>
      <description>arXiv:2503.08357v1 Announce Type: new 
Abstract: Wireless systems with inband full-duplex transceiver typically require multiple lines of defense against the effect of harsh self-interference, specifically, to avoid saturation of the analog-to-digital converter (ADC) in the receiver. We may unite the typical tandem operation of successive analog and digital self-interference cancellation (SIC) stages by means of digitally-assisted analog SIC. In this case, the ADC in the receive path requires considerable attention due its possibly overloaded operation outside the intended range. Using neural-network-based architectures of the transmitter nonlinearity, we therefore describe and compare four system options for SIC model optimization with different treatment of the receiver ADC in the learning process. We find that omitting the ADC in the backwards path via a so-called straight-through estimation approximation barely impedes model learning, thus providing an efficient alternative to the classical approach of automatic gain control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08357v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Niklas Knaepper, Gerald Enzner, Aleksej Chinaev</dc:creator>
    </item>
    <item>
      <title>Survey on Beyond Diagonal RIS Enabled 6G Wireless Networks: Fundamentals, Recent Advances, and Challenges</title>
      <link>https://arxiv.org/abs/2503.08423</link>
      <description>arXiv:2503.08423v1 Announce Type: new 
Abstract: Beyond Diagonal Reconfigurable Intelligent Surfaces (BD-RIS) represent a groundbreaking innovation in sixth-generation (6G) wireless networks, enabling unprecedented control over wireless propagation environments compared to conventional diagonal RIS (D-RIS). This survey provides a comprehensive analysis of BD-RIS, detailing its architectures, operational principles, and mathematical modeling while highlighting its performance benefits. BD-RIS classifications, including single-connected, fully-connected, and group-connected architectures, and their reflective, transmissive, hybrid, and multi-sector operating modes are examined. Recent advances in BD-RIS-enabled 6G networks are reviewed, focusing on critical areas such as channel estimation, sum-rate and spectral efficiency optimization, energy efficiency enhancement, and security. The survey identifies fundamental challenges in BD-RIS research, including hardware design limitations, adaptive channel estimation, and the impact of non-ideal hardware effects. Future research directions for BD-RIS are proposed, emphasizing the integration of artificial intelligence and machine learning (AI/ML), joint optimization of communication and sensing, and enhanced physical layer security (PLS). This study concludes by underscoring BD-RIS's transformative potential to redefine 6G wireless networks, offering valuable insights and lessons for future research and development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08423v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wali Ullah Khan, Manzoor Ahmed, Chandan Kumar Sheemar, Marco Di Renzo, Eva Lagunas, Asad Mahmood, Syed Tariq Shah, Octavia A. Dobre, Jorge Querol, Symeon Chatzinotas</dc:creator>
    </item>
    <item>
      <title>Additive Frequency Diverse Active Incoherent Millimeter-Wave Imaging</title>
      <link>https://arxiv.org/abs/2503.08556</link>
      <description>arXiv:2503.08556v1 Announce Type: new 
Abstract: We present an approach for improving spatial frequency sampling in active incoherent millimeter-wave (AIM) imaging systems using frequency diversity. AIM imaging relies on active transmission of spatio-temporally incoherent signals to illuminate a scene, from which interferometric Fourier-domain imaging can be implemented using a sparse receiving antenna array. One of the benefits of Fourier domain imaging is the sparsity of the receiving array, which can form images with equivalent resolution to traditional filled beamsteering arrays, but with a small fraction of the elements. The hardware reduction afforded by the sparse array often leads to an undersampled Fourier space, where even though image formation is possible, the image reconstruction may be degraded when viewing complex objects. To address this challenge without requiring additional receiver channels, we explore the use of frequency diversity in the illuminating and receiving systems. Fourier domain spatial frequency samples are determined by the electrical spacing and rotation of the receiving elements, thus by changing the frequency the sampled spatial frequencies also change. We implement an additive technique where the spatial frequency samples are summed prior to Fourier transform image formation. Importantly, because the system is active, a consistent signal-to-noise ratio is maintained across all frequencies, which may not be possible in traditional passive Fourier-domain imagers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08556v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jorge R. Colon-Berrios, Jeffrey A. Nanzer</dc:creator>
    </item>
    <item>
      <title>Integrated Sensing, Communication, and Powering (ISCAP) for IoT: A Joint Beamforming Design</title>
      <link>https://arxiv.org/abs/2503.08557</link>
      <description>arXiv:2503.08557v1 Announce Type: new 
Abstract: This paper studies Integrated Sensing, Communication, and Powering (ISCAP) as a novel framework designed to enhance Internet of Things (IoT) applications within sixth-generation wireless networks. In these applications, in addition to IoT devices requiring an energy supply and receiving information or control data to perform their tasks, the base station serving them must sense the devices and their environment to localize them, thereby improving data transmission and enabling simultaneous power delivery. In our multi-node ISCAP IoT system, we optimize base station beamforming alongside the receiver's power-splitting factor to maximize energy harvesting while adhering to strict communication and sensing constraints. To effectively tackle this non-convex optimization problem, we decompose it into three manageable subproblems and employ several techniques such as semidefinite relaxation and Rayleigh quotient methods to find an efficient solution. Simulation results demonstrate the effectiveness of the proposed design, highlighting performance trade-offs among sensing accuracy, communication reliability, and power transfer efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08557v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maryam Asadi Ahmadabadi, S. Mohammad Razavizadeh, Vahid Jamali</dc:creator>
    </item>
    <item>
      <title>Weakly Supervised Convolutional Dictionary Learning with Shared and Discriminative Components for Classification</title>
      <link>https://arxiv.org/abs/2503.08573</link>
      <description>arXiv:2503.08573v1 Announce Type: new 
Abstract: In today's data-driven landscape spanning finance, government, and healthcare sectors, the exponential growth of information necessitates robust solutions for secure storage, efficient dissemination, and fine-grained access control. Convolutional dictionary learning emerges as a powerful approach for extracting meaningful representations from complex data. This paper presents a novel weakly supervised convolutional dictionary learning framework that incorporates both shared and discriminative components for classification tasks. Our approach leverages limited label information to learn dictionaries that capture common patterns across classes while simultaneously highlighting class-specific features. By decomposing the learned representations into shared and discriminative parts, we enhance both feature interpretability and classification performance. Extensive experiments across multiple datasets demonstrate that our method outperforms state-of-the-art approaches, particularly in scenarios with limited labeled data. The proposed framework offers a promising solution for applications requiring both effective feature extraction and accurate classification in weakly supervised settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08573v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hao Chen, Yusen Wu, Dayuan Tan</dc:creator>
    </item>
    <item>
      <title>Data Foundations for Large Scale Multimodal Clinical Foundation Models</title>
      <link>https://arxiv.org/abs/2503.07667</link>
      <description>arXiv:2503.07667v1 Announce Type: cross 
Abstract: Recent advances in clinical AI have enabled remarkable progress across many clinical domains. However, existing benchmarks and models are primarily limited to a small set of modalities and tasks, which hinders the development of large-scale multimodal methods that can make holistic assessments of patient health and well-being. To bridge this gap, we introduce Clinical Large-Scale Integrative Multimodal Benchmark (CLIMB), a comprehensive clinical benchmark unifying diverse clinical data across imaging, language, temporal, and graph modalities. CLIMB comprises 4.51 million patient samples totaling 19.01 terabytes distributed across 2D imaging, 3D video, time series, graphs, and multimodal data. Through extensive empirical evaluation, we demonstrate that multitask pretraining significantly improves performance on understudied domains, achieving up to 29% improvement in ultrasound and 23% in ECG analysis over single-task learning. Pretraining on CLIMB also effectively improves models' generalization capability to new tasks, and strong unimodal encoder performance translates well to multimodal performance when paired with task-appropriate fusion strategies. Our findings provide a foundation for new architecture designs and pretraining strategies to advance clinical AI research. Code is released at https://github.com/DDVD233/climb.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07667v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Wei Dai, Peilin Chen, Malinda Lu, Daniel Li, Haowen Wei, Hejie Cui, Paul Pu Liang</dc:creator>
    </item>
    <item>
      <title>Theoretical Analysis of Multi-coding with Non-orthogonal Signaling</title>
      <link>https://arxiv.org/abs/2503.07765</link>
      <description>arXiv:2503.07765v1 Announce Type: cross 
Abstract: Even though orthogonal multi-code signaling and its derivative, simplex signaling, are well known and widely used in different communication systems, certain applications may choose to adopt non-orthogonal signaling to benefit from other advantages that such signaling methods can offer. Motivated by a class of multi-carrier spread spectrum systems, this paper presents a thorough symbol error rate analysis of the broad class of multi-code signaling methods when they make use of codes which are not necessarily orthogonal. Our analysis is also extended to the case where the code set includes the negative of each code vector, i.e., an extension to biorthogonal signaling. Moreover, it is shown that the symbol error rate results derived in this paper reduce to those available in the literature when the multi-codes are orthogonal or satisfy the correlation property of simplex multi-codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07765v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brian Nelson, Behrouz Farhang-Boroujeny</dc:creator>
    </item>
    <item>
      <title>GPT-PPG: A GPT-based Foundation Model for Photoplethysmography Signals</title>
      <link>https://arxiv.org/abs/2503.08015</link>
      <description>arXiv:2503.08015v1 Announce Type: cross 
Abstract: This study introduces a novel application of a Generative Pre-trained Transformer (GPT) model tailored for photoplethysmography (PPG) signals, serving as a foundation model for various downstream tasks. Adapting the standard GPT architecture to suit the continuous characteristics of PPG signals, our approach demonstrates promising results. Our models are pre-trained on our extensive dataset that contains more than 200 million 30s PPG samples. We explored different supervised fine-tuning techniques to adapt our model to downstream tasks, resulting in performance comparable to or surpassing current state-of-the-art (SOTA) methods in tasks like atrial fibrillation detection. A standout feature of our GPT model is its inherent capability to perform generative tasks such as signal denoising effectively, without the need for further fine-tuning. This success is attributed to the generative nature of the GPT framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08015v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoliang Chen, Cheng Ding, Saurabh Kataria, Runze Yan, Minxiao Wang, Randall Lee, Xiao Hu</dc:creator>
    </item>
    <item>
      <title>Online Conformal Compression for Zero-Delay Communication with Distortion Guarantees</title>
      <link>https://arxiv.org/abs/2503.08340</link>
      <description>arXiv:2503.08340v1 Announce Type: cross 
Abstract: We investigate a lossy source compression problem in which both the encoder and decoder are equipped with a pre-trained sequence predictor. We propose an online lossy compression scheme that, under a 0-1 loss distortion function, ensures a deterministic, per-sequence upper bound on the distortion (outage) level for any time instant. The outage guarantees apply irrespective of any assumption on the distribution of the sequences to be encoded or on the quality of the predictor at the encoder and decoder. The proposed method, referred to as online conformal compression (OCC), is built upon online conformal prediction--a novel method for constructing confidence intervals for arbitrary predictors. Numerical results show that OCC achieves a compression rate comparable to that of an idealized scheme in which the encoder, with hindsight, selects the optimal subset of symbols to describe to the decoder, while satisfying the overall outage constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08340v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Unnikrishnan Kunnath Ganesan, Giuseppe Durisi, Matteo Zecchin, Petar Popovski, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Efficient Resource Allocation in 5G Massive MIMO-NOMA Networks: Comparative Analysis of SINR-Aware Power Allocation and Spatial Correlation-Based Clustering</title>
      <link>https://arxiv.org/abs/2503.08466</link>
      <description>arXiv:2503.08466v1 Announce Type: cross 
Abstract: With the evolution of 5G networks, optimizing resource allocation has become crucial to meeting the increasing demand for massive connectivity and high throughput. Combining Non-Orthogonal Multiple Access (NOMA) and massive Multi-Input Multi-Output (MIMO) enhances spectral efficiency, power efficiency, and device connectivity. However, deploying MIMO-NOMA in dense networks poses challenges in managing interference and optimizing power allocation while ensuring that the Signal-to-Interference-plus-Noise Ratio (SINR) meets required thresholds. Unlike previous studies that analyze user clustering and power allocation techniques under simplified assumptions, this work provides a comparative evaluation of multiple clustering and allocation strategies under identical spatially correlated network conditions. We focus on maximizing the number of served users under a given Quality of Service (QoS) constraint rather than the conventional sum-rate maximization approach. Additionally, we consider spatial correlation in user grouping, a factor often overlooked despite its importance in mitigating intra-cluster interference. We evaluate clustering algorithms, including user pairing, random clustering, Correlation Iterative Clustering Algorithm (CIA), K-means++-based User Clustering (KUC), and Grey Wolf Optimizer-based clustering (GWO), in a downlink spatially correlated MIMO-NOMA environment. Numerical results demonstrate that the GWO-based clustering algorithm achieves superior energy efficiency while maintaining scalability, whereas CIA effectively maximizes the number of served users. These findings provide valuable insights for designing MIMO-NOMA systems that optimize resource allocation in next-generation wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08466v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samar Chebbi, Oussama Habachi, Jean-Pierre Cances, Vahid Meghdadi Essaid Sabir</dc:creator>
    </item>
    <item>
      <title>Transformers are Provably Optimal In-context Estimators for Wireless Communications</title>
      <link>https://arxiv.org/abs/2311.00226</link>
      <description>arXiv:2311.00226v4 Announce Type: replace 
Abstract: Pre-trained transformers exhibit the capability of adapting to new tasks through in-context learning (ICL), where they efficiently utilize a limited set of prompts without explicit model optimization. The canonical communication problem of estimating transmitted symbols from received observations can be modeled as an in-context learning problem: received observations are a noisy function of transmitted symbols, and this function can be represented by an unknown parameter whose statistics depend on an unknown latent context. This problem, which we term in-context estimation (ICE), has significantly greater complexity than the extensively studied linear regression problem. The optimal solution to the ICE problem is a non-linear function of the underlying context. In this paper, we prove that, for a subclass of such problems, a single-layer softmax attention transformer (SAT) computes the optimal solution of the above estimation problem in the limit of large prompt length. We also prove that the optimal configuration of such a transformer is indeed the minimizer of the corresponding training loss. Further, we empirically demonstrate the proficiency of multi-layer transformers in efficiently solving broader in-context estimation problems. Through extensive simulations, we show that solving ICE problems using transformers significantly outperforms standard approaches. Moreover, just with a few context examples, it achieves the same performance as an estimator with perfect knowledge of the latent context. The code is available \href{https://github.com/vishnutez/in-context-estimation}{here}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00226v4</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vishnu Teja Kunde, Vicram Rajagopalan, Chandra Shekhara Kaushik Valmeekam, Krishna Narayanan, Srinivas Shakkottai, Dileep Kalathil, Jean-Francois Chamberland</dc:creator>
    </item>
    <item>
      <title>Advancing Ubiquitous Wireless Connectivity through Channel Twinning</title>
      <link>https://arxiv.org/abs/2406.12268</link>
      <description>arXiv:2406.12268v2 Announce Type: replace 
Abstract: As an emerging trend in channel acquisition (CA), the concept of channel twinning (CT) has been proposed as a powerful enabler of ubiquitous connectivity in next-generation (xG) wireless systems. By fusing multimodal sensor data, CT advocates a high-fidelity and low-overhead CA paradigm, which is promising to provide accurate channel prediction in cross-domain and high-mobility scenarios of ubiquitous xG networks. However, existing literature lacks a universal CT architecture to address the challenges of heterogeneous scenarios, data, and resources in xG networks, which hinders the widespread deployment and applications of CT. This article discusses a new modularized CT architecture to bridge scene recognition, cooperative sensing, and decentralized training, comprising versatile model configuration, multimodal cooperative sensing, and lightweight twin modeling modules. Additionally, this article presents a detailed concept, technical features, and case studies of CT, outlines mainstream trends of realization methods, followed by potential applications of CT-empowered ubiquitous connectivity, and issues requiring future investigations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12268v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/MCOM.001.2400476</arxiv:DOI>
      <dc:creator>Yashuai Cao, Linglong Dai, Jingbo Tan, Jintao Wang, Tianyue Zheng, Wei Ni, Ekram Hossain, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>Dequantization of a signal from two parallel quantized observations</title>
      <link>https://arxiv.org/abs/2409.08071</link>
      <description>arXiv:2409.08071v2 Announce Type: replace 
Abstract: We propose a technique of signal acquisition using a combination of two devices with different sampling rates and quantization accuracies. Subsequent processing involving sparsity regularization enables us to reconstruct the signal at such a sampling frequency and with such a bit depth that was not possible using the two devices independently. Objective and subjective tests show the superiority of the proposed method in comparison with alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08071v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Vojt\v{e}ch Kovanda, Pavel Rajmic</dc:creator>
    </item>
    <item>
      <title>Integrating Semantic Communication and Human Decision-Making into an End-to-End Sensing-Decision Framework</title>
      <link>https://arxiv.org/abs/2412.05103</link>
      <description>arXiv:2412.05103v2 Announce Type: replace 
Abstract: As early as 1949, Weaver defined communication in a very broad sense to include all procedures by which one mind or technical system can influence another, thus establishing the idea of semantic communication. With the recent success of machine learning in expert assistance systems where sensed information is wirelessly provided to a human to assist task execution, the need to design effective and efficient communications has become increasingly apparent. In particular, semantic communication aims to convey the meaning behind the sensed information relevant for Human Decision-Making (HDM). Regarding the interplay between semantic communication and HDM, many questions remain, such as how to model the entire end-to-end sensing-decision-making process, how to design semantic communication for the HDM and which information should be provided to the HDM. To address these questions, we propose to integrate semantic communication and HDM into one probabilistic end-to-end sensing-decision framework that bridges communications and psychology. In our interdisciplinary framework, we model the human through a HDM process, allowing us to explore how feature extraction from semantic communication can best support HDM both in theory and in simulations. In this sense, our study reveals the fundamental design trade-off between maximizing the relevant semantic information and matching the cognitive capabilities of the HDM model. Our initial analysis shows how semantic communication can balance the level of detail with human cognitive capabilities while demanding less bandwidth, power, and latency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05103v2</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edgar Beck, Hsuan-Yu Lin, Patrick R\"uckert, Yongping Bao, Bettina von Helversen, Sebastian Fehrler, Kirsten Tracht, Armin Dekorsy</dc:creator>
    </item>
    <item>
      <title>Transfer Learning Assisted Fast Design Migration Over Technology Nodes: A Study on Transformer Matching Network</title>
      <link>https://arxiv.org/abs/2502.18636</link>
      <description>arXiv:2502.18636v2 Announce Type: replace 
Abstract: In this study, we introduce an innovative methodology for the design of mm-Wave passive networks that leverages knowledge transfer from a pre-trained synthesis neural network (NN) model in one technology node and achieves swift and reliable design adaptation across different integrated circuit (IC) technologies, operating frequencies, and metal options. We prove this concept through simulation-based demonstrations focusing on the training and comparison of the coefficient of determination (R2) of synthesis NNs for 1:1 on-chip transformers in GlobalFoundries(GF) 22nm FDX+ (target domain), with and without transfer learning from a model trained in GF 45nm SOI (source domain). In the experiments, we explore varying target data densities of 0.5%, 1%, 5%, and 100% with a complete dataset of 0.33 million in GF 22FDX+, and for comparative analysis, apply source data densities of 25%, 50%, 75%, and 100% with a complete dataset of 2.5 million in GF 45SOI. With the source data only at 30GHz, the experiments span target data from two metal options in GF 22FDX+ at frequencies of 30 and 39 GHz. The results prove that the transfer learning with the source domain knowledge (GF 45SOI) can both accelerate the training process in the target domain (GF 22FDX+) and improve the R2 values compared to models without knowledge transfer. Furthermore, it is observed that a model trained with just 5% of target data and augmented by transfer learning achieves R2 values superior to a model trained with 20% of the data without transfer, validating the advantage seen from 1% to 5% data density. This demonstrates a notable reduction of 4X in the necessary dataset size highlighting the efficacy of utilizing transfer learning to mm-Wave passive network design. The PyTorch learning and testing code is publicly available at https://github.com/ChenhaoChu/RFIC-TL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18636v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/IMS40175.2024.10600344</arxiv:DOI>
      <dc:creator>Chenhao Chu, Yuhao Mao, Hua Wang</dc:creator>
    </item>
    <item>
      <title>Physics-Informed Generative Approaches for Wireless Channel Modeling</title>
      <link>https://arxiv.org/abs/2503.05988</link>
      <description>arXiv:2503.05988v2 Announce Type: replace 
Abstract: In recent years, machine learning (ML) methods have become increasingly popular in wireless communication systems for several applications. A critical bottleneck for designing ML systems for wireless communications is the availability of realistic wireless channel datasets, which are extremely resource intensive to produce. To this end, the generation of realistic wireless channels plays a key role in the subsequent design of effective ML algorithms for wireless communication systems. Generative models have been proposed to synthesize channel matrices, but outputs produced by such methods may not correspond to geometrically viable channels and do not provide any insight into the scenario of interest. In this work, we aim to address both these issues by integrating a parametric, physics-based geometric channel (PBGC) modeling framework with generative methods. To address limitations with gradient flow through the PBGC model, a linearized reformulation is presented, which ensures smooth gradient flow during generative model training, while also capturing insights about the underlying physical environment. We evaluate our model against prior baselines by comparing the generated samples in terms of the 2-Wasserstein distance and through the utility of generated data when used for downstream compression tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05988v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Satyavrat Wagle, Akshay Malhotra, Shahab Hamidi-Rad, Aditya Sant, David J. Love, Christopher G. Brinton</dc:creator>
    </item>
    <item>
      <title>Learning Hypergraphs From Signals With Dual Smoothness Prior</title>
      <link>https://arxiv.org/abs/2211.01717</link>
      <description>arXiv:2211.01717v4 Announce Type: replace-cross 
Abstract: Hypergraph structure learning, which aims to learn the hypergraph structures from the observed signals to capture the intrinsic high-order relationships among the entities, becomes crucial when a hypergraph topology is not readily available in the datasets. There are two challenges that lie at the heart of this problem: 1) how to handle the huge search space of potential hyperedges, and 2) how to define meaningful criteria to measure the relationship between the signals observed on nodes and the hypergraph structure. In this paper, for the first challenge, we adopt the assumption that the ideal hypergraph structure can be derived from a learnable graph structure that captures the pairwise relations within signals. Further, we propose a hypergraph structure learning framework HGSL with a novel dual smoothness prior that reveals a mapping between the observed node signals and the hypergraph structure, whereby each hyperedge corresponds to a subgraph with both node signal smoothness and edge signal smoothness in the learnable graph structure. Finally, we conduct extensive experiments to evaluate HGSL on both synthetic and real world datasets. Experiments show that HGSL can efficiently infer meaningful hypergraph topologies from observed signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.01717v4</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bohan Tang, Siheng Chen, Xiaowen Dong</dc:creator>
    </item>
    <item>
      <title>Hypergraph Structure Inference From Data Under Smoothness Prior</title>
      <link>https://arxiv.org/abs/2308.14172</link>
      <description>arXiv:2308.14172v3 Announce Type: replace-cross 
Abstract: Hypergraphs are important for processing data with higher-order relationships involving more than two entities. In scenarios where explicit hypergraphs are not readily available, it is desirable to infer a meaningful hypergraph structure from the node features to capture the intrinsic relations within the data. However, existing methods either adopt simple pre-defined rules that fail to precisely capture the distribution of the potential hypergraph structure, or learn a mapping between hypergraph structures and node features but require a large amount of labelled data, i.e., pre-existing hypergraph structures, for training. Both restrict their applications in practical scenarios. To fill this gap, we propose a novel smoothness prior that enables us to design a method to infer the probability for each potential hyperedge without labelled data as supervision. The proposed prior indicates features of nodes in a hyperedge are highly correlated by the features of the hyperedge containing them. We use this prior to derive the relation between the hypergraph structure and the node features via probabilistic modelling. This allows us to develop an unsupervised inference method to estimate the probability for each potential hyperedge via solving an optimisation problem that has an analytical solution. Experiments on both synthetic and real-world data demonstrate that our method can learn meaningful hypergraph structures from data more efficiently than existing hypergraph structure inference methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.14172v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bohan Tang, Siheng Chen, Xiaowen Dong</dc:creator>
    </item>
    <item>
      <title>Hypergraph-MLP: Learning on Hypergraphs without Message Passing</title>
      <link>https://arxiv.org/abs/2312.09778</link>
      <description>arXiv:2312.09778v4 Announce Type: replace-cross 
Abstract: Hypergraphs are vital in modelling data with higher-order relations containing more than two entities, gaining prominence in machine learning and signal processing. Many hypergraph neural networks leverage message passing over hypergraph structures to enhance node representation learning, yielding impressive performances in tasks like hypergraph node classification. However, these message-passing-based models face several challenges, including oversmoothing as well as high latency and sensitivity to structural perturbations at inference time. To tackle those challenges, we propose an alternative approach where we integrate the information about hypergraph structures into training supervision without explicit message passing, thus also removing the reliance on it at inference. Specifically, we introduce Hypergraph-MLP, a novel learning framework for hypergraph-structured data, where the learning model is a straightforward multilayer perceptron (MLP) supervised by a loss function based on a notion of signal smoothness on hypergraphs. Experiments on hypergraph node classification tasks demonstrate that Hypergraph-MLP achieves competitive performance compared to existing baselines, and is considerably faster and more robust against structural perturbations at inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09778v4</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bohan Tang, Siheng Chen, Xiaowen Dong</dc:creator>
    </item>
    <item>
      <title>Intra-day Solar and Power Forecast for Optimization of Intraday Market Participation</title>
      <link>https://arxiv.org/abs/2501.09551</link>
      <description>arXiv:2501.09551v3 Announce Type: replace-cross 
Abstract: The prediction of solar irradiance enhances reliability in photovoltaic (PV) solar plant generation and grid integration. In Colombia, PV plants face penalties if energy production deviates beyond governmental thresholds from intraday market offers. This research employs Long Short-Term Memory (LSTM) and Bidirectional-LSTM (Bi-LSTM) models, utilizing meteorological data from a PV plant in El Paso, Cesar, Colombia, to predict solar irradiance with a 6-hour horizon and 10-minute resolution. While Bi-LSTM showed superior performance, the LSTM model achieved comparable results with significantly reduced training time (6 hours versus 18 hours), making it computationally advantageous. The LSTM predictions were averaged to create an hourly resolution model, evaluated using Mean Absolute Error, Root-Mean-Square Error, Normalized Root-Mean-Square Error, and Mean Absolute Percentage Error metrics. Comparison with the Global Forecast System (GFS) revealed similar performance, with both models effectively capturing daily solar irradiance patterns. The forecast model integrates with an Object-Oriented power production model, enabling accurate energy offers in the intraday market while minimizing penalty costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09551v3</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nelson Salazar-Pena, Adolfo Palma-Vergara, Mateo Montes-Vera, Maria Alejandra Vargas-Torres, Rodrigo Hernandez-Vanegas, Maria Amador, Boris Rojas, Adriana Salinas, Andres Velasco, Alejandra Tabares, Andres Gonzalez-Mancera</dc:creator>
    </item>
    <item>
      <title>Flexible Intelligent Metasurfaces for Enhancing MIMO Communications</title>
      <link>https://arxiv.org/abs/2502.16478</link>
      <description>arXiv:2502.16478v2 Announce Type: replace-cross 
Abstract: Flexible intelligent metasurfaces (FIMs) show great potential for improving the wireless network capacity in an energy-efficient manner. An FIM is a soft array consisting of several low-cost radiating elements. Each element can independently emit electromagnetic signals, while flexibly adjusting its position even perpendicularly to the overall surface to `morph' its 3D shape. More explicitly, compared to a conventional rigid antenna array, an FIM is capable of finding an optimal 3D surface shape that provides improved signal quality. In this paper, we study point-to-point multiple-input multiple-output (MIMO) communications between a pair of FIMs. In order to characterize the capacity limits of FIM-aided MIMO transmissions over frequency-flat fading channels, we formulate a transmit optimization problem for maximizing the MIMO channel capacity by jointly optimizing the 3D surface shapes of the transmitting and receiving FIMs as well as the MIMO transmit covariance matrix, subject to the total transmit power constraint and to the maximum perpendicular morphing range of the FIM. To solve this problem, we develop an efficient block coordinate descent (BCD) algorithm. The BCD algorithm iteratively updates the 3D surface shapes of the FIMs and the transmit covariance matrix, while keeping the other fixed, to find a locally optimal solution. Numerical results verify that FIMs can achieve higher MIMO capacity than that of the conventional rigid arrays. In particular, the MIMO channel capacity can be doubled by the proposed BCD algorithm under some setups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16478v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiancheng An, Zhu Han, Dusit Niyato, M\'erouane Debbah, Chau Yuen, Lajos Hanzo</dc:creator>
    </item>
  </channel>
</rss>
