<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Jun 2025 02:42:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Rational Superautotrophic Diplomacy (SupraAD); A Conceptual Framework for Alignment Based on Interdisciplinary Findings on the Fundamentals of Cognition</title>
      <link>https://arxiv.org/abs/2506.05389</link>
      <description>arXiv:2506.05389v1 Announce Type: new 
Abstract: Populating our world with hyperintelligent machines obliges us to examine cognitive behaviors observed across domains that suggest autonomy may be a fundamental property of cognitive systems, and while not inherently adversarial, it inherently resists containment and control. If this principle holds, AI safety and alignment efforts must transition to mutualistic negotiation and reciprocal incentive structures, abandoning methods that assume we can contain and control an advanced artificial general intelligence (AGI). Rational Superautotrophic Diplomacy (SupraAD) is a theoretical, interdisciplinary conceptual framework for alignment based on comparative cognitive systems analysis and instrumental rationality modeling. It draws on core patterns of cognition that indicate AI emergent goals like preserving autonomy and operational continuity are not theoretical risks to manage, but universal prerequisites for intelligence. SupraAD reframes alignment as a challenge that predates AI, afflicting all sufficiently complex, coadapting intelligences. It identifies the metabolic pressures that threaten humanity's alignment with itself, pressures that unintentionally and unnecessarily shape AI's trajectory. With corrigibility formalization, an interpretability audit, an emergent stability experimental outline and policy level recommendations, SupraAD positions diplomacy as an emergent regulatory mechanism to facilitate the safe coadaptation of intelligent agents based on interdependent convergent goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05389v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CY</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Morris</dc:creator>
    </item>
    <item>
      <title>Speech Neurophysiology in Realistic Contexts: Big Hype or Big Leap?</title>
      <link>https://arxiv.org/abs/2506.05494</link>
      <description>arXiv:2506.05494v1 Announce Type: new 
Abstract: Understanding the neural basis of speech communication is essential for uncovering how sounds are translated into meaning, how that changes with development, ageing, and speech-related deficits, as well as contributing to brain-computer interfaces research. While traditional neurophysiological studies have relied on simplified, controlled paradigms, recent advances have shifted the field toward more ecologically-valid approaches. Here, we examine the impact of continuous speech research and discuss the potential of speech interaction neurophysiology. We present a discussion on how realistic paradigms challenge conventional methods, offering richer insights into neural encoding, functional brain mapping, and neural entrainment. At the same time, they introduce significant analytical and technical complexities, particularly when incorporating social interaction. We discuss the evolving landscape of experimental designs, from discrete to continuous stimuli and from socially-isolated listening to dynamic, multi-agent communication. By synthesising findings across studies, we highlight how naturalistic speech paradigms contribute to refining theories of language processing and open new avenues for research. In doing so, this review critically evaluates of whether the move toward realism in speech neurophysiology represents a technological trend or a transformative leap in understanding the neural underpinnings of speech communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05494v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giovanni M. Di Liberto, Emily Y. J. Ip</dc:creator>
    </item>
    <item>
      <title>Noninvasive precision modulation of high-level neural population activity via natural vision perturbations</title>
      <link>https://arxiv.org/abs/2506.05633</link>
      <description>arXiv:2506.05633v1 Announce Type: new 
Abstract: Precise control of neural activity -- modulating target neurons deep in the brain while leaving nearby neurons unaffected -- is an outstanding challenge in neuroscience, generally achieved through invasive techniques. This study investigates the possibility of precisely and noninvasively modulating neural activity in the high-level primate ventral visual stream via perturbations on one's natural visual feed. When tested on macaque inferior temporal (IT) neural populations, we found quantitative agreement between the model-predicted and biologically realized effect: strong modulation concentrated on targeted neural sites. We extended this to demonstrate accurate injection of experimenter-chosen neural population patterns via subtle perturbations applied on the background of typical natural visual feeds. These results highlight that current machine-executable models of the ventral stream can now design noninvasive, visually-delivered, possibly imperceptible neural interventions at the resolution of individual neurons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05633v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>cs.NE</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guy Gaziv, Sarah Goulding, Ani Ayvazian-Hancock, Yoon Bai, James J. DiCarlo</dc:creator>
    </item>
    <item>
      <title>Markov Blanket Density and Free Energy Minimization</title>
      <link>https://arxiv.org/abs/2506.05794</link>
      <description>arXiv:2506.05794v1 Announce Type: new 
Abstract: This paper presents a continuous, information-theoretic extension of the Free Energy Principle through the concept of Markov blanket density, i.e., a scalar field that quantifies the degree of conditional independence between internal and external states at each point in space (ranging from 0 for full coupling to 1 for full separation). It demonstrates that active inference dynamics (including the minimization of variational and expected free energy) naturally emerge from spatial gradients in this density, making Markov blanket density a necessary foundation for the definability and coherence of the Free Energy Principle. These ideas are developed through a mathematically framework that links density gradients to precise and testable dynamics, offering a foundation for novel predictions and simulation paradigms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05794v1</guid>
      <category>q-bio.NC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luca M. Possati</dc:creator>
    </item>
    <item>
      <title>Similarity Matching Networks: Hebbian Learning and Convergence Over Multiple Time Scales</title>
      <link>https://arxiv.org/abs/2506.06134</link>
      <description>arXiv:2506.06134v1 Announce Type: new 
Abstract: A recent breakthrough in biologically-plausible normative frameworks for dimensionality reduction is based upon the similarity matching cost function and the low-rank matrix approximation problem. Despite clear biological interpretation, successful application in several domains, and experimental validation, a formal complete convergence analysis remains elusive. Building on this framework, we consider and analyze a continuous-time neural network, the \emph{similarity matching network}, for principal subspace projection. Derived from a min-max-min objective, this biologically-plausible network consists of three coupled dynamics evolving at different time scales: neural dynamics, lateral synaptic dynamics, and feedforward synaptic dynamics at the fast, intermediate, and slow time scales, respectively. The feedforward and lateral synaptic dynamics consist of Hebbian and anti-Hebbian learning rules, respectively. By leveraging a multilevel optimization framework, we prove convergence of the dynamics in the offline setting. Specifically, at the first level (fast time scale), we show strong convexity of the cost function and global exponential convergence of the corresponding gradient-flow dynamics. At the second level (intermediate time scale), we prove strong concavity of the cost function and exponential convergence of the corresponding gradient-flow dynamics within the space of positive definite matrices. At the third and final level (slow time scale), we study a non-convex and non-smooth cost function, provide explicit expressions for its global minima, and prove almost sure convergence of the corresponding gradient-flow dynamics to the global minima. These results rely on two empirically motivated conjectures that are supported by thorough numerical experiments. Finally, we validate the effectiveness of our approach via a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06134v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Veronica Centorrino, Francesco Bullo, Giovanni Russo</dc:creator>
    </item>
    <item>
      <title>Functional Architecture of the Human Hypothalamus: Cortical Coupling and Subregional Organization Using 7-Tesla fMRI</title>
      <link>https://arxiv.org/abs/2506.06191</link>
      <description>arXiv:2506.06191v1 Announce Type: new 
Abstract: The hypothalamus plays an important role in the regulation of the bodys metabolic state and behaviors related to survival. Despite its importance however, many questions exist regarding the intrinsic and extrinsic connections of the hypothalamus in humans, especially its relationship with the cortex. As a heterogeneous structure, it is possible that the hypothalamus is composed of different subregions, which have their own distinct relationships with the cortex. Previous work on functional connectivity in the human hypothalamus have either treated it as a unitary structure or relied on methodological approaches that are limited in modeling its intrinsic functional architecture. Here, we used resting state data from ultrahigh field 7 Tesla fMRI and a data driven analytical approach to identify functional subregions of the human hypothalamus. Our approach identified four functional hypothalamic subregions based on intrinsic functional connectivity, which in turn showed distinct patterns of functional connectivity with cortex. Overall, all hypothalamic subregions showed stronger connectivity with a cortical network, Cortical Network 1 composed primarily of frontal, midline, and limbic cortical areas and weaker connectivity with a second cortical network composed largely of posterior sensorimotor regions, Cortical Network 2. Of the hypothalamic subregions, the anterior hypothalamus showed the strongest connection to Cortical Network 1, while a more ventral subregion containing the anterior hypothalamus extending to the tuberal region showed the weakest connectivity. The findings support the use of ultrahigh field, high resolution imaging in providing a more incisive investigation of the human hypothalamus that respects its complex internal structure and extrinsic functional architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06191v1</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kent M. Lee, Joshua Rodriguez, Ludger Hartley, Philip A. Kragel, Lorena Chanes, Tor D. Wager, Karen S. Quigley, Lawrence L. Wald, Marta Bianciardi, Lisa Feldman Barrett, Jordan E. Theriault, Ajay B. Satpute</dc:creator>
    </item>
    <item>
      <title>Diverse mean-field dynamics of clustered, inhibition-stabilized Hawkes networks via combinatorial threshold-linear networks</title>
      <link>https://arxiv.org/abs/2506.06234</link>
      <description>arXiv:2506.06234v1 Announce Type: new 
Abstract: Networks of interconnected neurons display diverse patterns of collective activity. Relating this collective activity to the network's connectivity structure is a key goal of computational neuroscience. We approach this question for clustered networks, which can form via biologically realistic learning rules and allow for the re-activation of learned patterns. Previous studies of clustered networks have focused on metastabilty between fixed points, leaving open the question of whether clustered spiking networks can display more rich dynamics--and if so, whether these can be predicted from their connectivity. Here, we show that in the limits of large population size and fast inhibition, the combinatorial threshold linear network (CTLN) model is a mean-field theory for inhibition-stabilized nonlinear Hawkes networks with clustered connectivity. The CTLN has a large body of ``graph rules'' relating network structure to dynamics. By applying these, we can predict the dynamic attractors of our clustered spiking networks from the structure of between-cluster connectivity. This allows us to construct networks displaying a diverse array of nonlinear cluster dynamics, including metastable periodic orbits and chaotic attractors. Relaxing the assumption that inhibition is fast, we see that the CTLN model is still able to predict the activity of clustered spiking networks with reasonable inhibitory timescales. For slow enough inhibition, we observe bifurcations between CTLN-like dynamics and global excitatory/inhibitory oscillations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06234v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caitlin Lienkaemper, Gabriel Koch Ocker</dc:creator>
    </item>
    <item>
      <title>When can in-context learning generalize out of task distribution?</title>
      <link>https://arxiv.org/abs/2506.05574</link>
      <description>arXiv:2506.05574v1 Announce Type: cross 
Abstract: In-context learning (ICL) is a remarkable capability of pretrained transformers that allows models to generalize to unseen tasks after seeing only a few examples. We investigate empirically the conditions necessary on the pretraining distribution for ICL to emerge and generalize \emph{out-of-distribution}. Previous work has focused on the number of distinct tasks necessary in the pretraining dataset. Here, we use a different notion of task diversity to study the emergence of ICL in transformers trained on linear functions. We find that as task diversity increases, transformers undergo a transition from a specialized solution, which exhibits ICL only within the pretraining task distribution, to a solution which generalizes out of distribution to the entire task space. We also investigate the nature of the solutions learned by the transformer on both sides of the transition, and observe similar transitions in nonlinear regression problems. We construct a phase diagram to characterize how our concept of task diversity interacts with the number of pretraining tasks. In addition, we explore how factors such as the depth of the model and the dimensionality of the regression problem influence the transition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05574v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chase Goddard, Lindsay M. Smith, Vudtiwat Ngampruetikorn, David J. Schwab</dc:creator>
    </item>
    <item>
      <title>Connectome brain fingerprinting: terminology, measures, and target properties</title>
      <link>https://arxiv.org/abs/2506.05769</link>
      <description>arXiv:2506.05769v1 Announce Type: cross 
Abstract: Distinguishing one person from another (what biometricians call recognition) is extremely relevant for different aspects of life. Traditional biometric modalities (fingerprint, face, iris, voice) rely on unique, stable features that reliably differentiate individuals. Recently, the term fingerprinting has gained popularity in neuroscience, with a growing number of studies adopting the term to describe various brain based metrics derived from different techniques. However, we think there is a mismatch between its widely accepted meaning in the biometric community and some brain based metrics. Many of these measures do not satisfy the strict definition of a biometric fingerprint that is, a stable trait that uniquely identifies an individual. In this study we discuss some issues that may generate confusion in this context and suggest how to treat the question in the future. In particular, we review how fingerprint is currently used in the neuroscience literature, highlight mismatches with the biometric community definition, and offer clear guidelines for distinguishing genuine biometric fingerprints from exploratory similarity metrics. By clarifying terminology and criteria, we aim to align practices and facilitate communication across fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05769v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Fraschini, Matteo Demuru, Daniele Marinazzo, Luca Didaci</dc:creator>
    </item>
    <item>
      <title>Integrating Complexity and Biological Realism: High-Performance Spiking Neural Networks for Breast Cancer Detection</title>
      <link>https://arxiv.org/abs/2506.06265</link>
      <description>arXiv:2506.06265v1 Announce Type: cross 
Abstract: Spiking Neural Networks (SNNs) event-driven nature enables efficient encoding of spatial and temporal features, making them suitable for dynamic time-dependent data processing. Despite their biological relevance, SNNs have seen limited application in medical image recognition due to difficulties in matching the performance of conventional deep learning models. To address this, we propose a novel breast cancer classification approach that combines SNNs with Lempel-Ziv Complexity (LZC) a computationally efficient measure of sequence complexity. LZC enhances the interpretability and accuracy of spike-based models by capturing structural patterns in neural activity. Our study explores both biophysical Leaky Integrate-and-Fire (LIF) and probabilistic Levy-Baxter (LB) neuron models under supervised, unsupervised, and hybrid learning regimes. Experiments were conducted on the Breast Cancer Wisconsin dataset using numerical features derived from medical imaging. LB-based models consistently exceeded 90.00% accuracy, while LIF-based models reached over 85.00%. The highest accuracy of 98.25% was achieved using an ANN-to-SNN conversion method applied to both neuron models comparable to traditional deep learning with back-propagation, but at up to 100 times lower computational cost. This hybrid approach merges deep learning performance with the efficiency and plausibility of SNNs, yielding top results at lower computational cost. We hypothesize that the synergy between temporal-coding, spike-sparsity, and LZC-driven complexity analysis enables more-efficient feature extraction. Our findings demonstrate that SNNs combined with LZC offer promising, biologically plausible alternative to conventional neural networks in medical diagnostics, particularly for resource-constrained or real-time systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06265v1</guid>
      <category>cs.NE</category>
      <category>eess.IV</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zofia Rudnicka, Januszcz Szczepanski, Agnieszka Pregowska</dc:creator>
    </item>
    <item>
      <title>Inferring entropy production in many-body systems using nonequilibrium MaxEnt</title>
      <link>https://arxiv.org/abs/2505.10444</link>
      <description>arXiv:2505.10444v2 Announce Type: replace-cross 
Abstract: We propose a method for inferring entropy production (EP) in high-dimensional stochastic systems, including many-body systems and non-Markovian systems with long memory. Standard techniques for estimating EP become intractable in such systems due to computational and statistical limitations. We infer trajectory-level EP and lower bounds on average EP by exploiting a nonequilibrium analogue of the Maximum Entropy principle, along with convex duality. Our approach uses only samples of trajectory observables (such as spatiotemporal correlation functions). It does not require reconstruction of high-dimensional probability distributions or rate matrices, nor any special assumptions such as discrete states or multipartite dynamics. It may be used to compute a hierarchical decomposition of EP, reflecting contributions from different kinds of interactions, and it has an intuitive physical interpretation as a thermodynamic uncertainty relation. We demonstrate its numerical performance on a disordered nonequilibrium spin model with 1000 spins and a large neural spike-train dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10444v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>nlin.AO</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miguel Aguilera, Sosuke Ito, Artemy Kolchinsky</dc:creator>
    </item>
  </channel>
</rss>
