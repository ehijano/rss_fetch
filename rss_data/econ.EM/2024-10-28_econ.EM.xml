<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Oct 2024 02:57:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Heterogeneous Intertemporal Treatment Effects via Dynamic Panel Data Models</title>
      <link>https://arxiv.org/abs/2410.19060</link>
      <description>arXiv:2410.19060v1 Announce Type: new 
Abstract: We study the identification and estimation of heterogeneous, intertemporal treatment effects (TE) when potential outcomes depend on past treatments. First, applying a dynamic panel data model to observed outcomes, we show that instrument-based GMM estimators, such as Arellano and Bond (1991), converge to a non-convex (negatively weighted) aggregate of TE plus non-vanishing trends. We then provide restrictions on sequential exchangeability (SE) of treatment and TE heterogeneity that reduce the GMM estimand to a convex (positively weighted) aggregate of TE. Second, we introduce an adjusted inverse-propensity-weighted (IPW) estimator for a new notion of average treatment effect (ATE) over past observed treatments. Third, we show that when potential outcomes are generated by dynamic panel data models with homogeneous TE, such GMM estimators converge to causal parameters (even when SE is generically violated without conditioning on individual fixed effects). Finally, we motivate SE and compare it with parallel trends (PT) in various settings with observational data (when treatments are dynamic, rational choices under learning) or experimental data (when treatments are sequentially randomized).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19060v1</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philip Marx, Elie Tamer, Xun Tang</dc:creator>
    </item>
    <item>
      <title>Inference on Multiple Winners with Applications to Microcredit and Economic Mobility</title>
      <link>https://arxiv.org/abs/2410.19212</link>
      <description>arXiv:2410.19212v1 Announce Type: new 
Abstract: While policymakers and researchers are often concerned with conducting inference based on a data-dependent selection, a strictly larger class of inference problems arises when considering multiple data-dependent selections, such as when selecting on statistical significance or quantiles. Given this, we study the problem of conducting inference on multiple selections, which we dub the inference on multiple winners problem. In this setting, we encounter both selective and multiple testing problems, making existing approaches either not applicable or too conservative. Instead, we propose a novel, two-step approach to the inference on multiple winners problem, with the first step modeling the selection of winners, and the second step using this model to conduct inference only on the set of likely winners. Our two-step approach reduces over-coverage error by up to 96%. We apply our two-step approach to revisit the winner's curse in the creating moves to opportunity (CMTO) program, and to study external validity issues in the microcredit literature. In the CMTO application, we find that, after correcting for the inference on multiple winners problem, we fail to reject the possibility of null effects in the majority of census tracts selected by the CMTO program. In our microcredit application, we find that heterogeneity in treatment effect estimates remains largely unaffected even after our proposed inference corrections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19212v1</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andreas Petrou-Zeniou, Azeem M. Shaikh</dc:creator>
    </item>
    <item>
      <title>Robust Time Series Causal Discovery for Agent-Based Model Validation</title>
      <link>https://arxiv.org/abs/2410.19412</link>
      <description>arXiv:2410.19412v1 Announce Type: cross 
Abstract: Agent-Based Model (ABM) validation is crucial as it helps ensuring the reliability of simulations, and causal discovery has become a powerful tool in this context. However, current causal discovery methods often face accuracy and robustness challenges when applied to complex and noisy time series data, which is typical in ABM scenarios. This study addresses these issues by proposing a Robust Cross-Validation (RCV) approach to enhance causal structure learning for ABM validation. We develop RCV-VarLiNGAM and RCV-PCMCI, novel extensions of two prominent causal discovery algorithms. These aim to reduce the impact of noise better and give more reliable causal relation results, even with high-dimensional, time-dependent data. The proposed approach is then integrated into an enhanced ABM validation framework, which is designed to handle diverse data and model structures.
  The approach is evaluated using synthetic datasets and a complex simulated fMRI dataset. The results demonstrate greater reliability in causal structure identification. The study examines how various characteristics of datasets affect the performance of established causal discovery methods. These characteristics include linearity, noise distribution, stationarity, and causal structure density. This analysis is then extended to the RCV method to see how it compares in these different situations. This examination helps confirm whether the results are consistent with existing literature and also reveals the strengths and weaknesses of the novel approaches.
  By tackling key methodological challenges, the study aims to enhance ABM validation with a more resilient valuation framework presented. These improvements increase the reliability of model-driven decision making processes in complex systems analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19412v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>econ.EM</category>
      <category>stat.CO</category>
      <pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gene Yu, Ce Guo, Wayne Luk</dc:creator>
    </item>
    <item>
      <title>Unified Causality Analysis Based on the Degrees of Freedom</title>
      <link>https://arxiv.org/abs/2410.19469</link>
      <description>arXiv:2410.19469v1 Announce Type: cross 
Abstract: Temporally evolving systems are typically modeled by dynamic equations. A key challenge in accurate modeling is understanding the causal relationships between subsystems, as well as identifying the presence and influence of unobserved hidden drivers on the observed dynamics. This paper presents a unified method capable of identifying fundamental causal relationships between pairs of systems, whether deterministic or stochastic. Notably, the method also uncovers hidden common causes beyond the observed variables. By analyzing the degrees of freedom in the system, our approach provides a more comprehensive understanding of both causal influence and hidden confounders. This unified framework is validated through theoretical models and simulations, demonstrating its robustness and potential for broader application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19469v1</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andr\'as Telcs, Marcell T. Kurbucz, Antal Jakov\'ac</dc:creator>
    </item>
    <item>
      <title>Causal inference and policy evaluation without a control group</title>
      <link>https://arxiv.org/abs/2312.05858</link>
      <description>arXiv:2312.05858v2 Announce Type: replace 
Abstract: Without a control group, the most widespread methodologies for estimating causal effects cannot be applied. To fill this gap, we propose the Machine Learning Control Method, a new approach for causal panel analysis that estimates causal parameters without relying on untreated units. We formalize identification within the potential outcomes framework and then provide estimation based on machine learning algorithms. To illustrate the practical relevance of our method, we present simulation evidence, a replication study, and an empirical application on the impact of the COVID-19 crisis on educational inequality. We implement the proposed approach in the companion R package MachineControl</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05858v2</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Augusto Cerqua, Marco Letta, Fiammetta Menchetti</dc:creator>
    </item>
    <item>
      <title>Realized Stochastic Volatility Model with Skew-t Distributions for Improved Volatility and Quantile Forecasting</title>
      <link>https://arxiv.org/abs/2401.13179</link>
      <description>arXiv:2401.13179v2 Announce Type: replace 
Abstract: Forecasting volatility and quantiles of financial returns is essential for accurately measuring financial tail risks, such as value-at-risk and expected shortfall. The critical elements in these forecasts involve understanding the distribution of financial returns and accurately estimating volatility. This paper introduces an advancement to the traditional stochastic volatility model, termed the realized stochastic volatility model, which integrates realized volatility as a precise estimator of volatility. To capture the well-known characteristics of return distribution, namely skewness and heavy tails, we incorporate three types of skew-t distributions. Among these, two distributions include the skew-normal feature, offering enhanced flexibility in modeling the return distribution. We employ a Bayesian estimation approach using the Markov chain Monte Carlo method and apply it to major stock indices. Our empirical analysis, utilizing data from US and Japanese stock indices, indicates that the inclusion of both skewness and heavy tails in daily returns significantly improves the accuracy of volatility and quantile forecasts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13179v2</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Makoto Takahashi, Yuta Yamauchi, Toshiaki Watanabe, Yasuhiro Omori</dc:creator>
    </item>
    <item>
      <title>Estimating and predicting treatment-effect heterogeneity across sites, in multi-site randomized experiments with few randomization units per site</title>
      <link>https://arxiv.org/abs/2405.17254</link>
      <description>arXiv:2405.17254v2 Announce Type: replace 
Abstract: We seek to estimate and predict treatment-effect heterogeneity across sites, in multi-site randomized controlled trials, with a large number of sites but few randomization units per site. As is well-known, an Empirical-Bayes (EB) estimator can be used to estimate the variance of the treatment effect across sites. We propose consistent estimators of the coefficients from ridge and OLS regressions of site-level effects on site-level characteristics that are unobserved but can be unbiasedly estimated, such as sites' average outcome without treatment, or site-specific treatment effects on mediator variables. In experiments with imperfect compliance, we also propose a non-parametric and partly testable assumption under which the variance of local average treatment effects (LATEs) across sites can be estimated. We revisit Behaghel et al (2014), who study the effect of counseling programs on job seekers job-finding rate, in 200 job placement agencies in France. We find considerable treatment-effect heterogeneity, both for intention to treat and LATE effects, and the treatment effect is negatively correlated with sites' job-finding rate without treatment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17254v2</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ement de Chaisemartin, Antoine Deeb</dc:creator>
    </item>
    <item>
      <title>Actually, There is No Rotational Indeterminacy in the Approximate Factor Model</title>
      <link>https://arxiv.org/abs/2408.11676</link>
      <description>arXiv:2408.11676v2 Announce Type: replace 
Abstract: We show that in the approximate factor model the population normalised principal components converge in mean square (up to sign) under the standard assumptions for $n\to \infty$. Consequently, we have a generic interpretation of what the principal components estimator is actually identifying and existing results on factor identification are reinforced and refined. Based on this result, we provide a new asymptotic theory for the approximate factor model entirely without rotation matrices. We show that the factors space is consistently estimated with finite $T$ for $n\to \infty$ while consistency of the factors a.k.a the $L^2$ limit of the normalised principal components requires that both $(n, T)\to \infty$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11676v2</guid>
      <category>econ.EM</category>
      <pubDate>Mon, 28 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philipp Gersing</dc:creator>
    </item>
  </channel>
</rss>
