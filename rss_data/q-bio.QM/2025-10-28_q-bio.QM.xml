<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 29 Oct 2025 04:01:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Gut decisions based on the liver: A radiomics approach to boost colorectal cancer screening</title>
      <link>https://arxiv.org/abs/2510.23687</link>
      <description>arXiv:2510.23687v1 Announce Type: new 
Abstract: Non-invasive colorectal cancer (CRC) screening represents a key opportunity to improve colonoscopy participation rates and reduce CRC mortality. This study explores the potential of the gut-liver axis for predicting colorectal neoplasia through liver-derived radiomic features extracted from routine CT images as a novel opportunistic screening approach. In this retrospective study, we analyzed data from 1,997 patients who underwent colonoscopy and abdominal CT. Patients either had no colorectal neoplasia (n=1,189) or colorectal neoplasia (n_total=808; adenomas n=423, CRC n=385). Radiomics features were extracted from 3D liver segmentations using the Radiomics Processing ToolKit (RPTK), which performed feature extraction, filtering, and classification. The dataset was split into training (n=1,397) and test (n=600) cohorts. Five machine learning models were trained with 5-fold cross-validation on the 20 most informative features, and the best model ensemble was selected based on the validation AUROC. The best radiomics-based XGBoost model achieved a test AUROC of 0.810, clearly outperforming the best clinical-only model (test AUROC: 0.457). Subclassification between colorectal cancer and adenoma showed lower accuracy (test AUROC: 0.674). Our findings establish proof-of-concept that liver-derived radiomics from routine abdominal CT can predict colorectal neoplasia. Beyond offering a pragmatic, widely accessible adjunct to CRC screening, this approach highlights the gut-liver axis as a novel biomarker source for opportunistic screening and sparks new mechanistic hypotheses for future translational research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23687v1</guid>
      <category>q-bio.QM</category>
      <category>eess.IV</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Hinterberger (DKFZ Hector Cancer Institute at the University Medical Center Mannheim, Germany, Junior Clinical Cooperation Unit Translational Molecular Imaging in Oncologic Therapy Monitoring), Jonas Bohn (Division of Medical Image Computing, German Cancer Research Center, Translational Lung Research Center, Faculty of Biosciences, Heidelberg University, Heidelberg, Germany, National Center for Tumor Diseases), Dasha Trofimova (Division of Medical Image Computing, German Cancer Research Center, Helmholtz Imaging, Heidelberg, Germany), Nicolas Knabe (Department of Radiology and Nuclear Medicine, University Medical Center Mannheim, Heidelberg University, Mannheim, Germany), Julia Dettling (Department of Radiology and Nuclear Medicine, University Medical Center Mannheim, Heidelberg University, Mannheim, Germany), Tobias Norajitra (Division of Medical Image Computing, German Cancer Research Center, Translational Lung Research Center, Pattern Analysis and Learning Group, Heidelberg University Hospital, Heidelberg, Germany), Fabian Isensee (Division of Medical Image Computing, German Cancer Research Center, Helmholtz Imaging, Heidelberg, Germany), Johannes Betge (DKFZ Hector Cancer Institute at the University Medical Center Mannheim, Germany, Department of Medicine II, University Medical Center Mannheim, Medical Faculty Mannheim, Mannheim, Germany, Junior Clinical Cooperation Unit Translational Gastrointestinal Oncology and Preclinical Models, German Cancer Research Center, Heidelberg, Germany, German Cancer Consortium, DKTK, Heidelberg, Germany), Stefan O. Sch\"onberg (Department of Radiology and Nuclear Medicine, University Medical Center Mannheim, Heidelberg University, Mannheim, Germany), Dominik N\"orenberg (Department of Radiology and Nuclear Medicine, University Medical Center Mannheim, Heidelberg University, Mannheim, Germany), Sergio Grosu (Department of Radiology, University Hospital, LMU Munich, Munich, Germany), Sonja Loges (DKFZ Hector Cancer Institute at the University Medical Center Mannheim, Germany, Division of Personalized Medical Oncology, Department of Personalized Oncology, University Hospital Mannheim, Medical Faculty Mannheim, University of Heidelberg, Mannheim, Germany), Ralf Floca (Division of Medical Image Computing, German Cancer Research Center, National Center for Tumor Diseases, Pattern Analysis and Learning Group, Heidelberg University Hospital, Heidelberg, Germany), Jakob Nikolas Kather (Else Kroener Fresenius Center for Digital Health, Faculty of Medicine and University Hospital Carl Gustav Carus, TUD Dresden University of Technology, Dresden, Germany, Department of Medicine I, University Hospital Dresden, Dresden, Germany, Medical Oncology, National Center for Tumor Diseases), Klaus Maier-Hein (Division of Medical Image Computing, German Cancer Research Center, Translational Lung Research Center, National Center for Tumor Diseases, Helmholtz Imaging, Heidelberg, Germany, Pattern Analysis and Learning Group, Heidelberg University Hospital, Heidelberg, Germany, Faculty of Medicine, University of Heidelberg, Heidelberg, Germany, Faculty of Mathematics and Computer Science, Heidelberg University, Heidelberg, Germany), Freba Grawe (DKFZ Hector Cancer Institute at the University Medical Center Mannheim, Germany, Junior Clinical Cooperation Unit Translational Molecular Imaging in Oncologic Therapy Monitoring, Department of Radiology and Nuclear Medicine, University Medical Center Mannheim, Heidelberg University, Mannheim, Germany)</dc:creator>
    </item>
    <item>
      <title>Machine learning approaches for interpretable antibody property prediction using structural data</title>
      <link>https://arxiv.org/abs/2510.23975</link>
      <description>arXiv:2510.23975v1 Announce Type: new 
Abstract: Understanding the relationship between antibody sequence, structure and function is essential for the design of antibody-based therapeutics and research tools. Recently, machine learning (ML) models mostly based on the application of large language models to sequence information have been developed to predict antibody properties. Yet there are open directions to incorporate structural information, not only to enhance prediction but also to offer insights into the underlying molecular mechanisms. This chapter provides an overview of these approaches and describes two ML frameworks that integrate structural data (via graph representations) with neural networks to predict properties of antibodies: ANTIPASTI predicts binding affinity (a global property) whereas INFUSSE predicts residue flexibility (a local property). We survey the principles underpinning these models; the ways in which they encode structural knowledge; and the strategies that can be used to extract biologically relevant statistical signals that can help discover and disentangle molecular determinants of the properties of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23975v1</guid>
      <category>q-bio.QM</category>
      <category>physics.bio-ph</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Michalewicz, Mauricio Barahona, Barbara Bravi</dc:creator>
    </item>
    <item>
      <title>Integrating Genomics into Multimodal EHR Foundation Models</title>
      <link>https://arxiv.org/abs/2510.23639</link>
      <description>arXiv:2510.23639v1 Announce Type: cross 
Abstract: This paper introduces an innovative Electronic Health Record (EHR) foundation model that integrates Polygenic Risk Scores (PRS) as a foundational data modality, moving beyond traditional EHR-only approaches to build more holistic health profiles. Leveraging the extensive and diverse data from the All of Us (AoU) Research Program, this multimodal framework aims to learn complex relationships between clinical data and genetic predispositions. The methodology extends advancements in generative AI to the EHR foundation model space, enhancing predictive capabilities and interpretability. Evaluation on AoU data demonstrates the model's predictive value for the onset of various conditions, particularly Type 2 Diabetes (T2D), and illustrates the interplay between PRS and EHR data. The work also explores transfer learning for custom classification tasks, showcasing the architecture's versatility and efficiency. This approach is pivotal for unlocking new insights into disease prediction, proactive health management, risk stratification, and personalized treatment strategies, laying the groundwork for more personalized, equitable, and actionable real-world evidence generation in healthcare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23639v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jonathan Amar, Edward Liu, Alessandra Breschi, Liangliang Zhang, Pouya Kheradpour, Sylvia Li, Lisa Soleymani Lehmann, Alessandro Giulianelli, Matt Edwards, Yugang Jia, David Nola, Raghav Mani, Pankaj Vats, Jesse Tetreault, T. J. Chen, Cory Y. McLean</dc:creator>
    </item>
    <item>
      <title>Low-N Protein Activity Optimization with FolDE</title>
      <link>https://arxiv.org/abs/2510.24053</link>
      <description>arXiv:2510.24053v1 Announce Type: cross 
Abstract: Proteins are traditionally optimized through the costly construction and measurement of many mutants. Active Learning-assisted Directed Evolution (ALDE) alleviates that cost by predicting the best improvements and iteratively testing mutants to inform predictions. However, existing ALDE methods face a critical limitation: selecting the highest-predicted mutants in each round yields homogeneous training data insufficient for accurate prediction models in subsequent rounds. Here we present FolDE, an ALDE method designed to maximize end-of-campaign success. In simulations across 20 protein targets, FolDE discovers 23% more top 10% mutants than the best baseline ALDE method (p=0.005) and is 55% more likely to find top 1% mutants. FolDE achieves this primarily through naturalness-based warm-starting, which augments limited activity measurements with protein language model outputs to improve activity prediction. We also introduce a constant-liar batch selector, which improves batch diversity; this is important in multi-mutation campaigns but had limited effect in our benchmarks. The complete workflow is freely available as open-source software, making efficient protein optimization accessible to any laboratory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24053v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob B. Roberts, Catherine R. Ji, Isaac Donnell, Thomas D. Young, Allison N. Pearson, Graham A. Hudson, Leah S. Keiser, Mia Wesselkamper, Peter H. Winegar, Janik Ludwig, Sarah H. Klass, Isha V. Sheth, Ezechinyere C. Ukabiala, Maria C. T. Astolfi, Benjamin Eysenbach, Jay D. Keasling</dc:creator>
    </item>
    <item>
      <title>An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine</title>
      <link>https://arxiv.org/abs/2510.24359</link>
      <description>arXiv:2510.24359v1 Announce Type: cross 
Abstract: Artificial intelligence in medicine is built to serve the average patient. By minimizing error across large datasets, most systems deliver strong aggregate accuracy yet falter at the margins: patients with rare variants, multimorbidity, or underrepresented demographics. This average patient fallacy erodes both equity and trust. We propose a different design: a multi-agent ecosystem for N-of-1 decision support. In this environment, agents clustered by organ systems, patient populations, and analytic modalities draw on a shared library of models and evidence synthesis tools. Their results converge in a coordination layer that weighs reliability, uncertainty, and data density before presenting the clinician with a decision-support packet: risk estimates bounded by confidence ranges, outlier flags, and linked evidence. Validation shifts from population averages to individual reliability, measured by error in low-density regions, calibration in the small, and risk--coverage trade-offs. Anticipated challenges include computational demands, automation bias, and regulatory fit, addressed through caching strategies, consensus checks, and adaptive trial frameworks. By moving from monolithic models to orchestrated intelligence, this approach seeks to align medical AI with the first principle of medicine: care that is transparent, equitable, and centered on the individual.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24359v1</guid>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pedram Fard, Alaleh Azhir, Neguine Rezaii, Jiazi Tian, Hossein Estiri</dc:creator>
    </item>
    <item>
      <title>Pearl: A Foundation Model for Placing Every Atom in the Right Location</title>
      <link>https://arxiv.org/abs/2510.24670</link>
      <description>arXiv:2510.24670v1 Announce Type: cross 
Abstract: Accurately predicting the three-dimensional structures of protein-ligand complexes remains a fundamental challenge in computational drug discovery that limits the pace and success of therapeutic design. Deep learning methods have recently shown strong potential as structural prediction tools, achieving promising accuracy across diverse biomolecular systems. However, their performance and utility are constrained by scarce experimental data, inefficient architectures, physically invalid poses, and the limited ability to exploit auxiliary information available at inference. To address these issues, we introduce Pearl (Placing Every Atom in the Right Location), a foundation model for protein-ligand cofolding at scale. Pearl addresses these challenges with three key innovations: (1) training recipes that include large-scale synthetic data to overcome data scarcity; (2) architectures that incorporate an SO(3)-equivariant diffusion module to inherently respect 3D rotational symmetries, improving generalization and sample efficiency, and (3) controllable inference, including a generalized multi-chain templating system supporting both protein and non-polymeric components as well as dual unconditional/conditional modes. Pearl establishes a new state-of-the-art performance in protein-ligand cofolding. On the key metric of generating accurate (RMSD &lt; 2 \r{A}) and physically valid poses, Pearl surpasses AlphaFold 3 and other open source baselines on the public Runs N' Poses and PoseBusters benchmarks, delivering 14.5% and 14.2% improvements, respectively, over the next best model. In the pocket-conditional cofolding regime, Pearl delivers $3.6\times$ improvement on a proprietary set of challenging, real-world drug targets at the more rigorous RMSD &lt; 1 \r{A} threshold. Finally, we demonstrate that model performance correlates directly with synthetic dataset size used in training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24670v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator> Genesis Research Team, Alejandro Dobles, Nina Jovic, Kenneth Leidal, Pranav Murugan, David C. Williams, Drausin Wulsin, Nate Gruver, Christina X. Ji, Korrawat Pruegsanusak, Gianluca Scarpellini, Ansh Sharma, Wojciech Swiderski, Andrea Bootsma, Richard Strong Bowen, Charlotte Chen, Jamin Chen, Marc Andr\'e D\"amgen, Roy Tal Dew, Benjamin DiFrancesco, J. D. Fishman, Alla Ivanova, Zach Kagin, David Li-Bland, Zuli Liu, Igor Morozov, Jeffrey Ouyang-Zhang, Frank C. Pickard IV, Kushal S. Shah, Ben Shor, Gabriel Monteiro da Silva, Maxx Tessmer, Carl Tilbury, Cyr Vetcher, Daniel Zeng, Maruan Al-Shedivat, Aleksandra Faust, Evan N. Feinberg, Michael V. LeVine, Matteus Pan</dc:creator>
    </item>
    <item>
      <title>Machine Learning-Enhanced Colorimetric Sensing: Achieving over 5700-fold Accuracy Improvement via Full-Spectrum Modeling</title>
      <link>https://arxiv.org/abs/2509.03398</link>
      <description>arXiv:2509.03398v2 Announce Type: replace-cross 
Abstract: Conventional colorimetric sensing methods typically rely on signal intensity at a single wavelength, often selected heuristically based on peak visual modulation. This approach overlooks the structured information embedded in full-spectrum transmission profiles, particularly in intensity-based systems where linear models may be highly effective. In this study, we experimentally demonstrate that applying a forward feature selection strategy to normalized transmission spectra, combined with linear regression and ten-fold cross-validation, yields significant improvements in predictive accuracy. Using food dye dilutions as a model system, the mean squared error was reduced from over 22,000 with a single wavelength to 3.87 using twelve selected features, corresponding to a more than 5,700-fold enhancement. These results validate that full-spectrum modeling enables precise concentration prediction without requiring changes to the sensing hardware. The approach is broadly applicable to colorimetric assays used in medical diagnostics, environmental monitoring, and industrial analysis, offering a scalable pathway to improve sensitivity and reliability in existing platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03398v2</guid>
      <category>physics.med-ph</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Majid Aalizadeh, Chinmay Raut, Ali Tabartehfarahani, Xudong Fan</dc:creator>
    </item>
  </channel>
</rss>
