<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Jul 2024 01:35:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 10 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Data-driven modeling from biased small training data using periodic orbits</title>
      <link>https://arxiv.org/abs/2407.06229</link>
      <description>arXiv:2407.06229v1 Announce Type: new 
Abstract: In this study, we investigate the effect of reservoir computing training data on the reconstruction of chaotic dynamics. Our findings indicate that a training time series comprising a few periodic orbits of low periods can successfully reconstruct the Lorenz attractor. We also demonstrate that biased training data does not negatively impact reconstruction success. Our method's ability to reconstruct a physical measure is much better than the so-called cycle expansion approach, which relies on weighted averaging. Additionally, we demonstrate that fixed point attractors and chaotic transients can be accurately reconstructed by a model trained from a few periodic orbits, even when using different parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06229v1</guid>
      <category>physics.data-an</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kengo Nakai, Yoshitaka Saiki</dc:creator>
    </item>
    <item>
      <title>A unified machine learning approach for reconstructing hadronically decaying tau leptons</title>
      <link>https://arxiv.org/abs/2407.06788</link>
      <description>arXiv:2407.06788v1 Announce Type: cross 
Abstract: Tau leptons serve as an important tool for studying the production of Higgs and electroweak bosons, both within and beyond the Standard Model of particle physics. Accurate reconstruction and identification of hadronically decaying tau leptons is a crucial task for current and future high energy physics experiments. Given the advances in jet tagging, we demonstrate how tau lepton reconstruction can be decomposed into tau identification, kinematic reconstruction, and decay mode classification in a multi-task machine learning setup.Based on an electron-positron collision dataset with full detector simulation and reconstruction, we show that common jet tagging architectures can be effectively used for these subtasks. We achieve comparable momentum resolutions of 2-3% with all the tested models, while the precision of reconstructing individual decay modes is between 80-95%. This paper also serves as an introduction to a new publicly available Fu{\tau}ure dataset and provides recipes for the development and training of tau reconstruction algorithms, while allowing to study resilience to domain shifts and the use of foundation models for such tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06788v1</guid>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laurits Tani, Nalong-Norman Seeba, Hardi Vanaveski, Joosep Pata, Torben Lange</dc:creator>
    </item>
    <item>
      <title>Lorentz-Equivariant Geometric Algebra Transformers for High-Energy Physics</title>
      <link>https://arxiv.org/abs/2405.14806</link>
      <description>arXiv:2405.14806v2 Announce Type: replace 
Abstract: Extracting scientific understanding from particle-physics experiments requires solving diverse learning problems with high precision and good data efficiency. We propose the Lorentz Geometric Algebra Transformer (L-GATr), a new multi-purpose architecture for high-energy physics. L-GATr represents high-energy data in a geometric algebra over four-dimensional space-time and is equivariant under Lorentz transformations, the symmetry group of relativistic kinematics. At the same time, the architecture is a Transformer, which makes it versatile and scalable to large systems. L-GATr is first demonstrated on regression and classification tasks from particle physics. We then construct the first Lorentz-equivariant generative model: a continuous normalizing flow based on an L-GATr network, trained with Riemannian flow matching. Across our experiments, L-GATr is on par with or outperforms strong domain-specific baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14806v2</guid>
      <category>physics.data-an</category>
      <category>cs.LG</category>
      <category>hep-ph</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Spinner, Victor Bres\'o, Pim de Haan, Tilman Plehn, Jesse Thaler, Johann Brehmer</dc:creator>
    </item>
  </channel>
</rss>
