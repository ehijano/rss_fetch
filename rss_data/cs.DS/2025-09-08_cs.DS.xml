<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Sep 2025 04:00:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Subsequence Covers of Words</title>
      <link>https://arxiv.org/abs/2509.05827</link>
      <description>arXiv:2509.05827v1 Announce Type: new 
Abstract: We introduce subsequence covers (s-covers, in short), a new type of covers of a word. A word $C$ is an s-cover of a word $S$ if the occurrences of $C$ in $S$ as subsequences cover all the positions in $S$.
  The s-covers seem to be computationally much harder than standard covers of words (cf. Apostolico et al., Inf. Process. Lett. 1991), but, on the other hand, much easier than the related shuffle powers (Warmuth and Haussler, J. Comput. Syst. Sci. 1984).
  We give a linear-time algorithm for testing if a candidate word $C$ is an s-cover of a word $S$ over a polynomially-bounded integer alphabet. We also give an algorithm for finding a shortest s-cover of a word $S$, which in the case of a constant-sized alphabet, also runs in linear time.
  The words without proper s-cover are called s-primitive. We complement our algorithmic results with explicit lower and an upper bound on the length of a longest s-primitive word. Both bounds are exponential in the size of the alphabet. The upper bound presented here improves the bound given in the conference version of this paper [SPIRE 2022].</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05827v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:journal_reference>"Subsequence covers of words". Theor. Comput. Sci. 1041: 115216 (2025)</arxiv:journal_reference>
      <dc:creator>Panagiotis Charalampopoulos, Solon P. Pissis, Jakub Radoszewski, Wojciech Rytter, Tomasz Wale\'n, Wiktor Zuba</dc:creator>
    </item>
    <item>
      <title>Generalized Graph Packing Problems Parameterized by Treewidth</title>
      <link>https://arxiv.org/abs/2509.06091</link>
      <description>arXiv:2509.06091v1 Announce Type: new 
Abstract: $H$-Packing is the problem of finding a maximum number of vertex-disjoint copies of $H$ in a given graph $G$. $H$-Partition is the special case of finding a set of vertex-disjoint copies that cover each vertex of $G$ exactly once. Our goal is to study these problems and some generalizations on bounded-treewidth graphs. The case of $H$ being a triangle is well understood: given a tree decomposition of $G$ having treewidth $tw$, the $K_3$-Packing problem can be solved in time $2^{tw} \cdot n^{O(1)}$, while Lokshtanov et al.~[{\it ACM Transactions on Algorithms} 2018] showed, under the Strong Exponential-Time Hypothesis (SETH), that there is no $(2-\epsilon)^{tw}\cdot n^{O(1)}$ algorithm for any $\epsilon&gt;0$ even for $K_3$-Partition. Similar results can be obtained for any other clique $K_d$ for $d\ge 3$. We provide generalizations in two directions:
  - We consider a generalization of the problem where every vertex can be used at most $c$ times for some $c\ge 1$. When $H$ is any clique $K_d$ with $d\ge 3$, then we give upper and lower bounds showing that the optimal running time increases to $(c+1)^{tw}\cdot n^{O(1)}$. We consider two variants depending on whether a copy of $H$ can be used multiple times in the packing.
  - If $H$ is not a clique, then the dependence of the running time on treewidth may not be even single exponential. Specifically, we show that if $H$ is any fixed graph where not every 2-connected component is a clique, then there is no $2^{o({tw}\log {tw})}\cdot n^{O(1)}$ algorithm for \textsc{$H$-Partition}, assuming the Exponential-Time Hypothesis (ETH).</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06091v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bar{\i}\c{s} Can Esmer, D\'aniel Marx</dc:creator>
    </item>
    <item>
      <title>Parameterized Algorithms for Computing Pareto Sets</title>
      <link>https://arxiv.org/abs/2509.06124</link>
      <description>arXiv:2509.06124v1 Announce Type: new 
Abstract: Dynamic programming over tree decompositions is a common technique in parameterized algorithms. In this paper, we study whether this technique can also be applied to compute Pareto sets of multiobjective optimization problems. We first derive an algorithm to compute the Pareto set for the multicriteria s-t cut problem and show how this result can be applied to a polygon aggregation problem arising in cartography that has recently been introduced by Rottmann et al. (GIScience 2021). We also show how to apply these techniques to also compute the Pareto set of the multiobjective minimum spanning tree problem and for the multiobjective TSP. The running time of our algorithms is $O(f(w)\cdot\mathrm{poly}(n,p_{\text{max}}))$, where $f$ is some function in the treewidth $w$, $n$ is the input size, and $p_{\text{max}}$ is an upper bound on the size of the Pareto sets of the subproblems that occur in the dynamic program. Finally, we present an experimental evaluation of computing Pareto sets on real-world instances of polygon aggregation problems. For this matter we devised a task-specific data structure that allows for efficient storage and modification of large sets of Pareto-optimal solutions. Throughout the implementation process, we incorporated several improved strategies and heuristics that significantly reduced both runtime and memory usage, enabling us to solve instances with treewidth of up to 22 within reasonable amount of time. Moreover, we conducted a preprocessing study to compare different tree decompositions in terms of their estimated overall runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06124v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua K\"onen, Heiko R\"oglin, Tarek Stuck</dc:creator>
    </item>
    <item>
      <title>Efficient Catalytic Graph Algorithms</title>
      <link>https://arxiv.org/abs/2509.06209</link>
      <description>arXiv:2509.06209v1 Announce Type: new 
Abstract: We give fast, simple, and implementable catalytic logspace algorithms for two fundamental graph problems.
  First, a randomized catalytic algorithm for $s\to t$ connectivity running in $\widetilde{O}(nm)$ time, and a deterministic catalytic algorithm for the same running in $\widetilde{O}(n^3 m)$ time. The former algorithm is the first algorithmic use of randomization in $\mathsf{CL}$. The algorithm uses one register per vertex and repeatedly ``pushes'' values along the edges in the graph.
  Second, a deterministic catalytic algorithm for simulating random walks which in $\widetilde{O}( m T^2 / \varepsilon )$ time estimates the probability a $T$-step random walk ends at a given vertex within $\varepsilon$ additive error. The algorithm uses one register for each vertex and increments it at each visit to ensure repeated visits follow different outgoing edges.
  Prior catalytic algorithms for both problems did not have explicit runtime bounds beyond being polynomial in $n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06209v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Cook, Edward Pyne</dc:creator>
    </item>
    <item>
      <title>Zero-Freeness is All You Need: A Weitz-Type FPTAS for the Entire Lee-Yang Zero-Free Region</title>
      <link>https://arxiv.org/abs/2509.06623</link>
      <description>arXiv:2509.06623v1 Announce Type: new 
Abstract: We present a Weitz-type FPTAS for the ferromagnetic Ising model across the entire Lee-Yang zero-free region, without relying on the strong spatial mixing (SSM) property. Our algorithm is Weitz-type for two reasons. First, it expresses the partition function as a telescoping product of ratios, with the key being to approximate each ratio. Second, it uses Weitz's self-avoiding walk tree, and truncates it at logarithmic depth to give a good and efficient approximation. The key difference from the standard Weitz algorithm is that we approximate a carefully designed edge-deletion ratio instead of the marginal probability of a vertex's spin, ensuring our algorithm does not require SSM.
  Furthermore, by establishing local dependence of coefficients (LDC), we indeed prove a novel form of SSM for these edge-deletion ratios, which, in turn, implies the standard SSM for the random cluster model. This is the first SSM result for the random cluster model on general graphs, beyond lattices. We prove LDC using a new division relation, and remarkably, such relations hold quite universally. As a result, we establish LDC for a variety of models. Combined with existing zero-freeness results for these models, we derive new SSM results for them. Our work suggests that both Weitz-type FPTASes and SSM can be derived from zero-freeness, while zero-freeness alone suffices for Weitz-type FPTASes, SSM additionally requires LDC, a combinatorial property independent of zero-freeness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06623v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuai Shao, Ke Shi</dc:creator>
    </item>
    <item>
      <title>The Steiner Shortest Path Tree Problem</title>
      <link>https://arxiv.org/abs/2509.06789</link>
      <description>arXiv:2509.06789v1 Announce Type: new 
Abstract: We introduce and study a novel problem of computing a shortest path tree with a minimum number of non-terminals. It can be viewed as an (unweighted) Steiner Shortest Path Tree (SSPT) that spans a given set of terminal vertices by shortest paths from a given source while minimizing the number of nonterminal vertices included in the tree. This problem is motivated by applications where shortest-path connections from a source are essential, and where reducing the number of intermediate vertices helps limit cost, complexity, or overhead. We show that the SSPT problem is NP-hard. To approximate it, we introduce and study the shortest path subgraph of a graph. Using it, we show an approximation-preserving reduction of SSPT to the uniform vertex-weighted variant of the Directed Steiner Tree (DST) problem, termed UVDST. Consequently, the algorithm of [Grandoni et al., 2023] approximating DST implies a quasi-polynomial polylog-approximation algorithm for SSPT. We present a polynomial polylog-approximation algorithm for UVDST, and thus for SSPT, for a restricted class of graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06789v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omer Asher, Yefim Dinitz, Shlomi Dolev, Li-on Raviv, Baruch Schieber</dc:creator>
    </item>
    <item>
      <title>Engineering Select Support for Hybrid Bitvectors</title>
      <link>https://arxiv.org/abs/2509.06900</link>
      <description>arXiv:2509.06900v1 Announce Type: new 
Abstract: One of the central problems in the design of compressed data structures is the efficient support for rank and select queries on bitvectors. These two operations form the backbone of more complex data structures (such as wavelet trees) used for the compact representation of texts, trees, graphs, or grids. Their efficient implementation is one of the most frequently studied problems in compressed data structures.
  One effective solution is the so-called hybrid bitvector implementation, which partitions the input bitvector into blocks and adaptively selects an encoding method, such as run-length, plain, or minority encoding, based on local redundancy. Experiments have shown that hybrid bitvectors achieve excellent all-around performance on repetitive and non-repetitive inputs.
  However, current implementations support only rank queries (i.e., counting the number of ones up to a given position) and lack support for select queries. This limitation significantly restricts their applicability. In this paper, we propose a method to add support for select queries to hybrid bitvectors, and we conduct an extensive set of experiments. Our results show that hybrid bitvectors offer excellent performance, matching the speed of the fastest and the space efficiency of the most compact existing bitvectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06900v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Chiu, Dominik Kempa</dc:creator>
    </item>
    <item>
      <title>Toward Efficient and Scalable Design of In-Memory Graph-Based Vector Search</title>
      <link>https://arxiv.org/abs/2509.05750</link>
      <description>arXiv:2509.05750v1 Announce Type: cross 
Abstract: Vector data is prevalent across business and scientific applications, and its popularity is growing with the proliferation of learned embeddings. Vector data collections often reach billions of vectors with thousands of dimensions, thus, increasing the complexity of their analysis. Vector search is the backbone of many critical analytical tasks, and graph-based methods have become the best choice for analytical tasks that do not require guarantees on the quality of the answers. Although several paradigms (seed selection, incremental insertion, neighborhood propagation, neighborhood diversification, and divide-and-conquer) have been employed to design in-memory graph-based vector search algorithms, a systematic comparison of the key algorithmic advances is still missing. We conduct an exhaustive experimental evaluation of twelve state-of-the-art methods on seven real data collections, with sizes up to 1 billion vectors. We share key insights about the strengths and limitations of these methods; e.g., the best approaches are typically based on incremental insertion and neighborhood diversification, and the choice of the base graph can hurt scalability. Finally, we discuss open research directions, such as the importance of devising more sophisticated data adaptive seed selection and diversification strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05750v1</guid>
      <category>cs.IR</category>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <category>cs.PF</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ilias Azizi, Karima Echihab, Themis Palpanas, Vassilis Christophides</dc:creator>
    </item>
    <item>
      <title>Scalable Learning of One-Counter Automata via State-Merging Algorithms</title>
      <link>https://arxiv.org/abs/2509.05762</link>
      <description>arXiv:2509.05762v1 Announce Type: cross 
Abstract: We propose One-counter Positive Negative Inference (OPNI), a passive learning algorithm for deterministic real-time one-counter automata (DROCA). Inspired by the RPNI algorithm for regular languages, OPNI constructs a DROCA consistent with any given valid sample set.
  We further present a method for combining OPNI with active learning of DROCA, and provide an implementation of the approach. Our experimental results demonstrate that this approach scales more effectively than existing state-of-the-art algorithms. We also evaluate the performance of the proposed approach for learning visibly one-counter automata.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05762v1</guid>
      <category>cs.FL</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shibashis Guha, Anirban Majumdar, Prince Mathew, A. V. Sreejith</dc:creator>
    </item>
    <item>
      <title>A Simple and Robust Protocol for Distributed Counting</title>
      <link>https://arxiv.org/abs/2509.05870</link>
      <description>arXiv:2509.05870v1 Announce Type: cross 
Abstract: We revisit the distributed counting problem, where a server must continuously approximate the total number of events occurring across $k$ sites while minimizing communication. The communication complexity of this problem is known to be $\Theta(\frac{k}{\epsilon}\log N)$ for deterministic protocols. Huang, Yi, and Zhang (2012) showed that randomization can reduce this to $\Theta(\frac{\sqrt{k}}{\epsilon}\log N)$, but their analysis is restricted to the {\em oblivious setting}, where the stream of events is independent of the protocol's outputs.
  Xiong, Zhu, and Huang (2023) presented a robust protocol for distributed counting that removes the oblivious assumption. However, their communication complexity is suboptimal by a $polylog(k)$ factor and their protocol is substantially more complex than the oblivious protocol of Huang et al. (2012). This left open a natural question: could it be that the simple protocol of Huang et al. (2012) is already robust?
  We resolve this question with two main contributions. First, we show that the protocol of Huang et al. (2012) is itself not robust by constructing an explicit adaptive attack that forces it to lose its accuracy. Second, we present a new, surprisingly simple, robust protocol for distributed counting that achieves the optimal communication complexity of $O(\frac{\sqrt{k}}{\epsilon} \log N)$. Our protocol is simpler than that of Xiong et al. (2023), perhaps even simpler than that of Huang et al. (2012), and is the first to match the optimal oblivious complexity in the adaptive setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05870v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edith Cohen, Moshe Shechner, Uri Stemmer</dc:creator>
    </item>
    <item>
      <title>A General Framework for Low Soundness Homomorphism Testing</title>
      <link>https://arxiv.org/abs/2509.05871</link>
      <description>arXiv:2509.05871v1 Announce Type: cross 
Abstract: We introduce a general framework to design and analyze algorithms for the problem of testing homomorphisms between finite groups in the low-soundness regime.
  In this regime, we give the first constant-query tests for various families of groups. These include tests for: (i) homomorphisms between arbitrary cyclic groups, (ii) homomorphisms between any finite group and $\mathbb{Z}_p$, (iii) automorphisms of dihedral and symmetric groups, (iv) inner automorphisms of non-abelian finite simple groups and extraspecial groups, and (v) testing linear characters of $\mathrm{GL}_n(\mathbb{F}_q)$, and finite-dimensional Lie algebras over $\mathbb{F}_q$. We also recover the result of Kiwi [TCS'03] for testing homomorphisms between $\mathbb{F}_q^n$ and $\mathbb{F}_q$.
  Prior to this work, such tests were only known for abelian groups with a constant maximal order (such as $\mathbb{F}_q^n$). No tests were known for non-abelian groups.
  As an additional corollary, our framework gives combinatorial list decoding bounds for cyclic groups with list size dependence of $O(\varepsilon^{-2})$ (for agreement parameter $\varepsilon$). This improves upon the currently best-known bound of $O(\varepsilon^{-105})$ due to Dinur, Grigorescu, Kopparty, and Sudan [STOC'08], and Guo and Sudan [RANDOM'14].</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05871v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tushant Mittal, Sourya Roy</dc:creator>
    </item>
    <item>
      <title>DISTRIBUTEDANN: Efficient Scaling of a Single DISKANN Graph Across Thousands of Computers</title>
      <link>https://arxiv.org/abs/2509.06046</link>
      <description>arXiv:2509.06046v1 Announce Type: cross 
Abstract: We present DISTRIBUTEDANN, a distributed vector search service that makes it possible to search over a single 50 billion vector graph index spread across over a thousand machines that offers 26ms median query latency and processes over 100,000 queries per second. This is 6x more efficient than existing partitioning and routing strategies that route the vector query to a subset of partitions in a scale out vector search system. DISTRIBUTEDANN is built using two well-understood components: a distributed key-value store and an in-memory ANN index. DISTRIBUTEDANN has replaced conventional scale-out architectures for serving the Bing search engine, and we share our experience from making this transition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06046v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.IR</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Philip Adams, Menghao Li, Shi Zhang, Li Tan, Qi Chen, Mingqin Li, Zengzhong Li, Knut Risvik, Harsha Vardhan Simhadri</dc:creator>
    </item>
    <item>
      <title>Separable convex optimization over indegree polytopes</title>
      <link>https://arxiv.org/abs/2509.06182</link>
      <description>arXiv:2509.06182v1 Announce Type: cross 
Abstract: We study egalitarian (acyclic) orientations of undirected graphs under indegree-based objectives, such as minimizing the $\varphi$-sum of indegrees for a strictly convex function $\varphi$, decreasing minimization (dec-min), and increasing maximization (inc-max). In the non-acyclic setting of Frank and Murota (2022), a single orientation simultaneously optimizes these three objectives, however, restricting to acyclic orientations confines us to the corners of the indegree polytope, where these fairness objectives do diverge. We establish strong hardness results across a broad range of settings: minimizing the $\varphi$-sum of indegrees is NP-hard for every discrete strictly convex function $\varphi$; dec-min and inc-max are NP-hard for every indegree bound $k \geq 2$, as well as without a bound; and the complementary inc-min and dec-max problems are NP-hard even on $3$-regular graphs. On the algorithmic side, we give a polynomial-time algorithm for minimizing the maximum weighted indegree via a weighted smallest-last ordering. We also provide an exact exponential-time algorithm for minimizing general separable discrete convex objectives over indegrees, and a polynomial-time algorithm for the non-acyclic case. Finally, for maximizing the sum of the products of indegrees and outdegrees, we prove NP-hardness on graphs of maximum degree $4$, give an algorithm for maximum degree $3$, and provide a $3$-approximation algorithm. Our results delineate the algorithmic frontier of convex integral optimization over indegree (base-)polytopes, and highlight both theoretical consequences and practical implications, notably for scheduling and deadlock-free routing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06182v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>N\'ora A. Borsik, P\'eter Madarasi</dc:creator>
    </item>
    <item>
      <title>Degree Realization by Bipartite Cactus Graphs</title>
      <link>https://arxiv.org/abs/2509.06194</link>
      <description>arXiv:2509.06194v1 Announce Type: cross 
Abstract: The \textsc{Degree Realization} problem with respect to a graph family $\mathcal{F}$ is defined as follows. The input is a sequence $d$ of $n$ positive integers, and the goal is to decide whether there exists a graph $G \in \mathcal{F}$ whose degrees correspond to $d$. The main challenges are to provide a precise characterization of all the sequences that admit a realization in $\mathcal{F}$ and to design efficient algorithms that construct one of the possible realizations, if one exists.
  This paper studies the problem of realizing degree sequences by bipartite cactus graphs (where the input is given as a single sequence, without the bi-partition). A characterization of the sequences that have a cactus realization is already known [28]. In this paper, we provide a systematic way to obtain such a characterization, accompanied by a realization algorithm. This allows us to derive a characterization for bipartite cactus graphs, and as a byproduct, also for several other interesting sub-families of cactus graphs, including bridge-less cactus graphs and core cactus graphs, as well as for the bipartite sub-families of these families.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.06194v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amotz Bar-Noy, Toni Bohnlein, David Peleg, Yingli Ran, Dror Rawitz</dc:creator>
    </item>
    <item>
      <title>SDPs and Robust Satisfiability of Promise CSP</title>
      <link>https://arxiv.org/abs/2211.08373</link>
      <description>arXiv:2211.08373v5 Announce Type: replace 
Abstract: For a constraint satisfaction problem (CSP), a robust satisfaction algorithm is one that outputs an assignment satisfying most of the constraints on instances that are near-satisfiable. It is known that the CSPs that admit efficient robust satisfaction algorithms are precisely those of bounded width, i.e., CSPs whose satisfiability can be checked by a simple local consistency algorithm (eg., 2-SAT or Horn-SAT in the Boolean case). While the exact satisfiability of a bounded width CSP can be checked by combinatorial algorithms, the robust algorithm is based on rounding a canonical Semidefinite Programming (SDP) relaxation.
  In this work, we initiate the study of robust satisfaction algorithms for promise CSPs, which are a vast generalization of CSPs that have received much attention recently. The motivation is to extend the theory beyond CSPs, as well as to better understand the power of SDPs. We present robust SDP rounding algorithms under some general conditions, namely the existence of particular high-dimensional Boolean symmetries known as majority or alternating threshold polymorphisms. On the hardness front, we prove that the lack of such polymorphisms makes the PCSP hard for all pairs of symmetric Boolean predicates. Our approach relies on SDP integrality gaps argued via the absence of certain colorings of the sphere, with connections to sphere Ramsey theory.
  We conjecture that PCSPs with robust satisfaction algorithms are precisely those for which the feasibility of the canonical SDP implies (exact) satisfiability. We also give a precise algebraic condition, known as a minion characterization, of which PCSPs have the latter property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.08373v5</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joshua Brakensiek, Venkatesan Guruswami, Sai Sandeep</dc:creator>
    </item>
    <item>
      <title>Distance Estimation for High-Dimensional Discrete Distributions</title>
      <link>https://arxiv.org/abs/2308.04264</link>
      <description>arXiv:2308.04264v2 Announce Type: replace 
Abstract: Given two distributions $\mathcal{P}$ and $\mathcal{Q}$ over a high-dimensional domain $\{0,1\}^n$, and a parameter $\varepsilon$, the goal of distance estimation is to determine the statistical distance between $\mathcal{P}$ and $\mathcal{Q}$, up to an additive tolerance $\pm \varepsilon$. Since exponential lower bounds (in $n$) are known for the problem in the standard sampling model, research has focused on richer query models where one can draw conditional samples. This paper presents the first polynomial query distance estimator in the conditional sampling model ($\mathsf{COND}$).
  We base our algorithm on the relatively weaker \textit{subcube conditional} sampling ($\mathsf{SUBCOND}$) oracle, which draws samples from the distribution conditioned on some of the dimensions. $\mathsf{SUBCOND}$ is a promising model for widespread practical use because it captures the natural behavior of discrete samplers. Our algorithm makes $\tilde{\mathcal{O}}(n^3/\varepsilon^5)$ queries to $\mathsf{SUBCOND}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.04264v2</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gunjan Kumar, Kuldeep S. Meel, Yash Pote</dc:creator>
    </item>
    <item>
      <title>Sorting and Selection in Rounds with Adversarial Comparisons</title>
      <link>https://arxiv.org/abs/2310.09483</link>
      <description>arXiv:2310.09483v2 Announce Type: replace 
Abstract: We continue the study of selection and sorting of $n$ numbers under the adversarial comparator model, where comparisons can be adversarially tampered with if the arguments are sufficiently close.
  We derive a randomized sorting algorithm that does $O(n \log^2 n)$ comparisons and gives a correct answer with high probability, addressing an open problem of Ajtai, Feldman, Hassadim, and Nelson [AFHN15]. Our algorithm also implies a selection algorithm that does $O(n \log n)$ comparisons and gives a correct answer with high probability. Both of these results are a $\log$ factor away from the naive lower bound. [AFHN15] shows an $\Omega(n^{1+\varepsilon})$ lower bound for both sorting and selection in the deterministic case, so our results also prove a discrepancy between what is possible with deterministic and randomized algorithms in this setting.
  We also consider both sorting and selection in rounds, exploring the tradeoff between accuracy, number of comparisons, and number of rounds. Using results from sorting networks, we give general algorithms for sorting in $d$ rounds where the number of comparisons increases with $d$ and the accuracy decreases with $d$. Using these algorithms, we derive selection algorithms in $d+O(\log d)$ rounds that use the same number of comparisons as the corresponding sorting algorithm, but have a constant accuracy. Notably, this gives selection algorithms in $d$ rounds that use $n^{1 + o(1)}$ comparisons and have constant accuracy for all $d = \omega(1)$, which still beats the deterministic lower bound of $\Omega(n^{1+\varepsilon})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09483v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chris Trevisan</dc:creator>
    </item>
    <item>
      <title>The Average-Value Allocation Problem</title>
      <link>https://arxiv.org/abs/2407.10401</link>
      <description>arXiv:2407.10401v2 Announce Type: replace 
Abstract: We initiate the study of centralized algorithms for welfare-maximizing allocation of goods to buyers subject to average-value constraints. We show that this problem is NP-hard to approximate beyond a factor of $\frac{e}{e-1}$, and provide a $\frac{4e}{e-1}$-approximate offline algorithm. For the online setting, we show that no non-trivial approximations are achievable under adversarial arrivals. Under i.i.d. arrivals, we present a polytime online algorithm that provides a constant approximation of the optimal (computationally-unbounded) online algorithm. In contrast, we show that no constant approximation of the ex-post optimum is achievable by an online algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10401v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kshipra Bhawalkar, Zhe Feng, Anupam Gupta, Aranyak Mehta, David Wajc, Di Wang</dc:creator>
    </item>
    <item>
      <title>FPT approximations for Capacitated Sum of Radii and Diameters</title>
      <link>https://arxiv.org/abs/2409.04984</link>
      <description>arXiv:2409.04984v2 Announce Type: replace 
Abstract: The Capacitated Sum of Radii problem involves partitioning a set of points $P$, where each point $p\in P$ has capacity $U_p$, into $k$ clusters that minimize the sum of cluster radii, such that the number of points in the cluster centered at point $p$ is at most $U_p$. We begin by showing that the problem is APX-hard, and that under gap-ETH there is no parameterized approximation scheme (FPT-AS). We then construct a $\approx5.83$-approximation algorithm in FPT time (improving a previous $\approx7.61$ approximation in FPT time). Our results also hold when the objective is a general monotone symmetric norm of radii. We also improve the approximation factors for the uniform capacity case, and for the closely related problem of Capacitated Sum of Diameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04984v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnold Filtser, Ameet Gadekar</dc:creator>
    </item>
    <item>
      <title>Resident fitness computation in linear time and other algorithmic aspects of interacting trajectories</title>
      <link>https://arxiv.org/abs/2502.11561</link>
      <description>arXiv:2502.11561v2 Announce Type: replace 
Abstract: The notion of a system of interacting trajectories was recently introduced by Hermann, Gonz\'alez Casanova, Soares dos Santos, T\'obi\'as and Wakolbinger. Such a system of $[0,1]$-valued piecewise linear trajectories arises as a scaling limit of the system of logarithmic subpopulation sizes in a population-genetic model (more precisely, a Moran model) with mutation and selection. By definition, the resident fitness is initially 0 and afterwards it increases by the ultimate slope of each trajectory that reaches height 1.
  We show that although the interaction of $n$ trajectories may yield $\Omega(n^2)$ slope changes in total, the resident fitness function can be computed algorithmically in $O(n)$ time. Our algorithm uses the so-called continued lines representation of the system of interacting trajectories. In the special case of Poissonian interacting trajectories where the birth times of the trajectories form a Poisson process and the initial slopes are random and i.i.d., we provide a linear bound on the expected total number of slope changes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11561v2</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Katalin Friedl, Vikt\'oria Nemkin, Andr\'as T\'obi\'as</dc:creator>
    </item>
    <item>
      <title>With a Little Help From My Friends: Exploiting Probability Distribution Advice in Algorithm Design</title>
      <link>https://arxiv.org/abs/2505.04949</link>
      <description>arXiv:2505.04949v2 Announce Type: replace 
Abstract: We study online algorithms with predictions using distributional advice, a type of prediction that arises when leveraging expert knowledge or historical data. To demonstrate the usefulness and versatility of this framework, we focus on the fundamental problem of online metric matching, considering both the fractional and integral variants. Our main positive result is, for the former, an algorithm achieving the optimal cost under perfect advice, while smoothly defaulting to competitive ratios comparable to advice-free algorithms as the prediction's quality degrades. For the integral matching, we are able to provide an algorithm with essentially the same guarantees, up to an additive sublinear term. We conclude by discussing how our algorithmic framework can be extended to other online optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04949v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Cl\'ement L. Canonne, Kenny Chen, Juli\'an Mestre</dc:creator>
    </item>
    <item>
      <title>Improved sampling algorithms and Poincar\'e inequalities for non-log-concave distributions</title>
      <link>https://arxiv.org/abs/2507.11236</link>
      <description>arXiv:2507.11236v3 Announce Type: replace 
Abstract: We study the problem of sampling from a distribution $\mu$ with density $\propto e^{-V}$ for some potential function $V:\mathbb R^d\to \mathbb R$ with query access to $V$ and $\nabla V$. We start with the following standard assumptions:
  (1) The potential function $V$ is $L$-smooth.
  (2) The second moment $\mathbf{E}_{X\sim \mu}[\|X\|^2]\leq M$.
  Recently, He and Zhang (COLT'25) showed that the query complexity of sampling from such distributions is at least $\left(\frac{LM}{d\epsilon}\right)^{\Omega(d)}$ where $\epsilon$ is the desired accuracy in total variation distance, and the Poincar\'e constant can be arbitrarily large.
  Meanwhile, another common assumption in the study of diffusion based samplers (see e.g., the work of Chen, Chewi, Li, Li, Salim and Zhang (ICLR'23)) strengthens the smoothness condition (1) to the following:
  (1*) The potential function of *every* distribution along the Ornstein-Uhlenbeck process starting from $\mu$ is $L$-smooth.
  We show that under the assumptions (1*) and (2), the query complexity of sampling from $\mu$ can be $\mathrm{poly}(L,d)\cdot \left(\frac{Ld+M}{\epsilon^2}\right)^{\mathcal{O}(L+1)}$, which is polynomial in $d$ and $\frac{1}{\epsilon}$ when $L=\mathcal{O}(1)$ and $M=\mathrm{poly}(d)$. This improves the algorithm with quasi-polynomial query complexity developed by Huang et al. (COLT'24). Our results imply that the seemly moderate strengthening of the smoothness condition (1) to (1*) can lead to an exponential gap in the query complexity of sampling algorithms.
  Moreover, we show that together with the assumption (1*) and the stronger moment assumption that $\|X\|$ is $\lambda$-sub-Gaussian for $X\sim\mu$, the Poincar\'e constant of $\mu$ is at most $\mathcal{O}(\lambda)^{2(L+1)}$. As an application of our technique, we obtain improved estimate of the Poincar\'e constant for mixture of Gaussians with the same covariance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11236v3</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen He, Zhehan Lei, Jianan Shao, Chihao Zhang</dc:creator>
    </item>
    <item>
      <title>Strong Linearizability without Compare&amp;Swap: The Case of Bags</title>
      <link>https://arxiv.org/abs/2411.19365</link>
      <description>arXiv:2411.19365v2 Announce Type: replace-cross 
Abstract: Because strongly-linearizable objects provide stronger guarantees than linearizability, they serve as valuable building blocks for the design of concurrent data structures. Yet, many objects that have linearizable implementations from base objects weaker than compare&amp;swap objects do not have strongly-linearizable implementations from the same base objects. We focus on one such object: the bag, a multiset from which processes can take unspecified elements.
  We present the first lock-free, strongly-linearizable implementation of a bag from interfering objects (specifically, registers, and test&amp;set objects). This may be surprising, since there are provably no such implementations of stacks or queues.
  Since a bag can contain arbitrarily many elements, an unbounded amount of space must be used to implement it. Hence, it makes sense to also consider a bag with a bound on its capacity. However, like stacks and queues, a bag with capacity $b$ shared by more than $2b$ processes has no lock-free, strongly-linearizable implementation from interfering objects. If we further restrict a bounded bag so that only one process can insert into it, we are able to obtain a lock-free, strongly-linearizable implementation from $O(b + n)$ interfering objects, where $n$ is the number of processes.
  Our goal is to understand the circumstances under which strongly-linearizable implementations of bags exist and, more generally, to understand the power of interfering objects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19365v2</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.DISC.2025.22</arxiv:DOI>
      <dc:creator>Faith Ellen, Gal Sela</dc:creator>
    </item>
    <item>
      <title>Unweighted One-Sided Code Sparsifiers and Thin Subgraphs</title>
      <link>https://arxiv.org/abs/2502.02799</link>
      <description>arXiv:2502.02799v2 Announce Type: replace-cross 
Abstract: For a linear code $\mathcal{C} \subseteq \mathbb{F}_2^n$ and $\alpha \in [0,1]$, call a set $S \subseteq [n]$ an (unweighted) one-sided $\alpha$-sparsifier of $\mathcal{C}$ if for all $c \in \mathcal{C}$, $\mathrm{wt}(c_S)\geq \alpha \cdot \mathrm{wt}(c)$, where $c_S$ is the projection of $c$ onto the coordinates in $S$ and $\mathrm{wt}(c)$ is the Hamming weight of $c$. \\ We show that every $k$-dimensional linear code $\mathcal{C}\subseteq \mathbb{F}_2^n$ has at least $2^{n - k}$ many unweighted one-sided $1/2$-sparsifiers and hence one of size at most $n/2 + O(\sqrt{n k})$. As an application, letting $\mathcal{C} \subseteq \mathbb{F}_2^E$ denote the cut-space of a graph $G=(V, E)$, we show a lower bound of $2^{\lvert E \rvert- (\lvert V \rvert - 1)}$ on the number of $1/2$-thin subgraphs of $G$ and the existence of a $1/2$-thin subgraph with at least $\lvert E \rvert /2-O(\sqrt{\lvert E \rvert \cdot \lvert V \rvert})$ edges. In contrast to previous results on thin subgraphs, our proofs are purely "combinatorial".</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02799v2</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shayan Oveis Gharan, Arvin Sahami</dc:creator>
    </item>
    <item>
      <title>Solving Modular Linear Systems with a Constraint by parallel decomposition of the Smith form and extended Euclidean division modulo powers of primes divisors</title>
      <link>https://arxiv.org/abs/2503.10158</link>
      <description>arXiv:2503.10158v4 Announce Type: replace-cross 
Abstract: Integral linear systems $Ax=b$ with matrices $A$, $b$ and solutions $x$ are also required to be in integers, can be solved using invariant factors of $A$ (by computing the Smith Canonical Form of $A$). This paper explores a new problem which arises in applications, that of obtaining conditions for solving the Modular Linear System $Ax=b\rem n$ given $A,b$ in $\zz_n$ for $x$ in $\zz_n$ along with the constraint that the value of the linear function $\phi(x)=\la w,x\ra$ is coprime to $n$ for some solution $x$. In this paper we develop decomposition of the system to coprime moduli $p^{r(p)}$ which are divisors of $n$ and show how such a decomposition simplifies the computation of Smith form. This extends the well known index calculus method of computing the discrete logarithm where the moduli over which the linear system is reduced were assumed to be prime (to solve the reduced systems over prime fields) to the case when the factors of the modulus are prime powers $p^{r(p)}$. It is shown how this problem can be addressed effciently using the invariant factors and Smith form of the augmented matrix $[A,-p^{r(p)}I]$ and conditions modulo $p$ satisfied by $w$, where $p^{r(p)}$ vary over all divisors of $n$ with $p$ prime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10158v4</guid>
      <category>math.NT</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Virendra Sule</dc:creator>
    </item>
    <item>
      <title>Dynamic Approximate Maximum Matching in the Distributed Vertex Partition Model</title>
      <link>https://arxiv.org/abs/2504.17338</link>
      <description>arXiv:2504.17338v2 Announce Type: replace-cross 
Abstract: We initiate the study of approximate maximum matching in the vertex partition model, for graphs subject to dynamic changes. We assume that the $n$ vertices of the graph are partitioned among $k$ players, who execute a distributed algorithm and communicate via message passing. An adaptive adversary may perform dynamic updates to the graph topology by inserting or removing edges between the nodes, and the algorithm needs to respond to these changes by adapting the output of the players, with the goal of maintaining an approximate maximum matching. The main performance metric in this setting is the algorithm's update time, which corresponds to the number of rounds required for updating the solution upon an adversarial change. For the standard setting of single-edge insertions and deletions, we obtain the following results:
  We give a randomized Las Vegas algorithm with an expected update time of $O( \frac{\sqrt{m}}{\beta k} )$ rounds that maintains a $\frac{2}{3}$-approximate maximum matching that is also maximal, where $m$ is the number of edges of the graph. We also show that any algorithm has a worst case update time of $\Omega( \frac{n}{\beta k^2\log n} )$, assuming a link bandwidth of $O(\beta\log n)$ bits per round, if it maintains a matching that is maximal and does not have any 3-augmenting paths. For batch-dynamic updates, where the adversary may modify up to $\ell\ge 1$ edges at once, we prove the following: There is a randomized algorithm that succeeds with high probability in maintaining a $\frac{2}{3}$-approximate maximum matching and has a worst case update time of $\Omega( \frac{\ell\log n}{\sqrt{\beta k}} )$ rounds. We show that $\Omega( \frac{\ell}{\beta k \log n} )$ poses a lower bound for maintaining a maximal matching without 3-augmenting paths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17338v2</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Robinson, Xianbin Zhu</dc:creator>
    </item>
    <item>
      <title>Quasi-optimal hierarchically semi-separable matrix approximation</title>
      <link>https://arxiv.org/abs/2505.16937</link>
      <description>arXiv:2505.16937v2 Announce Type: replace-cross 
Abstract: We present a randomized algorithm for producing a quasi-optimal hierarchically semi-separable (HSS) approximation to an $N\times N$ matrix $A$ using only matrix-vector products with $A$ and $A^T$. We prove that, using $O(k \log(N/k))$ matrix-vector products and ${O}(N k^2 \log(N/k))$ additional runtime, the algorithm returns an HSS matrix $B$ with rank-$k$ blocks whose expected Frobenius norm error $\mathbb{E}[\|A - B\|_F^2]$ is at most $O(\log(N/k))$ times worse than the best possible approximation error by an HSS rank-$k$ matrix. In fact, the algorithm we analyze in a simple modification of an empirically effective method proposed by [Levitt &amp; Martinsson, SISC 2024]. As a stepping stone towards our main result, we prove two results that are of independent interest: a similar guarantee for a variant of the algorithm which accesses $A$'s entries directly, and explicit error bounds for near-optimal subspace approximation using projection-cost-preserving sketches. To the best of our knowledge, our analysis constitutes the first polynomial-time quasi-optimality result for HSS matrix approximation, both in the explicit access model and the matrix-vector product query model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16937v2</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noah Amsel, Tyler Chen, Feyza Duman Keles, Diana Halikias, Cameron Musco, Christopher Musco, David Persson</dc:creator>
    </item>
    <item>
      <title>Grassroots Consensus</title>
      <link>https://arxiv.org/abs/2505.19216</link>
      <description>arXiv:2505.19216v3 Announce Type: replace-cross 
Abstract: Consider people with smartphones operating without external authorities or global resources other than the network itself. In this setting, high-end applications supporting sovereign democratic digital communities, community banks, and digital cooperatives require consensus executed by community members, which must be reconfigurable to support community dynamics.
  The Constitutional Consensus protocol aims to address this need by introducing constitutional self-governance to consensus: participants dynamically amend the participant set, supermajority threshold, and timeout parameter through the consensus protocol itself. We achieve this by enhancing a DAG-based protocol (like Cordial Miners) with participant-controlled reconfiguration, while also supporting both high- and low-throughput operation (like Morpheus), remaining quiescent when idle. This three-way synthesis uniquely combines: (1) constitutional amendments for self-governance, (2) a cryptographic DAG structure for simplicity, parallelism, and throughput, and (3) both high- and low-throughput operation. The protocol achieves consensus in $3\delta$, maintains O(n) amortized communication complexity during high throughput, and seamlessly transitions between modes. The basic protocol (without constitutional amendments) realizes these features in 25 lines of pseudocode, making it one of the most concise consensus protocols for eventual synchrony.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19216v3</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Idit Keidar, Andrew Lewis-Pye, Ehud Shapiro</dc:creator>
    </item>
    <item>
      <title>Constructive l2-Discrepancy Minimization with Additive Deviations</title>
      <link>https://arxiv.org/abs/2508.21423</link>
      <description>arXiv:2508.21423v2 Announce Type: replace-cross 
Abstract: The \emph{signed series} problem in the $\ell_2$ norm asks, given set of vectors $v_1,\ldots,v_n\in \mathbf{R}^d$ having at most unit $\ell_2$ norm, does there always exist a series $(\varepsilon_i)_{i\in [n]}$ of $\pm 1$ signs such that for all $i\in [n]$, $\max_{i\in [n]} \|\sum_{j=1}^i \varepsilon_i v_i\|_2 = O(\sqrt{d})$. A result of Banaszczyk [2012, \emph{Rand. Struct. Alg.}] states that there exist signs $\varepsilon_i\in \{-1,1\},\; i\in [n]$ such that $\max_{i\in [n]} \|\sum_{j=1}^i \varepsilon_i v_i\|_2 = O(\sqrt{d+\log n})$. The best constructive bound known so far is of $O(\sqrt{d\log n})$, by Bansal and Garg [2017, \emph{STOC.}, 2019, \emph{SIAM J. Comput.}]. We give a polynomial-time randomized algorithm to find signs $x(i) \in \{-1,1\},\; i\in [n]$ such that \[ \max_{i\in [n]} \|\sum_{j=1}^i x(i)v_i\|_2 = O(\sqrt{d + \log^2 n}) = O(\sqrt{d}+\log n).\] By the constructive reduction of Harvey and Samadi [\emph{COLT}, 2014], this also yields a constructive bound of $O(\sqrt{d}+\log n)$ for the Steinitz problem in the $\ell_2$-norm. Thus, we algorithmically achieve Banaszczyk's bounds for both problems when $d \geq \log^2n$, which also matches the conjectured bounds. Our algorithm is based on the framework on Bansal and Garg, together with a new analysis involving $(i)$ additional linear and spectral orthogonality constraints during the construction of the covariance matrix of the random walk steps, which allow us to control the quadratic variation in the linear as well as the quadratic components of the discrepancy increment vector, alongwith $(ii)$ a ``Freedman-like" version of the Hanson-Wright concentration inequality, for filtration-dependent sums of subgaussian chaoses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21423v2</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Tue, 09 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kunal Dutta</dc:creator>
    </item>
  </channel>
</rss>
