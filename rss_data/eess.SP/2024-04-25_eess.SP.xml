<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Apr 2024 19:12:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 25 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Security-Sensitive Task Offloading in Integrated Satellite-Terrestrial Networks</title>
      <link>https://arxiv.org/abs/2404.15278</link>
      <description>arXiv:2404.15278v1 Announce Type: new 
Abstract: With the rapid development of sixth-generation (6G) communication technology, global communication networks are moving towards the goal of comprehensive and seamless coverage. In particular, low earth orbit (LEO) satellites have become a critical component of satellite communication networks. The emergence of LEO satellites has brought about new computational resources known as the \textit{LEO satellite edge}, enabling ground users (GU) to offload computing tasks to the resource-rich LEO satellite edge. However, existing LEO satellite computational offloading solutions primarily focus on optimizing system performance, neglecting the potential issue of malicious satellite attacks during task offloading. In this paper, we propose the deployment of LEO satellite edge in an integrated satellite-terrestrial networks (ISTN) structure to support \textit{security-sensitive computing task offloading}. We model the task allocation and offloading order problem as a joint optimization problem to minimize task offloading delay, energy consumption, and the number of attacks while satisfying reliability constraints. To achieve this objective, we model the task offloading process as a Markov decision process (MDP) and propose a security-sensitive task offloading strategy optimization algorithm based on proximal policy optimization (PPO). Experimental results demonstrate that our algorithm significantly outperforms other benchmark methods in terms of performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15278v1</guid>
      <category>eess.SP</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjun Lan, Kongyang Chen, Jiannong Cao, Yikai Li, Ning Li, Qi Chen, Yuvraj Sahni</dc:creator>
    </item>
    <item>
      <title>Jointly Modeling Spatio-Temporal Features of Tactile Signals for Action Classification</title>
      <link>https://arxiv.org/abs/2404.15279</link>
      <description>arXiv:2404.15279v1 Announce Type: new 
Abstract: Tactile signals collected by wearable electronics are essential in modeling and understanding human behavior. One of the main applications of tactile signals is action classification, especially in healthcare and robotics. However, existing tactile classification methods fail to capture the spatial and temporal features of tactile signals simultaneously, which results in sub-optimal performances. In this paper, we design Spatio-Temporal Aware tactility Transformer (STAT) to utilize continuous tactile signals for action classification. We propose spatial and temporal embeddings along with a new temporal pretraining task in our model, which aims to enhance the transformer in modeling the spatio-temporal features of tactile signals. Specially, the designed temporal pretraining task is to differentiate the time order of tubelet inputs to model the temporal properties explicitly. Experimental results on a public action classification dataset demonstrate that our model outperforms state-of-the-art methods in all metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15279v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jimmy Lin, Junkai Li, Jiasi Gao, Weizhi Ma, Yang Liu</dc:creator>
    </item>
    <item>
      <title>Global 4D Ionospheric STEC Prediction based on DeepONet for GNSS Rays</title>
      <link>https://arxiv.org/abs/2404.15284</link>
      <description>arXiv:2404.15284v1 Announce Type: new 
Abstract: The ionosphere is a vitally dynamic charged particle region in the Earth's upper atmosphere, playing a crucial role in applications such as radio communication and satellite navigation. The Slant Total Electron Contents (STEC) is an important parameter for characterizing wave propagation, representing the integrated electron density along the ray of radio signals passing through the ionosphere. The accurate prediction of STEC is essential for mitigating the ionospheric impact particularly on Global Navigation Satellite Systems (GNSS). In this work, we propose a high-precision STEC prediction model named DeepONet-STEC, which learns nonlinear operators to predict the 4D temporal-spatial integrated parameter for specified ground station - satellite ray path globally. As a demonstration, we validate the performance of the model based on GNSS observation data for global and US-CORS regimes under ionospheric quiet and storm conditions. The DeepONet-STEC model results show that the three-day 72 hour prediction in quiet periods could achieve high accuracy using observation data by the Precise Point Positioning (PPP) with temporal resolution 30s. Under active solar magnetic storm periods, the DeepONet-STEC also demonstrated its robustness and superiority than traditional deep learning methods. This work presents a neural operator regression architecture for predicting the 4D temporal-spatial ionospheric parameter for satellite navigation system performance, which may be further extended for various space applications and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15284v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dijia Cai, Zenghui Shi, Haiyang Fu, Huan Liu, Hongyi Qian, Yun Sui, Feng Xu, Ya-Qiu Jin</dc:creator>
    </item>
    <item>
      <title>EEGDiR: Electroencephalogram denoising network for temporal information storage and global modeling through Retentive Network</title>
      <link>https://arxiv.org/abs/2404.15289</link>
      <description>arXiv:2404.15289v1 Announce Type: new 
Abstract: Electroencephalogram (EEG) signals play a pivotal role in clinical medicine, brain research, and neurological disease studies. However, susceptibility to various physiological and environmental artifacts introduces noise in recorded EEG data, impeding accurate analysis of underlying brain activity. Denoising techniques are crucial to mitigate this challenge. Recent advancements in deep learningbased approaches exhibit substantial potential for enhancing the signal-to-noise ratio of EEG data compared to traditional methods. In the realm of large-scale language models (LLMs), the Retentive Network (Retnet) infrastructure, prevalent for some models, demonstrates robust feature extraction and global modeling capabilities. Recognizing the temporal similarities between EEG signals and natural language, we introduce the Retnet from natural language processing to EEG denoising. This integration presents a novel approach to EEG denoising, opening avenues for a profound understanding of brain activities and accurate diagnosis of neurological diseases. Nonetheless, direct application of Retnet to EEG denoising is unfeasible due to the one-dimensional nature of EEG signals, while natural language processing deals with two-dimensional data. To facilitate Retnet application to EEG denoising, we propose the signal embedding method, transforming one-dimensional EEG signals into two dimensions for use as network inputs. Experimental results validate the substantial improvement in denoising effectiveness achieved by the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15289v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Wang, Fei Deng, Peifan Jiang</dc:creator>
    </item>
    <item>
      <title>A point cloud processing method of mmWave radar over automotive scenario</title>
      <link>https://arxiv.org/abs/2404.15290</link>
      <description>arXiv:2404.15290v1 Announce Type: new 
Abstract: This paper introduces in detail the effective method of comprehensive target judgment by using radar RA map and point cloud map. Different output of radar can effectively judge the road boundary of target and the relative coordinates of target, avoid the error of output caused by excessive processing information, and greatly improve the processing efficiency of DBSCAN of the measured target.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15290v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qingmian Wan, Hongli Peng, Xing Liao, Kuayue Liu</dc:creator>
    </item>
    <item>
      <title>Multi-objective Optimization for Multi-UAV-assisted Mobile Edge Computing</title>
      <link>https://arxiv.org/abs/2404.15292</link>
      <description>arXiv:2404.15292v1 Announce Type: new 
Abstract: Recent developments in unmanned aerial vehicles (UAVs) and mobile edge computing (MEC) have provided users with flexible and resilient computing services. However, meeting the computing-intensive and latency-sensitive demands of users poses a significant challenge due to the limited resources of UAVs. To address this challenge, we present a multi-objective optimization approach for multi-UAV-assisted MEC systems. First, we formulate a multi-objective optimization problem \textcolor{b2}{aiming} at minimizing the total task completion delay, reducing the total UAV energy consumption, and maximizing the total amount of offloaded tasks by jointly optimizing task offloading, computation resource allocation, and UAV trajectory control. Since the problem is a mixed-integer non-linear programming (MINLP) and NP-hard problem which is challenging, we propose a joint task offloading, computation resource allocation, and UAV trajectory control (JTORATC) approach to solve the problem. \textcolor{b3}{However, since the decision variables of task offloading, computation resource allocation, and UAV trajectory control are coupled with each other, the original problem is split into three sub-problems, i.e., task offloading, computation resource allocation, and UAV trajectory control, which are solved individually to obtain the corresponding decisions.} \textcolor{b2}{Moreover, the sub-problem of task offloading is solved by using distributed splitting and threshold rounding methods, the sub-problem of computation resource allocation is solved by adopting the Karush-Kuhn-Tucker (KKT) method, and the sub-problem of UAV trajectory control is solved by employing the successive convex approximation (SCA) method.} Simulation results show that the proposed JTORATC has superior performance compared to the other benchmark methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15292v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geng Sun, Yixian Wang, Zemin Sun, Qingqing Wu, Jiawen Kang, Dusit Niyato, Victor C. M. Leung</dc:creator>
    </item>
    <item>
      <title>Multimodal Physical Fitness Monitoring (PFM) Framework Based on TimeMAE-PFM in Wearable Scenarios</title>
      <link>https://arxiv.org/abs/2404.15294</link>
      <description>arXiv:2404.15294v1 Announce Type: new 
Abstract: Physical function monitoring (PFM) plays a crucial role in healthcare especially for the elderly. Traditional assessment methods such as the Short Physical Performance Battery (SPPB) have failed to capture the full dynamic characteristics of physical function. Wearable sensors such as smart wristbands offer a promising solution to this issue. However, challenges exist, such as the computational complexity of machine learning methods and inadequate information capture. This paper proposes a multi-modal PFM framework based on an improved TimeMAE, which compresses time-series data into a low-dimensional latent space and integrates a self-enhanced attention module. This framework achieves effective monitoring of physical health, providing a solution for real-time and personalized assessment. The method is validated using the NHATS dataset, and the results demonstrate an accuracy of 70.6% and an AUC of 82.20%, surpassing other state-of-the-art time-series classification models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15294v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junjie Zhang, Zheming Zhang, Huachen Xiang, Yangquan Tan, Linnan Huo, Fengyi Wang</dc:creator>
    </item>
    <item>
      <title>Multi-stream Transmission for Directional Modulation Network via distributed Multi-UAV-aided Multi-IRS</title>
      <link>https://arxiv.org/abs/2404.15297</link>
      <description>arXiv:2404.15297v1 Announce Type: new 
Abstract: Active intelligent reflecting surface (IRS) is a revolutionary technique for the future 6G networks. The conventional far-field single-IRS-aided directional modulation(DM) networks have only one (no direct path) or two (existing direct path) degrees of freedom (DoFs). This means that there are only one or two streams transmitted simultaneously from base station to user and will seriously limit its rate gain achieved by IRS. How to create multiple DoFs more than two for DM? In this paper, single large-scale IRS is divided to multiple small IRSs and a novel multi-IRS-aided multi-stream DM network is proposed to achieve a point-to-point multi-stream transmission by creating $K$ ($\geq3$) DoFs, where multiple small IRSs are placed distributively via multiple unmanned aerial vehicles (UAVs). The null-space projection, zero-forcing (ZF) and phase alignment are adopted to design the transmit beamforming vector, receive beamforming vector and phase shift matrix (PSM), respectively, called NSP-ZF-PA. Here, $K$ PSMs and their corresponding beamforming vectors are independently optimized. The weighted minimum mean-square error (WMMSE) algorithm is involved in alternating iteration for the optimization variables by introducing the power constraint on IRS, named WMMSE-PC, where the majorization-minimization (MM) algorithm is used to solve the total PSM. To achieve a lower computational complexity, a maximum trace method, called Max-TR-SVD, is proposed by optimize the PSM of all IRSs. Numerical simulation results has shown that the proposed NSP-ZF-PA performs much better than Max-TR-SVD in terms of rate. In particular, the rate of NSP-ZF-PA with sixteen small IRSs is about five times that of NSP-ZF-PA with combining all small IRSs as a single large IRS. Thus, a dramatic rate enhancement may be achieved by multiple distributed IRSs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15297v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ke Yang, Rongen Dong, Feng Shu, Weiping Shi, Yan Wang, Xuehui Wang</dc:creator>
    </item>
    <item>
      <title>Robust Phase Retrieval by Alternating Minimization</title>
      <link>https://arxiv.org/abs/2404.15302</link>
      <description>arXiv:2404.15302v1 Announce Type: new 
Abstract: We consider a least absolute deviation (LAD) approach to the robust phase retrieval problem that aims to recover a signal from its absolute measurements corrupted with sparse noise. To solve the resulting non-convex optimization problem, we propose a robust alternating minimization (Robust-AM) derived as an unconstrained Gauss-Newton method. To solve the inner optimization arising in each step of Robust-AM, we adopt two computationally efficient methods for linear programs. We provide a non-asymptotic convergence analysis of these practical algorithms for Robust-AM under the standard Gaussian measurement assumption. These algorithms, when suitably initialized, are guaranteed to converge linearly to the ground truth at an order-optimal sample complexity with high probability while the support of sparse noise is arbitrarily fixed and the sparsity level is no larger than $1/4$. Additionally, through comprehensive numerical experiments on synthetic and image datasets, we show that Robust-AM outperforms existing methods for robust phase retrieval offering comparable theoretical performance</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15302v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seonho Kim, Kiryung Lee</dc:creator>
    </item>
    <item>
      <title>ADAPT^2: Adapting Pre-Trained Sensing Models to End-Users via Self-Supervision Replay</title>
      <link>https://arxiv.org/abs/2404.15305</link>
      <description>arXiv:2404.15305v1 Announce Type: new 
Abstract: Self-supervised learning has emerged as a method for utilizing massive unlabeled data for pre-training models, providing an effective feature extractor for various mobile sensing applications. However, when deployed to end-users, these models encounter significant domain shifts attributed to user diversity. We investigate the performance degradation that occurs when self-supervised models are fine-tuned in heterogeneous domains. To address the issue, we propose ADAPT^2, a few-shot domain adaptation framework for personalizing self-supervised models. ADAPT2 proposes self-supervised meta-learning for initial model pre-training, followed by a user-side model adaptation by replaying the self-supervision with user-specific data. This allows models to adjust their pre-trained representations to the user with only a few samples. Evaluation with four benchmarks demonstrates that ADAPT^2 outperforms existing baselines by an average F1-score of 8.8%p. Our on-device computational overhead analysis on a commodity off-the-shelf (COTS) smartphone shows that ADAPT2 completes adaptation within an unobtrusive latency (in three minutes) with only a 9.54% memory consumption, demonstrating the computational efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15305v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Hyungjun Yoon, Jaehyun Kwak, Biniyam Aschalew Tolera, Gaole Dai, Mo Li, Taesik Gong, Kimin Lee, Sung-Ju Lee</dc:creator>
    </item>
    <item>
      <title>DCAE-SR: Design of a Denoising Convolutional Autoencoder for reconstructing Electrocardiograms signals at Super Resolution</title>
      <link>https://arxiv.org/abs/2404.15307</link>
      <description>arXiv:2404.15307v1 Announce Type: new 
Abstract: Electrocardiogram (ECG) signals play a pivotal role in cardiovascular diagnostics, providing essential information on the electrical activity of the heart. However, the inherent noise and limited resolution in ECG recordings can hinder accurate interpretation and diagnosis. In this paper, we propose a novel model for ECG super resolution (SR) that uses a DNAE to enhance temporal and frequency information inside ECG signals. Our approach addresses the limitations of traditional ECG signal processing techniques. Our model takes in input 5-second length ECG windows sampled at 50 Hz (very low resolution) and it is able to reconstruct a denoised super-resolution signal with an x10 upsampling rate (sampled at 500 Hz). We trained the proposed DCAE-SR on public available myocardial infraction ECG signals. Our method demonstrates superior performance in reconstructing high-resolution ECG signals from very low-resolution signals with a sampling rate of 50 Hz. We compared our results with the current deep-learning literature approaches for ECG super-resolution and some non-deep learning reproducible methods that can perform both super-resolution and denoising. We obtained current state-of-the-art performances in super-resolution of very low resolution ECG signals frequently corrupted by ECG artifacts. We were able to obtain a signal-to-noise ratio of 12.20 dB (outperforms previous 4.68 dB), mean squared error of 0.0044 (outperforms previous 0.0154) and root mean squared error of 4.86% (outperforms previous 12.40%). In conclusion, our DCAE-SR model offers a robust (to artefact presence), versatile and explainable solution to enhance the quality of ECG signals. This advancement holds promise in advancing the field of cardiovascular diagnostics, paving the way for improved patient care and high-quality clinical decisions</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15307v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ugo Lomoio, Pierangelo Veltri, Pietro Hiram Guzzi, Pietro Lio'</dc:creator>
    </item>
    <item>
      <title>Label-Efficient Sleep Staging Using Transformers Pre-trained with Position Prediction</title>
      <link>https://arxiv.org/abs/2404.15308</link>
      <description>arXiv:2404.15308v1 Announce Type: new 
Abstract: Sleep staging is a clinically important task for diagnosing various sleep disorders, but remains challenging to deploy at scale because it because it is both labor-intensive and time-consuming. Supervised deep learning-based approaches can automate sleep staging but at the expense of large labeled datasets, which can be unfeasible to procure for various settings, e.g., uncommon sleep disorders. While self-supervised learning (SSL) can mitigate this need, recent studies on SSL for sleep staging have shown performance gains saturate after training with labeled data from only tens of subjects, hence are unable to match peak performance attained with larger datasets. We hypothesize that the rapid saturation stems from applying a sub-optimal pretraining scheme that pretrains only a portion of the architecture, i.e., the feature encoder, but not the temporal encoder; therefore, we propose adopting an architecture that seamlessly couples the feature and temporal encoding and a suitable pretraining scheme that pretrains the entire model. On a sample sleep staging dataset, we find that the proposed scheme offers performance gains that do not saturate with amount of labeled training data (e.g., 3-5\% improvement in balanced sleep staging accuracy across low- to high-labeled data settings), reducing the amount of labeled training data needed for high performance (e.g., by 800 subjects). Based on our findings, we recommend adopting this SSL paradigm for subsequent work on SSL for sleep staging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15308v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sayeri Lala, Hanlin Goh, Christopher Sandino</dc:creator>
    </item>
    <item>
      <title>Sparse Bayesian Correntropy Learning for Robust Muscle Activity Reconstruction from Noisy Brain Recordings</title>
      <link>https://arxiv.org/abs/2404.15309</link>
      <description>arXiv:2404.15309v1 Announce Type: new 
Abstract: Sparse Bayesian learning has promoted many effective frameworks for brain activity decoding, especially for the reconstruction of muscle activity. However, existing sparse Bayesian learning mainly employs Gaussian distribution as error assumption in the reconstruction task, which is not necessarily the truth in the real-world application. On the other hand, brain recording is known to be highly noisy and contains many non-Gaussian noises, which could lead to significant performance degradation for sparse Bayesian learning method. The goal of this paper is to propose a new robust implementation for sparse Bayesian learning, so that robustness and sparseness can be realized simultaneously. Motivated by the great robustness of maximum correntropy criterion (MCC), we proposed an integration of MCC into the sparse Bayesian learning regime. To be specific, we derived the explicit error assumption inherent in the MCC and then leveraged it for the likelihood function. Meanwhile, we used the automatic relevance determination (ARD) technique for the sparse prior distribution. To fully evaluate the proposed method, a synthetic dataset and a real-world muscle activity reconstruction task with two different brain modalities were employed. Experimental results showed that our proposed sparse Bayesian correntropy learning framework improves significantly the robustness in a noisy regression task. The proposed method can realize higher correlation coefficient and lower root mean squared error in the real-world muscle activity reconstruction tasks. Sparse Bayesian correntropy learning provides a powerful tool for neural decoding which can promote the development of brain-computer interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15309v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuanhao Li, Badong Chen, Natsue Yoshimura, Yasuharu Koike, Okito Yamashita</dc:creator>
    </item>
    <item>
      <title>Fusing Pretrained ViTs with TCNet for Enhanced EEG Regression</title>
      <link>https://arxiv.org/abs/2404.15311</link>
      <description>arXiv:2404.15311v1 Announce Type: new 
Abstract: The task of Electroencephalogram (EEG) analysis is paramount to the development of Brain-Computer Interfaces (BCIs). However, to reach the goal of developing robust, useful BCIs depends heavily on the speed and the accuracy at which BCIs can understand neural dynamics. In response to that goal, this paper details the integration of pre-trained Vision Transformers (ViTs) with Temporal Convolutional Networks (TCNet) to enhance the precision of EEG regression. The core of this approach lies in harnessing the sequential data processing strengths of ViTs along with the superior feature extraction capabilities of TCNet, to significantly improve EEG analysis accuracy. In addition, we analyze the importance of how to construct optimal patches for the attention mechanism to analyze, balancing both speed and accuracy tradeoffs. Our results showcase a substantial improvement in regression accuracy, as evidenced by the reduction of Root Mean Square Error (RMSE) from 55.4 to 51.8 on EEGEyeNet's Absolute Position Task, outperforming existing state-of-the-art models. Without sacrificing performance, we increase the speed of this model by an order of magnitude (up to 4.32x faster). This breakthrough not only sets a new benchmark in EEG regression analysis but also opens new avenues for future research in the integration of transformer architectures with specialized feature extraction methods for diverse EEG datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15311v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Modesitt, Haicheng Yin, Williams Huang Wang, Brian Lu</dc:creator>
    </item>
    <item>
      <title>Realtime Person Identification via Gait Analysis</title>
      <link>https://arxiv.org/abs/2404.15312</link>
      <description>arXiv:2404.15312v1 Announce Type: new 
Abstract: Each person has a unique gait, i.e., walking style, that can be used as a biometric for personal identification. Recent works have demonstrated effective gait recognition using deep neural networks, however most of these works predominantly focus on classification accuracy rather than model efficiency. In order to perform gait recognition using wearable devices on the edge, it is imperative to develop highly efficient low-power models that can be deployed on to small form-factor devices such as microcontrollers. In this paper, we propose a small CNN model with 4 layers that is very amenable for edge AI deployment and realtime gait recognition. This model was trained on a public gait dataset with 20 classes augmented with data collected by the authors, aggregating to 24 classes in total. Our model achieves 96.7% accuracy and consumes only 5KB RAM with an inferencing time of 70 ms and 125mW power, while running continuous inference on Arduino Nano 33 BLE Sense. We successfully demonstrated realtime identification of the authors with the model running on Arduino, thus underscoring the efficacy and providing a proof of feasiblity for deployment in practical systems in near future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15312v1</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shanmuga Venkatachalam, Harideep Nair, Prabhu Vellaisamy, Yongqi Zhou, Ziad Youssfi, John Paul Shen</dc:creator>
    </item>
    <item>
      <title>Detection of direct path component absence in NLOS UWB channel</title>
      <link>https://arxiv.org/abs/2404.15314</link>
      <description>arXiv:2404.15314v1 Announce Type: new 
Abstract: In this paper a novel NLOS (Non-Line-of-Sight) identification technique is proposed. In comparison to other methods described in the literature, it discerns a situation when the delayed direct path component is available from when it's totally blocked and introduced biases are much higher and harder to mitigate. In the method, NLOS identification is performed using Support Vector Machine (SVM) algorithm based on various signal features. The paper includes description of the method and the results of performed experiment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15314v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.23919/MIKON.2018.8405190</arxiv:DOI>
      <dc:creator>Marcin Kolakowski, Jozef Modelski</dc:creator>
    </item>
    <item>
      <title>The largest EEG-based BCI reproducibility study for open science: the MOABB benchmark</title>
      <link>https://arxiv.org/abs/2404.15319</link>
      <description>arXiv:2404.15319v1 Announce Type: new 
Abstract: Objective. This study conduct an extensive Brain-computer interfaces (BCI) reproducibility analysis on open electroencephalography datasets, aiming to assess existing solutions and establish open and reproducible benchmarks for effective comparison within the field. The need for such benchmark lies in the rapid industrial progress that has given rise to undisclosed proprietary solutions. Furthermore, the scientific literature is dense, often featuring challenging-to-reproduce evaluations, making comparisons between existing approaches arduous.
  Approach. Within an open framework, 30 machine learning pipelines (separated into raw signal: 11, Riemannian: 13, deep learning: 6) are meticulously re-implemented and evaluated across 36 publicly available datasets, including motor imagery (14), P300 (15), and SSVEP (7). The analysis incorporates statistical meta-analysis techniques for results assessment, encompassing execution time and environmental impact considerations.
  Main results. The study yields principled and robust results applicable to various BCI paradigms, emphasizing motor imagery, P300, and SSVEP. Notably, Riemannian approaches utilizing spatial covariance matrices exhibit superior performance, underscoring the necessity for significant data volumes to achieve competitive outcomes with deep learning techniques. The comprehensive results are openly accessible, paving the way for future research to further enhance reproducibility in the BCI domain.
  Significance. The significance of this study lies in its contribution to establishing a rigorous and transparent benchmark for BCI research, offering insights into optimal methodologies and highlighting the importance of reproducibility in driving advancements within the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15319v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sylvain Chevallier, Igor Carrara, Bruno Aristimunha, Pierre Guetschel, Sara Sedlar, Bruna Lopes, Sebastien Velut, Salim Khazem, Thomas Moreau</dc:creator>
    </item>
    <item>
      <title>Characteristics-Based Design of Multi-Exponent Bandpass Filters</title>
      <link>https://arxiv.org/abs/2404.15321</link>
      <description>arXiv:2404.15321v1 Announce Type: new 
Abstract: We develop methods to design bandpass filters given desired characteristics such as peak frequency, bandwidth, and group delay. We develop this filter design method for filters we refer to as Generalized Auditory Filters (GAFs) which are represented as second order filters raised to non-unitary exponents and hence have three degrees of freedom. Our method for filter design accommodates specification of a trio of frequency-domain characteristics from amongst the peak frequency, convexity, 3dB, ndB quality factor, equivalent rectangular bandwidth, maximum group delay, and phase accumulation. To develop our characteristics-based design methods, we derive expressions for the filter constants directly in terms of filter characteristics. The parameterization of GAFs in terms of sets of characteristics allows for specifying magnitude-based characteristics (e.g. bandwidths) and phase-based characteristics (e.g. group delays) simultaneously. This enables designing sharply tuned filters without significant group delay, and is particularly important in filterbanks where frequency selectivity and synchronization are both important aspects of design. Using our methods, we directly dictate values for desired filter characteristics - unlike iterative filter design methods. This allows for more direct design of GAFs for phase-picking from seismic signals, cochlear implants, and rainbow sensors. The methods also directly apply to related bandpass and multi-band filters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15321v1</guid>
      <category>eess.SP</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samiya A Alkhairy</dc:creator>
    </item>
    <item>
      <title>Transportation mode recognition based on low-rate acceleration and location signals with an attention-based multiple-instance learning network</title>
      <link>https://arxiv.org/abs/2404.15323</link>
      <description>arXiv:2404.15323v1 Announce Type: new 
Abstract: Transportation mode recognition (TMR) is a critical component of human activity recognition (HAR) that focuses on understanding and identifying how people move within transportation systems. It is commonly based on leveraging inertial, location, or both types of signals, captured by modern smartphone devices. Each type has benefits (such as increased effectiveness) and drawbacks (such as increased battery consumption) depending on the transportation mode (TM). Combining the two types is challenging as they exhibit significant differences such as very different sampling rates. This paper focuses on the TMR task and proposes an approach for combining the two types of signals in an effective and robust classifier. Our network includes two sub-networks for processing acceleration and location signals separately, using different window sizes for each signal. The two sub-networks are designed to also embed the two types of signals into the same space so that we can then apply an attention-based multiple-instance learning classifier to recognize TM. We use very low sampling rates for both signal types to reduce battery consumption. We evaluate the proposed methodology on a publicly available dataset and compare against other well known algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15323v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christos Siargkas, Vasileios Papapanagiotou, Anastasios Delopoulos</dc:creator>
    </item>
    <item>
      <title>Advanced simulation-based predictive modelling for solar irradiance sensor farms</title>
      <link>https://arxiv.org/abs/2404.15324</link>
      <description>arXiv:2404.15324v1 Announce Type: new 
Abstract: As solar power continues to grow and replace traditional energy sources, the need for reliable forecasting models becomes increasingly important to ensure the stability and efficiency of the grid. However, the management of these models still needs to be improved, and new tools and technologies are required to handle the deployment and control of solar facilities. This work introduces a novel framework named Cloud-based Analysis and Integration for Data Efficiency (CAIDE), designed for real-time monitoring, management, and forecasting of solar irradiance sensor farms. CAIDE is designed to manage multiple sensor farms simultaneously while improving predictive models in real-time using well-grounded Modeling and Simulation (M&amp;S) methodologies. The framework leverages Model Based Systems Engineering (MBSE) and an Internet of Things (IoT) infrastructure to support the deployment and analysis of solar plants in dynamic environments. The system can adapt and re-train the model when given incorrect results, ensuring that forecasts remain accurate and up-to-date. Furthermore, CAIDE can be executed in sequential, parallel, and distributed architectures, assuring scalability. The effectiveness of CAIDE is demonstrated in a complex scenario composed of several solar irradiance sensor farms connected to a centralized management system. Our results show that CAIDE is scalable and effective in managing and forecasting solar power production while improving the accuracy of predictive models in real time. The framework has important implications for the deployment of solar plants and the future of renewable energy sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15324v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/17477778.2024.2333775</arxiv:DOI>
      <arxiv:journal_reference>Journal of Simulation, pp. 1-18, 2024</arxiv:journal_reference>
      <dc:creator>Jos\'e L. Risco-Mart\'in, Ignacio-Iker Prado-Rujas, Javier Campoy, Mar\'ia S. P\'erez, Katzalin Olcoz</dc:creator>
    </item>
    <item>
      <title>5G-Advanced AI/ML Beam Management: Performance Evaluation with Integrated ML Models</title>
      <link>https://arxiv.org/abs/2404.15326</link>
      <description>arXiv:2404.15326v1 Announce Type: new 
Abstract: The legacy beam management (BM) procedure in 5G introduces higher measurement and reporting overheads for larger beam codebooks resulting in higher power consumption of user equipment (UEs). Hence, the 3rd generation partnership project (3GPP) studied the use of artificial intelligence (AI) and machine learning (ML) in the air interface to reduce the overhead associated with the legacy BM procedure. The usage of AI/ML in BM is mainly discussed with regard to spatial-domain beam prediction (SBP) and time-domain beam prediction (TBP). In this study, we discuss different sub-use cases of SBP and TBP and evaluate the beam prediction accuracy of AI/ML models designed for each sub-use case along with AI/ML model generalization aspects. Moreover, a comprehensive system-level performance evaluation is presented in terms of user throughput with integrated AI/ML models to a 3GPP-compliant system-level simulator. Based on user throughput evaluations, we present AI/ML BM design guidelines for the deployment of lightweight, low-complexity AI/ML models discussed in this study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15326v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nalin Jayaweera, Andrea Bonfante, Mark Schamberger, Amir Mehdi Ahmadian Tehrani, Tachporn Sanguanpuak, Preetish Tilak, Keeth Jayasinghe, Frederick W. Vook, Nandana Rajatheva</dc:creator>
    </item>
    <item>
      <title>A Low-Complexity Design for IRS-Assisted Secure Dual-Function Radar-Communication System</title>
      <link>https://arxiv.org/abs/2404.15327</link>
      <description>arXiv:2404.15327v1 Announce Type: new 
Abstract: In dual-function radar-communication (DFRC) systems the probing signal contains information intended for the communication users, which makes that information vulnerable to eavesdropping by the targets. We study the security of a DFRC system aided by an intelligent reflecting surface (IRS) from the physical layer security (PLS) perspective. The IRS helps overcome path loss or blockage and introduces more degrees of freedom for system design, however, it also makes the design problem more challenging. In the system considered, the radar embeds artificial noise (AN) in the probing waveform, and the radar waveform, the AN noise and the IRS parameters are designed to optimize the communication secrecy rate while meeting radar signal-to-noise ratio (SNR) constraints. The contribution of the paper is a novel, low complexity approach to solve the underlying optimization problem and obtain the design parameters. In particular, we consider an alternating optimization approach, where in each iteration, the problem is decomposed into two sub-problems, namely, one that designs the IRS parameters, and another that jointly designs the radar waveform and the AN. The challenges in those sub-problems are the fractional objective, the SNR being a quartic function of the IRS parameters, and the unit-modulus constraint on the IRS parameters. A fractional programming technique is used to transform the fractional form objective into a more tractable non-fractional polynomial form. A closed-form based approach is proposed for the IRS design problem, which results in low complexity IRS design. Numerical results are provided to demonstrate the convergence properties of the proposed system design method, the secrecy rate and beamforming performance of the designed system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15327v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi-Kai Li, Athina Petropulu</dc:creator>
    </item>
    <item>
      <title>Time topological analysis of EEG using signature theory</title>
      <link>https://arxiv.org/abs/2404.15328</link>
      <description>arXiv:2404.15328v1 Announce Type: new 
Abstract: Anomaly detection in multivariate signals is a task of paramount importance in many disciplines (epidemiology, finance, cognitive sciences and neurosciences, oncology, etc.). In this perspective, Topological Data Analysis (TDA) offers a battery of "shape" invariants that can be exploited for the implementation of an effective detection scheme. Our contribution consists of extending the constructions presented in \cite{chretienleveraging} on the construction of simplicial complexes from the Signatures of signals and their predictive capacities, rather than the use of a generic distance as in \cite{petri2014homological}. Signature theory is a new theme in Machine Learning arXiv:1603.03788 stemming from recent work on the notions of Rough Paths developed by Terry Lyons and his team \cite{lyons2002system} based on the formalism introduced by Chen \cite{chen1957integration}. We explore in particular the detection of changes in topology, based on tracking the evolution of homological persistence and the Betti numbers associated with the complex introduced in \cite{chretienleveraging}. We apply our tools for the analysis of brain signals such as EEG to detect precursor phenomena to epileptic seizures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15328v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>St\'ephane Chr\'etien, Ben Gao, Astrid Thebault-Guiochon, R\'emi Vaucher</dc:creator>
    </item>
    <item>
      <title>Greedy Capon Beamformer</title>
      <link>https://arxiv.org/abs/2404.15329</link>
      <description>arXiv:2404.15329v1 Announce Type: new 
Abstract: We propose greedy Capon beamformer (GBF) for direction finding of narrow-band sources present in the array's viewing field. After defining the grid covering the location search space, the algorithm greedily builds the interference-plus-noise covariance matrix by identifying a high-power source on the grid using Capon's principle of maximizing the signal to interference plus noise ratio (SINR) while enforcing unit gain towards the signal of interest. An estimate of the power of the detected source is derived by exploiting the unit power constraint, which subsequently allows to update the noise covariance matrix by simple rank-1 matrix addition composed of outerproduct of the selected steering matrix with itself scaled by the signal power estimate. Our numerical examples demonstrate effectiveness of the proposed GCB in direction finding where it perform favourably compared to the state-of-the-art algorithms under a broad variety of settings. Furthermore, GCB estimates of direction-of-arrivals (DOAs) are very fast to compute.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15329v1</guid>
      <category>eess.SP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Esa Ollila</dc:creator>
    </item>
    <item>
      <title>Anchor Pair Selection in TDOA Positioning Systems by Door Transition Error Minimization</title>
      <link>https://arxiv.org/abs/2404.15330</link>
      <description>arXiv:2404.15330v1 Announce Type: new 
Abstract: This paper presents an adaptive anchor pairs selection algorithm for UWB (ultra-wideband) TDOA-based (Time Difference of Arrival) indoor positioning systems. The method assumes dividing the system operation area into zones. The most favorable anchor pairs are selected by minimizing the positioning errors in doorways leading to these zones where possible users' locations are limited to small, narrow areas. The sets are determined separately for going in and out of the zone to take users' body shadowing into account. The determined anchor pairs are then used to calculate TDOA values and localize the user moving around the apartment with an Extended Kalman Filter based algorithm. The method was tested experimentally in a furnished apartment. The results have shown that the adaptive selection of the anchor pairs leads to an increase in the user's localization accuracy. The median trajectory error was about 0.32 m.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15330v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.23919/MIKON54314.2022.9924777</arxiv:DOI>
      <dc:creator>Marcin Kolakowski, Jozef Modelski</dc:creator>
    </item>
    <item>
      <title>Comparing Self-Supervised Learning Techniques for Wearable Human Activity Recognition</title>
      <link>https://arxiv.org/abs/2404.15331</link>
      <description>arXiv:2404.15331v1 Announce Type: new 
Abstract: Human Activity Recognition (HAR) based on the sensors of mobile/wearable devices aims to detect the physical activities performed by humans in their daily lives. Although supervised learning methods are the most effective in this task, their effectiveness is constrained to using a large amount of labeled data during training. While collecting raw unlabeled data can be relatively easy, annotating data is challenging due to costs, intrusiveness, and time constraints.
  To address these challenges, this paper explores alternative approaches for accurate HAR using a limited amount of labeled data. In particular, we have adapted recent Self-Supervised Learning (SSL) algorithms to the HAR domain and compared their effectiveness. We investigate three state-of-the-art SSL techniques of different families: contrastive, generative, and predictive. Additionally, we evaluate the impact of the underlying neural network on the recognition rate by comparing state-of-the-art CNN and transformer architectures.
  Our results show that a Masked Auto Encoder (MAE) approach significantly outperforms other SSL approaches, including SimCLR, commonly considered one of the best-performing SSL methods in the HAR domain.
  The code and the pre-trained SSL models are publicly available for further research and development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15331v1</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sannara Ek, Riccardo Presotto, Gabriele Civitarese, Fran\c{c}ois Portet, Philippe Lalanda, Claudio Bettini</dc:creator>
    </item>
    <item>
      <title>Clinical translation of machine learning algorithms for seizure detection in scalp electroencephalography: a systematic review</title>
      <link>https://arxiv.org/abs/2404.15332</link>
      <description>arXiv:2404.15332v1 Announce Type: new 
Abstract: Machine learning algorithms for seizure detection have shown great diagnostic potential, with recent reported accuracies reaching 100%. However, few published algorithms have fully addressed the requirements for successful clinical translation. For example, the properties of training data may critically limit the generalisability of algorithms, algorithms may be sensitive to variability across EEG acquisition hardware, and run-time processing costs may render them unfeasible for real-time clinical use cases. Here, we systematically review machine learning seizure detection algorithms with a focus on clinical translatability, assessed by criteria including generalisability, run-time costs, explainability, and clinically-relevant performance metrics. For non-specialists, we provide domain-specific knowledge necessary to contextualise model development and evaluation. Our critical evaluation of machine learning algorithms with respect to their potential real-world effectiveness can help accelerate clinical translation and identify gaps in the current seizure detection literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15332v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nina Moutonnet, Steven White, Benjamin P Campbell, Danilo Mandic, Gregory Scott</dc:creator>
    </item>
    <item>
      <title>EB-GAME: A Game-Changer in ECG Heartbeat Anomaly Detection</title>
      <link>https://arxiv.org/abs/2404.15333</link>
      <description>arXiv:2404.15333v1 Announce Type: new 
Abstract: Cardiologists use electrocardiograms (ECG) for the detection of arrhythmias. However, continuous monitoring of ECG signals to detect cardiac abnormal-ities requires significant time and human resources. As a result, several deep learning studies have been conducted in advance for the automatic detection of arrhythmia. These models show relatively high performance in supervised learning, but are not applicable in cases with few training examples. This is because abnormal ECG data is scarce compared to normal data in most real-world clinical settings. Therefore, in this study, GAN-based anomaly detec-tion, i.e., unsupervised learning, was employed to address the issue of data imbalance. This paper focuses on detecting abnormal signals in electrocardi-ograms (ECGs) using only labels from normal signals as training data. In-spired by self-supervised vision transformers, which learn by dividing images into patches, and masked auto-encoders, known for their effectiveness in patch reconstruction and solving information redundancy, we introduce the ECG Heartbeat Anomaly Detection model, EB-GAME. EB-GAME was trained and validated on the MIT-BIH Arrhythmia Dataset, where it achieved state-of-the-art performance on this benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15333v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>JuneYoung Park, Da Young Kim, Yunsoo Kim, Jisu Yoo, Tae Joon Kim</dc:creator>
    </item>
    <item>
      <title>Performance Enhancement via Real-time Image-based Beam Tracking for WA-OWC with Dynamic Waves and Mobile Receivers</title>
      <link>https://arxiv.org/abs/2404.15334</link>
      <description>arXiv:2404.15334v1 Announce Type: new 
Abstract: Intensified underwater activities have driven the escalating demand for reliable, flexible, and high data-rate underwater communication links. Optical wireless communication (OWC) emerges as the most promising technology for short- to medium-range communication, facilitating the real-time high-speed transmission of information from undersea to an aerial vehicle which can subsequently relay the information to a terrestrial station. However, establishing a robust water-air link confronts two primary challenges: (i) beam wandering due to the time-varying refraction when the light beam passes through the undulating ocean surface and (ii) the drone's movement when it hovers above the ocean surface. This paper experimentally demonstrated a real-time imaged-based beam tracking system to mitigate beam misalignment due to dynamic waves and receiver movement over a 0.14-m underwater and 1.83-m free-space OWC channel. Experimental results evince a notable reduction in the standard deviation of the received light spot offset from the receiver. Moreover, the tracking system can proficiently accommodate receiver velocities of up to 150 cm/s while maintaining a paltry packet loss rate (PLR) below 10%. By addressing the combined effects of dynamic waves and moving receivers, the proposed beam tracking system successfully enables a 70% reduction in PLR and an order of magnitude decrease in bit error rate (BER). This results in a substantial 17-fold surge in maximum throughput, from 50 Mbps to 850 Mbps. The experimental results validate the feasibility and effectiveness of the beam tracking system for vanquishing the detrimental effects in the complex water-air OWC (WA-OWC) channel and supporting high-speed data transmission.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15334v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yujie Di, Anzi Xu, Lian-Kuan Chen</dc:creator>
    </item>
    <item>
      <title>Integrative Deep Learning Framework for Parkinson's Disease Early Detection using Gait Cycle Data Measured by Wearable Sensors: A CNN-GRU-GNN Approach</title>
      <link>https://arxiv.org/abs/2404.15335</link>
      <description>arXiv:2404.15335v1 Announce Type: new 
Abstract: Efficient early diagnosis is paramount in addressing the complexities of Parkinson's disease because timely intervention can substantially mitigate symptom progression and improve patient outcomes. In this paper, we present a pioneering deep learning architecture tailored for the binary classification of subjects, utilizing gait cycle datasets to facilitate early detection of Parkinson's disease. Our model harnesses the power of 1D-Convolutional Neural Networks (CNN), Gated Recurrent Units (GRU), and Graph Neural Network (GNN) layers, synergistically capturing temporal dynamics and spatial relationships within the data. In this work, 16 wearable sensors located at the end of subjects' shoes for measuring the vertical Ground Reaction Force (vGRF) are considered as the vertices of a graph, their adjacencies are modelled as edges of this graph, and finally, the measured data of each sensor is considered as the feature vector of its corresponding vertex. Therefore, The GNN layers can extract the relations among these sensors by learning proper representations. Regarding the dynamic nature of these measurements, GRU and CNN are used to analyze them spatially and temporally and map them to an embedding space. Remarkably, our proposed model achieves exceptional performance metrics, boasting accuracy, precision, recall, and F1 score values of 99.51%, 99.57%, 99.71%, and 99.64%, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15335v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alireza Rashnu, Armin Salimi-Badr</dc:creator>
    </item>
    <item>
      <title>Machine Learning Techniques for Source Localisation in Elastic Media</title>
      <link>https://arxiv.org/abs/2404.15336</link>
      <description>arXiv:2404.15336v1 Announce Type: new 
Abstract: Coronary Artery Disease (CAD) results from plaque deposit in a coronary artery. Early diagnosis is imperative, so a non-invasive detection method is being developed to identify acoustic signals caused by partial occlusions in the artery. The blood flow in the artery is disturbed and imposes oscillatory stresses on the artery wall. The deformations caused by the stresses can be detected at the chest surface. Therefore, by using data simulating these surface signals, which arise from randomly assigned source positions, machine learning (ML) can be utilised to predict the source of the occlusion. Seven ML algorithms were investigated, and the results from this study found that an ensemble model combining k-Nearest Neighbours and Random Forest had the best performance. The metrics used to evaluate this was the mean squared error and Euclidean distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15336v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bansi Mandalia, Steve Greenwald, Simon Shaw, Gregory Slabaugh</dc:creator>
    </item>
    <item>
      <title>RSSI Estimation for Constrained Indoor Wireless Networks using ANN</title>
      <link>https://arxiv.org/abs/2404.15337</link>
      <description>arXiv:2404.15337v1 Announce Type: new 
Abstract: In the expanding field of the Internet of Things (IoT), wireless channel estimation is a significant challenge. This is specifically true for low-power IoT (LP-IoT) communication, where efficiency and accuracy are extremely important. This research establishes two distinct LP-IoT wireless channel estimation models using Artificial Neural Networks (ANN): a Feature-based ANN model and a Sequence-based ANN model. Both models have been constructed to enhance LP-IoT communication by lowering the estimation error in the LP-IoT wireless channel. The Feature-based model aims to capture complex patterns of measured Received Signal Strength Indicator (RSSI) data using environmental characteristics. The Sequence-based approach utilises predetermined categorisation techniques to estimate the RSSI sequence of specifically selected environment characteristics. The findings demonstrate that our suggested approaches attain remarkable precision in channel estimation, with an improvement in MSE of $88.29\%$ of the Feature-based model and $97.46\%$ of the Sequence-based model over existing research. Additionally, the comparative analysis of these techniques with traditional and other Deep Learning (DL)-based techniques also highlights the superior performance of our developed models and their potential in real-world IoT applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15337v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Samrah Arif, M. Arif Khan, Sabih Ur Rehman</dc:creator>
    </item>
    <item>
      <title>RayPet: Unveiling Challenges and Solutions for Activity and Posture Recognition in Pets Using FMCW Mm-Wave Radar</title>
      <link>https://arxiv.org/abs/2404.15340</link>
      <description>arXiv:2404.15340v1 Announce Type: new 
Abstract: Recognizing animal activities holds a crucial role in monitoring animals' health and well-being. Additionally, a considerable audience is keen on monitoring their pets' well-being and health status. Insight into animals' habitual activities and patterns not only aids veterinarians in accurate diagnoses but also offers pet owners early alerts. Traditional methods of tracking animal behavior involve wearable sensors like IMU sensors, collars, or cameras. Nevertheless, concerns, including privacy, robustness, and animal discomfort persist. In this study, radar technology, a noninvasive remote sensing technology widely employed in human health monitoring, is explored for AAR. Radar enables fine motion analysis through Microdoppler spectrograms. Utilizing an off-the-shelf FMCW mm-wave radar, we gather data from five distinct activities and postures. Merging radar technology with Machine Learning and Deep Learning algorithms helps distinguish diverse pet activities and postures. Specific challenges in AAR, such as random movements, being uncontrollable, noise, and small animal size, make radar adoption for animal monitoring complex. In this study, RayPet unveils different challenges and solutions regarding monitoring small animals. To overcome the challenges, different signal processing steps are devised and implemented, tailored for animals. We use four types of classifiers and achieve an accuracy rate of 89%. This progress marks an important step in using radar technology to observe and comprehend activities and postures in pets in particular and in animals in general, contributing to our knowledge of animal well-being and behavior analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15340v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ehsan Sadeghi, Abel van Raalte, Alessandro Chiumento, Paul Havinga</dc:creator>
    </item>
    <item>
      <title>Classifier-guided neural blind deconvolution: a physics-informed denoising module for bearing fault diagnosis under heavy noise</title>
      <link>https://arxiv.org/abs/2404.15341</link>
      <description>arXiv:2404.15341v1 Announce Type: new 
Abstract: Blind deconvolution (BD) has been demonstrated as an efficacious approach for extracting bearing fault-specific features from vibration signals under strong background noise. Despite BD's desirable feature in adaptability and mathematical interpretability, a significant challenge persists: How to effectively integrate BD with fault-diagnosing classifiers? This issue arises because the traditional BD method is solely designed for feature extraction with its own optimizer and objective function. When BD is combined with downstream deep learning classifiers, the different learning objectives will be in conflict. To address this problem, this paper introduces classifier-guided BD (ClassBD) for joint learning of BD-based feature extraction and deep learning-based fault classification. Firstly, we present a time and frequency neural BD that employs neural networks to implement conventional BD, thereby facilitating the seamless integration of BD and the deep learning classifier for co-optimization of model parameters. Subsequently, we develop a unified framework to use a deep learning classifier to guide the learning of BD filters. In addition, we devise a physics-informed loss function composed of kurtosis, $l_2/l_4$ norm, and a cross-entropy loss to jointly optimize the BD filters and deep learning classifier. Consequently, the fault labels provide useful information to direct BD to extract features that distinguish classes amidst strong noise. To the best of our knowledge, this is the first of its kind that BD is successfully applied to bearing fault diagnosis. Experimental results from three datasets demonstrate that ClassBD outperforms other state-of-the-art methods under noisy conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15341v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jing-Xiao Liao, Chao He, Jipu Li, Jinwei Sun, Shiping Zhang, Xiaoge Zhang</dc:creator>
    </item>
    <item>
      <title>WaveSleepNet: An Interpretable Network for Expert-like Sleep Staging</title>
      <link>https://arxiv.org/abs/2404.15342</link>
      <description>arXiv:2404.15342v1 Announce Type: new 
Abstract: Although deep learning algorithms have proven their efficiency in automatic sleep staging, the widespread skepticism about their "black-box" nature has limited its clinical acceptance. In this study, we propose WaveSleepNet, an interpretable neural network for sleep staging that reasons in a similar way to sleep experts. In this network, we utilize the latent space representations generated during training to identify characteristic wave prototypes corresponding to different sleep stages. The feature representation of an input signal is segmented into patches within the latent space, each of which is compared against the learned wave prototypes. The proximity between these patches and the wave prototypes is quantified through scores, indicating the prototypes' presence and relative proportion within the signal. The scores are served as the decision-making criteria for final sleep staging. During training, an ensemble of loss functions is employed for the prototypes' diversity and robustness. Furthermore, the learned wave prototypes are visualized by analysing occlusion sensitivity. The efficacy of WaveSleepNet is validated across three public datasets, achieving sleep staging performance that are on par with the state-of-the-art models when several WaveSleepNets are combine into a larger network. A detailed case study examined the decision-making process of the WaveSleepNet which aligns closely with American Academy of Sleep Medicine (AASM) manual guidelines. Another case study systematically explained the misidentified reason behind each sleep stage. WaveSleepNet's transparent process provides specialists with direct access to the physiological significance of its criteria, allowing for future adaptation or enrichment by sleep experts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15342v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Pei, Wei Luo</dc:creator>
    </item>
    <item>
      <title>Edge-Efficient Deep Learning Models for Automatic Modulation Classification: A Performance Analysis</title>
      <link>https://arxiv.org/abs/2404.15343</link>
      <description>arXiv:2404.15343v1 Announce Type: new 
Abstract: The recent advancement in deep learning (DL) for automatic modulation classification (AMC) of wireless signals has encouraged numerous possible applications on resource-constrained edge devices. However, developing optimized DL models suitable for edge applications of wireless communications is yet to be studied in depth. In this work, we perform a thorough investigation of optimized convolutional neural networks (CNNs) developed for AMC using the three most commonly used model optimization techniques: a) pruning, b) quantization, and c) knowledge distillation. Furthermore, we have proposed optimized models with the combinations of these techniques to fuse the complementary optimization benefits. The performances of all the proposed methods are evaluated in terms of sparsity, storage compression for network parameters, and the effect on classification accuracy with a reduction in parameters. The experimental results show that the proposed individual and combined optimization techniques are highly effective for developing models with significantly less complexity while maintaining or even improving classification performance compared to the benchmark CNNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15343v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nayan Moni Baishya, B. R. Manoj, Prabin K. Bora</dc:creator>
    </item>
    <item>
      <title>Adversarial Robustness of Distilled and Pruned Deep Learning-based Wireless Classifiers</title>
      <link>https://arxiv.org/abs/2404.15344</link>
      <description>arXiv:2404.15344v1 Announce Type: new 
Abstract: Data-driven deep learning (DL) techniques developed for automatic modulation classification (AMC) of wireless signals are vulnerable to adversarial attacks. This poses a severe security threat to the DL-based wireless systems, specifically for edge applications of AMC. In this work, we address the joint problem of developing optimized DL models that are also robust against adversarial attacks. This enables efficient and reliable deployment of DL-based AMC on edge devices. We first propose two optimized models using knowledge distillation and network pruning, followed by a computationally efficient adversarial training process to improve the robustness. Experimental results on five white-box attacks show that the proposed optimized and adversarially trained models can achieve better robustness than the standard (unoptimized) model. The two optimized models also achieve higher accuracy on clean (unattacked) samples, which is essential for the reliability of DL-based solutions at edge applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15344v1</guid>
      <category>eess.SP</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nayan Moni Baishya, B. R. Manoj</dc:creator>
    </item>
    <item>
      <title>A Novel Micro-Doppler Coherence Loss for Deep Learning Radar Applications</title>
      <link>https://arxiv.org/abs/2404.15346</link>
      <description>arXiv:2404.15346v1 Announce Type: new 
Abstract: Deep learning techniques are subject to increasing adoption for a wide range of micro-Doppler applications, where predictions need to be made based on time-frequency signal representations. Most, if not all, of the reported applications focus on translating an existing deep learning framework to this new domain with no adjustment made to the objective function. This practice results in a missed opportunity to encourage the model to prioritize features that are particularly relevant for micro-Doppler applications. Thus the paper introduces a micro-Doppler coherence loss, minimized when the normalized power of micro-Doppler oscillatory components between input and output is matched. The experiments conducted on real data show that the application of the introduced loss results in models more resilient to noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15346v1</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.23919/EuRAD50154.2022.9784491</arxiv:DOI>
      <dc:creator>Mikolaj Czerkawski, Christos Ilioudis, Carmine Clemente, Craig Michie, Ivan Andonovic, Christos Tachtatzis</dc:creator>
    </item>
    <item>
      <title>Advanced Neural Network Architecture for Enhanced Multi-Lead ECG Arrhythmia Detection through Optimized Feature Extraction</title>
      <link>https://arxiv.org/abs/2404.15347</link>
      <description>arXiv:2404.15347v1 Announce Type: new 
Abstract: Cardiovascular diseases are a pervasive global health concern, contributing significantly to morbidity and mortality rates worldwide. Among these conditions, arrhythmia, characterized by irregular heart rhythms, presents formidable diagnostic challenges. This study introduces an innovative approach utilizing deep learning techniques, specifically Convolutional Neural Networks (CNNs), to address the complexities of arrhythmia classification. Leveraging multi-lead Electrocardiogram (ECG) data, our CNN model, comprising six layers with a residual block, demonstrates promising outcomes in identifying five distinct heartbeat types: Left Bundle Branch Block (LBBB), Right Bundle Branch Block (RBBB), Atrial Premature Contraction (APC), Premature Ventricular Contraction (PVC), and Normal Beat. Through rigorous experimentation, we highlight the transformative potential of our methodology in enhancing diagnostic accuracy for cardiovascular arrhythmias. Arrhythmia diagnosis remains a critical challenge in cardiovascular care, often relying on manual interpretation of ECG signals, which can be time-consuming and prone to subjectivity. To address these limitations, we propose a novel approach that leverages deep learning algorithms to automate arrhythmia classification. By employing advanced CNN architectures and multi-lead ECG data, our methodology offers a robust solution for precise and efficient arrhythmia detection. Through comprehensive evaluation, we demonstrate the effectiveness of our approach in facilitating more accurate clinical decision-making, thereby improving patient outcomes in managing cardiovascular arrhythmias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15347v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.17626.76489</arxiv:DOI>
      <dc:creator>Bhavith Chandra Challagundla</dc:creator>
    </item>
    <item>
      <title>High-Linearity PAM-4 Silicon Micro-ring Transmitter Architecture with Electronic-Photonic Hybrid DAC</title>
      <link>https://arxiv.org/abs/2404.15348</link>
      <description>arXiv:2404.15348v1 Announce Type: new 
Abstract: This paper presents a high linearity PAM-4 transmitter (TX) architecture, consisting of a three-segment micro-ring modulator (MRM) and a matched CMOS driver. This architecture can drive a high-linearity 4-level pulse amplitude (PAM-4) modulation signal, thereby extending the tunable operating wavelength range for achieving linear PAM-4 output. We use the three-segment MRM to increase design flexibility so that the linearity of PAM-4 output can be optimized with another degree of freedom. Each phase shift region is directly driven by the independently amplitude-tunable Non-Return-to-Zero (NRZ) signal. The three-segment modulator can achieve an adjustable wavelength range of approximately 0.037 nm within the high linearity PAM-4 output limit when the driving voltage varies from 1.5 V to 3 V, simultaneously achieving an adjustable insertion loss (IL) range of approximately 2 dB, roughly four times that of the two-segment MRM with a similar design. The driver circuit with adjustable driving voltage is co-designed to adjust the eye height to improve PAM-4 linearity. In this article, the high linearity PAM-4 silicon micro-ring architecture can be employed in optical transmitters to adjust PAM-4 eye-opening size and maximize the PAM-4 output linearity, thus offering the potential for high-performance and low-power overhead transmitters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15348v1</guid>
      <category>eess.SP</category>
      <category>physics.optics</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zheng Li, Chengyang Lv, Min Tan</dc:creator>
    </item>
    <item>
      <title>A Survey on Multimodal Wearable Sensor-based Human Action Recognition</title>
      <link>https://arxiv.org/abs/2404.15349</link>
      <description>arXiv:2404.15349v1 Announce Type: new 
Abstract: The combination of increased life expectancy and falling birth rates is resulting in an aging population. Wearable Sensor-based Human Activity Recognition (WSHAR) emerges as a promising assistive technology to support the daily lives of older individuals, unlocking vast potential for human-centric applications. However, recent surveys in WSHAR have been limited, focusing either solely on deep learning approaches or on a single sensor modality. In real life, our human interact with the world in a multi-sensory way, where diverse information sources are intricately processed and interpreted to accomplish a complex and unified sensing system. To give machines similar intelligence, multimodal machine learning, which merges data from various sources, has become a popular research area with recent advancements. In this study, we present a comprehensive survey from a novel perspective on how to leverage multimodal learning to WSHAR domain for newcomers and researchers. We begin by presenting the recent sensor modalities as well as deep learning approaches in HAR. Subsequently, we explore the techniques used in present multimodal systems for WSHAR. This includes inter-multimodal systems which utilize sensor modalities from both visual and non-visual systems and intra-multimodal systems that simply take modalities from non-visual systems. After that, we focus on current multimodal learning approaches that have applied to solve some of the challenges existing in WSHAR. Specifically, we make extra efforts by connecting the existing multimodal literature from other domains, such as computer vision and natural language processing, with current WSHAR area. Finally, we identify the corresponding challenges and potential research direction in current WSHAR area for further improvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15349v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.MM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianyuan Ni, Hao Tang, Syed Tousiful Haque, Yan Yan, Anne H. H. Ngu</dc:creator>
    </item>
    <item>
      <title>Evaluating Fast Adaptability of Neural Networks for Brain-Computer Interface</title>
      <link>https://arxiv.org/abs/2404.15350</link>
      <description>arXiv:2404.15350v1 Announce Type: new 
Abstract: Electroencephalography (EEG) classification is a versatile and portable technique for building non-invasive Brain-computer Interfaces (BCI). However, the classifiers that decode cognitive states from EEG brain data perform poorly when tested on newer domains, such as tasks or individuals absent during model training. Researchers have recently used complex strategies like Model-agnostic meta-learning (MAML) for domain adaptation. Nevertheless, there is a need for an evaluation strategy to evaluate the fast adaptability of the models, as this characteristic is essential for real-life BCI applications for quick calibration. We used motor movement and imaginary signals as input to Convolutional Neural Networks (CNN) based classifier for the experiments. Datasets with EEG signals typically have fewer examples and higher time resolution. Even though batch-normalization is preferred for Convolutional Neural Networks (CNN), we empirically show that layer-normalization can improve the adaptability of CNN-based EEG classifiers with not more than ten fine-tuning steps. In summary, the present work (i) proposes a simple strategy to evaluate fast adaptability, and (ii) empirically demonstrate fast adaptability across individuals as well as across tasks with simple transfer learning as compared to MAML approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15350v1</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anupam Sharma, Krishna Miyapuram</dc:creator>
    </item>
    <item>
      <title>Integrating Physiological Data with Large Language Models for Empathic Human-AI Interaction</title>
      <link>https://arxiv.org/abs/2404.15351</link>
      <description>arXiv:2404.15351v1 Announce Type: new 
Abstract: This paper explores enhancing empathy in Large Language Models (LLMs) by integrating them with physiological data. We propose a physiological computing approach that includes developing deep learning models that use physiological data for recognizing psychological states and integrating the predicted states with LLMs for empathic interaction. We showcase the application of this approach in an Empathic LLM (EmLLM) chatbot for stress monitoring and control. We also discuss the results of a pilot study that evaluates this EmLLM chatbot based on its ability to accurately predict user stress, provide human-like responses, and assess the therapeutic alliance with the user.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15351v1</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Poorvesh Dongre, Majid Behravan, Kunal Gupta, Mark Billinghurst, Denis Gra\v{c}anin</dc:creator>
    </item>
    <item>
      <title>TransfoRhythm: A Transformer Architecture Conductive to Blood Pressure Estimation via Solo PPG Signal Capturing</title>
      <link>https://arxiv.org/abs/2404.15352</link>
      <description>arXiv:2404.15352v1 Announce Type: new 
Abstract: Recent statistics indicate that approximately 1.3 billion individuals worldwide suffer from hypertension, a leading cause of premature death globally. Blood pressure (BP) serves as a critical health indicator for accurate and timely diagnosis and/or treatment of hypertension. Driven by recent advancements in Artificial Intelligence (AI) and Deep Neural Networks (DNNs), there has been a surge of interest in developing data-driven and cuff-less BP estimation solutions. In this context, current literature predominantly focuses on coupling Electrocardiography (ECG) and Photoplethysmography (PPG) sensors, though this approach is constrained by reliance on multiple sensor types. An alternative, utilizing standalone PPG signals, presents challenges due to the absence of auxiliary sensors (ECG), requiring the use of morphological features while addressing motion artifacts and high-frequency noise. To address these issues, the paper introduces the TransfoRhythm framework, a Transformer-based DNN architecture built upon the recently released physiological database, MIMIC-IV. Leveraging Multi-Head Attention (MHA) mechanism, TransfoRhythm identifies dependencies and similarities across data segments, forming a robust framework for cuff-less BP estimation solely using PPG signals. To our knowledge, this paper represents the first study to apply the MIMIC IV dataset for cuff-less BP estimation, and TransfoRhythm is the first MHA-based model trained via MIMIC IV for BP prediction. Performance evaluation through comprehensive experiments demonstrates TransfoRhythm's superiority over its state-of-the-art counterparts. Specifically, TransfoRhythm achieves highly accurate results with Root Mean Square Error (RMSE) of [1.84, 1.42] and Mean Absolute Error (MAE) of [1.50, 1.17] for systolic and diastolic blood pressures, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15352v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Arjomand, Amin Boudesh, Farnoush Bayatmakou, Kenneth B. Kent, Arash Mohammadi</dc:creator>
    </item>
    <item>
      <title>SQUWA: Signal Quality Aware DNN Architecture for Enhanced Accuracy in Atrial Fibrillation Detection from Noisy PPG Signals</title>
      <link>https://arxiv.org/abs/2404.15353</link>
      <description>arXiv:2404.15353v1 Announce Type: new 
Abstract: Atrial fibrillation (AF), a common cardiac arrhythmia, significantly increases the risk of stroke, heart disease, and mortality. Photoplethysmography (PPG) offers a promising solution for continuous AF monitoring, due to its cost efficiency and integration into wearable devices. Nonetheless, PPG signals are susceptible to corruption from motion artifacts and other factors often encountered in ambulatory settings. Conventional approaches typically discard corrupted segments or attempt to reconstruct original signals, allowing for the use of standard machine learning techniques. However, this reduces dataset size and introduces biases, compromising prediction accuracy and the effectiveness of continuous monitoring. We propose a novel deep learning model, Signal Quality Weighted Fusion of Attentional Convolution and Recurrent Neural Network (SQUWA), designed to learn how to retain accurate predictions from partially corrupted PPG. Specifically, SQUWA innovatively integrates an attention mechanism that directly considers signal quality during the learning process, dynamically adjusting the weights of time series segments based on their quality. This approach enhances the influence of higher-quality segments while reducing that of lower-quality ones, effectively utilizing partially corrupted segments. This approach represents a departure from the conventional methods that exclude such segments, enabling the utilization of a broader range of data, which has great implications for less disruption when monitoring of AF risks and more accurate estimation of AF burdens. Our extensive experiments show that SQUWA outperform existing PPG-based models, achieving the highest AUCPR of 0.89 with label noise mitigation. This also exceeds the 0.86 AUCPR of models trained with using both electrocardiogram (ECG) and PPG data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15353v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runze Yan, Cheng Ding, Ran Xiao, Aleksandr Fedorov, Randall J Lee, Fadi Nahab, Xiao Hu</dc:creator>
    </item>
    <item>
      <title>Elevating Spectral GNNs through Enhanced Band-pass Filter Approximation</title>
      <link>https://arxiv.org/abs/2404.15354</link>
      <description>arXiv:2404.15354v1 Announce Type: new 
Abstract: Spectral Graph Neural Networks (GNNs) have attracted great attention due to their capacity to capture patterns in the frequency domains with essential graph filters. Polynomial-based ones (namely poly-GNNs), which approximately construct graph filters with conventional or rational polynomials, are routinely adopted in practice for their substantial performances on graph learning tasks. However, previous poly-GNNs aim at achieving overall lower approximation error on different types of filters, e.g., low-pass and high-pass, but ignore a key question: \textit{which type of filter warrants greater attention for poly-GNNs?} In this paper, we first show that poly-GNN with a better approximation for band-pass graph filters performs better on graph learning tasks. This insight further sheds light on critical issues of existing poly-GNNs, i.e., those poly-GNNs achieve trivial performance in approximating band-pass graph filters, hindering the great potential of poly-GNNs. To tackle the issues, we propose a novel poly-GNN named TrigoNet. TrigoNet constructs different graph filters with novel trigonometric polynomial, and achieves leading performance in approximating band-pass graph filters against other polynomials. By applying Taylor expansion and deserting nonlinearity, TrigoNet achieves noticeable efficiency among baselines. Extensive experiments show the advantages of TrigoNet in both accuracy performances and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15354v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guoming Li, Jian Yang, Shangsong Liang, Dongsheng Luo</dc:creator>
    </item>
    <item>
      <title>Towards Robust and Interpretable EMG-based Hand Gesture Recognition using Deep Metric Meta Learning</title>
      <link>https://arxiv.org/abs/2404.15360</link>
      <description>arXiv:2404.15360v1 Announce Type: new 
Abstract: Current electromyography (EMG) pattern recognition (PR) models have been shown to generalize poorly in unconstrained environments, setting back their adoption in applications such as hand gesture control. This problem is often due to limited training data, exacerbated by the use of supervised classification frameworks that are known to be suboptimal in such settings. In this work, we propose a shift to deep metric-based meta-learning in EMG PR to supervise the creation of meaningful and interpretable representations. We use a Siamese Deep Convolutional Neural Network (SDCNN) and contrastive triplet loss to learn an EMG feature embedding space that captures the distribution of the different classes. A nearest-centroid approach is subsequently employed for inference, relying on how closely a test sample aligns with the established data distributions. We derive a robust class proximity-based confidence estimator that leads to a better rejection of incorrect decisions, i.e. false positives, especially when operating beyond the training data domain. We show our approach's efficacy by testing the trained SDCNN's predictions and confidence estimations on unseen data, both in and out of the training domain. The evaluation metrics include the accuracy-rejection curve and the Kullback-Leibler divergence between the confidence distributions of accurate and inaccurate predictions. Outperforming comparable models on both metrics, our results demonstrate that the proposed meta-learning approach improves the classifier's precision in active decisions (after rejection), thus leading to better generalization and applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15360v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Simon Tam, Shriram Tallam Puranam Raghu, \'Etienne Buteau, Erik Scheme, Mounir Boukadoum, Alexandre Campeau-Lecours, Benoit Gosselin</dc:creator>
    </item>
    <item>
      <title>MP-DPD: Low-Complexity Mixed-Precision Neural Networks for Energy-Efficient Digital Predistortion of Wideband Power Amplifiers</title>
      <link>https://arxiv.org/abs/2404.15364</link>
      <description>arXiv:2404.15364v1 Announce Type: new 
Abstract: Digital Pre-Distortion (DPD) enhances signal quality in wideband RF power amplifiers (PAs). As signal bandwidths expand in modern radio systems, DPD's energy consumption increasingly impacts overall system efficiency. Deep Neural Networks (DNNs) offer promising advancements in DPD, yet their high complexity hinders their practical deployment. This paper introduces open-source mixed-precision (MP) neural networks that employ quantized low-precision fixed-point parameters for energy-efficient DPD. This approach reduces computational complexity and memory footprint, thereby lowering power consumption without compromising linearization efficacy. Applied to a 160MHz-BW 1024-QAM OFDM signal from a digital RF PA, MP-DPD gives no performance loss against 32-bit floating-point precision DPDs, while achieving -43.75 (L)/-45.27 (R) dBc in Adjacent Channel Power Ratio (ACPR) and -38.72 dB in Error Vector Magnitude (EVM). A 16-bit fixed-point-precision MP-DPD enables a 2.8X reduction in estimated inference power. The PyTorch learning and testing code is publicly available at \url{https://github.com/lab-emi/OpenDPD}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15364v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LMWT.2024.3386330</arxiv:DOI>
      <dc:creator>Yizhuo Wu, Ang Li, Mohammadreza Beikmirza, Gagan Deep Singh, Qinyu Chen, Leo C. N. de Vreede, Morteza Alavi, Chang Gao</dc:creator>
    </item>
    <item>
      <title>A Weight-aware-based Multi-source Unsupervised Domain Adaptation Method for Human Motion Intention Recognition</title>
      <link>https://arxiv.org/abs/2404.15366</link>
      <description>arXiv:2404.15366v1 Announce Type: new 
Abstract: Accurate recognition of human motion intention (HMI) is beneficial for exoskeleton robots to improve the wearing comfort level and achieve natural human-robot interaction. A classifier trained on labeled source subjects (domains) performs poorly on unlabeled target subject since the difference in individual motor characteristics. The unsupervised domain adaptation (UDA) method has become an effective way to this problem. However, the labeled data are collected from multiple source subjects that might be different not only from the target subject but also from each other. The current UDA methods for HMI recognition ignore the difference between each source subject, which reduces the classification accuracy. Therefore, this paper considers the differences between source subjects and develops a novel theory and algorithm for UDA to recognize HMI, where the margin disparity discrepancy (MDD) is extended to multi-source UDA theory and a novel weight-aware-based multi-source UDA algorithm (WMDD) is proposed. The source domain weight, which can be adjusted adaptively by the MDD between each source subject and target subject, is incorporated into UDA to measure the differences between source subjects. The developed multi-source UDA theory is theoretical and the generalization error on target subject is guaranteed. The theory can be transformed into an optimization problem for UDA, successfully bridging the gap between theory and algorithm. Moreover, a lightweight network is employed to guarantee the real-time of classification and the adversarial learning between feature generator and ensemble classifiers is utilized to further improve the generalization ability. The extensive experiments verify theoretical analysis and show that WMDD outperforms previous UDA methods on HMI recognition tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15366v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao-Yin Liu, Guotao Li, Xiao-Hu Zhou, Xu Liang, Zeng-Guang Hou</dc:creator>
    </item>
    <item>
      <title>Leveraging Visibility Graphs for Enhanced Arrhythmia Classification with Graph Convolutional Networks</title>
      <link>https://arxiv.org/abs/2404.15367</link>
      <description>arXiv:2404.15367v1 Announce Type: new 
Abstract: Arrhythmias, detectable via electrocardiograms (ECGs), pose significant health risks, emphasizing the need for robust automated identification techniques. Although traditional deep learning methods have shown potential, recent advances in graph-based strategies are aimed at enhancing arrhythmia detection performance. However, effectively representing ECG signals as graphs remains a challenge. This study explores graph representations of ECG signals using Visibility Graph (VG) and Vector Visibility Graph (VVG), coupled with Graph Convolutional Networks (GCNs) for arrhythmia classification. Through experiments on the MIT-BIH dataset, we investigated various GCN architectures and preprocessing parameters. The results reveal that GCNs, when integrated with VG and VVG for signal graph mapping, can classify arrhythmias without the need for preprocessing or noise removal from ECG signals. While both VG and VVG methods show promise, VG is notably more efficient. The proposed approach was competitive compared to baseline methods, although classifying the S class remains challenging, especially under the inter-patient paradigm. Computational complexity, particularly with the VVG method, required data balancing and sophisticated implementation strategies. The source code is publicly available for further research and development at https://github.com/raffoliveira/VG_for_arrhythmia_classification_with_GCN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15367v1</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rafael F. Oliveira, Gladston J. P. Moreira, Vander L. S. Freitas, Eduardo J. S. Luz</dc:creator>
    </item>
    <item>
      <title>Unmasking the Role of Remote Sensors in Comfort, Energy and Demand Response</title>
      <link>https://arxiv.org/abs/2404.15368</link>
      <description>arXiv:2404.15368v1 Announce Type: new 
Abstract: In single-zone multi-room houses (SZMRHs), temperature controls rely on a single probe near the thermostat, resulting in temperature discrepancies that cause thermal discomfort and energy waste. Augmenting smart thermostats (STs) with per-room sensors has gained acceptance by major ST manufacturers. This paper leverages additional sensory information to empirically characterize the services provided by buildings, including thermal comfort, energy efficiency, and demand response (DR). Utilizing room-level time-series data from 1,000 houses, metadata from 110,000 houses across the United States, and data from two real-world testbeds, we examine the limitations of SZMRHs and explore the potential of remote sensors. We discovered that comfortable DR durations (CDRDs) for rooms are typically 70% longer or 40% shorter than for the room with the thermostat. When averaging, rooms at the control temperature's bounds are typically deviated around -3{\deg}F to 2.5{\deg}F from the average. Moreover, in 95\% of houses, we identified rooms experiencing notably higher solar gains compared to the rest of the rooms, while 85% and 70% of houses demonstrated lower heat input and poor insulation, respectively. Lastly, it became evident that the consumption of cooling energy escalates with the increase in the number of sensors, whereas heating usage experiences fluctuations ranging from -19% to +25% This study serves as a benchmark for assessing the thermal comfort and DR services in the existing housing stock, while also highlighting the energy efficiency impacts of sensing technologies. Our approach sets the stage for more granular, precise control strategies of SZMRHs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15368v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ozan Baris Mulayim, Edson Severnini, Mario Berg\'es</dc:creator>
    </item>
    <item>
      <title>Self-Supervised Learning for User Localization</title>
      <link>https://arxiv.org/abs/2404.15370</link>
      <description>arXiv:2404.15370v1 Announce Type: new 
Abstract: Machine learning techniques have shown remarkable accuracy in localization tasks, but their dependency on vast amounts of labeled data, particularly Channel State Information (CSI) and corresponding coordinates, remains a bottleneck. Self-supervised learning techniques alleviate the need for labeled data, a potential that remains largely untapped and underexplored in existing research. Addressing this gap, we propose a pioneering approach that leverages self-supervised pretraining on unlabeled data to boost the performance of supervised learning for user localization based on CSI. We introduce two pretraining Auto Encoder (AE) models employing Multi Layer Perceptrons (MLPs) and Convolutional Neural Networks (CNNs) to glean representations from unlabeled data via self-supervised learning. Following this, we utilize the encoder portion of the AE models to extract relevant features from labeled data, and finetune an MLP-based Position Estimation Model to accurately deduce user locations. Our experimentation on the CTW-2020 dataset, which features a substantial volume of unlabeled data but limited labeled samples, demonstrates the viability of our approach. Notably, the dataset covers a vast area spanning over 646x943x41 meters, and our approach demonstrates promising results even for such expansive localization tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15370v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ankan Dash, Jingyi Gu, Guiling Wang, Nirwan Ansari</dc:creator>
    </item>
    <item>
      <title>Efficient Verification of a RADAR SoC Using Formal and Simulation-Based Methods</title>
      <link>https://arxiv.org/abs/2404.15371</link>
      <description>arXiv:2404.15371v1 Announce Type: new 
Abstract: As the demand for Internet of Things (IoT) and Human-to-Machine Interaction (HMI) increases, modern System-on-Chips (SoCs) offering such solutions are becoming increasingly complex. This intricate design poses significant challenges for verification, particularly when time-to-market is a crucial factor for consumer electronics products. This paper presents a case study based on our work to verify a complex Radio Detection And Ranging (RADAR) based SoC that performs on-chip sensing of human motion with millimetre accuracy. We leverage both formal and simulation-based methods to complement each other and achieve verification sign-off with high confidence. While employing a requirements-driven flow approach, we demonstrate the use of different verification methods to cater to multiple requirements and highlight our know-how from the project. Additionally, we used Machine Learning (ML) based methods, specifically the Xcelium ML tool from Cadence, to improve verification throughput.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15371v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aman Kumar, Mark Litterick, Samuele Candido</dc:creator>
    </item>
    <item>
      <title>Robust EEG-based Emotion Recognition Using an Inception and Two-sided Perturbation Model</title>
      <link>https://arxiv.org/abs/2404.15373</link>
      <description>arXiv:2404.15373v1 Announce Type: new 
Abstract: Automated emotion recognition using electroencephalogram (EEG) signals has gained substantial attention. Although deep learning approaches exhibit strong performance, they often suffer from vulnerabilities to various perturbations, like environmental noise and adversarial attacks. In this paper, we propose an Inception feature generator and two-sided perturbation (INC-TSP) approach to enhance emotion recognition in brain-computer interfaces. INC-TSP integrates the Inception module for EEG data analysis and employs two-sided perturbation (TSP) as a defensive mechanism against input perturbations. TSP introduces worst-case perturbations to the model's weights and inputs, reinforcing the model's elasticity against adversarial attacks. The proposed approach addresses the challenge of maintaining accurate emotion recognition in the presence of input uncertainties. We validate INC-TSP in a subject-independent three-class emotion recognition scenario, demonstrating robust performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15373v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shadi Sartipi, Mujdat Cetin</dc:creator>
    </item>
    <item>
      <title>Minimum Description Feature Selection for Complexity Reduction in Machine Learning-based Wireless Positioning</title>
      <link>https://arxiv.org/abs/2404.15374</link>
      <description>arXiv:2404.15374v1 Announce Type: new 
Abstract: Recently, deep learning approaches have provided solutions to difficult problems in wireless positioning (WP). Although these WP algorithms have attained excellent and consistent performance against complex channel environments, the computational complexity coming from processing high-dimensional features can be prohibitive for mobile applications. In this work, we design a novel positioning neural network (P-NN) that utilizes the minimum description features to substantially reduce the complexity of deep learning-based WP. P-NN's feature selection strategy is based on maximum power measurements and their temporal locations to convey information needed to conduct WP. We improve P-NN's learning ability by intelligently processing two different types of inputs: sparse image and measurement matrices. Specifically, we implement a self-attention layer to reinforce the training ability of our network. We also develop a technique to adapt feature space size, optimizing over the expected information gain and the classification capability quantified with information-theoretic measures on signal bin selection. Numerical results show that P-NN achieves a significant advantage in performance-complexity tradeoff over deep learning baselines that leverage the full power delay profile (PDP). In particular, we find that P-NN achieves a large improvement in performance for low SNR, as unnecessary measurements are discarded in our minimum description features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15374v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Myeung Suk Oh, Anindya Bijoy Das, Taejoon Kim, David J. Love, Christopher G. Brinton</dc:creator>
    </item>
    <item>
      <title>MIMO Multipath-based SLAM for Non-Ideal Reflective Surfaces</title>
      <link>https://arxiv.org/abs/2404.15375</link>
      <description>arXiv:2404.15375v1 Announce Type: new 
Abstract: Multipath-based simultaneous localization and mapping (MP-SLAM) is a well established approach to obtain position information of transmitters and receivers as well as information regarding the propagation environments in future multiple input multiple output (MIMO) communication systems. Conventional methods for MP-SLAM consider specular reflections of the radio signals occurring at smooth, flat surfaces, which are modeled by virtual anchors (VAs) that are mirror images of the physical anchors (PAs), with each VA generating a single multipath component (MPC). However, non-ideal reflective surfaces (such as walls covered by shelves or cupboards) cause dispersion effects that violate the VA model and lead to multiple MPCs that are associated to a single VA. In this paper, we introduce a Bayesian particle-based sum-product algorithm (SPA) for MP-SLAM in MIMO communications systems. Our method considers non-ideal reflective surfaces by jointly estimating the parameters of individual dispersion models for each detected surface in delay and angle domain leveraging multiple-measurement-to-feature data association. We demonstrate that the proposed SLAM method can robustly and jointly estimate the positions and dispersion extents of ideal and non-ideal reflective surfaces using numerical simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15375v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukas Wielandner, Alexander Venus, Thomas Wilding, Klaus Witrisal, Erik Leitinger</dc:creator>
    </item>
    <item>
      <title>Joint Soil and Above-Ground Biomass Characterization Using Radars</title>
      <link>https://arxiv.org/abs/2404.15508</link>
      <description>arXiv:2404.15508v1 Announce Type: new 
Abstract: Soil moisture sensing through biomass or vegetation canopy has challenged researchers, even those who use SAR sensors with penetration capabilities. This is mainly due to the imposed extra time and phase offsets on Radio Frequency (RF) signals as they travel through the canopy. These offsets depend on the vegetation canopy moisture and height, both of which are typically unknown in agricultural and forest fields. In this paper, we leverage the mobility of an unmanned aerial system (UAS) to collect spatially-diverse radar measurements, enabling the joint estimation of soil moisture, above-ground biomass moisture, and biomass height, all without assuming any calibration steps. We leverage the changes in time-of-flight (ToF) and angle-of-arrival (AoA) measurements of reflected radar signals as the UAS flies above a reflector buried under the soil. We demonstrate the effectiveness of our algorithm by simulating its performance under realistic measurement noises as well as conducting lab experiments with different types of above-ground biomass. Our simulation results conclude that our algorithm is capable of estimating volumetric soil moisture to less than 1% median absolute error (MAE), vegetation height to 11.1cm MAE, and vegetation relative permittivity to 0.32 MAE. Our experimental results demonstrate the effectiveness of the proposed method in practical scenarios for varying biomass moistures and heights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15508v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke Jacobs, Mohamad Alipour, Adam Watts, Elahe Soltanaghai</dc:creator>
    </item>
    <item>
      <title>A Reconfigurable Subarray Architecture and Hybrid Beamforming for Millimeter-Wave Dual-Function-Radar-Communication Systems</title>
      <link>https://arxiv.org/abs/2404.15750</link>
      <description>arXiv:2404.15750v1 Announce Type: new 
Abstract: Dual-function-radar-communication (DFRC) is a promising candidate technology for next-generation networks. By integrating hybrid analog-digital (HAD) beamforming into a multi-user millimeter-wave (mmWave) DFRC system, we design a new reconfigurable subarray (RS) architecture and jointly optimize the HAD beamforming to maximize the communication sum-rate and ensure a prescribed signal-to-clutter-plus-noise ratio for radar sensing. Considering the non-convexity of this problem arising from multiplicative coupling of the analog and digital beamforming, we convert the sum-rate maximization into an equivalent weighted mean-square error minimization and apply penalty dual decomposition to decouple the analog and digital beamforming. Specifically, a second-order cone program is first constructed to optimize the fully digital counterpart of the HAD beamforming. Then, the sparsity of the RS architecture is exploited to obtain a low-complexity solution for the HAD beamforming. The convergence and complexity analyses of our algorithm are carried out under the RS architecture. Simulations corroborate that, with the RS architecture, DFRC offers effective communication and sensing and improves energy efficiency by 83.4% and 114.2% with a moderate number of radio frequency chains and phase shifters, compared to the persistently- and fullyconnected architectures, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15750v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Xin Jin, Tiejun Lv, Wei Ni, Zhipeng Lin, Qiuming Zhu, Ekram Hossain, H. Vincent Poor</dc:creator>
    </item>
    <item>
      <title>Rechargeable UAV Trajectory Optimization for Real-Time Persistent Data Collection of Large-Scale Sensor Networks</title>
      <link>https://arxiv.org/abs/2404.15761</link>
      <description>arXiv:2404.15761v1 Announce Type: new 
Abstract: Continuous real-time data collection in wireless sensor networks is crucial for facilitating timely decision-making and environmental monitoring. Unmanned aerial vehicles (UAVs) have received plenty of attention for collecting data efficiently due to their high flexibility and enhanced communication ability, nonetheless, the limited onboard energy restricts UAVs' application on persistent missions, such as disaster search and rescue. In this paper, we propose a rechargeable UAV-assisted periodic data collection scheme, where the UAV replenishes energy through the wireless charging platform during the mission to provide persistent information services for the sensor nodes (SNs). Specifically, the total completion time is minimized by optimizing the trajectory of the UAV to reach the balance among the collecting time, flight time, and recharging time. However, optimally solving this problem is highly non-trivial due to the non-convex constraints and the involved integer variables. To address this issue, the formulated problem is decomposed into two subproblems, namely, UAV data collection trajectory optimization and SN clustering and UAV visiting order optimization. By exploiting the convex optimization techniques and proving the total time is non-decreasing with the cluster number, a periodic trajectory optimization algorithm based on successive convex approximation (SCA) and bisection search is proposed to solve the main problem. The simulation results show the efficiency of the proposed scheme in practical scenarios and the completion time of the proposed algorithm is on average 39% and 33% lower than the two benchmarks, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15761v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Wang, Deshi Li, Kaitao Meng</dc:creator>
    </item>
    <item>
      <title>Recent Activities of a European Union Joint Research Project on Metrology for Emerging Wireless Standards</title>
      <link>https://arxiv.org/abs/2404.15798</link>
      <description>arXiv:2404.15798v1 Announce Type: new 
Abstract: Emerging wireless technologies with Gbps connectivity, such as the 5th generation (5G) and 6th generation (6G) of mobile networks, require improved and substantiating documentation for the wireless standards concerning the radio signals, systems, transmission environments used, and the radio frequency exposures created. Current challenges faced by the telecommunications sector include the lack of accurate, fast, low-cost, and traceable methods for manufacturers to demonstrate 5G and 6G product verifications matching customer specifications. This paper gives an update on the recent research and development activities from an EU Joint Research Project entitled metrology for emerging wireless standards (MEWS) in support of the above.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15798v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.23919/AMTA58553.2023.10293283</arxiv:DOI>
      <dc:creator>Tian Hong Loh, Tas Emrah, Frederic Pythoud, Wei Fan, Djamel Allal, Akram Alomainy</dc:creator>
    </item>
    <item>
      <title>SNR Maximization and Localization for UAV-IRS-Assisted Near-Field Systems</title>
      <link>https://arxiv.org/abs/2404.15830</link>
      <description>arXiv:2404.15830v1 Announce Type: new 
Abstract: This letter introduces a novel unmanned aerial vehicle (UAV)-intelligent reflecting surface (IRS) structure into near-field localization systems to enhance the design flexibility of IRS, thereby obtaining additional performance gains. Specifically, a UAV-IRS is utilized to improve the harsh wireless environment and provide localization possibilities. To improve the localization accuracy, a joint optimization problem considering UAV position and UAV-IRS passive beamforming is formulated to maximize the receiving signal-to-noise ratio (SNR). An alternative optimization algorithm is proposed to solve the complex non-convex problem leveraging the projected gradient ascent (PGA) algorithm and the principle of minimizing the phase difference of the receiving signals. Closed-form expressions for UAV-IRS phase shift are derived to reduce the algorithm complexity. In the simulations, the proposed algorithm is compared with three different schemes and outperforms the others in both receiving SNR and localization accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15830v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanfu Zhang, Yidan Mei, Erwu Liu, Rui Wang</dc:creator>
    </item>
    <item>
      <title>Machine Learning for Pre/Post Flight UAV Rotor Defect Detection Using Vibration Analysis</title>
      <link>https://arxiv.org/abs/2404.15880</link>
      <description>arXiv:2404.15880v1 Announce Type: new 
Abstract: Unmanned Aerial Vehicles (UAVs) will be critical infrastructural components of future smart cities. In order to operate efficiently, UAV reliability must be ensured by constant monitoring for faults and failures. To this end, the work presented in this paper leverages signal processing and Machine Learning (ML) methods to analyze the data of a comprehensive vibrational analysis to determine the presence of rotor blade defects during pre and post-flight operation. With the help of dimensionality reduction techniques, the Random Forest algorithm exhibited the best performance and detected defective rotor blades perfectly. Additionally, a comprehensive analysis of the impact of various feature subsets is presented to gain insight into the factors affecting the model's classification decision process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15880v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandre Gemayel, Dimitrios Michael Manias, Abdallah Shami</dc:creator>
    </item>
    <item>
      <title>Accurate Direct Positioning in Distributed MIMO Using Delay-Doppler Channel Measurements</title>
      <link>https://arxiv.org/abs/2404.15936</link>
      <description>arXiv:2404.15936v1 Announce Type: new 
Abstract: Distributed multiple-input multiple-output (D-MIMO) is a promising technology for simultaneous communication and positioning. However, phase synchronization between multiple access points in D-MIMO is challenging, which requires methods that function without the need for phase synchronization. We therefore present a method for D-MIMO that performs direct positioning of a moving device based on the delay-Doppler characteristics of the channel state information (CSI). Our method relies on particle-filter-based Bayesian inference with a state-space model. We use recent measurements from a sub-6 GHz D-MIMO OFDM system in an industrial environment to demonstrate centimeter accuracy under partial line-of-sight (LoS) conditions and decimeter accuracy under full non-LoS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15936v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin J. B. Deutschmann, Christian Nelson, Mikael Henriksson, Gian Marti, Alva Kosasih, Nuutti Tervo, Erik Leitinger, Fredrik Tufvesson</dc:creator>
    </item>
    <item>
      <title>Soil analysis with machine-learning-based processing of stepped-frequency GPR field measurements: Preliminary study</title>
      <link>https://arxiv.org/abs/2404.15961</link>
      <description>arXiv:2404.15961v1 Announce Type: new 
Abstract: Ground Penetrating Radar (GPR) has been widely studied as a tool for extracting soil parameters relevant to agriculture and horticulture. When combined with Machine-Learning-based (ML) methods, high-resolution Stepped Frequency Countinuous Wave Radar (SFCW) measurements hold the promise to give cost effective access to depth resolved soil parameters, including at root-level depth. In a first step in this direction, we perform an extensive field survey with a tractor mounted SFCW GPR instrument. Using ML data processing we test the GPR instrument's capabilities to predict the apparent electrical conductivity (ECaR) as measured by a simultaneously recording Electromagnetic Induction (EMI) instrument. The large-scale field measurement campaign with 3472 co-registered and geo-located GPR and EMI data samples distributed over ~6600 square meters was performed on a golf course. The selected terrain benefits from a high surface homogeneity, but also features the challenge of only small, and hence hard to discern, variations in the measured soil parameter. Based on the quantitative results we suggest the use of nugget-to-sill ratio as a performance metric for the evaluation of end-to-end ML performance in the agricultural setting and discuss the limiting factors in the multi-sensor regression setting. The code is released as open source and available at https://opensource.silicon-austria.com/xuc/soil-analysis-machine-learning-stepped-frequency-gpr.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15961v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunlei Xu, Michael Pregesbauer, Naga Sravani Chilukuri, Daniel Windhager, Mahsa Yousefi, Pedro Julian, Lothar Ratschbacher</dc:creator>
    </item>
    <item>
      <title>Maximum Discrepancy Generative Regularization and Non-Negative Matrix Factorization for Single Channel Source Separation</title>
      <link>https://arxiv.org/abs/2404.15296</link>
      <description>arXiv:2404.15296v1 Announce Type: cross 
Abstract: The idea of adversarial learning of regularization functionals has recently been introduced in the wider context of inverse problems. The intuition behind this method is the realization that it is not only necessary to learn the basic features that make up a class of signals one wants to represent, but also, or even more so, which features to avoid in the representation. In this paper, we will apply this approach to the training of generative models, leading to what we call Maximum Discrepancy Generative Regularization. In particular, we apply this to problem of source separation by means of Non-negative Matrix Factorization (NMF) and present a new method for the adversarial training of NMF bases. We show in numerical experiments, both for image and audio separation, that this leads to a clear improvement of the reconstructed signals, in particular in the case where little or no strong supervision data is available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15296v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Ludvigsen, Markus Grasmair</dc:creator>
    </item>
    <item>
      <title>NMBEnet: Efficient Near-field mmWave Beam Training for Multiuser OFDM Systems Using Sub-6 GHz Pilots</title>
      <link>https://arxiv.org/abs/2404.15469</link>
      <description>arXiv:2404.15469v1 Announce Type: cross 
Abstract: Combining millimetre-wave (mmWave) communications with an extremely large-scale antenna array (ELAA) presents a promising avenue for meeting the spectral efficiency demands of the future sixth generation (6G) mobile communications. However, beam training for mmWave ELAA systems is challenged by excessive pilot overheads as well as insufficient accuracy, as the huge near-field codebook has to be accounted for. In this paper, inspired by the similarity between far-field sub-6 GHz channels and near-field mmWave channels, we propose to leverage sub-6 GHz uplink pilot signals to directly estimate the optimal near-field mmWave codeword, which aims to reduce pilot overhead and bypass the channel estimation. Moreover, we adopt deep learning to perform this dual mapping function, i.e., sub-6 GHz to mmWave, far-field to near-field, and a novel neural network structure called NMBEnet is designed to enhance the precision of beam training. Specifically, when considering the orthogonal frequency division multiplexing (OFDM) communication scenarios with high user density, correlations arise both between signals from different users and between signals from different subcarriers. Accordingly, the convolutional neural network (CNN) module and graph neural network (GNN) module included in the proposed NMBEnet can leverage these two correlations to further enhance the precision of beam training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15469v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wang Liu, Cunhua Pan, Hong Ren, Cheng-Xiang Wang, Jiangzhou Wang, Xiaohu You</dc:creator>
    </item>
    <item>
      <title>Co-existing/Cooperating Multicell Massive MIMO and Cell-Free Massive MIMO Deployments: Heuristic Designs and Performance Analysis</title>
      <link>https://arxiv.org/abs/2404.15530</link>
      <description>arXiv:2404.15530v1 Announce Type: cross 
Abstract: Cell-free massive MIMO (CF-mMIMO) represent a deeply investigated evolution from the conventional multicell co-located massive MIMO (MC-mMIMO) network deployments. Anticipating a gradual integration of CF-mMIMO systems alongside pre-existing MC-mMIMO network elements, this paper considers a scenario where both deployments coexist, in order to serve a large number of users using a shared set of frequencies. The investigation explores the impact of this coexistence on the network's downlink performance, considering various degrees of mutual cooperation, precoder selection, and power control strategies. Moreover, to take into account the effect of the proposed cooperation scenarios on the fronthaul links, this paper also provides a fronthaul-aware heuristic association algorithm between users and network elements, which permits fulfilling the fronthaul requirement on each link. The research is finally completed by extensive simulations, shedding light on the performance outcomes associated with the diverse cooperation levels and several solutions delineated in the paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15530v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano Buzzi, Carmen D'Andrea, Li Wang, Ahmet Hasim Gokceoglu, Gunnar Peters</dc:creator>
    </item>
    <item>
      <title>Dynamic Beam Coverage for Satellite Communications Aided by Movable-Antenna Array</title>
      <link>https://arxiv.org/abs/2404.15643</link>
      <description>arXiv:2404.15643v1 Announce Type: cross 
Abstract: Due to the ultra-dense constellation, efficient beam coverage and interference mitigation are crucial to low-earth orbit (LEO) satellite communication systems, while the conventional directional antennas and fixed-position antenna (FPA) arrays both have limited degrees of freedom (DoFs) in beamforming to adapt to the time-varying coverage requirement of terrestrial users. To address this challenge, we propose in this paper utilizing movable antenna (MA) arrays to enhance the satellite beam coverage and interference mitigation. Specifically, given the satellite orbit and the coverage requirement within a specific time interval, the antenna position vector (APV) and antenna weight vector (AWV) of the satellite-mounted MA array are jointly optimized over time to minimize the average signal leakage power to the interference area of the satellite, subject to the constraints of the minimum beamforming gain over the coverage area, the continuous movement of MAs, and the constant modulus of AWV. The corresponding continuous-time decision process for the APV and AWV is first transformed into a more tractable discrete-time optimization problem. Then, an alternating optimization (AO)-based algorithm is developed by iteratively optimizing the APV and AWV, where the successive convex approximation (SCA) technique is utilized to obtain locally optimal solutions during the iterations. Moreover, to further reduce the antenna movement overhead, a low-complexity MA scheme is proposed by using an optimized common APV over all time slots. Simulation results validate that the proposed MA array-aided beam coverage schemes can significantly decrease the interference leakage of the satellite compared to conventional FPA-based schemes, while the low-complexity MA scheme can achieve a performance comparable to the continuous-movement scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15643v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lipeng Zhu, Xiangyu Pi, Wenyan Ma, Zhenyu Xiao, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Telco-RAG: Navigating the Challenges of Retrieval-Augmented Language Models for Telecommunications</title>
      <link>https://arxiv.org/abs/2404.15939</link>
      <description>arXiv:2404.15939v1 Announce Type: cross 
Abstract: The application of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems in the telecommunication domain presents unique challenges, primarily due to the complex nature of telecom standard documents and the rapid evolution of the field. The paper introduces and open-sources Telco-RAG, a customized RAG framework designed to handle the specific needs of telecommunications standards, particularly 3rd Generation Partnership Project (3GPP) documents. Telco-RAG addresses the critical challenges of implementing a RAG pipeline on highly technical content, paving the way for applying LLMs in telecommunications and offering guidelines for RAG implementation in other technical domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15939v1</guid>
      <category>cs.IR</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrei-Laurentiu Bornea, Fadhel Ayed, Antonio De Domenico, Nicola Piovesan, Ali Maatouk</dc:creator>
    </item>
    <item>
      <title>Fast and Robust Expectation Propagation MIMO Detection via Preconditioned Conjugated Gradient</title>
      <link>https://arxiv.org/abs/2404.15968</link>
      <description>arXiv:2404.15968v1 Announce Type: cross 
Abstract: We study the expectation propagation (EP) algorithm for symbol detection in massive multiple-input multiple-output (MIMO) systems. The EP detector shows excellent performance but suffers from a high computational complexity due to the matrix inversion, required in each EP iteration to perform marginal inference on a Gaussian system. We propose an inversion-free variant of the EP algorithm by treating inference on the mean and variance as two separate and simpler subtasks: We study the preconditioned conjugate gradient algorithm for obtaining the mean, which can significantly reduce the complexity and increase stability by relying on the Jacobi preconditioner that proves to fit the EP characteristics very well. For the variance, we use a simple approximation based on linear regression of the Gram channel matrix. Numerical studies on the Rayleigh-fading channel and on a realistic 3GPP channel model reveal the efficiency of the proposed scheme, which offers an attractive performance-complexity tradeoff and even outperforms the original EP detector in high multi-user inference cases where the matrix inversion becomes numerically unstable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15968v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Schmid, Dominik Sulz, Laurent Schmalen</dc:creator>
    </item>
    <item>
      <title>BeSound: Bluetooth-Based Position Estimation Enhancing with Cross-Modality Distillation</title>
      <link>https://arxiv.org/abs/2404.15999</link>
      <description>arXiv:2404.15999v1 Announce Type: cross 
Abstract: Smart factories leverage advanced technologies to optimize manufacturing processes and enhance efficiency. Implementing worker tracking systems, primarily through camera-based methods, ensures accurate monitoring. However, concerns about worker privacy and technology protection make it necessary to explore alternative approaches. We propose a non-visual, scalable solution using Bluetooth Low Energy (BLE) and ultrasound coordinates. BLE position estimation offers a very low-power and cost-effective solution, as the technology is available on smartphones and is scalable due to the large number of smartphone users, facilitating worker localization and safety protocol transmission. Ultrasound signals provide faster response times and higher accuracy but require custom hardware, increasing costs. To combine the benefits of both modalities, we employ knowledge distillation (KD) from ultrasound signals to BLE RSSI data. Once the student model is trained, the model only takes as inputs the BLE-RSSI data for inference, retaining the advantages of ubiquity and low cost of BLE RSSI. We tested our approach using data from an experiment with twelve participants in a smart factory test bed environment. We obtained an increase of 11.79% in the F1-score compared to the baseline (target model without KD and trained with BLE-RSSI data only).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15999v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hymalai Bello, Sungho Suh, Bo Zhou, Paul Lukowicz</dc:creator>
    </item>
    <item>
      <title>Unimodal and Multimodal Sensor Fusion for Wearable Activity Recognition</title>
      <link>https://arxiv.org/abs/2404.16005</link>
      <description>arXiv:2404.16005v1 Announce Type: cross 
Abstract: Combining different sensing modalities with multiple positions helps form a unified perception and understanding of complex situations such as human behavior. Hence, human activity recognition (HAR) benefits from combining redundant and complementary information (Unimodal/Multimodal). Even so, it is not an easy task. It requires a multidisciplinary approach, including expertise in sensor technologies, signal processing, data fusion algorithms, and domain-specific knowledge. This Ph.D. work employs sensing modalities such as inertial, pressure (audio and atmospheric pressure), and textile capacitive sensing for HAR. The scenarios explored are gesture and hand position tracking, facial and head pattern recognition, and body posture and gesture recognition. The selected wearable devices and sensing modalities are fully integrated with machine learning-based algorithms, some of which are implemented in the embedded device, on the edge, and tested in real-time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16005v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hymalai Bello</dc:creator>
    </item>
    <item>
      <title>How to Make Money From Fresh Data: Subscription Strategies in Age-Based Systems</title>
      <link>https://arxiv.org/abs/2404.16009</link>
      <description>arXiv:2404.16009v1 Announce Type: cross 
Abstract: We consider a communication system consisting of a server that tracks and publishes updates about a time-varying data source or event, and a gossip network of users interested in closely tracking the event. The timeliness of the information is measured through the version age of information. The users wish to have their expected version ages remain below a threshold, and have the option to either rely on gossip from their neighbors or subscribe to the server directly to follow updates about the event if the former option does not meet the timeliness requirements. The server wishes to maximize its profit by increasing the number of subscribers and reducing costs associated with the frequent sampling of the event. We model the problem setup as a Stackelberg game between the server and the users, where the server commits to a frequency of sampling the event, and the users make decisions on whether to subscribe or not. As an initial work, we focus on directed networks with unidirectional flow of information and obtain the optimal equilibrium strategies for all the players. We provide simulation results to confirm the theoretical findings and provide additional insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16009v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Priyanka Kaswan, Melih Bastopcu, Sennur Ulukus, S. Rasoul Etesami, Tamer Ba\c{s}ar</dc:creator>
    </item>
    <item>
      <title>Variational Tracking and Redetection for Closely-spaced Objects in Heavy Clutter: Supplementary Materials</title>
      <link>https://arxiv.org/abs/2309.01774</link>
      <description>arXiv:2309.01774v2 Announce Type: replace 
Abstract: The non-homogeneous Poisson process (NHPP) is a widely used measurement model that allows for an object to generate multiple measurements over time. However, it can be difficult to efficiently and reliably track multiple objects under this NHPP model in scenarios with a high density of closely-spaced objects and heavy clutter. Therefore, based on the general coordinate ascent variational filtering framework, this paper presents a variational Bayes association-based NHPP tracker (VB-AbNHPP) that can efficiently perform tracking, data association, and learning of target and clutter rates with a parallelisable implementation. In addition, a variational localisation strategy is proposed, which enables rapid rediscovery of missed targets from a large surveillance area under extremely heavy clutter. This strategy is integrated into the VB-AbNHPP tracker, resulting in a robust methodology that can automatically detect and recover from track loss. This tracker demonstrates improved tracking performance compared with existing trackers in challenging scenarios, in terms of both accuracy and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01774v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runze Gan, Qing Li, Simon Godsill</dc:creator>
    </item>
    <item>
      <title>Reconfigurable Intelligent Surface Constructing 6G Near-Field Networks</title>
      <link>https://arxiv.org/abs/2403.15390</link>
      <description>arXiv:2403.15390v2 Announce Type: replace 
Abstract: Near-field propagation, particularly that enabled by reconfigurable intelligent surfaces (RIS), has emerged as a promising research topic in recent years. However, a comprehensive literature review on RIS-based near-field technologies is still lacking. This article aims to fill this gap by providing a brief overview of near-field concepts and a systematic survey of the state-of-the-art RIS-based near-field technologies. The focus is on three key aspects: the construction of ubiquitous near-field wireless propagation environments using RIS, the enabling of new near-field paradigms for 6G networks through RIS, and the challenges faced by RIS-based near-field technologies. This technical review intends to facilitate the development and innovation of RIS-based near-field technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15390v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3969/j.issn.1006-1010.20240327-0003</arxiv:DOI>
      <arxiv:journal_reference>ZHAO Yajun. Reconfigurable Intelligent Surface Constructing 6G Near-Field Networks[J]. Mobile Communications, 2024,48(4): 2-11</arxiv:journal_reference>
      <dc:creator>Yajun Zhao</dc:creator>
    </item>
    <item>
      <title>Generalized Forgetting Recursive Least Squares: Stability and Robustness Guarantees</title>
      <link>https://arxiv.org/abs/2308.04259</link>
      <description>arXiv:2308.04259v2 Announce Type: replace-cross 
Abstract: This work presents generalized forgetting recursive least squares (GF-RLS), a generalization of recursive least squares (RLS) that encompasses many extensions of RLS as special cases. First, sufficient conditions are presented for the 1) Lyapunov stability, 2) uniform Lyapunov stability, 3) global asymptotic stability, and 4) global uniform exponential stability of parameter estimation error in GF-RLS when estimating fixed parameters without noise. Second, robustness guarantees are derived for the estimation of time-varying parameters in the presence of measurement noise and regressor noise. These robustness guarantees are presented in terms of global uniform ultimate boundedness of the parameter estimation error. A specialization of this result gives a bound to the asymptotic bias of least squares estimators in the errors-in-variables problem. Lastly, a survey is presented to show how GF-RLS can be used to analyze various extensions of RLS from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.04259v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brian Lai, Dennis S. Bernstein</dc:creator>
    </item>
    <item>
      <title>EMF-Aware Power Control for Massive MIMO: Cell-Free versus Cellular Networks</title>
      <link>https://arxiv.org/abs/2311.08989</link>
      <description>arXiv:2311.08989v2 Announce Type: replace-cross 
Abstract: The impressive growth of wireless data networks has recently led to increased attention to the issue of electromagnetic pollution. Specific absorption rates and incident power densities have become popular indicators for measuring electromagnetic field (EMF) exposure. This paper tackles the problem of power control in user-centric cell-free massive multiple-input-multiple-output (CF-mMIMO) systems under EMF constraints. Specifically, the power allocation maximizing the minimum data rate across users is derived for both the uplink and the downlink under EMF constraints. The developed solution is also applied to a cellular mMIMO system and compared to other benchmark strategies. Simulation results prove that EMF safety restrictions can be easily met without jeopardizing the minimum data rate, that the CF-mMIMO outperforms the multi-cell massive MIMO deployment, and that the proposed power control strategy greatly improves the system fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.08989v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergi Liesegang, Stefano Buzzi</dc:creator>
    </item>
    <item>
      <title>MAINS: A Magnetic Field Aided Inertial Navigation System for Indoor Positioning</title>
      <link>https://arxiv.org/abs/2312.02599</link>
      <description>arXiv:2312.02599v3 Announce Type: replace-cross 
Abstract: A Magnetic field Aided Inertial Navigation System (MAINS) for indoor navigation is proposed in this paper. MAINS leverages an array of magnetometers to measure spatial variations in the magnetic field, which are then used to estimate the displacement and orientation changes of the system, thereby aiding the inertial navigation system (INS). Experiments show that MAINS significantly outperforms the stand-alone INS, demonstrating a remarkable two orders of magnitude reduction in position error. Furthermore, when compared to the state-of-the-art magnetic-field-aided navigation approach, the proposed method exhibits slightly improved horizontal position accuracy. On the other hand, it has noticeably larger vertical error on datasets with large magnetic field variations. However, one of the main advantages of MAINS compared to the state-of-the-art is that it enables flexible sensor configurations. The experimental results show that the position error after 2 minutes of navigation in most cases is less than 3 meters when using an array of 30 magnetometers. Thus, the proposed navigation solution has the potential to solve one of the key challenges faced with current magnetic-field simultaneous localization and mapping (SLAM) solutions: the very limited allowable length of the exploration phase during which unvisited areas are mapped.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02599v3</guid>
      <category>cs.RO</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuan Huang, Gustaf Hendeby, Hassen Fourati, Christophe Prieur, Isaac Skog</dc:creator>
    </item>
    <item>
      <title>Multi-Fidelity Bayesian Optimization With Across-Task Transferable Max-Value Entropy Search</title>
      <link>https://arxiv.org/abs/2403.09570</link>
      <description>arXiv:2403.09570v2 Announce Type: replace-cross 
Abstract: In many applications, ranging from logistics to engineering, a designer is faced with a sequence of optimization tasks for which the objectives are in the form of black-box functions that are costly to evaluate. For example, the designer may need to tune the hyperparameters of neural network models for different learning tasks over time. Rather than evaluating the objective function for each candidate solution, the designer may have access to approximations of the objective functions, for which higher-fidelity evaluations entail a larger cost. Existing multi-fidelity black-box optimization strategies select candidate solutions and fidelity levels with the goal of maximizing the information accrued about the optimal value or solution for the current task. Assuming that successive optimization tasks are related, this paper introduces a novel information-theoretic acquisition function that balances the need to acquire information about the current task with the goal of collecting information transferable to future tasks. The proposed method includes shared inter-task latent variables, which are transferred across tasks by implementing particle-based variational Bayesian updates. Experimental results across synthetic and real-world examples reveal that the proposed provident acquisition strategy that caters to future tasks can significantly improve the optimization efficiency as soon as a sufficient number of tasks is processed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09570v2</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunchuan Zhang, Sangwoo Park, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>DeepFunction: Deep Metric Learning-based Imbalanced Classification for Diagnosing Threaded Pipe Connection Defects using Functional Data</title>
      <link>https://arxiv.org/abs/2404.03329</link>
      <description>arXiv:2404.03329v2 Announce Type: replace-cross 
Abstract: In modern manufacturing, most of the product lines are conforming. Few products are nonconforming but with different defect types. The identification of defect types can help further root cause diagnosis of production lines. With the sensing development, signals of process variables can be collected in high resolution, which can be regarded as multichannel functional data. They have abundant information to characterize the process and help identify the defect types. Motivated by a real example from the pipe tightening process, we focus on defect classification where each sample is a multichannel functional data. However, the available samples for each defect type are limited and imbalanced. Moreover, the functions are incomplete since the pre-tightening process before the pipe tightening process is unobserved. To classify the defect samples based on imbalanced, multichannel, and incomplete functional data is very important but challenging. Thus, we propose an innovative classification framework based on deep metric learning using functional data (DeepFunction). The framework leverages the power of deep metric learning to train on imbalanced datasets. A neural network specially crafted for processing functional data is also proposed to handle multichannel and incomplete functional data. The results from a real-world case study demonstrate the superior accuracy of our framework when compared to existing benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03329v2</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yukun Xie, Juan Du, Chen Zhang</dc:creator>
    </item>
    <item>
      <title>Exponentially Weighted Moving Models</title>
      <link>https://arxiv.org/abs/2404.08136</link>
      <description>arXiv:2404.08136v2 Announce Type: replace-cross 
Abstract: An exponentially weighted moving model (EWMM) for a vector time series fits a new data model each time period, based on an exponentially fading loss function on past observed data. The well known and widely used exponentially weighted moving average (EWMA) is a special case that estimates the mean using a square loss function. For quadratic loss functions EWMMs can be fit using a simple recursion that updates the parameters of a quadratic function. For other loss functions, the entire past history must be stored, and the fitting problem grows in size as time increases. We propose a general method for computing an approximation of EWMM, which requires storing only a window of a fixed number of past samples, and uses an additional quadratic term to approximate the loss associated with the data before the window. This approximate EWMM relies on convex optimization, and solves problems that do not grow with time. We compare the estimates produced by our approximation with the estimates from the exact EWMM method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08136v2</guid>
      <category>stat.CO</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Luxenberg, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>On Target Detection in the Presence of Clutter in Joint Communication and Sensing Cellular Networks</title>
      <link>https://arxiv.org/abs/2404.12133</link>
      <description>arXiv:2404.12133v2 Announce Type: replace-cross 
Abstract: Recent works on joint communication and sensing (JCAS) cellular networks have proposed to use time division mode (TDM) and concurrent mode (CM), as alternative methods for sharing the resources between communication and sensing signals. While the performance of these JCAS schemes for object tracking and parameter estimation has been studied in previous works, their performance on target detection in the presence of clutter has not been analyzed. In this paper, we propose a detection scheme for estimating the number of targets in JCAS cellular networks that employ TDM or CM resource sharing. The proposed detection method allows for the presence of clutter and/or temporally correlated noise. This scheme is studied with respect to the JCAS trade-off parameters that allow to control the time slots in TDM and the power resources in CM allocated to sensing and communications. The performance of two fundamental transmit beamforming schemes, typical for JCAS, is compared in terms of the receiver operating characteristics curves. Our results indicate that in general the TDM scheme gives a somewhat better detection performance compared to the CM scheme, although both schemes outperform existing approaches provided that their respective trade-off parameters are tuned properly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12133v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ICSPCS58109.2023.10261147</arxiv:DOI>
      <arxiv:journal_reference>2023 16th International Conference on Signal Processing and Communication System (ICSPCS)</arxiv:journal_reference>
      <dc:creator>Julia Vinogradova, Gabor Fodor</dc:creator>
    </item>
  </channel>
</rss>
