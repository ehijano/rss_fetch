<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Oct 2024 04:00:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Distributed MPC Formation Path Following for Acoustically Communicating Underwater Vehicles</title>
      <link>https://arxiv.org/abs/2410.11959</link>
      <description>arXiv:2410.11959v1 Announce Type: new 
Abstract: We propose and analyse a model predictive control (MPC) strategy tailored for networks of underwater agents tasked with maintaining formation while following a shared path and using acoustic communication channels. The strategy accommodates both time-division and frequency-division medium access schemes, and addresses the inherent challenges of lossy and broadcast communication over acoustic media. Our approach extends an existing distributed control algorithm originally assuming standard double precision in exchanged data, and designed for synchronous, bidirectional, and reliable communication. Here we introduce adaptations for handling broadcast asynchronous communication, for mitigating packet losses, and for quantising exchanged data. These modifications are general and intended to be applicable to other distributed control schemes that were developed under idealised assumptions. Our goal is thus to help facilitating deployment also of other control schemes in practical field conditions. We provide simulation results that quantify the impact of these adaptations on the performance of the original controller, along with sensitivity analyses on how performance losses are influenced by key hyperparameters. Additionally, we characterise the data rate savings vs. control performance losses that may be achieved through tuning such hyperparameters, showcasing the feasibility of implementing the proposed strategy for practical purposes using commercially available full-duplex or half-duplex modems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11959v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emil Wengle, Damiano Varagnolo</dc:creator>
    </item>
    <item>
      <title>Model reduction, machine learning based global optimisation for large-scale steady state nonlinear systems</title>
      <link>https://arxiv.org/abs/2410.11994</link>
      <description>arXiv:2410.11994v1 Announce Type: new 
Abstract: Many engineering processes can be accurately modelled using partial differential equations (PDEs), but high dimensionality and non-convexity of the resulting systems pose limitations on their efficient optimisation. In this work, a model reduction, machine-learning methodology combining principal component analysis (PCA) and artificial neural networks (ANNs) is employed to construct a reduced surrogate model, which can then be utilised by advanced deterministic global optimisation algorithms to compute global optimal solutions with theoretical guarantees. However, such optimisation would still be time-consuming due to the high non-convexity of the activation functions inside the reduced ANN structures. To develop a computationally-efficient optimisation framework, we propose two alternative strategies: The first one is a piecewise-affine reformulation of the nonlinear ANN activation functions, while the second one is based on deep rectifier neural networks with ReLU activation function. The performance of the proposed framework is demonstrated through two illustrative case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11994v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Min Tao, Panagiotis Petsagkourakis, Jie Li, Constantinos Theodoropoulos</dc:creator>
    </item>
    <item>
      <title>On a control system on an infinite temporal tree</title>
      <link>https://arxiv.org/abs/2410.12044</link>
      <description>arXiv:2410.12044v1 Announce Type: new 
Abstract: We discuss the stochastic interpretation of a control system determined by a system of differential equations on a tree. For example, such a system on a finite tree arises after replacing the coefficients of the equation on an interval with stochastic processes in discrete time and with finitely many states. The countable number of states will correspond to a more complicated and, at the same time, more general case of an infinite tree, which is under consideration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12044v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey Buterin</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Newsvendor on a Metric</title>
      <link>https://arxiv.org/abs/2410.12134</link>
      <description>arXiv:2410.12134v1 Announce Type: new 
Abstract: We consider a fundamental generalization of the classical newsvendor problem where the seller needs to decide on the inventory of a product jointly for multiple locations on a metric as well as a fulfillment policy to satisfy the uncertain demand that arises sequentially over time after the inventory decisions have been made. To address the distributional ambiguity, we consider a distributionally robust setting where the decision-maker only knows the mean and variance of the demand, and the goal is to make inventory and fulfillment decisions to minimize the worst-case expected inventory and fulfillment cost. We design a near-optimal policy for the problem with theoretical guarantees on its performance. Our policy generalizes the classical solution of Scarf (1957), maintaining its simplicity and interpretability: it identifies a hierarchical set of clusters, assigns a ``virtual" underage cost to each cluster, then makes sure that each cluster holds at least the inventory suggested by Scarf's solution if the cluster behaved as a single point with ``virtual" underage cost. As demand arrives sequentially, our policy fulfills orders from nearby clusters, minimizing fulfilment costs, while balancing inventory consumption across the clusters to avoid depleting any single one. We show that the policy achieves a poly-logarithmic approximation. To the best of our knowledge, this is the first algorithm with provable performance guarantees. Furthermore, our numerical experiments show that the policy performs well in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12134v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ayoub Foussoul, Vineet Goyal</dc:creator>
    </item>
    <item>
      <title>Shape optimization for contact problem involving Signorini unilateral conditions</title>
      <link>https://arxiv.org/abs/2410.12315</link>
      <description>arXiv:2410.12315v1 Announce Type: new 
Abstract: This paper investigates a shape optimization problem involving the Signorini unilateral conditions in a linear elastic model, without any penalization procedure. The shape sensitivity analysis is performed using tools from convex and variational analysis such as proximal operators and the notion of twice epi-differentiability. We prove that the solution to the Signorini problem admits a directional derivative with respect to the shape which moreover coincides with the solution to another Signorini problem. Then, the shape gradient of the corresponding energy functional is explicitly characterized which allows us to perform numerical simulations to illustrate this methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12315v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aymeric Jacob de Cordemoy</dc:creator>
    </item>
    <item>
      <title>Generalized Smooth Stochastic Variational Inequalities: Almost Sure Convergence and Convergence Rates</title>
      <link>https://arxiv.org/abs/2410.12334</link>
      <description>arXiv:2410.12334v1 Announce Type: new 
Abstract: This paper focuses on solving a stochastic variational inequality (SVI) problem under relaxed smoothness assumption for a class of structured non-monotone operators. The SVI problem has attracted significant interest in the machine learning community due to its immediate application to adversarial training and multi-agent reinforcement learning. In many such applications, the resulting operators do not satisfy the smoothness assumption. To address this issue, we focus on the generalized smoothness assumption and consider two well-known stochastic methods with clipping, namely, projection and Korpelevich. For these clipped methods, we provide the first almost-sure convergence results without making any assumptions on the boundedness of either the stochastic operator or the stochastic samples. Furthermore, we provide the first in-expectation convergence rate results for these methods under a relaxed smoothness assumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12334v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniil Vankov, Angelia Nedich, Lalitha Sankar</dc:creator>
    </item>
    <item>
      <title>The Team Orienteering Problem with Service Times and Mandatory &amp; Incompatible Nodes</title>
      <link>https://arxiv.org/abs/2410.12368</link>
      <description>arXiv:2410.12368v1 Announce Type: new 
Abstract: The Team Orienteering Problem with Service Times and Mandatory &amp; Incompatible Nodes (TOP-ST-MIN) is a variant of the classic Team Orienteering Problem (TOP), which includes three novel features that stem from two real-world problems previously studied by the authors. We prove that even finding a feasible solution is NP-complete. Two versions of this variant are considered in our study. For such versions, we proposed two alternative mathematical formulations, a mixed and a compact formulations. Based on the compact formulation, we developed a Cutting-Plane Algorithm (CPA) exploiting five families of valid inequalities. Extensive computational experiments showed that the CPA outperforms CPLEX in solving the new benchmark instances, generated in such a way to evaluate the impact of the three novel features that characterise the problem. The CPA is also competitive for the TOP since it is able to solve almost the same number of instances as the state-of-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12368v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Guastalla, Roberto Aringhieri, Pierre Hosteins</dc:creator>
    </item>
    <item>
      <title>Accelerated Gradient Descent by Concatenation of Stepsize Schedules</title>
      <link>https://arxiv.org/abs/2410.12395</link>
      <description>arXiv:2410.12395v1 Announce Type: new 
Abstract: This work considers stepsize schedules for gradient descent on smooth convex objectives. We extend the existing literature and propose a unified technique for constructing stepsizes with analytic bounds for arbitrary iterations. This technique constructs new stepsize schedules by concatenating two short stepsize schedules. Using this approach, we introduce two new families of stepsize schedules, achieving a convergence rate of $O(n^{-\log_2(\sqrt 2+1)})$ with state-of-the-art constants for the objective value and gradient norm of the last iterate, respectively. Furthermore, our analytically derived stepsize schedules either match or surpass the existing best numerically computed stepsize schedules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12395v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zehao Zhang, Rujun Jiang</dc:creator>
    </item>
    <item>
      <title>Robust model predictive control for large-scale distributed parameter systems under uncertainty</title>
      <link>https://arxiv.org/abs/2410.12398</link>
      <description>arXiv:2410.12398v1 Announce Type: new 
Abstract: Control of nonlinear distributed parameter systems (DPS) under uncertainty is a meaningful task for many industrial processes. However, both intrinsic uncertainty and high dimensionality of DPS require intensive computations, while non-convexity of nonlinear systems can inhibit the computation of global optima during the control procedure. In this work, polynomial chaos expansion (PCE) was used to account for the uncertainties in quantities of interest through a systematic data collection from the high-fidelity simulator. Then the proper orthogonal decomposition (POD) method was adopted to project the high-dimensional nonlinear dynamics of the computed statistical moments/bounds onto a low-dimensional subspace, where recurrent neural networks (RNNs) were subsequently built to capture the reduced dynamics. Finally, the reduced RNNs based model predictive control (MPC) would generate a set of sequential optimisation problems, of which near global optima could be computed through the mixed integer linear programming (MILP) reformulation techniques and advanced MILP solver. The effectiveness of the proposed framework is demonstrated through two case studies: a chemical tubular reactor and a cell-immobilisation packed-bed bioreactor for the bioproduction of succinic acid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12398v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Min Tao, Ioannis Zacharopoulos, Constantinos Theodoropoulos</dc:creator>
    </item>
    <item>
      <title>A Class of Degenerate Mean Field Games, Associated FBSDEs and Master Equations</title>
      <link>https://arxiv.org/abs/2410.12404</link>
      <description>arXiv:2410.12404v1 Announce Type: new 
Abstract: In this paper, we study a class of degenerate mean field games (MFGs) with state-distribution dependent and unbounded functional diffusion coefficients. With a probabilistic method, we study the well-posedness of the forward-backward stochastic differential equations (FBSDEs) associated with the MFG and arising from the maximum principle, and estimate the corresponding Jacobian and Hessian flows. We further establish the classical regularity of the value functional $V$; in particular, we show that when the cost function is $C^3$ in the spatial and control variables and $C^2$ in the distribution argument, then the value functional is $C^1$ in time and $C^2$ in the spatial and distribution variables. As a consequence, the value functional $V$ is the unique classical solution of the degenerate MFG master equation. The typical linear-quadratic examples are studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12404v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alain Bensoussan, Ziyu Huang, Shanjian Tang, Sheung Chi Phillip Yam</dc:creator>
    </item>
    <item>
      <title>A Primal-dual algorithm for image reconstruction with ICNNs</title>
      <link>https://arxiv.org/abs/2410.12441</link>
      <description>arXiv:2410.12441v1 Announce Type: new 
Abstract: We address the optimization problem in a data-driven variational reconstruction framework, where the regularizer is parameterized by an input-convex neural network (ICNN). While gradient-based methods are commonly used to solve such problems, they struggle to effectively handle non-smoothness which often leads to slow convergence. Moreover, the nested structure of the neural network complicates the application of standard non-smooth optimization techniques, such as proximal algorithms. To overcome these challenges, we reformulate the problem and eliminate the network's nested structure. By relating this reformulation to epigraphical projections of the activation functions, we transform the problem into a convex optimization problem that can be efficiently solved using a primal-dual algorithm. We also prove that this reformulation is equivalent to the original variational problem. Through experiments on several imaging tasks, we demonstrate that the proposed approach outperforms subgradient methods in terms of both speed and stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12441v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hok Shing Wong, Matthias J. Ehrhardt, Subhadip Mukherjee</dc:creator>
    </item>
    <item>
      <title>A Robo-Advisor System: expected utility modeling via pairwise comparisons</title>
      <link>https://arxiv.org/abs/2410.12570</link>
      <description>arXiv:2410.12570v1 Announce Type: new 
Abstract: We introduce a robo-advisor system that recommends customized investment portfolios to users using an expected utility model elicited from pairwise comparison questionnaires. The robo-advisor system comprises three fundamental components. First, we employ a static preference questionnaire approach to generate questionnaires consisting of pairwise item comparisons. Next, we design three optimization-based preference elicitation approaches to estimate the nominal utility function pessimistically, optimistically, and neutrally. Finally, we compute portfolios based on the nominal utility using an expected utility maximization optimization model. We conduct a series of numerical tests on a simulated user and a number of human users to evaluate the efficiency of the proposed model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12570v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Chen, Jia Liu</dc:creator>
    </item>
    <item>
      <title>Zeroth-Order Feedback Optimization in Multi-Agent Systems: Tackling Coupled Constraints</title>
      <link>https://arxiv.org/abs/2410.12647</link>
      <description>arXiv:2410.12647v1 Announce Type: new 
Abstract: This paper investigates distributed zeroth-order feedback optimization in multi-agent systems with coupled constraints, where each agent operates its local action vector and observes only zeroth-order information to minimize a global cost function subject to constraints in which the local actions are coupled. Specifically, we employ two-point zeroth-order gradient estimation with delayed information to construct stochastic gradients, and leverage the constraint extrapolation technique and the averaging consensus framework to effectively handle the coupled constraints. We also provide convergence rate and oracle complexity results for our algorithm, characterizing its computational efficiency and scalability by rigorous theoretical analysis. Numerical experiments are conducted to validate the algorithm's effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12647v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingpeng Duan, Yujie Tang</dc:creator>
    </item>
    <item>
      <title>Best-Worst Disaggregation: An approach to the preference disaggregation problem</title>
      <link>https://arxiv.org/abs/2410.12678</link>
      <description>arXiv:2410.12678v1 Announce Type: new 
Abstract: Preference disaggregation methods in Multi-Criteria Decision-Making (MCDM) often encounter challenges related to inconsistency and cognitive biases when deriving a value function from experts' holistic preferences. This paper introduces the Best-Worst Disaggregation (BWD) method, a novel approach that integrates the principles of the Best-Worst Method (BWM) into the disaggregation framework to enhance the consistency and reliability of derived preference models. BWD employs the "consider-the-opposite" strategy from BWM, allowing experts to provide two opposite pairwise comparison vectors of alternatives. This approach reduces cognitive load and mitigates anchoring bias, possibly leading to more reliable criteria weights and attribute value functions. An optimization model is formulated to determine the most suitable additive value function to the preferences expressed by an expert. The method also incorporates a consistency analysis to quantify and improve the reliability of the judgments. Additionally, BWD is extended to handle interval-valued preferences, enhancing its applicability in situations with uncertainty or imprecise information. We also developed an approach to identify a reference set, which is used for pairwise comparisons to elicit the value functions and weights. A case study in logistics performance evaluation demonstrates the practicality and effectiveness of BWD, showing that it produces reliable rankings aligned closely with experts' preferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12678v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Brunelli, Fuqi Liang, Jafar Rezaei</dc:creator>
    </item>
    <item>
      <title>BIBO stability of port-Hamiltonian systems</title>
      <link>https://arxiv.org/abs/2410.12697</link>
      <description>arXiv:2410.12697v1 Announce Type: new 
Abstract: We study the question of when a distributed port-Hamiltonian system is bounded-input bounded-output (BIBO) stable. Exploiting the particular structure of the transfer function of these systems, we derive several sufficient conditions for BIBO stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12697v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.FA</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix L. Schwenninger, Alexander A. Wierzba</dc:creator>
    </item>
    <item>
      <title>Learnable Optimization-Based Algorithms for Low-Dose CT Reconstruction</title>
      <link>https://arxiv.org/abs/2410.11903</link>
      <description>arXiv:2410.11903v1 Announce Type: cross 
Abstract: Low-dose computed tomography (LDCT) aims to minimize the radiation exposure to patients while maintaining diagnostic image quality. However, traditional CT reconstruction algorithms often struggle with the ill-posed nature of the problem, resulting in severe image artifacts. Recent advances in optimization-based deep learning algorithms offer promising solutions to improve LDCT reconstruction. In this paper, we explore learnable optimization algorithms (LOA) for CT reconstruction, which integrate deep learning within variational models to enhance the regularization process. These methods, including LEARN++ and MAGIC, leverage dual-domain networks that optimize both image and sinogram data, significantly improving reconstruction quality. We also present proximal gradient descent and ADMM-inspired networks, which are efficient and theoretically grounded approaches. Our results demonstrate that these learnable methods outperform traditional techniques, offering enhanced artifact reduction, better detail preservation, and robust performance in clinical scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11903v1</guid>
      <category>eess.IV</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daisy Chen</dc:creator>
    </item>
    <item>
      <title>Marine spatial planning techniques with a case study on wave-powered offshore aquaculture farms</title>
      <link>https://arxiv.org/abs/2410.11926</link>
      <description>arXiv:2410.11926v1 Announce Type: cross 
Abstract: As emerging marine technologies lead to the development of new infrastructure across the ocean, they enter an environment that existing ecosystems and industries already rely on. Although necessary to provide sustainable sources of energy and food, careful planning will be important to make informed decisions and avoid conflicts. This paper examines several techniques used for marine spatial planning, an approach for analyzing and planning the use of marine resources. Using open source software including QGIS and Python, the potential for developing wave-powered offshore aquaculture farms using the RM3 wave energy converter along the Northeast coast of the United States is assessed and several feasible sites are identified. The optimal site, located at 43.7{\deg}N, 68.9{\deg}W along the coast of Maine, has a total cost for a 5-pen farm of $56.8M, annual fish yield of 676 tonnes, and a levelized cost of fish of $9.23 per kilogram. Overall trends indicate that the cost greatly decreases with distance to shore due to the greater availability of wave energy and that conflicts and environmental constraints significantly limit the number of feasible sites in this region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11926v1</guid>
      <category>physics.ao-ph</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gabriel Ewig, Arezoo Hasankhani, Eugene Won, Maha Haji</dc:creator>
    </item>
    <item>
      <title>Multiple Gaussian process models based global sensitivity analysis and efficient optimization of in vitro mRNA transcription process</title>
      <link>https://arxiv.org/abs/2410.11976</link>
      <description>arXiv:2410.11976v1 Announce Type: cross 
Abstract: The in vitro transcription (IVT) process is a critical step in RNA production. To ensure the efficiency of RNA manufacturing, it is essential to optimize and identify its key influencing factors. In this study, multiple Gaussian Process (GP) models are used to perform efficient optimization and global sensitivity analysis (GSA). Firstly, multiple GP models were constructed using the data from multiple experimental replicates, accurately capturing the complexities of the IVT process. Then GSA was conducted to determine the dominant reaction factors, specifically the concentrations of reactants NTP and Mg across all data-driven models. Concurrently, a multi-start optimization algorithm was applied to these GP models to identify optimal operational conditions that maximize RNA yields across all surrogate models. These optimized conditions are subsequently validated through additional experimental data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11976v1</guid>
      <category>q-bio.QM</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Min Tao, Adithya Nair, Ioanna Kalospyrou, Robert A Milton, Mabrouka Maamra, Zoltan Kis, Joan Cordiner, Solomon F Brown</dc:creator>
    </item>
    <item>
      <title>Parallel Batch Scheduling With Incompatible Job Families Via Constraint Programming</title>
      <link>https://arxiv.org/abs/2410.11981</link>
      <description>arXiv:2410.11981v1 Announce Type: cross 
Abstract: This paper addresses the incompatible case of parallel batch scheduling, where compatible jobs belong to the same family, and jobs from different families cannot be processed together in the same batch. Existing constraint programming (CP) models for this problem fail to synchronize the processing of the jobs within their batch, resulting in batch interruptions. In the context of the diffusion area in the semiconductor manufacturing process, these interrupted solutions would disrupt the thermal stability required for a uniform dopant distribution on the wafers. This paper proposes three new CP models that directly tackle these interruptions in the formulation, including two adaptions of existing models and a novel Redundant Synchronized (RS) model. These existing and novel models are compared on standard test cases, demonstrating the superiority of the RS model in finding optimal or near-optimal solutions quickly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11981v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jorge A. Huertas, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Optimizing Beer Glass Shapes to Minimize Heat Transfer -- New Results</title>
      <link>https://arxiv.org/abs/2410.12043</link>
      <description>arXiv:2410.12043v1 Announce Type: cross 
Abstract: This paper addresses the problem of determining the optimum shape for a beer glass that minimizes the heat transfer while the liquid is consumed, thereby keeping it cold for as long as possible. The proposed solution avoids the use of insulating materials. The glass is modeled as a body of revolution generated by a smooth curve, constructed from a material with negligible thermal resistance, but insulated at the base. The ordinary differential equation describing the problem is derived from the first law of Thermodynamics applied to a control volume encompassing the liquid. This is an inverse optimization problem, aiming to find the shape of the glass (represented by curve $S$) that minimizes the heat transfer rate. In contrast, the direct problem aims to determine the heat transfer rate for a given geometry. The solution obtained here is analytic, and the resulting function describing the relation between height ans radius of the glass, is in closed form, providing a family of optimal glass shapes that can be manufactured by conventional methods. Special attention is payed to the dimensions and the capacity of the resulting shapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12043v1</guid>
      <category>physics.pop-ph</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Cl\'audio C. Pellegrini</dc:creator>
    </item>
    <item>
      <title>Loss Landscape Characterization of Neural Networks without Over-Parametrziation</title>
      <link>https://arxiv.org/abs/2410.12455</link>
      <description>arXiv:2410.12455v1 Announce Type: cross 
Abstract: Optimization methods play a crucial role in modern machine learning, powering the remarkable empirical achievements of deep learning models. These successes are even more remarkable given the complex non-convex nature of the loss landscape of these models. Yet, ensuring the convergence of optimization methods requires specific structural conditions on the objective function that are rarely satisfied in practice. One prominent example is the widely recognized Polyak-Lojasiewicz (PL) inequality, which has gained considerable attention in recent years. However, validating such assumptions for deep neural networks entails substantial and often impractical levels of over-parametrization. In order to address this limitation, we propose a novel class of functions that can characterize the loss landscape of modern deep models without requiring extensive over-parametrization and can also include saddle points. Crucially, we prove that gradient-based optimizers possess theoretical guarantees of convergence under this assumption. Finally, we validate the soundness of our new function class through both theoretical analysis and empirical experimentation across a diverse range of deep learning models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12455v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rustem Islamov, Niccol\`o Ajroldi, Antonio Orvieto, Aurelien Lucchi</dc:creator>
    </item>
    <item>
      <title>A finite difference method with symmetry properties for the high-dimensional Bratu equation</title>
      <link>https://arxiv.org/abs/2410.12553</link>
      <description>arXiv:2410.12553v1 Announce Type: cross 
Abstract: Solving the three-dimensional (3D) Bratu equation is highly challenging due to the presence of multiple and sharp solutions. Research on this equation began in the late 1990s, but there are no satisfactory results to date. To address this issue, we introduce a symmetric finite difference method (SFDM) which embeds the symmetry properties of the solutions into a finite difference method (FDM). This SFDM is primarily used to obtain more accurate solutions and bifurcation diagrams for the 3D Bratu equation. Additionally, we propose modifying the Bratu equation by incorporating a new constraint that facilitates the construction of bifurcation diagrams and simplifies handling the turning points. The proposed method, combined with the use of sparse matrix representation, successfully solves the 3D Bratu equation on grids of up to $301^3$ points. The results demonstrate that SFDM outperforms all previously employed methods for the 3D Bratu equation. Furthermore, we provide bifurcation diagrams for the 1D, 2D, 4D, and 5D cases, and accurately identify the first turning points in all dimensions. All simulations indicate that the bifurcation diagrams of the Bratu equation on the cube domains closely resemble the well-established behavior on the ball domains described by Joseph and Lundgren [1]. Furthermore, when SFDM is applied to linear stability analysis, it yields the same largest real eigenvalue as the standard FDM despite having fewer equations and variables in the nonlinear system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12553v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Muhammad Luthfi Shahab, Hadi Susanto, Haralampos Hatzikirou</dc:creator>
    </item>
    <item>
      <title>Hamiltonian bridge: A physics-driven generative framework for targeted pattern control</title>
      <link>https://arxiv.org/abs/2410.12665</link>
      <description>arXiv:2410.12665v1 Announce Type: cross 
Abstract: Patterns arise spontaneously in a range of systems spanning the sciences, and their study typically focuses on mechanisms to understand their evolution in space-time. Increasingly, there has been a transition towards controlling these patterns in various functional settings, with implications for engineering. Here, we combine our knowledge of a general class of dynamical laws for pattern formation in non-equilibrium systems, and the power of stochastic optimal control approaches to present a framework that allows us to control patterns at multiple scales, which we dub the "Hamiltonian bridge". We use a mapping between stochastic many-body Lagrangian physics and deterministic Eulerian pattern forming PDEs to leverage our recent approach utilizing the Feynman-Kac-based adjoint path integral formulation for the control of interacting particles and generalize this to the active control of patterning fields. We demonstrate the applicability of our computational framework via numerical experiments on the control of phase separation with and without a conserved order parameter, self-assembly of fluid droplets, coupled reaction-diffusion equations and finally a phenomenological model for spatio-temporal tissue differentiation. We interpret our numerical experiments in terms of a theoretical understanding of how the underlying physics shapes the geometry of the pattern manifold, altering the transport paths of patterns and the nature of pattern interpolation. We finally conclude by showing how optimal control can be utilized to generate complex patterns via an iterative control protocol over pattern forming pdes which can be casted as gradient flows. All together, our study shows how we can systematically build in physical priors into a generative framework for pattern control in non-equilibrium systems across multiple length and time scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12665v1</guid>
      <category>cond-mat.soft</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.AI</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vishaal Krishnan, Sumit Sinha, L. Mahadevan</dc:creator>
    </item>
    <item>
      <title>Efficient Optimization Algorithms for Linear Adversarial Training</title>
      <link>https://arxiv.org/abs/2410.12677</link>
      <description>arXiv:2410.12677v1 Announce Type: cross 
Abstract: Adversarial training can be used to learn models that are robust against perturbations. For linear models, it can be formulated as a convex optimization problem. Compared to methods proposed in the context of deep learning, leveraging the optimization structure allows significantly faster convergence rates. Still, the use of generic convex solvers can be inefficient for large-scale problems. Here, we propose tailored optimization algorithms for the adversarial training of linear models, which render large-scale regression and classification problems more tractable. For regression problems, we propose a family of solvers based on iterative ridge regression and, for classification, a family of solvers based on projected gradient descent. The methods are based on extended variable reformulations of the original problem. We illustrate their efficiency in numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12677v1</guid>
      <category>stat.ML</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ant\^onio H. RIbeiro, Thomas B. Sch\"on, Dave Zahariah, Francis Bach</dc:creator>
    </item>
    <item>
      <title>Nonconvex Stochastic Bregman Proximal Gradient Method with Application to Deep Learning</title>
      <link>https://arxiv.org/abs/2306.14522</link>
      <description>arXiv:2306.14522v3 Announce Type: replace 
Abstract: Stochastic gradient methods for minimizing nonconvex composite objective functions typically rely on the Lipschitz smoothness of the differentiable part, but this assumption fails in many important problem classes like quadratic inverse problems and neural network training, leading to instability of the algorithms in both theory and practice. To address this, we propose a family of stochastic Bregman proximal gradient (SBPG) methods that only require smooth adaptivity. SBPG replaces the quadratic approximation in SGD with a Bregman proximity measure, offering a better approximation model that handles non-Lipschitz gradients in nonconvex objectives. We establish the convergence properties of vanilla SBPG and show it achieves optimal sample complexity in the nonconvex setting. Experimental results on quadratic inverse problems demonstrate SBPG's robustness in terms of stepsize selection and sensitivity to the initial point. Furthermore, we introduce a momentum-based variant, MSBPG, which enhances convergence by relaxing the mini-batch size requirement while preserving the optimal oracle complexity. We apply MSBPG to the training of deep neural networks, utilizing a polynomial kernel function to ensure smooth adaptivity of the loss function. Experimental results on benchmark datasets confirm the effectiveness and robustness of MSBPG in training neural networks. Given its negligible additional computational cost compared to SGD in large-scale optimization, MSBPG shows promise as a universal open-source optimizer for future applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14522v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Kuangyu Ding, Jingyang Li, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>A stochastic programming approach for dynamic allocation of bed capacity and assignment of patients to collaborating hospitals during pandemic outbreaks</title>
      <link>https://arxiv.org/abs/2311.15898</link>
      <description>arXiv:2311.15898v2 Announce Type: replace 
Abstract: Sustaining regular and infectious care during an infectious outbreak requires adequate management support for capacity allocation for regular and infectious patients. During the COVID-19 pandemic, hospitals faced severe challenges, including uncertainty concerning the number of infectious patients needing hospitalization and too little regional cooperation. This led to inefficient usage of healthcare capacity. To better prepare for future pandemics, we have developed a decision support system for central regional decision-making on opening and closing (regular care) hospital rooms for infectious patients and assigning new infectious patients to regional hospitals. Since the relabeling of rooms takes some lead time, we make decisions with a stochastic lookahead approach using stochastic programming with sample average approximation based on scenarios of the number of occupied infectious beds and infectious patients needing hospitalization. The lookahead approach produces high-quality decisions by measuring the impact of current decisions on future costs, such as costs for bed shortages, unused beds for infectious patients, and opening and closing rooms. Our simulation study applied to a COVID-19 scenario in the Netherlands, demonstrates that the stochastic lookahead approach outperforms a deterministic approach as well as other heuristic decision rules such as hospitals acting individually and implementing a pandemic unit, i.e., one hospital is designated to take all regional infectious patients until full. Our approach is very flexible and capable of tuning the model parameters to take into account the characteristics of future, yet unknown, pandemics, and supports sustaining regular care by minimizing the strain of infectious care on the available number of beds for regular care.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15898v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stef Baas, Sander Dijkstra, Richard J. Boucherie, Anne Zander</dc:creator>
    </item>
    <item>
      <title>Semidefinite Relaxations of the Gromov-Wasserstein Distance</title>
      <link>https://arxiv.org/abs/2312.14572</link>
      <description>arXiv:2312.14572v3 Announce Type: replace 
Abstract: The Gromov-Wasserstein (GW) distance is an extension of the optimal transport problem that allows one to match objects between incomparable spaces. At its core, the GW distance is specified as the solution of a non-convex quadratic program and is not known to be tractable to solve. In particular, existing solvers for the GW distance are only able to find locally optimal solutions. In this work, we propose a semi-definite programming (SDP) relaxation of the GW distance. The relaxation can be viewed as the Lagrangian dual of the GW distance augmented with constraints that relate to the linear and quadratic terms of transportation plans. In particular, our relaxation provides a tractable (polynomial-time) algorithm to compute globally optimal transportation plans (in some instances) together with an accompanying proof of global optimality. Our numerical experiments suggest that the proposed relaxation is strong in that it frequently computes the globally optimal solution. Our Python implementation is available at https://github.com/tbng/gwsdp.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14572v3</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyu Chen, Binh T. Nguyen, Shang Hui Koh, Yong Sheng Soh</dc:creator>
    </item>
    <item>
      <title>A diving heuristic for mixed-integer problems with unbounded semi-continuous variables</title>
      <link>https://arxiv.org/abs/2403.19411</link>
      <description>arXiv:2403.19411v2 Announce Type: replace 
Abstract: Semi-continuous decision variables arise naturally in many real-world applications. They are defined to take either value zero or any value within a specified range, and occur mainly to prevent small nonzero values in the solution. One particular challenge that can come with semi-continuous variables in practical models is that their upper bound may be large or even infinite. In this article, we briefly discuss these challenges, and present a new diving heuristic tailored for mixed-integer optimization problems with general semi-continuous variables. The heuristic is designed to work independently of whether the semi-continuous variables are bounded from above, and thus circumvents the specific difficulties that come with unbounded semi-continuous variables. We conduct extensive computational experiments on three different test sets, integrating the heuristic in an open-source MIP solver. The results indicate that this heuristic is a successful tool for finding high-quality solutions in negligible time. At the root node the primal gap is reduced by an average of 5 % up to 21 %, and considering the overall performance improvement, the primal integral is reduced by 2 % to 17 % on average.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19411v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katrin Halbig, Alexander Hoen, Ambros Gleixner, Jakob Witzig, Dieter Weninger</dc:creator>
    </item>
    <item>
      <title>Nonlinear integral extension of PID control with improved convergence of perturbed second-order dynamic systems</title>
      <link>https://arxiv.org/abs/2404.02502</link>
      <description>arXiv:2404.02502v2 Announce Type: replace 
Abstract: Nonlinear extension of the integral part of a standard proportional-integral-derivative (PID) feedback control is proposed for the perturbed second-order systems. For the matched constant perturbations, the global asymptotic stability is shown, while for Lipschitz perturbations an ultimately bounded output error is guaranteed. It is shown that the proposed control is also applicable to second-order systems extended by additional (parasitic) actuator dynamics with low-pass characteristics, thus representing a frequently encountered application case. The proposed nonlinear control is proven to outperform its linear PID counterpart during the settling phase, i.e. at convergence of the residual output error. An experimental case study of the second-order system with an additional actuator dynamics and considerable perturbations is demonstrated to confirm and benchmark the control performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02502v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Ruderman</dc:creator>
    </item>
    <item>
      <title>On the Projection-Based Convexification of Some Spectral Sets</title>
      <link>https://arxiv.org/abs/2405.14143</link>
      <description>arXiv:2405.14143v2 Announce Type: replace 
Abstract: Given a finite-dimensional real inner-product space $\mathbb{E}$ and a closed convex cone $\mathcal{K}\subseteq\mathbb{R}^n$, we call $\lambda:\mathbb{E}\to\mathcal{K}$ a spectral map if $(\mathbb{E},\mathbb{R}^n,\lambda)$ forms a generalized Fan-Theobald-von Neumann (FTvN) system (Gowda, 2019). Common examples of $\lambda$ include the eigenvalue map, the singular-value map and the characteristic map of complete and isometric hyperbolic polynomials. We call $\mathcal{S} \subseteq \mathbb{E}$ a spectral set if $\mathcal{S} := \lambda^{-1}(\mathcal{C})$ for some $\mathcal{C}\subseteq \mathbb{R}^n$. We provide projection-based characterizations of $\mathsf{clconv}\mathcal{S}$ (i.e., the closed convex hull of $\mathcal{S}$) under two settings, namely, when $\mathcal{C}$ has no invariance property and when $\mathcal{C}$ has certain invariance properties. In the former setting, our approach is based on characterizing the bi-polar set of $\mathcal{S}$, which allows us to judiciously exploit the properties of $\lambda$ via convex dualities. In the latter setting, our results complement the existing characterization of $\mathsf{clconv}\mathcal{S}$ in Jeong and Gowda (2023), and unify and extend the related results in Kim et al. (2022) established for certain special cases of $\lambda$ and $\mathcal{C}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14143v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renbo Zhao</dc:creator>
    </item>
    <item>
      <title>A penalty barrier framework for nonconvex constrained optimization</title>
      <link>https://arxiv.org/abs/2406.09901</link>
      <description>arXiv:2406.09901v2 Announce Type: replace 
Abstract: Focusing on minimization problems with structured objective function and smooth constraints, we present a flexible technique that combines the beneficial regularization effects of (exact) penalty and interior-point methods. Working in the fully nonconvex setting, a pure barrier approach requires careful steps when approaching the infeasible set, thus hindering convergence. We show how a tight integration with a penalty scheme overcomes such conservatism, does not require a strictly feasible starting point, and thus accommodates equality constraints. The crucial advancement that allows us to invoke generic (possibly accelerated) subsolvers is a marginalization step: closely related to a conjugacy operation, this step effectively merges (exact) penalty and barrier into a smooth, full domain functional object. When the penalty exactness takes effect, the generated subproblems do not suffer the ill-conditioning typical of barrier methods, nor do they exhibit the nonsmoothness of exact penalty terms. We provide a theoretical characterization of the algorithm and its asymptotic properties, deriving convergence results for fully nonconvex problems. Stronger conclusions are available for the convex setting, where optimality can be guaranteed. Illustrative examples and numerical simulations demonstrate the wide range of problems our theory and algorithm are able to cover.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09901v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto De Marchi, Andreas Themelis</dc:creator>
    </item>
    <item>
      <title>Analysis of Data Value in Stochastic Optimal Power Flow for Distribution Systems</title>
      <link>https://arxiv.org/abs/2406.13148</link>
      <description>arXiv:2406.13148v3 Announce Type: replace 
Abstract: The rise of advanced data technologies in electric power distribution systems enables operators to optimize operations but raises concerns about data security and consumer privacy. Resulting data protection mechanisms that alter or obfuscate datasets may invalidate the efficacy of data-driven decision-support tools and impact the value of these datasets to the decision-maker. This paper derives tools for distribution system operators to enrich data-driven operative decisions with information on data quality and, simultaneously, assess data usefulness in the context of this decision. To this end, we derive an AC optimal power flow model for radial distribution systems with data-informed stochastic parameters that internalize a data quality metric. We derive a tractable reformulation and discuss the marginal sensitivity of the optimal solution as a proxy for data value. Our model can capture clustered data provision, e.g., from resource aggregators, and internalize individual data quality information from each data provider. We use the IEEE 33-bus test system, examining scenarios with varying photovoltaic penetration and load scenarios, to demonstrate the application of our approach and discuss the relationship between data quality and its value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13148v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehrnoush Ghazanfariharandi, Robert Mieth</dc:creator>
    </item>
    <item>
      <title>Flow shops with reentry: The total weighted completion time objective</title>
      <link>https://arxiv.org/abs/2408.03582</link>
      <description>arXiv:2408.03582v2 Announce Type: replace 
Abstract: Flow shops are widely studied machine environments in which all jobs must visit all machines in the same order. While conventional flow shops assume that each job traverses the shop only once, many industrial environments require jobs to loop through the shop multiple times before completion. This means that after traversing the shop and completing its processing on the last machine, a job must return to the first machine and traverse the shop again until it has completed all its required loops. Such a setting, referred to as a flow shop with reentry, has numerous applications in industry, e.g., semiconductor manufacturing. The planning problem is to schedule all loops of all jobs while minimizing the total weighted completion time. In this paper, we consider reentrant flow shops with unit processing times. We show that this problem is strongly NP-hard if the number of machines is part of the input. We propose the Least Remaining Loops First (LRL) priority rule and show that it minimizes the total unweighted completion time. Then, we analyze the Weighted Least Remaining Loops First (WLRL) priority rule and show that it has a worst-case performance ratio of $(1+\sqrt{2})/2$ (about 1.2). Additionally, we present a fully polynomial time approximation scheme (FPTAS) and a pseudo-polynomial time algorithm if the number of machines in the flow shop is fixed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03582v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maximilian von Aspern, Felix Buld, Nicklas Klein, Michael Pinedo</dc:creator>
    </item>
    <item>
      <title>ResQPASS: an algorithm for bounded variable linear least squares with asymptotic Krylov convergence</title>
      <link>https://arxiv.org/abs/2302.13616</link>
      <description>arXiv:2302.13616v4 Announce Type: replace-cross 
Abstract: We present the Residual Quadratic Programming Active-Set Subspace (ResQPASS) method that solves large-scale linear least-squares problems with bound constraints on the variables. The problem is solved by creating a series of small problems of increasing size by projecting onto the basis of residuals. Each projected problem is solved by the active-set method for convex quadratic programming, warm-started with a working set and solution from the previous problem. The method coincides with conjugate gradients (CG) or, equivalently, LSQR when none of the constraints is active. When only a few constraints are active the method converges, after a few initial iterations, like CG and LSQR. An analysis links the convergence to an asymptotic Krylov subspace. We also present an efficient implementation where QR factorizations of the projected problems are updated over the inner iterations and Cholesky the outer iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.13616v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bas Symoens, Wim Vanroose</dc:creator>
    </item>
    <item>
      <title>A quantum central path algorithm for linear optimization</title>
      <link>https://arxiv.org/abs/2311.03977</link>
      <description>arXiv:2311.03977v2 Announce Type: replace-cross 
Abstract: We propose a novel quantum algorithm for solving linear optimization problems by quantum-mechanical simulation of the central path. While interior point methods follow the central path with an iterative algorithm that works with successive linearizations of the perturbed KKT conditions, we perform a single simulation working directly with the nonlinear complementarity equations. This approach yields an algorithm for solving linear optimization problems involving $m$ constraints and $n$ variables to $\varepsilon$-optimality using $\mathcal{O} \left( \sqrt{m + n} \frac{R_{1}}{\varepsilon}\right)$ queries to an oracle that evaluates a potential function, where $R_{1}$ is an $\ell_{1}$-norm upper bound on the size of the optimal solution. In the standard gate model (i.e., without access to quantum RAM) our algorithm can obtain highly-precise solutions to LO problems using at most $$\mathcal{O} \left( \sqrt{m + n} \textsf{nnz} (A) \frac{R_1}{\varepsilon}\right)$$ elementary gates, where $\textsf{nnz} (A)$ is the total number of non-zero elements found in the constraint matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03977v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brandon Augustino, Jiaqi Leng, Giacomo Nannicini, Tam\'as Terlaky, Xiaodi Wu</dc:creator>
    </item>
    <item>
      <title>Robust Market Convergence: From Discrete to Continuous Time</title>
      <link>https://arxiv.org/abs/2402.16108</link>
      <description>arXiv:2402.16108v3 Announce Type: replace-cross 
Abstract: Continuous time financial market models are often motivated as scaling limits of discrete time models. The objective of this paper is to establish such a connection for a robust framework. More specifically, we consider discrete time models that are parameterized by Markovian transition kernels, and a continuous time framework with drift and volatility uncertainty, again parameterized in a Markovian way. Our main result is a limit theory that establishes convergence of the uncertainty sets in the Hausdorff metric topology and weak convergence of the associated worst-case expectations. Furthermore, we discuss a structure preservation property of certain approximations. Namely, we establish the convergence of discrete to continuous time robust superhedging prices for some complete robust market models. As illustration of our main results, we use the idea of Kushner's Markov chain approximation method and provide a recursive algorithm for the computation of continuous time robust superhedging prices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16108v3</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Criens</dc:creator>
    </item>
    <item>
      <title>Clearing time randomization and transaction fees for auction market design</title>
      <link>https://arxiv.org/abs/2405.09764</link>
      <description>arXiv:2405.09764v2 Announce Type: replace-cross 
Abstract: Flaws of a continuous limit order book mechanism raise the question of whether a continuous trading session and a periodic auction session would bring better efficiency. This paper wants to go further in designing a periodic auction when both a continuous market and a periodic auction market are available to traders. In a periodic auction, we discover that a strategic trader could take advantage of the accumulated information available along the auction duration by arriving at the latest moment before the auction closes, increasing the price impact on the market. Such price impact moves the clearing price away from the efficient price and may disturb the efficiency of a periodic auction market. We thus propose and quantify the effect of two remedies to mitigate these flaws: randomizing the auction's closing time and optimally designing a transaction fees policy for both the strategic traders and other market participants. Our results show that these policies encourage a strategic trader to send their orders earlier to enhance the efficiency of the auction market, illustrated by data extracted from Alphabet and Apple stocks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09764v2</guid>
      <category>q-fin.TR</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thibaut Mastrolia, Tianrui Xu</dc:creator>
    </item>
    <item>
      <title>Adversarial Training of Two-Layer Polynomial and ReLU Activation Networks via Convex Optimization</title>
      <link>https://arxiv.org/abs/2405.14033</link>
      <description>arXiv:2405.14033v2 Announce Type: replace-cross 
Abstract: Training neural networks which are robust to adversarial attacks remains an important problem in deep learning, especially as heavily overparameterized models are adopted in safety-critical settings. Drawing from recent work which reformulates the training problems for two-layer ReLU and polynomial activation networks as convex programs, we devise a convex semidefinite program (SDP) for adversarial training of two-layer polynomial activation networks and prove that the convex SDP achieves the same globally optimal solution as its nonconvex counterpart. The convex SDP is observed to improve robust test accuracy against $\ell_\infty$ attacks relative to the original convex training formulation on multiple datasets. Additionally, we present scalable implementations of adversarial training for two-layer polynomial and ReLU networks which are compatible with standard machine learning libraries and GPU acceleration. Leveraging these implementations, we retrain the final two fully connected layers of a Pre-Activation ResNet-18 model on the CIFAR-10 dataset with both polynomial and ReLU activations. The two `robustified' models achieve significantly higher robust test accuracies against $\ell_\infty$ attacks than a Pre-Activation ResNet-18 model trained with sharpness-aware minimization, demonstrating the practical utility of convex adversarial training on large-scale problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14033v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Kuelbs, Sanjay Lall, Mert Pilanci</dc:creator>
    </item>
    <item>
      <title>Increasing Both Batch Size and Learning Rate Accelerates Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2409.08770</link>
      <description>arXiv:2409.08770v3 Announce Type: replace-cross 
Abstract: The performance of mini-batch stochastic gradient descent (SGD) strongly depends on setting the batch size and learning rate to minimize the empirical loss in training the deep neural network. In this paper, we present theoretical analyses of mini-batch SGD with four schedulers: (i) constant batch size and decaying learning rate scheduler, (ii) increasing batch size and decaying learning rate scheduler, (iii) increasing batch size and increasing learning rate scheduler, and (iv) increasing batch size and warm-up decaying learning rate scheduler. We show that mini-batch SGD using scheduler (i) does not always minimize the expectation of the full gradient norm of the empirical loss, whereas it does using any of schedulers (ii), (iii), and (iv). Furthermore, schedulers (iii) and (iv) accelerate mini-batch SGD. The paper also provides numerical results of supporting analyses showing that using scheduler (iii) or (iv) minimizes the full gradient norm of the empirical loss faster than using scheduler (i) or (ii).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08770v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hikaru Umeda, Hideaki Iiduka</dc:creator>
    </item>
    <item>
      <title>How Transformers Implement Induction Heads: Approximation and Optimization Analysis</title>
      <link>https://arxiv.org/abs/2410.11474</link>
      <description>arXiv:2410.11474v2 Announce Type: replace-cross 
Abstract: Transformers have demonstrated exceptional in-context learning capabilities, yet the theoretical understanding of the underlying mechanisms remain limited. A recent work (Elhage et al., 2021) identified a "rich" in-context mechanism known as induction head, contrasting with "lazy" $n$-gram models that overlook long-range dependencies. In this work, we provide both approximation and optimization analyses of how transformers implement induction heads. In the approximation analysis, we formalize both standard and generalized induction head mechanisms, and examine how transformers can efficiently implement them, with an emphasis on the distinct role of each transformer submodule. For the optimization analysis, we study the training dynamics on a synthetic mixed target, composed of a 4-gram and an in-context 2-gram component. This setting enables us to precisely characterize the entire training process and uncover an {\em abrupt transition} from lazy (4-gram) to rich (induction head) mechanisms as training progresses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11474v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingze Wang, Ruoxi Yu, Weinan E, Lei Wu</dc:creator>
    </item>
  </channel>
</rss>
