<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.ao-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.ao-ph</link>
    <description>physics.ao-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.ao-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Jun 2025 01:47:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Comparing the dynamics of idealized squall lines between NWP and LES models</title>
      <link>https://arxiv.org/abs/2506.19435</link>
      <description>arXiv:2506.19435v1 Announce Type: new 
Abstract: Both Numerical Weather Prediction (NWP) models and Large-Eddy Simulation (LES) models are used to simulate convective systems, such as squall lines, but with different purposes. NWP models aim for the most accurate weather forecasts, whereas LES models are typically used to advance our understanding of physical processes. Therefore, these types of models differ in their design. With increasing computer power, the domain sizes and resolutions of these models converge, which raises the question if the model results also converge. We investigated an idealized squall line with the NWP model ICON (ICOsahedral Non-hydrostatic) and the LES model MicroHH. These models differ in their design, mainly because ICON solves the compressible equations on a triangular grid, while MicroHH solves the anelastic equations on a regular grid. The case setup, including resolution, domain size, boundary conditions, and microphysics scheme, is aligned between the models. The models simulate the same squall-line structure and circulation pattern in simulations with both warm and ice microphysics. However, there are quantitative differences with MicroHH having a more intense squall-line circulation than ICON at all resolutions (1 km, 500 m, and 250 m), mainly because MicroHH has less numerical diffusion. The magnitude of the differences is sensitive to the advection scheme and the resolution and less sensitive to the formulation of turbulent diffusion. The quantitative differences between the models across resolutions highlight the importance of model physics and numerics, whereas the good qualitative agreement gives confidence that insights from LES can be applied in NWP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19435v1</guid>
      <category>physics.ao-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mirjam Tijhuis, Axel Seifert, Alberto de Lozar, Bart J. H. van Stratum, Chiel C. van Heerwaarden</dc:creator>
    </item>
    <item>
      <title>Extreme Learning Machines for Exoplanet Simulations: A Faster, Lightweight Alternative to Deep Learning</title>
      <link>https://arxiv.org/abs/2506.19679</link>
      <description>arXiv:2506.19679v1 Announce Type: cross 
Abstract: Increasing resolution and coverage of astrophysical and climate data necessitates increasingly sophisticated models, often pushing the limits of computational feasibility. While emulation methods can reduce calculation costs, the neural architectures typically used--optimised via gradient descent--are themselves computationally expensive to train, particularly in terms of data generation requirements. This paper investigates the utility of the Extreme Learning Machine (ELM) as a lightweight, non-gradient-based machine learning algorithm for accelerating complex physical models.
  We evaluate ELM surrogate models in two test cases with different data structures: (i) sequentially-structured data, and (ii) image-structured data. For test case (i), where the number of samples $N$ &gt;&gt; the dimensionality of input data $d$, ELMs achieve remarkable efficiency, offering a 100,000$\times$ faster training time and a 40$\times$ faster prediction speed compared to a Bi-Directional Recurrent Neural Network (BIRNN), whilst improving upon BIRNN test performance. For test case (ii), characterised by $d &gt;&gt; N$ and image-based inputs, a single ELM was insufficient, but an ensemble of 50 individual ELM predictors achieves comparable accuracy to a benchmark Convolutional Neural Network (CNN), with a 16.4$\times$ reduction in training time, though costing a 6.9$\times$ increase in prediction time. We find different sample efficiency characteristics between the test cases: in test case (i) individual ELMs demonstrate superior sample efficiency, requiring only 0.28% of the training dataset compared to the benchmark BIRNN, while in test case (ii) the ensemble approach requires 78% of the data used by the CNN to achieve comparable results--representing a trade-off between sample efficiency and model complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19679v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <category>physics.ao-ph</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tara P. A. Tahseen, Lu\'is F. Sim\~oes, Kai Hou Yip, Nikolaos Nikolaou, Jo\~ao M. Mendon\c{c}a, Ingo P. Waldmann</dc:creator>
    </item>
  </channel>
</rss>
