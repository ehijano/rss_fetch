<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Dec 2024 05:00:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Automatic Differentiation: Inverse Accumulation Mode</title>
      <link>https://arxiv.org/abs/2411.18786</link>
      <description>arXiv:2411.18786v1 Announce Type: new 
Abstract: We show that, under certain circumstances, it is possible to automatically compute Jacobian-inverse-vector and Jacobian-inverse-transpose-vector products about as efficiently as Jacobian-vector and Jacobian-transpose-vector products. The key insight is to notice that the Jacobian corresponding to the use of one basis function is of a form whose sparsity is invariant to inversion. The main restriction of the method is a constraint on the number of active variables, which suggests a variety of techniques or generalization to allow the constraint to be enforced or relaxed. This technique has the potential to allow the efficient direct calculation of Newton steps as well as other numeric calculations of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18786v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Barak A. Pearlmutter, Jeffrey Mark Siskind</dc:creator>
    </item>
    <item>
      <title>Computation of the exponential function of matrices by a formula without oscillatory integrals on infinite intervals</title>
      <link>https://arxiv.org/abs/2411.19086</link>
      <description>arXiv:2411.19086v1 Announce Type: new 
Abstract: We propose a quadrature-based formula for computing the exponential function of matrices with a non-oscillatory integral on an infinite interval and an oscillatory integral on a finite interval. In the literature, existing quadrature-based formulas are based on the inverse Laplace transform or the Fourier transform. We show these expressions are essentially equivalent in terms of complex integrals and choose the former as a starting point to reduce computational cost. By choosing a simple integral path, we derive an integral expression mentioned above. Then, we can easily apply the double-exponential formula and the Gauss-Legendre formula, which have rigorous error bounds. As numerical experiments show, the proposed formula outperforms the existing formulas when the imaginary parts of the eigenvalues of matrices have large absolute values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19086v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masato Suzuki, Ken'ichiro Tanaka</dc:creator>
    </item>
    <item>
      <title>Numerical analysis of a constrained strain energy minimization problem</title>
      <link>https://arxiv.org/abs/2411.19089</link>
      <description>arXiv:2411.19089v1 Announce Type: new 
Abstract: We consider a setting in which an evolving surface is implicitly characterized as the zero level of a level set function. Such an implicit surface does not encode any information about the path of a single point on the evolving surface. In the literature different approaches for determining a velocity that induces corresponding paths of points on the surface have been proposed. One of these is based on minimization of the strain energy functional. This then leads to a constrained minimization problem, which has a corresponding equivalent formulation as a saddle point problem. The main topic of this paper is a detailed analysis of this saddle point problem and of a finite element discretization of this problem. We derive well-posedness results for the continuous and discrete problems and optimal error estimates for a finite element discretization that uses standard $H^1$-conforming finite element spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19089v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tilman Aleman, Arnold Reusken</dc:creator>
    </item>
    <item>
      <title>Bound-preserving and entropy stable enriched Galerkin methods for nonlinear hyperbolic equations</title>
      <link>https://arxiv.org/abs/2411.19160</link>
      <description>arXiv:2411.19160v1 Announce Type: new 
Abstract: In this paper, we develop monolithic limiting techniques for enforcing nonlinear stability constraints in enriched Galerkin (EG) discretizations of nonlinear scalar hyperbolic equations. To achieve local mass conservation and gain control over the cell averages, the space of continuous (multi-)linear finite element approximations is enriched with piecewise-constant functions. The resulting spatial semi-discretization has the structure of a variational multiscale method. For linear advection equations, it is inherently stable but generally not bound preserving. To satisfy discrete maximum principles and ensure entropy stability in the nonlinear case, we use limiters adapted to the structure of our locally conservative EG method. The cell averages are constrained using a flux limiter, while the nodal values of the continuous component are constrained using a clip-and-scale limiting strategy for antidiffusive element contributions. The design and analysis of our new algorithms build on recent advances in the fields of convex limiting and algebraic entropy fixes for finite element methods. In addition to proving the claimed properties of the proposed approach, we conduct numerical studies for two-dimensional nonlinear hyperbolic problems. The numerical results demonstrate the ability of our limiters to prevent violations of the imposed constraints, while preserving the optimal order of accuracy in experiments with smooth solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19160v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dmitri Kuzmin, Sanghyun Lee, Yi-Yung Yang</dc:creator>
    </item>
    <item>
      <title>A simple universal algorithm for high-dimensional integration</title>
      <link>https://arxiv.org/abs/2411.19164</link>
      <description>arXiv:2411.19164v1 Announce Type: new 
Abstract: We present a simple universal algorithm for high-dimensional integration which has the optimal error rate (independent of the dimension) in all weighted Korobov classes both in the randomized and the deterministic setting. Our theoretical findings are complemented by numerical tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19164v1</guid>
      <category>math.NA</category>
      <category>cs.CC</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takashi Goda, David Krieg</dc:creator>
    </item>
    <item>
      <title>Estimating the numerical range with a Krylov subspace</title>
      <link>https://arxiv.org/abs/2411.19165</link>
      <description>arXiv:2411.19165v1 Announce Type: new 
Abstract: Krylov subspace methods are a powerful tool for efficiently solving high-dimensional linear algebra problems. In this work, we study the approximation quality that a Krylov subspace provides for estimating the numerical range of a matrix. In contrast to prior results, which often depend on the gaps between eigenvalues, our estimates depend only on the dimensions of the matrix and Krylov subspace, and the conditioning of the eigenbasis of the matrix. In addition, we provide nearly matching lower bounds for our estimates, illustrating the tightness of our arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19165v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cecilia Chen, John Urschel</dc:creator>
    </item>
    <item>
      <title>Exponential integrator Fourier Galerkin methods for semilinear parabolic equations</title>
      <link>https://arxiv.org/abs/2411.19265</link>
      <description>arXiv:2411.19265v1 Announce Type: new 
Abstract: In this paper, in order to improve the spatial accuracy, the exponential integrator Fourier Galerkin method (EIFG) is proposed for solving semilinear parabolic equations in rectangular domains. In this proposed method, the spatial discretization is first carried out by the Fourier-based Galerkin approximation, and then the time integration of the resulting semi-discrete system is approximated by the explicit exponential Runge-Kutta approach, which leads to the fully-discrete numerical solution. With certain regularity assumptions on the model problem, error estimate measured in $H^2$-norm is explicitly derived for EIFG method with two RK stages. Several two and three dimensional examples are shown to demonstrate the excellent performance of EIFG method, which are coincident to the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19265v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianguo Huang, Yuejin Xu</dc:creator>
    </item>
    <item>
      <title>Performance Evaluation of Single-step Explicit Exponential Integration Methods on Stiff Ordinary Differential Equations</title>
      <link>https://arxiv.org/abs/2411.19374</link>
      <description>arXiv:2411.19374v1 Announce Type: new 
Abstract: Stiff systems of ordinary differential equations (ODEs) arise in a wide range of scientific and engineering disciplines and are traditionally solved using implicit integration methods due to their stability and efficiency. However, these methods are computationally expensive, particularly for applications requiring repeated integration, such as parameter estimation, Bayesian inference, neural ODEs, physics-informed neural networks, and MeshGraphNets. Explicit exponential integration methods have been proposed as a potential alternative, leveraging the matrix exponential to address stiffness without requiring nonlinear solvers. This study evaluates several state-of-the-art explicit single-step exponential schemes against classical implicit methods on benchmark stiff ODE problems, analyzing their accuracy, stability, and scalability with step size. Despite their initial appeal, our results reveal that explicit exponential methods significantly lag behind implicit schemes in accuracy and scalability for stiff ODEs. The backward Euler method consistently outperformed higher-order exponential methods in accuracy at small step sizes, with none surpassing the accuracy of the first-order integrating factor Euler method. Exponential methods fail to improve upon first-order accuracy, revealing the integrating factor Euler method as the only reliable choice for repeated, inexpensive integration in applications such as neural ODEs and parameter estimation. This study exposes the limitations of explicit exponential methods and calls for the development of improved algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19374v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Colby Fronk, Linda Petzold</dc:creator>
    </item>
    <item>
      <title>Updating Katz centrality by counting walks</title>
      <link>https://arxiv.org/abs/2411.19560</link>
      <description>arXiv:2411.19560v1 Announce Type: new 
Abstract: We develop efficient and effective strategies for the update of Katz centralities after node and edge removal in simple graphs. We provide explicit formulas for the ``loss of walks" a network suffers when nodes/edges are removed, and use these to inform our algorithms. The theory builds on the newly introduced concept of $\cF$-avoiding first-passage walks. Further, bounds on the change of total network communicability are also derived. Extensive numerical experiments on synthetic and real-world networks complement our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19560v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SI</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesca Arrigo, Daniele Bertaccini, Alessandro Filippo</dc:creator>
    </item>
    <item>
      <title>Cut-edge centralities in an undirected graph</title>
      <link>https://arxiv.org/abs/2411.19603</link>
      <description>arXiv:2411.19603v1 Announce Type: new 
Abstract: A centrality measure of the cut-edges of an undirected graph, given in [Altafini et al.~SIMAX 2023] and based on Kemeny's constant, is revisited. A numerically more stable expression is given to compute this measure, and an explicit expression is provided for some classes of graphs, including one-path graphs and trees formed by three or more branches. These results theoretically confirm the good physical behaviour of this centrality measure, experimentally observed in [Altafini et al.~SIMAX 2023]. Numerical tests are reported to check the stability and to confirm the good physical behaviour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19603v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dario Bini, Guy Latouche, Steve Kirkland, Beatrice Meini</dc:creator>
    </item>
    <item>
      <title>Unified discontinuous Galerkin analysis of a thermo/poro-viscoelasticity model</title>
      <link>https://arxiv.org/abs/2411.19610</link>
      <description>arXiv:2411.19610v1 Announce Type: new 
Abstract: We present and analyze a discontinuous Galerkin method for the numerical modeling of a Kelvin-Voigt thermo/poro-viscoelastic problem. We present the derivation of the model, and we develop a stability analysis in the continuous setting that holds both for the full inertial and quasi-static problems and that is robust with respect to most of the physical parameters of the problem. For spatial discretization, we propose an arbitrary-order weighted symmetric interior penalty scheme that supports general polytopal grids and is robust with respect to strong heterogeneities in the model coefficients. For the semi-discrete problem, we prove the extension of the stability result demonstrated in the continuous setting. A wide set of numerical simulations is presented to assess the convergence and robustness properties of the proposed method. Moreover, we test the scheme with literature and physically sound test cases for proof-of-concept applications in the geophysical context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19610v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano Bonetti, Mattia Corti</dc:creator>
    </item>
    <item>
      <title>Offline-online approximation of multiscale eigenvalue problems with random defects</title>
      <link>https://arxiv.org/abs/2411.19614</link>
      <description>arXiv:2411.19614v1 Announce Type: new 
Abstract: In this paper, we consider an elliptic eigenvalue problem with multiscale, randomly perturbed coefficients. For an efficient and accurate approximation of the solutions for many different realizations of the coefficient, we propose a computational multiscale method in the spirit of the Localized Orthogonal Decomposition (LOD) method together with an offline-online strategy similar to [M{\aa}lqvist, Verf\"urth, ESIAM Math. Model. Numer. Anal., 56(1):237-260, 2022]. The offline phase computes and stores local contributions to the LOD stiffness matrix for selected defect configurations. Given any perturbed coefficient, the online phase combines the pre-computed quantities in an efficient manner. We further propose a modification in the online phase, for which numerical results indicate enhanced performances for moderate and high defect probabilities. We show rigorous a priori error estimates for eigenfunctions as well as eigenvalues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19614v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dilini Kolombage, Barbara Verf\"urth</dc:creator>
    </item>
    <item>
      <title>The lifex library version 2.0</title>
      <link>https://arxiv.org/abs/2411.19624</link>
      <description>arXiv:2411.19624v1 Announce Type: new 
Abstract: This article presents updates to lifex [Africa, SoftwareX (2022)], a C++ library for high-performance finite element simulations of multiphysics, multiscale and multidomain problems. In this release, we introduce an additional intergrid transfer method for non-matching multiphysics coupling on the same domain, significantly optimize nearest-neighbor point searches and interface coupling utilities, extend the support for 2D and mixed-dimensional problems, and provide improved facilities for input/output and simulation serialization and restart. These advancements also propagate to the previously released modules of lifex specifically designed for cardiac modeling and simulation, namely lifex-fiber [Africa et al., BMC Bioinformatics (2023)], lifex-ep [Africa et al., BMC Bioinformatics (2023)] and lifex-cfd [Africa et al., Computer Physics Communications (2024)]. The changes introduced in this release aim at consolidating lifex's position as a valuable and versatile tool for the simulation of multiphysics systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19624v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michele Bucelli</dc:creator>
    </item>
    <item>
      <title>A nonconservative macroscopic traffic flow model in a two-dimensional urban-porous city</title>
      <link>https://arxiv.org/abs/2411.19625</link>
      <description>arXiv:2411.19625v1 Announce Type: new 
Abstract: In this paper we propose a novel traffic flow model based on understanding the city as a porous media, this is, streets and building-blocks characterizing the urban landscape are seen now as the fluid-phase and the solid-phase of a porous media, respectively. Moreover, based in the interchange of mass in the porous media models, we can model the interchange of cars between streets and off-street parking-spaces. Therefore, our model is not a standard conservation law, being formulated as the coupling of a non-stationary convection-diffusion-reaction PDE with a Darcy-Brinkman-Forchheimer PDE system. To solve this model, the classical Galerkin P1 finite element method combined with an explicit time marching scheme of strong stability-preserving type was enough to stabilize our numerical solutions. Numerical experiences on an urban-porous domain inspired by the city of Guadalajara (Mexico) allow us to simulate the influence of the porosity terms on the traffic speed, the traffic flow at rush-valley hours, and the streets congestions due to the lack of parking spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19625v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>N. Garcia-Chan, L. J. Alvarez-Vazquez, A. Martinez, M. E. Vazquez-Mendez</dc:creator>
    </item>
    <item>
      <title>PACMANN: Point Adaptive Collocation Method for Artificial Neural Networks</title>
      <link>https://arxiv.org/abs/2411.19632</link>
      <description>arXiv:2411.19632v1 Announce Type: new 
Abstract: Physics-Informed Neural Networks (PINNs) are an emerging tool for approximating the solution of Partial Differential Equations (PDEs) in both forward and inverse problems. PINNs minimize a loss function which includes the PDE residual determined for a set of collocation points. Previous work has shown that the number and distribution of these collocation points have a significant influence on the accuracy of the PINN solution. Therefore, the effective placement of these collocation points is an active area of research. Specifically, adaptive collocation point sampling methods have been proposed, which have been reported to scale poorly to higher dimensions. In this work, we address this issue and present the Point Adaptive Collocation Method for Artificial Neural Networks (PACMANN). Inspired by classic optimization problems, this approach incrementally moves collocation points toward regions of higher residuals using gradient-based optimization algorithms guided by the gradient of the squared residual. We apply PACMANN for forward and inverse problems, and demonstrate that this method matches the performance of state-of-the-art methods in terms of the accuracy/efficiency tradeoff for the low-dimensional problems, while outperforming available approaches for high-dimensional problems; the best performance is observed for the Adam optimizer. Key features of the method include its low computational cost and simplicity of integration in existing physics-informed neural network pipelines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19632v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Coen Visser, Alexander Heinlein, Bianca Giovanardi</dc:creator>
    </item>
    <item>
      <title>A posteriori error analysis of a mixed FEM for the coupled Brinkman-Forchheimer/Darcy problem</title>
      <link>https://arxiv.org/abs/2411.19695</link>
      <description>arXiv:2411.19695v1 Announce Type: new 
Abstract: We consider a mixed variational formulation recently proposed for the coupling of the Brinkman--Forchheimer and Darcy equations and develop the first reliable and efficient residual-based a posteriori error estimator for the 2D version of the associated conforming mixed finite element scheme. For the reliability analysis, due to the nonlinear nature of the problem, we make use of the inf-sup condition and the strong monotonicity of the operators involved, along with a stable Helmholtz decomposition in Hilbert spaces and local approximation properties of the Raviart--Thomas and Cl\'ement interpolants. On the other hand, inverse inequalities, the localization technique through bubble functions, and known results from previous works are the main tools yielding the efficiency estimate. Finally, several numerical examples confirming the theoretical properties of the estimator and illustrating the performance of the associated adaptive algorithms are reported. In particular, the case of flow through a heterogeneous porous medium is considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19695v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergio Caucao, Paulo Z\'u\~niga</dc:creator>
    </item>
    <item>
      <title>Higher order error estimates for regularization of inverse problems under non-additive noise</title>
      <link>https://arxiv.org/abs/2411.19736</link>
      <description>arXiv:2411.19736v1 Announce Type: new 
Abstract: In this work we derive higher order error estimates for inverse problems distorted by non-additive noise, in terms of Bregman distances. The results are obtained by means of a novel source condition, inspired by the dual problem. Specifically, we focus on variational regularization having the Kullback-Leibler divergence as data-fidelity, and a convex penalty term. In this framework, we provide an interpretation of the new source condition, and present error estimates also when a variational formulation of the source condition is employed. We show that this approach can be extended to variational regularization that incorporates more general convex data fidelities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19736v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diana-Elena Mirciu, Elena Resmerita</dc:creator>
    </item>
    <item>
      <title>Explicit error bounds of the SE and DE formulas for integrals with logarithmic and algebraic singularity</title>
      <link>https://arxiv.org/abs/2411.19755</link>
      <description>arXiv:2411.19755v1 Announce Type: new 
Abstract: The SE and DE formulas are known as efficient quadrature formulas for integrals with endpoint singularities. Especially for integrals with algebraic singularity, explicit error bounds in a computable form have been given, which are useful for computation with guaranteed accuracy. Such explicit error bounds have also given for integrals with logarithmic singularity. However, the error bounds have two points to be discussed. The first point is on overestimation of divergence speed of logarithmic singularity. The second point is on the case where there exist both logarithmic and algebraic singularity. To remedy these points, this study provides new error bounds for integrals with logarithmic and algebraic singularity. Although existing and new error bounds described above handle integrals over the finite interval, the SE and DE formulas may be applied to integrals over the semi-infinite interval. On the basis of the new results, this study provides new error bounds for integrals over the semi-infinite interval with logarithmic and algebraic singularity at the origin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19755v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomoaki Okayama, Kosei Arakawa, Ryo Kamigaki, Eita Yabumoto</dc:creator>
    </item>
    <item>
      <title>Randomized Kaczmarz with tail averaging</title>
      <link>https://arxiv.org/abs/2411.19877</link>
      <description>arXiv:2411.19877v1 Announce Type: new 
Abstract: The randomized Kaczmarz (RK) method is a well-known approach for solving linear least-squares problems with a large number of rows. RK accesses and processes just one row at a time, leading to exponentially fast convergence for consistent linear systems. However, RK fails to converge to the least-squares solution for inconsistent systems. This work presents a simple fix: average the RK iterates produced in the tail part of the algorithm. The proposed tail-averaged randomized Kaczmarz (TARK) converges for both consistent and inconsistent least-squares problems at a polynomial rate, which is known to be optimal for any row-access method. An extension of TARK also leads to efficient solutions for ridge-regularized least-squares problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19877v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ethan N. Epperly, Gil Goldshlager, Robert J. Webber</dc:creator>
    </item>
    <item>
      <title>Traction force microscopy for linear and nonlinear elastic materials as a parameter identification inverse problem</title>
      <link>https://arxiv.org/abs/2411.19917</link>
      <description>arXiv:2411.19917v1 Announce Type: new 
Abstract: Traction force microscopy is a method widely used in biophysics and cell biology to determine forces that biological cells apply to their environment. In the experiment, the cells adhere to a soft elastic substrate, which is then deformed in response to cellular traction forces. The inverse problem consists in computing the traction stress applied by the cell from microscopy measurements of the substrate deformations. In this work, we consider a linear model, in which 3D forces are applied at a 2D interface, called 2.5D traction force microscopy, and a nonlinear pure 2D model, from which we directly obtain a linear pure 2D model. All models lead to a linear resp. nonlinear parameter identification problem for a boundary value problem of elasticity. We analyze the respective forward operators and conclude with some numerical experiments for simulated and experimental data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19917v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gesa Sarnighausen, Tram Thi Ngoc Nguyen, Thorsten Hohage, Mangalika Sinha, Sarah Koester, Timo Betz, Ulrich Sebastian Schwarz, Anne Wald</dc:creator>
    </item>
    <item>
      <title>Stratified Non-Negative Tensor Factorization</title>
      <link>https://arxiv.org/abs/2411.18805</link>
      <description>arXiv:2411.18805v1 Announce Type: cross 
Abstract: Non-negative matrix factorization (NMF) and non-negative tensor factorization (NTF) decompose non-negative high-dimensional data into non-negative low-rank components. NMF and NTF methods are popular for their intrinsic interpretability and effectiveness on large-scale data. Recent work developed Stratified-NMF, which applies NMF to regimes where data may come from different sources (strata) with different underlying distributions, and seeks to recover both strata-dependent information and global topics shared across strata. Applying Stratified-NMF to multi-modal data requires flattening across modes, and therefore loses geometric structure contained implicitly within the tensor. To address this problem, we extend Stratified-NMF to the tensor setting by developing a multiplicative update rule and demonstrating the method on text and image data. We find that Stratified-NTF can identify interpretable topics with lower memory requirements than Stratified-NMF. We also introduce a regularized version of the method and demonstrate its effects on image data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18805v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Sietsema, Zerrin Vural, James Chapman, Yotam Yaniv, Deanna Needell</dc:creator>
    </item>
    <item>
      <title>Augmented Lagrange method for optimal control problems of parabolic equation with state constraints</title>
      <link>https://arxiv.org/abs/2411.18958</link>
      <description>arXiv:2411.18958v1 Announce Type: cross 
Abstract: The augmented Lagrange method is employed to address the optimal control problem involving pointwise state constraints in parabolic equations. The strong convergence of the primal variables and the weak convergence of the dual variables are rigorously established. The sub-problems arising in the algorithm are solved using the Method of Successive Approximations (MSA), derived from Pontryagin's principle. Numerical experiments are provided to validate the convergence of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18958v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weilong You, Fu Zhang</dc:creator>
    </item>
    <item>
      <title>On analytical integration of interaction potentials between cylindrical and rectangular bodies with a focus on van der Waals attraction</title>
      <link>https://arxiv.org/abs/2411.19035</link>
      <description>arXiv:2411.19035v1 Announce Type: cross 
Abstract: The paper deals with the analytical integration of interaction potentials between specific geometries such as disks, cylinders, rectangles, and rectangular prisms. Interaction potentials are modeled as inverse-power laws with respect to the point-pair distance, and the complete body-body potential is obtained by pairwise summation (integration). Several exact new interaction laws are obtained, such as disk-plate and (in-plane) rectangle-rectangle for an arbitrary exponent, and disk-disk and rectangle-rectangle for van der Waals attraction. To balance efficiency and accuracy, additional approximate laws are proposed for disk-disk, point-cylinder, and disk-cylinder interactions. A brief numerical example illustrates the application of the pre-integrated Lennard-Jones disk-disk interaction potential for the interaction between elastic fibers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19035v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aleksandar Borkovi\'c, Michael H. Gferer, Roger A. Sauer</dc:creator>
    </item>
    <item>
      <title>An isogemetric analysis formulation for the dynamics of geometrically exact viscoelastic beams and beam systems with arbitrarily curved initial geometry</title>
      <link>https://arxiv.org/abs/2411.19054</link>
      <description>arXiv:2411.19054v1 Announce Type: cross 
Abstract: We present a novel formulation for the dynamics of geometrically exact Timoshenko beams and beam structures made of viscoelastic material featuring complex, arbitrarily curved initial geometries. An $\textrm{SO}(3)$-consistent and second-order accurate time integration scheme for accelerations, velocities and rate-dependent viscoelastic strain measures is adopted. To achieve high efficiency and geometrical flexibility, the spatial discretization is carried out with the isogemetric collocation (IGA-C) method, which permits bypassing elements integration keeping all the advantages of the isogeometric analysis (IGA) in terms of high-order space accuracy and geometry representation. Moreover, a primal formulation guarantees the minimal kinematic unknowns. The generalized Maxwell model is deployed directly to the one-dimensional beam strain and stress measures. This allows to express the internal variables in terms of the same kinematic unknowns, as for the case of linear elastic rate-independent materials bypassing the complexities introduced by the viscoelastic material. As a result, existing $\textrm{SO}(3)$-consistent linearizations of the governing equations in the strong form (and associated updating formulas) can straightforwardly be used. Through a series of numerical tests, the attributes and potentialities of the proposed formulation are demonstrated. In particular, we show the capability to accurately simulate beams and beam systems featuring complex initial geometry and topology, opening interesting perspectives in the inverse design of programmable mechanical meta-materials and objects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19054v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giulio Ferri, Enzo Marino</dc:creator>
    </item>
    <item>
      <title>Sparse optimization for estimating the cross-power spectrum in linear inverse models : from theory to the application in brain connectivity</title>
      <link>https://arxiv.org/abs/2411.19225</link>
      <description>arXiv:2411.19225v1 Announce Type: cross 
Abstract: In this work we present a computationally efficient linear optimization approach for estimating the cross--power spectrum of an hidden multivariate stochastic process from that of another observed process. Sparsity in the resulting estimator of the cross--power is induced through $\ell_1$ regularization and the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA) is used for computing such an estimator. With respect to a standard implementation, we prove that a proper initialization step is sufficient to guarantee the required symmetric and antisymmetric properties of the involved quantities. Further, we show how structural properties of the forward operator can be exploited within the FISTA update in order to make our approach adequate also for large--scale problems such as those arising in context of brain functional connectivity.
  The effectiveness of the proposed approach is shown in a practical scenario where we aim at quantifying the statistical relationships between brain regions in the context of non-invasive electromagnetic field recordings. Our results show that our method provide results with an higher specificity that classical approaches based on a two--step procedure where first the hidden process describing the brain activity is estimated through a linear optimization step and then the cortical cross--power spectrum is computed from the estimated time--series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19225v1</guid>
      <category>stat.ME</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laura Carini, Isabella Furci, Sara Sommariva</dc:creator>
    </item>
    <item>
      <title>A Simple Introduction to the SiMPL Method for Density-Based Topology Optimization</title>
      <link>https://arxiv.org/abs/2411.19421</link>
      <description>arXiv:2411.19421v1 Announce Type: cross 
Abstract: We introduce a novel method for solving density-based topology optimization problems: \underline{Si}gmoidal \underline{M}irror descent with a \underline{P}rojected \underline{L}atent variable (SiMPL). The SiMPL method (pronounced as "the simple method") optimizes a design using only first-order derivative information of the objective function. The bound constraints on the density field are enforced with the help of the (negative) Fermi--Dirac entropy, which is also used to define a non-symmetric distance function called a Bregman divergence on the set of admissible designs. This Bregman divergence leads to a simple update rule that is further simplified with the help of a so-called latent variable. %Introducing a generalized Barzilai-Borwein step size rule accelerates the convergence of SiMPL.
  Because the SiMPL method involves discretizing the latent variable, it produces a sequence of pointwise-feasible iterates, even when high-order finite elements are used in the discretization. Numerical experiments demonstrate that the method outperforms other popular first-order optimization algorithms. To outline the general applicability of the technique, we include examples with (self-load) compliance minimization and compliant mechanism optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19421v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dohyun Kim, Boyan Stefanov Lazarov, Thomas M. Surowiec, Brendan Keith</dc:creator>
    </item>
    <item>
      <title>Fast Mutual Information Computation for Large Binary Datasets</title>
      <link>https://arxiv.org/abs/2411.19702</link>
      <description>arXiv:2411.19702v1 Announce Type: cross 
Abstract: Mutual Information (MI) is a powerful statistical measure that quantifies shared information between random variables, particularly valuable in high-dimensional data analysis across fields like genomics, natural language processing, and network science. However, computing MI becomes computationally prohibitive for large datasets where it is typically required a pairwise computational approach where each column is compared to others. This work introduces a matrix-based algorithm that accelerates MI computation by leveraging vectorized operations and optimized matrix calculations. By transforming traditional pairwise computational approaches into bulk matrix operations, the proposed method enables efficient MI calculation across all variable pairs. Experimental results demonstrate significant performance improvements, with computation times reduced up to 50,000 times in the largest dataset using optimized implementations, particularly when utilizing hardware optimized frameworks. The approach promises to expand MI's applicability in data-driven research by overcoming previous computational limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19702v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andre O. Falcao</dc:creator>
    </item>
    <item>
      <title>Sparse Pseudospectral Shattering</title>
      <link>https://arxiv.org/abs/2411.19926</link>
      <description>arXiv:2411.19926v1 Announce Type: cross 
Abstract: The eigenvalues and eigenvectors of nonnormal matrices can be unstable under perturbations of their entries. This renders an obstacle to the analysis of numerical algorithms for non-Hermitian eigenvalue problems. A recent technique to handle this issue is pseudospectral shattering [BGVKS23], showing that adding a random perturbation to any matrix has a regularizing effect on the stability of the eigenvalues and eigenvectors. Prior work has analyzed the regularizing effect of dense Gaussian perturbations, where independent noise is added to every entry of a given matrix [BVKS20, BGVKS23, BKMS21, JSS21].
  We show that the same effect can be achieved by adding a sparse random perturbation. In particular, we show that given any $n\times n$ matrix $M$ of polynomially bounded norm: (a) perturbing $O(n\log^2(n))$ random entries of $M$ by adding i.i.d. complex Gaussians yields $\log\kappa_V(A)=O(\text{poly}\log(n))$ and $\log (1/\eta(A))=O(\text{poly}\log(n))$ with high probability; (b) perturbing $O(n^{1+\alpha})$ random entries of $M$ for any constant $\alpha&gt;0$ yields $\log\kappa_V(A)=O_\alpha(\log(n))$ and $\log(1/\eta(A))=O_\alpha(\log(n))$ with high probability. Here, $\kappa_V(A)$ denotes the condition number of the eigenvectors of the perturbed matrix $A$ and $\eta(A)$ denotes its minimum eigenvalue gap.
  A key mechanism of the proof is to reduce the study of $\kappa_V(A)$ to control of the pseudospectral area and minimum eigenvalue gap of $A$, which are further reduced to estimates on the least two singular values of shifts of $A$. We obtain the required least singular value estimates via a streamlining of an argument of Tao and Vu [TV07] specialized to the case of sparse complex Gaussian perturbations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19926v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rikhav Shah, Nikhil Srivastava, Edward Zeng</dc:creator>
    </item>
    <item>
      <title>New Algebraic Fast Algorithms for $N$-body Problems in Two and Three Dimensions</title>
      <link>https://arxiv.org/abs/2309.14085</link>
      <description>arXiv:2309.14085v3 Announce Type: replace 
Abstract: We present two new algebraic multilevel hierarchical matrix algorithms to perform fast matrix-vector product (MVP) for $N$-body problems in $d$ dimensions, namely efficient $\mathcal{H}^2_{*}$ (fully nested algorithm, i.e., $\mathcal{H}^2$ matrix-like algorithm) and $(\mathcal{H}^2 + \mathcal{H})_{*}$ (semi-nested algorithm, i.e., cross of $\mathcal{H}^2$ and $\mathcal{H}$ matrix-like algorithms). The efficient $\mathcal{H}^2_{*}$ and $(\mathcal{H}^2 + \mathcal{H})_{*}$ hierarchical representations are based on our recently introduced weak admissibility condition in higher dimensions, where the admissible clusters are the far-field and the vertex-sharing clusters. Due to the use of nested form of the bases, the proposed hierarchical matrix algorithms are more efficient than the non-nested algorithms ($\mathcal{H}$ matrix algorithms). We rely on purely algebraic low-rank approximation techniques (e.g., ACA and NCA) and develop both algorithms in a black-box fashion. Another noteworthy contribution of this article is that we perform a comparative study of the proposed algorithms with different algebraic (NCA or ACA-based compression) fast MVP algorithms in $2$D and $3$D. The fast algorithms are tested on various kernel matrices and applied to get fast iterative solutions of a dense linear system arising from the discretized integral equations and radial basis function interpolation. Notably, all the algorithms are developed in a similar fashion in $\texttt{C++}$ and tested within the same environment, allowing for meaningful comparisons. The numerical results demonstrate that the proposed algorithms are competitive to the NCA-based standard $\mathcal{H}^2$ matrix algorithm with respect to the memory and time. The C++ implementation of the proposed algorithms is available at https://github.com/riteshkhan/H2weak/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14085v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ritesh Khan, Sivaram Ambikasaran</dc:creator>
    </item>
    <item>
      <title>Property-preserving numerical approximation of a Cahn-Hilliard-Navier-Stokes model with variable density and degenerate mobility</title>
      <link>https://arxiv.org/abs/2310.01522</link>
      <description>arXiv:2310.01522v3 Announce Type: replace 
Abstract: In this paper, we present a new computational framework to approximate a Cahn-Hilliard-Navier-Stokes model with variable density and degenerate mobility that preserves the mass of the mixture, the pointwise bounds of the density and the decreasing energy. This numerical scheme is based on a finite element approximation for the Navier-Stokes fluid flow with discontinuous pressure and an upwind discontinuous Galerkin scheme for the Cahn-Hilliard part. Finally, several numerical experiments such as a convergence test and some well-known benchmark problems are conducted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01522v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.apnum.2024.11.005</arxiv:DOI>
      <dc:creator>Daniel Acosta-Soba, Francisco Guill\'en-Gonz\'alez, J. Rafael Rodr\'iguez-Galv\'an, Jin Wang</dc:creator>
    </item>
    <item>
      <title>Faster randomized partial trace estimation</title>
      <link>https://arxiv.org/abs/2310.12364</link>
      <description>arXiv:2310.12364v2 Announce Type: replace 
Abstract: We develop randomized matrix-free algorithms for estimating partial traces, a generalization of the trace arising in quantum physics and chemistry. Our algorithm improves on the typicality-based approach used in [T. Chen and Y-C. Cheng, \emph{Numerical computation of the equilibrium-reduced density matrix for strongly coupled open quantum systems}, J. Chem. Phys. 157, 064106 (2022)] by deflating important subspaces (e.g. corresponding to the low-energy eigenstates) explicitly. This results in a significant variance reduction, leading to several order-of-magnitude speedups over the previous state of the art. We then apply our algorithm to study the thermodynamics of several Heisenberg spin systems, particularly the entanglement spectrum and ergotropy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12364v2</guid>
      <category>math.NA</category>
      <category>cond-mat.str-el</category>
      <category>cs.NA</category>
      <category>quant-ph</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/23M1620399</arxiv:DOI>
      <arxiv:journal_reference>SIAM Journal on Scientific Computing, Volume 46, Issue 6, December 2024, Pages: A3427 - A3447</arxiv:journal_reference>
      <dc:creator>Tyler Chen, Robert Chen, Kevin Li, Skai Nzeuton, Yilu Pan, Yixin Wang</dc:creator>
    </item>
    <item>
      <title>Multilevel Picard algorithm for general semilinear parabolic PDEs with gradient-dependent nonlinearities</title>
      <link>https://arxiv.org/abs/2310.12545</link>
      <description>arXiv:2310.12545v4 Announce Type: replace 
Abstract: In this paper we introduce a multilevel Picard approximation algorithm for general semilinear parabolic PDEs with gradient-dependent nonlinearities whose coefficient functions do not need to be constant. We also provide a full convergence and complexity analysis of our algorithm. To obtain our main results, we consider a particular stochastic fixed-point equation (SFPE) motivated by the Feynman-Kac representation and the Bismut-Elworthy-Li formula. We show that the PDE under consideration has a unique viscosity solution which coincides with the first component of the unique solution of the stochastic fixed-point equation. Moreover, the gradient of the unique viscosity solution of the PDE exists and coincides with the second component of the unique solution of the stochastic fixed-point equation. Furthermore, we also provide a numerical example in up to $300$ dimensions to demonstrate the practical applicability of our multilevel Picard algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12545v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Sizhou Wu</dc:creator>
    </item>
    <item>
      <title>Probabilistic time integration for semi-explicit PDAEs</title>
      <link>https://arxiv.org/abs/2406.07220</link>
      <description>arXiv:2406.07220v3 Announce Type: replace 
Abstract: This paper deals with the application of probabilistic time integration methods to semi-explicit partial differential-algebraic equations of parabolic type and its semi-discrete counterparts, namely semi-explicit differential-algebraic equations of index 2. The proposed methods iteratively construct a probability distribution over the solution of deterministic problems, enhancing the information obtained from the numerical simulation. Within this paper, we examine the efficacy of the randomized versions of the implicit Euler method, the midpoint scheme, and exponential integrators of first and second order. By demonstrating the consistency and convergence properties of these solvers, we illustrate their utility in capturing the sensitivity of the solution to numerical errors. Our analysis establishes the theoretical validity of randomized time integration for constrained systems and offers insights into the calibration of probabilistic integrators for practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07220v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. Altmann, A. Moradi</dc:creator>
    </item>
    <item>
      <title>Non-stationary Gaussian random fields on hypersurfaces: Sampling and strong error analysis</title>
      <link>https://arxiv.org/abs/2406.08185</link>
      <description>arXiv:2406.08185v2 Announce Type: replace 
Abstract: A flexible model for non-stationary Gaussian random fields on hypersurfaces is introduced.The class of random fields on curves and surfaces is characterized by an amplitude spectral density of a second order elliptic differential operator.Sampling is done by a Galerkin--Chebyshev approximation based on the surface finite element method and Chebyshev polynomials. Strong error bounds are shown with convergence rates depending on the smoothness of the approximated random field. Numerical experiments that confirm the convergence rates are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08185v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Jansson, Annika Lang, Mike Pereira</dc:creator>
    </item>
    <item>
      <title>An extrapolation-driven network architecture for physics-informed deep learning</title>
      <link>https://arxiv.org/abs/2406.12460</link>
      <description>arXiv:2406.12460v4 Announce Type: replace 
Abstract: Current PINN implementations with sequential learning strategies often experience some weaknesses, such as the failure to reproduce the previous training results when using a single network, the difficulty to strictly ensure continuity and smoothness at the time interval nodes when using multiple networks, and the increase in complexity and computational overhead. To overcome these shortcomings, we first investigate the extrapolation capability of the PINN method for time-dependent PDEs. Taking advantage of this extrapolation property, we generalize the training result obtained in a specific time subinterval to larger intervals by adding a correction term to the network parameters of the subinterval. The correction term is determined by further training with the sample points in the added subinterval. Secondly, by designing an extrapolation control function with special characteristics and combining it with a correction term, we construct a new neural network architecture whose network parameters are coupled with the time variable, which we call the extrapolation-driven network architecture. Based on this architecture, using a single neural network, we can obtain the overall PINN solution of the whole domain with the following two characteristics: (1) it completely inherits the local solution of the interval obtained from the previous training, (2) at the interval node, it strictly maintains the continuity and smoothness that the true solution has. The extrapolation-driven network architecture allows us to divide a large time domain into multiple subintervals and solve the time-dependent PDEs one by one in a chronological order. This training scheme respects the causality principle and effectively overcomes the difficulties of the conventional PINN method in solving the evolution equation on a large time domain. Numerical experiments verify the performance of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12460v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yong Wang, Yanzhong Yao, Zhiming Gao</dc:creator>
    </item>
    <item>
      <title>A fast neural hybrid Newton solver adapted to implicit methods for nonlinear dynamics</title>
      <link>https://arxiv.org/abs/2407.03945</link>
      <description>arXiv:2407.03945v2 Announce Type: replace 
Abstract: The use of implicit time-stepping schemes for the numerical approximation of solutions to stiff nonlinear time-evolution equations brings well-known advantages including, typically, better stability behaviour and corresponding support of larger time steps, and better structure preservation properties. However, this comes at the price of having to solve a nonlinear equation at every time step of the numerical scheme. In this work, we propose a novel deep learning based hybrid Newton's method to accelerate this solution of the nonlinear time step system for stiff time-evolution nonlinear equations. We propose a targeted learning strategy which facilitates robust unsupervised learning in an offline phase and provides a highly efficient initialisation for the Newton iteration leading to consistent acceleration of Newton's method. A quantifiable rate of improvement in Newton's method achieved by improved initialisation is provided and we analyse the upper bound of the generalisation error of our unsupervised learning strategy. These theoretical results are supported by extensive numerical results, demonstrating the efficiency of our proposed neural hybrid solver both in one- and two-dimensional cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03945v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianyu Jin, Georg Maierhofer, Katharina Schratz, Yang Xiang</dc:creator>
    </item>
    <item>
      <title>On latent dynamics learning in nonlinear reduced order modeling</title>
      <link>https://arxiv.org/abs/2408.15183</link>
      <description>arXiv:2408.15183v2 Announce Type: replace 
Abstract: In this work, we present the novel mathematical framework of latent dynamics models (LDMs) for reduced order modeling of parameterized nonlinear time-dependent PDEs. Our framework casts this latter task as a nonlinear dimensionality reduction problem, while constraining the latent state to evolve accordingly to an (unknown) dynamical system. A time-continuous setting is employed to derive error and stability estimates for the LDM approximation of the full order model (FOM) solution. We analyze the impact of using an explicit Runge-Kutta scheme in the time-discrete setting, resulting in the $\Delta\text{LDM}$ formulation, and further explore the learnable setting, $\Delta\text{LDM}_\theta$, where deep neural networks approximate the discrete LDM components, while providing a bounded approximation error with respect to the FOM. Moreover, we extend the concept of parameterized Neural ODE - recently proposed as a possible way to build data-driven dynamical systems with varying input parameters - to be a convolutional architecture, where the input parameters information is injected by means of an affine modulation mechanism, while designing a convolutional autoencoder neural network able to retain spatial-coherence, thus enhancing interpretability at the latent level. Numerical experiments, including the Burgers' and the advection-reaction-diffusion equations, demonstrate the framework's ability to obtain, in a multi-query context, a time-continuous approximation of the FOM solution, thus being able to query the LDM approximation at any given time instance while retaining a prescribed level of accuracy. Our findings highlight the remarkable potential of the proposed LDMs, representing a mathematically rigorous framework to enhance the accuracy and approximation capabilities of reduced order modeling for time-dependent parameterized PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15183v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Farenga, Stefania Fresca, Simone Brivio, Andrea Manzoni</dc:creator>
    </item>
    <item>
      <title>Polynomial approximation of noisy functions</title>
      <link>https://arxiv.org/abs/2410.02317</link>
      <description>arXiv:2410.02317v2 Announce Type: replace 
Abstract: Approximating a univariate function on the interval $[-1,1]$ with a polynomial is among the most classical problems in numerical analysis. When the function evaluations come with noise, a least-squares fit is known to reduce the effect of noise as more samples are taken. The generic algorithm for the least-squares problem requires $O(Nn^2)$ operations, where $N+1$ is the number of sample points and $n$ is the degree of the polynomial approximant. This algorithm is unstable when $n$ is large, for example $n\gg \sqrt{N}$ for equispaced sample points. In this study, we blend numerical analysis and statistics to introduce a stable and fast $O(N\log N)$ algorithm called NoisyChebtrunc based on the Chebyshev interpolation. It has the same error reduction effect as least-squares and the convergence is spectral until the error reaches $O(\sigma \sqrt{{n}/{N}})$, where $\sigma$ is the noise level, after which the error continues to decrease at the Monte-Carlo $O(1/\sqrt{N})$ rate. To determine the polynomial degree, NoisyChebtrunc employs a statistical criterion, namely Mallows' $C_p$. We analyze NoisyChebtrunc in terms of the variance and concentration in the infinity norm to the underlying noiseless function. These results show that with high probability the infinity-norm error is bounded by a small constant times $\sigma \sqrt{{n}/{N}}$, when the noise {is} independent and follows a subgaussian or subexponential distribution. We illustrate the performance of NoisyChebtrunc with numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02317v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takeru Matsuda, Yuji Nakatsukasa</dc:creator>
    </item>
    <item>
      <title>High order ADER-DG method with local DG predictor for solutions of differential-algebraic systems of equations</title>
      <link>https://arxiv.org/abs/2410.04018</link>
      <description>arXiv:2410.04018v2 Announce Type: replace 
Abstract: A numerical method ADER-DG with a local DG predictor for solving a DAE system has been developed, which was based on the formulation of ADER-DG methods using a local DG predictor for solving ODE and PDE systems. The basis functions were chosen in the form of Lagrange interpolation polynomials with nodal points at the roots of the Radau polynomials, which differs from the classical formulations of the ADER-DG method, where it is customary to use the roots of Legendre polynomials. It was shown that the use of this basis leads to A-stability and L1-stability in the case of using the DAE solver as ODE solver. The numerical method ADER-DG allows one to obtain a highly accurate numerical solution even on very coarse grids, with a step greater than the main characteristic scale of solution variation. The local discrete time solution can be used as a numerical solution of the DAE system between grid nodes, thereby providing subgrid resolution even in the case of very coarse grids. The classical test examples were solved by developed numerical method ADER-DG. With increasing index of the DAE system, a decrease in the empirical convergence orders p is observed. An unexpected result was obtained in the numerical solution of the stiff DAE system -- the empirical convergence orders of the numerical solution obtained using the developed method turned out to be significantly higher than the values expected for this method in the case of stiff problems. It turns out that the use of Lagrange interpolation polynomials with nodal points at the roots of the Radau polynomials is much better suited for solving stiff problems. Estimates showed that the computational costs of the ADER-DG method are approximately comparable to the computational costs of implicit Runge-Kutta methods used to solve DAE systems. Methods were proposed to reduce the computational costs of the ADER-DG method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04018v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>I. S. Popov</dc:creator>
    </item>
    <item>
      <title>A priori and a posteriori error estimates of a really pressure-robust virtual element method for the incompressible Brinkman problem</title>
      <link>https://arxiv.org/abs/2411.16067</link>
      <description>arXiv:2411.16067v2 Announce Type: replace 
Abstract: This paper presents both a priori and a posteriori error analyses for a really pressure-robust virtual element method to approximate the incompressible Brinkman problem. We construct a divergence-preserving reconstruction operator using the Raviart-Thomas element for the discretization on the right-hand side. The optimal priori error estimates are carried out, which imply the velocity error in the energy norm is independent of both the continuous pressure and the viscosity. Taking advantage of the virtual element method's ability to handle more general polygonal meshes, we implement effective mesh refinement strategies and develop a residual-type a posteriori error estimator. This estimator is proven to provide global upper and local lower bounds for the discretization error. Finally, some numerical experiments demonstrate the robustness, accuracy, reliability and efficiency of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16067v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Xiong, Yanping Chen</dc:creator>
    </item>
    <item>
      <title>Runge-Kutta Discontinuous Galerkin Method Based on Flux Vector Splitting with Constrained Optimization-based TVB(D)-minmod Limiter for Solving Hyperbolic Conservation Laws</title>
      <link>https://arxiv.org/abs/2411.16367</link>
      <description>arXiv:2411.16367v3 Announce Type: replace 
Abstract: The flux vector splitting (FVS) method has firstly been incorporated into the discontinuous Galerkin (DG) framework for reconstructing the numerical fluxes required for the spatial semi-discrete formulation, setting it apart from the conventional DG approaches that typically utilize the Lax-Friedrichs flux scheme or classical Riemann solvers. The control equations of hyperbolic conservation systems are initially reformulated into a flux-split form. Subsequently, a variational approach is applied to this flux-split form, from which a DG spatial semi-discrete scheme based on FVS is derived. In order to suppress numerical pseudo-oscillations, the smoothness measurement function IS from the WENO limiter is integrated into the TVB(D)-minmod limiter, constructing an optimization problem based on the smoothness factor constraint, thereby realizing a TVB(D)-minmod limiter applicable to arbitrary high-order polynomial approximation. Subsequently, drawing on the ``reconstructed polynomial and the original high-order scheme's L2 -error constraint'' from the literature [1] , combined with our smoothness factor constraint, a bi-objective optimization problem is formulated to enable the TVB(D)-minmod limiter to balance oscillation suppression and high precision. As for hyperbolic conservation systems, limiters are typically required to be used in conjunction with local characteristic decomposition. To transform polynomials from the physical space to the characteristic space, an interpolation-based characteristic transformation scheme has been proposed, and its equivalence with the original moment characteristic transformation has been demonstrated in one-dimensional scenarios. Finally, the concept of ``flux vector splitting based on Jacobian eigenvalue decomposition'' has been applied to the conservative linear scalar transport equations and the nonlinear Burgers' equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16367v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengrong Xie, Xiaofeng Cai, Haibiao Zheng</dc:creator>
    </item>
    <item>
      <title>Marcinkiewicz--Zygmund inequalities for scattered data on polygons</title>
      <link>https://arxiv.org/abs/2411.16584</link>
      <description>arXiv:2411.16584v2 Announce Type: replace 
Abstract: Given a set of scattered points on a regular or irregular 2D polygon, we aim to employ them as quadrature points to construct a quadrature rule that establishes Marcinkiewicz--Zygmund inequalities on this polygon. The quadrature construction is aided by Bernstein--B\'{e}zier polynomials. For this purpose, we first propose a quadrature rule on triangles with an arbitrary degree of exactness and establish Marcinkiewicz--Zygmund estimates for 3-, 10-, and 21-point quadrature rules on triangles. Based on the 3-point quadrature rule on triangles, we then propose the desired quadrature rule on the polygon that satisfies Marcinkiewicz--Zygmund inequalities for $1\leq p \leq \infty$. As a byproduct, we provide error analysis for both quadrature rules on triangles and polygons. Numerical results further validate our construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16584v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao-Ning Wu</dc:creator>
    </item>
    <item>
      <title>Fast convolution algorithm for state space models</title>
      <link>https://arxiv.org/abs/2411.17729</link>
      <description>arXiv:2411.17729v2 Announce Type: replace 
Abstract: We present a fast, robust algorithm for applying a matrix transfer function of a linear time invariant system (LTI) in time domain. Computing $L$ states of a multiple-input multiple-output (MIMO) LTI appears to require $L$ matrix-vector multiplications. We demonstrate that, for any finite user-selected accuracy, the number of matrix-vector multiplications can be reduced to $\mathcal{O}\left(\log_{2}L\right)$ (within an $\mathcal{O}\left(L\right)$ algorithm). The algorithm uses an approximation of the rational transfer function in the z-domain by a matrix polynomial of degree $2^{N+1}-1$, where $N$ is chosen to achieve any user-selected accuracy. Importantly, using a cascade implementation in time domain, applying the transfer function requires only $N+1$ matrix-vector multiplications. We note that LTI systems are used in state space models (SSMs) for modeling long range dependencies where $L$ is large. In applications where the state matrix of LTI system is approximated by a structured matrix, the computational cost is further reduced. We briefly describe several structured approximations of matrices that can be used for such purpose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17729v2</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gregory Beylkin</dc:creator>
    </item>
    <item>
      <title>A robust time-split linearized explicit/implicit technique for two-dimensional hydrodynamic model: an application to floods in Cameroon far north region</title>
      <link>https://arxiv.org/abs/2411.17740</link>
      <description>arXiv:2411.17740v2 Announce Type: replace 
Abstract: This paper deals with a time-split explicit/implicit approach for solving a two-dimensional hydrodynamic flow model with appropriate initial and boundary conditions. The time-split technique is employed to upwind the convection term and to treat the friction slope so that the numerical oscillations and stability are well controlled. A suitable time step restriction for stability and convergence accurate of the new algorithm is established using the $L^{\infty}(0,T; L^{2})$-norm. Under a time step requirement, some numerical examples confirm the theoretical studies and suggest that the proposed computational technique is spatial fourth-order accurate and temporal second-order convergent. An application to floods observed in Cameroon far north region is considered and discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17740v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Eric Ngondiep</dc:creator>
    </item>
    <item>
      <title>Numerical approximation of SDEs with fractional noise and distributional drift</title>
      <link>https://arxiv.org/abs/2302.11455</link>
      <description>arXiv:2302.11455v3 Announce Type: replace-cross 
Abstract: We study the numerical approximation of SDEs with singular drifts (including distributions) driven by a fractional Brownian motion. Under the Catellier-Gubinelli condition that imposes the regularity of the drift to be strictly greater than $1-1/(2H)$, we obtain an explicit rate of convergence of a tamed Euler scheme towards the SDE, extending results for bounded drifts. Beyond this regime, when the regularity of the drift is $1-1/(2H)$, we derive a non-explicit rate. As a byproduct, strong well-posedness for these equations is recovered. Proofs use new regularising properties of discrete-time fBm and a new critical Gr\"onwall-type lemma. We present examples and simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.11455v3</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ludovic Gouden\`ege, El Mehdi Haress, Alexandre Richard</dc:creator>
    </item>
    <item>
      <title>Regularized methods via cubic model subspace minimization for nonconvex optimization</title>
      <link>https://arxiv.org/abs/2306.14290</link>
      <description>arXiv:2306.14290v4 Announce Type: replace-cross 
Abstract: Adaptive cubic regularization methods for solving nonconvex problems need the efficient computation of the trial step, involving the minimization of a cubic model. We propose a new approach in which this model is minimized in a low dimensional subspace that, in contrast to classic approaches, is reused for a number of iterations. Whenever the trial step produced by the low-dimensional minimization process is unsatisfactory, we employ a regularized Newton step whose regularization parameter is a by-product of the model minimization over the low-dimensional subspace. We show that the worst-case complexity of classic cubic regularized methods is preserved, despite the possible regularized Newton steps. We focus on the large class of problems for which (sparse) direct linear system solvers are available and provide several experimental results showing the very large gains of our new approach when compared to standard implementations of adaptive cubic regularization methods based on direct linear solvers. Our first choice as projection space for the low-dimensional model minimization is the polynomial Krylov subspace; nonetheless, we also explore the use of rational Krylov subspaces in case where the polynomial ones lead to less competitive numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14290v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefania Bellavia, Davide Palitta, Margherita Porcelli, Valeria Simoncini</dc:creator>
    </item>
    <item>
      <title>Randomized Algorithms for Symmetric Nonnegative Matrix Factorization</title>
      <link>https://arxiv.org/abs/2402.08134</link>
      <description>arXiv:2402.08134v2 Announce Type: replace-cross 
Abstract: Symmetric Nonnegative Matrix Factorization (SymNMF) is a technique in data analysis and machine learning that approximates a symmetric matrix with a product of a nonnegative, low-rank matrix and its transpose. To design faster and more scalable algorithms for SymNMF we develop two randomized algorithms for its computation. The first algorithm uses randomized matrix sketching to compute an initial low-rank approximation to the input matrix and proceeds to rapidly compute a SymNMF of the approximation. The second algorithm uses randomized leverage score sampling to approximately solve constrained least squares problems. Many successful methods for SymNMF rely on (approximately) solving sequences of constrained least squares problems. We prove theoretically that leverage score sampling can approximately solve nonnegative least squares problems to a chosen accuracy with high probability. Additionally, we prove sampling complexity results for previously proposed hybrid sampling techniques which deterministically include high leverage score rows. This hybrid scheme is crucial for obtaining speeds ups in practice. Finally we demonstrate that both methods work well in practice by applying them to graph clustering tasks on large real world data sets. These experiments show that our methods approximately maintain solution quality and achieve significant speed ups for both large dense and large sparse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08134v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koby Hayashi, Sinan G. Aksoy, Grey Ballard, Haesun Park</dc:creator>
    </item>
    <item>
      <title>Neural Networks-based Random Vortex Methods for Modelling Incompressible Flows</title>
      <link>https://arxiv.org/abs/2405.13691</link>
      <description>arXiv:2405.13691v2 Announce Type: replace-cross 
Abstract: In this paper we introduce a novel Neural Networks-based approach for approximating solutions to the (2D) incompressible Navier--Stokes equations, which is an extension of so called Deep Random Vortex Methods (DRVM), that does not require the knowledge of the Biot--Savart kernel associated to the computational domain. Our algorithm uses a Neural Network (NN), that approximates the vorticity based on a loss function that uses a computationally efficient formulation of the Random Vortex Dynamics. The neural vorticity estimator is then combined with traditional numerical PDE-solvers, which can be considered as a final implicit linear layer of the network, for the Poisson equation to compute the velocity field. The main advantage of our method compared to the standard DRVM and other NN-based numerical algorithms is that it strictly enforces physical properties, such as incompressibility or (no slip) boundary conditions, which might be hard to guarantee otherwise. The approximation abilities of our algorithm, and its capability for incorporating measurement data, are validated by several numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13691v2</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladislav Cherepanov, Sebastian W. Ertel</dc:creator>
    </item>
    <item>
      <title>Stein transport for Bayesian inference</title>
      <link>https://arxiv.org/abs/2409.01464</link>
      <description>arXiv:2409.01464v2 Announce Type: replace-cross 
Abstract: We introduce $\textit{Stein transport}$, a novel methodology for Bayesian inference designed to efficiently push an ensemble of particles along a predefined curve of tempered probability distributions. The driving vector field is chosen from a reproducing kernel Hilbert space and can be derived either through a suitable kernel ridge regression formulation or as an infinitesimal optimal transport map in the Stein geometry. The update equations of Stein transport resemble those of Stein variational gradient descent (SVGD), but introduce a time-varying score function as well as specific weights attached to the particles. While SVGD relies on convergence in the long-time limit, Stein transport reaches its posterior approximation at finite time $t=1$. Studying the mean-field limit, we discuss the errors incurred by regularisation and finite-particle effects, and we connect Stein transport to birth-death dynamics and Fisher-Rao gradient flows. In a series of experiments, we show that in comparison to SVGD, Stein transport not only often reaches more accurate posterior approximations with a significantly reduced computational budget, but that it also effectively mitigates the variance collapse phenomenon commonly observed in SVGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01464v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 02 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolas N\"usken</dc:creator>
    </item>
  </channel>
</rss>
