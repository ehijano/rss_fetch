<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Sep 2024 04:00:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Comparison of Sparse Solvers for Severely Ill-Conditioned Linear Systems in Geophysical Marker-In-Cell Simulations</title>
      <link>https://arxiv.org/abs/2409.11515</link>
      <description>arXiv:2409.11515v1 Announce Type: new 
Abstract: Solving sparse linear systems is a critical challenge in many scientific and engineering fields, particularly when these systems are severely ill-conditioned. This work aims to provide a comprehensive comparison of various solvers designed for such problems, offering valuable insights and guidance for domain scientists and researchers. We develop the tools required to accurately evaluate the performance and correctness of 16 solvers from 11 state-of-the-art numerical libraries, focusing on their effectiveness in handling ill-conditioned matrices. The solvers were tested on linear systems arising from a coupled hydro-mechanical marker-in-cell geophysical simulation. To address the challenge of computing accurate error bounds on the solution, we introduce the Projected Adam method, a novel algorithm to efficiently compute the condition number of a matrix without relying on eigenvalues or singular values. Our benchmark results demonstrate that Intel oneAPI MKL PARDISO, UMFPACK, and MUMPS are the most reliable solvers for the tested scenarios. This work serves as a resource for selecting appropriate solvers, understanding the impact of condition numbers, and improving the robustness of numerical solutions in practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11515v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Marcel Ferrari</dc:creator>
    </item>
    <item>
      <title>Spline-based solution transfer for space-time methods in 2D+t</title>
      <link>https://arxiv.org/abs/2409.11639</link>
      <description>arXiv:2409.11639v1 Announce Type: new 
Abstract: This work introduces a new solution-transfer process for slab-based space-time finite element methods. The new transfer process is based on Hsieh-Clough-Tocher (HCT) splines and satisfies the following requirements: (i) it maintains high-order accuracy up to 4th order, (ii) it preserves a discrete maximum principle, (iii) it enforces mass conservation, and (iv) it constructs a smooth, continuous surrogate solution in between space-time slabs. While many existing transfer methods meet the first three requirements, the fourth requirement is crucial for enabling visualization and boundary condition enforcement for space-time applications. In this paper, we derive an error bound for our HCT spline-based transfer process. Additionally, we conduct numerical experiments quantifying the conservative nature and order of accuracy of the transfer process. Lastly, we present a qualitative evaluation of the visualization properties of the smooth surrogate solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11639v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Logan Larose, Jude T. Anderson, David M. Williams</dc:creator>
    </item>
    <item>
      <title>A novel Mortar Method Integration using Radial Basis Functions</title>
      <link>https://arxiv.org/abs/2409.11735</link>
      <description>arXiv:2409.11735v1 Announce Type: new 
Abstract: Recent advancements in computational capabilities have significantly enhanced the numerical simulation of complex multiphysics and multidomain problems. However, mesh generation remains a primary bottleneck in these simulations. To address this challenge, non-conforming grids are often utilized, which necessitates the development of robust and efficient intergrid interpolator operators. This paper presents a novel approach for transferring variable fields across non-conforming meshes within a mortar framework, where weak continuity conditions are imposed. The key contribution of our work is the introduction of an innovative algorithm that utilizes Radial Basis Function (RBF) interpolations to compute the mortar integral, offering a compelling alternative to traditional projection-based algorithms. Pairing RBF methods with numerical integration techniques, we propose an efficient algorithm tailored for complex three-dimensional scenarios. This paper details the formulation, analysis, and validation of the proposed RBF algorithm through a series of numerical examples, demonstrating its effectiveness. Furthermore, the details of the implementation are discussed and a test case involving a complex geometry is presented, to illustrate the applicability and advantages of our approach in addressing real-world problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11735v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daniele Moretto, Andrea Franceschini, Massimiliano Ferronato</dc:creator>
    </item>
    <item>
      <title>Fully guaranteed and computable error bounds on the energy for periodic Kohn-Sham equations with convex density functionals</title>
      <link>https://arxiv.org/abs/2409.11769</link>
      <description>arXiv:2409.11769v1 Announce Type: new 
Abstract: In this article, we derive fully guaranteed error bounds for the energy of convex nonlinear mean-field models. These results apply in particular to Kohn-Sham equations with convex density functionals, which includes the reduced Hartree-Fock (rHF) model, as well as the Kohn-Sham model with exact exchange-density functional (which is unfortunately not explicit and therefore not usable in practice). We then decompose the obtained bounds into two parts, one depending on the chosen discretization and one depending on the number of iterations performed in the self-consistent algorithm used to solve the nonlinear eigenvalue problem, paving the way for adaptive refinement strategies. The accuracy of the bounds is demonstrated on a series of test cases, including a Silicon crystal and an Hydrogen Fluoride molecule simulated with the rHF model and discretized with planewaves. We also show that, although not anymore guaranteed, the error bounds remain very accurate for a Silicon crystal simulated with the Kohn-Sham model using nonconvex exchangecorrelation functionals of practical interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11769v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Bordignon (CERMICS), Genevi\`eve Dusson (LMB), \'Eric Canc\`es (CERMICS, MATHERIALS), Gaspard Kemlin (LAMFA), Rafael Antonio Lainez Reyes (IANS), Benjamin Stamm (IANS)</dc:creator>
    </item>
    <item>
      <title>Conditions aux limites fortement non lin{\'e}aires pour les {\'e}quations d'Euler de la dynamique des gaz</title>
      <link>https://arxiv.org/abs/2409.11774</link>
      <description>arXiv:2409.11774v1 Announce Type: new 
Abstract: We study various formulations of the boundary conditions for the Euler equations of gas dynamics from a mathematical and numerical point of view. In the case of one space dimension, we recall the classical results, based on an analysis of the linearized problem. Then we present a more recent formulation of the problem, which allows for nonlinear effects at the boundary of the study domain. This formulation fits naturally into a finite volume discretization, and we present a significant one-dimensional test case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11774v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Dubois (LMO, LMSSC)</dc:creator>
    </item>
    <item>
      <title>Adaptive Time-Step Semi-Implicit One-Step Taylor Scheme for Stiff Ordinary Differential Equations</title>
      <link>https://arxiv.org/abs/2409.11990</link>
      <description>arXiv:2409.11990v1 Announce Type: new 
Abstract: In this study, we propose high-order implicit and semi-implicit schemes for solving ordinary differential equations (ODEs) based on Taylor series expansion. These methods are designed to handle stiff and non-stiff components within a unified framework, ensuring stability and accuracy. The schemes are derived and analyzed for their consistency and stability properties, showcasing their effectiveness in practical computational scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11990v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S. Boscarino, E. Macca</dc:creator>
    </item>
    <item>
      <title>A Lightweight, Geometrically Flexible Fast Algorithm for the Evaluation of Layer and Volume Potentials</title>
      <link>https://arxiv.org/abs/2409.11998</link>
      <description>arXiv:2409.11998v1 Announce Type: new 
Abstract: Over the last two decades, several fast, robust, and high-order accurate methods have been developed for solving the Poisson equation in complicated geometry using potential theory. In this approach, rather than discretizing the partial differential equation itself, one first evaluates a volume integral to account for the source distribution within the domain, followed by solving a boundary integral equation to impose the specified boundary conditions. Here, we present a new fast algorithm which is easy to implement and compatible with virtually any discretization technique, including unstructured domain triangulations, such as those used in standard finite element or finite volume methods. Our approach combines earlier work on potential theory for the heat equation, asymptotic analysis, the nonuniform fast Fourier transform (NUFFT), and the dual-space multilevel kernel-splitting (DMK) framework. It is insensitive to flaws in the triangulation, permitting not just nonconforming elements, but arbitrary aspect ratio triangles, gaps and various other degeneracies. On a single CPU core, the scheme computes the solution at a rate comparable to that of the fast Fourier transform (FFT) in work per gridpoint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11998v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fredrik Fryklund, Leslie Greengard, Shidong Jiang, Samuel Potter</dc:creator>
    </item>
    <item>
      <title>A multiscale approach to the stationary Ginzburg-Landau equations of superconductivity</title>
      <link>https://arxiv.org/abs/2409.12023</link>
      <description>arXiv:2409.12023v1 Announce Type: new 
Abstract: In this work, we study the numerical approximation of minimizers of the Ginzburg-Landau free energy, a common model to describe the behavior of superconductors under magnetic fields. The unknowns are the order parameter, which characterizes the density of superconducting charge carriers, and the magnetic vector potential, which allows to deduce the magnetic field that penetrates the superconductor. Physically important and numerically challenging are especially settings which involve lattices of quantized vortices which can be formed in materials with a large Ginzburg-Landau parameter $\kappa$. In particular, $\kappa$ introduces a severe mesh resolution condition for numerical approximations. In order to reduce these computational restrictions, we investigate a particular discretization which is based on mixed meshes where we apply a Lagrange finite element approach for the vector potential and a localized orthogonal decomposition (LOD) approach for the order parameter. We justify the proposed method by a rigorous a-priori error analysis (in $L^2$ and $H^1$) in which we keep track of the influence of $\kappa$ in all error contributions. This allows us to conclude $\kappa$-dependent resolution conditions for the various meshes and which only impose moderate practical constraints compared to a conventional finite element discretization. Finally, our theoretical findings are illustrated by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12023v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian D\"oding, Benjamin D\"orich, Patrick Henning</dc:creator>
    </item>
    <item>
      <title>On the generalization ability of coarse-grained molecular dynamics models for non-equilibrium processes</title>
      <link>https://arxiv.org/abs/2409.11519</link>
      <description>arXiv:2409.11519v1 Announce Type: cross 
Abstract: One essential goal of constructing coarse-grained molecular dynamics (CGMD) models is to accurately predict non-equilibrium processes beyond the atomistic scale. While a CG model can be constructed by projecting the full dynamics onto a set of resolved variables, the dynamics of the CG variables can recover the full dynamics only when the conditional distribution of the unresolved variables is close to the one associated with the particular projection operator. In particular, the model's applicability to various non-equilibrium processes is generally unwarranted due to the inconsistency in the conditional distribution. Here, we present a data-driven approach for constructing CGMD models that retain certain generalization ability for non-equilibrium processes. Unlike the conventional CG models based on pre-selected CG variables (e.g., the center of mass), the present CG model seeks a set of auxiliary CG variables based on the time-lagged independent component analysis to minimize the entropy contribution of the unresolved variables. This ensures the distribution of the unresolved variables under a broad range of non-equilibrium conditions approaches the one under equilibrium. Numerical results of a polymer melt system demonstrate the significance of this broadly-overlooked metric for the model's generalization ability, and the effectiveness of the present CG model for predicting the complex viscoelastic responses under various non-equilibrium flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11519v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liyao Lyu, Huan Lei</dc:creator>
    </item>
    <item>
      <title>Application of a Fourier-Type Series Approach based on Triangles of Constant Width to Letterforms</title>
      <link>https://arxiv.org/abs/2409.11958</link>
      <description>arXiv:2409.11958v1 Announce Type: cross 
Abstract: In this work, we present a novel approach to type design by using Fourier-type series to generate letterforms. We construct a Fourier-type series for functions in $L^2(S^1,\mathbb C)$ based on triangles of constant width instead of circles to model the curves and shapes that define individual characters. In order to compute the coefficients of the series, we construct an isomorphism $\mathcal R:L^2(S^1,\mathbb C)\to L^2(S^1,\mathbb C)$ and study its application to letterforms, thus presenting an alternative to the common use of B\'ezier curves. The proposed method demonstrates potential for creative experimentation in modern type design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11958v1</guid>
      <category>math.CA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.NA</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micha Wasem, Florence Yerly</dc:creator>
    </item>
    <item>
      <title>An Approximation Theory Framework for Measure-Transport Sampling Algorithms</title>
      <link>https://arxiv.org/abs/2302.13965</link>
      <description>arXiv:2302.13965v4 Announce Type: replace 
Abstract: This article presents a general approximation-theoretic framework to analyze measure transport algorithms for probabilistic modeling. A primary motivating application for such algorithms is sampling -- a central task in statistical inference and generative modeling. We provide a priori error estimates in the continuum limit, i.e., when the measures (or their densities) are given, but when the transport map is discretized or approximated using a finite-dimensional function space. Our analysis relies on the regularity theory of transport maps and on classical approximation theory for high-dimensional functions. A third element of our analysis, which is of independent interest, is the development of new stability estimates that relate the distance between two maps to the distance~(or divergence) between the pushforward measures they define. We present a series of applications of our framework, where quantitative convergence rates are obtained for practical problems using Wasserstein metrics, maximum mean discrepancy, and Kullback--Leibler divergence. Specialized rates for approximations of the popular triangular Kn{\"o}the-Rosenblatt maps are obtained, followed by numerical experiments that demonstrate and extend our theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.13965v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ricardo Baptista, Bamdad Hosseini, Nikola B. Kovachki, Youssef M. Marzouk, Amir Sagiv</dc:creator>
    </item>
    <item>
      <title>Half precision wave simulation</title>
      <link>https://arxiv.org/abs/2310.00236</link>
      <description>arXiv:2310.00236v2 Announce Type: replace 
Abstract: In recent years, half precision floating-point arithmetic has gained wide support in hardware and software stack thanks to the advance of artificial intelligence and machine learning applications. Operating at half precision can significantly reduce the memory footprint comparing to operating at single or double precision. For memory bound applications such as time domain wave simulations, this is an attractive feature. However, the narrower width of the half precision data format can lead to degradation of the solution quality due to larger roundoff errors. In this work, we illustrate with carefully designed numerical experiments the negative impact caused by the accumulation of roundoff errors in wave simulations. Specifically, the energy-conserving property of the wave equations is employed as a convenient diagnosis tool. The corresponding remedy in the form of compensated sum is then provided, with its efficacy demonstrated using numerical examples with both acoustic and elastic wave equations on hardware that support half precision arithmetic natively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00236v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Longfei Gao, Kevin Harms</dc:creator>
    </item>
    <item>
      <title>Localized Orthogonal Decomposition Methods vs. Classical FEM for the Gross-Pitaevskii Equation</title>
      <link>https://arxiv.org/abs/2403.11268</link>
      <description>arXiv:2403.11268v2 Announce Type: replace 
Abstract: The time-dependent Gross-Pitaevksii equation (GPE) is a nonlinear Schr\"odinger equation which is used in quantum physics to model the dynamics of Bose-Einstein condensates. In this work we consider numerical approximations of the GPE based on a multiscale approach known as the localized orthogonal decomposition. Combined with an energy preserving time integrator one derives a method which is of high order in space and time under mild regularity assumptions. In previous work, the method has been shown to be numerically very efficient compared to first order Lagrange FEM. In this paper, we further investigate the performance of the method and compare it with higher order Lagrange FEM. For rough problems we observe that the novel method performs very efficient and retains its high order, while the classical methods can only compete well for smooth problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11268v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian D\"oding</dc:creator>
    </item>
    <item>
      <title>Formulae and transformations for simplicial tensorial finite elements via polytopal templates</title>
      <link>https://arxiv.org/abs/2405.10402</link>
      <description>arXiv:2405.10402v2 Announce Type: replace 
Abstract: We introduce a unified method for constructing the basis functions of a wide variety of partially continuous tensor-valued finite elements on simplices using polytopal templates. These finite element spaces are essential for achieving well-posed discretisations of mixed formulations of partial differential equations that involve tensor-valued functions, such as the Hellinger-Reissner formulation of linear elasticity. In our proposed polytopal template method, the basis functions are constructed from template tensors associated with the geometric polytopes (vertices, edges, faces etc.) of the reference simplex and any scalar-valued $H^1$-conforming finite element space. From this starting point we can construct the Regge, Hellan-Herrmann-Johnson, Pechstein-Sch\"oberl, Hu-Zhang, Hu-Ma-Sun and Gopalakrishnan-Lederer-Sch\"oberl elements. Because the Hu-Zhang element and the Hu-Ma-Sun element cannot be mapped from the reference simplex to a physical simplex via standard double Piola mappings, we also demonstrate that the polytopal template tensors can be used to define a consistent mapping from a reference simplex even to a non-affine simplex in the physical mesh. Finally, we discuss the implications of element regularity with two numerical examples for the Reissner-Mindlin plate problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10402v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Adam Sky, Michael Neunteufel, Jack S. Hale, Andreas Zilian</dc:creator>
    </item>
    <item>
      <title>CPAFT: A Consistent Parallel Advancing Front Technique for Unstructured Triangular/Tetrahedral Mesh Generation</title>
      <link>https://arxiv.org/abs/2405.20618</link>
      <description>arXiv:2405.20618v2 Announce Type: replace 
Abstract: Compared with the remarkable progress made in parallel numerical solvers of partial differential equations,the development of algorithms for generating unstructured triangular/tetrahedral meshes has been relatively sluggish. In this paper, we propose a novel, consistent parallel advancing front technique (CPAFT) by combining the advancing front technique, the domain decomposition method based on space-filling curves, the distributed forest-of-overlapping-trees approach, and the consistent parallel maximal independent set algorithm. The newly proposed CPAFT algorithm can mathematically ensure that the generated unstructured triangular/tetrahedral meshes are independent of the number of processors and the implementation of domain decomposition. Several numerical tests are conducted to validate the parallel consistency and outstanding parallel efficiency of the proposed algorithm, which scales effectively up to two thousand processors. This is, as far as we know, the first parallel unstructured triangular/tetrahedral mesh generator with scalability to O(1,000) CPU processors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20618v2</guid>
      <category>math.NA</category>
      <category>cs.CG</category>
      <category>cs.NA</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengdi Ma, Jizu Huang, Hao Luo, Chao Yang</dc:creator>
    </item>
    <item>
      <title>Intrinsic mixed-dimensional beam-shell-solid couplings in linear Cosserat continua via tangential differential calculus</title>
      <link>https://arxiv.org/abs/2407.12515</link>
      <description>arXiv:2407.12515v3 Announce Type: replace 
Abstract: We present an approach to the coupling of mixed-dimensional continua by employing the mathematically enriched linear Cosserat micropolar model. The kinematical reduction of the model to lower dimensional domains leaves its fundamental degrees of freedom intact. Consequently, the degrees of freedom intrinsically agree even at the interface with a domain of a different dimensionality. Thus, this approach circumvents the need for intermediate finite elements or mortar methods. We introduce the derivations of all models of various dimensions using tangential differential calculus. The coupling itself is then achieved by defining a mixed-dimensional action functional with consistent Sobolev trace operators. Finally, we present numerical examples involving a three-dimensional silicone-rubber block reinforced with a curved graphite shell on its lower surface, a three-dimensional silver block reinforced with a graphite plate and beams, and lastly, intersecting silver shells reinforced with graphite beams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12515v3</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Adam Sky, Jack S. Hale, Andreas Zilian, St\'ephane P. A. Bordas, Patrizio Neff</dc:creator>
    </item>
    <item>
      <title>Differential Inversion of the Implicit Euler Method: Symbolic Analysis</title>
      <link>https://arxiv.org/abs/2409.05445</link>
      <description>arXiv:2409.05445v2 Announce Type: replace 
Abstract: The implicit Euler method integrates systems of ordinary differential equations $$\frac{d x}{d t}=G(t,x(t))$$ with differentiable right-hand side $G : {\mathbb R} \times {\mathbb R}^n \rightarrow {\mathbb R}^n$ from an initial state $x=x(0) \in {\mathbb R}^n$ to a target time $t \in {\mathbb R}$ as $x(t)=E(t,m,x)$ using an equidistant discretization of the time interval $[0,t]$ yielding $m&gt;0$ time steps. We present a method for efficiently computing the product of its inverse Jacobian $$(E')^{-1} \equiv \left (\frac{d E}{d x}\right )^{-1} \in {\mathbb R}^{n \times n} $$ with a given vector $v \in {\mathbb R}^n.$ We show that the differential inverse $(E')^{-1} \cdot v$ can be evaluated for given $v \in {\mathbb R}^n$ with a computational cost of $\mathcal{O}(m \cdot n^2)$ as opposed to the standard $\mathcal{O}(m \cdot n^3)$ or, naively, even $\mathcal{O}(m \cdot n^4).$ The theoretical results are supported by actual run times. A reference implementation is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05445v2</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Uwe Naumann</dc:creator>
    </item>
    <item>
      <title>Local MALA-within-Gibbs for Bayesian image deblurring with total variation prior</title>
      <link>https://arxiv.org/abs/2409.09810</link>
      <description>arXiv:2409.09810v2 Announce Type: replace 
Abstract: We consider Bayesian inference for image deblurring with total variation (TV) prior. Since the posterior is analytically intractable, we resort to Markov chain Monte Carlo (MCMC) methods. However, since most MCMC methods significantly deteriorate in high dimensions, they are not suitable to handle high resolution imaging problems. In this paper, we show how low-dimensional sampling can still be facilitated by exploiting the sparse conditional structure of the posterior. To this end, we make use of the local structures of the blurring operator and the TV prior by partitioning the image into rectangular blocks and employing a blocked Gibbs sampler with proposals stemming from the Metropolis-Hastings adjusted Langevin Algorithm (MALA). We prove that this MALA-within-Gibbs (MLwG) sampling algorithm has dimension-independent block acceptance rates and dimension-independent convergence rate. In order to apply the MALA proposals, we approximate the TV by a smoothed version, and show that the introduced approximation error is evenly distributed and dimension-independent. Since the posterior is a Gibbs density, we can use the Hammersley-Clifford Theorem to identify the posterior conditionals which only depend locally on the neighboring blocks. We outline computational strategies to evaluate the conditionals, which are the target densities in the Gibbs updates, locally and in parallel. In two numerical experiments, we validate the dimension-independent properties of the MLwG algorithm and demonstrate its superior performance over MALA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09810v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafael Flock, Shuigen Liu, Yiqiu Dong, Xin T. Tong</dc:creator>
    </item>
    <item>
      <title>Practical Aspects on Solving Differential Equations Using Deep Learning: A Primer</title>
      <link>https://arxiv.org/abs/2408.11266</link>
      <description>arXiv:2408.11266v2 Announce Type: replace-cross 
Abstract: Deep learning has become a popular tool across many scientific fields, including the study of differential equations, particularly partial differential equations. This work introduces the basic principles of deep learning and the Deep Galerkin method, which uses deep neural networks to solve differential equations. This primer aims to provide technical and practical insights into the Deep Galerkin method and its implementation. We demonstrate how to solve the one-dimensional heat equation step-by-step. We also show how to apply the Deep Galerkin method to solve systems of ordinary differential equations and integral equations, such as the Fredholm of the second kind. Additionally, we provide code snippets within the text and the complete source code on Github. The examples are designed so that one can run them on a simple computer without needing a GPU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11266v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 19 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Georgios Is. Detorakis</dc:creator>
    </item>
  </channel>
</rss>
