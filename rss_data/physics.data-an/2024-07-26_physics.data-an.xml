<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 26 Jul 2024 04:00:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 26 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Application of the Digital Annealer Unit in Optimizing Chemical Reaction Conditions for Enhanced Production Yields</title>
      <link>https://arxiv.org/abs/2407.17485</link>
      <description>arXiv:2407.17485v1 Announce Type: cross 
Abstract: Finding appropriate reaction conditions that yield high product rates in chemical synthesis is crucial for the chemical and pharmaceutical industries. However, due to the vast chemical space, conducting experiments for each possible reaction condition is impractical. Consequently, models such as QSAR (Quantitative Structure-Activity Relationship) or ML (Machine Learning) have been developed to predict the outcomes of reactions and illustrate how reaction conditions affect product yield. Despite these advancements, inferring all possible combinations remains computationally prohibitive when using a conventional CPU. In this work, we explore using a Digital Annealing Unit (DAU) to tackle these large-scale optimization problems more efficiently by solving Quadratic Unconstrained Binary Optimization (QUBO). Two types of QUBO models are constructed in this work: one using quantum annealing and the other using ML. Both models are built and tested on four high-throughput experimentation (HTE) datasets and selected Reaxys datasets. Our results suggest that the performance of models is comparable to classical ML methods (i.e., Random Forest and Multilayer Perceptron (MLP)), while the inference time of our models requires only seconds with a DAU. Additionally, in campaigns involving active learning and autonomous design of reaction conditions to achieve higher reaction yield, our model demonstrates significant improvements by adding new data, showing promise of adopting our method in the iterative nature of such problem settings. Our method can also accelerate the screening of billions of reaction conditions, achieving speeds millions of times faster than traditional computing units in identifying superior conditions. Therefore, leveraging the DAU with our developed QUBO models has the potential to be a valuable tool for innovative chemical synthesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17485v1</guid>
      <category>physics.chem-ph</category>
      <category>cs.ET</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shih-Cheng Li, Pei-Hwa Wang, Jheng-Wei Su, Wei-Yin Chiang, Shih-Hsien Huang, Yen-Chu Lin, Chia-Ho Ou, Chih-Yu Chen</dc:creator>
    </item>
    <item>
      <title>The most likely common cause</title>
      <link>https://arxiv.org/abs/2306.17557</link>
      <description>arXiv:2306.17557v2 Announce Type: replace 
Abstract: The common cause principle for two random variables $A$ and $B$ is examined in the case of causal insufficiency, when their common cause $C$ is known to exist, but only the joint probability of $A$ and $B$ is observed. As a result, $C$ cannot be uniquely identified (the latent confounder problem). We show that the generalized maximum likelihood method can be applied to this situation and allows identification of $C$ that is consistent with the common cause principle. It closely relates to the maximum entropy principle. Investigation of the two binary symmetric variables reveals a non-analytic behavior of conditional probabilities reminiscent of a second-order phase transition. This occurs during the transition from correlation to anti-correlation in the observed probability distribution. The relation between the generalized likelihood approach and alternative methods, such as predictive likelihood and the minimum common cause entropy, is discussed. The consideration of the common cause for three observed variables (and one hidden cause) uncovers causal structures that defy representation through directed acyclic graphs with the Markov condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.17557v2</guid>
      <category>physics.data-an</category>
      <category>cs.AI</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. Hovhannisyan, A. E. Allahverdyan</dc:creator>
    </item>
    <item>
      <title>Robust experimental data assimilation for the Spalart-Allmaras turbulence model</title>
      <link>https://arxiv.org/abs/2309.06679</link>
      <description>arXiv:2309.06679v3 Announce Type: replace-cross 
Abstract: This study presents a methodology focusing on the use of computational model and experimental data fusion to improve the Spalart-Allmaras (SA) closure model for Reynolds-averaged Navier-Stokes solutions. In particular, our goal is to develop a technique that not only assimilates sparse experimental data to improve turbulence model performance, but also preserves generalization for unseen cases by recovering classical SA behavior. We achieve our goals using data assimilation, namely the Ensemble Kalman filtering approach (EnKF), to calibrate the coefficients of the SA model for separated flows. A holistic calibration strategy is implemented via the parameterization of the production, diffusion, and destruction terms. This calibration relies on the assimilation of experimental data collected in the form of velocity profiles, skin friction, and pressure coefficients. Despite using observational data from a single flow condition around a backward-facing step (BFS), the recalibrated SA model demonstrates generalization to other separated flows, including cases such as the 2D NASA wall mounted hump (2D-WMH) and modified BFS. Significant improvement is observed in the quantities of interest, i.e., skin friction coefficient ($C_f$) and pressure coefficient ($C_p$) for each flow tested. Finally, it is also demonstrated that the newly proposed model recovers SA proficiency for flows, such as a NACA-0012 airfoil and axisymmetric jet (ASJ), and that the individually calibrated terms in the SA model target specific flow-physics wherein the calibrated production term improves the re-circulation zone while destruction improves the recovery zone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.06679v3</guid>
      <category>physics.flu-dyn</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deepinder Jot Singh Aulakh, Xiang Yang, Romit Maulik</dc:creator>
    </item>
    <item>
      <title>Accurate Machine Learning Predictions of Coercivity in High-Performance Permanent Magnets</title>
      <link>https://arxiv.org/abs/2312.02475</link>
      <description>arXiv:2312.02475v4 Announce Type: replace-cross 
Abstract: Increased demand for high-performance permanent magnets in the electric vehicle and wind turbine industries has prompted the search for cost-effective alternatives.Discovering new magnetic materials with the desired intrinsic and extrinsic permanent magnet properties presents a significant challenge to researchers because of issues with the global supply of rare-earth elements, material stability, and a low maximum magnetic energy product BH$_{max}$.While first-principle density functional theory (DFT) predicts materials' magnetic moments, magneto-crystalline anisotropy constants, and exchange interactions, it cannot compute coercivity ($H_c$).Although it is possible to calculate $H_c$ theoretically with micromagnetic simulations, the predicted value is larger than the experiment by almost an order of magnitude, due to the Brown paradox.To circumvent these, we employ machine learning (ML) methods on an extensive database obtained from experiments, DFT calculations, and micromagnetic modeling.The use of a large dataset enables realistic $H_c$ predictions for materials such as Ce-doped Nd$_2$Fe$_{14}$B, comparing favorably against micromagnetically simulated coercivities.Remarkably, our ML model accurately identifies uniaxial magneto-crystalline anisotropy as the primary contributor to $H_c$. With DFT calculations, we predict the Nd-site dependent magnetic anisotropy behavior in Nd$_2$Fe$_{14}$B, confirming that Nd $4g$-sites mainly contribute to uniaxial magneto-crystalline anisotropy, and also calculate Curie temperature (T$_{C}$).Both calculated results are in good agreement with experiment.The coupled experimental dataset and ML modeling with DFT input predict $H_c$ with far greater accuracy and speed than was previously possible using micromagnetic modeling.Further, we reverse-engineer the inter-grain exchange coupling with micromagnetic simulations by employing the ML predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02475v4</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Churna Bhandari, Gavin N. Nop, Jonathan D. H. Smith, Durga Paudyal</dc:creator>
    </item>
    <item>
      <title>A Priori Uncertainty Quantification of Reacting Turbulence Closure Models using Bayesian Neural Networks</title>
      <link>https://arxiv.org/abs/2402.18729</link>
      <description>arXiv:2402.18729v2 Announce Type: replace-cross 
Abstract: While many physics-based closure model forms have been posited for the sub-filter scale (SFS) in large eddy simulation (LES), vast amounts of data available from direct numerical simulation (DNS) create opportunities to leverage data-driven modeling techniques. Albeit flexible, data-driven models still depend on the dataset and the functional form of the model chosen. Increased adoption of such models requires reliable uncertainty estimates both in the data-informed and out-of-distribution regimes. In this work, we employ Bayesian neural networks (BNNs) to capture both epistemic and aleatoric uncertainties in a reacting flow model. In particular, we model the filtered progress variable scalar dissipation rate which plays a key role in the dynamics of turbulent premixed flames. We demonstrate that BNN models can provide unique insights about the structure of uncertainty of the data-driven closure models. We also propose a method for the incorporation of out-of-distribution information in a BNN. The efficacy of the model is demonstrated by a priori evaluation on a dataset consisting of a variety of flame conditions and fuels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18729v2</guid>
      <category>physics.flu-dyn</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Graham Pash, Malik Hassanaly, Shashank Yellapantula</dc:creator>
    </item>
  </channel>
</rss>
