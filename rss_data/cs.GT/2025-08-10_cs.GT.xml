<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 11 Aug 2025 04:01:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Stochastic Bandits for Crowdsourcing and Multi-Platform Autobidding</title>
      <link>https://arxiv.org/abs/2508.05844</link>
      <description>arXiv:2508.05844v1 Announce Type: new 
Abstract: Motivated by applications in crowdsourcing, where a fixed sum of money is split among $K$ workers, and autobidding, where a fixed budget is used to bid in $K$ simultaneous auctions, we define a stochastic bandit model where arms belong to the $K$-dimensional probability simplex and represent the fraction of budget allocated to each task/auction. The reward in each round is the sum of $K$ stochastic rewards, where each of these rewards is unlocked with a probability that varies with the fraction of the budget allocated to that task/auction. We design an algorithm whose expected regret after $T$ steps is of order $K\sqrt{T}$ (up to log factors) and prove a matching lower bound. Improved bounds of order $K (\log T)^2$ are shown when the function mapping budget to probability of unlocking the reward (i.e., terminating the task or winning the auction) satisfies additional diminishing-returns conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05844v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Bachoc, Nicol\`o Cesa-Bianchi, Tommaso Cesari, Roberto Colomboni</dc:creator>
    </item>
    <item>
      <title>An Overlapping Coalition Game Approach for Collaborative Block Mining and Edge Task Offloading in MEC-assisted Blockchain Networks</title>
      <link>https://arxiv.org/abs/2508.06031</link>
      <description>arXiv:2508.06031v1 Announce Type: new 
Abstract: Mobile edge computing (MEC) is a promising technology that enhances the efficiency of mobile blockchain networks, by enabling miners, often acted by mobile users (MUs) with limited computing resources, to offload resource-intensive mining tasks to nearby edge computing servers. Collaborative block mining can further boost mining efficiency by allowing multiple miners to form coalitions, pooling their computing resources and transaction data together to mine new blocks collaboratively. Therefore, an MEC-assisted collaborative blockchain network can leverage the strengths of both technologies, offering improved efficiency, security, and scalability for blockchain systems. While existing research in this area has mainly focused on the single-coalition collaboration mode, where each miner can only join one coalition, this work explores a more comprehensive multi-coalition collaboration mode, which allows each miner to join multiple coalitions. To analyze the behavior of miners and the edge computing service provider (ECP) in this scenario, we propose a novel two-stage Stackelberg game. In Stage I, the ECP, as the leader, determines the prices of computing resources for all MUs. In Stage II, each MU decides the coalitions to join, resulting in an overlapping coalition formation (OCF) game; Subsequently, each coalition decides how many edge computing resources to purchase from the ECP, leading to an edge resource competition (ERC) game. We derive the closed-form Nash equilibrium for the ERC game, based on which we further propose an OCF-based alternating algorithm to achieve a stable coalition structure for the OCF game and develop a near-optimal pricing strategy for the ECP's resource pricing problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06031v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Licheng Ye, Zehui Xiong, Lin Gao, Dusit Niyato</dc:creator>
    </item>
    <item>
      <title>Social Welfare in Battery Charging Games</title>
      <link>https://arxiv.org/abs/2508.06320</link>
      <description>arXiv:2508.06320v1 Announce Type: new 
Abstract: The recent rise of renewable energy produced by many decentralized sources yields interesting market design challenges for electrical grids. Balancing supply and demand in such networks is both a temporal and spatial challenge due to capacity constraints. The recent surge in the number of household-owned batteries, especially in regions with rooftop solar adoption, offers mitigation potential but often acts misaligned with grid-level objectives. In fact, the decision to charge or discharge a household-owned battery is a strategic choice by each battery owner governed by selfish incentives. This calls for an analysis from a game-theoretic point of view.
  We initiate this timely research direction by considering a game-theoretic setting where selfish agents strategically charge or discharge their batteries to increase their profit. In particular, we study a Stackelberg-like market model where a third party introduces price incentives, aiming to optimize renewable energy utilization while preserving grid feasibility. For this, we study the existence and the quality of equilibria under various pricing strategies. We find that the existence of equilibria crucially depends on the chosen pricing and that the obtained social welfare varies widely. This calls for more sophisticated market models and pricing mechanisms and opens up a rich field for future research in Algorithmic Game Theory on incentives in renewable energy networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06320v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-032-03639-1_4</arxiv:DOI>
      <dc:creator>Simon Krogmann, Pascal Lenzner, Alexander Skopalik, Tobias Str\"aubig</dc:creator>
    </item>
    <item>
      <title>A Geometric Analysis of Gains from Trade</title>
      <link>https://arxiv.org/abs/2508.06469</link>
      <description>arXiv:2508.06469v1 Announce Type: new 
Abstract: We provide a geometric proof that the random proposer mechanism is a $4$-approximation to the first-best gains from trade in bilateral exchange. We then refine this geometric analysis to recover the state-of-the-art approximation ratio of $3.15$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06469v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason Hartline, Kangning Wang</dc:creator>
    </item>
    <item>
      <title>Can LLMs effectively provide game-theoretic-based scenarios for cybersecurity?</title>
      <link>https://arxiv.org/abs/2508.05670</link>
      <description>arXiv:2508.05670v1 Announce Type: cross 
Abstract: Game theory has long served as a foundational tool in cybersecurity to test, predict, and design strategic interactions between attackers and defenders. The recent advent of Large Language Models (LLMs) offers new tools and challenges for the security of computer systems; In this work, we investigate whether classical game-theoretic frameworks can effectively capture the behaviours of LLM-driven actors and bots. Using a reproducible framework for game-theoretic LLM agents, we investigate two canonical scenarios -- the one-shot zero-sum game and the dynamic Prisoner's Dilemma -- and we test whether LLMs converge to expected outcomes or exhibit deviations due to embedded biases. Our experiments involve four state-of-the-art LLMs and span five natural languages, English, French, Arabic, Vietnamese, and Mandarin Chinese, to assess linguistic sensitivity. For both games, we observe that the final payoffs are influenced by agents characteristics such as personality traits or knowledge of repeated rounds. Moreover, we uncover an unexpected sensitivity of the final payoffs to the choice of languages, which should warn against indiscriminate application of LLMs in cybersecurity applications and call for in-depth studies, as LLMs may behave differently when deployed in different countries. We also employ quantitative metrics to evaluate the internal consistency and cross-language stability of LLM agents, to help guide the selection of the most stable LLMs and optimising models for secure applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05670v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniele Proverbio, Alessio Buscemi, Alessandro Di Stefano, The Anh Han, German Castignani, Pietro Li\`o</dc:creator>
    </item>
    <item>
      <title>The Fair Game: Auditing &amp; Debiasing AI Algorithms Over Time</title>
      <link>https://arxiv.org/abs/2508.06443</link>
      <description>arXiv:2508.06443v1 Announce Type: cross 
Abstract: An emerging field of AI, namely Fair Machine Learning (ML), aims to quantify different types of bias (also known as unfairness) exhibited in the predictions of ML algorithms, and to design new algorithms to mitigate them. Often, the definitions of bias used in the literature are observational, i.e. they use the input and output of a pre-trained algorithm to quantify a bias under concern. In reality,these definitions are often conflicting in nature and can only be deployed if either the ground truth is known or only in retrospect after deploying the algorithm. Thus,there is a gap between what we want Fair ML to achieve and what it does in a dynamic social environment. Hence, we propose an alternative dynamic mechanism,"Fair Game",to assure fairness in the predictions of an ML algorithm and to adapt its predictions as the society interacts with the algorithm over time. "Fair Game" puts together an Auditor and a Debiasing algorithm in a loop around an ML algorithm. The "Fair Game" puts these two components in a loop by leveraging Reinforcement Learning (RL). RL algorithms interact with an environment to take decisions, which yields new observations (also known as data/feedback) from the environment and in turn, adapts future decisions. RL is already used in algorithms with pre-fixed long-term fairness goals. "Fair Game" provides a unique framework where the fairness goals can be adapted over time by only modifying the auditor and the different biases it quantifies. Thus,"Fair Game" aims to simulate the evolution of ethical and legal frameworks in the society by creating an auditor which sends feedback to a debiasing algorithm deployed around an ML system. This allows us to develop a flexible and adaptive-over-time framework to build Fair ML systems pre- and post-deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06443v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.GT</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1017/cfl.2025.8</arxiv:DOI>
      <arxiv:journal_reference>Cambridge Forum on AI: Law and Governance , Volume 1 , 2025 , p. e27</arxiv:journal_reference>
      <dc:creator>Debabrota Basu, Udvas Das</dc:creator>
    </item>
    <item>
      <title>What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting</title>
      <link>https://arxiv.org/abs/2508.06454</link>
      <description>arXiv:2508.06454v1 Announce Type: cross 
Abstract: Committee-selection problems arise in many contexts and applications, and there has been increasing interest within the social choice research community on identifying which properties are satisfied by different multi-winner voting rules. In this work, we propose a data-driven framework to evaluate how frequently voting rules violate axioms across diverse preference distributions in practice, shifting away from the binary perspective of axiom satisfaction given by worst-case analysis. Using this framework, we analyze the relationship between multi-winner voting rules and their axiomatic performance under several preference distributions. We then show that neural networks, acting as voting rules, can outperform traditional rules in minimizing axiom violations. Our results suggest that data-driven approaches to social choice can inform the design of new voting systems and support the continuation of data-driven research in social choice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06454v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Caiata, Ben Armstrong, Kate Larson</dc:creator>
    </item>
    <item>
      <title>Transaction Fee Market Design for Parallel Execution</title>
      <link>https://arxiv.org/abs/2502.11964</link>
      <description>arXiv:2502.11964v2 Announce Type: replace 
Abstract: Given the low throughput of blockchains like Bitcoin and Ethereum, scalability - the ability to process an increasing number of transactions - has become a central focus of blockchain research. One promising approach is the parallelization of transaction execution across multiple threads. However, achieving efficient parallelization requires a redesign of the incentive structure within the fee market. Currently, the fee market does not differentiate between transactions that access multiple high-demand storage keys (i.e., unique identifiers for individual data entries) versus a single low-demand one, as long as they require the same computational effort. Addressing this discrepancy is crucial for enabling more effective parallel execution.
  In this work, we aim to bridge the gap between the current fee market and the need for parallel execution by exploring alternative fee market designs. To this end, we propose a framework consisting of two key components: a Gas Computation Mechanism (GCM), which quantifies the load a transaction places on the network in terms of parallelization and computation, measured in units of gas, and a Transaction Fee Mechanism (TFM), which assigns a price to each unit of gas. We additionally introduce a set of desirable properties for a GCM, propose several candidate mechanisms, and evaluate them against these criteria. Our analysis highlights two strong candidates: the weighted area GCM, which integrates smoothly with existing TFMs such as EIP-1559 and satisfies a broad subset of the outlined properties, and the time-proportional makespan GCM, which assigns gas costs based on the context of the entire block's schedule and, through this dependence on the overall execution outcome, captures the dynamics of parallel execution more accurately.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11964v2</guid>
      <category>cs.GT</category>
      <category>cs.DC</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bahar Acilan, Andrei Constantinescu, Lioba Heimbach, Roger Wattenhofer</dc:creator>
    </item>
    <item>
      <title>Selfish Mining under General Stochastic Rewards</title>
      <link>https://arxiv.org/abs/2502.20360</link>
      <description>arXiv:2502.20360v2 Announce Type: replace 
Abstract: Selfish miners selectively withhold blocks to earn disproportionately high revenue. The vast majority of the selfish mining literature focuses exclusively on block rewards. Carlsten et al. [2016] is a notable exception, observing that similar strategic behavior is profitable in a zero-block-reward regime (the endgame for Bitcoin's quadrennial halving schedule) if miners are compensated with transaction fees alone. Neither model fully captures miner incentives today. The block reward remains 3.125 BTC, yet some blocks yield significantly higher revenue. For example, congestion during the launch of the Babylon protocol in August 2024 caused transaction fees to spike to 9.52 BTC. Our results are both practical and theoretical. Of practical interest, we study selfish mining profitability under a combined reward function that more accurately models miner incentives. This analysis enables us to make quantitative claims about protocol risk (e.g., the mining power at which a selfish strategy becomes profitable is reduced by 22% when optimizing over the combined reward function versus block rewards alone) and qualitative observations (e.g., a miner considering both block rewards and transaction fees will mine more or less aggressively respectively). These practical results follow from our novel model and methodology, which constitute our theoretical contributions. We model general, time-accruing stochastic rewards, which requires explicit treatment of difficult adjustment and randomness; we characterize reward function structure through a set of properties (e.g., that rewards accrue only as a function of time). We present a new methodology to analytically calculate expected selfish miner rewards under a broad class of stochastic reward functions and validate our method numerically by comparing it with the existing literature and simulating the combined reward sources directly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20360v2</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maryam Bahrani, Michael Neuder, S. Matthew Weinberg</dc:creator>
    </item>
    <item>
      <title>Precomputed Dominant Resource Fairness</title>
      <link>https://arxiv.org/abs/2507.08846</link>
      <description>arXiv:2507.08846v2 Announce Type: replace 
Abstract: Although resource allocation is a well studied problem in computer science, until the prevalence of distributed systems, such as computing clouds and data centres, the question had been addressed predominantly for single resource type scenarios. At the beginning of the last decade, with the introuction of Dominant Resource Fairness, the studies of the resource allocation problem has finally extended to the multiple resource type scenarios. Dominant Resource Fairness is a solution, addressing the problem of fair allocation of multiple resource types, among users with heterogeneous demands. Based on Max-min Fairness, which is a well established algorithm in the literature for allocating resources in the single resource type scenarios, Dominant Resource Fairness generalises the scheme to the multiple resource case. It has a number of desirable properties that makes it preferable over alternatives, such as Sharing Incentive, Envy-Freeness, Pareto Efficiency, and Strategy Proofness, and as such, it is widely adopted in distributed systems. In the present study, we revisit the original study, and analyse the structure of the algorithm in closer view, to come up with an alternative algorithm, which approximates the Dominant Resource Fairness allocation in fewer steps. We name the new algorithm Precomputed Dominant Resource Fairness, after its main working principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08846v2</guid>
      <category>cs.GT</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Serdar Metin</dc:creator>
    </item>
    <item>
      <title>What Do Agents Think Others Would Do? Level-2 Inverse Games for Inferring Agents' Estimates of Others' Objectives</title>
      <link>https://arxiv.org/abs/2508.03824</link>
      <description>arXiv:2508.03824v2 Announce Type: replace 
Abstract: Effectively interpreting strategic interactions among multiple agents requires us to infer each agent's objective from limited information. Existing inverse game-theoretic approaches frame this challenge in terms of a "level-1" inference problem, in which we take the perspective of a third-party observer and assume that individual agents share complete knowledge of one another's objectives. However, this assumption breaks down in decentralized, real-world decision scenarios like urban driving and bargaining, in which agents may act based on conflicting views of one another's objectives. We demonstrate the necessity of inferring agents' heterogeneous estimates of each other's objectives through empirical examples, and by theoretically characterizing the prediction error of level-1 inference on fictitious gameplay data from linear-quadratic games. To address this fundamental issue, we propose a framework for level-2 inference to address the question: "What does each agent believe about all agents' objectives?" We prove that the level-2 inference problem is non-convex even in benign settings like linear-quadratic games, and we develop an efficient gradient-based approach for identifying local solutions. Experiments on a synthetic urban driving example show that our approach uncovers nuanced misalignments that level-1 methods miss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03824v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hamzah I. Khan, Jingqi Li, David Fridovich-Keil</dc:creator>
    </item>
    <item>
      <title>Off-Policy Evaluation for Sequential Persuasion Process with Unobserved Confounding</title>
      <link>https://arxiv.org/abs/2504.01211</link>
      <description>arXiv:2504.01211v2 Announce Type: replace-cross 
Abstract: In this paper, we expand the Bayesian persuasion framework to account for unobserved confounding variables in sender-receiver interactions. While traditional models assume that belief updates follow Bayesian principles, real-world scenarios often involve hidden variables that impact the receiver's belief formation and decision-making. We conceptualize this as a sequential decision-making problem, where the sender and receiver interact over multiple rounds. In each round, the sender communicates with the receiver, who also interacts with the environment. Crucially, the receiver's belief update is affected by an unobserved confounding variable. By reformulating this scenario as a Partially Observable Markov Decision Process (POMDP), we capture the sender's incomplete information regarding both the dynamics of the receiver's beliefs and the unobserved confounder. We prove that finding an optimal observation-based policy in this POMDP is equivalent to solving for an optimal signaling strategy in the original persuasion framework. Furthermore, we demonstrate how this reformulation facilitates the application of proximal learning for off-policy evaluation in the persuasion process. This advancement enables the sender to evaluate alternative signaling strategies using only observational data from a behavioral policy, thus eliminating the necessity for costly new experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01211v2</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 11 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nishanth Venkatesh S., Heeseung Bang, Andreas A. Malikopoulos</dc:creator>
    </item>
  </channel>
</rss>
