<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Jan 2025 05:02:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Statistical Design of Thermal Protection System Using Physics-Informed Neural Network</title>
      <link>https://arxiv.org/abs/2501.18078</link>
      <description>arXiv:2501.18078v1 Announce Type: new 
Abstract: Thermal protection systems (TPS) of space vehicles are designed computationally rather than experimentally. They are validated using ground experiments, but all aspects of the flight cannot be replicated on ground. This ground-to-flight mapping introduces uncertainties which need to be accounted for while designing any thermal protection system. Thus, precise computational models along with uncertainty quantification in the models are required to design the TPS. The focus of this study is to estimate the thermal material parameters of TPS based on the target reliability requirements using statistical methods. To perform uncertainty quantification (UQ) of a system, a simulated model of the system needs to be solved many times on statistical samples, increasing the computational time and cost of the overall process. A physics-informed neural network (PINN) model is used in the analysis instead of traditional physics based numerical solutions. The accuracy of PINN is comparable to that of the numerical solution. To find the parameter distribution, sampling of the parameter space is performed using Sequential Monte- Carlo (SMC) method. The sampling method is efficient as it generates samples based on the target distribution in parallel and it also generates diverse samples for proper UQ. Combining the use of both PINN predictive model and SMC sampling, the framework can approximate the parameter distributions that satisfy the TPS design reliability constraints. The framework achieved remarkable increases in the speed of performing the reliability analysis of the TPS. This reliability analysis can be used for design optimization of the TPS based on risk analysis along with other systems of the vehicle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18078v1</guid>
      <category>cs.CE</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karthik Reddy Lyathakula, Aseem Muhammad, Sevki Cesmeci</dc:creator>
    </item>
    <item>
      <title>Characterization of Permanent Magnet Synchronous Machines based on semi-analytic model reduction for drive cycle analysis</title>
      <link>https://arxiv.org/abs/2501.18200</link>
      <description>arXiv:2501.18200v1 Announce Type: new 
Abstract: The characterization of an interior permanent magnet synchronous machine (IPMSM) requires numerical analysis of the nonlinear magnetic motor model in different load conditions. To obtain the case-specific best machine behavior, a strategy for the determination of stator input current amplitude and angle is employed for all possible load torques given a limited terminal current amplitude and DC bus voltage. Various losses are calculated using state of the art loss models. The electromagnetic performance of the electric machine is stored in lookup tables. These can then be used for the drive cycle analysis of the electric drive train in the design and optimization stages.
  To avoid the use of a dedicated mesh generator in the numerical analysis, volumetric spline-based models are suggested.With this approach, the mesh can be generated directly from the Computer Aided Design (CAD) geometry. This enables an automatic adaption of the grid following a geometry perturbation. With this the approximated solution is kept consistent over the different iterations of an overlying optimization, improving its convergence behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18200v1</guid>
      <category>cs.CE</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leon Blumrich, Yves Burkhardt, Sebastian Sch\"ops</dc:creator>
    </item>
    <item>
      <title>Neural Network Modeling of Microstructure Complexity Using Digital Libraries</title>
      <link>https://arxiv.org/abs/2501.18189</link>
      <description>arXiv:2501.18189v1 Announce Type: cross 
Abstract: Microstructure evolution in matter is often modeled numerically using field or level-set solvers, mirroring the dual representation of spatiotemporal complexity in terms of pixel or voxel data, and geometrical forms in vector graphics. Motivated by this analog, as well as the structural and event-driven nature of artificial and spiking neural networks, respectively, we evaluate their performance in learning and predicting fatigue crack growth and Turing pattern development. Predictions are made based on digital libraries constructed from computer simulations, which can be replaced by experimental data to lift the mathematical overconstraints of physics. Our assessment suggests that the leaky integrate-and-fire neuron model offers superior predictive accuracy with fewer parameters and less memory usage, alleviating the accuracy-cost tradeoff in contrast to the common practices in computer vision tasks. Examination of network architectures shows that these benefits arise from its reduced weight range and sparser connections. The study highlights the capability of event-driven models in tackling problems with evolutionary bulk-phase and interface behaviors using the digital library approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18189v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.CE</category>
      <category>nlin.PS</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingjie Zhao, Zhiping Xu</dc:creator>
    </item>
    <item>
      <title>A weakly compressible SPH method for RANS simulation of wall-bounded turbulent flows</title>
      <link>https://arxiv.org/abs/2501.18397</link>
      <description>arXiv:2501.18397v1 Announce Type: cross 
Abstract: This paper presents a Weakly Compressible Smoothed Particle Hydrodynamics (WCSPH) method for solving the two-equation Reynolds-Averaged Navier-Stokes (RANS) model. The turbulent wall-bounded flow with or without mild flow separation, a crucial flow pattern in engineering applications, yet rarely explored in the SPH community, is simulated. The inconsistency between the Lagrangian characteristic and RANS model, mainly due to the intense particle shear and near-wall discontinuity, is firstly revealed and addressed by the mainstream and nearwall improvements, respectively. The mainstream improvements, including Adaptive Riemann-eddy Dissipation (ARD) and Limited Transport Velocity Formulation (LTVF), address dissipation incompatibility and turbulent kinetic energy over-prediction issues. The nearwall improvements, such as the particle-based wall model realization, weighted near-wall compensation scheme, and constant $y_p$ strategy, improve the accuracy and stability of the adopted wall model, where the wall dummy particles are still used for future coupling of solid dynamics. Besides, to perform rigorous convergence tests, an level-set-based boundary-offset technique is developed to ensure consistent $y^+$ across different resolutions. The benchmark wall-bounded turbulent cases, including straight, mildly- and strongly-curved, and Half Converging and Diverging (HCD) channels are calculated. Good convergence is, to our best knowledge, firstly achieved for both velocity and turbulent kinetic energy for the SPH-RANS method. All the results agree well with the data from the experiments or simulated by the Eulerian methods at engineering-acceptable resolutions. The proposed method bridges particle-based and mesh-based RANS models, providing adaptability for other turbulence models and potential for turbulent fluid-structure interaction (FSI) simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18397v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.CE</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feng Wang, Zhongguo Sun, Xiangyu Hu</dc:creator>
    </item>
    <item>
      <title>Gaussian process regression + deep neural network autoencoder for probabilistic surrogate modeling in nonlinear mechanics of solids</title>
      <link>https://arxiv.org/abs/2407.10732</link>
      <description>arXiv:2407.10732v2 Announce Type: replace 
Abstract: Many real-world applications demand accurate and fast predictions, as well as reliable uncertainty estimates. However, quantifying uncertainty on high-dimensional predictions is still a severely under-investigated problem, especially when input-output relationships are non-linear. To handle this problem, the present work introduces an innovative approach that combines autoencoder deep neural networks with the probabilistic regression capabilities of Gaussian processes. The autoencoder provides a low-dimensional representation of the solution space, while the Gaussian process is a Bayesian method that provides a probabilistic mapping between the low-dimensional inputs and outputs. We validate the proposed framework for its application to surrogate modeling of non-linear finite element simulations. Our findings highlight that the proposed framework is computationally efficient as well as accurate in predicting non-linear deformations of solid bodies subjected to external forces, all the while providing insightful uncertainty assessments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10732v2</guid>
      <category>cs.CE</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Saurabh Deshpande, Hussein Rappel, Mark Hobbs, St\'ephane P. A. Bordas, Jakub Lengiewicz</dc:creator>
    </item>
    <item>
      <title>Energy-based physics-informed neural network for frictionless contact problems under large deformation</title>
      <link>https://arxiv.org/abs/2411.03671</link>
      <description>arXiv:2411.03671v2 Announce Type: replace 
Abstract: Numerical methods for contact mechanics are of great importance in engineering applications, enabling the prediction and analysis of complex surface interactions under various conditions. In this work, we propose an energy-based physics-informed neural network (PINNs) framework for solving frictionless contact problems under large deformation. Inspired by microscopic Lennard-Jones potential, a surface contact energy is used to describe the contact phenomena. To ensure the robustness of the proposed PINN framework, relaxation, gradual loading and output scaling techniques are introduced. In the numerical examples, the well-known Hertz contact benchmark problem is conducted, demonstrating the effectiveness and robustness of the proposed PINNs framework. Moreover, challenging contact problems with the consideration of geometrical and material nonlinearities are tested. It has been shown that the proposed PINNs framework provides a reliable and powerful tool for nonlinear contact mechanics. More importantly, the proposed PINNs framework exhibits competitive computational efficiency to the commercial FEM software when dealing with those complex contact problems. The codes used in this manuscript are available at https://github.com/JinshuaiBai/energy_PINN_Contact.(The code will be available after acceptance)</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03671v2</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinshuai Bai, Zhongya Lin, Yizheng Wang, Jiancong Wen, Yinghua Liu, Timon Rabczuk, YuanTong Gu, Xi-Qiao Feng</dc:creator>
    </item>
    <item>
      <title>Generating Synthetic Genotypes using Diffusion Models</title>
      <link>https://arxiv.org/abs/2412.03278</link>
      <description>arXiv:2412.03278v3 Announce Type: replace 
Abstract: In this paper, we introduce the first diffusion model designed to generate complete synthetic human genotypes, which, by standard protocols, one can straightforwardly expand into full-length, DNA-level genomes. The synthetic genotypes mimic real human genotypes without just reproducing known genotypes, in terms of approved metrics. When training biomedically relevant classifiers with synthetic genotypes, accuracy is near-identical to the accuracy achieved when training classifiers with real data. We further demonstrate that augmenting small amounts of real with synthetically generated genotypes drastically improves performance rates. This addresses a significant challenge in translational human genetics: real human genotypes, although emerging in large volumes from genome wide association studies, are sensitive private data, which limits their public availability. Therefore, the integration of additional, insensitive data when striving for rapid sharing of biomedical knowledge of public interest appears imperative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03278v3</guid>
      <category>cs.CE</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip Kenneweg, Raghuram Dandinasivara, Xiao Luo, Barbara Hammer, Alexander Sch\"onhuth</dc:creator>
    </item>
  </channel>
</rss>
