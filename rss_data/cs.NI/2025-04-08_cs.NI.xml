<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Apr 2025 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Negotiating Strict Latency Limits for Dynamic Real-Time Services in Vehicular Time-Sensitive Networks</title>
      <link>https://arxiv.org/abs/2504.05793</link>
      <description>arXiv:2504.05793v1 Announce Type: new 
Abstract: Future vehicles are expected to dynamically deploy in-vehicle applications within a Service-Oriented Architecture (SOA). Critical services operate under hard real-time constraints, which Time-Sensitive Networking (TSN) complements on the in-vehicle Ethernet layer. TSN ensures deterministic communication between critical services and its Credit-Based Shaper (CBS) supports dynamic resource reservations. However, the dynamic nature of service deployment challenges network resource configuration, since any new reservation may change the latency of already validated flows. In addition, standard methods of worst-case latency analysis for CBS have been found incorrect, and current TSN stream reservation procedures lack mechanisms to signal application layer Quality-of-Service (QoS) requirements or verify deadlines. In this paper, we propose a QoS negotiation scheme within the automotive SOA that interacts with the TSN network controller to reserve resources while ensuring latency bounds. We comparatively evaluate reservation schemes using worst-case analysis and simulations of a realistic In-Vehicle Network (IVN) for demonstrating their impact on QoS guarantees, resource utilization, and setup times. We find that only a reservation scheme utilizing per-queue delay budgets and network calculus provides valid configurations and guarantees acceptable latency bounds throughout the IVN. The proposed service negotiation mechanism efficiently establishes 450 vehicular network reservations in just 11ms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05793v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timo H\"ackel, Lisa Maile, Philipp Meyer, Franz Korf, Thomas C. Schmidt</dc:creator>
    </item>
    <item>
      <title>Context-aware Rate Adaptation for Predictive Flying Networks using Contextual Bandits</title>
      <link>https://arxiv.org/abs/2504.05964</link>
      <description>arXiv:2504.05964v1 Announce Type: new 
Abstract: The increasing complexity of wireless technologies, such as Wi-Fi, presents significant challenges for Rate Adaptation (RA) due to the large configuration space of transmission parameters. While extensive research has been conducted on RA for low-mobility networks, existing solutions fail to adapt in flying networks, where high mobility and dynamic wireless conditions introduce additional uncertainty.
  We propose Linear Upper Confidence Bound for RA (LinRA), a novel Contextual Bandit-based approach that leverages real-time link context to optimize transmission rates. Designed for predictive flying networks, where future trajectories are known, LinRA proactively adapts to obstacles affecting channel quality. Simulation results demonstrate that LinRA converges $\mathbf{5.2\times}$ faster than state-of-the-art benchmarks and improves throughput by 80\% in Non Line-of-Sight (NLoS) conditions, matching the performance of ideal algorithms. With low time complexity, LinRA is a scalable and efficient RA solution for predictive flying networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05964v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruben Queiros, Megumi Kaneko, Helder Fontes, Rui Campos</dc:creator>
    </item>
    <item>
      <title>Multi-Modality Sensing in mmWave Beamforming for Connected Vehicles Using Deep Learning</title>
      <link>https://arxiv.org/abs/2504.06173</link>
      <description>arXiv:2504.06173v1 Announce Type: new 
Abstract: Beamforming techniques are considered as essential parts to compensate severe path losses in millimeter-wave (mmWave) communications. In particular, these techniques adopt large antenna arrays and formulate narrow beams to obtain satisfactory received powers. However, performing accurate beam alignment over narrow beams for efficient link configuration by traditional standard defined beam selection approaches, which mainly rely on channel state information and beam sweeping through exhaustive searching, imposes computational and communications overheads. And, such resulting overheads limit their potential use in vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V) communications involving highly dynamic scenarios. In comparison, utilizing out-of-band contextual information, such as sensing data obtained from sensor devices, provides a better alternative to reduce overheads. This paper presents a deep learning-based solution for utilizing the multi-modality sensing data for predicting the optimal beams having sufficient mmWave received powers so that the best V2I and V2V line-of-sight links can be ensured proactively. The proposed solution has been tested on real-world measured mmWave sensing and communication data, and the results show that it can achieve up to 98.19% accuracies while predicting top-13 beams. Correspondingly, when compared to existing been sweeping approach, the beam sweeping searching space and time overheads are greatly shortened roughly by 79.67% and 91.89%, respectively which confirm a promising solution for beamforming in mmWave enabled communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06173v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCCN.2025.3558026</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Cognitive Communications and Networking, 2025</arxiv:journal_reference>
      <dc:creator>Muhammad Baqer Mollah, Honggang Wang, Mohammad Ataul Karim, Hua Fang</dc:creator>
    </item>
    <item>
      <title>Status Updating with Time Stamp Errors</title>
      <link>https://arxiv.org/abs/2504.05371</link>
      <description>arXiv:2504.05371v1 Announce Type: cross 
Abstract: A status updating system is considered in which multiple processes are sampled and transmitted through a shared channel. Each process has its dedicated server that processes its samples before time stamping them for transmission. Time stamps, however, are prone to errors, and hence the status updates received may not be credible. Our setting models the time stamp error rate as a function of the servers' busy times. Hence, to reduce errors and enhance credibility, servers need to process samples on a relatively prolonged schedule. This, however, deteriorates timeliness, which is captured through the age of information (AoI) metric. An optimization problem is formulated whose goal to characterize the optimal processes' schedule and sampling instances to achieve the optimal trade-off between timeliness and credibility. The problem is first solved for a single process setting, where it is shown that a threshold-based sleep-wake schedule is optimal, in which the server wakes up and is allowed to process newly incoming samples only if the AoI surpasses a certain threshold that depends on the required timeliness-credibility trade-off. Such insights are then extended to the multi-process setting, where two main scheduling and sleep-wake policies, namely round-robin scheduling with threshold-waiting and asymmetric scheduling with zero-waiting, are introduced and analyzed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05371v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Md Nurul Absar Siddiky, Ahmed Arafa</dc:creator>
    </item>
    <item>
      <title>Sherlock: A Dataset for Process-aware Intrusion Detection Research on Power Grid Networks</title>
      <link>https://arxiv.org/abs/2504.06102</link>
      <description>arXiv:2504.06102v1 Announce Type: cross 
Abstract: Physically distributed components and legacy protocols make the protection of power grids against increasing cyberattack threats challenging. Infamously, the 2015 and 2016 blackouts in Ukraine were caused by cyberattacks, and the German Federal Office for Information Security (BSI) recorded over 200 cyber incidents against the German energy sector between 2023 and 2024. Intrusion detection promises to quickly detect such attacks and mitigate the worst consequences. However, public datasets of realistic scenarios are vital to evaluate these systems. This paper introduces Sherlock, a dataset generated with the co-simulator Wattson. In total, Sherlock covers three scenarios with various attacks manipulating the process state by injecting malicious commands or manipulating measurement values. We additionally test five recently-published intrusion detection systems on Sherlock, highlighting specific challenges for intrusion detection in power grids. Dataset and documentation are available at https://sherlock.wattson.it/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06102v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3714393.3726006</arxiv:DOI>
      <dc:creator>Eric Wagner, Lennart Bader, Konrad Wolsing, Martin Serror</dc:creator>
    </item>
    <item>
      <title>A Case for Network-wide Orchestration of Host-based Intrusion Detection and Response</title>
      <link>https://arxiv.org/abs/2504.06241</link>
      <description>arXiv:2504.06241v1 Announce Type: cross 
Abstract: Recent cyber incidents and the push for zero trust security underscore the necessity of monitoring host-level events. However, current host-level intrusion detection systems (IDS) lack the ability to correlate alerts and coordinate a network-wide response in real time. Motivated by advances in system-level extensions free of rebooting and network-wide orchestration of host actions, we propose using a central IDS orchestrator to remotely program the logic of each host IDS and collect the alerts generated in real time. In this paper, we make arguments for such a system concept and provide a high level design of the main system components. Furthermore, we have developed a system prototype and evaluated it using two experimental scenarios rooted from real-world attacks. The evaluation results show that the host-based IDS orchestration system is able to defend against the attacks effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06241v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mark Timmons, Daniel Lukaszewski, Geoffrey Xie</dc:creator>
    </item>
    <item>
      <title>OffRAC: Offloading Through Remote Accelerator Calls</title>
      <link>https://arxiv.org/abs/2504.04404</link>
      <description>arXiv:2504.04404v2 Announce Type: replace 
Abstract: Modern applications increasingly demand ultra-low latency for data processing, often facilitated by host-controlled accelerators like GPUs and FPGAs. However, significant delays result from host involvement in accessing accelerators. To address this limitation, we introduce a novel paradigm we call Offloading through Remote Accelerator Calls (OffRAC), which elevates accelerators to first-class compute resources. OffRAC enables direct calls to FPGA-based accelerators without host involvement. Utilizing the stateless function abstraction of serverless computing, with applications decomposed into simpler stateless functions, offloading promotes efficient acceleration and distribution of computational loads across the network. To realize this proposal, we present a prototype design and implementation of an OffRAC platform for FPGAs that assembles diverse requests from multiple clients into complete accelerator calls with multi-tenancy performance isolation. This design minimizes the implementation complexity for accelerator users while ensuring isolation and programmability. Results show that the OffRAC approach reduces the latency of network calls to accelerators down to approximately 10.5 us, as well as sustaining high application throughput up to 85Gbps, demonstrating scalability and efficiency, making it compelling for the next generation of low-latency applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04404v2</guid>
      <category>cs.NI</category>
      <category>cs.AR</category>
      <pubDate>Wed, 09 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ziyi Yang, Krishnan B. Iyer, Yixi Chen, Ran Shu, Zsolt Istv\'an, Marco Canini, Suhaib A. Fahmy</dc:creator>
    </item>
  </channel>
</rss>
