<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Feb 2025 05:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Biased Linearity Testing in the 1% Regime</title>
      <link>https://arxiv.org/abs/2502.01900</link>
      <description>arXiv:2502.01900v1 Announce Type: new 
Abstract: We study linearity testing over the $p$-biased hypercube $(\{0,1\}^n, \mu_p^{\otimes n})$ in the 1% regime. For a distribution $\nu$ supported over $\{x\in \{0,1\}^k:\sum_{i=1}^k x_i=0 \text{ (mod 2)} \}$, with marginal distribution $\mu_p$ in each coordinate, the corresponding $k$-query linearity test $\text{Lin}(\nu)$ proceeds as follows: Given query access to a function $f:\{0,1\}^n\to \{-1,1\}$, sample $(x_1,\dots,x_k)\sim \nu^{\otimes n}$, query $f$ on $x_1,\dots,x_k$, and accept if and only if $\prod_{i\in [k]}f(x_i)=1$.
  Building on the work of Bhangale, Khot, and Minzer (STOC '23), we show, for $0 &lt; p \leq \frac{1}{2}$, that if $k \geq 1 + \frac{1}{p}$, then there exists a distribution $\nu$ such that the test $\text{Lin}(\nu)$ works in the 1% regime; that is, any function $f:\{0,1\}^n\to \{-1,1\}$ passing the test $\text{Lin}(\nu)$ with probability $\geq \frac{1}{2}+\epsilon$, for some constant $\epsilon &gt; 0$, satisfies $\Pr_{x\sim \mu_p^{\otimes n}}[f(x)=g(x)] \geq \frac{1}{2}+\delta$, for some linear function $g$, and a constant $\delta = \delta(\epsilon)&gt;0$.
  Conversely, we show that if $k &lt; 1+\frac{1}{p}$, then no such test $\text{Lin}(\nu)$ works in the 1% regime. Our key observation is that the linearity test $\text{Lin}(\nu)$ works if and only if the distribution $\nu$ satisfies a certain pairwise independence property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01900v1</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Subhash Khot, Kunal Mittal</dc:creator>
    </item>
    <item>
      <title>The $\text{FP}^\text{NP}$ versus \#P dichotomy for \#EO</title>
      <link>https://arxiv.org/abs/2502.02012</link>
      <description>arXiv:2502.02012v1 Announce Type: new 
Abstract: The complexity classification of the Holant problem has remained unresolved for the past fifteen years. Counting complex-weighted Eulerian orientation problems, denoted as \#EO, is regarded as one of the most significant challenges to the comprehensive complexity classification of the Holant problem. This article presents an $\text{FP}^\text{NP}$ vs. \#P dichotomy for \#EO, demonstrating that \#EO defined by a signature set is either \#P-hard or polynomial-time computable with a specific NP oracle. This result provides a comprehensive complexity classification for \#EO, and potentially leads to a dichotomy for the Holant problem. Furthermore, we derive three additional dichotomies related to the Holant problem from the dichotomy for \#EO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02012v1</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boning Meng, Juqiu Wang, Mingji Xia</dc:creator>
    </item>
    <item>
      <title>Upper and Lower Bounds on $T_1$ and $T_2$ Decision Tree Model</title>
      <link>https://arxiv.org/abs/2502.02022</link>
      <description>arXiv:2502.02022v1 Announce Type: new 
Abstract: We study a decision tree model in which one is allowed to query subsets of variables. This model is a generalization of the standard decision tree model. For example, the $\lor-$decision (or $T_1$-decision) model has two queries, one is a bit-query and one is the $\lor$-query with arbitrary variables. We show that a monotone property graph, i.e. nontree graph is lower bounded by $n\log n$ in $T_1$-decision tree model. Also, in a different but stronger model, $T_2$-decision tree model, we show that the majority function and symmetric function can be queried in $\frac{3n}{4}$ and $n$, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02022v1</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yousef M. Alhamdan</dc:creator>
    </item>
    <item>
      <title>New Sufficient Algebraic Conditions for Local Consistency over Homogeneous Structures of Finite Duality</title>
      <link>https://arxiv.org/abs/2502.02090</link>
      <description>arXiv:2502.02090v1 Announce Type: new 
Abstract: The path to the solution of Feder-Vardi dichotomy conjecture by Bulatov and Zhuk led through showing that more and more general algebraic conditions imply polynomial-time algorithms for the finite-domain Constraint Satisfaction Problems (CSPs) whose templates satisfy them. These investigations resulted in the discovery of the appropriate height 1 Maltsev conditions characterizing bounded strict width, bounded width, the applicability of the few-subpowers algorithm, and many others.
  For problems in the range of the similar Bodirsky-Pinsker conjecture on infinite-domain CSPs, one can only find such a characterization for the notion of bounded strict width, with a proof essentially the same as in the finite case. In this paper, we provide the first non-trivial results showing that certain height 1 Maltsev conditions imply bounded width, and in consequence tractability, for a natural subclass of templates within the Bodirsky-Pinsker conjecture which includes many templates in the literature as well as templates for which no complexity classification is known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02090v1</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom\'a\v{s} Nagy, Michael Pinsker, Micha{\l} Wrona</dc:creator>
    </item>
    <item>
      <title>The Algebraic Cost of a Boolean Sum</title>
      <link>https://arxiv.org/abs/2502.02442</link>
      <description>arXiv:2502.02442v1 Announce Type: new 
Abstract: The P versus NP problem is about the computational power of an existential $\exists_{w \in \{0,1\}^n}$ quantifier. The VP versus VNP problem is about the power of a boolean sum $\sum_{w \in \{0,1\}^n}$ operation. We study the power of a single boolean sum $\sum_{w \in \{0,1\}}$, and prove that in some cases the cost of eliminating this sum is large. This identifies a fundamental difference between the permanent and the determinant. This investigation also leads to the simplest proof we are aware of that the permanent is VNP-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02442v1</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ian Orzel, Srikanth Srinivasan, S\'ebastien Tavenas, Amir Yehudayoff</dc:creator>
    </item>
    <item>
      <title>Lower Bounds for Chain-of-Thought Reasoning in Hard-Attention Transformers</title>
      <link>https://arxiv.org/abs/2502.02393</link>
      <description>arXiv:2502.02393v1 Announce Type: cross 
Abstract: Chain-of-thought reasoning and scratchpads have emerged as critical tools for enhancing the computational capabilities of transformers. While theoretical results show that polynomial-length scratchpads can extend transformers' expressivity from $TC^0$ to $PTIME$, their required length remains poorly understood. Empirical evidence even suggests that transformers need scratchpads even for many problems in $TC^0$, such as Parity or Multiplication, challenging optimistic bounds derived from circuit complexity. In this work, we initiate the study of systematic lower bounds for the number of CoT steps across different algorithmic problems, in the hard-attention regime. We study a variety of algorithmic problems, and provide bounds that are tight up to logarithmic factors. Overall, these results contribute to emerging understanding of the power and limitations of chain-of-thought reasoning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02393v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alireza Amiri, Xinting Huang, Mark Rofin, Michael Hahn</dc:creator>
    </item>
    <item>
      <title>The Rise of Plurimorphisms: Algebraic Approach to Approximation</title>
      <link>https://arxiv.org/abs/2401.15186</link>
      <description>arXiv:2401.15186v2 Announce Type: replace 
Abstract: Following the success of the so-called algebraic approach to the study of decision constraint satisfaction problems (CSPs), exact optimization of valued CSPs, and most recently promise CSPs, we propose an algebraic framework for valued promise CSPs.
  To every valued promise CSP we associate an algebraic object, its so-called valued minion. Our main result shows that the existence of a homomorphism between the associated valued minions implies a polynomial-time reduction between the original CSPs. We also show that this general reduction theorem includes important inapproximability results, for instance, the inapproximability of almost solvable systems of linear equations beyond the random assignment threshold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15186v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Libor Barto, Silvia Butti, Alexandr Kazda, Caterina Viola, Stanislav \v{Z}ivn\'y</dc:creator>
    </item>
    <item>
      <title>Finding quantum partial assignments by search-to-decision reductions</title>
      <link>https://arxiv.org/abs/2408.03986</link>
      <description>arXiv:2408.03986v2 Announce Type: replace-cross 
Abstract: In computer science, many search problems are reducible to decision problems, which implies that finding a solution is as hard as deciding whether a solution exists. A quantum analogue of search-to-decision reductions would be to ask whether a quantum algorithm with access to a $\mathsf{QMA}$ oracle can construct $\mathsf{QMA}$ witnesses as quantum states. By a result from Irani, Natarajan, Nirkhe, Rao, and Yuen (CCC '22), it is known that this does not hold relative to a quantum oracle, unlike the cases of $\mathsf{NP}$, $\mathsf{MA}$, and $\mathsf{QCMA}$ where search-to-decision relativizes. We prove that if one is not interested in the quantum witness as a quantum state but only in terms of its partial assignments, i.e. the reduced density matrices, then there exists a classical polynomial-time algorithm with access to a $\mathsf{QMA}$ oracle that outputs approximations of the density matrices of a near-optimal quantum witness, for any desired constant locality and inverse polynomial error. Our construction is based on a circuit-to-Hamiltonian mapping that approximately preserves near-optimal $\mathsf{QMA}$ witnesses and a new $\mathsf{QMA}$-complete problem, Low-energy Density Matrix Verification, which is called by the $\mathsf{QMA}$ oracle to adaptively construct approximately consistent density matrices of a low-energy state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03986v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jordi Weggemans</dc:creator>
    </item>
    <item>
      <title>Generalization Error Bound for Quantum Machine Learning in NISQ Era -- A Survey</title>
      <link>https://arxiv.org/abs/2409.07626</link>
      <description>arXiv:2409.07626v2 Announce Type: replace-cross 
Abstract: Despite the mounting anticipation for the quantum revolution, the success of Quantum Machine Learning (QML) in the Noisy Intermediate-Scale Quantum (NISQ) era hinges on a largely unexplored factor: the generalization error bound, a cornerstone of robust and reliable machine learning models. Current QML research, while exploring novel algorithms and applications extensively, is predominantly situated in the context of noise-free, ideal quantum computers. However, Quantum Circuit (QC) operations in NISQ-era devices are susceptible to various noise sources and errors. In this article, we conduct a Systematic Mapping Study (SMS) to explore the state-of-the-art generalization bound for supervised QML in NISQ-era and analyze the latest practices in the field. Our study systematically summarizes the existing computational platforms with quantum hardware, datasets, optimization techniques, and the common properties of the bounds found in the literature. We further present the performance accuracy of various approaches in classical benchmark datasets like the MNIST and IRIS datasets. The SMS also highlights the limitations and challenges in QML in the NISQ era and discusses future research directions to advance the field. Using a detailed Boolean operators query in five reliable indexers, we collected 544 papers and filtered them to a small set of 37 relevant articles. This filtration was done following the best practice of SMS with well-defined research questions and inclusion and exclusion criteria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07626v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s42484-024-00204-w</arxiv:DOI>
      <arxiv:journal_reference>Quantum Mach. Intell. 6, 90 (2024)</arxiv:journal_reference>
      <dc:creator>Bikram Khanal, Pablo Rivas, Arun Sanjel, Korn Sooksatra, Ernesto Quevedo, Alejandro Rodriguez</dc:creator>
    </item>
    <item>
      <title>Classical Algorithms for Constant Approximation of the Ground State Energy of Local Hamiltonians</title>
      <link>https://arxiv.org/abs/2410.21833</link>
      <description>arXiv:2410.21833v2 Announce Type: replace-cross 
Abstract: We construct classical algorithms computing an approximation of the ground state energy of an arbitrary $k$-local Hamiltonian acting on $n$ qubits.
  We first consider the setting where a good ``guiding state'' is available, which is the main setting where quantum algorithms are expected to achieve an exponential speedup over classical methods. We show that a constant approximation (i.e., an approximation with constant relative accuracy) of the ground state energy can be computed classically in $\mathrm{poly}\left(1/\chi,n\right)$ time and $\mathrm{poly}(n)$ space, where $\chi$ denotes the overlap between the guiding state and the ground state (as in prior works in dequantization, we assume sample-and-query access to the guiding state). This gives a significant improvement over the recent classical algorithm by Gharibian and Le Gall (SICOMP 2023), and matches (up a to polynomial overhead) both the time and space complexities of quantum algorithms for constant approximation of the ground state energy. We also obtain classical algorithms for higher-precision approximation.
  For the setting where no guided state is given (i.e., the standard version of the local Hamiltonian problem), we obtain a classical algorithm computing a constant approximation of the ground state energy in $2^{O(n)}$ time and $\mathrm{poly}(n)$ space. To our knowledge, before this work it was unknown how to classically achieve these bounds simultaneously, even for constant approximation. We also discuss complexity-theoretic aspects of our results and their implications for the quantum PCP conjecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21833v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Le Gall</dc:creator>
    </item>
  </channel>
</rss>
