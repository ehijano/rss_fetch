<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 28 Apr 2025 04:00:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Cloud Weaving Model for AI development</title>
      <link>https://arxiv.org/abs/2504.17823</link>
      <description>arXiv:2504.17823v1 Announce Type: new 
Abstract: While analysing challenges in pilot projects developing AI with marginalized communities, we found it difficult to express them within commonly used paradigms. We therefore constructed an alternative conceptual framework to ground AI development in the social fabric -- the Cloud Weaving Model -- inspired (amongst others) by indigenous knowledge, motifs from nature, and Eastern traditions. This paper introduces and elaborates on the fundamental elements of the model (clouds, spiders, threads, spiderwebs, and weather) and their interpretation in an AI context. The framework is then applied to comprehend patterns observed in co-creation pilots approaching marginalized communities, highlighting neglected yet relevant dimensions for responsible AI development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17823v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3706599.3716235</arxiv:DOI>
      <dc:creator>Darcy Kim, Aida Kalender, Sennay Ghebreab, Giovanni Sileno</dc:creator>
    </item>
    <item>
      <title>The Role of Open-Source LLMs in Shaping the Future of GeoAI</title>
      <link>https://arxiv.org/abs/2504.17833</link>
      <description>arXiv:2504.17833v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are transforming geospatial artificial intelligence (GeoAI), offering new capabilities in data processing, spatial analysis, and decision support. This paper examines the open-source paradigm's pivotal role in this transformation. While proprietary LLMs offer accessibility, they often limit the customization, interoperability, and transparency vital for specialized geospatial tasks. Conversely, open-source alternatives significantly advance Geographic Information Science (GIScience) by fostering greater adaptability, reproducibility, and community-driven innovation. Open frameworks empower researchers to tailor solutions, integrate cutting-edge methodologies (e.g., reinforcement learning, advanced spatial indexing), and align with FAIR principles. However, the growing reliance on any LLM necessitates careful consideration of security vulnerabilities, ethical risks, and robust governance for AI-generated geospatial outputs. Ongoing debates on accessibility, regulation, and misuse underscore the critical need for responsible AI development strategies. This paper argues that GIScience advances best not through a single model type, but by cultivating a diverse, interoperable ecosystem combining open-source foundations for innovation, bespoke geospatial models, and interdisciplinary collaboration. By critically evaluating the opportunities and challenges of open-source LLMs within the broader GeoAI landscape, this work contributes to a nuanced discourse on leveraging AI to effectively advance spatial research, policy, and decision-making in an equitable, sustainable, and scientifically rigorous manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17833v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiao Huang, Zhengzhong Tu, Xinyue Ye, Michael Goodchild</dc:creator>
    </item>
    <item>
      <title>A Walk across Europe: Development of a high-resolution walkability index</title>
      <link>https://arxiv.org/abs/2504.17897</link>
      <description>arXiv:2504.17897v1 Announce Type: new 
Abstract: Physical inactivity significantly contributes to obesity and other non-communicable diseases, yet efforts to increase population-wide physical activity levels have met with limited success. The built environment plays a pivotal role in encouraging active behaviors like walking. Walkability indices, which aggregate various environmental features, provide a valuable tool for promoting healthy, walkable environments. However, a standardized, high-resolution walkability index for Europe has been lacking. This study addresses that gap by developing a standardized, high-resolution walkability index for the entire European region. Seven core components were selected to define walkability: walkable street length, intersection density, green spaces, slope, public transport access, land use mix, and 15-minute walking isochrones. These were derived from harmonized, high-resolution datasets such as Sentinel-2, NASA's elevation models, OpenStreetMap, and CORINE Land Cover. A 100 m x 100 m hierarchical grid system and advanced geospatial methods, like network buffers and distance decay, were used at scale to efficiently model real-world density and proximity effects. The resulting index was weighted by population and analyzed at different spatial levels using visual mapping, spatial clustering, and correlation analysis. Findings revealed a distinct urban-to-rural gradient, with high walkability scores concentrated in compact urban centers rich in street connectivity and land use diversity. The index highlighted cities like Barcelona, Berlin, Munich, Paris, and Warsaw as walkability leaders. This standardized, high-resolution walkability index serves as a practical tool for researchers, planners, and policymakers aiming to support active living and public health across diverse European contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17897v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nishit Patel, Hoang-Ha Nguyen, Jet van de Geest, Alfred Wagtendonk, Mohan JS Raju, Payam Dadvand, Kees de Hoogh, Marta Cirach, Mark Nieuwenhuijsen, Thao Minh Lam, Jeroen Lakerveld</dc:creator>
    </item>
    <item>
      <title>AI Ethics and Social Norms: Exploring ChatGPT's Capabilities From What to How</title>
      <link>https://arxiv.org/abs/2504.18044</link>
      <description>arXiv:2504.18044v1 Announce Type: new 
Abstract: Using LLMs in healthcare, Computer-Supported Cooperative Work, and Social Computing requires the examination of ethical and social norms to ensure safe incorporation into human life. We conducted a mixed-method study, including an online survey with 111 participants and an interview study with 38 experts, to investigate the AI ethics and social norms in ChatGPT as everyday life tools. This study aims to evaluate whether ChatGPT in an empirical context operates following ethics and social norms, which is critical for understanding actions in industrial and academic research and achieving machine ethics. The findings of this study provide initial insights into six important aspects of AI ethics, including bias, trustworthiness, security, toxicology, social norms, and ethical data. Significant obstacles related to transparency and bias in unsupervised data collection methods are identified as ChatGPT's ethical concerns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18044v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omid Veisi, Sasan Bahrami, Roman Englert, Claudia M\"uller</dc:creator>
    </item>
    <item>
      <title>Hype and Adoption of Generative Artificial Intelligence Applications</title>
      <link>https://arxiv.org/abs/2504.18081</link>
      <description>arXiv:2504.18081v1 Announce Type: new 
Abstract: New technologies create opportunities while displacing others. They enhance life by supporting entertainment, education, and social connectivity but also replace humans in productivity and analytical tasks. Adapting to these shifts requires technical adjustments and social readiness. For digital transformation to succeed, organizations and their workforce must be psychologically prepared. We are entering the era of Generative AI with tools like ChatGPT, Bing AI, and Microsoft Office Copilot. Understanding public sentiment toward these innovations is crucial for refining technology acceptance models and informing market strategies. Using the Gartner Hype Cycle and Kubler-Ross Change Curve, this study suggests that generative AI adoption is a dual-stage process. It follows the phases of technology trigger, peak of expectations, trough of disillusionment, slope of enlightenment, and plateau of productivity, while also reflecting emotional stages like shock, denial, and integration. The study used sentiment and emotion analysis on a large dataset of tweets about generative AI, translating them into scores to track user responses over time. Unlike prior research, which offered a snapshot of sentiment, this study captures the dynamic evolution of attitudes, linking empirical evidence with theoretical frameworks. It shifts the focus from information seekers to content creators. With the release of generative AI tools, there is a significant gap in understanding societal reception and adaptation. Policymakers face uncertainty about guiding markets for these changes. This research validates the applicability of the Gartner Hype Cycle and Kubler-Ross Change Curve to generative AI. It provides insights for businesses in integrating these tools and crafting policies to enhance readiness and resilience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18081v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vinh Truong (RMIT University)</dc:creator>
    </item>
    <item>
      <title>Reimagining Assistive Walkers: An Exploration of Challenges and Preferences in Older Adults</title>
      <link>https://arxiv.org/abs/2504.18169</link>
      <description>arXiv:2504.18169v1 Announce Type: new 
Abstract: The well-being of older adults relies significantly on maintaining balance and mobility. As physical ability declines, older adults often accept the need for assistive devices. However, existing walkers frequently fail to consider user preferences, leading to perceptions of imposition and reduced acceptance. This research explores the challenges faced by older adults, caregivers, and healthcare professionals when using walkers, assesses their perceptions, and identifies their needs and preferences. A holistic approach was employed, using tailored perception questionnaires for older adults (24 participants), caregivers (30 participants), and healthcare professionals (27 participants), all of whom completed the survey. Over 50% of caregivers and healthcare professionals displayed good knowledge, positive attitudes, and effective practices regarding walkers. However, over 30% of participants perceived current designs as fall risks, citing the need for significant upper body strength, potentially affecting safety and movement. More than 50% highlighted the importance of incorporating fall detection, ergonomic designs, noise reduction, and walker ramps to better meet user needs and preferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18169v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>19th International Conference on Rehabilitation Robotics (ICORR), 2025</arxiv:journal_reference>
      <dc:creator>Victory A. Aruona, Sergio D. Sierra M., Nigel Harris, Marcela Munera, Carlos A. Cifuentes</dc:creator>
    </item>
    <item>
      <title>Automated Work Records for Precision Agriculture Management: A Low-Cost GNSS IoT Solution for Paddy Fields in Central Japan</title>
      <link>https://arxiv.org/abs/2504.18222</link>
      <description>arXiv:2504.18222v1 Announce Type: new 
Abstract: Agricultural field operations are generally tracked as work records (WR), incorporating data points such as; work type, machine type, timestamped trajectories and field information. WR data which is automatically recorded by modern machinery equipped with Information and Communication Technologies (ICT) can enable efficient farm management decision making. Globally, farmers often rely on aged or legacy farming machinery and manual data recording, which introduces significant labor costs and increases the risk of inaccurate data input. To address this challenge, a field study in Central Japan was conducted to showcase automated data collection by retrofitting legacy farming machinery with low-cost Internet of Things (IoT) devices. For single-purpose vehicles (SPV), which only carry out single work types such as planting, LTE (Long Term Evolution) and Global Navigation Satellite System (GNSS) units were installed to record trajectory data. For multi-purpose vehicles (MPV), such as tractors which perform multiple work types, the configuration settings of these vehicles had to include implements and attachments data. To obtain this data, industry standard LTE-GNSS Bluetooth gateways were fitted onto MPV and low-cost BLE (Bluetooth Low Energy) beacons were attached to implements. After installation, over a seven-month field preparation and planting period 1,623 WR, including 421 WR for SPV and 1,120 WR for MVP, were automatically obtained. For MPV, the WR included detailed configuration settings enabling detection of the specific work types. These findings demonstrate the potential of low cost IoT GNSS devices for precision agriculture strategies to support management decisions in farming operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18222v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Grosse, K. Honda, C. Spech, J. C. Pineda</dc:creator>
    </item>
    <item>
      <title>"Two Means to an End Goal": Connecting Explainability and Contestability in the Regulation of Public Sector AI</title>
      <link>https://arxiv.org/abs/2504.18236</link>
      <description>arXiv:2504.18236v1 Announce Type: new 
Abstract: Explainability and its emerging counterpart contestability have become important normative and design principles for the trustworthy use of AI as they enable users and subjects to understand and challenge AI decisions. However, the regulation of AI systems spans technical, legal, and organizational dimensions, producing a multiplicity in meaning that complicates the implementation of explainability and contestability. Resolving this conceptual ambiguity requires specifying and comparing the meaning of both principles across regulation dimensions, disciplines, and actors. This process, here defined as translation, is essential to provide guidance on the principles' realization. We present the findings of a semi-structured interview study with 14 interdisciplinary AI regulation experts. We report on the experts' understanding of the intersection between explainability and contestability in public AI regulation, their advice for a decision subject and a public agency in a welfare allocation AI use case, and their perspectives on the connections and gaps within the research landscape. We provide differentiations between descriptive and normative explainability, judicial and non-judicial channels of contestation, and individual and collective contestation action. We further outline three translation processes in the alignment of top-down and bottom-up regulation, the assignment of responsibility for interpreting regulations, and the establishment of interdisciplinary collaboration. Our contributions include an empirically grounded conceptualization of the intersection between explainability and contestability and recommendations on implementing these principles in public institutions. We believe our contributions can inform policy-making and regulation of these core principles and enable more effective and equitable design, development, and deployment of trustworthy public AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18236v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timoth\'ee Schmude, Mireia Yurrita, Kars Alfrink, Thomas Le Goff, Tiphaine Viard</dc:creator>
    </item>
    <item>
      <title>AI Safety Assurance for Automated Vehicles: A Survey on Research, Standardization, Regulation</title>
      <link>https://arxiv.org/abs/2504.18328</link>
      <description>arXiv:2504.18328v1 Announce Type: new 
Abstract: Assuring safety of artificial intelligence (AI) applied to safety-critical systems is of paramount importance. Especially since research in the field of automated driving shows that AI is able to outperform classical approaches, to handle higher complexities, and to reach new levels of autonomy. At the same time, the safety assurance required for the use of AI in such safety-critical systems is still not in place. Due to the dynamic and far-reaching nature of the technology, research on safeguarding AI is being conducted in parallel to AI standardization and regulation. The parallel progress necessitates simultaneous consideration in order to carry out targeted research and development of AI systems in the context of automated driving. Therefore, in contrast to existing surveys that focus primarily on research aspects, this paper considers research, standardization and regulation in a concise way. Accordingly, the survey takes into account the interdependencies arising from the triplet of research, standardization and regulation in a forward-looking perspective and anticipates and discusses open questions and possible future directions. In this way, the survey ultimately serves to provide researchers and safety experts with a compact, holistic perspective that discusses the current status, emerging trends, and possible future developments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18328v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TIV.2024.3496797</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Intelligent Vehicles 2024</arxiv:journal_reference>
      <dc:creator>Lars Ullrich, Michael Buchholz, Klaus Dietmayer, Knut Graichen</dc:creator>
    </item>
    <item>
      <title>VIGMA: An Open-Access Framework for Visual Gait and Motion Analytics</title>
      <link>https://arxiv.org/abs/2504.17960</link>
      <description>arXiv:2504.17960v1 Announce Type: cross 
Abstract: Gait disorders are commonly observed in older adults, who frequently experience various issues related to walking. Additionally, researchers and clinicians extensively investigate mobility related to gait in typically and atypically developing children, athletes, and individuals with orthopedic and neurological disorders. Effective gait analysis enables the understanding of the causal mechanisms of mobility and balance control of patients, the development of tailored treatment plans to improve mobility, the reduction of fall risk, and the tracking of rehabilitation progress. However, analyzing gait data is a complex task due to the multivariate nature of the data, the large volume of information to be interpreted, and the technical skills required. Existing tools for gait analysis are often limited to specific patient groups (e.g., cerebral palsy), only handle a specific subset of tasks in the entire workflow, and are not openly accessible. To address these shortcomings, we conducted a requirements assessment with gait practitioners (e.g., researchers, clinicians) via surveys and identified key components of the workflow, including (1) data processing and (2) data analysis and visualization. Based on the findings, we designed VIGMA, an open-access visual analytics framework integrated with computational notebooks and a Python library, to meet the identified requirements. Notably, the framework supports analytical capabilities for assessing disease progression and for comparing multiple patient groups. We validated the framework through usage scenarios with experts specializing in gait and mobility rehabilitation. VIGMA is available at https://github.com/komar41/VIGMA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17960v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TVCG.2025.3564866</arxiv:DOI>
      <dc:creator>Kazi Shahrukh Omar, Shuaijie Wang, Ridhuparan Kungumaraju, Tanvi Bhatt, Fabio Miranda</dc:creator>
    </item>
    <item>
      <title>Artificial Intelligence health advice accuracy varies across languages and contexts</title>
      <link>https://arxiv.org/abs/2504.18310</link>
      <description>arXiv:2504.18310v1 Announce Type: cross 
Abstract: Using basic health statements authorized by UK and EU registers and 9,100 journalist-vetted public-health assertions on topics such as abortion, COVID-19 and politics from sources ranging from peer-reviewed journals and government advisories to social media and news across the political spectrum, we benchmark six leading large language models from in 21 languages, finding that, despite high accuracy on English-centric textbook claims, performance falls in multiple non-European languages and fluctuates by topic and source, highlighting the urgency of comprehensive multilingual, domain-aware validation before deploying AI in global health communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18310v1</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prashant Garg, Thiemo Fetzer</dc:creator>
    </item>
    <item>
      <title>Automated Consistency Analysis for Legal Contracts</title>
      <link>https://arxiv.org/abs/2504.18422</link>
      <description>arXiv:2504.18422v1 Announce Type: cross 
Abstract: Business contracts, particularly sale and purchase agreements, often contain a large number of clauses and are correspondingly long and complex. In practice, it is therefore a great challenge to keep track of their legal context and to identify and avoid inconsistencies in such contracts. Against this background, we describe a method and tool called ContractCheck which allows for the consistency analysis of legal contracts, in particular Share Purchase Agreements (SPAs). In order to identify the concepts that are relevant for an analysis we define an ontology for SPAs. The analysis is, then, based on an encoding of the preconditions for the execution of the clauses of an SPA, as well as on a set of proposed consistency constraints formalized using decidable fragments of First-Order Logic (FOL). Based on the ontology for SPAs, textual SPAs are first encoded in a structured natural language format that we refer to as ``blocks''. ContractCheck interprets these blocks and constraints and translates them into assertions formulated in FOL. It then invokes a Satisfiability Modulo Theory (SMT) solver in order to check the executability of a considered contract, either by providing a satisfying model, or by proving the existence of conflicting clauses that prevent the contract from being executed. We illustrate the application of ContractCheck to concrete SPAs, including one example of an SPA of realistic size and complexity, and conclude by suggesting directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18422v1</guid>
      <category>cs.LO</category>
      <category>cs.CY</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alan Khoja, Martin K\"olbl, Stefan Leue, R\"udiger Wilhelmi</dc:creator>
    </item>
    <item>
      <title>Scaling Laws For Scalable Oversight</title>
      <link>https://arxiv.org/abs/2504.18530</link>
      <description>arXiv:2504.18530v1 Announce Type: cross 
Abstract: Scalable oversight, the process by which weaker AI systems supervise stronger ones, has been proposed as a key strategy to control future superintelligent systems. However, it is still unclear how scalable oversight itself scales. To address this gap, we propose a framework that quantifies the probability of successful oversight as a function of the capabilities of the overseer and the system being overseen. Specifically, our framework models oversight as a game between capability-mismatched players; the players have oversight-specific and deception-specific Elo scores that are a piecewise-linear function of their general intelligence, with two plateaus corresponding to task incompetence and task saturation. We validate our framework with a modified version of the game Nim and then apply it to four oversight games: "Mafia", "Debate", "Backdoor Code" and "Wargames". For each game, we find scaling laws that approximate how domain performance depends on general AI system capability (using Chatbot Arena Elo as a proxy for general capability). We then build on our findings in a theoretical study of Nested Scalable Oversight (NSO), a process in which trusted models oversee untrusted stronger models, which then become the trusted models in the next step. We identify conditions under which NSO succeeds and derive numerically (and in some cases analytically) the optimal number of oversight levels to maximize the probability of oversight success. In our numerical examples, the NSO success rate is below 52% when overseeing systems that are 400 Elo points stronger than the baseline overseer, and it declines further for overseeing even stronger systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18530v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua Engels, David D. Baek, Subhash Kantamneni, Max Tegmark</dc:creator>
    </item>
    <item>
      <title>Adapting Probabilistic Risk Assessment for AI</title>
      <link>https://arxiv.org/abs/2504.18536</link>
      <description>arXiv:2504.18536v1 Announce Type: cross 
Abstract: Modern general-purpose artificial intelligence (AI) systems present an urgent risk management challenge, as their rapidly evolving capabilities and potential for catastrophic harm outpace our ability to reliably assess their risks. Current methods often rely on selective testing and undocumented assumptions about risk priorities, frequently failing to make a serious attempt at assessing the set of pathways through which Al systems pose direct or indirect risks to society and the biosphere. This paper introduces the probabilistic risk assessment (PRA) for AI framework, adapting established PRA techniques from high-reliability industries (e.g., nuclear power, aerospace) for the new challenges of advanced AI. The framework guides assessors in identifying potential risks, estimating likelihood and severity, and explicitly documenting evidence, underlying assumptions, and analyses at appropriate granularities. The framework's implementation tool synthesizes the results into a risk report card with aggregated risk estimates from all assessed risks. This systematic approach integrates three advances: (1) Aspect-oriented hazard analysis provides systematic hazard coverage guided by a first-principles taxonomy of AI system aspects (e.g. capabilities, domain knowledge, affordances); (2) Risk pathway modeling analyzes causal chains from system aspects to societal impacts using bidirectional analysis and incorporating prospective techniques; and (3) Uncertainty management employs scenario decomposition, reference scales, and explicit tracing protocols to structure credible projections with novelty or limited data. Additionally, the framework harmonizes diverse assessment methods by integrating evidence into comparable, quantified absolute risk estimates for critical decisions. We have implemented this as a workbook tool for AI developers, evaluators, and regulators, available on the project website.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18536v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.AP</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Katariina Wisakanto, Joe Rogero, Avyay M. Casheekar, Richard Mallah</dc:creator>
    </item>
    <item>
      <title>The Moral Mind(s) of Large Language Models</title>
      <link>https://arxiv.org/abs/2412.04476</link>
      <description>arXiv:2412.04476v3 Announce Type: replace 
Abstract: As large language models (LLMs) increasingly participate in tasks with ethical and societal stakes, a critical question arises: do they exhibit an emergent "moral mind" - a consistent structure of moral preferences guiding their decisions - and to what extent is this structure shared across models? To investigate this, we applied tools from revealed preference theory to nearly 40 leading LLMs, presenting each with many structured moral dilemmas spanning five foundational dimensions of ethical reasoning. Using a probabilistic rationality test, we found that at least one model from each major provider exhibited behavior consistent with approximately stable moral preferences, acting as if guided by an underlying utility function. We then estimated these utility functions and found that most models cluster around neutral moral stances. To further characterize heterogeneity, we employed a non-parametric permutation approach, constructing a probabilistic similarity network based on revealed preference patterns. The results reveal a shared core in LLMs' moral reasoning, but also meaningful variation: some models show flexible reasoning across perspectives, while others adhere to more rigid ethical profiles. These findings provide a new empirical lens for evaluating moral consistency in LLMs and offer a framework for benchmarking ethical alignment across AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04476v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Avner Seror</dc:creator>
    </item>
    <item>
      <title>Multilingual Large Language Models and Curse of Multilinguality</title>
      <link>https://arxiv.org/abs/2406.10602</link>
      <description>arXiv:2406.10602v2 Announce Type: replace-cross 
Abstract: Multilingual Large Language Models (LLMs) have gained large popularity among Natural Language Processing (NLP) researchers and practitioners. These models, trained on huge datasets, show proficiency across various languages and demonstrate effectiveness in numerous downstream tasks. This paper navigates the landscape of multilingual LLMs, providing an introductory overview of their technical aspects. It explains underlying architectures, objective functions, pre-training data sources, and tokenization methods. This work explores the unique features of different model types: encoder-only (mBERT, XLM-R), decoder-only (XGLM, PALM, BLOOM, GPT-3), and encoder-decoder models (mT5, mBART). Additionally, it addresses one of the significant limitations of multilingual LLMs - the curse of multilinguality - and discusses current attempts to overcome it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10602v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.48550/arXiv.2406.10602</arxiv:DOI>
      <dc:creator>Daniil Gurgurov, Tanja B\"aumel, Tatiana Anikina</dc:creator>
    </item>
    <item>
      <title>Learning by gaming, coding and making with EDUMING: A new approach to utilising atypical digital games for learning</title>
      <link>https://arxiv.org/abs/2504.13878</link>
      <description>arXiv:2504.13878v2 Announce Type: replace-cross 
Abstract: Papert's constructionism makes it clear that learning is particularly effective when learners create tangible artifacts and share and discuss them in social contexts. Technological progress in recent decades has created numerous opportunities for learners to not only passively consume media, but to actively shape it through construction. This article uses the EDUMING concept to present a new method to simplify the development of digital learning games and thus support their integration into learning situations. A key difference between the concept and established ideas such as game-based learning, gamification, serious games, etc. is that games are not closed and are consumed passively, but can also be actively developed by users individually by modifying the source code with the help of an IDE. As part of an empirical study, the usability of the game "Professor Chip's Learning Quest" (PCLQ) is recorded, as well as previous experience with digital learning games and the acceptance and motivation to use new technologies. The purpose of this article is to test the PCLQ digital learning game, developed according to the EDUMING concept, as part of an exploratory study regarding its usability, acceptance and suitability for use in schools. The study is intended as a first empirical approach to practical testing of the concept.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13878v2</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefan Pietrusky</dc:creator>
    </item>
  </channel>
</rss>
