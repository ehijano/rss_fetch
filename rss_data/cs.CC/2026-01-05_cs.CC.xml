<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 05 Jan 2026 05:00:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Exponential lower bound via exponential sums</title>
      <link>https://arxiv.org/abs/2601.00387</link>
      <description>arXiv:2601.00387v1 Announce Type: new 
Abstract: Valiant's famous VP vs. VNP conjecture states that the symbolic permanent polynomial does not have polynomial-size algebraic circuits. However, the best upper bound on the size of the circuits computing the permanent is exponential. Informally, VNP is an exponential sum of VP-circuits. In this paper we study whether, in general, exponential sums (of algebraic circuits) require exponential-size algebraic circuits. We show that the famous Shub-Smale $\tau$-conjecture indeed implies such an exponential lower bound for an exponential sum. Our main tools come from parameterized complexity. Along the way, we also prove an exponential fpt (fixed-parameter tractable) lower bound for the parameterized algebraic complexity class VW$_{nb}^0$[P], assuming the same conjecture. VW$_{nb}^0$[P] can be thought of as the weighted sums of (unbounded-degree) circuits, where only $\pm 1$ constants are cost-free. To the best of our knowledge, this is the first time the Shub-Smale $\tau$-conjecture has been applied to prove explicit exponential lower bounds.
  Furthermore, we prove that when this class is fpt, then a variant of the counting hierarchy, namely the linear counting hierarchy collapses. Moreover, if a certain type of parameterized exponential sums is fpt, then integers, as well as polynomials with coefficients being definable in the linear counting hierarchy have subpolynomial $\tau$-complexity.
  Finally, we characterize a related class VW[F], in terms of permanents, where we consider an exponential sum of algebraic formulas instead of circuits. We show that when we sum over cycle covers that have one long cycle and all other cycles have constant length, then the resulting family of polynomials is complete for VW[F] on certain types of graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00387v1</guid>
      <category>cs.CC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Somnath Bhattacharjee, Markus Bl\"aser, Pranjal Dutta, Saswata Mukherjee</dc:creator>
    </item>
    <item>
      <title>A Parameterized-Complexity Framework for Finding Local Optima</title>
      <link>https://arxiv.org/abs/2601.00560</link>
      <description>arXiv:2601.00560v1 Announce Type: new 
Abstract: Local search is a fundamental optimization technique that is both widely used in practice and deeply studied in theory, yet its computational complexity remains poorly understood. The traditional frameworks, PLS and the standard algorithm problem, introduced by Johnson, Papadimitriou, and Yannakakis (1988) fail to capture the methodology of local search algorithms: PLS is concerned with finding a local optimum and not with using local search, while the standard algorithm problem restricts each improvement step to follow a fixed pivoting rule. In this work, we introduce a novel formulation of local search which provides a middle ground between these models. In particular, the task is to output not only a local optimum but also a chain of local improvements leading to it. With this framework, we aim to capture the challenge in designing a good pivoting rule. Especially, when combined with the parameterized complexity paradigm, it enables both strong lower bounds and meaningful tractability results. Unlike previous works that combined parameterized complexity with local search, our framework targets the whole task of finding a local optimum and not only a single improvement step. Focusing on two representative meta-problems -- Subset Weight Optimization Problem with the $c$-swap neighborhood and Weighted Circuit with the flip neighborhood -- we establish fixed-parameter tractability results related to the number of distinct weights, while ruling out an analogous result when parameterized by the distance to the nearest optimum via a new type of reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00560v1</guid>
      <category>cs.CC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Ganian, Hung P. Hoang, Christian Komusiewicz, Nils Morawietz</dc:creator>
    </item>
    <item>
      <title>Quantifier Elimination Meets Treewidth</title>
      <link>https://arxiv.org/abs/2601.00312</link>
      <description>arXiv:2601.00312v1 Announce Type: cross 
Abstract: In this paper, we address the complexity barrier inherent in Fourier-Motzkin elimination (FME) and cylindrical algebraic decomposition (CAD) when eliminating a block of (existential) quantifiers. To mitigate this, we propose exploiting structural sparsity in the variable dependency graph of quantified formulas. Utilizing tools from parameterized algorithms, we investigate the role of treewidth, a parameter that measures the graph's tree-likeness, in the process of quantifier elimination. A novel dynamic programming framework, structured over a tree decomposition of the dependency graph, is developed for applying FME and CAD, and is also extensible to general quantifier elimination procedures. Crucially, we prove that when the treewidth is a constant, the framework achieves a significant exponential complexity improvement for both FME and CAD, reducing the worst-case complexity bound from doubly exponential to single exponential. Preliminary experiments on sparse linear real arithmetic (LRA) and nonlinear real arithmetic (NRA) benchmarks confirm that our algorithm outperforms the existing popular heuristic-based approaches on instances exhibiting low treewidth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00312v1</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <category>cs.SC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wu, Jiyu Zhu, Amir Kafshdar Goharshady, Jie An, Bican Xia, Naijun Zhan</dc:creator>
    </item>
    <item>
      <title>Stronger Approximation Guarantees for Non-Monotone {\gamma}-Weakly DR-Submodular Maximization</title>
      <link>https://arxiv.org/abs/2601.00611</link>
      <description>arXiv:2601.00611v1 Announce Type: cross 
Abstract: Maximizing submodular objectives under constraints is a fundamental problem in machine learning and optimization. We study the maximization of a nonnegative, non-monotone $\gamma$-weakly DR-submodular function over a down-closed convex body. Our main result is an approximation algorithm whose guarantee depends smoothly on $\gamma$; in particular, when $\gamma=1$ (the DR-submodular case) our bound recovers the $0.401$ approximation factor, while for $\gamma&lt;1$ the guarantee degrades gracefully and, it improves upon previously reported bounds for $\gamma$-weakly DR-submodular maximization under the same constraints. Our approach combines a Frank-Wolfe-guided continuous-greedy framework with a $\gamma$-aware double-greedy step, yielding a simple yet effective procedure for handling non-monotonicity. This results in state-of-the-art guarantees for non-monotone $\gamma$-weakly DR-submodular maximization over down-closed convex bodies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00611v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hareshkumar Jadav, Ranveer Singh, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>$\mathrm{TIME}[t]\subseteq \mathrm{SPACE}[O(\sqrt{t})]$ via Tree Height Compression</title>
      <link>https://arxiv.org/abs/2508.14831</link>
      <description>arXiv:2508.14831v4 Announce Type: replace 
Abstract: We prove a square-root space simulation for deterministic multitape Turing machines, showing $\mathrm{TIME}[t]\subseteq \mathrm{SPACE}[O(\sqrt{t})]$ \emph{measured in tape cells over a fixed finite alphabet}. The key step is a Height Compression Theorem that uniformly (and in logspace) reshapes the canonical left-deep succinct computation tree for a block-respecting run into a binary tree whose evaluation-stack depth along any DFS path is $O(\log T)$ for $T=\lceil t/b\rceil$, while preserving $O(b)$ workspace at leaves and $O(1)$ at internal nodes. Edges have \emph{addressing/topology} checkable in $O(\log t)$ space, and \emph{semantic} correctness across merges is witnessed by an exact $O(b)$ bounded-window replay at the unique interface. Algorithmically, an Algebraic Replay Engine with constant-degree maps over a constant-size field, together with pointerless DFS, index-free streaming, and a \emph{rolling boundary buffer that prevents accumulation of leaf summaries}, ensures constant-size per-level tokens and eliminates wide counters, yielding the additive tradeoff $S(b)=O(b+t/b)$. Choosing $b=\Theta(\sqrt{t})$ gives $O(\sqrt{t})$ space with no residual multiplicative polylog factors. The construction is uniform, relativizes, and is robust to standard model choices. Consequences include branching-program upper bounds $2^{O(\sqrt{s})}$ for size-$s$ bounded-fan-in circuits, tightened quadratic-time lower bounds for $\mathrm{SPACE}[n]$-complete problems via the standard hierarchy argument, and $O(\sqrt{t})$-space certifying interpreters; under explicit locality assumptions, the framework extends to geometric $d$-dimensional models. Conceptually, the work isolates path bookkeeping as the chief obstruction to $O(\sqrt{t})$ and removes it via structural height compression with per-path analysis rather than barrier-prone techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14831v4</guid>
      <category>cs.CC</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Logan Nye</dc:creator>
    </item>
    <item>
      <title>Constant Inapproximability of Pacing Equilibria in Second-Price Auctions</title>
      <link>https://arxiv.org/abs/2501.15295</link>
      <description>arXiv:2501.15295v2 Announce Type: replace-cross 
Abstract: In this paper, we revisit the problem of approximating a pacing equilibrium in second-price auctions, introduced by Conitzer, Kroer, Sodomka, and Moses [Oper. Res. 2022]. We show that finding a constant-factor approximation of a pacing equilibrium is PPAD-hard, thereby strengthening previous results of Chen, Kroer, and Kumar [Math. Oper. Res. 2024], which established PPAD-hardness only for inverse-polynomial approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15295v2</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Chen, Yuhao Li</dc:creator>
    </item>
    <item>
      <title>Strassen $2\times2$ Matrix Multiplication from a 3-dimensional Volume Form</title>
      <link>https://arxiv.org/abs/2507.13510</link>
      <description>arXiv:2507.13510v2 Announce Type: replace-cross 
Abstract: The Strassen $2\times2$ matrix multiplication algorithm arises from the volume form on the 3-dimensional quotient space of the $2\times 2$ matrices by the multiples of identity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13510v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benoit Jacob (AMD)</dc:creator>
    </item>
  </channel>
</rss>
