<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Nov 2025 02:41:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Predicting the spatial distribution and demographics of commercial swine farms in the United States</title>
      <link>https://arxiv.org/abs/2511.00132</link>
      <description>arXiv:2511.00132v1 Announce Type: new 
Abstract: Data on livestock farm locations and demographics are essential for disease monitoring, risk assessment, and developing spatially explicit epidemiological models. Our semantic segmentation model achieved an F2 score of 92 % and a mean Intersection over Union of 76 %. An initial total of 194,474 swine barn candidates were identified in the Southeast (North Carolina = 111,135, South Carolina = 37,264 Virginia = 46,075) and 524,962 in the Midwest (Iowa = 168,866 Minnesota = 165,714 Ohio = 190,382). The post processing Random Forest classifier reduced false positives by 82 % in the Southeast and 88 % in the Midwest, resulting in 45,580 confirmed barn polygons. These were grouped into 16,976 predicted farms and classified into one of the four production types. Population sizes were then estimated using the Random Forest regression model, with prediction accuracy varying by production type. Across all farms, 87 % of predictions for operations with 1,000 2,000 pigs were within 500 pigs of the reference value, with nursery farms showing the highest agreement (R2= 0.82), followed by finisher farms (R2 = 0.77) and sow farms (R2 = 0.56). Our results revealed substantial gaps in the existing spatial and demographic data on U.S. swine production.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00132v1</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Felipe E. Sanchez, Thomas A. Lake, Jason A. Galvis, Chris Jones, Gustavo Machado</dc:creator>
    </item>
    <item>
      <title>A Systematic Review of Spatio-Temporal Statistical Models: Theory, Structure, and Applications</title>
      <link>https://arxiv.org/abs/2511.00422</link>
      <description>arXiv:2511.00422v1 Announce Type: new 
Abstract: Data with spatial-temporal attributes are prevalent across many research fields, and statistical models for analyzing spatio-temporal relationships are widely used. Existing reviews focus either on specific domains or model types, creating a gap in comprehensive, cross-disciplinary overviews. To address this, we conducted a systematic literature review following the PRISMA guidelines, searched two databases for the years 2021-2025, and identified 83 publications that met our criteria. We propose a classification scheme for spatio-temporal model structures and highlight their application in the most common fields: epidemiology, ecology, public health, economics, and criminology. Although tasks vary by domain, many models share similarities. We found that hierarchical models are the most frequently used, and most models incorporate additive components to account for spatial-temporal dependencies. The preferred model structures differ among fields of application. We also observe that research efforts are concentrated in only a few specific disciplines, despite the broader relevance of spatio-temporal data. Furthermore, we notice that reproducibility remains limited. Our review, therefore, not only offers inspiration for comparing model structures in an interdisciplinary manner but also highlights opportunities for greater transparency, accessibility, and cross-domain knowledge transfer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00422v1</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isabella Habereder, Thomas Kneib, Isao Echizen, Timo Spinde</dc:creator>
    </item>
    <item>
      <title>Spatiotemporal Dynamics of Conflict Occurrence and Fatalities in Ethiopia: A Bayesian Model and Predictive Insights Using Event-level Data (1997--2024)</title>
      <link>https://arxiv.org/abs/2511.00867</link>
      <description>arXiv:2511.00867v1 Announce Type: new 
Abstract: This study presents a spatiotemporal dual Bayesian model that examines both the occurrence and number of conflict fatalities using event-level data from Ethiopia (1997-2024), sourced from the Armed Conflict Location and Event Data (ACLED) project. Fatalities are treated as two linked outcomes: the binary occurrence of deaths and the count of deaths when they occur. The model combines additive fixed effects for covariates with random effects capturing spatiotemporal influences, allowing for outcome-specific effects. Covariates include event type and season as categorical variables, proximity to cities and borders as nonlinear effects, and population as an offset term in the count model. A latent spatiotemporal process accounts for shared spatial and temporal dependence, with the spatial structure modeled using a Mat\'ern field prior and inference via Integrated Nested Laplace Approximation (INLA). Results show strong spatial clustering and temporal variation in fatality risk, emphasizing the importance of modeling both dimensions for better understanding and prediction. Airstrikes, shelling, and attacks show the highest fatality likelihood and counts, while communal and rebel actors cause the most deaths. Multiple fatalities are more likely in summer, and proximity to borders drives intense violence, whereas remoteness from urban centers is linked to lower-intensity events. These results provide insight for planning, policy, and resource allocation to protect vulnerable communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00867v1</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yassin Tesfaw Abebe, Abdu Mohammed Seid, Lassi Roininen, Mohammed Seid Ali</dc:creator>
    </item>
    <item>
      <title>The Multidimensional Index of Child Growth (MICG) of the Task Force "Towards a Multidimensional Approach for Child Growth" of the International Union for Nutrition Sciences</title>
      <link>https://arxiv.org/abs/2511.01607</link>
      <description>arXiv:2511.01607v1 Announce Type: new 
Abstract: Children's growth extends beyond height and weight. This paper introduces the Multidimensional Index of Child Growth (MICG), developed by the IUNS Task Force "Towards a Multidimensional Approach for Child Growth." The IUNS-MICG applies a capability- and rights-based framework covering 14 dimensions of child wellbeing, including health, care, mental wellbeing, participation, autonomy, mobility, and safety. Using data from the Young Lives Study in Ethiopia, India, Peru, and Vietnam, we tested the framework with 29 indicators. Comparisons of different weighting methods show that equal weights provide robust and policy-relevant results. MICG uncovers deprivations hidden by physical measures alone; for instance, rural girls in Peru face educational and mental wellbeing disadvantages despite similar physical growth. Further analyses show that community participation in WASH programs is linked to higher multidimensional outcomes, especially for the most deprived. We also extend MICG with a Bayesian approach to estimate children's unrealized opportunities and propose a spiderweb growth chart for visualizing multidimensional progress. MICG offers a practical, equity-focused tool to monitor, evaluate, and strengthen interventions that support the Sustainable Development Goals and ensure no child is left behind.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01607v1</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rolando Gonzales Martinez, Hinke Haisma</dc:creator>
    </item>
    <item>
      <title>Geometric Modeling of Hippocampal Tau Deposition: A Surface-Based Framework for Covariate Analysis and Off-Target Contamination Detection</title>
      <link>https://arxiv.org/abs/2511.01732</link>
      <description>arXiv:2511.01732v1 Announce Type: new 
Abstract: We introduce a framework combining geometric modeling with disease progression analysis to investigate tau deposition in Alzheimer's disease (AD) using positron emission tomography (PET) data. Focusing on the hippocampus, we construct a principal surface that captures the spatial distribution and morphological changes of tau pathology. By projecting voxels onto this surface, we quantify tau coverage, intensity, and thickness through bidirectional projection distances and interpolated standardized uptake value ratios (SUVR). This low-dimensional embedding preserves spatial specificity while mitigating multiple comparison issues. Covariate effects are analyzed using a two-stage regression model with inverse probability weighting to adjust for signal sparsity and selection bias. Using the SuStaIn model, we identify subtypes and stages of AD, revealing distinct tau dynamics: the limbic-predominant subtype shows age-related nonlinear accumulation in coverage and thickness, whereas the posterior subtype exhibits uniform SUVR increases across disease progression. Model-based predictions show that hippocampal tau deposition follows a structured spatial trajectory expanding bidirectionally with increasing thickness, while subtype differences highlight posterior hippocampal involvement consistent with whole-brain patterns. Finally, directional signal patterns on the principal surface reveal contamination from the choroid plexus, demonstrating the broader applicability of the proposed framework across modalities including amyloid PET.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01732v1</guid>
      <category>stat.AP</category>
      <category>q-bio.QM</category>
      <category>stat.OT</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liangkang Wang, Akhil Ambekar, Ani Eloyan</dc:creator>
    </item>
    <item>
      <title>Large Language Model-Derived Priors Can Improve Bayesian Survival Analyses: A Glioblastoma Application</title>
      <link>https://arxiv.org/abs/2511.01778</link>
      <description>arXiv:2511.01778v1 Announce Type: new 
Abstract: This report describes an application of artificial intelligence (AI) to the Bayesian analysis of glioblastoma survival data. It has been suggested that AI can be used to construct prior distributions for parameters in Bayesian models rather than using the difficult, unreliable, and time-consuming process of eliciting expert opinion from radiation oncologists. Here, we show how generative AI can quickly propose sensible prior distributions of the hazard ratio comparing two glioblastoma therapies, for a standard Bayesian survival model on real data. Three Chatbots generated two alternative priors each which were evaluated by a radiation oncologist and then used in a sensitivity analysis to assess posterior stability. The results suggest that, for this cancer survival analysis, priors from generative AI are a preferred alternative method to expert elicitation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01778v1</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard Evans, Max Felland, Susanna Evans, Lindsey Sloan</dc:creator>
    </item>
    <item>
      <title>Chitchat with AI: Understand the supply chain carbon disclosure of companies worldwide through Large Language Model</title>
      <link>https://arxiv.org/abs/2511.00024</link>
      <description>arXiv:2511.00024v1 Announce Type: cross 
Abstract: In the context of global sustainability mandates, corporate carbon disclosure has emerged as a critical mechanism for aligning business strategy with environmental responsibility. The Carbon Disclosure Project (CDP) hosts the world's largest longitudinal dataset of climate-related survey responses, combining structured indicators with open-ended narratives, but the heterogeneity and free-form nature of these disclosures present significant analytical challenges for benchmarking, compliance monitoring, and investment screening. This paper proposes a novel decision-support framework that leverages large language models (LLMs) to assess corporate climate disclosure quality at scale. It develops a master rubric that harmonizes narrative scoring across 11 years of CDP data (2010-2020), enabling cross-sector and cross-country benchmarking. By integrating rubric-guided scoring with percentile-based normalization, our method identifies temporal trends, strategic alignment patterns, and inconsistencies in disclosure across industries and regions. Results reveal that sectors such as technology and countries like Germany consistently demonstrate higher rubric alignment, while others exhibit volatility or superficial engagement, offering insights that inform key decision-making processes for investors, regulators, and corporate environmental, social, and governance (ESG) strategists. The proposed LLM-based approach transforms unstructured disclosures into quantifiable, interpretable, comparable, and actionable intelligence, advancing the capabilities of AI-enabled decision support systems (DSSs) in the domain of climate governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00024v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haotian Hang, Yueyang Shen, Vicky Zhu, Jose Cruz, Michelle Li</dc:creator>
    </item>
    <item>
      <title>Position Paper: If Innovation in AI Systematically Violates Fundamental Rights, Is It Innovation at All?</title>
      <link>https://arxiv.org/abs/2511.00027</link>
      <description>arXiv:2511.00027v1 Announce Type: cross 
Abstract: Artificial intelligence (AI) now permeates critical infrastructures and decision-making systems where failures produce social, economic, and democratic harm. This position paper challenges the entrenched belief that regulation and innovation are opposites. As evidenced by analogies from aviation, pharmaceuticals, and welfare systems and recent cases of synthetic misinformation, bias and unaccountable decision-making, the absence of well-designed regulation has already created immeasurable damage. Regulation, when thoughtful and adaptive, is not a brake on innovation -- it is its foundation. The present position paper examines the EU AI Act as a model of risk-based, responsibility-driven regulation that addresses the Collingridge Dilemma: acting early enough to prevent harm, yet flexibly enough to sustain innovation. Its adaptive mechanisms -- regulatory sandboxes, small and medium enterprises (SMEs) support, real-world testing, fundamental rights impact assessment (FRIA) -- demonstrate how regulation can accelerate responsibly, rather than delay, technological progress. The position paper summarises how governance tools transform perceived burdens into tangible advantages: legal certainty, consumer trust, and ethical competitiveness. Ultimately, the paper reframes progress: innovation and regulation advance together. By embedding transparency, impact assessments, accountability, and AI literacy into design and deployment, the EU framework defines what responsible innovation truly means -- technological ambition disciplined by democratic values and fundamental rights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00027v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Josu Eguiluz Casta\~neira, Axel Brando, Migle Laukyte, Marc Serra-Vidal</dc:creator>
    </item>
    <item>
      <title>Closing the SNAP Gap: Identifying Under-Enrollment in High-Poverty ZIP Codes</title>
      <link>https://arxiv.org/abs/2511.00080</link>
      <description>arXiv:2511.00080v1 Announce Type: cross 
Abstract: This project began by constructing an index of economic insecurity using multiple socioeconomic indicators. Although poverty alone predicted SNAP participation more accurately than the composite index, its explanatory power was weaker than anticipated, echoing past findings that enrollment cannot be explained by income alone. This led to a shift in focus: identifying ZIP codes with high poverty but unexpectedly low SNAP participation, areas defined here as having a SNAP Gap, where ZIPs fall in the top 30 percent of family poverty and the bottom 10 percent of SNAP enrollment. Using nationally available ZIP level data from 2014 to 2023, I trained logistic classification models on four interpretable structural indicators: lack of vehicle, lack of internet access, lack of computer access, and percentage of adults with only a high school diploma. The most effective model relies on just two predictors, vehicle access and education, and outperforms tree based classifiers in both precision and calibration. Results show that economic insecurity is consistently concentrated in rural ZIP codes, with transportation access emerging as the most stable barrier to program take up. This study provides a nationwide diagnostic framework that can inform the development of scalable screening tools for targeting outreach and improving benefit access in underserved communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00080v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Auyona Ray</dc:creator>
    </item>
    <item>
      <title>Forecasting Occupational Survivability of Rickshaw Pullers in a Changing Climate with Wearable Data</title>
      <link>https://arxiv.org/abs/2511.00081</link>
      <description>arXiv:2511.00081v1 Announce Type: cross 
Abstract: Cycle rickshaw pullers are highly vulnerable to extreme heat, yet little is known about how their physiological biomarkers respond under such conditions. This study collected real-time weather and physiological data using wearable sensors from 100 rickshaw pullers in Dhaka, Bangladesh. In addition, interviews with 12 pullers explored their knowledge, perceptions, and experiences related to climate change. We developed a Linear Gaussian Bayesian Network (LGBN) regression model to predict key physiological biomarkers based on activity, weather, and demographic features. The model achieved normalized mean absolute error values of 0.82, 0.47, 0.65, and 0.67 for skin temperature, relative cardiac cost, skin conductance response, and skin conductance level, respectively. Using projections from 18 CMIP6 climate models, we layered the LGBN on future climate forecasts to analyze survivability for current (2023-2025) and future years (2026-2100). Based on thresholds of WBGT above 31.1{\deg}C and skin temperature above 35{\deg}C, 32% of rickshaw pullers already face high heat exposure risk. By 2026-2030, this percentage may rise to 37% with average exposure lasting nearly 12 minutes, or about two-thirds of the trip duration. A thematic analysis of interviews complements these findings, showing that rickshaw pullers recognize their increasing climate vulnerability and express concern about its effects on health and occupational survivability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00081v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Masfiqur Rahaman, Maoyejatun Hasana, Shahad Shahriar Rahman, MD Sajid Mostafiz Noor, Razin Reaz Abedin, Md Toki Tahmid, Duncan Watson Parris, Tanzeem Choudhury, A. B. M. Alim Al Islam, Tauhidur Rahman</dc:creator>
    </item>
    <item>
      <title>Deep recurrent-convolutional neural network learning and physics Kalman filtering comparison in dynamic load identification</title>
      <link>https://arxiv.org/abs/2511.00100</link>
      <description>arXiv:2511.00100v1 Announce Type: cross 
Abstract: The dynamic structural load identification capabilities of the gated recurrent unit, long short-term memory, and convolutional neural networks are examined herein. The examination is on realistic small dataset training conditions and on a comparative view to the physics-based residual Kalman filter (RKF). The dynamic load identification suffers from the uncertainty related to obtaining poor predictions when in civil engineering applications only a low number of tests are performed or are available, or when the structural model is unidentifiable. In considering the methods, first, a simulated structure is investigated under a shaker excitation at the top floor. Second, a building in California is investigated under seismic base excitation, which results in loading for all degrees of freedom. Finally, the International Association for Structural Control-American Society of Civil Engineers (IASC-ASCE) structural health monitoring benchmark problem is examined for impact and instant loading conditions. Importantly, the methods are shown to outperform each other on different loading scenarios, while the RKF is shown to outperform the networks in physically parametrized identifiable cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00100v1</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1177/14759217241262972</arxiv:DOI>
      <arxiv:journal_reference>Structural Health Monitoring 24.3 (2025): 1752-1782</arxiv:journal_reference>
      <dc:creator>Marios Impraimakis</dc:creator>
    </item>
    <item>
      <title>Analysis of Line Break prediction models for detecting defensive breakthrough in football</title>
      <link>https://arxiv.org/abs/2511.00121</link>
      <description>arXiv:2511.00121v1 Announce Type: cross 
Abstract: In football, attacking teams attempt to break through the opponent's defensive line to create scoring opportunities. This action, known as a Line Break, is a critical indicator of offensive effectiveness and tactical performance, yet previous studies have mainly focused on shots or goal opportunities rather than on how teams break the defensive line. In this study, we develop a machine learning model to predict Line Breaks using event and tracking data from the 2023 J1 League season. The model incorporates 189 features, including player positions, velocities, and spatial configurations, and employs an XGBoost classifier to estimate the probability of Line Breaks. The proposed model achieved high predictive accuracy, with an AUC of 0.982 and a Brier score of 0.015. Furthermore, SHAP analysis revealed that factors such as offensive player speed, gaps in the defensive line, and offensive players' spatial distributions significantly contribute to the occurrence of Line Breaks. Finally, we found a moderate positive correlation between the predicted probability of being Line-Broken and the number of shots and crosses conceded at the team level. These results suggest that Line Breaks are closely linked to the creation of scoring opportunities and provide a quantitative framework for understanding tactical dynamics in football.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00121v1</guid>
      <category>cs.LG</category>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shoma Yagi, Jun Ichikawa, Genki Ichinose</dc:creator>
    </item>
    <item>
      <title>Molecular diversity as a biosignature</title>
      <link>https://arxiv.org/abs/2511.00525</link>
      <description>arXiv:2511.00525v1 Announce Type: cross 
Abstract: The search for life in the Solar System hinges on data from planetary missions. Biosignatures based on molecular identity, isotopic composition, or chiral excess require measurements that current and planned missions cannot provide.
  We introduce a new class of biosignatures, defined by the statistical organization of molecular assemblages and quantified using ecodiversity metrics. Using this framework, we analyze amino acid diversity across a dataset spanning terrestrial and extraterrestrial contexts.
  We find that biotic samples are consistently more diverse, and therefore distinct, from their sparser abiotic counterparts. This distinction holds for fatty acids as well, indicating that the diversity signal reflects a fundamental biosynthetic signature. It also proves persistent under space-like degradation.
  Relying only on relative abundances, this biogenicity assessment strategy is applicable to any molecular composition data from archived, current, and planned planetary missions. By capturing a fundamental statistical property of life's chemical organization, it may also transcend biosignatures that are contingent on Earth's evolutionary history.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00525v1</guid>
      <category>astro-ph.EP</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gideon Yoffe, Fabian Klenner, Barak Sober, Yohai Kaspi, Itay Halevy</dc:creator>
    </item>
    <item>
      <title>Air Pollution Forecasting in Bucharest</title>
      <link>https://arxiv.org/abs/2511.00532</link>
      <description>arXiv:2511.00532v1 Announce Type: cross 
Abstract: Air pollution, especially the particulate matter 2.5 (PM2.5), has become a growing concern in recent years, primarily in urban areas. Being exposed to air pollution is linked to developing numerous health problems, like the aggravation of respiratory diseases, cardiovascular disorders, lung function impairment, and even cancer or early death. Forecasting future levels of PM2.5 has become increasingly important over the past few years, as it can provide early warnings and help prevent diseases. This paper aims to design, fine-tune, test, and evaluate machine learning models for predicting future levels of PM2.5 over various time horizons. Our primary objective is to assess and compare the performance of multiple models, ranging from linear regression algorithms and ensemble-based methods to deep learning models, such as advanced recurrent neural networks and transformers, as well as large language models, on this forecasting task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00532v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Drago\c{s}-Andrei \c{S}erban, R\u{a}zvan-Alexandru Sm\u{a}du, Dumitru-Clementin Cercel</dc:creator>
    </item>
    <item>
      <title>Breaking Down the Scoring: Interrater Reliability and National Bias in Olympic Breaking</title>
      <link>https://arxiv.org/abs/2511.00553</link>
      <description>arXiv:2511.00553v1 Announce Type: cross 
Abstract: Introduction: The inclusion of Breaking in the 2024 Paris Olympic Games introduced a distinctive competition format in which two athletes compete head-to-head in battle rounds. Unlike other aesthetic sports, where athletes receive independent scores for their performances, Breaking judges assess the relative performance quality between two competitors across five predefined evaluation aspects. This may considerably increase their cognitive load and warrants a thorough examination of judging reliability and potential national bias, the tendency of judges to favor athletes from their own country. Methods: Official scoring data from the 2024 Olympic Breaking events were analyzed. Interrater reliability was assessed using the Intraclass Correlation Coefficient, while national bias was estimated using mixed-effects modelling based on judges' individual scores. Results: The analyses revealed low to moderate interrater reliability in Breaking, notably lower than levels reported in other aesthetic sports. Moreover, substantial national bias was detected, with judges displaying a systematic tendency to favor athletes from their own country. Discussion: Although the observed national bias, despite its notable magnitude, likely had only a limited effect on final competition outcomes, the relatively low interrater reliability highlights potential weaknesses in the current scoring framework that may warrant refinement. Nonetheless, Breaking's unique system of aggregating judges' scores into discrete votes appears to reduce the influence of individual judges on competition outcomes, thereby enhancing the system's robustness against unilateral score manipulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00553v1</guid>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Patrick Alexander Braeunig (Sportwissenschaftliches Institut, Universit\"at des Saarlandes)</dc:creator>
    </item>
    <item>
      <title>Reliable Curation of EHR Dataset via Large Language Models under Environmental Constraints</title>
      <link>https://arxiv.org/abs/2511.00772</link>
      <description>arXiv:2511.00772v1 Announce Type: cross 
Abstract: Electronic health records (EHRs) are central to modern healthcare delivery and research; yet, many researchers lack the database expertise necessary to write complex SQL queries or generate effective visualizations, limiting efficient data use and scientific discovery. To address this barrier, we introduce CELEC, a large language model (LLM)-powered framework for automated EHR data extraction and analytics. CELEC translates natural language queries into SQL using a prompting strategy that integrates schema information, few-shot demonstrations, and chain-of-thought reasoning, which together improve accuracy and robustness. On a subset of the EHRSQL benchmark, CELEC achieves execution accuracy comparable to prior systems while maintaining low latency, cost efficiency, and strict privacy by exposing only database metadata to the LLM. CELEC also adheres to strict privacy protocols: the LLM accesses only database metadata (e.g., table and column names), while all query execution occurs securely within the institutional environment, ensuring that no patient-level data is ever transmitted to or shared with the LLM. Ablation studies confirm that each component of the SQL generation pipeline, particularly the few-shot demonstrations, plays a critical role in performance. By lowering technical barriers and enabling medical researchers to query EHR databases directly, CELEC streamlines research workflows and accelerates biomedical discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00772v1</guid>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Raymond M. Xiong, Panyu Chen, Tianze Dong, Jian Lu, Benjamin Goldstein, Danyang Zhuo, Anru R. Zhang</dc:creator>
    </item>
    <item>
      <title>From Path Coefficients to Targeted Estimands: A Comparison of Structural Equation Models (SEM) and Targeted Maximum Likelihood Estimation (TMLE)</title>
      <link>https://arxiv.org/abs/2511.01040</link>
      <description>arXiv:2511.01040v1 Announce Type: cross 
Abstract: Structural Equation Modeling (SEM) has gained popularity in the social sciences and causal inference due to its flexibility in modeling complex relationships between variables and its availability in modern statistical software. To move beyond the parametric assumptions of SEM, this paper reviews targeted maximum likelihood estimation (TMLE), a doubly robust, machine learning-based approach that builds on nonparametric SEM. We demonstrate that both TMLE and SEM can be used to estimate standard causal effects and show that TMLE is robust to model misspecification. We conducted simulation studies under both correct and misspecified model conditions, implementing SEM and TMLE to estimate these causal effects. The simulations confirm that TMLE consistently outperforms SEM under misspecification in terms of bias, mean squared error, and the validity of confidence intervals. We applied both approaches to a real-world dataset to analyze the mediation effects of poverty on access to high school, revealing that the direct effect is no longer significant under TMLE, whereas SEM indicates significance. We conclude with practical guidance on using SEM and TMLE in light of recent developments in targeted learning for causal inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01040v1</guid>
      <category>stat.OT</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junjie Ma, Xiaoya Zhang, Guangye He, Yuting Han, Ting Ge, Feng Ji</dc:creator>
    </item>
    <item>
      <title>A structural equation formulation for general quasi-periodic Gaussian processes</title>
      <link>https://arxiv.org/abs/2511.01151</link>
      <description>arXiv:2511.01151v1 Announce Type: cross 
Abstract: This paper introduces a structural equation formulation that gives rise to a new family of quasi-periodic Gaussian processes, useful to process a broad class of natural and physiological signals. The proposed formulation simplifies generation and forecasting, and provides hyperparameter estimates, which we exploit in a convergent and consistent iterative estimation algorithm. A bootstrap approach for standard error estimation and confidence intervals is also provided. We demonstrate the computational and scaling benefits of the proposed approach on a broad class of problems, including water level tidal analysis, CO$_{2}$ emission data, and sunspot numbers data. By leveraging the structural equations, our method reduces the cost of likelihood evaluations and predictions from $\mathcal{O}(k^2 p^2)$ to $\mathcal{O}(p^2)$, significantly improving scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01151v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Unnati Nigam, Radhendushka Srivastava, Faezeh Marzbanrad, Michael Burke</dc:creator>
    </item>
    <item>
      <title>Z-Dip: a validated generalization of the Dip Test</title>
      <link>https://arxiv.org/abs/2511.01705</link>
      <description>arXiv:2511.01705v1 Announce Type: cross 
Abstract: Detecting multimodality in empirical distributions is a fundamental problem in statistics and data analysis, with applications ranging from clustering to social science. Hartigan's Dip Test is a classical nonparametric procedure for testing unimodality versus multimodality, but its interpretation is hindered by strong dependence on sample size and the need for lookup tables. We introduce the Z-Dip, a standardized extension of the Dip Test that removes sample-size dependence by comparing observed Dip values to simulated null distributions. We calibrate a universal decision threshold for Z-Dip via simulation and bootstrap resampling, providing a unified criterion for multimodality detection. In the final section, we also propose a downsampling-based approach to further mitigate residual sample-size effects in very large datasets. Lookup tables and software implementations are made available for efficient use in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01705v1</guid>
      <category>stat.ME</category>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edoardo Di Martino, Matteo Cinelli, Roy Cerqueti</dc:creator>
    </item>
    <item>
      <title>Variational Data-Consistent Assimilation</title>
      <link>https://arxiv.org/abs/2511.01759</link>
      <description>arXiv:2511.01759v1 Announce Type: cross 
Abstract: This work introduces a new class of four-dimensional variational data assimilation (4D-Var) methods grounded in data-consistent inversion (DCI) theory. The methods extend classical 4D-Var by incorporating a predictability-aware regularization term. The first method formulated is referred to as Data-Consistent 4D-Var (DC-4DVar), which is then enhanced using a Weighted Mean Error (WME) quantity-of-interest map to construct the DC-WME 4D-Var method. While the DC and DC-WME cost functions both involve a predictability-aware regularization term, the DC-WME function includes a modification to the model-data misfit, thereby improving estimation accuracy, robustness, and theoretical consistency in nonlinear and partially observed dynamical systems. Proofs are provided that establish the existence and uniqueness of the minimizer and analyze how a predictability assumption that is common within the DCI framework helps to promote solution stability. Numerical experiments are presented on benchmark dynamical systems (Lorenz-63 and Lorenz-96) as well as for the shallow water equations (SWE). In the benchmark dynamical systems, the DC-WME 4D-Var formulation is shown to consistently outperform standard 4D-Var in reducing both error and bias while maintaining robustness under high observation noise and short assimilation windows. Despite introducing modest computational overhead, DC-WME 4D-Var delivers improvements in estimation performance and forecast skill, demonstrating its potential practicality and scalability for high-dimensional data assimilation problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01759v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rylan Spence, Troy Butler, Clint Dawson</dc:creator>
    </item>
    <item>
      <title>Robust semi-parametric signal detection in particle physics with classifiers decorrelated via optimal transport</title>
      <link>https://arxiv.org/abs/2409.06399</link>
      <description>arXiv:2409.06399v4 Announce Type: replace 
Abstract: Searches for signals of new physics in particle physics are usually done by training a supervised classifier to separate a signal model from the known Standard Model physics (also called the background model). However, even when the signal model is correct, systematic errors in the background model can influence supervised classifiers and might adversely affect the signal detection procedure. To tackle this problem, one approach is to use the (possibly misspecified) classifier only to perform a preliminary signal-enrichment step and then to carry out a signal detection test on the signal-rich sample. For this procedure to work, we need a classifier constrained to be decorrelated with one or more protected variables used for the signal-detection step. We do this by considering an optimal transport map of the classifier output that makes it independent of the protected variable(s) for the background. We then fit a semiparametric mixture model to the distribution of the protected variable after making cuts on the transformed classifier to detect the presence of a signal. We compare and contrast this decorrelation method with previous approaches, show that the decorrelation procedure is robust to moderate background misspecification, and analyze the power and validity of the signal detection test as a function of the cut on the classifier both with and without decorrelation. We conclude that decorrelation and signal enrichment help produce a stable, robust, valid, and more powerful test.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06399v4</guid>
      <category>stat.AP</category>
      <category>hep-ex</category>
      <category>hep-ph</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Purvasha Chakravarti, Lucas Kania, Olaf Behnke, Mikael Kuusela, Larry Wasserman</dc:creator>
    </item>
    <item>
      <title>Pluri-Gaussian rapid updating of geological domains</title>
      <link>https://arxiv.org/abs/2506.01575</link>
      <description>arXiv:2506.01575v2 Announce Type: replace 
Abstract: Over the past decade, the rapid updating of resource knowledge and the integration of real-time sensor information have gained attention in both industry and academia. However, most studies on rapid resource model updating have focused on continuous variables, such as grade variables and coal quality parameters. Geological domain modelling is an essential component of resource estimation, which is why it is crucial to extend data assimilation techniques to enable the rapid updating of categorical variables. In this paper, a methodology inspired by pluri-Gaussian simulation is proposed for near-real-time updating of geological domains, followed by updating grade variables within these domain boundaries. The proposed algorithm consists of a Gibbs sampler for converting geological domains into Gaussian random fields, an ensemble Kalman filter with multiple data assimilations for rapid updating, and rotation based iterative Gaussianisation for multi-Gaussian transformation. We demonstrate the algorithm by using a synthetic case study with observations sampled from the ground truth, as well as a real case study that uses production drilling samples to jointly update geological domains and grade variables. Both case studies are based on real data from an iron oxide-copper-gold deposit in South Australia. This approach enhances resource knowledge by incorporating both categorical and continuous variables, leading to improved reproduction of domain geometries, closer matches between predictions and observations, and more geologically realistic resource models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01575v2</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sultan Abulkhair, Peter Dowd, Chaoshui Xu</dc:creator>
    </item>
    <item>
      <title>The Perceived Influences of Environment on Health in Italy: a Penalized Ordinal Regression Approach</title>
      <link>https://arxiv.org/abs/2510.01803</link>
      <description>arXiv:2510.01803v2 Announce Type: replace 
Abstract: Understanding how individuals perceive their living environment is a complex task, as it reflects both personal and contextual determinants. In this paper, we address this task by analyzing the environmental module of the Italian nationwide health surveillance system PASSI (Progressi delle Aziende Sanitarie per la Salute in Italia), integrating it with contextual information at the municipal level, including socio-economic indicators, pollution exposure, and other geographical characteristics. Methodologically, we adopt a penalized semi-parallel cumulative ordinal regression model to analyze how subjective perceptions are shaped by both personal and territorial determinants. The approach balances flexibility and interpretability by allowing both parallel and non-parallel effects while regularizing estimates to address multicollinearity and separation issues. We use the model as an analytical tool to uncover the determinants of positivity and neutrality in environmental perceptions, defined as factors that contribute the most to improving perception or increasing the sense of neutrality. The results are diverse. First, results reveal significant heterogeneity across Italian territories, indicating that local characteristics strongly shape environmental perception. Second, various individual factors interact with contextual influences to shape perceptions. Third, hazardous environmental factors, such as higher PM2.5 levels, appear to be associated with poorer environmental perception, suggesting a tendency among respondents to recognize specific environmental issues. Overall, the approach demonstrates strong potential for application and provides useful insights for environmental policy planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01803v2</guid>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mattia Stival, Angela Andreella, Gaia Bertarelli, Catarina Mid\~oes, Stefano Federico Tonellato, Stefano Campostrini</dc:creator>
    </item>
    <item>
      <title>Characterizing the Effects of Environmental Exposures on Social Mobility: Bayesian Semi-parametrics for Principal Stratification</title>
      <link>https://arxiv.org/abs/2412.00311</link>
      <description>arXiv:2412.00311v3 Announce Type: replace-cross 
Abstract: Understanding the causal effects of air pollution exposures on social mobility is attracting increasing attention. At the same time, education is widely recognized as a key driver of social mobility. However, the causal pathways linking fine particulate matter (PM2.5) exposure, educational attainment, and social mobility remain largely unexplored. To address this, we adopt the principal stratification approach, which rigorously defines causal effects when a post-treatment variable--educational attainment--is affected by exposure--PM2.5--and may, in turn, affect the primary outcome--social mobility. To estimate the causal effects, we propose a Bayesian semi-parametric method leveraging infinite mixtures for modeling the primary outcome. The proposed method (i) allows flexible modeling of the distribution of the primary potential outcomes, (ii) improves the accuracy of counterfactual imputation--a fundamental problem in causal inference framework--, and (iii) enables the characterization of treatment effects across different values of the post-treatment variable. We evaluate the performance of the proposed methodology through a Monte Carlo simulation study, demonstrating its advantages over existing approaches. Finally, we apply our method to a national dataset of 3,009 counties in the United States to estimate the causal effect of PM2.5 on social mobility, taking into account educational attainment as a post-treatment variable. Our findings indicate that in counties where higher PM2.5 exposure significantly reduces educational attainment social mobility decreases by approximately 5% compared to counties with lower PM2.5 exposure. We also find that in counties where exposure to PM2.5 does not affect educational attainment, social mobility is reduced by approximately 2% hinting at the possibility of further, yet unexplored, pathways connecting air pollution and social mobility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00311v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dafne Zorzetto, Paolo Dalla Torre, Sonia Petrone, Francesca Dominici, Falco J. Bargagli-Stoffi</dc:creator>
    </item>
    <item>
      <title>Mendelian Randomization Methods for Causal Inference: Estimands, Identification and Inference</title>
      <link>https://arxiv.org/abs/2509.11519</link>
      <description>arXiv:2509.11519v2 Announce Type: replace-cross 
Abstract: Mendelian randomization (MR) has become an essential tool for causal inference in biomedical and public health research. By using genetic variants as instrumental variables, MR helps address unmeasured confounding and reverse causation, offering a quasi-experimental framework to evaluate causal effects of modifiable exposures on health outcomes. Despite its promise, MR faces substantial methodological challenges, including invalid instruments, weak instrument bias, and design complexities across different data structures. In this tutorial review, we provide a comprehensive overview of MR methods for causal inference, emphasizing clarity of causal interpretation, study design comparisons, availability of software tools, and practical guidance for applied scientists. We organize the review around causal estimands, ensuring that analyses are anchored to well-defined causal questions. We discuss the problems of invalid and weak instruments, comparing available strategies for their detection and correction. We integrate discussions of population-based versus family-based MR designs, analyses based on individual-level versus summary-level data, and one-sample versus two-sample MR designs, highlighting their relative advantages and limitations. We also summarize recent methodological advances and software developments that extend MR to settings with many weak or invalid instruments and to modern high-dimensional omics data. Real-data applications, including UK Biobank and Alzheimer's disease proteomics studies, illustrate the use of these methods in practice. This review aims to serve as a tutorial-style reference for both methodologists and applied scientists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11519v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minhao Yao, Anqi Wang, Xihao Li, Zhonghua Liu</dc:creator>
    </item>
    <item>
      <title>Beyond PCA: Manifold Dimension Estimation via Local Graph Structure</title>
      <link>https://arxiv.org/abs/2510.15141</link>
      <description>arXiv:2510.15141v3 Announce Type: replace-cross 
Abstract: Local principal component analysis (Local PCA) has proven to be an effective tool for estimating the intrinsic dimension of a manifold. More recently, curvature-adjusted PCA (CA-PCA) has improved upon this approach by explicitly accounting for the curvature of the underlying manifold, rather than assuming local flatness. Building on these insights, we propose a general framework for manifold dimension estimation that captures the manifold's local graph structure by integrating PCA with regression-based techniques. Within this framework, we introduce two representative estimators: quadratic embedding (QE) and total least squares (TLS). Experiments on both synthetic and real-world datasets demonstrate that these methods perform competitively with, and often outperform, state-of-the-art alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15141v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zelong Bi, Pierre Lafaye de Micheaux</dc:creator>
    </item>
  </channel>
</rss>
