<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Jul 2025 02:22:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Characterizing p-Simulation Between Theories</title>
      <link>https://arxiv.org/abs/2507.13576</link>
      <description>arXiv:2507.13576v1 Announce Type: new 
Abstract: This paper characterizes when one axiomatic theory, as a proof system for tautologies, $p$-simulates another, by showing: (i)~if c.e. theory $\mathcal{S}$ efficiently interprets $\mathcal{S}{+}\phi$, then $\mathcal{S}$ $p$-simulates $\mathcal{S}{+}\phi$ (Je\v{r}\'abek in Pudl\'ak17 proved simulation), since the interpretation maps an $\mathcal{S}{+}\phi$-proof whose lines are all theorems into an $\mathcal{S}$-proof; (ii)~$\mathcal{S}$ proves ``$\mathcal{S}$ efficiently interprets $\mathcal{S}{+}\phi$'' iff $\mathcal{S}$ proves ``$\mathcal{S}$ $p$-simulates $\mathcal{S}{+}\phi$'' (if so, $\mathcal{S}$ already proves the $\Pi_1$ theorems of $\mathcal{S}{+}\phi$); and (iii)~no $\mathcal{S}$ $p$-simulates all theories. Result (iii) implies $\textbf{P}{\neq}\textbf{NP}{\neq}\textbf{coNP}$, using the nonrelativizing fact ``no c.e. theory interprets all c.e. theories'' (false for $\mathcal{S}$ with predicate for true sentences). To explore whether this framework resolves other open questions, the paper formulates conjectures stronger than ``no optimal proof system exists'' that imply Feige's Hypothesis, the existence of one-way functions, and circuit lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13576v1</guid>
      <category>cs.CC</category>
      <category>math.LO</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hunter Monroe</dc:creator>
    </item>
    <item>
      <title>Treedepth Inapproximability and Exponential ETH Lower Bound</title>
      <link>https://arxiv.org/abs/2507.13818</link>
      <description>arXiv:2507.13818v1 Announce Type: new 
Abstract: Treedepth is a central parameter to algorithmic graph theory. The current state-of-the-art in computing and approximating treedepth consists of a $2^{O(k^2)} n$-time exact algorithm and a polynomial-time $O(\text{OPT} \log^{3/2} \text{OPT})$-approximation algorithm, where the former algorithm returns an elimination forest of height $k$ (witnessing that treedepth is at most $k$) for the $n$-vertex input graph $G$, or correctly reports that $G$ has treedepth larger than $k$, and $\text{OPT}$ is the actual value of the treedepth. On the complexity side, exactly computing treedepth is NP-complete, but the known reductions do not rule out a polynomial-time approximation scheme (PTAS), and under the Exponential Time Hypothesis (ETH) only exclude a running time of $2^{o(\sqrt n)}$ for exact algorithms.
  We show that 1.0003-approximating treedepth is NP-hard, and that exactly computing the treedepth of an $n$-vertex graph requires time $2^{\Omega(n)}$, unless the ETH fails. We further derive that there exist absolute constants $\delta, c &gt; 0$ such that any $(1+\delta)$-approximation algorithm requires time $2^{\Omega(n / \log^c n)}$. We do so via a simple direct reduction from Satisfiability to Treedepth, inspired by a reduction recently designed for Treewidth [STOC '25].</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13818v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\'Edouard Bonnet, Daniel Neuen, Marek Soko{\l}owski</dc:creator>
    </item>
    <item>
      <title>Exact versus Approximate Representations of Boolean Functions in the De Morgan Basis</title>
      <link>https://arxiv.org/abs/2507.13963</link>
      <description>arXiv:2507.13963v1 Announce Type: new 
Abstract: A seminal result of Nisan and Szegedy (STOC, 1992) shows that for any total Boolean function, the degree of the real polynomial that computes the function, and the minimal degree of a real polynomial that point-wise approximates the function, are at most polynomially separated. Extending this result from degree to other complexity measures like sparsity of the polynomial representation, or total weight of the coefficients, remains poorly understood.
  In this work, we consider this problem in the De Morgan basis, and prove an analogous result for the sparsity of the polynomials at a logarithmic scale. Our result further implies that the exact $\ell_1$ norm and its approximate variant are also similarly related to each other at a log scale. This is in contrast to the Fourier basis, where the analog of our results are known to be false.
  Our proof is based on a novel random restriction method. Unlike most existing random restriction methods used in complexity theory, our random restriction process is adaptive and is based on how various complexity measures simplify during the restriction process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13963v1</guid>
      <category>cs.CC</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arkadev Chattopadhyay, Yogesh Dahiya, Shachar Lovett</dc:creator>
    </item>
    <item>
      <title>Strassen $2\times2$ Matrix Multiplication from a 3-dimensional Volume Form</title>
      <link>https://arxiv.org/abs/2507.13510</link>
      <description>arXiv:2507.13510v1 Announce Type: cross 
Abstract: The Strassen $2\times2$ matrix multiplication algorithm arises from the volume form on the 3-dimensional quotient space of the $2\times 2$ matrices by the multiples of identity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13510v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benoit Jacob (AMD)</dc:creator>
    </item>
    <item>
      <title>Fast computational deep thermalization</title>
      <link>https://arxiv.org/abs/2507.13670</link>
      <description>arXiv:2507.13670v1 Announce Type: cross 
Abstract: Deep thermalization refers to the emergence of Haar-like randomness from quantum systems upon partial measurements. As a generalization of quantum thermalization, it is often associated with high complexity and entanglement. Here, we introduce computational deep thermalization and construct the fastest possible dynamics exhibiting it at infinite effective temperature. Our circuit dynamics produce quantum states with low entanglement in polylogarithmic depth that are indistinguishable from Haar random states to any computationally bounded observer. Importantly, the observer is allowed to request many copies of the same residual state obtained from partial projective measurements on the state -- this condition is beyond the standard settings of quantum pseudorandomness, but natural for deep thermalization. In cryptographic terms, these states are pseudorandom, pseudoentangled, and crucially, retain these properties under local measurements. Our results demonstrate a new form of computational thermalization, where thermal-like behavior arises from structured quantum states endowed with cryptographic properties, instead of from highly unstructured ensembles. The low resource complexity of preparing these states suggests scalable simulations of deep thermalization using quantum computers. Our work also motivates the study of computational quantum pseudorandomness beyond BQP observers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13670v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shantanav Chakraborty, Soonwon Choi, Soumik Ghosh, Tudor Giurgic\u{a}-Tiron</dc:creator>
    </item>
    <item>
      <title>Proceedings of the 15th International Workshop on Non-Classical Models of Automata and Applications</title>
      <link>https://arxiv.org/abs/2507.14082</link>
      <description>arXiv:2507.14082v1 Announce Type: cross 
Abstract: The Fifteenth International Workshop on Non-Classical Models of Automata and Applications (NCMA 2025) was held in Loughborough, UK, on July 21 and 22, 2025, organized by the Department of Computer Science at Loughborough University and co-located with the 26th International Conference on Descriptional Complexity of Formal Systems (DCFS 2025, 22-24 July).
  The NCMA workshop series was established in 2009 as an annual event for researchers working on non-classical and classical models of automata, grammars or related devices. Such models are investigated both as theoretical models and as formal models for applications from various points of view. The goal of the NCMA workshop series is to exchange and develop novel ideas in order to gain deeper and interdisciplinary coverage of this particular area that may foster new insights and substantial progress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14082v1</guid>
      <category>cs.FL</category>
      <category>cs.CC</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.422</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 422, 2025</arxiv:journal_reference>
      <dc:creator>Nelma Moreira (Universidade do Porto), Luca Prigioniero (Loughborough University)</dc:creator>
    </item>
    <item>
      <title>Computable one-way functions on the reals</title>
      <link>https://arxiv.org/abs/2406.15817</link>
      <description>arXiv:2406.15817v3 Announce Type: replace 
Abstract: A major open problem in computational complexity is the existence of a one-way function, namely a function from strings to strings which is computationally easy to compute but hard to invert. Levin (2023) formulated the notion of one-way functions from reals (infinite bit-sequences) to reals in terms of computability, and asked whether partial computable one-way functions exist. We give a strong positive answer using the hardness of the halting problem and exhibiting a total computable one-way function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15817v3</guid>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.LO</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>George Barmpalias, Xiaoyan Zhang</dc:creator>
    </item>
    <item>
      <title>Statistical and Computational Guarantees of Kernel Max-Sliced Wasserstein Distances</title>
      <link>https://arxiv.org/abs/2405.15441</link>
      <description>arXiv:2405.15441v4 Announce Type: replace-cross 
Abstract: Optimal transport has been very successful for various machine learning tasks; however, it is known to suffer from the curse of dimensionality. Hence, dimensionality reduction is desirable when applied to high-dimensional data with low-dimensional structures. The kernel max-sliced (KMS) Wasserstein distance is developed for this purpose by finding an optimal nonlinear mapping that reduces data into $1$ dimension before computing the Wasserstein distance. However, its theoretical properties have not yet been fully developed. In this paper, we provide sharp finite-sample guarantees under milder technical assumptions compared with state-of-the-art for the KMS $p$-Wasserstein distance between two empirical distributions with $n$ samples for general $p\in[1,\infty)$. Algorithm-wise, we show that computing the KMS $2$-Wasserstein distance is NP-hard, and then we further propose a semidefinite relaxation (SDR) formulation (which can be solved efficiently in polynomial time) and provide a relaxation gap for the obtained solution. We provide numerical examples to demonstrate the good performance of our scheme for high-dimensional two-sample testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15441v4</guid>
      <category>stat.ML</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Wang, March Boedihardjo, Yao Xie</dc:creator>
    </item>
  </channel>
</rss>
