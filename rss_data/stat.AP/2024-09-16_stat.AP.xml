<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Sep 2024 03:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Statistical Analysis of Quantitative Cancer Imaging Data</title>
      <link>https://arxiv.org/abs/2409.08809</link>
      <description>arXiv:2409.08809v1 Announce Type: new 
Abstract: Recent advances in types and extent of medical imaging technologies has led to proliferation of multimodal quantitative imaging data in cancer. Quantitative medical imaging data refer to numerical representations derived from medical imaging technologies, such as radiology and pathology imaging, that can be used to assess and quantify characteristics of diseases, especially cancer. The use of such data in both clinical and research setting enables precise quantifications and analyses of tumor characteristics that can facilitate objective evaluation of disease progression, response to therapy, and prognosis. The scale and size of these imaging biomarkers is vast and presents several analytical and computational challenges that range from high-dimensionality to complex structural correlation patterns. In this review article, we summarize some state-of-the-art statistical methods developed for quantitative medical imaging data ranging from topological, functional and shape data analyses to spatial process models. We delve into common imaging biomarkers with a focus on radiology and pathology imaging in cancer, address the analytical questions and challenges they present, and highlight the innovative statistical and machine learning models that have been developed to answer relevant scientific and clinical questions. We also outline some emerging and open problems in this area for future explorations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08809v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shariq Mohammed, Maria Masotti, Nathaniel Osher, Satwik Acharyya, Veerabhadran Baladandayuthapani</dc:creator>
    </item>
    <item>
      <title>Tracing the impacts of Mount Pinatubo eruption on global climate using spatially-varying changepoint detection</title>
      <link>https://arxiv.org/abs/2409.08908</link>
      <description>arXiv:2409.08908v1 Announce Type: new 
Abstract: Significant events such as volcanic eruptions can have global and long lasting impacts on climate. These global impacts, however, are not uniform across space and time. Understanding how the Mt. Pinatubo eruption affects global and regional climate is of great interest for predicting impact on climate due to similar events. We propose a Bayesian framework to simultaneously detect and estimate spatially-varying temporal changepoints for regional climate impacts. Our approach takes into account the diffusing nature of the changes caused by the volcanic eruption and leverages spatial correlation. We illustrate our method on simulated datasets and compare it with an existing changepoint detection method. Finally, we apply our method on monthly stratospheric aerosol optical depth and surface temperature data from 1985 to 1995 to detect and estimate changepoints following the 1991 Mt. Pinatubo eruption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08908v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samantha Shi-Jun, Lyndsay Shand, Bo Li</dc:creator>
    </item>
    <item>
      <title>Resilient Infrastructure Network: Sparse Edge Change Identification via L1-Regularized Least Squares</title>
      <link>https://arxiv.org/abs/2409.08304</link>
      <description>arXiv:2409.08304v1 Announce Type: cross 
Abstract: Adversarial actions and a rapid climate change are disrupting operations of infrastructure networks (e.g., energy, water, and transportation systems). Unaddressed disruptions lead to system-wide shutdowns, emphasizing the need for quick and robust identification methods. One significant disruption arises from edge changes (addition or deletion) in networks. We present an $\ell_1$-norm regularized least-squares framework to identify multiple but sparse edge changes using noisy data. We focus only on networks that obey equilibrium equations, as commonly observed in the above sectors. The presence or lack of edges in these networks is captured by the sparsity pattern of the weighted, symmetric Laplacian matrix, while noisy data are node injections and potentials. Our proposed framework systematically leverages the inherent structure within the Laplacian matrix, effectively avoiding overparameterization. We demonstrate the robustness and efficacy of the proposed approach through a series of representative examples, with a primary emphasis on power networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08304v1</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajasekhar Anguluri</dc:creator>
    </item>
    <item>
      <title>Graphical Structural Learning of rs-fMRI data in Heavy Smokers</title>
      <link>https://arxiv.org/abs/2409.08395</link>
      <description>arXiv:2409.08395v2 Announce Type: cross 
Abstract: Recent studies revealed structural and functional brain changes in heavy smokers. However, the specific changes in topological brain connections are not well understood. We used Gaussian Undirected Graphs with the graphical lasso algorithm on rs-fMRI data from smokers and non-smokers to identify significant changes in brain connections. Our results indicate high stability in the estimated graphs and identify several brain regions significantly affected by smoking, providing valuable insights for future clinical research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08395v2</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiru Gong, Qimin Zhang, Huili Zheng, Zheyan Liu, Shaohan Chen</dc:creator>
    </item>
    <item>
      <title>Federated One-Shot Ensemble Clustering</title>
      <link>https://arxiv.org/abs/2409.08396</link>
      <description>arXiv:2409.08396v1 Announce Type: cross 
Abstract: Cluster analysis across multiple institutions poses significant challenges due to data-sharing restrictions. To overcome these limitations, we introduce the Federated One-shot Ensemble Clustering (FONT) algorithm, a novel solution tailored for multi-site analyses under such constraints. FONT requires only a single round of communication between sites and ensures privacy by exchanging only fitted model parameters and class labels. The algorithm combines locally fitted clustering models into a data-adaptive ensemble, making it broadly applicable to various clustering techniques and robust to differences in cluster proportions across sites. Our theoretical analysis validates the effectiveness of the data-adaptive weights learned by FONT, and simulation studies demonstrate its superior performance compared to existing benchmark methods. We applied FONT to identify subgroups of patients with rheumatoid arthritis across two health systems, revealing improved consistency of patient clusters across sites, while locally fitted clusters proved less transferable. FONT is particularly well-suited for real-world applications with stringent communication and privacy constraints, offering a scalable and practical solution for multi-site clustering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08396v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rui Duan, Xin Xiong, Jueyi Liu, Katherine P. Liao, Tianxi Cai</dc:creator>
    </item>
    <item>
      <title>Cross-Country Comparative Analysis of Climate Resilience and Localized Mapping in Data-Sparse Regions</title>
      <link>https://arxiv.org/abs/2409.08765</link>
      <description>arXiv:2409.08765v1 Announce Type: cross 
Abstract: Climate resilience across sectors varies significantly in low-income countries (LICs), with agriculture being the most vulnerable to climate change. Existing studies typically focus on individual countries, offering limited insights into broader cross-country patterns of adaptation and vulnerability. This paper addresses these gaps by introducing a framework for cross-country comparative analysis of sectoral climate resilience using meta-analysis and cross-country panel data techniques. The study identifies shared vulnerabilities and adaptation strategies across LICs, enabling more effective policy design. Additionally, a novel localized climate-agriculture mapping technique is developed, integrating sparse agricultural data with high-resolution satellite imagery to generate fine-grained maps of agricultural productivity under climate stress. Spatial interpolation methods, such as kriging, are used to address data gaps, providing detailed insights into regional agricultural productivity and resilience. The findings offer policymakers tools to prioritize climate adaptation efforts and optimize resource allocation both regionally and nationally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08765v1</guid>
      <category>cs.NE</category>
      <category>stat.AP</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ronald Katende</dc:creator>
    </item>
    <item>
      <title>The underreported death toll of wars: a probabilistic reassessment from a structured expert elicitation</title>
      <link>https://arxiv.org/abs/2409.08779</link>
      <description>arXiv:2409.08779v1 Announce Type: cross 
Abstract: Event datasets including those provided by Uppsala Conflict Data Program (UCDP) are based on reports from the media and international organizations, and are likely to suffer from reporting bias. Since the UCDP has strict inclusion criteria, they most likely under-estimate conflict-related deaths, but we do not know by how much. Here, we provide a generalizable, cross-national measure of uncertainty around UCDP reported fatalities that is more robust and realistic than UCDP's documented low and high estimates, and make available a dataset and R package accounting for the measurement uncertainty. We use a structured expert elicitation combined with statistical modelling to derive a distribution of plausible number of fatalities given the number of battle-related deaths and the type of violence documented by the UCDP. The results can help scholars understand the extent of bias affecting their empirical analyses of organized violence and contribute to improve the accuracy of conflict forecasting systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08779v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paola Vesco, David Randahl, H{\aa}vard Hegre, Stina H\"ogbladh, Mert Can Yilmaz</dc:creator>
    </item>
    <item>
      <title>AutoIRT: Calibrating Item Response Theory Models with Automated Machine Learning</title>
      <link>https://arxiv.org/abs/2409.08823</link>
      <description>arXiv:2409.08823v1 Announce Type: cross 
Abstract: Item response theory (IRT) is a class of interpretable factor models that are widely used in computerized adaptive tests (CATs), such as language proficiency tests. Traditionally, these are fit using parametric mixed effects models on the probability of a test taker getting the correct answer to a test item (i.e., question). Neural net extensions of these models, such as BertIRT, require specialized architectures and parameter tuning. We propose a multistage fitting procedure that is compatible with out-of-the-box Automated Machine Learning (AutoML) tools. It is based on a Monte Carlo EM (MCEM) outer loop with a two stage inner loop, which trains a non-parametric AutoML grade model using item features followed by an item specific parametric model. This greatly accelerates the modeling workflow for scoring tests. We demonstrate its effectiveness by applying it to the Duolingo English Test, a high stakes, online English proficiency test. We show that the resulting model is typically more well calibrated, gets better predictive performance, and more accurate scores than existing methods (non-explanatory IRT models and explanatory IRT models like BERT-IRT). Along the way, we provide a brief survey of machine learning methods for calibration of item parameters for CATs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08823v1</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Sharpnack, Phoebe Mulcaire, Klinton Bicknell, Geoff LaFlair, Kevin Yancey</dc:creator>
    </item>
    <item>
      <title>Dynamic Bayesian Networks with Conditional Dynamics in Edge Addition and Deletion</title>
      <link>https://arxiv.org/abs/2409.08965</link>
      <description>arXiv:2409.08965v1 Announce Type: cross 
Abstract: This study presents a dynamic Bayesian network framework that facilitates intuitive gradual edge changes. We use two conditional dynamics to model the edge addition and deletion, and edge selection separately. Unlike previous research that uses a mixture network approach, which restricts the number of possible edge changes, or structural priors to induce gradual changes, which can lead to unclear network evolution, our model induces more frequent and intuitive edge change dynamics. We employ Markov chain Monte Carlo (MCMC) sampling to estimate the model structures and parameters and demonstrate the model's effectiveness in a portfolio selection application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08965v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lupe S. H. Chan, Amanda M. Y. Chu, Mike K. P. So</dc:creator>
    </item>
    <item>
      <title>Adoption and implication of the Biased-Annotator Competence Estimation (BACE) model into COVID-19 vaccine Twitter data: Human annotation for latent message features</title>
      <link>https://arxiv.org/abs/2302.09482</link>
      <description>arXiv:2302.09482v3 Announce Type: replace 
Abstract: Traditional quantitative content analysis approach (human coding method) has weaknesses, such as assuming all human coders are equally accurate once the intercoder reliability for training reaches a threshold score. We applied the Biased-Annotator Competence Estimation (BACE) model (Tyler, 2021), which draws on Bayesian modeling to improve human coding. An important contribution of this model is it takes each coder's potential biases and reliability into consideration and treats the "true" label of each message as a latent parameter, with quantifiable estimation uncertainties. In contrast, in conventional human coding, each message will receive a fixed label without estimates for measurement uncertainties. In this extended abstract, we first summarize the weaknesses of conventional human coding; and then apply the BACE model to COVID-19 vaccine Twitter data and compare BACE with other statistical models; finally, we discuss how the BACE model can be applied to improve human coding of latent message features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.09482v3</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luhang Sun, Yun-Shiuan Chuang, Yibing Sun, Sijia Yang</dc:creator>
    </item>
    <item>
      <title>Varying coefficients correlated velocity models in complex landscapes with boundaries applied to narwhal responses to noise exposure</title>
      <link>https://arxiv.org/abs/2408.03741</link>
      <description>arXiv:2408.03741v4 Announce Type: replace 
Abstract: Narwhals in the Arctic are increasingly exposed to human activities that can temporarily or permanently threaten their survival by modifying their behavior. We examine GPS data from a population of narwhals exposed to ship and seismic airgun noise during a controlled experiment in 2018 in the Scoresby Sound fjord system in Southeast Greenland. The fjord system has a complex shore line, restricting the behavioral response options for the narwhals to escape the threats. We propose a new continuous-time correlated velocity model with varying coefficients that includes spatial constraints on movement. To assess the sound exposure effect we compare a baseline model for the movement before exposure to a response model for the movement during exposure. Our model, applied to the narwhal data, suggests increased tortuosity of the trajectories as a consequence of the spatial constraints, and further indicates that sound exposure can disturb narwhal motion up to a couple of tens of kilometers. Specifically, we found an increase in velocity and a decrease in the movement persistence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03741v4</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandre Delporte, Susanne Ditlevsen, Adeline Samson</dc:creator>
    </item>
    <item>
      <title>A Multi-objective Economic Statistical Design of the CUSUM chart: NSGA II Approach</title>
      <link>https://arxiv.org/abs/2409.04673</link>
      <description>arXiv:2409.04673v2 Announce Type: replace 
Abstract: This paper presents an approach for the economic statistical design of the Cumulative Sum (CUSUM) control chart in a multi-objective optimization framework. The proposed methodology integrates economic considerations with statistical aspects to optimize the design parameters like the sample size ($n$), sampling interval ($h$), and decision interval ($H$) of the CUSUM chart. The Non-dominated Sorting Genetic Algorithm II (NSGA II) is employed to solve the multi-objective optimization problem, aiming to minimize both the average cost per cycle ($C_E$) and the out-of-control Average Run Length ($ARL_\delta$) simultaneously. The effectiveness of the proposed approach is demonstrated through a numerical example by determining the optimized CUSUM chart parameters using NSGA II. Additionally, sensitivity analysis is conducted to assess the impact of variations in input parameters. The corresponding results indicate that the proposed methodology significantly reduces the expected cost per cycle by about 43% when compared to the findings of the article by M. Lee in the year 2011. A more extensive comparison with respect to both $C_E$ and $ARL_\delta$ has also been provided for justifying the methodology proposed in this article. This highlights the practical relevance and potential of this study for the right application of the technique of the CUSUM chart for process control purposes in industries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04673v2</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sandeep Kajal, Arup Ranjan Mukhopadhyay</dc:creator>
    </item>
    <item>
      <title>A Tutorial on Asymptotic Properties for Biostatisticians with Applications to COVID-19 Data</title>
      <link>https://arxiv.org/abs/2211.07351</link>
      <description>arXiv:2211.07351v2 Announce Type: replace-cross 
Abstract: Asymptotic properties of statistical estimators play a significant role both in practice and in theory. However, many asymptotic results in statistics rely heavily on the independent and identically distributed (iid) assumption, which is not realistic when we have fixed designs. In this article, we build a roadmap of general procedures for deriving asymptotic properties under fixed designs and the observations need not to be iid. We further provide their applications in many statistical applications. Finally, we apply our results to Poisson regression using a COVID-19 dataset as an illustration to demonstrate the power of these results in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.07351v2</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Elvis Han Cui</dc:creator>
    </item>
    <item>
      <title>Functional Clustering for Longitudinal Associations between Social Determinants of Health and Stroke Mortality in the US</title>
      <link>https://arxiv.org/abs/2406.10499</link>
      <description>arXiv:2406.10499v4 Announce Type: replace-cross 
Abstract: Understanding the longitudinally changing associations between Social Determinants of Health (SDOH) and stroke mortality is essential for effective stroke management. Previous studies have uncovered significant regional disparities in the relationships between SDOH and stroke mortality. However, existing studies have not utilized longitudinal associations to develop data-driven methods for regional division in stroke control. To fill this gap, we propose a novel clustering method to analyze SDOH -- stroke mortality associations in US counties. To enhance the interpretability of the clustering outcomes, we introduce a novel regularized expectation-maximization algorithm equipped with various sparsity-and-smoothness-pursued penalties, aiming at simultaneous clustering and variable selection in longitudinal associations. As a result, we can identify crucial SDOH that contribute to longitudinal changes in stroke mortality. This facilitates the clustering of US counties into different regions based on the relationships between these SDOH and stroke mortality. The effectiveness of our proposed method is demonstrated through extensive numerical studies. By applying our method to longitudinal data on SDOH and stroke mortality at the county level, we identify 18 important SDOH for stroke mortality and divide the US counties into two clusters based on these selected SDOH. Our findings unveil complex regional heterogeneity in the longitudinal associations between SDOH and stroke mortality, providing valuable insights into region-specific SDOH adjustments for mitigating stroke mortality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10499v4</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Fangzhi Luo, Jianbin Tan, Donglan Zhang, Hui Huang, Ye Shen</dc:creator>
    </item>
    <item>
      <title>Discovery of Two Ultra-Diffuse Galaxies with Unusually Bright Globular Cluster Luminosity Functions via a Mark-Dependently Thinned Point Process (MATHPOP)</title>
      <link>https://arxiv.org/abs/2409.06040</link>
      <description>arXiv:2409.06040v2 Announce Type: replace-cross 
Abstract: We present \textsc{Mathpop}, a novel method to infer the globular cluster (GC) counts in ultra-diffuse galaxies (UDGs) and low-surface brightness galaxies (LSBGs). Many known UDGs have a surprisingly high ratio of GC number to surface brightness. However, standard methods to infer GC counts in UDGs face various challenges, such as photometric measurement uncertainties, GC membership uncertainties, and assumptions about the GC luminosity functions (GCLFs). \textsc{Mathpop} tackles these challenges using the mark-dependent thinned point process, enabling joint inference of the spatial and magnitude distributions of GCs. In doing so, \textsc{Mathpop} allows us to infer and quantify the uncertainties in both GC counts and GCLFs with minimal assumptions. As a precursor to \textsc{Mathpop}, we also address the data uncertainties coming from the selection process of GC candidates: we obtain probabilistic GC candidates instead of the traditional binary classification based on the color--magnitude diagram. We apply \textsc{Mathpop} to 40 LSBGs in the Perseus cluster using GC catalogs from a \textit{Hubble Space Telescope} imaging program. We then compare our results to those from an independent study using the standard method. We further calibrate and validate our approach through extensive simulations. Our approach reveals two LSBGs having GCLF turnover points much brighter than the canonical value with Bayes' factor being $\sim4.5$ and $\sim2.5$, respectively. An additional crude maximum-likelihood estimation shows that their GCLF TO points are approximately $0.9$~mag and $1.1$~mag brighter than the canonical value, with $p$-value $\sim 10^{-8}$ and $\sim 10^{-5}$, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06040v2</guid>
      <category>astro-ph.GA</category>
      <category>stat.AP</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dayi Li, Gwendolyn Eadie, Patrick Brown, William Harris, Roberto Abraham, Pieter van Dokkum, Steven Janssens, Samantha Berek, Shany Danieli, Aaron Romanowsky, Joshua Speagle</dc:creator>
    </item>
  </channel>
</rss>
