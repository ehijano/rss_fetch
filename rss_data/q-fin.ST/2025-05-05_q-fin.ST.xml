<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.ST</link>
    <description>q-fin.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 May 2025 04:02:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Multiscale Causal Analysis of Market Efficiency via News Uncertainty Networks and the Financial Chaos Index</title>
      <link>https://arxiv.org/abs/2505.01543</link>
      <description>arXiv:2505.01543v1 Announce Type: new 
Abstract: This study evaluates the scale-dependent informational efficiency of stock markets using the Financial Chaos Index, a tensor-eigenvalue-based measure of realized volatility. Incorporating Granger causality and network-theoretic analysis across a range of economic, policy, and news-based uncertainty indices, we assess whether public information is efficiently incorporated into asset price fluctuations. Based on a 34-year time period from 1990 to 2023, at the daily frequency, the semi-strong form of the Efficient Market Hypothesis is rejected at the 1\% level of significance, indicating that asset price changes respond predictably to lagged news-based uncertainty. In contrast, at the monthly frequency, such predictive structure largely vanishes, supporting informational efficiency at coarser temporal resolutions. A structural analysis of the Granger causality network reveals that fiscal and monetary policy uncertainties act as core initiators of systemic volatility, while peripheral indices, such as those related to healthcare and consumer prices, serve as latent bridges that become activated under crisis conditions. These findings underscore the role of time-scale decomposition and structural asymmetries in diagnosing market inefficiencies and mapping the propagation of macro-financial uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01543v1</guid>
      <category>q-fin.ST</category>
      <category>econ.EM</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masoud Ataei</dc:creator>
    </item>
    <item>
      <title>Why is the volatility of single stocks so much rougher than that of the S&amp;P500?</title>
      <link>https://arxiv.org/abs/2505.02678</link>
      <description>arXiv:2505.02678v1 Announce Type: new 
Abstract: The Nested factor model was introduced by Chicheportiche et al. to represent non-linear correlations between stocks. Stock returns are explained by a standard factor model, but the (log)-volatilities of factors and residuals are themselves decomposed into factor modes, with a common dominant volatility mode affecting both market and sector factors but also residuals. Here, we consider the case of a single factor where the only dominant log-volatility mode is rough, with a Hurst exponent $H \simeq 0.11$ and the log-volatility residuals are ''super-rough'', with $H \simeq 0$. We demonstrate that such a construction naturally accounts for the somewhat surprising stylized fact reported by Wu et al. , where it has been observed that the Hurst exponents of stock indexes are large compared to those of individual stocks. We propose a statistical procedure to estimate the Hurst factor exponent from the stock returns dynamics together with theoretical guarantees of its consistency. We demonstrate the effectiveness of our approach through numerical experiments and apply it to daily stock data from the S&amp;P500 index. The estimated roughness exponents for both the factor and idiosyncratic components validate the assumptions underlying our model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02678v1</guid>
      <category>q-fin.ST</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Othmane Zarhali, Cecilia Aubrun, Emmanuel Bacry, Jean-Philippe Bouchaud, Jean-Fran\c{c}ois Muzy</dc:creator>
    </item>
    <item>
      <title>Neural and Time-Series Approaches for Pricing Weather Derivatives: Performance and Regime Adaptation Using Satellite Data</title>
      <link>https://arxiv.org/abs/2411.12013</link>
      <description>arXiv:2411.12013v2 Announce Type: replace-cross 
Abstract: This paper studies pricing of weather-derivative (WD) contracts on temperature and precipitation. For temperature-linked strangles in Toronto and Chicago, we benchmark a harmonic-regression/ARMA model against a feed-forward neural network (NN), finding that the NN reduces out-of-sample mean-squared error (MSE) and materially shifts December fair values relative to both the time-series model and the industry-standard Historic Burn Approach (HBA).
  For precipitation, we employ a compound Poisson--Gamma framework: shape and scale parameters are estimated via maximum likelihood estimation (MLE) and via a convolutional neural network (CNN) trained on 30-day rainfall sequences spanning multiple seasons. The CNN adaptively learns season-specific $(\alpha,\beta)$ mappings, thereby capturing heterogeneity across regimes that static i.i.d.\ fits miss. At valuation, we assume days are i.i.d.\ $\Gamma(\hat{\alpha},\hat{\beta})$ within each regime and apply a mean-count approximation (replacing the Poisson count by its mean ($n\hat{\lambda}$) to derive closed-form strangle prices.
  Exploratory analysis of 1981--2023 NASA POWER data confirms pronounced seasonal heterogeneity in $(\alpha,\beta)$ between summer and winter, demonstrating that static global fits are inadequate. Back-testing on Toronto and Chicago grids shows that our regime-adaptive CNN yields competitive valuations and underscores how model choice can shift strangle prices. Payoffs are evaluated analytically when possible and by simulation elsewhere, enabling a like-for-like comparison of forecasting and valuation methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12013v2</guid>
      <category>q-fin.MF</category>
      <category>cs.LG</category>
      <category>q-fin.ST</category>
      <category>stat.ML</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Hening Tallarico, Pablo Olivares</dc:creator>
    </item>
    <item>
      <title>Beating the Correlation Breakdown: Robust Inference, Flexible Scenarios, and Stress Testing for Financial Portfolios</title>
      <link>https://arxiv.org/abs/2504.15268</link>
      <description>arXiv:2504.15268v2 Announce Type: replace-cross 
Abstract: We live in a multivariate world, and effective modeling of financial portfolios, including their construction, allocation, forecasting, and risk analysis, simply is not possible without explicitly modeling the dependence structure of their assets. Dependence structure can drive portfolio results more than the combined effects of other parameters in investment and risk models, but the literature provides relatively little to define the finite-sample distributions of dependence measures in useable and useful ways under challenging, real-world financial data conditions. Yet this is exactly what is needed to make valid inferences about their estimates, and to use these inferences for essential purposes such as hypothesis testing, dynamic monitoring, realistic and granular scenario and reverse scenario analyses, and mitigating the effects of correlation breakdowns during market upheavals. This work develops a new and straightforward method, Nonparametric Angles-based Correlation (NAbC), for defining the finite-sample distributions of any dependence measure whose matrix of pairwise associations is positive definite (e.g. Pearsons, Kendalls, Spearmans, Tail Dependence Matrix, and others). The solution remains valid under marginal asset distributions characterized by notably different and varying degrees of serial correlation, non-stationarity, heavy-tailedness, and asymmetry. Importantly, NAbCs p-values and confidence intervals remain analytically consistent at both the matrix level and the pairwise cell level. Finally, NAbC maintains validity even when selected cells in the matrix are frozen for a given scenario or stress test, thus enabling flexible, granular, and realistic scenarios. NAbC stands alone in providing all of these capabilities simultaneously, and should prove to be a very useful means by which we can better understand and manage financial portfolios in our multivariate world.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15268v2</guid>
      <category>q-fin.RM</category>
      <category>q-fin.PM</category>
      <category>q-fin.ST</category>
      <category>stat.AP</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>JD Opdyke</dc:creator>
    </item>
  </channel>
</rss>
