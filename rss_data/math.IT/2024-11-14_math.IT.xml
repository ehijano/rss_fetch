<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Nov 2024 05:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Erasure Decoding for Quantum LDPC Codes via Belief Propagation with Guided Decimation</title>
      <link>https://arxiv.org/abs/2411.08177</link>
      <description>arXiv:2411.08177v1 Announce Type: new 
Abstract: Quantum low-density parity-check (LDPC) codes are a promising family of quantum error-correcting codes for fault tolerant quantum computing with low overhead. Decoding quantum LDPC codes on quantum erasure channels has received more attention recently due to advances in erasure conversion for various types of qubits including neutral atoms, trapped ions, and superconducting qubits. Belief propagation with guided decimation (BPGD) decoding of quantum LDPC codes has demonstrated good performance in bit-flip and depolarizing noise. In this work, we apply BPGD decoding to quantum erasure channels. Using a natural modification, we show that BPGD offers competitive performance on quantum erasure channels for multiple families of quantum LDPC codes. Furthermore, we show that the performance of BPGD decoding on erasure channels can sometimes be improved significantly by either adding damping or adjusting the initial channel log-likelihood ratio for bits that are not erased. More generally, our results demonstrate BPGD is an effective general-purpose solution for erasure decoding across the quantum LDPC landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08177v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/Allerton63246.2024.10735275</arxiv:DOI>
      <dc:creator>Mert G\"okduman, Hanwen Yao, Henry D. Pfister</dc:creator>
    </item>
    <item>
      <title>Improved Constructions of Skew-Tolerant Gray Codes</title>
      <link>https://arxiv.org/abs/2411.08233</link>
      <description>arXiv:2411.08233v1 Announce Type: new 
Abstract: We study skew-tolerant Gray codes, which are Gray codes in which changes in consecutive codewords occur in adjacent positions. We present the first construction of asymptotically non-vanishing skew-tolerant Gray codes, offering an exponential improvement over the known construction. We also provide linear-time encoding and decoding algorithms for our codes. Finally, we extend the definition to non-binary alphabets, and provide constructions of complete $m$-ary skew-tolerant Gray codes for every base $m\geq 3$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08233v1</guid>
      <category>cs.IT</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Sac Himelfarb, Moshe Schwartz</dc:creator>
    </item>
    <item>
      <title>Efficient encoding and decoding algorithm for a class of perfect single-deletion-correcting permutation codes</title>
      <link>https://arxiv.org/abs/2411.08258</link>
      <description>arXiv:2411.08258v1 Announce Type: new 
Abstract: A permutation code is a nonlinear code whose codewords are permutation of a set of symbols. We consider the use of permutation code in the deletion channel, and consider the symbol-invariant error model, meaning that the values of the symbols that are not removed are not affected by the deletion. In 1992, Levenshtein gave a construction of perfect single-deletion-correcting permutation codes that attain the maximum code size. Furthermore, he showed in the same paper that the set of all permutations of a given length can be partitioned into permutation codes so constructed. This construction relies on the binary Varshamov-Tenengolts codes. In this paper we give an independent and more direct proof of Levenshtein's result that does not depend on the Varshamov-Tenengolts code. Using the new approach, we devise efficient encoding and decoding algorithms that correct one deletion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08258v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minhan Gao, Kenneth W. Shum</dc:creator>
    </item>
    <item>
      <title>Dynamic Thresholding Algorithm with Memory for Linear Inverse Problems</title>
      <link>https://arxiv.org/abs/2411.08284</link>
      <description>arXiv:2411.08284v1 Announce Type: new 
Abstract: The relaxed optimal $k$-thresholding pursuit (ROTP) is a recent algorithm for linear inverse problems. This algorithm is based on the optimal $k$-thresholding technique which performs vector thresholding and error metric reduction simultaneously. Although ROTP can be used to solve small to medium-sized linear inverse problems, the computational cost of this algorithm is high when solving large-scale problems. By merging the optimal $k$-thresholding technique and iterative method with memory as well as optimization with sparse search directions, we propose the so-called dynamic thresholding algorithm with memory (DTAM), which iteratively and dynamically selects vector bases to construct the problem solution. At every step, the algorithm uses more than one or all iterates generated so far to construct a new search direction, and solves only the small-sized quadratic subproblems at every iteration. Thus the computational complexity of DTAM is remarkably lower than that of ROTP-type methods. It turns out that DTAM can locate the solution of linear inverse problems if the matrix involved satisfies the restricted isometry property. Experiments on synthetic data, audio signal reconstruction and image denoising demonstrate that the proposed algorithm performs comparably to several mainstream thresholding and greedy algorithms, and it works much faster than the ROTP-type algorithms especially when the sparsity level of signal is relatively low.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08284v1</guid>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhong-Feng Sun, Yun-Bin Zhao, Jin-Chuan Zhou, Zheng-Hai Huang</dc:creator>
    </item>
    <item>
      <title>Modeling and Optimization for Rotatable Antenna Enabled Wireless Communication</title>
      <link>https://arxiv.org/abs/2411.08411</link>
      <description>arXiv:2411.08411v1 Announce Type: new 
Abstract: In this paper, we propose a new rotatable antenna (RA) model to improve the performance of wireless communication systems. Different from conventional fixed-position antenna (FPA), the proposed RA system can independently and flexibly change the three-dimensional (3D) orientation of each antenna by adjusting its declination angles to achieve desired channel realizations. Specifically, we study an RA-enabled uplink communication system, where the receive beamforming and the declination angles of all RAs are jointly optimized to maximize the minimum signal-to-interference-plus-noise ratio (SINR) among all the users. In the special single-user and free-space propagation setup, the optimal declination angles are derived in closed form with the maximum-ratio combining (MRC) beamformer applied at the base station (BS). In the general multi-user and multi-path setup, we propose an alternating optimization (AO) algorithm to alternately optimize the receive beamforming and the declination angles in an iterative manner. Simulation results are provided to demonstrate that the proposed RA-enabled system can significantly outperform other benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08411v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingjie Wu, Beixiong Zheng, Tiantian Ma, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Fractional Fourier Domain PAPR Reduction</title>
      <link>https://arxiv.org/abs/2411.08473</link>
      <description>arXiv:2411.08473v1 Announce Type: new 
Abstract: High peak-to-average power ratio (PAPR) has long posed a challenge for multi-carrier systems, impacting amplifier efficiency and overall system performance. This paper introduces dynamic angle fractional Fourier division multiplexing (DA-FrFDM), an innovative multi-carrier system that effectively reduces PAPR for both QAM and Gaussian signals with minimal signaling overhead. DA-FrFDM leverages the fractional Fourier domain to balance PAPR characteristics between the time and frequency domains, achieving significant PAPR reduction while preserving signal quality. Furthermore, DA-FrFDM refines signal processing and enables one-tap equalization in the fractional Fourier domain through the simple multiplication of time-domain signals by a quadratic phase sequence. Our results show that DA-FrFDM not only outperforms existing PAPR reduction techniques but also retains efficient inter-carrier interference (ICI) mitigation capabilities in doubly dispersive channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08473v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yewen Cao, Yulin Shao, Rose Qingyang Hu</dc:creator>
    </item>
    <item>
      <title>Variable-Length Feedback Codes via Deep Learning</title>
      <link>https://arxiv.org/abs/2411.08481</link>
      <description>arXiv:2411.08481v1 Announce Type: new 
Abstract: Variable-length feedback coding has the potential to significantly enhance communication reliability in finite block length scenarios by adapting coding strategies based on real-time receiver feedback. Designing such codes, however, is challenging. While deep learning (DL) has been employed to design sophisticated feedback codes, existing DL-aided feedback codes are predominantly fixed-length and suffer performance degradation in the high code rate regime, limiting their adaptability and efficiency. This paper introduces deep variable-length feedback (DeepVLF) code, a novel DL-aided variable-length feedback coding scheme. By segmenting messages into multiple bit groups and employing a threshold-based decoding mechanism for independent decoding of each bit group across successive communication rounds, DeepVLF outperforms existing DL-based feedback codes and establishes a new benchmark in feedback channel coding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08481v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenwei Lai, Yulin Shao, Yu Ding, Deniz Gunduz</dc:creator>
    </item>
    <item>
      <title>Sum Rate Maximization for Movable Antenna-Aided Downlink RSMA Systems</title>
      <link>https://arxiv.org/abs/2411.08509</link>
      <description>arXiv:2411.08509v1 Announce Type: new 
Abstract: Rate splitting multiple access (RSMA) is regarded as an essential and powerful physical-layer (PHY) paradigm for next generation communication systems. Under such a system, users employ successive interference cancellation (SIC), allowing them to decode a portion of the interference and treat the remainder as noise. However, a problem is that current RSMA systems rely on fixed-position antenna arrays, limiting their capacity to fully exploit spatial freedom. This constraint restricts beamforming gain, which substantially degrades RSMA performance. To address this problem, we propose an movable antenna (MA)-aided RSMA scheme that allows the antennas at the base station (BS) to adjust their positions dynamically. Our target is to maximize the system's sum rate of both common and private messages by jointly optimizing the MA positions, beamforming matrix, and common rate allocation. To tackle the formulated non-convex problem, we employ fractional programming (FP) and develop a two-stage, coarse-to-fine-grained search algorithm to obtain suboptimal solutions. Numerical results demonstrate that, with appropriate antenna adjustments, the MA-enabled system significantly enhances the overall performance and reliability of RSMA when employing the proposed algorithm compared to fixed-position antenna configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08509v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cixiao Zhang, Size Peng, Yin Xu, Xiaowu Ou, Xinghao Guo, Dazhi He, Wenjun Zhang</dc:creator>
    </item>
    <item>
      <title>On the Design of Variable Modulation and Adaptive Modulation for Uplink Sparse Code Multiple Access</title>
      <link>https://arxiv.org/abs/2411.08520</link>
      <description>arXiv:2411.08520v1 Announce Type: new 
Abstract: Sparse code multiple access (SCMA) is a promising non-orthogonal multiple access scheme for enabling massive connectivity in next generation wireless networks. However, current SCMA codebooks are designed with the same size, leading to inflexibility of user grouping and supporting diverse data rates. To address this issue, we propose a variable modulation SCMA (VM-SCMA) that allows users to employ codebooks with different modulation orders. To guide the VM-SCMA design, a VM matrix (VMM) that assigns modulation orders based on the SCMA factor graph is first introduced. We formulate the VM-SCMA design using the proposed average inverse product distance and the asymptotic upper bound of sum-rate, and jointly optimize the VMM, VM codebooks, power and codebook allocations. The proposed VM-SCMA not only enables diverse date rates but also supports different modulation order combinations for each rate. Leveraging these distinct advantages, we further propose an adaptive VM-SCMA (AVM-SCMA) scheme which adaptively selects the rate and the corresponding VM codebooks to adapt to the users' channel conditions by maximizing the proposed effective throughput. Simulation results show that the overall designs are able to simultaneously achieve a high-level system flexibility, enhanced error rate results, and significantly improved throughput performance, when compared to conventional SCMA schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08520v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qu Luo, Pei Xiao, Gaojie Chen, Jing Zhu</dc:creator>
    </item>
    <item>
      <title>A Framework for Robust Lossy Compression of Heavy-Tailed Sources</title>
      <link>https://arxiv.org/abs/2411.08549</link>
      <description>arXiv:2411.08549v1 Announce Type: new 
Abstract: We study the rate-distortion problem for both scalar and vector memoryless heavy-tailed $\alpha$-stable sources ($0 &lt; \alpha &lt; 2$). Using a recently defined notion of ``strength" as a power measure, we derive the rate-distortion function for $\alpha$-stable sources subject to a constraint on the strength of the error, and show it to be logarithmic in the strength-to-distortion ratio. We showcase how our framework paves the way to finding optimal quantizers for $\alpha$-stable sources and more generally to heavy-tailed ones. In addition, we study high-rate scalar quantizers and show that uniform ones are asymptotically optimal under the strength measure. We compare uniform Gaussian and Cauchy quantizers and show that more representation points for the Cauchy source are required to guarantee the same quantization quality. Our findings generalize the well-known rate-distortion and quantization results of Gaussian sources ($\alpha = 2$) under a quadratic distortion measure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08549v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karim Ezzeddine, Jihad Fahs, Ibrahim Abou-Faycal</dc:creator>
    </item>
    <item>
      <title>Integrated Precoder and Trajectory Design for MIMO UAV-Assisted Relay System With Finite-Alphabet Inputs</title>
      <link>https://arxiv.org/abs/2411.08680</link>
      <description>arXiv:2411.08680v1 Announce Type: new 
Abstract: Unmanned aerial vehicles (UAVs) are gaining widespread use in wireless relay systems due to their exceptional flexibility and cost-effectiveness. This paper focuses on the integrated design of UAV trajectories and the precoders at both the transmitter and UAV in a UAV-assisted relay communication system, accounting for transmit power constraints and UAV flight limitations. Unlike previous works that primarily address multiple-input single-output (MISO) systems with Gaussian inputs, we investigate a more realistic scenario involving multiple-input multiple-output (MIMO) systems with finite-alphabet inputs. To tackle the challenging and inherently non-convex problem, we propose an efficient solution algorithm that leverages successive convex approximation and alternating optimization techniques. Simulation results validate the effectiveness of the proposed algorithm, demonstrating its capability to optimize system performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08680v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyang Di, Xiaodong Zhu, Yulin Shao</dc:creator>
    </item>
    <item>
      <title>Large Wireless Model (LWM): A Foundation Model for Wireless Channels</title>
      <link>https://arxiv.org/abs/2411.08872</link>
      <description>arXiv:2411.08872v1 Announce Type: new 
Abstract: This paper presents the Large Wireless Model (LWM) -- the world's first foundation model for wireless channels. Designed as a task-agnostic model, LWM generates universal, rich, contextualized channel embeddings (features) that potentially enhance performance across a wide range of downstream tasks in wireless communication and sensing systems. Towards this objective, LWM, which has a transformer-based architecture, was pre-trained in a self-supervised manner on large-scale wireless channel datasets. Our results show consistent improvements in classification and regression tasks when using the LWM embeddings compared to raw channel representations, especially in scenarios with high-complexity machine learning tasks and limited training datasets. This LWM's ability to learn from large-scale wireless data opens a promising direction for intelligent systems that can efficiently adapt to diverse tasks with limited data, paving the way for addressing key challenges in wireless communication and sensing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08872v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sadjad Alikhani, Gouranga Charan, Ahmed Alkhateeb</dc:creator>
    </item>
    <item>
      <title>A Computer Search of New OBZCPs of Lengths up to 49</title>
      <link>https://arxiv.org/abs/2402.06081</link>
      <description>arXiv:2402.06081v3 Announce Type: replace 
Abstract: This paper aims to search for new optimal and sub-optimal Odd Binary Z-Complimentary Pairs (OBZCPs) for lengths up to 49. As an alternative to the celebrated binary Golay complementary pairs, optimal OBZCPs are the best almost-complementary sequence pairs having odd lengths. We introduce a computer search algorithm with time complexity $O(2^N)$, where $N$ denotes the sequence length and then show optimal results for all $27 \le N \le 33$ and $N=37,41,49$. For those sequence lengths (i.e., $N=35,39,43,45,47$) with no optimal pairs, we show OBZCPs with largest zero-correlation zone (ZCZ) widths (i.e., $Z$-optimal). Finally, based on the Pursley--Sarwate criterion (PSC), we present a table of OBZCPs with smallest combined auto-correlation and cross-correlation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06081v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.NT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Kazakov, Zilong Liu</dc:creator>
    </item>
    <item>
      <title>Destructive and constructive RIS beamforming in an ISAC-multi-user MIMO network</title>
      <link>https://arxiv.org/abs/2404.11314</link>
      <description>arXiv:2404.11314v2 Announce Type: replace 
Abstract: Integrated sensing and communication (ISAC) has already established itself as a promising solution to the spectrum scarcity problem, even more so when paired with a reconfigurable intelligent surface (RIS), as RISs can shape the propagation environment by adjusting their phase-shift coefficients. Albeit the potential performance gain, a RIS is also a potential security threat to the system. In this paper, we explore both the positive and negative sides of having a RIS in a multi-user multiple-input multiple-output (MIMO) ISAC network. We first develop an alternating optimization algorithm, obtaining the active and passive beamforming vectors that maximize the sensing signal-to-noise ratio (SNR) under minimum signal-to-interference-plus-noise ratio (SINR) constraints for the communication users and finite power budget. We also investigate the destructive potential of the RIS by devising a RIS phase-shift optimization algorithm that minimizes the sensing SNR while preserving the same minimum communication SINR previously guaranteed by the system. We further investigate the impact of the RIS's individual element failures on the system performance. The simulation results show that the RIS performance-boosting potential is as good as its destructive one and that both of our optimization strategies are hindered by the investigated impairments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11314v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Steven Rivetti, Ozlem Tugfe Demir, Emil Bjornson, Mikael Skoglund</dc:creator>
    </item>
    <item>
      <title>A Rate-Distortion Analysis for Composite Sources Under Subsource-Dependent Fidelity Criteria</title>
      <link>https://arxiv.org/abs/2405.11818</link>
      <description>arXiv:2405.11818v2 Announce Type: replace 
Abstract: A composite source, consisting of multiple subsources and a memoryless switch, outputs one symbol at a time from the subsource selected by the switch. If some data should be encoded more accurately than other data from an information source, the composite source model is suitable because in this model different distortion constraints can be put on the subsources. In this context, we propose subsource-dependent fidelity criteria for composite sources and use them to formulate a rate-distortion problem. We solve the problem and obtain a single-letter expression for the rate-distortion function. Further rate-distortion analysis characterizes the performance of classify-then-compress (CTC) coding, which is frequently used in practice when subsource-dependent fidelity criteria are considered. Our analysis shows that CTC coding generally has performance loss relative to optimal coding, even if the classification is perfect. We also identify the cause of the performance loss, that is, class labels have to be reproduced in CTC coding. Last but not least, we show that the performance loss is negligible for asymptotically small distortion if CTC coding is appropriately designed and some mild conditions are satisfied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11818v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiakun Liu, H. Vincent Poor, Iickho Song, Wenyi Zhang</dc:creator>
    </item>
    <item>
      <title>Explainable Enrichment-Driven GrAph Reasoner (EDGAR) for Large Knowledge Graphs with Applications in Drug Repurposing</title>
      <link>https://arxiv.org/abs/2409.18659</link>
      <description>arXiv:2409.18659v2 Announce Type: replace 
Abstract: Knowledge graphs (KGs) represent connections and relationships between real-world entities. We propose a link prediction framework for KGs named Enrichment-Driven GrAph Reasoner (EDGAR), which infers new edges by mining entity-local rules. This approach leverages enrichment analysis, a well-established statistical method used to identify mechanisms common to sets of differentially expressed genes. EDGAR's inference results are inherently explainable and rankable, with p-values indicating the statistical significance of each enrichment-based rule.
  We demonstrate the framework's effectiveness on a large-scale biomedical KG, ROBOKOP, focusing on drug repurposing for Alzheimer disease (AD) as a case study. Initially, we extracted 14 known drugs from the KG and identified 20 contextual biomarkers through enrichment analysis, revealing functional pathways relevant to shared drug efficacy for AD. Subsequently, using the top 1000 enrichment results, our system identified 1246 additional drug candidates for AD treatment. The top 10 candidates were validated using evidence from medical literature.
  EDGAR is deployed within ROBOKOP, complete with a web user interface. This is the first study to apply enrichment analysis to large graph completion and drug repurposing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18659v2</guid>
      <category>cs.IT</category>
      <category>cs.IR</category>
      <category>math.IT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Olawumi Olasunkanmi, Evan Morris, Yaphet Kebede, Harlin Lee, Stanley Ahalt, Alexander Tropsha, Chris Bizon</dc:creator>
    </item>
    <item>
      <title>Optimal vintage factor analysis with deflation varimax</title>
      <link>https://arxiv.org/abs/2310.10545</link>
      <description>arXiv:2310.10545v3 Announce Type: replace-cross 
Abstract: Vintage factor analysis is one important type of factor analysis that aims to first find a low-dimensional representation of the original data, and then to seek a rotation such that the rotated low-dimensional representation is scientifically meaningful. The most widely used vintage factor analysis is the Principal Component Analysis (PCA) followed by the varimax rotation. Despite its popularity, little theoretical guarantee can be provided to date mainly because varimax rotation requires to solve a non-convex optimization over the set of orthogonal matrices.
  In this paper, we propose a deflation varimax procedure that solves each row of an orthogonal matrix sequentially. In addition to its net computational gain and flexibility, we are able to fully establish theoretical guarantees for the proposed procedure in a broader context. Adopting this new deflation varimax as the second step after PCA, we further analyze this two step procedure under a general class of factor models. Our results show that it estimates the factor loading matrix in the minimax optimal rate when the signal-to-noise-ratio (SNR) is moderate or large. In the low SNR regime, we offer possible improvement over using PCA and the deflation varimax when the additive noise under the factor model is structured. The modified procedure is shown to be minimax optimal in all SNR regimes. Our theory is valid for finite sample and allows the number of the latent factors to grow with the sample size as well as the ambient dimension to grow with, or even exceed, the sample size. Extensive simulation and real data analysis further corroborate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.10545v3</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xin Bing, Dian Jin, Yuqian Zhang</dc:creator>
    </item>
    <item>
      <title>Discrete-Valued Signal Estimation via Low-Complexity Message Passing Algorithm for Highly Correlated Measurements</title>
      <link>https://arxiv.org/abs/2411.07558</link>
      <description>arXiv:2411.07558v2 Announce Type: replace-cross 
Abstract: This paper considers a discrete-valued signal estimation scheme based on a low-complexity Bayesian optimal message passing algorithm (MPA) for solving massive linear inverse problems under highly correlated measurements. Gaussian belief propagation (GaBP) can be derived by applying the central limit theorem (CLT)-based Gaussian approximation to the sum-product algorithm (SPA) operating on a dense factor graph (FG), while matched filter (MF)-expectation propagation (EP) can be obtained based on the EP framework tailored for the same FG. Generalized approximate message passing (GAMP) can be found by applying a rigorous approximation technique for both of them in the large-system limit, and these three MPAs perform signal detection using MF by assuming large-scale uncorrelated observations. However, each of them has a different inherent self-noise suppression mechanism, which makes a significant difference in the robustness against the correlation of the observations when we apply an annealed discrete denoiser (ADD) that adaptively controls its nonlinearity with the inverse temperature parameter corresponding to the number of iterations. In this paper, we unravel the mechanism of this interesting phenomenon, and further demonstrate the practical applicability of the low-complexity Bayesian optimal MPA with ADD under highly correlated measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07558v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomoharu Furudoi, Takumi Takahashi, Shinsuke Ibi, Hideki Ochiai</dc:creator>
    </item>
  </channel>
</rss>
