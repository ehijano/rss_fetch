<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 10 Oct 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Log-concave Sampling over a Convex Body with a Barrier: a Robust and Unified Dikin Walk</title>
      <link>https://arxiv.org/abs/2410.05700</link>
      <description>arXiv:2410.05700v1 Announce Type: new 
Abstract: We consider the problem of sampling from a $d$-dimensional log-concave distribution $\pi(\theta) \propto \exp(-f(\theta))$ for $L$-Lipschitz $f$, constrained to a convex body with an efficiently computable self-concordant barrier function, contained in a ball of radius $R$ with a $w$-warm start.
  We propose a \emph{robust} sampling framework that computes spectral approximations to the Hessian of the barrier functions in each iteration. We prove that for polytopes that are described by $n$ hyperplanes, sampling with the Lee-Sidford barrier function mixes within $\widetilde O((d^2+dL^2R^2)\log(w/\delta))$ steps with a per step cost of $\widetilde O(nd^{\omega-1})$, where $\omega\approx 2.37$ is the fast matrix multiplication exponent. Compared to the prior work of Mangoubi and Vishnoi, our approach gives faster mixing time as we are able to design a generalized soft-threshold Dikin walk beyond log-barrier.
  We further extend our result to show how to sample from a $d$-dimensional spectrahedron, the constrained set of a semidefinite program, specified by the set $\{x\in \mathbb{R}^d: \sum_{i=1}^d x_i A_i \succeq C \}$ where $A_1,\ldots,A_d, C$ are $n\times n$ real symmetric matrices. We design a walk that mixes in $\widetilde O((nd+dL^2R^2)\log(w/\delta))$ steps with a per iteration cost of $\widetilde O(n^\omega+n^2d^{3\omega-5})$. We improve the mixing time bound of prior best Dikin walk due to Narayanan and Rakhlin that mixes in $\widetilde O((n^2d^3+n^2dL^2R^2)\log(w/\delta))$ steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05700v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuzhou Gu, Nikki Lijing Kuang, Yi-An Ma, Zhao Song, Lichen Zhang</dc:creator>
    </item>
    <item>
      <title>Faster Algorithms for Graph Monopolarity</title>
      <link>https://arxiv.org/abs/2410.06337</link>
      <description>arXiv:2410.06337v1 Announce Type: new 
Abstract: A graph $G = (V,E)$ is said to be monopolar if its vertex set admits a partition $V = (C \uplus{} I)$ where $G[C]$ is a cluster graph and $I$ is an independent set in $G$. Monopolar graphs generalize both bipartite graphs and split graphs, and they have been extensively studied from both graph-theoretic and algorithmic points of view. In this work we focus on the problem MONOPOLAR RECOGNITION (MR) of deciding whether a given graph is monopolar. MR is known to be solvable in polynomial time in certain classes of graphs such as cographs and claw-free graphs, and to be NP-Hard in various restricted classes such as subcubic planar graphs. We initiate the study of exact exponential-time algorithms for MR and allied problems. We design an algorithm that solves MR in $\OhStar(1.3734^{n})$ time on input graphs with $n$ vertices. In fact we solve the more general problems MONOPOLAR EXTENSION (ME) and LIST MONOPOLAR PARTITION (LMP), which were introduced in the literature as part of the study of graph monopolarity, in $\OhStar(1.3734^{n})$ time. We also design fast parameterized algorithms for MR using two notions of distance from triviality as the parameters. Our FPT algorithms solve MR in $\OhStar(3.076^{k_{v}})$ and $\OhStar(2.253^{k_{e}})$ time, where $k_{v}$ and $k_{e}$ are, respectively, the sizes of the smallest claw-free vertex and edge deletion sets of the input graph. These results are a significant addition to the small number of FPT algorithms currently known for MR. Le and Nevries have shown that if a graph $G$ is chair-free, then an instance $(G,C')$ of ME can be solved in polynomial time for any subset $C'$ of its vertices. We significantly generalize this result; we show that we can solve instances $(G,C')$ of ME in polynomial time for arbitrary graphs $G$ and any chair-free vertex deletion set $C'$ of $G$. We believe this result could be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06337v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Geevarghese Philip, Shrinidhi Teganahally Sridhara</dc:creator>
    </item>
    <item>
      <title>Losing Treewidth In The Presence Of Weights</title>
      <link>https://arxiv.org/abs/2410.06343</link>
      <description>arXiv:2410.06343v1 Announce Type: new 
Abstract: In the Weighted Treewidth-$\eta$ Deletion problem we are given a node-weighted graph $G$ and we look for a vertex subset $X$ of minimum weight such that the treewidth of $G-X$ is at most $\eta$. We show that Weighted Treewidth-$\eta$ Deletion admits a randomized polynomial-time constant-factor approximation algorithm for every fixed $\eta$. Our algorithm also works for the more general Weighted Planar $F$-M-Deletion problem.
  This work extends the results for unweighted graphs by [Fomin, Lokshtanov, Misra, Saurabh; FOCS '12] and answers a question posed by [Agrawal, Lokshtanov, Misra, Saurabh, Zehavi; APPROX/RANDOM '18] and [Kim, Lee, Thilikos; APPROX/RANDOM '21]. The presented algorithm is based on a novel technique of random sampling of so-called protrusions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06343v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micha{\l} W{\l}odarczyk</dc:creator>
    </item>
    <item>
      <title>A Decomposition Approach to the Weighted $k$-server Problem</title>
      <link>https://arxiv.org/abs/2410.06485</link>
      <description>arXiv:2410.06485v1 Announce Type: new 
Abstract: A natural variant of the classical online $k$-server problem is the Weighted $k$-server problem, where the cost of moving a server is its weight times the distance through which it moves. Despite its apparent simplicity, the weighted $k$-server problem is extremely poorly understood. Specifically, even on uniform metric spaces, finding the optimum competitive ratio of randomized algorithms remains an open problem -- the best upper bound known is $2^{2^{k+O(1)}}$ due to a deterministic algorithm (Bansal et al., 2018), and the best lower bound known is $\Omega(2^k)$ (Ayyadevara and Chiplunkar, 2021).
  With the aim of closing this exponential gap between the upper and lower bounds, we propose a decomposition approach for designing a randomized algorithm for weighted $k$-server on uniform metrics. Our first contribution includes two relaxed versions of the problem and a technique to obtain an algorithm for weighted $k$-server from algorithms for the two relaxed versions. Specifically, we prove that if there exists an $\alpha_1$-competitive algorithm for one version (which we call Weighted $k$-Server - Service Pattern Construction (W$k$S-SPC) and there exists an $\alpha_2$-competitive algorithm for the other version (which we call Weighted $k$-server - Revealed Service Pattern (W$k$S-RSP)), then there exists an $(\alpha_1\alpha_2)$-competitive algorithm for weighted $k$-server on uniform metric spaces. Our second contribution is a $2^{O(k^2)}$-competitive randomized algorithm for W$k$S-RSP. As a consequence, the task of designing a $2^{poly(k)}$-competitive randomized algorithm for weighted $k$-server on uniform metrics reduces to designing a $2^{poly(k)}$-competitive randomized algorithm for W$k$S-SPC. Finally, we also prove that the $\Omega(2^k)$ lower bound for weighted $k$-server, in fact, holds for W$k$S-RSP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06485v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhil Ayyadevara, Ashish Chiplunkar, Amatya Sharma</dc:creator>
    </item>
    <item>
      <title>A short note about the learning-augmented secretary problem</title>
      <link>https://arxiv.org/abs/2410.06583</link>
      <description>arXiv:2410.06583v1 Announce Type: new 
Abstract: We consider the secretary problem through the lens of learning-augmented algorithms. As it is known that the best possible expected competitive ratio is $1/e$ in the classic setting without predictions, a natural goal is to design algorithms that are 1-consistent and $1/e$-robust. Unfortunately, [FY24] provided hardness constructions showing that such a goal is not attainable when the candidates' true values are allowed to scale with $n$. Here, we provide a simple and explicit alternative hardness construction showing that such a goal is not achievable even when the candidates' true values are constants that do not scale with $n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06583v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davin Choo, Chun Kai Ling</dc:creator>
    </item>
    <item>
      <title>An Optimal Algorithm for the Stacker Crane Problem on Fixed Topologies</title>
      <link>https://arxiv.org/abs/2410.06764</link>
      <description>arXiv:2410.06764v1 Announce Type: new 
Abstract: The Stacker Crane Problem (SCP) is a variant of the Traveling Salesman Problem. In SCP, pairs of pickup and delivery points are designated on a graph, and a crane must visit these points to move objects from each pickup location to its respective delivery point. The goal is to minimize the total distance traveled. SCP is known to be NP-hard, even on tree structures. The only positive results, in terms of polynomial-time solvability, apply to graphs that are topologically equivalent to a path or a cycle.
  We propose an algorithm that is optimal for each fixed topology, running in near-linear time. This is achieved by demonstrating that the problem is fixed-parameter tractable (FPT) when parameterized by both the cycle rank and the number of branch vertices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06764v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yike Chen, Ke Shi, Chao Xu</dc:creator>
    </item>
    <item>
      <title>A Polynomial Time Algorithm for Steiner Tree when Terminals Avoid a $K_4$-Minor</title>
      <link>https://arxiv.org/abs/2410.06793</link>
      <description>arXiv:2410.06793v1 Announce Type: new 
Abstract: We study a special case of the Steiner Tree problem in which the input graph does not have a minor model of a complete graph on 4 vertices for which all branch sets contain a terminal. We show that this problem can be solved in $O(n^4)$ time, where $n$ denotes the number of vertices in the input graph. This generalizes a seminal paper by Erickson et al. [Math. Oper. Res., 1987] that solves Steiner tree on planar graphs with all terminals on one face in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06793v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carla Groenland, Jesper Nederlof, Tomohiro Koana</dc:creator>
    </item>
    <item>
      <title>Near-Optimal-Time Quantum Algorithms for Approximate Pattern Matching</title>
      <link>https://arxiv.org/abs/2410.06808</link>
      <description>arXiv:2410.06808v1 Announce Type: new 
Abstract: Approximate Pattern Matching is among the most fundamental string-processing tasks. Given a text $T$ of length $n$, a pattern $P$ of length $m$, and a threshold $k$, the task is to identify the fragments of $T$ that are at distance at most $k$ to $P$. We consider the two most common distances: Hamming distance (the number of character substitutions) in Pattern Matching with Mismatches and edit distance (the minimum number of character insertions, deletions, and substitutions) in Pattern Matching with Edits. We revisit the complexity of these two problems in the quantum setting.
  Our recent work [STOC'24] shows that $\hat{O}(\sqrt{nk})$ quantum queries are sufficient to solve (the decision version of) Pattern Matching with Edits. However, the quantum time complexity of the underlying solution does not provide any improvement over classical computation. On the other hand, the state-of-the-art algorithm for Pattern Matching with Mismatches [Jin and Nogler; SODA'23] achieves query complexity $\hat{O}(\sqrt{nk^{3/2}})$ and time complexity $\tilde{O}(\sqrt{nk^2})$, falling short of an unconditional lower bound of $\Omega(\sqrt{nk})$ queries.
  In this work, we present quantum algorithms with a time complexity of $\tilde{O}(\sqrt{nk}+\sqrt{n/m}\cdot k^2)$ for Pattern Matching with Mismatches and $\hat{O}(\sqrt{nk}+\sqrt{n/m}\cdot k^{3.5})$ for Pattern Matching with Edits; both solutions use $\hat{O}(\sqrt{nk})$ queries. The running times are near-optimal for $k\ll m^{1/3}$ and $k\ll m^{1/6}$, respectively, and offer advantage over classical algorithms for $k\ll (mn)^{1/4}$ and $k\ll (mn)^{1/7}$, respectively. Our solutions can also report the starting positions of approximate occurrences of $P$ in $T$ (represented as collections of arithmetic progressions); in this case, the unconditional lower bound and the complexities of our algorithms increase by a $\Theta(\sqrt{n/m})$ factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06808v1</guid>
      <category>cs.DS</category>
      <category>quant-ph</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomasz Kociumaka, Jakob Nogler, Philip Wellnitz</dc:creator>
    </item>
    <item>
      <title>Faster and Simpler Online Computation of String Net Frequency</title>
      <link>https://arxiv.org/abs/2410.06837</link>
      <description>arXiv:2410.06837v1 Announce Type: new 
Abstract: An occurrence of a repeated substring $u$ in a string $S$ is called a net occurrence if extending the occurrence to the left or to the right decreases the number of occurrences to 1. The net frequency (NF) of a repeated substring $u$ in a string $S$ is the number of net occurrences of $u$ in $S$. Very recently, Guo et al. [SPIRE 2024] proposed an online $O(n \log \sigma)$-time algorithm that maintains a data structure of $O(n)$ space which answers Single-NF queries in $O(m\log \sigma + \sigma^2)$ time and reports all answers of the All-NF problem in $O(n\sigma^2)$ time. Here, $n$ is the length of the input string $S$, $m$ is the query pattern length, and $\sigma$ is the alphabet size. The $\sigma^2$ term is a major drawback of their method since computing string net frequencies is originally motivated for Chinese language processing where $\sigma$ can be thousands large. This paper presents an improved online $O(n \log \sigma)$-time algorithm, which answers Single-NF queries in $O(m \log \sigma)$ time and reports all answers to the All-NF problem in output-optimal $O(|\mathsf{NF}^+(S)|)$ time, where $\mathsf{NF}^+(S)$ is the set of substrings of $S$ paired with their positive NF values. We note that $|\mathsf{NF}^+(S)| = O(n)$ always holds. In contract to Guo et al.'s algorithm that is based on Ukkonen's suffix tree construction, our algorithm is based on Weiner's suffix tree construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06837v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shunsuke Inenaga</dc:creator>
    </item>
    <item>
      <title>Online Matching Meets Sampling Without Replacement</title>
      <link>https://arxiv.org/abs/2410.06868</link>
      <description>arXiv:2410.06868v1 Announce Type: new 
Abstract: Sampling without replacement is a natural online rounding strategy for converting fractional bipartite matching into an integral one. In Online Bipartite Matching, we can use the Balance algorithm to fractionally match each online vertex, and then sample an unmatched offline neighbor with probability proportional to the fractional matching. In Online Stochastic Matching, we can take the solution to a linear program relaxation as a reference, and then match each online vertex to an unmatched offline neighbor with probability proportional to the fractional matching of the online vertex's type. On the one hand, we find empirical evidence that online matching algorithms based on sampling without replacement outperform existing algorithms. On the other hand, the literature offers little theoretical understanding of the power of sampling without replacement in online matching problems.
  This paper fills the gap in the literature by giving the first non-trivial competitive analyses of sampling without replacement for online matching problems. In Online Stochastic Matching, we develop a potential function analysis framework to show that sampling without replacement is at least $0.707$-competitive. The new analysis framework further allows us to derandomize the algorithm to obtain the first polynomial-time deterministic algorithm that breaks the $1-\frac{1}{e}$ barrier. In Online Bipartite Matching, we show that sampling without replacement provides provable online correlated selection guarantees when the selection probabilities correspond to the fractional matching chosen by the Balance algorithm. As a result, we prove that sampling without replacement is at least $0.513$-competitive for Online Bipartite Matching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06868v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyi Huang, Chui Shan Lee, Jianqiao Lu, Xinkai Shu</dc:creator>
    </item>
    <item>
      <title>Positive bias makes tensor-network contraction tractable</title>
      <link>https://arxiv.org/abs/2410.05414</link>
      <description>arXiv:2410.05414v1 Announce Type: cross 
Abstract: Tensor network contraction is a powerful computational tool in quantum many-body physics, quantum information and quantum chemistry. The complexity of contracting a tensor network is thought to mainly depend on its entanglement properties, as reflected by the Schmidt rank across bipartite cuts. Here, we study how the complexity of tensor-network contraction depends on a different notion of quantumness, namely, the sign structure of its entries. We tackle this question rigorously by investigating the complexity of contracting tensor networks whose entries have a positive bias.
  We show that for intermediate bond dimension d&gt;~n, a small positive mean value &gt;~1/d of the tensor entries already dramatically decreases the computational complexity of approximately contracting random tensor networks, enabling a quasi-polynomial time algorithm for arbitrary 1/poly(n) multiplicative approximation. At the same time exactly contracting such tensor networks remains #P-hard, like for the zero-mean case [HHEG20]. The mean value 1/d matches the phase transition point observed in [CJHS24]. Our proof makes use of Barvinok's method for approximate counting and the technique of mapping random instances to statistical mechanical models. We further consider the worst-case complexity of approximate contraction of positive tensor networks, where all entries are non-negative. We first give a simple proof showing that a multiplicative approximation with error exponentially close to one is at least StoqMA-hard. We then show that when considering additive error in the matrix 1-norm, the contraction of positive tensor network is BPP-Complete. This result compares to Arad and Landau's [AL10] result, which shows that for general tensor networks, approximate contraction up to matrix 2-norm additive error is BQP-Complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05414v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaqing Jiang, Jielun Chen, Norbert Schuch, Dominik Hangleiter</dc:creator>
    </item>
    <item>
      <title>LevAttention: Time, Space, and Streaming Efficient Algorithm for Heavy Attentions</title>
      <link>https://arxiv.org/abs/2410.05462</link>
      <description>arXiv:2410.05462v1 Announce Type: cross 
Abstract: A central problem related to transformers can be stated as follows: given two $n \times d$ matrices $Q$ and $K$, and a non-negative function $f$, define the matrix $A$ as follows: (1) apply the function $f$ to each entry of the $n \times n$ matrix $Q K^T$, and then (2) normalize each of the row sums of $A$ to be equal to $1$. The matrix $A$ can be computed in $O(n^2 d)$ time assuming $f$ can be applied to a number in constant time, but the quadratic dependence on $n$ is prohibitive in applications where it corresponds to long context lengths. For a large class of functions $f$, we show how to find all the ``large attention scores", i.e., entries of $A$ which are at least a positive value $\varepsilon$, in time with linear dependence on $n$ (i.e., $n \cdot \textrm{poly}(d/\varepsilon)$) for a positive parameter $\varepsilon &gt; 0$. Our class of functions include all functions $f$ of the form $f(x) = |x|^p$, as explored recently in transformer models. Using recently developed tools from randomized numerical linear algebra, we prove that for any $K$, there is a ``universal set" $U \subset [n]$ of size independent of $n$, such that for any $Q$ and any row $i$, the large attention scores $A_{i,j}$ in row $i$ of $A$ all have $j \in U$. We also find $U$ in $n \cdot \textrm{poly}(d/\varepsilon)$ time. Notably, we (1) make no assumptions on the data, (2) our workspace does not grow with $n$, and (3) our algorithms can be computed in streaming and parallel settings. We call the attention mechanism that uses only the subset of keys in the universal set as LevAttention since our algorithm to identify the universal set $U$ is based on leverage scores. We empirically show the benefits of our scheme for vision transformers, showing how to train new models that use our universal set while training as well, showing that our model is able to consistently select ``important keys'' during training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05462v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ravindran Kannan, Chiranjib Bhattacharyya, Praneeth Kacham, David P. Woodruff</dc:creator>
    </item>
    <item>
      <title>Information Design with Unknown Prior</title>
      <link>https://arxiv.org/abs/2410.05533</link>
      <description>arXiv:2410.05533v1 Announce Type: cross 
Abstract: Classical information design models (e.g., Bayesian persuasion and cheap talk) require players to have perfect knowledge of the prior distribution of the state of the world. Our paper studies repeated persuasion problems in which the information designer does not know the prior. The information designer learns to design signaling schemes from repeated interactions with the receiver. We design learning algorithms for the information designer to achieve no regret compared to using the optimal signaling scheme with known prior, under two models of the receiver's decision-making. (1) The first model assumes that the receiver knows the prior and can perform posterior update and best respond to signals. In this model, we design a learning algorithm for the information designer with $O(\log T)$ regret in the general case, and another algorithm with $\Theta(\log \log T)$ regret in the case where the receiver has only two actions. (2) The second model assumes that the receiver does not know the prior and employs a no-regret learning algorithm to take actions. We show that the information designer can achieve regret $O(\sqrt{\mathrm{rReg}(T) T})$, where $\mathrm{rReg}(T)=o(T)$ is an upper bound on the receiver's learning regret. Our work thus provides a learning foundation for the problem of information design with unknown prior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05533v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Lin, Ce Li</dc:creator>
    </item>
    <item>
      <title>Extended convexity and smoothness and their applications in deep learning</title>
      <link>https://arxiv.org/abs/2410.05807</link>
      <description>arXiv:2410.05807v1 Announce Type: cross 
Abstract: The underlying mechanism by which simple gradient-based iterative algorithms can effectively handle the non-convex problem of deep model training remains incompletely understood within the traditional convex and non-convex analysis frameworks, which often require the Lipschitz smoothness of the gradient and strong convexity. In this paper, we introduce $\mathcal{H}(\phi)$-convexity and $\mathcal{H}(\Phi)$-smoothness, which broaden the existing concepts of smoothness and convexity, and delineate their fundamental properties. Building on these concepts, we introduce the high-order gradient descent and high-order stochastic gradient descent methods, which serve as extensions to the traditional gradient descent and stochastic gradient descent methods, respectively. Furthermore, we establish descent lemmas for the $\mathcal{H}(\phi)$-convex and $\mathcal{H}(\Phi)$-smooth objective functions when utilizing these four methods. On the basis of these findings, we develop the gradient structure control algorithm to address non-convex optimization objectives, encompassing both the functions represented by machine learning models and common loss functions in deep learning. The effectiveness of the proposed methodology is empirically validated through experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05807v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Binchuan Qi</dc:creator>
    </item>
    <item>
      <title>Mini-Batch Kernel $k$-means</title>
      <link>https://arxiv.org/abs/2410.05902</link>
      <description>arXiv:2410.05902v1 Announce Type: cross 
Abstract: We present the first mini-batch kernel $k$-means algorithm, offering an order of magnitude improvement in running time compared to the full batch algorithm. A single iteration of our algorithm takes $\widetilde{O}(kb^2)$ time, significantly faster than the $O(n^2)$ time required by the full batch kernel $k$-means, where $n$ is the dataset size and $b$ is the batch size. Extensive experiments demonstrate that our algorithm consistently achieves a 10-100x speedup with minimal loss in quality, addressing the slow runtime that has limited kernel $k$-means adoption in practice. We further complement these results with a theoretical analysis under an early stopping condition, proving that with a batch size of $\widetilde{\Omega}(\max \{\gamma^{4}, \gamma^{2}\} \cdot \epsilon^{-2})$, the algorithm terminates in $O(\gamma^2/\epsilon)$ iterations with high probability, where $\gamma$ bounds the norm of points in feature space and $\epsilon$ is a termination threshold. Our analysis holds for any reasonable center initialization, and when using $k$-means++ initialization, the algorithm achieves an approximation ratio of $O(\log k)$ in expectation. For normalized kernels, such as Gaussian or Laplacian it holds that $\gamma=1$. Taking $\epsilon = O(1)$ and $b=\Theta(\log n)$, the algorithm terminates in $O(1)$ iterations, with each iteration running in $\widetilde{O}(k)$ time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05902v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Jourdan, Gregory Schwartzman</dc:creator>
    </item>
    <item>
      <title>Weighted Embeddings for Low-Dimensional Graph Representation</title>
      <link>https://arxiv.org/abs/2410.06042</link>
      <description>arXiv:2410.06042v1 Announce Type: cross 
Abstract: Learning low-dimensional numerical representations from symbolic data, e.g., embedding the nodes of a graph into a geometric space, is an important concept in machine learning. While embedding into Euclidean space is common, recent observations indicate that hyperbolic geometry is better suited to represent hierarchical information and heterogeneous data (e.g., graphs with a scale-free degree distribution). Despite their potential for more accurate representations, hyperbolic embeddings also have downsides like being more difficult to compute and harder to use in downstream tasks.
  We propose embedding into a weighted space, which is closely related to hyperbolic geometry but mathematically simpler. We provide the embedding algorithm WEmbed and demonstrate, based on generated as well as over 2000 real-world graphs, that our weighted embeddings heavily outperform state-of-the-art Euclidean embeddings for heterogeneous graphs while using fewer dimensions. The running time of WEmbed and embedding quality for the remaining instances is on par with state-of-the-art Euclidean embedders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06042v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.SI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Bl\"asius, Jean-Pierre von der Heydt, Maximilian Katzmann, Nikolai Maas</dc:creator>
    </item>
    <item>
      <title>Smoothed analysis for graph isomorphism</title>
      <link>https://arxiv.org/abs/2410.06095</link>
      <description>arXiv:2410.06095v1 Announce Type: cross 
Abstract: From a theoretical point of view, graph isomorphism testing is a notoriously difficult problem, with no known polynomial-time algorithm. However, from a practical point of view, the problem is essentially solved: various elementary combinatorial ``refinement'' algorithms seem to be very efficient in practice. Some philosophical justification for this phenomenon is provided by a classical theorem of Babai, Erd\H{o}s and Selkow: an extremely simple polynomial-time combinatorial algorithm (variously known as ``na\"ive refinement'', ``na\"ive vertex classification'', ``colour refinement'' or the ``1-dimensional Weisfeiler--Leman algorithm'') yields a so-called $\textit{canonical labelling scheme}$ for ``almost all graphs''. More precisely, for a typical outcome of a random graph $\mathbb{G}(n,1/2)$, this simple combinatorial algorithm assigns labels to vertices in a way that easily permits isomorphism-testing against any other graph.
  We improve the Babai--Erd\H os--Selkow theorem in two directions. First, we consider $\textit{randomly perturbed}$ graphs, in accordance with the $\textit{smoothed analysis}$ philosophy of Spielman and Teng: for $\textit{any}$ graph $G$, na\"ive refinement, becomes effective after a tiny random perturbation to $G$ (specifically, the addition and removal of about $O(n)$ random edges). This improves on previous work in this direction due to Gaudio, R\'acz and Sridhar.
  Second, we complete a long line of research on canonical labelling and automorphisms for random graphs: for any sequence of probabilities $(p_{n})_{n\in\mathbb{N}}$, we prove that a certain polynomial-time canonical labelling algorithm succeeds on random graphs $\mathbb G(n,p_n)$ with probability $1-o(1)$ as $n\to\infty$. This result complements previous works of Bollob\'as, Czajka--Pandurangan and Linial--Mosheiff.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06095v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Anastos, Matthew Kwan, Benjamin Moore</dc:creator>
    </item>
    <item>
      <title>Provable Accuracy Bounds for Hybrid Dynamical Optimization and Sampling</title>
      <link>https://arxiv.org/abs/2410.06397</link>
      <description>arXiv:2410.06397v1 Announce Type: cross 
Abstract: Analog dynamical accelerators (DXs) are a growing sub-field in computer architecture research, offering order-of-magnitude gains in power efficiency and latency over traditional digital methods in several machine learning, optimization, and sampling tasks. However, limited-capacity accelerators require hybrid analog/digital algorithms to solve real-world problems, commonly using large-neighborhood local search (LNLS) frameworks. Unlike fully digital algorithms, hybrid LNLS has no non-asymptotic convergence guarantees and no principled hyperparameter selection schemes, particularly limiting cross-device training and inference.
  In this work, we provide non-asymptotic convergence guarantees for hybrid LNLS by reducing to block Langevin Diffusion (BLD) algorithms. Adapting tools from classical sampling theory, we prove exponential KL-divergence convergence for randomized and cyclic block selection strategies using ideal DXs. With finite device variation, we provide explicit bounds on the 2-Wasserstein bias in terms of step duration, noise strength, and function parameters. Our BLD model provides a key link between established theory and novel computing platforms, and our theoretical results provide a closed-form expression linking device variation, algorithm hyperparameters, and performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06397v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew X. Burns, Qingyuan Hou, Michael C. Huang</dc:creator>
    </item>
    <item>
      <title>Leaf Stripping on Uniform Attachment Trees</title>
      <link>https://arxiv.org/abs/2410.06481</link>
      <description>arXiv:2410.06481v1 Announce Type: cross 
Abstract: In this note we analyze the performance of a simple root-finding algorithm in uniform attachment trees. The leaf-stripping algorithm recursively removes all leaves of the tree for a carefully chosen number of rounds. We show that, with probability $1 - \epsilon$, the set of remaining vertices contains the root and has a size only depending on $\epsilon$ but not on the size of the tree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06481v1</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Louigi Addario-Berry, Anna Brandenberger, Simon Briend, Nicolas Broutin, G\'abor Lugosi</dc:creator>
    </item>
    <item>
      <title>Constant-delay enumeration for SLP-compressed documents</title>
      <link>https://arxiv.org/abs/2209.12301</link>
      <description>arXiv:2209.12301v3 Announce Type: replace 
Abstract: We study the problem of enumerating results from a query over a compressed document. The model we use for compression are straight-line programs (SLPs), which are defined by a context-free grammar that produces a single string. For our queries, we use a model called Annotated Automata, an extension of regular automata that allows annotations on letters. This model extends the notion of Regular Spanners as it allows arbitrarily long outputs. Our main result is an algorithm that evaluates such a query by enumerating all results with output-linear delay after a preprocessing phase which takes linear time on the size of the SLP, and cubic time over the size of the automaton. This is an improvement over Schmid and Schweikardt's result, which, with the same preprocessing time, enumerates with a delay that is logarithmic on the size of the uncompressed document. We achieve this through a persistent data structure named Enumerable Compact Sets with Shifts which guarantees output-linear delay under certain restrictions. These results imply constant-delay enumeration algorithms in the context of regular spanners. Further, we use an extension of annotated automata which utilizes succinctly encoded annotations to save an exponential factor from previous results that dealt with constant-delay enumeration over vset automata. Lastly, we extend our results in the same fashion Schmid and Schweikardt did to allow complex document editing while maintaining the constant delay guarantee.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.12301v3</guid>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mart\'in Mu\~noz, Cristian Riveros</dc:creator>
    </item>
    <item>
      <title>Online Maximum Independent Set of Hyperrectangles</title>
      <link>https://arxiv.org/abs/2307.13261</link>
      <description>arXiv:2307.13261v2 Announce Type: replace 
Abstract: The maximum independent set problem is a classical NP-hard problem in theoretical computer science. In this work, we study a special case where the family of graphs considered is restricted to intersection graphs of sets of axis-aligned hyperrectangles and the input is provided in an online fashion. We prove results for several adversary models, classes of hyperrectangles, and restrictions on the order of the input. Under the adaptive offline and adaptive online adversary models, we find the optimal online algorithm for unit hypercubes, $\sigma$-bounded hypercubes, unit-volume hyperrectangles, and arbitrary hypercubes, in both non-dominated and arbitrary order. Under the oblivious adversary model, we prove bounds on the competitive ratio of an optimal online algorithm for the same classes of hyperrectangles and input orders, and we find algorithms that are optimal up to constant factors. For input in dominating order, we find the optimal online algorithm for arbitrary hyperrectangles under all adversary models. We conclude by discussing several promising directions for future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.13261v2</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rishi Advani, Abolfazl Asudeh</dc:creator>
    </item>
    <item>
      <title>On the Communication Complexity of Approximate Pattern Matching</title>
      <link>https://arxiv.org/abs/2403.18812</link>
      <description>arXiv:2403.18812v2 Announce Type: replace 
Abstract: The decades-old Pattern Matching with Edits problem, given a length-$n$ string $T$ (the text), a length-$m$ string $P$ (the pattern), and a positive integer $k$ (the threshold), asks to list all fragments of $T$ that are at edit distance at most $k$ from $P$. The one-way communication complexity of this problem is the minimum amount of space needed to encode the answer so that it can be retrieved without accessing the input strings $P$ and $T$.
  The closely related Pattern Matching with Mismatches problem (defined in terms of the Hamming distance instead of the edit distance) is already well understood from the communication complexity perspective: Clifford, Kociumaka, and Porat [SODA 2019] proved that $\Omega(n/m \cdot k \log(m/k))$ bits are necessary and $O(n/m \cdot k\log (m|\Sigma|/k))$ bits are sufficient; the upper bound allows encoding not only the occurrences of $P$ in $T$ with at most $k$ mismatches but also the substitutions needed to make each $k$-mismatch occurrence exact.
  Despite recent improvements in the running time [Charalampopoulos, Kociumaka, and Wellnitz; FOCS 2020 and 2022], the communication complexity of Pattern Matching with Edits remained unexplored, with a lower bound of $\Omega(n/m \cdot k\log(m/k))$ bits and an upper bound of $O(n/m \cdot k^3\log m)$ bits stemming from previous research. In this work, we prove an upper bound of $O(n/m \cdot k \log^2 m)$ bits, thus establishing the optimal communication complexity up to logarithmic factors. We also show that $O(n/m \cdot k \log m \log (m|\Sigma|))$ bits allow encoding, for each $k$-error occurrence of $P$ in $T$, the shortest sequence of edits needed to make the occurrence exact.
  We leverage the techniques behind our new result on the communication complexity to obtain quantum algorithms for Pattern Matching with Edits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18812v2</guid>
      <category>cs.DS</category>
      <category>quant-ph</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomasz Kociumaka, Jakob Nogler, Philip Wellnitz</dc:creator>
    </item>
    <item>
      <title>Semirandom Planted Clique and the Restricted Isometry Property</title>
      <link>https://arxiv.org/abs/2404.14159</link>
      <description>arXiv:2404.14159v2 Announce Type: replace 
Abstract: We give a simple, greedy $O(n^{\omega+0.5})=O(n^{2.872})$-time algorithm to list-decode planted cliques in a semirandom model introduced in [CSV17] (following [FK01]) that succeeds whenever the size of the planted clique is $k\geq O(\sqrt{n} \log^2 n)$. In the model, the edges touching the vertices in the planted $k$-clique are drawn independently with probability $p=1/2$ while the edges not touching the planted clique are chosen by an adversary in response to the random choices. Our result shows that the computational threshold in the semirandom setting is within a $O(\log^2 n)$ factor of the information-theoretic one [Ste17] thus resolving an open question of Steinhardt. This threshold also essentially matches the conjectured computational threshold for the well-studied special case of fully random planted clique.
  All previous algorithms [CSV17, MMT20, BKS23] in this model are based on rather sophisticated rounding algorithms for entropy-constrained semidefinite programming relaxations and their sum-of-squares strengthenings and the best known guarantee is a $n^{O(1/\epsilon)}$-time algorithm to list-decode planted cliques of size $k \geq \tilde{O}(n^{1/2+\epsilon})$. In particular, the guarantee trivializes to quasi-polynomial time if the planted clique is of size $O(\sqrt{n} \operatorname{polylog} n)$. Our algorithm achieves an almost optimal guarantee with a surprisingly simple greedy algorithm.
  The prior state-of-the-art algorithmic result above is based on a reduction to certifying bounds on the size of unbalanced bicliques in random graphs -- closely related to certifying the restricted isometry property (RIP) of certain random matrices and known to be hard in the low-degree polynomial model. Our key idea is a new approach that relies on the truth of -- but not efficient certificates for -- RIP of a new class of matrices built from the input graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14159v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaros{\l}aw B{\l}asiok, Rares-Darius Buhai, Pravesh K. Kothari, David Steurer</dc:creator>
    </item>
    <item>
      <title>Online Matching and Contention Resolution for Edge Arrivals with Vanishing Probabilities</title>
      <link>https://arxiv.org/abs/2406.14506</link>
      <description>arXiv:2406.14506v2 Announce Type: replace 
Abstract: We study the performance of sequential contention resolution and matching algorithms on random graphs with vanishing edge probabilities. When the edges of the graph are processed in an adversarially-chosen order, we derive a new OCRS that is $0.382$-selectable, attaining the "independence benchmark" from the literature under the vanishing edge probabilities assumption. Complementary to this positive result, we show that no OCRS can be more than $0.390$-selectable, significantly improving upon the upper bound of $0.428$ from the literature. We also derive negative results that are specialized to bipartite graphs or subfamilies of OCRS's. Meanwhile, when the edges of the graph are processed in a uniformly random order, we show that the simple greedy contention resolution scheme which accepts all active and feasible edges is $1/2$-selectable. This result is tight due to a known upper bound. Finally, when the algorithm can choose the processing order, we show that a slight tweak to the random order -- give each vertex a random priority and process edges in lexicographic order -- results in a strictly better contention resolution scheme that is $1-\ln(2-1/e)\approx0.510$-selectable. Our positive results also apply to online matching on $1$-uniform random graphs with vanishing (non-identical) edge probabilities, extending and unifying some results from the random graphs literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14506v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>In EC 2024</arxiv:journal_reference>
      <dc:creator>Will Ma, Calum MacRury, Pranav Nuti</dc:creator>
    </item>
    <item>
      <title>Fast and Accurate Algorithms to Calculate Expected Modularity in Probabilistic Networks</title>
      <link>https://arxiv.org/abs/2408.07161</link>
      <description>arXiv:2408.07161v2 Announce Type: replace 
Abstract: Modularity maximization is a widely used community detection technique for deterministic networks. However, little research has been performed to develop efficient modularity calculation algorithms for probabilistic networks. Particularly, it is challenging to efficiently calculate expected modularity when all possible worlds are considered. To address this problem, we propose two algorithms, namely $\mathrm{PWP}^{\mathrm{EMOD}}$ and $\mathrm{APWP}^{\mathrm{EMOD}}$, partitioning the possible worlds based on their modularities to significantly reduce the number of probability calculations. We evaluate the accuracy and time efficiency of our algorithms through comprehensive experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07161v2</guid>
      <category>cs.DS</category>
      <category>cs.SI</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Shen, Matteo Magnani, Christian Rohner, Fiona Skerman</dc:creator>
    </item>
    <item>
      <title>On the Optimal Linear Contraction Order of Tree Tensor Networks, and Beyond</title>
      <link>https://arxiv.org/abs/2209.12332</link>
      <description>arXiv:2209.12332v5 Announce Type: replace-cross 
Abstract: The contraction cost of a tensor network depends on the contraction order. However, the optimal contraction ordering problem is known to be NP-hard. We show that the linear contraction ordering problem for tree tensor networks admits a polynomial-time algorithm, by drawing connections to database join ordering. The result relies on the adjacent sequence interchange property of the contraction cost, which enables a global decision of the contraction order based on local comparisons. Based on that, we specify a modified version of the IKKBZ database join ordering algorithm to find the optimal tree tensor network linear contraction order. Finally, we extend our algorithm as a heuristic to general contraction orders and arbitrary tensor network topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.12332v5</guid>
      <category>quant-ph</category>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/23M161286X</arxiv:DOI>
      <arxiv:journal_reference>SIAM J. Sci. Comput. 46, B647-B668 (2024)</arxiv:journal_reference>
      <dc:creator>Mihail Stoian, Richard Milbradt, Christian B. Mendl</dc:creator>
    </item>
    <item>
      <title>A Bias-Accuracy-Privacy Trilemma for Statistical Estimation</title>
      <link>https://arxiv.org/abs/2301.13334</link>
      <description>arXiv:2301.13334v3 Announce Type: replace-cross 
Abstract: Differential privacy (DP) is a rigorous notion of data privacy, used for private statistics. The canonical algorithm for differentially private mean estimation is to first clip the samples to a bounded range and then add noise to their empirical mean. Clipping controls the sensitivity and, hence, the variance of the noise that we add for privacy. But clipping also introduces statistical bias. This tradeoff is inherent: we prove that no algorithm can simultaneously have low bias, low error, and low privacy loss for arbitrary distributions.
  Additionally, we show that under strong notions of DP (i.e., pure or concentrated DP), unbiased mean estimation is impossible, even if we assume that the data is sampled from a Gaussian. On the positive side, we show that unbiased mean estimation is possible under a more permissive notion of differential privacy (approximate DP) if we assume that the distribution is symmetric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.13334v3</guid>
      <category>math.ST</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gautam Kamath, Argyris Mouzakis, Matthew Regehr, Vikrant Singhal, Thomas Steinke, Jonathan Ullman</dc:creator>
    </item>
    <item>
      <title>Trainability Barriers in Low-Depth QAOA Landscapes</title>
      <link>https://arxiv.org/abs/2402.10188</link>
      <description>arXiv:2402.10188v2 Announce Type: replace-cross 
Abstract: The Quantum Alternating Operator Ansatz (QAOA) is a prominent variational quantum algorithm for solving combinatorial optimization problems. Its effectiveness depends on identifying input parameters that yield high-quality solutions. However, understanding the complexity of training QAOA remains an under-explored area. Previous results have given analytical performance guarantees for a small, fixed number of parameters. At the opposite end of the spectrum, barren plateaus are likely to emerge at $\Omega(n)$ parameters for $n$ qubits. In this work, we study the difficulty of training in the intermediate regime, which is the focus of most current numerical studies and near-term hardware implementations. Through extensive numerical analysis of the quality and quantity of local minima, we argue that QAOA landscapes can exhibit a superpolynomial growth in the number of low-quality local minima even when the number of parameters scales logarithmically with $n$. This means that the common technique of gradient descent from randomly initialized parameters is doomed to fail beyond small $n$, and emphasizes the need for good initial guesses of the optimal parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10188v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3649153.3649204</arxiv:DOI>
      <arxiv:journal_reference>21st ACM International Conference on Computing Frontiers CF'24, pages 199-206, May 2024</arxiv:journal_reference>
      <dc:creator>Joel Rajakumar, John Golden, Andreas B\"artschi, Stephan Eidenbenz</dc:creator>
    </item>
    <item>
      <title>Counting overlapping pairs of strings</title>
      <link>https://arxiv.org/abs/2405.09393</link>
      <description>arXiv:2405.09393v2 Announce Type: replace-cross 
Abstract: A correlation is a binary vector that encodes all possible positions of overlaps of two words, where an overlap for an ordered pair of words (u,v) occurs if a suffix of word u matches a prefix of word v. As multiple pairs can have the same correlation, it is relevant to count how many pairs of words share the same correlation depending on the alphabet size and word length n. We exhibit recurrences to compute the number of such pairs -- which is termed population size -- for any correlation; for this, we exploit a relationship between overlaps of two words and self-overlap of one word. This theorem allows us to compute the number of pairs with a longest overlap of a given length and to show that the expected length of the longest border of two words asymptotically diverges, which solves two open questions raised by Gabric in 2022. Finally, we also provide bounds for the asymptotic of the population ratio of any correlation. Given the importance of word overlaps in areas like word combinatorics, bioinformatics, and digital communication, our results may ease analyses of algorithms for string processing, code design, or genome assembly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09393v2</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eric Rivals, Pengfei Wang</dc:creator>
    </item>
    <item>
      <title>Exponentially Reduced Circuit Depths Using Trotter Error Mitigation</title>
      <link>https://arxiv.org/abs/2408.14385</link>
      <description>arXiv:2408.14385v2 Announce Type: replace-cross 
Abstract: Product formulae are a popular class of digital quantum simulation algorithms due to their conceptual simplicity, low overhead, and performance which often exceeds theoretical expectations. Recently, Richardson extrapolation and polynomial interpolation have been proposed to mitigate the Trotter error incurred by use of these formulae. This work provides an improved, rigorous analysis of these techniques for the task of calculating time-evolved expectation values. We demonstrate that, to achieve error $\epsilon$ in a simulation of time $T$ using a $p^\text{th}$-order product formula with extrapolation, circuits depths of $O\left(T^{1+1/p} \textrm{polylog}(1/\epsilon)\right)$ are sufficient -- an exponential improvement in the precision over product formulae alone. Furthermore, we achieve commutator scaling, improve the complexity with $T$, and do not require fractional implementations of Trotter steps. Our results provide a more accurate characterisation of the algorithmic error mitigation techniques currently proposed to reduce Trotter error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14385v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.str-el</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James D. Watson, Jacob Watkins</dc:creator>
    </item>
    <item>
      <title>Adversary Resilient Learned Bloom Filters</title>
      <link>https://arxiv.org/abs/2409.06556</link>
      <description>arXiv:2409.06556v2 Announce Type: replace-cross 
Abstract: Creating an adversary resilient construction of the Learned Bloom Filter with provable guarantees is an open problem. We define a strong adversarial model for the Learned Bloom Filter. Our adversarial model extends an existing adversarial model designed for the Classical (i.e not ``Learned'') Bloom Filter by prior work and considers computationally bounded adversaries that run in probabilistic polynomial time (PPT). Using our model, we construct an adversary resilient variant of the Learned Bloom Filter called the Downtown Bodega Filter. We show that: if pseudo-random permutations exist, then an Adversary Resilient Learned Bloom Filter may be constructed with $2\lambda$ extra bits of memory and at most one extra pseudo-random permutation in the critical path. We construct a hybrid adversarial model for the case where a fraction of the query workload is chosen by an adversary. We show realistic scenarios where using the Downtown Bodega Filter gives better performance guarantees compared to alternative approaches in this hybrid model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06556v2</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Allison Bishop, Hayder Tirmazi</dc:creator>
    </item>
    <item>
      <title>Gibbs state preparation for commuting Hamiltonian: Mapping to classical Gibbs sampling</title>
      <link>https://arxiv.org/abs/2410.04909</link>
      <description>arXiv:2410.04909v2 Announce Type: replace-cross 
Abstract: Gibbs state preparation, or Gibbs sampling, is a key computational technique extensively used in physics, statistics, and other scientific fields. Recent efforts for designing fast mixing Gibbs samplers for quantum Hamiltonians have largely focused on commuting local Hamiltonians (CLHs), a non-trivial subclass of Hamiltonians which include highly entangled systems such as the Toric code and quantum double model. Most previous Gibbs samplers relied on simulating the Davies generator, which is a Lindbladian associated with the thermalization process in nature.
  Instead of using the Davies generator, we design a different Gibbs sampler for various CLHs by giving a reduction to classical Hamiltonians, in the sense that one can efficiently prepare the Gibbs state for some CLH $H$ on a quantum computer as long as one can efficiently do classical Gibbs sampling for the corresponding classical Hamiltonian $H^{(c)}$. We demonstrate that our Gibbs sampler is able to replicate state-of-the-art results as well as prepare the Gibbs state in regimes which were previously unknown, such as the low temperature region, as long as there exists fast mixing Gibbs samplers for the corresponding classical Hamiltonians. Our reductions are as follows.
  - If $H$ is a 2-local qudit CLH, then $H^{(c)}$ is a 2-local qudit classical Hamiltonian.
  - If $H$ is a 4-local qubit CLH on 2D lattice and there are no classical qubits, then $H^{(c)}$ is a 2-local qudit classical Hamiltonian on a planar graph. As an example, our algorithm can prepare the Gibbs state for the (defected) Toric code at any non-zero temperature in $\mathcal O(n^2)$ time.
  - If $H$ is a 4-local qubit CLH on 2D lattice and there are classical qubits, assuming that quantum terms are uniformly correctable, then $H^{(c)}$ is a constant-local classical Hamiltonian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04909v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yeongwoo Hwang, Jiaqing Jiang</dc:creator>
    </item>
  </channel>
</rss>
