<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Oct 2024 04:00:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Machine Learning-Powered Data Cleaning for LEGEND</title>
      <link>https://arxiv.org/abs/2410.14701</link>
      <description>arXiv:2410.14701v1 Announce Type: new 
Abstract: Neutrinoless double-beta decay ($0\nu\beta\beta$) is a rare nuclear process that, if observed, will provide insight into the nature of neutrinos and help explain the matter-antimatter asymmetry in the universe. The Large Enriched Germanium Experiment for Neutrinoless Double-Beta Decay (LEGEND) will operate in two phases to search for $0\nu\beta\beta$. The first (second) stage will employ 200 (1000) kg of High-Purity Germanium (HPGe) enriched in $^{76}$Ge to achieve a half-life sensitivity of 10$^{27}$ (10$^{28}$) years. In this study, we present a semi-supervised data-driven approach to remove non-physical events captured by HPGe detectors powered by a novel artificial intelligence model. We utilize Affinity Propagation to cluster waveform signals based on their shape and a Support Vector Machine to classify them into different categories. We train, optimize, test our model on data taken from a natural abundance HPGe detector installed in the Full Chain Test experimental stand at the University of North Carolina at Chapel Hill. We demonstrate that our model yields a maximum physics event sacrifice of $0.024 ^{+0.004}_{-0.003} \%$ when performing data cleaning cuts. Our model is being used to accelerate data cleaning development for LEGEND-200.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14701v1</guid>
      <category>physics.data-an</category>
      <category>nucl-ex</category>
      <category>physics.ins-det</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>E. Le\'on, A. Li, M. A. Bahena Schott, B. Bos, M. Busch, J. R. Chapman, G. L. Duran, J. Gruszko, R. Henning, E. L. Martin, J. F. Wilkerson</dc:creator>
    </item>
    <item>
      <title>The Typicality of Regimes Associated with Northern Hemisphere Heatwaves</title>
      <link>https://arxiv.org/abs/2410.12179</link>
      <description>arXiv:2410.12179v1 Announce Type: cross 
Abstract: We study the hemispheric to continental scale regimes that lead to summertime heatwaves in the Northern Hemisphere. By using a powerful data mining methodology - archetype analysis - we identify characteristic spatial patterns consisting of a blocking high pressure systems embedded within a meandering upper atmosphere circulation that is longitudinally modulated by coherent Rossby Wave Packets. Periods when these atmospheric regimes are strongly expressed correspond to large increases in the likelihood of extreme surface temperature. Most strikingly, these regimes are shown to be typical of surface extremes and frequently reoccur. Three well publicised heatwaves are studied in detail - the June-July 2003 western European heatwave, the August 2010 "Russian" heatwave, and the June 2021 "Heatdome" event across western North America, and are shown to be driven by blocking high pressure systems linked to stalled Rossby Wave Packets. We discuss the implications of our work for long-range prediction or early warning, climate model assessment and post-event diagnosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12179v1</guid>
      <category>physics.ao-ph</category>
      <category>physics.data-an</category>
      <category>physics.flu-dyn</category>
      <category>physics.geo-ph</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher C. Chapman, Didier P. Monselesan, James S. Risbey, Abdelwaheb Hannachi, Valerio Lucarini, Richard Matear</dc:creator>
    </item>
    <item>
      <title>Enhancing Precision of Signal Correction in PVES Experiments: The Impact of Bayesian Analysis on the Results of the QWeak and MOLLER Experiments</title>
      <link>https://arxiv.org/abs/2410.14768</link>
      <description>arXiv:2410.14768v1 Announce Type: cross 
Abstract: The precise measurement of parity-violating asymmetries in parity-violating electron scattering experiments is a powerful tool for probing new physics beyond the Standard Model. Achieving the expected precision requires both experimental and post-processing signal corrections. This includes using auxiliary detectors to distinguish the main signal from background signals and implementing post-measurement corrections, such as the Bayesian statistics method, to address uncontrolled factors during the experiments. Asymmetry values in the scattering of electrons off proton targets in QWeak and P2 and off electron targets in MOLLER are influenced by detector array configurations, beam polarization angles, and beam spin variations. The Bayesian framework refines full probabilistic models to account for all necessary factors, thereby extracting asymmetry values and the underlying physics under specified conditions. For the QWeak experiment, a reanalysis of the inelastic asymmetry measurement using the Bayesian method has yielded a closer fit to measured asymmetries, with uncertainties reduced by 40\% compared to the Monte Carlo minimization method. This approach was successfully applied to simulated data for the MOLLER experiment and is predicted to be similarly effective in P2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14768v1</guid>
      <category>hep-ph</category>
      <category>nucl-ex</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elham Gorgannejad, Wouter Deconinck, David S. Armstrong</dc:creator>
    </item>
    <item>
      <title>Martingale drift of Langevin dynamics and classical canonical spin statistics -- II</title>
      <link>https://arxiv.org/abs/2410.14981</link>
      <description>arXiv:2410.14981v1 Announce Type: cross 
Abstract: In the previous paper we have shown analytically that, if the drift function of the d-dimensional Langevin equation is the Langevin function with a properly chosen scale factor, then the evolution of the drift function is a martingale associated with the histories generated by the very Langevin equation. Moreover, we numerically demonstrated that those generated histories from a common initial data become asymptotically ballistic, whose orientations obey the classical canonical spin statistics under the external field corresponding to the initial data. In the present paper we provide with an analytical explanation of the latter numerical finding by introducing a martingale in the spin functional space. In a specific context the present result elucidates a new physical aspect of martingale theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14981v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ken Sekimoto</dc:creator>
    </item>
    <item>
      <title>Latency correction in sparse neuronal spike trains with overlapping global events</title>
      <link>https://arxiv.org/abs/2410.15018</link>
      <description>arXiv:2410.15018v1 Announce Type: cross 
Abstract: Background: In Kreuz et al., J Neurosci Methods 381, 109703 (2022) two methods were proposed that perform latency correction, i.e., optimize the spike time alignment of sparse neuronal spike trains with well defined global spiking events. The first one based on direct shifts is fast but uses only partial latency information, while the other one makes use of the full information but relies on the computationally costly simulated annealing. Both methods reach their limits and can become unreliable when successive global events are not sufficiently separated or even overlap.
  New Method: Here we propose an iterative scheme that combines the advantages of the two original methods by using in each step as much of the latency information as possible and by employing a very fast extrapolation direct shift method instead of the much slower simulated annealing.
  Results: We illustrate the effectiveness and the improved performance, measured in terms of the relative shift error, of the new iterative scheme not only on simulated data with known ground truths but also on single-unit recordings from two medial superior olive neurons of a gerbil.
  Comparison with Existing Method(s): The iterative scheme outperforms the existing approaches on both the simulated and the experimental data. Due to its low computational demands, and in contrast to simulated annealing, it can also be applied to very large datasets.
  Conclusions: The new method generalizes and improves on the original method both in terms of accuracy and speed. Importantly, it is the only method that allows to disentangle global events with overlap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15018v1</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <category>physics.data-an</category>
      <category>physics.med-ph</category>
      <category>stat.AP</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Arturo Mariani, Federico Senocrate, Jason Mikiel-Hunter, David McAlpine, Barbara Beiderbeck, Michael Pecka, Kevin Lin, Thomas Kreuz</dc:creator>
    </item>
    <item>
      <title>Deep Multimodal Representation Learning for Stellar Spectra</title>
      <link>https://arxiv.org/abs/2410.16081</link>
      <description>arXiv:2410.16081v1 Announce Type: cross 
Abstract: Recently, contrastive learning (CL), a technique most prominently used in natural language and computer vision, has been used to train informative representation spaces for galaxy spectra and images in a self-supervised manner. Following this idea, we implement CL for stars in the Milky Way, for which recent astronomical surveys have produced a huge amount of heterogeneous data. Specifically, we investigate Gaia XP coefficients and RVS spectra. Thus, the methods presented in this work lay the foundation for aggregating the knowledge implicitly contained in the multimodal data to enable downstream tasks like cross-modal generation or fused stellar parameter estimation. We find that CL results in a highly structured representation space that exhibits explicit physical meaning. Evaluating Using this representation space to perform cross-modal generation and stellar label regression results in excellent performance with high-quality generated samples as well as accurate and precise label predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16081v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Buck, Christian Schwarz</dc:creator>
    </item>
    <item>
      <title>Detecting and Attributing Change in Climate and Complex Systems: Foundations, Green's Functions, and Nonlinear Fingerprints</title>
      <link>https://arxiv.org/abs/2212.02628</link>
      <description>arXiv:2212.02628v4 Announce Type: replace-cross 
Abstract: Detection and attribution (D&amp;A) studies are cornerstones of climate science, providing crucial evidence for policy decisions. Their goal is to link observed climate change patterns to anthropogenic and natural drivers via the optimal fingerprinting method (OFM). We show that response theory for nonequilibrium systems offers the physical and dynamical basis for OFM, including the concept of causality used for attribution. Our framework clarifies the method's assumptions, advantages, and potential weaknesses. We use our theory to perform D&amp;A for prototypical climate change experiments performed on an energy balance model and on a low-resolution coupled climate model. We also explain the underpinnings of degenerate fingerprinting, which offers early warning indicators for tipping points. Finally, we extend the OFM to the nonlinear response regime. Our analysis shows that OFM has broad applicability across diverse stochastic systems influenced by time-dependent forcings, with potential relevance to ecosystems, quantitative social sciences, and finance, among others.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.02628v4</guid>
      <category>physics.ao-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <category>physics.geo-ph</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valerio Lucarini, Micka\"el Chekroun</dc:creator>
    </item>
    <item>
      <title>Inhomogeneous random graphs with infinite-mean fitness variables</title>
      <link>https://arxiv.org/abs/2212.08462</link>
      <description>arXiv:2212.08462v3 Announce Type: replace-cross 
Abstract: We consider an inhomogeneous Erd\H{o}s-R\'enyi random graph ensemble with exponentially decaying random disconnection probabilities determined by an i.i.d. field of variables with heavy tails and infinite mean associated to the vertices of the graph. This model was recently investigated in the physics literature in Garuccio et al. (2020) as a scale-invariant random graph within the context of network renormalization. From a mathematical perspective, the model fits in the class of scale-free inhomogeneous random graphs whose asymptotic geometrical features have been recently attracting interest. While for this type of graphs several results are known when the underlying vertex variables have finite mean and variance, here instead we consider the case of one-sided stable variables with necessarily infinite mean. To simplify our analysis, we assume that the variables are sampled from a Pareto distribution with parameter $\alpha\in(0,1)$. We start by characterizing the asymptotic distributions of the typical degrees and some related observables. In particular, we show that the degree of a vertex converges in distribution, after proper scaling, to a mixed Poisson law. We then show that correlations among degrees of different vertices are asymptotically non-vanishing, but at the same time a form of asymptotic tail independence is found when looking at the behavior of the joint Laplace transform around zero. Moreover, we present some findings concerning the asymptotic density of wedges and triangles and show a cross-over for the existence of dust (i.e. disconnected vertices).</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.08462v3</guid>
      <category>math.PR</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Avena, Diego Garlaschelli, Rajat Subhra Hazra, Margherita Lalli</dc:creator>
    </item>
    <item>
      <title>Graph Neural Network-Based Track Finding in the LHCb Vertex Detector</title>
      <link>https://arxiv.org/abs/2407.12119</link>
      <description>arXiv:2407.12119v3 Announce Type: replace-cross 
Abstract: The next decade will see an order of magnitude increase in data collected by high-energy physics experiments, driven by the High-Luminosity LHC (HL-LHC). The reconstruction of charged particle trajectories (tracks) has always been a critical part of offline data processing pipelines. The complexity of HL-LHC data will however increasingly mandate track finding in all stages of an experiment's real-time processing. This paper presents a GNN-based track-finding pipeline tailored for the Run 3 LHCb experiment's vertex detector and benchmarks its physics performance and computational cost against existing classical algorithms on GPU architectures. A novelty of our work compared to existing GNN tracking pipelines is batched execution, in which the GPU evaluates the pipeline on hundreds of events in parallel. We evaluate the impact of neural-network quantisation on physics and computational performance, and comment on the outlook for GNN tracking algorithms for other parts of the LHCb track-finding pipeline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12119v3</guid>
      <category>physics.ins-det</category>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anthony Correia, Fotis I. Giasemis, Nabil Garroum, Vladimir Vava Gligorov, Bertrand Granado</dc:creator>
    </item>
  </channel>
</rss>
