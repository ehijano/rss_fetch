<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.BM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.BM</link>
    <description>q-bio.BM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.BM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Feb 2025 05:05:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>CL-MFAP: A Contrastive Learning-Based Multimodal Foundation Model for Molecular Property Prediction and Antibiotic Screening</title>
      <link>https://arxiv.org/abs/2502.11001</link>
      <description>arXiv:2502.11001v1 Announce Type: new 
Abstract: Due to the rise in antimicrobial resistance, identifying novel compounds with antibiotic potential is crucial for combatting this global health issue. However, traditional drug development methods are costly and inefficient. Recognizing the pressing need for more effective solutions, researchers have turned to machine learning techniques to streamline the prediction and development of novel antibiotic compounds. While foundation models have shown promise in antibiotic discovery, current mainstream efforts still fall short of fully leveraging the potential of multimodal molecular data. Recent studies suggest that contrastive learning frameworks utilizing multimodal data exhibit excellent performance in representation learning across various domains. Building upon this, we introduce CL-MFAP, an unsupervised contrastive learning (CL)-based multimodal foundation (MF) model specifically tailored for discovering small molecules with potential antibiotic properties (AP) using three types of molecular data. This model employs 1.6 million bioactive molecules with drug-like properties from the ChEMBL dataset to jointly pretrain three encoders: (1) a transformer-based encoder with rotary position embedding for processing SMILES strings; (2) another transformer-based encoder, incorporating a novel bi-level routing attention mechanism to handle molecular graph representations; and (3) a Morgan fingerprint encoder using a multilayer perceptron, to achieve the contrastive learning purpose. The CL-MFAP outperforms baseline models in antibiotic property prediction by effectively utilizing different molecular modalities and demonstrates superior domain-specific performance when fine-tuned for antibiotic-related property prediction tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11001v1</guid>
      <category>q-bio.BM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gen Zhou, Sugitha Janarthanan, Yutong Lu, Pingzhao Hu</dc:creator>
    </item>
    <item>
      <title>Deep Learning of Proteins with Local and Global Regions of Disorder</title>
      <link>https://arxiv.org/abs/2502.11326</link>
      <description>arXiv:2502.11326v1 Announce Type: new 
Abstract: Although machine learning has transformed protein structure prediction of folded protein ground states with remarkable accuracy, intrinsically disordered proteins and regions (IDPs/IDRs) are defined by diverse and dynamical structural ensembles that are predicted with low confidence by algorithms such as AlphaFold. We present a new machine learning method, IDPForge (Intrinsically Disordered Protein, FOlded and disordered Region GEnerator), that exploits a transformer protein language diffusion model to create all-atom IDP ensembles and IDR disordered ensembles that maintains the folded domains. IDPForge does not require sequence-specific training, back transformations from coarse-grained representations, nor ensemble reweighting, as in general the created IDP/IDR conformational ensembles show good agreement with solution experimental data, and options for biasing with experimental restraints are provided if desired. We envision that IDPForge with these diverse capabilities will facilitate integrative and structural studies for proteins that contain intrinsic disorder.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11326v1</guid>
      <category>q-bio.BM</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oufan Zhang, Zi Hao Liu, Julie D Forman-Kay, Teresa Head-Gordon</dc:creator>
    </item>
    <item>
      <title>ControllableGPT: A Ground-Up Designed Controllable GPT for Molecule Optimization</title>
      <link>https://arxiv.org/abs/2502.10631</link>
      <description>arXiv:2502.10631v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) employ three popular training approaches: Masked Language Models (MLM), Causal Language Models (CLM), and Sequence-to-Sequence Models (seq2seq). However, each approach has its strengths and limitations, and faces challenges in addressing specific tasks that require controllable and bidirectional generation, such as drug optimization. To address this challenge, inspired by the biological processes of growth and evolution, which involve the expansion, shrinking, and mutation of sequences, we introduce ControllableGPT. This initiative represents the first effort to combine the advantages of MLM, CLM, and seq2seq into a single unified, controllable GPT framework. It enables the precise management of specific locations and ranges within a sequence, allowing for expansion, reduction, or mutation over chosen or random lengths, while maintaining the integrity of any specified positions or subsequences. In this work, we designed ControllableGPT for drug optimization from the ground up, which included proposing the Causally Masked Seq2seq (CMS) objective, developing the training corpus, introducing a novel pre-training approach, and devising a unique generation process. We demonstrate the effectiveness and controllability of ControllableGPT by conducting experiments on drug optimization tasks for both viral and cancer benchmarks, surpassing competing baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10631v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuefeng Liu, Songhao Jiang, Bo Li, Rick Stevens</dc:creator>
    </item>
    <item>
      <title>AI-guided transition path sampling of lipid flip-flop and membrane nanoporation</title>
      <link>https://arxiv.org/abs/2502.11894</link>
      <description>arXiv:2502.11894v1 Announce Type: cross 
Abstract: We study lipid translocation ("flip-flop") between the leaflets of a planar lipid bilayer with transition path sampling (TPS). Rare flip-flops compete with biological machineries that actively establish asymmetric lipid compositions. Artificial Intelligence (AI) guided TPS captures flip-flop without biasing the dynamics by initializing molecular dynamics simulations close to the tipping point, i.e., where it is equally likely for a lipid to next go to one or the other leaflet. We train a neural network model on the fly to predict the respective probability, i.e., the "committor" encoding the mechanism of flip-flop. Whereas coarse-grained DMPC lipids "tunnel" through the hydrophobic bilayer, unaided by water, atomistic DMPC lipids instead utilize spontaneously formed water nanopores to traverse to the other side. For longer DSPC lipids, these membrane defects are less stable, with lipid transfer along transient water threads in a locally thinned membrane emerging as a third distinct mechanism. Remarkably, in the high (~660) dimensional feature space of the deep neural networks, the reaction coordinate becomes effectively linear, in line with Cover's theorem and consistent with the idea of dominant reaction tubes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11894v1</guid>
      <category>cond-mat.soft</category>
      <category>q-bio.BM</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matthias Post, Gerhard Hummer</dc:creator>
    </item>
    <item>
      <title>Classifying the Stoichiometry of Virus-like Particles with Interpretable Machine Learning</title>
      <link>https://arxiv.org/abs/2502.12049</link>
      <description>arXiv:2502.12049v1 Announce Type: cross 
Abstract: Virus-like particles (VLPs) are valuable for vaccine development due to their immune-triggering properties. Understanding their stoichiometry, the number of protein subunits to form a VLP, is critical for vaccine optimisation. However, current experimental methods to determine stoichiometry are time-consuming and require highly purified proteins. To efficiently classify stoichiometry classes in proteins, we curate a new dataset and propose an interpretable, data-driven pipeline leveraging linear machine learning models. We also explore the impact of feature encoding on model performance and interpretability, as well as methods to identify key protein sequence features influencing classification. The evaluation of our pipeline demonstrates that it can classify stoichiometry while revealing protein features that possibly influence VLP assembly. The data and code used in this work are publicly available at https://github.com/Shef-AIRE/StoicIML.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12049v1</guid>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayang Zhang, Xianyuan Liu, Wei Wu, Sina Tabakhi, Wenrui Fan, Shuo Zhou, Kang Lan Tee, Tuck Seng Wong, Haiping Lu</dc:creator>
    </item>
  </channel>
</rss>
