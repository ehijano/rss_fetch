<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.TO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.TO</link>
    <description>q-bio.TO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.TO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 May 2025 04:15:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Information-Theoretic Analysis of Brain MRI: Mutual Information and Pixel Intensity Patterns in Tumor vs. Normal Tissues</title>
      <link>https://arxiv.org/abs/2505.02318</link>
      <description>arXiv:2505.02318v1 Announce Type: cross 
Abstract: The application of information theory in medical imaging, particularly in magnetic resonance imaging (MRI), offers powerful quantitative tools for analyzing structural differences in brain tissues. This study utilizes mutual information (MI) and pixel intensity distributions to differentiate between normal and tumor-affected brain MRI images. Mutual information analyses revealed significantly higher MI values in tumor images compared to normal ones, indicating greater internal similarity within tumor images. Pixel intensity analysis further demonstrated distinct distribution patterns between the two groups: tumor images showed pronounced pixel frequency concentrations within a specific intensity range (0.3, 0.4), suggesting predictable structural characteristics. Conversely, normal images exhibited broader, more uniform pixel intensity distributions across most intensity ranges, except for an initial peak observed in both groups. These findings highlight the capability of information-theoretic metrics, such as mutual information and pixel intensity analysis, to effectively distinguish tumor tissue from normal brain structures, providing promising avenues for enhanced diagnostic and analytical methods in neuroimaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02318v1</guid>
      <category>physics.med-ph</category>
      <category>q-bio.TO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mazaher Kabiri, Shahd Qasem Mahd Tarman</dc:creator>
    </item>
    <item>
      <title>Giving Simulated Cells a Voice: Evolving Prompt-to-Intervention Models for Cellular Control</title>
      <link>https://arxiv.org/abs/2505.02766</link>
      <description>arXiv:2505.02766v1 Announce Type: cross 
Abstract: Guiding biological systems toward desired states, such as morphogenetic outcomes, remains a fundamental challenge with far-reaching implications for medicine and synthetic biology. While large language models (LLMs) have enabled natural language as an interface for interpretable control in AI systems, their use as mediators for steering biological or cellular dynamics remains largely unexplored.
  In this work, we present a functional pipeline that translates natural language prompts into spatial vector fields capable of directing simulated cellular collectives. Our approach combines a large language model with an evolvable neural controller (Prompt-to-Intervention, or P2I), optimized via evolutionary strategies to generate behaviors such as clustering or scattering in a simulated 2D environment.
  We demonstrate that even with constrained vocabulary and simplified cell models, evolved P2I networks can successfully align cellular dynamics with user-defined goals expressed in plain language. This work offers a complete loop from language input to simulated bioelectric-like intervention to behavioral output, providing a foundation for future systems capable of natural language-driven cellular control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02766v1</guid>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>cs.RO</category>
      <category>q-bio.TO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nam H. Le, Patrick Erikson, Yanbo Zhang, Michael Levin, Josh Bongard</dc:creator>
    </item>
    <item>
      <title>Beyond the Monitor: Mixed Reality Visualization and AI for Enhanced Digital Pathology Workflow</title>
      <link>https://arxiv.org/abs/2505.02780</link>
      <description>arXiv:2505.02780v1 Announce Type: cross 
Abstract: Pathologists rely on gigapixel whole-slide images (WSIs) to diagnose diseases like cancer, yet current digital pathology tools hinder diagnosis. The immense scale of WSIs, often exceeding 100,000 X 100,000 pixels, clashes with the limited views traditional monitors offer. This mismatch forces constant panning and zooming, increasing pathologist cognitive load, causing diagnostic fatigue, and slowing pathologists' adoption of digital methods. PathVis, our mixed-reality visualization platform for Apple Vision Pro, addresses these challenges. It transforms the pathologist's interaction with data, replacing cumbersome mouse-and-monitor navigation with intuitive exploration using natural hand gestures, eye gaze, and voice commands in an immersive workspace. PathVis integrates AI to enhance diagnosis. An AI-driven search function instantly retrieves and displays the top five similar patient cases side-by-side, improving diagnostic precision and efficiency through rapid comparison. Additionally, a multimodal conversational AI assistant offers real-time image interpretation support and aids collaboration among pathologists across multiple Apple devices. By merging the directness of traditional pathology with advanced mixed-reality visualization and AI, PathVis improves diagnostic workflows, reduces cognitive strain, and makes pathology practice more effective and engaging. The PathVis source code and a demo video are publicly available at: https://github.com/jaiprakash1824/Path_Vis</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02780v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>q-bio.TO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jai Prakash Veerla, Partha Sai Guttikonda, Helen H. Shang, Mohammad Sadegh Nasr, Cesar Torres, Jacob M. Luber</dc:creator>
    </item>
    <item>
      <title>Integrating anatomy and electrophysiology in the healthy human heart: Insights from biventricular statistical shape analysis using universal coordinates</title>
      <link>https://arxiv.org/abs/2501.04504</link>
      <description>arXiv:2501.04504v2 Announce Type: replace 
Abstract: A cardiac digital twin is a virtual replica of a patient-specific heart, mimicking its anatomy and physiology. A crucial step of building a cardiac digital twin is anatomical twinning, where the computational mesh of the digital twin is tailored to the patient-specific cardiac anatomy. In a number of studies, the effect of anatomical variation on clinically relevant functional measurements like electrocardiograms (ECGs) is investigated, using computational simulations. While such a simulation environment provides researchers with a carefully controlled ground truth, the impact of anatomical differences on functional measurements in real-world patients remains understudied. In this study, we develop a biventricular statistical shape model and use it to quantify the effect of biventricular anatomy on ECG-derived and demographic features, providing novel insights for the development of digital twins of cardiac electrophysiology. To this end, a dataset comprising high-resolution cardiac CT scans from 271 healthy individuals, including athletes, is utilized. Furthermore, a novel, universal, ventricular coordinate-based method is developed to establish lightweight shape correspondence. The performance of the shape model is rigorously established, focusing on its dimensionality reduction capabilities and the training data requirements. Additionally, a comprehensive synthetic cohort is made available, featuring ready-to-use biventricular meshes with fiber structures and anatomical region annotations. These meshes are well-suited for electrophysiological simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04504v2</guid>
      <category>q-bio.TO</category>
      <pubDate>Tue, 06 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.compbiomed.2025.110230</arxiv:DOI>
      <arxiv:journal_reference>Computers in Biology and Medicine, 192 (2025), 110230</arxiv:journal_reference>
      <dc:creator>Lore Van Santvliet, Elena Zappon, Matthias A. F. Gsell, Franz Thaler, Maarten Blondeel, Steven Dymarkowski, Guido Claessen, Rik Willems, Martin Urschler, Bert Vandenberk, Gernot Plank, Maarten De Vos</dc:creator>
    </item>
  </channel>
</rss>
