<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Jun 2025 01:43:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Numerical analysis of scattered point measurement-based regularization for backward problems for fractional wave equations</title>
      <link>https://arxiv.org/abs/2506.18948</link>
      <description>arXiv:2506.18948v1 Announce Type: new 
Abstract: In this work, our aim is to reconstruct the unknown initial value from terminal data. We develop a numerical framework on nonuniform time grids for fractional wave equations under the lower regularity assumptions. Then, we introduce a regularization method that effectively handles scattered point measurements contaminated with stochastic noise. The optimal error estimates of stochastic convergence not only balance discretization errors, the noise, and the number of observation points, but also propose an a priori choice of regularization parameters. Finally, several numerical experiments are presented to demonstrate the efficiency and accuracy of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18948v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dakang Cen, Zhiyuan Li, Wenlong Zhang</dc:creator>
    </item>
    <item>
      <title>Modular data assimilation for flow prediction</title>
      <link>https://arxiv.org/abs/2506.19002</link>
      <description>arXiv:2506.19002v1 Announce Type: new 
Abstract: This report develops several modular, 2-step realizations (inspired by Kalman filter algorithms) of nudging-based data assimilation \begin{equation*} \begin{array}{cc} Step{{{\text { }}}}1 &amp; \begin{array}{c} \frac{\widetilde {v}^{n+1}-v^{n}}{k}+v^{n}\cdot \nabla \widetilde {v}% ^{n+1}-\nu \triangle \widetilde {v}^{n+1}+\nabla q^{n+1}=f(x){{{{\text { }}}}% } \\ \nabla \cdot \widetilde {v}^{n+1}=0% \end{array} \\ Step{{{\text { }}}}2 &amp; \frac{v^{n+1}-\widetilde {v}^{n+1}}{k}-\chi I_{H}(u(t^{n+1})-v^{n+1})=0.% \end{array}% \end{equation*} Several variants of this algorithm are developed. Three main results are developed. The first is that if $I_{H}^{2}=I_{H}$, then Step 2 can be rewritten as the explicit step \begin{equation*} v^{n+1}=\widetilde {v}^{n+1}+\frac{k\chi }{1+k\chi }[I_{H}u(t^{n+1})-I_{H}% \widetilde {v}^{n+1}]. \end{equation*} This means Step 2 has the greater stability of an implicit update and the lesser complexity of an explicit analysis step. The second is that the basic result of nudging (that for $H$ \textit{small enough} and $\chi $\ \textit{large enough} predictability horizons are infinite) holds for one variant of the modular algorithm. The third is that, for \textit{any} $H&gt;0$ and \textit{any} $\chi&gt;0$, one step of the modular algorithm decreases the next step's error and \textit{increases} (an estimate of) predictability horizons. A method synthesizing assimilation with eddy viscosity models of turbulence is also presented. Numerical tests are given, confirming the effectiveness of the modular assimilation algorithm. The conclusion is that the modular, 2-step method overcomes many algorithmic inadequacies of standard nudging methods and retains a robust mathematical foundation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19002v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aytekin \c{C}{\i}b{\i}k, Rui Fang, William Layton</dc:creator>
    </item>
    <item>
      <title>Stabilizing PDE--ML Coupled System</title>
      <link>https://arxiv.org/abs/2506.19274</link>
      <description>arXiv:2506.19274v1 Announce Type: new 
Abstract: A long-standing obstacle in the use of machine-learnt surrogates with larger PDE systems is the onset of instabilities when solved numerically. Efforts towards ameliorating these have mostly concentrated on improving the accuracy of the surrogates or imbuing them with additional structure, and have garnered limited success. In this article, we study a prototype problem and draw insights that can help with more complex systems. In particular, we focus on a viscous Burgers'-ML system and, after identifying the cause of the instabilities, prescribe strategies to stabilize the coupled system. To improve the accuracy of the stabilized system, we next explore methods based on the Mori--Zwanzig formalism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19274v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saad Qadeer, Panos Stinis, Hui Wan</dc:creator>
    </item>
    <item>
      <title>Spectral approximation to fractional integral operator</title>
      <link>https://arxiv.org/abs/2506.19332</link>
      <description>arXiv:2506.19332v1 Announce Type: new 
Abstract: We propose a fast and stable method for constructing matrix approximations to fractional integral operators applied to series in the Chebyshev fractional polynomials. This method utilizes a recurrence relation satisfied by the fractional integrals of mapped Chebyshev polynomials and significantly outperforms existing methods. Through numerical examples, we highlight the broad applicability of these matrix approximations, including the solution of boundary value problems for fractional integral and differential equations. Additional applications include fractional differential equation initial value problems and fractional eigenvalue problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19332v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaolin Liu, Kuan Xu</dc:creator>
    </item>
    <item>
      <title>A High-Order Compact Hermite Difference Method for Double-Diffusive Convection</title>
      <link>https://arxiv.org/abs/2506.19367</link>
      <description>arXiv:2506.19367v1 Announce Type: new 
Abstract: In this paper, a class of high-order compact finite difference Hermite scheme is presented for the simulation of double-diffusive convection. To maintain linear stability, the convective fluxes are split into positive and negative parts, then the compact Hermite difference methods are used to discretize the positive and negative fluxes, respectively. The diffusion fluxes of the governing equations are directly approximated by a high-order finite difference scheme based on the Hermite interpolation. The advantages of the proposed schemes are that the derivative values of the solutions are directly solved by the compact central difference scheme, and the auxiliary derivative equation is no longer required. The third-order Runge-Kutta method is utilized for the temporal discretization. Several numerical tests are presented to assess the numerical capability of the newly proposed algorithm. The numerical results are in great agreement with the benchmark solutions and some of the accurate results available in the literature. Subsequently, we apply the algorithm to solve steady and unsteady problems of double-diffusive convection and a preliminary application to the double-diffusive convection for different Raleigh numbers and aspect ratios is carried out.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19367v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jianqing Yang, Jianxian Qiu</dc:creator>
    </item>
    <item>
      <title>General-domain FC-based shock-dynamics solver II: Non-smooth domains, accuracy and parallel performance</title>
      <link>https://arxiv.org/abs/2506.19370</link>
      <description>arXiv:2506.19370v1 Announce Type: new 
Abstract: This contribution Part II of a two-part series, extends the general-domain FC-SDNN (Fourier Continuation Shock-Detecting Neural Network) introduces in Part I to enable treatment of non-smooth domains, it introduces a parallel implementation of the scheme with high-quality weak and strong scalability properties, and it illustrates the overall methodology for a variety of tests for the 2D Euler equations--including supersonic and hypersonic flows and shocks past obstacles with corners. The results produces by the new methods are compared to previous theoretical and experimental results, and the high parallel scalability of the algorithm is demonstrated in both weak and strong scaling cases. Thanks to its use of a localized yet smooth artificial viscosity term--whose support is confined to regions near flow discontinuities identified by an artificial neural network--the algorithm maintains minimal numerical dissipation away from discontinuities. Overall, the method delivers accurate, sharp resolution of shocks and contact discontinuities, while producing smooth numerical solutions in regular flow regions--as evidences by the near-complete absence of spurious oscillations in level-set contours, even under strong shocks and high-speed flow conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19370v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel V. Leibovici, Oscar P. Bruno</dc:creator>
    </item>
    <item>
      <title>Towards automated generation of fast and accurate algorithms for recursive matrix multiplication</title>
      <link>https://arxiv.org/abs/2506.19405</link>
      <description>arXiv:2506.19405v1 Announce Type: new 
Abstract: We propose a strategy for the generation of fast and accurate versions of non-commutative recursive matrix multiplication algorithms. To generate these algorithms, we consider matrix and tensor norm bounds governing the stability and accuracy of numerical matrix multiplication. We start by a unification on known max-norm bounds on matrix multiplication stability and then extend them to further norms and more generally to recursive bilinear algorithms and the alternative basis matrix multiplication algorithms. Then our strategy has three phases. First, we reduce those bounds by minimizing a growth factor along the orbits of the associated matrix multiplication tensor decomposition. Second, we develop heuristics that minimize the number of operations required to realize a bilinear formula, while further improving its accuracy. Third, we perform an alternative basis sparsification that improves on the time complexity constant and mostly preserves the overall accuracy. For instance this strategy allows us to propose a non-commutative algorithm for multiplying 2x2-matrices using 7 coefficient products. This algorithm reaches simultaneously a better accuracy in practice compared to previously known such fast ___2x2x2:7___ Strassen-like algorithms and a time complexity bound with the best currently known leading term (obtained via alternative basis sparsification). We also present detailed results of our technique on other recursive matrix multiplication algorithms, such as Smirnov's ___3x3x6:40___ family of algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19405v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SC</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Guillaume Dumas (CASC), Cl\'ement Pernet (CASC), Alexandre Sedoglavic (CRIStAL)</dc:creator>
    </item>
    <item>
      <title>Sharp numerical approximation of the Hardy constant</title>
      <link>https://arxiv.org/abs/2506.19422</link>
      <description>arXiv:2506.19422v1 Announce Type: new 
Abstract: We study the $P_1$ finite element approximation of the best constant in the classical Hardy inequality over bounded domains containing the origin in $\mathbb{R}^N$, for $N \geq 3$.
  Despite the fact that this constant is not attained in the associated Sobolev space $H^1$, our main result establishes an explicit, sharp, and dimension-independent rate of convergence proportional to $1/|\log h|^2$.
  The analysis carefully combines an improved Hardy inequality involving a reminder term with logarithmic weights, approximation estimates for Hardy-type singular radial functions constituting minimizing sequences, properties of piecewise linear and continuous finite elements, and weighted Sobolev space techniques.
  We also consider other closely related spectral problems involving the Laplacian with singular quadratic potentials obtaining sharp convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19422v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liviu I. Ignat, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>A Generalized Framework for Higher-Order Localized Orthogonal Decomposition Methods</title>
      <link>https://arxiv.org/abs/2506.19462</link>
      <description>arXiv:2506.19462v1 Announce Type: new 
Abstract: We introduce a generalized framework for studying higher-order versions of the multiscale method known as Localized Orthogonal Decomposition. Through a suitable reformulation, we are able to accommodate both conforming and nonconforming constraints in the construction process. In particular, we offer a new perspective on localization strategies. We fully analyze the strategy for linear elliptic problems and discuss extensions to the Helmholtz equation and the Gross--Pitaevskii eigenvalue problem. Numerical examples are presented that particularly provide valuable comparisons between conforming and nonconforming constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19462v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Moritz Hauck, Alexei Lozinski, Roland Maier</dc:creator>
    </item>
    <item>
      <title>Anisotropic approximation on space-time domains</title>
      <link>https://arxiv.org/abs/2506.19517</link>
      <description>arXiv:2506.19517v1 Announce Type: new 
Abstract: We investigate anisotropic (piecewise) polynomial approximation of functions in Lebesgue spaces as well as anisotropic Besov spaces. For this purpose we study temporal and spacial moduli of smoothness and their properties. In particular, we prove Jackson- and Whitney-type inequalities on Lipschitz cylinders, i.e., space-time domains $I\times D$ with a finite interval $I$ and a bounded Lipschitz domain $D\subset \R^d$, $d\in \N$. As an application, we prove a direct estimate result for adaptive space-time finite element approximation in the discontinuous setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19517v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro Morin, Cornelia Schneider, Nick Schneider</dc:creator>
    </item>
    <item>
      <title>Sparse and low-rank approximations of parametric elliptic PDEs: the best of both worlds</title>
      <link>https://arxiv.org/abs/2506.19584</link>
      <description>arXiv:2506.19584v1 Announce Type: new 
Abstract: A new approximation format for solutions of partial differential equations depending on infinitely many parameters is introduced. By combining low-rank tensor approximation in a selected subset of variables with a sparse polynomial expansion in the remaining parametric variables, it addresses in particular classes of elliptic problems where a direct polynomial expansion is inefficient, such as those arising from random diffusion coefficients with short correlation length. A convergent adaptive solver is proposed and analyzed that maintains quasi-optimal ranks of approximations and at the same time yields optimal convergence rates of spatial discretizations without coarsening. The results are illustrated by numerical tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19584v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Markus Bachmayr, Huqing Yang</dc:creator>
    </item>
    <item>
      <title>Hybrid high-order approximations of div-curl systems on domains with general topology</title>
      <link>https://arxiv.org/abs/2506.19616</link>
      <description>arXiv:2506.19616v1 Announce Type: new 
Abstract: We devise and analyze hybrid polyhedral methods of arbitrary order for the approximation of div-curl systems on three-dimensional domains featuring non-trivial topology. The div-curl systems we are interested in stem from magnetostatics, and can either be first-order (field formulation) or second-order (vector potential formulation). The well-posedness of the resulting discrete problems essentially hinges on recently established, topologically generic, hybrid versions of the (first and second) Weber inequalities. Our error analysis covers the case of regular solutions. Leveraging (co)homology computation techniques from the literature, we perform an in-depth numerical assessment of our approach, covering, in particular, the case of non-simply-connected domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19616v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J\'er\'emy Dalphin, Jean-Pierre Ducreux, Simon Lemaire, Silvano Pitassi</dc:creator>
    </item>
    <item>
      <title>Fast Flexible LSQR with a Hybrid Variant for Efficient Large-Scale Regularization</title>
      <link>https://arxiv.org/abs/2506.19666</link>
      <description>arXiv:2506.19666v1 Announce Type: new 
Abstract: A wide range of applications necessitates solving large-scale ill-posed problems contaminated by noise. Krylov subspace regularization methods are particularly advantageous in this context, as they rely solely on matrix-vector multiplication. Among the most widely used techniques are LSQR and CGLS, both of which can be extended with flexible preconditioning to enforce solution properties such as nonnegativity or sparsity. Flexible LSQR (FLSQR) can also be further combined with direct methods to create efficient hybrid approaches. The Flexible Golub-Kahan bidiagonalization underlying FLSQR requires two long-term recurrences. In this paper, we introduce a novel Fast Flexible Golub-Kahan bidiagonalization method that employs one long-term and one short-term recurrence. Using this, we develop the Fast Flexible LSQR (FaFLSQR) algorithm, which offers comparable computational cost to FCGLS while also supporting hybrid regularization like FLSQR. We analyze the properties of FaFLSQR and prove its mathematical equivalence to FCGLS. Numerical experiments demonstrate that in floating point arithmetic FaFLSQR outperforms both FCGLS and FLSQR in terms of computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19666v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eva Miku\v{s}ov\'a, Iveta Hn\v{e}tynkov\'a</dc:creator>
    </item>
    <item>
      <title>Krylov and core transformation algorithms for an inverse eigenvalue problem to compute recurrences of multiple orthogonal polynomials</title>
      <link>https://arxiv.org/abs/2506.19796</link>
      <description>arXiv:2506.19796v1 Announce Type: new 
Abstract: In this paper, we develop algorithms for computing the recurrence coefficients corresponding to multiple orthogonal polynomials on the step-line. We reformulate the problem as an inverse eigenvalue problem, which can be solved using numerical linear algebra techniques. We consider two approaches: the first is based on the link with block Krylov subspaces and results in a biorthogonal Lanczos process with multiple starting vectors; the second consists of applying a sequence of Gaussian eliminations on a diagonal matrix to construct the banded Hessenberg matrix containing the recurrence coefficients. We analyze the accuracy and stability of the algorithms with numerical experiments on the ill-conditioned inverse eigenvalue problemshave related to Kravchuk and Hahn polynomials, as well as on other better conditioned examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19796v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Amin Faghih, Michele Rinelli, Marc Van Barel, Raf Vandebril, Robbe Vermeiren</dc:creator>
    </item>
    <item>
      <title>Asymptotic analysis and design of linear elastic shell lattice metamaterials</title>
      <link>https://arxiv.org/abs/2506.18910</link>
      <description>arXiv:2506.18910v1 Announce Type: cross 
Abstract: We present an asymptotic analysis of shell lattice metamaterials based on Ciarlet's shell theory, introducing a new metric--asymptotic directional stiffness (ADS)--to quantify how the geometry of the middle surface governs the effective stiffness. We prove a convergence theorem that rigorously characterizes ADS and establishes its upper bound, along with necessary and sufficient condition for achieving it. As a key result, our theory provides the first rigorous explanation for the high bulk modulus observed in Triply Periodic Minimal Surfaces (TPMS)-based shell lattices. To optimize ADS on general periodic surfaces, we propose a triangular-mesh-based discretization and shape optimization framework. Numerical experiments validate the theoretical findings and demonstrate the effectiveness of the optimization under various design objectives. Our implementation is available at https://github.com/lavenklau/minisurf.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18910v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Di Zhang, Ligang Liu</dc:creator>
    </item>
    <item>
      <title>On the algorithmic construction of deep ReLU networks</title>
      <link>https://arxiv.org/abs/2506.19104</link>
      <description>arXiv:2506.19104v1 Announce Type: cross 
Abstract: It is difficult to describe in mathematical terms what a neural network trained on data represents. On the other hand, there is a growing mathematical understanding of what neural networks are in principle capable of representing. Feedforward neural networks using the ReLU activation function represent continuous and piecewise linear functions and can approximate many others. The study of their expressivity addresses the question: which ones? Contributing to the available answers, we take the perspective of a neural network as an algorithm. In this analogy, a neural network is programmed constructively, rather than trained from data. An interesting example is a sorting algorithm: we explicitly construct a neural network that sorts its inputs exactly, not approximately, and that, in a sense, has optimal computational complexity if the input dimension is large. Such constructed networks may have several billion parameters. We construct and analyze several other examples, both existing and new. We find that, in these examples, neural networks as algorithms are typically recursive and parallel. Compared to conventional algorithms, ReLU networks are restricted by having to be continuous. Moreover, the depth of recursion is limited by the depth of the network, with deep networks having superior properties over shallow ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19104v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daan Huybrechs</dc:creator>
    </item>
    <item>
      <title>High precision PINNs in unbounded domains: application to singularity formulation in PDEs</title>
      <link>https://arxiv.org/abs/2506.19243</link>
      <description>arXiv:2506.19243v1 Announce Type: cross 
Abstract: We investigate the high-precision training of Physics-Informed Neural Networks (PINNs) in unbounded domains, with a special focus on applications to singularity formulation in PDEs. We propose a modularized approach and study the choices of neural network ansatz, sampling strategy, and optimization algorithm. When combined with rigorous computer-assisted proofs and PDE analysis, the numerical solutions identified by PINNs, provided they are of high precision, can serve as a powerful tool for studying singularities in PDEs. For 1D Burgers equation, our framework can lead to a solution with very high precision, and for the 2D Boussinesq equation, which is directly related to the singularity formulation in 3D Euler and Navier-Stokes equations, we obtain a solution whose loss is $4$ digits smaller than that obtained in \cite{wang2023asymptotic} with fewer training steps. We also discuss potential directions for pushing towards machine precision for higher-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19243v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yixuan Wang, Ziming Liu, Zongyi Li, Anima Anandkumar, Thomas Y. Hou</dc:creator>
    </item>
    <item>
      <title>From kinetic mixtures to compressible two-phase flow: A BGK-type model and rigorous derivation</title>
      <link>https://arxiv.org/abs/2506.19321</link>
      <description>arXiv:2506.19321v1 Announce Type: cross 
Abstract: We propose a BGK-type kinetic model for a binary gas mixture, designed to serve as a kinetic formulation of compressible two-phase fluid dynamics. The model features species-dependent adiabatic exponents, and the relaxation operator is constructed by solving an entropy minimization problem under moments constraints. Starting from this model, we derive the compressible two-phase Euler equations via a formal Chapman--Enskog expansion and identify dissipative corrections of Navier--Stokes type. We then rigorously justify the Euler limit using the relative entropy method, establishing quantitative convergence estimates under appropriate regularity assumptions. Finally, we present numerical experiments based on an implicit-explicit Runge--Kutta method, which confirm the asymptotic preserving property and demonstrate the convergence from the BGK model to the isentropic two-phase Euler system in the hydrodynamic regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19321v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seung Yeon Cho, Young-Pil Choi, Byung-Hoon Hwang, Sihyun Song</dc:creator>
    </item>
    <item>
      <title>Time-Sensitive Importance Splitting</title>
      <link>https://arxiv.org/abs/2506.19568</link>
      <description>arXiv:2506.19568v1 Announce Type: cross 
Abstract: State-of-the-art methods for rare event simulation of non-Markovian models face practical or theoretical limits if observing the event of interest requires prior knowledge or information on the timed behavior of the system. In this paper, we attack both limits by extending importance splitting with a time-sensitive importance function. To this end, we perform backwards reachability search from the target states, considering information about the lower and upper bounds of the active timers in order to steer the generation of paths towards the rare event. We have developed a prototype implementation of the approach for input/output stochastic automata within the Modest Toolset. Preliminary experiments show the potential of the approach in estimating rare event probabilities for an example from reliability engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19568v1</guid>
      <category>cs.LO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Gabriel Dengler, Carlos E. Budde, Laura Carnevali, Arnd Hartmanns</dc:creator>
    </item>
    <item>
      <title>Numerical solution of quantum Landau-Lifshitz-Gilbert equation</title>
      <link>https://arxiv.org/abs/2506.19594</link>
      <description>arXiv:2506.19594v1 Announce Type: cross 
Abstract: The classical Landau-Lifshitz-Gilbert (LLG) equation has long served as a cornerstone for modeling magnetization dynamics in magnetic systems, yet its classical nature limits its applicability to inherently quantum phenomena such as entanglement and nonlocal correlations. Inspired by the need to incorporate quantum effects into spin dynamics, recently a quantum generalization of the LLG equation is proposed [Phys. Rev. Lett. 133, 266704 (2024)] which captures essential quantum behavior in many-body systems. In this work, we develop a robust numerical methodology tailored to this quantum LLG framework that not only handles the complexity of quantum many-body systems but also preserves the intrinsic mathematical structures and physical properties dictated by the equation. We apply the proposed method to a class of many-body quantum spin systems, which host topological states of matter, and demonstrate rich quantum behavior, including the emergence of long-time entangled states. This approach opens a pathway toward reliable simulations of quantum magnetism beyond classical approximations, potentially leading to new discoveries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19594v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vahid Azimi-Mousolou, Davoud Mirzaei</dc:creator>
    </item>
    <item>
      <title>Deep neural networks with ReLU, leaky ReLU, and softplus activation provably overcome the curse of dimensionality for Kolmogorov partial differential equations with Lipschitz nonlinearities in the $L^p$-sense</title>
      <link>https://arxiv.org/abs/2309.13722</link>
      <description>arXiv:2309.13722v2 Announce Type: replace 
Abstract: Recently, several deep learning (DL) methods for approximating high-dimensional partial differential equations (PDEs) have been proposed. The interest that these methods have generated in the literature is in large part due to simulations which appear to demonstrate that such DL methods have the capacity to overcome the curse of dimensionality (COD) for PDEs in the sense that the number of computational operations they require to achieve a certain approximation accuracy $\varepsilon\in(0,\infty)$ grows at most polynomially in the PDE dimension $d\in\mathbb N$ and the reciprocal of $\varepsilon$. While there is thus far no mathematical result that proves that one of such methods is indeed capable of overcoming the COD, there are now a number of rigorous results in the literature that show that deep neural networks (DNNs) have the expressive power to approximate PDE solutions without the COD in the sense that the number of parameters used to describe the approximating DNN grows at most polynomially in both the PDE dimension $d\in\mathbb N$ and the reciprocal of the approximation accuracy $\varepsilon&gt;0$. Roughly speaking, in the literature it is has been proved for every $T&gt;0$ that solutions $u_d\colon [0,T]\times\mathbb R^d\to \mathbb R$, $d\in\mathbb N$, of semilinear heat PDEs with Lipschitz continuous nonlinearities can be approximated by DNNs with ReLU activation at the terminal time in the $L^2$-sense without the COD provided that the initial value functions $\mathbb R^d\ni x\mapsto u_d(0,x)\in\mathbb R$, $d\in\mathbb N$, can be approximated by ReLU DNNs without the COD. It is the key contribution of this work to generalize this result by establishing this statement in the $L^p$-sense with $p\in(0,\infty)$ and by allowing the activation function to be more general covering the ReLU, the leaky ReLU, and the softplus activation functions as special cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.13722v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Ackermann, Arnulf Jentzen, Thomas Kruse, Benno Kuckuck, Joshua Lee Padgett</dc:creator>
    </item>
    <item>
      <title>High-order adaptive multi-domain time integration scheme for microscale lithium-ion batteries simulations</title>
      <link>https://arxiv.org/abs/2310.06573</link>
      <description>arXiv:2310.06573v3 Announce Type: replace 
Abstract: We investigate the modeling and simulation of ionic transport and charge conservation in lithium-ion batteries (LIBs) at the microscale. It is a multiphysics problem that involves a wide range of time scales. The associated computational challenges motivate the investigation of numerical techniques that can decouple the time integration of the governing equations in the liquid electrolyte and the solid phase (active materials and current collectors). First, it is shown that semi-discretization in space of the non-dimensionalized governing equations leads to a system of index-1 semi-explicit differential algebraic equations (DAEs). Then, a new generation of strategies for multi-domain integration is presented, enabling high-order adaptive coupling of both domains in time, with efficient and potentially different domain integrators. They reach a high level of flexibility for real applications, beyond the limitations of multirate methods. A simple 1D LIB half-cell code is implemented as a demonstrator of the new strategy for the simulation of different modes of cell operation. The integration of the decoupled subsystems is performed with high-order accurate implicit nonlinear solvers. The accuracy of the space discretization is assessed by comparing the numerical results to the analytical solutions. Then, temporal convergence studies demonstrate the accuracy of the new multi-domain coupling approach. Finally, the accuracy and computational efficiency of the adaptive coupling strategy are discussed in the light of the conditioning of the decoupled subproblems compared to the one of the fully-coupled problem. This new approach will constitute a key ingredient for the high-fidelity 3D LIB simulations based on actual electrode microstructures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06573v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Asad (CMAP,), Romain de Loubens (Total Energies One Tech), Laurent Fran\c{c}ois (CMAP), Marc Massot (CMAP)</dc:creator>
    </item>
    <item>
      <title>$L_2$-approximation using median lattice algorithms</title>
      <link>https://arxiv.org/abs/2501.15331</link>
      <description>arXiv:2501.15331v2 Announce Type: replace 
Abstract: In this paper, we study the problem of multivariate $L_2$-approximation of functions belonging to a weighted Korobov space. We propose and analyze a median lattice-based algorithm, inspired by median integration rules, which have attracted significant attention in the theory of quasi-Monte Carlo methods. Our algorithm approximates the Fourier coefficients associated with a suitably chosen frequency index set, where each coefficient is estimated by taking the median over approximations from randomly shifted rank-1 lattice rules with independently chosen generating vectors. We prove that the algorithm achieves, with high probability, a convergence rate of the $L_2$-approximation error that is arbitrarily close to optimal with respect to the number of function evaluations. Furthermore, we show that the error bound depends only polynomially on the dimension, or is even independent of the dimension, under certain summability conditions on the weights. Numerical experiments illustrate the performance of the proposed median lattice-based algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15331v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zexin Pan, Peter Kritzer, Takashi Goda</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of decoupled mixed FEM for the Cahn-Hilliard-Navier-Stokes equations</title>
      <link>https://arxiv.org/abs/2502.14559</link>
      <description>arXiv:2502.14559v2 Announce Type: replace 
Abstract: We develop a decoupled, first-order, fully discrete, energy-stable scheme for the Cahn-Hilliard-Navier-Stokes equations. This scheme calculates the Cahn-Hilliard and Navier-Stokes equations separately, thus effectively decoupling the entire system. To further separate the velocity and pressure components in the Navier-Stokes equations, we use the pressure-correction projection method. We demonstrate that the scheme is primitively energy stable and prove the optimal $L^2$ error estimate of the fully discrete scheme in the $P_r\times P_r\times P_r\times P_{r-1}$ finite element spaces, where the phase field, chemical potential, velocity and pressure satisfy the first-order accuracy in time and the $\left(r+1,r+1,r+1,r\right)th$-order accuracy in space, respectively. Furthermore, numerical experiments are conducted to support these theoretical findings. Notably, compared to other numerical schemes, our algorithm is more time-efficient and numerically shown to be unconditionally stable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14559v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haijun Gao, Xi Li, Minfu Feng</dc:creator>
    </item>
    <item>
      <title>Quasi-Monte Carlo for Bayesian shape inversion governed by the Poisson problem subject to Gevrey regular domain deformations</title>
      <link>https://arxiv.org/abs/2502.14661</link>
      <description>arXiv:2502.14661v2 Announce Type: replace 
Abstract: We consider the application of a quasi-Monte Carlo cubature rule to Bayesian shape inversion subject to the Poisson equation under Gevrey regular parameterizations of domain uncertainty. We analyze the parametric regularity of the associated posterior distribution and design randomly shifted rank-1 lattice rules which can be shown to achieve dimension-independent, faster-than-Monte Carlo cubature convergence rates for high-dimensional integrals over the posterior distribution. In addition, we consider the effect of dimension truncation and finite element discretization errors for this model. Finally, a series of numerical experiments are presented to validate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14661v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ana Djurdjevac, Vesa Kaarnioja, Max Orteu, Claudia Schillings</dc:creator>
    </item>
    <item>
      <title>Construction of exact refinements for the two-dimensional hierarchical B-spline de Rham complex</title>
      <link>https://arxiv.org/abs/2502.19542</link>
      <description>arXiv:2502.19542v3 Announce Type: replace 
Abstract: The de Rham complex arises naturally when studying problems in electromagnetism and fluid mechanics. Stable numerical methods to solve these problems can be obtained by using a discrete de Rham complex that preserves the structure of the continuous one. This property is not necessarily guaranteed when the discrete function spaces are hierarchical B-splines, and research shows that an arbitrary choice of refinement domains may give rise to spurious harmonic fields that ruin the accuracy of the solution. We will focus on the two-dimensional de Rham complex over the unit square $\Omega \subseteq \mathbb{R}^2$, and provide theoretical results and a constructive algorithm to ensure that the structure of the complex is preserved: when a pair of functions are in conflict some additional functions, forming an L-chain between the pair, are also refined. Another crucial aspect to consider in the hierarchical setting is the notion of admissibility, as it is possible to obtain optimal convergence rates of numerical solutions and improved stability by limiting the multi-level interaction of basis functions. We show that, under a common restriction, the admissibility class of the first space of the discrete complex persists throughout the remaining spaces. Moreover, admissible refinement can be combined with our new algorithm to obtain admissible meshes that also respect the structure of the de Rham complex. Finally, we include numerical results that motivate the importance of the previous concerns for the vector Laplace and Maxwell eigenvalue problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19542v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diogo C. Cabanas, Kendrick M. Shepherd, Deepesh Toshniwal, Rafael V\'azquez</dc:creator>
    </item>
    <item>
      <title>The Whitney method of fundamental solutions with Lusin wavelets</title>
      <link>https://arxiv.org/abs/2504.09458</link>
      <description>arXiv:2504.09458v3 Announce Type: replace 
Abstract: We establish the theoretical foundation for a variant of the method of fundamental solutions (MFS), where the source points $\{q_j\}_{j=1}^\infty$ accumulate towards the domain in a Whitney fashion, meaning that their separation is proportional to the distance to the domain. We prove that the normalized Lusin wavelets $\psi_j(w) = b_j(w-q_j)^{-2}$ constitute a generalized basis, known as a frame, for the Hardy subspace of $L_2$-traces of holomorphic functions on the domain. Consequently, our method, where $\psi_j$ are used as basis functions in the MFS, enables a numerically stable approximation of solutions to Laplace boundary value problems, even when the solutions lack analytic continuation across the boundary. Despite the source points accumulating towards the domain, our computations achieve at least 12 digits of accuracy uniformly up to the boundary, including cases when the solution lacks analytic continuation or when the boundary has corners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09458v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.CA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jakob Jonsson, Andreas Ros\'en, Emil Timlin</dc:creator>
    </item>
    <item>
      <title>A hybrid high-order method for the biharmonic problem</title>
      <link>https://arxiv.org/abs/2504.16608</link>
      <description>arXiv:2504.16608v2 Announce Type: replace 
Abstract: This paper proposes a new hybrid high-order discretization for the biharmonic problem and the corresponding eigenvalue problem. The discrete ansatz space includes degrees of freedom in $n-2$ dimensional submanifolds (e.g., nodal values in 2D and edge values in 3D), in addition to the typical degrees of freedom in the mesh and on the hyperfaces in the HHO literature. This approach enables the characteristic commuting property of the hybrid high-order methodology in any space dimension and allows for lower eigenvalue bounds of higher order for the eigenvalue problem. The main results are quasi-best approximation estimates as well as reliable and efficient error control. The latter motivates an adaptive mesh-refining algorithm that empirically recovers optimal convergence rates for singular solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16608v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yizhou Liang, Ngoc Tien Tran</dc:creator>
    </item>
    <item>
      <title>Geometric flow regularization in latent spaces for smooth dynamics with the efficient variations of curvature</title>
      <link>https://arxiv.org/abs/2506.09679</link>
      <description>arXiv:2506.09679v2 Announce Type: replace 
Abstract: We design strategies in nonlinear geometric analysis to temper the effects of adversarial learning for sufficiently smooth data of numerical method-type dynamics in encoder-decoder methods, variational and deterministic, through the use of geometric flow regularization. We augment latent spaces with geometric flows to control structure. Our techniques rely on adaptations of curvature and Ricci flow. We invent new geometric flows or discover them neurally and non-parametrically. All of our flows are solved using physics-informed learning. Traditional geometric meaning is traded for computing ability, but we maintain key geometric invariants, the primary of which are maintained, intrinsically-low structure, canonicity or a lack of irregularity, nontriviality due to sufficient lower bounds on curvature, and distortion of volume element, that develop quality in the inference stage. Our primary contributions are fourfold. We develop a loss based on Gaussian curvature using closed path circulation integration for surfaces, bypassing automatic differentiation of the Christoffel symbols through use of Stokes' theorem. We invent a new parametric flow derived from a linear version of the Gauss equation and a Riemannian decomposition for a custom tensor defined with a normal Hessian and Weyl tensor proxies. We develop two strategies based on time differentiation of functionals, one with a special case of scalar curvature for conformally-changed metrics, and another with harmonic maps, their energy, and induced metrics. Our methods, while diminished analytically, maintain overall integral latent structure. We showcase that curvature flows and the formulation of geometric structure in intermediary encoded settings enhance learning and overall zero-shot and adversarial fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09679v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Gracyk</dc:creator>
    </item>
    <item>
      <title>Simultaneous recovery of a corroded boundary and admittance using the Kohn-Vogelius method</title>
      <link>https://arxiv.org/abs/2506.17938</link>
      <description>arXiv:2506.17938v2 Announce Type: replace 
Abstract: We address the problem of identifying an unknown portion $\Gamma$ of the boundary of a $d$-dimensional ($d \in \{1, 2\}$) domain $\Omega$ and its associated Robin admittance coefficient, using two sets of boundary Cauchy data $(f, g)$--representing boundary temperature and heat flux--measured on the accessible portion $\Sigma$ of the boundary. Identifiability results \cite{Bacchelli2009,PaganiPierotti2009} indicate that a single measurement on $\Sigma$ is insufficient to uniquely determine both $\Gamma$ and $\alpha$, but two independent inputs yielding distinct solutions ensure the uniqueness of the pair $\Gamma$ and $\alpha$. In this paper, we propose a cost function based on the energy-gap of two auxiliary problems. We derive the variational derivatives of this objective functional with respect to both the Robin boundary $\Gamma$ and the admittance coefficient $\alpha$. These derivatives are utilized to develop a nonlinear gradient-based iterative scheme for the simultaneous numerical reconstruction of $\Gamma$ and $\alpha$. Numerical experiments are presented to demonstrate the effectiveness and practicality of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17938v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moustapha Essahraoui, Elmehdi Cherrat, Lekbir Afraites, Julius Fergy Tiongson Rabago</dc:creator>
    </item>
    <item>
      <title>ANOVA-boosting for Random Fourier Features</title>
      <link>https://arxiv.org/abs/2404.03050</link>
      <description>arXiv:2404.03050v2 Announce Type: replace-cross 
Abstract: We propose two algorithms for boosting random Fourier feature models for approximating high-dimensional functions. These methods utilize the classical and generalized analysis of variance (ANOVA) decomposition to learn low-order functions, where there are few interactions between the variables. Our algorithms are able to find an index set of important input variables and variable interactions reliably. Furthermore, we generalize already existing random Fourier feature models to an ANOVA setting, where terms of different order can be used. Our algorithms have the advantage of interpretability, meaning that the influence of every input variable is known in the learned model, even for dependent input variables. We give theoretical as well as numerical results that our algorithms perform well for sensitivity analysis. The ANOVA-boosting step reduces the approximation error of existing methods significantly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03050v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Potts, Laura Weidensager</dc:creator>
    </item>
    <item>
      <title>Interpolating between Optimal Transport and KL regularized Optimal Transport using R\'enyi Divergences</title>
      <link>https://arxiv.org/abs/2404.18834</link>
      <description>arXiv:2404.18834v2 Announce Type: replace-cross 
Abstract: Regularized optimal transport (OT) has received much attention in recent years starting from Cuturi's introduction of Kullback-Leibler (KL) divergence regularized OT. In this paper, we propose regularizing the OT problem using the family of $\alpha$-R\'enyi divergences for $\alpha \in (0, 1)$. R\'enyi divergences are neither $f$-divergences nor Bregman distances, but they recover the KL divergence in the limit $\alpha \nearrow 1$. The advantage of introducing the additional parameter $\alpha$ is that for $\alpha \searrow 0$ we obtain convergence to the unregularized OT problem. For the KL regularized OT problem, this was achieved by letting the regularization parameter $\varepsilon$ tend to zero, which causes numerical instabilities. We present two different ways to obtain premetrics on probability measures, namely by R\'enyi divergence constraints and by penalization. The latter premetric interpolates between the unregularized and the KL regularized OT problem with weak convergence of the unique minimizer, generalizing the interpolation property of KL regularized OT. We use a nested mirror descent algorithm to solve the primal formulation. Both on real and synthetic data sets R\'enyi regularized OT plans outperform their KL and Tsallis counterparts in terms of being closer to the unregularized transport plans and recovering the ground truth in inference tasks better.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18834v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.NA</category>
      <pubDate>Wed, 25 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Bresch, Viktor Stein</dc:creator>
    </item>
  </channel>
</rss>
