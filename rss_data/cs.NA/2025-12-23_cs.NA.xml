<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Dec 2025 05:00:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Voronoi integration of the rendering equation</title>
      <link>https://arxiv.org/abs/2512.17974</link>
      <description>arXiv:2512.17974v1 Announce Type: new 
Abstract: In photorealistic image rendering, Monte Carlo methods form the foundation for the integration of the rendering equation in modern approaches. However, despite their effectiveness, traditional Monte Carlo methods often face challenges in controlling variance, resulting in noisy visual artifacts in regions that are difficult to render. In this work, we propose a new approach to the integration of the rendering equation by introducing a Voronoi tessellation reweighting scheme combined with a Poisson point process sampling strategy to address some of the limitations of standard Monte Carlo methods. From a theoretical point of view, we show that the variance induced by a Poisson-Voronoi tessellation is smaller than that of the Monte Carlo method when the intensity of the underlying process is arbitrarily large and when the function to be integrated satisfies a Holder continuity condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17974v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Chenavier, Samuel Delepoulle, Christophe Renaud, Franck Vandewi\`ele</dc:creator>
    </item>
    <item>
      <title>A local Fortin projection for the Scott-Vogelius elements on general meshes</title>
      <link>https://arxiv.org/abs/2512.18033</link>
      <description>arXiv:2512.18033v1 Announce Type: new 
Abstract: We construct a local Fortin projection for the Scott-Vogelius finite element pair for polynomial degree $k \ge 4$ on general shape-regular triangulations in two dimensions. In particular, the triangulation may contain singular vertices. In addition to preserving the divergence in the dual of the pressure space, the projection preserves discrete boundary data and satisfies local stability estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18033v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Franziska Eickmann, Johnny Guzm\'an, Michael Neilan, L. Ridgway Scott, Tabea Tscherpel</dc:creator>
    </item>
    <item>
      <title>Approximation and learning with compositional tensor trains</title>
      <link>https://arxiv.org/abs/2512.18059</link>
      <description>arXiv:2512.18059v1 Announce Type: new 
Abstract: We introduce compositional tensor trains (CTTs) for the approximation of multivariate functions, a class of models obtained by composing low-rank functions in the tensor-train format. This format can encode standard approximation tools, such as (sparse) polynomials, deep neural networks (DNNs) with fixed width, or tensor networks with arbitrary permutation of the inputs, or more general affine coordinate transformations, with similar complexities. This format can be viewed as a DNN with width exponential in the input dimension and structured weights matrices. Compared to DNNs, this format enables controlled compression at the layer level using efficient tensor algebra. On the optimization side, we derive a layerwise algorithm inspired by natural gradient descent, allowing to exploit efficient low-rank tensor algebra. This relies on low-rank estimations of Gram matrices, and tensor structured random sketching. Viewing the format as a discrete dynamical system, we also derive an optimization algorithm inspired by numerical methods in optimal control. Numerical experiments on regression tasks demonstrate the expressivity of the new format and the relevance of the proposed optimization algorithms. Overall, CTTs combine the expressivity of compositional models with the algorithmic efficiency of tensor algebra, offering a scalable alternative to standard deep neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18059v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Eigel, Charles Miranda, Anthony Nouy, David Sommer</dc:creator>
    </item>
    <item>
      <title>A Domain Decomposition Deep Neural Network Method with Multi-Activation Functions for Solving Elliptic and Parabolic Interface Problems</title>
      <link>https://arxiv.org/abs/2512.18178</link>
      <description>arXiv:2512.18178v1 Announce Type: new 
Abstract: We present a domain decomposition-based deep learning method for solving elliptic and parabolic interface problems with discontinuous coefficients in two to ten dimensions. Our Multi-Activation Function (MAF) approach employs two independent neural networks, one for each subdomain, coupled through interface conditions in the loss function. The key innovation is a multi-activation mechanism within each subdomain network that adaptively blends multiple activation functions (e.g., $\tanh$ and Gaussian-type) with interface-aware weighting, enhancing learning efficiency near interfaces where coupling constraints are most demanding. We prove conditional error bounds relating solution accuracy to trained loss values and quadrature errors. Numerical experiments on elliptic and parabolic interface problems with various interface geometries (2D--10D) validate the effectiveness and accuracy of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18178v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qijia Zhai</dc:creator>
    </item>
    <item>
      <title>A Singularity Guided Nystr\"om Method for Elastostatics on Two Dimensional Domains with Corners</title>
      <link>https://arxiv.org/abs/2512.18208</link>
      <description>arXiv:2512.18208v1 Announce Type: new 
Abstract: We develop a comprehensive analytical and numerical framework for boundary integral equations (BIEs) of the 2D Lam\'e system on cornered domains. By applying local Mellin analysis on a wedge, we obtain a factorizable characteristic equation for the singular exponents of the boundary densities, and clarify their dependence on boundary conditions. The Fredholm well-posedness of the BIEs on cornered domains is proved in weighted Sobolev spaces. We further construct an explicit density-to-Taylor mapping for the BIE and show its invertibility for all but a countable set of angles. Based on these analytical results, we propose a singularity guided Nystr\"om (SGN) scheme for the numerical solution of BIEs on cornered domains. The SGN uses the computed corner exponents and a Legendre-tail indicator to drive panel refinement. An error analysis that combines this refinement strategy with an exponentially accurate far-field quadrature rule is provided. Numerical experiments across various cornered geometries demonstrate that SGN obtains higher order accuracy than uniform Nystr\"om method and reveal a crowding-limited regime for domains with re-entrant angles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18208v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baoling Xie, Jun Lai</dc:creator>
    </item>
    <item>
      <title>Hybrid multiscale method for polymer melts: analysis and simulations</title>
      <link>https://arxiv.org/abs/2512.18272</link>
      <description>arXiv:2512.18272v1 Announce Type: new 
Abstract: We model the flow behaviour of dense melts of flexible and semiflexible ring polymers in the presence of walls using a hybrid multiscale approach. Specifically, we perform molecular dynamics simulations and apply the Irving-Kirkwood formula to determine an averaged stress tensor for a macroscopic model. For the latter, we choose a Cahn-Hilliard-Navier-Stokes system with dynamic and no-slip boundary conditions. We present numerical simulations of the macroscopic flow that are based on a finite element method. In particular, we present detailed proofs of the solvability and the energy stability of our numerical scheme. Phase segregation under flow between flexible and semiflexible rings, as observed in the microscopic simulations, can be replicated in the macroscopic model by introducing effective attractive forces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18272v1</guid>
      <category>math.NA</category>
      <category>cond-mat.soft</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ranajay Datta, M\'aria Luk\'a\v{c}ov\'a-Medvi\v{d}ov\'a, Andreas Sch\"omer, Peter Virnau</dc:creator>
    </item>
    <item>
      <title>Convexification Numerical Method for Imaging of Moving Targets</title>
      <link>https://arxiv.org/abs/2512.18361</link>
      <description>arXiv:2512.18361v1 Announce Type: new 
Abstract: The problem of imaging of a moving target is formulated as a Coefficient Inverse Problem for a hyperbolic equation with its coefficient depending on all three spatial variables and time. As the initial condition, the point source running along a straight line is used. Lateral Cauchy data are known for each position of the point source. A truncated Fourier series with respect to a special orthonormal basis is used. First, Lipschitz stability estimate is obtained. Next, a globally convergent numerical method, the so-called convexification method, is developed and its convergence analysis is carried out. The convexification method is based on a Carleman estimate. Results of numerical experiments are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18361v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael V. Klibanov, Jingzhi Li, Vladimir G. Romanov, Zhipeng Yang</dc:creator>
    </item>
    <item>
      <title>Sixth-order explicit one-step methods for stiff ODEs via hybrid deferred correction involving RK2 and RK4: Application to reaction-diffusion equations</title>
      <link>https://arxiv.org/abs/2512.18377</link>
      <description>arXiv:2512.18377v1 Announce Type: new 
Abstract: In this paper, the fourth-order explicit Runge-Kutta method (RK4) is used to make a Deferred Correction (DC) on the explicit midpoint rule, resulting in an explicit one-step method of order six of accuracy, denoted DC6RK2/4. Convergence and order of accuracy of DC6RK2/4 are proven through a deferred correction condition satisfied by the RK4. The region of absolute stability of this method contains that of a RK6 and is tangent to the region [-5.626,0[x[-4.730,4.730] of the complex plane, containing a significant part of the imaginary axis. Numerical experiments with standard test problems for stiff systems of ODEs show that DC6RK2/4 performs well on problems regarding strong non-linearity and long-term integration, and this method does not require extremely small time steps for accurate numerical solutions of stiff problems. Moreover, this method is better than standard implicit methods like the Backward Differentiation Formulae and the DC methods for the implicit midpoint rule on stiff problems for which Jacobian matrices along the solution curve have complex eigenvalues where imaginary parts have larger magnitudes than real parts. An application of DC6RK2/4 to a class of test problems for reaction-diffusion equations in one dimensional is also carried out.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18377v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Saint Cyr E. R. Koyaguerebo-Im\'e</dc:creator>
    </item>
    <item>
      <title>A least-squares meshfree method for the incompressible Navier-Stokes equations: A satisfactory solenoidal velocity field via a staggered-variable arrangement</title>
      <link>https://arxiv.org/abs/2512.18422</link>
      <description>arXiv:2512.18422v1 Announce Type: new 
Abstract: Incompressible flow solvers based on strong-form meshfree methods represent arbitrary geometries without the need for a global mesh system. However, their local evaluations make it difficult to satisfy incompressibility at the discrete level. Moreover, the collocated arrangement of velocity and pressure variables tends to induce a zero-energy mode, leading to decoupling between the two variables. In projection-based approaches, a spatial discretization scheme based on a conventional node-based moving least-squares method for the pressure causes inconsistency between the discrete operators on both sides of the Poisson equation. Thus, a solenoidal velocity field cannot be ensured numerically. In this study, a numerical method for the incompressible Navier-Stokes equations is developed by introducing a local primal-dual grid into the mesh-constrained discrete point method, enabling consistent discrete operators. The \textit{virtual} dual cell constructed is based on the local connectivity among nodes, and therefore our method remains truly meshfree. To achieve a consistent coupling between velocity and pressure variables under the primal-dual arrangement, time evolution converting is applied to evolve the velocity on cell interfaces. For numerical validation, a linear acoustic equation is solved to confirm the effectiveness of the staggered-variable arrangement based on the local primal-dual grid. Then, incompressible Navier-Stokes equations are solved, and the proposed method is demonstrated to satisfy the condition of a solenoidal velocity field at the discrete level, achieve the expected spatial convergence order, and accurately reproduce flow features over a wide range of Reynolds numbers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18422v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takeharu Matsuda, Satoshi Ii</dc:creator>
    </item>
    <item>
      <title>Overcoming Spectral Bias via Cross-Attention</title>
      <link>https://arxiv.org/abs/2512.18586</link>
      <description>arXiv:2512.18586v1 Announce Type: new 
Abstract: Spectral bias implies an imbalance in training dynamics, whereby high-frequency components may converge substantially more slowly than low-frequency ones. To alleviate this issue, we propose a cross-attention-based architecture that adaptively reweights a scaled multiscale random Fourier feature bank with learnable scaling factors. The learnable scaling adjusts the amplitudes of the multiscale random Fourier features, while the cross-attention residual structure provides an input-dependent mechanism to emphasize the most informative scales. As a result, the proposed design accelerates high-frequency convergence relative to comparable baselines built on the same multiscale bank. Moreover, the attention module supports incremental spectral enrichment: dominant Fourier modes extracted from intermediate approximations via discrete Fourier analysis can be appended to the feature bank and used in subsequent training, without modifying the backbone architecture.
  We further extend this framework to PDE learning by introducing a linear combination of two sub-networks: one specialized in capturing high-frequency components of the PDE solution and the other in capturing low-frequency components, with a learnable (or optimally chosen) mixing factor to balance the two contributions and improve training efficiency in oscillatory regimes. Numerical experiments on high-frequency and discontinuous regression problems, image reconstruction tasks, as well as representative PDE examples, demonstrate the effectiveness and robustness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18586v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaodong Feng, Tao Tang, Xiaoliang Wan, Tao Zhou</dc:creator>
    </item>
    <item>
      <title>Generalized Chebyshev acceleration on the unit disc</title>
      <link>https://arxiv.org/abs/2512.18848</link>
      <description>arXiv:2512.18848v1 Announce Type: new 
Abstract: Generalized Chebyshev acceleration is a semi-iterative technique applicable to a basic iterative method only when the eigenvalues of the iteration matrix satisfy a highly restrictive inclusion condition. In this work, we relax this requirement by introducing an alternative iterative scheme that converges to the same solution. The effectiveness of the proposed approach is examined through its application to a large-scale sparse normal matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18848v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nurg\"ul G\"okg\"oz</dc:creator>
    </item>
    <item>
      <title>Weak Galerkin finite element methods for elliptic interface problems on nonconvex polygonal partitions</title>
      <link>https://arxiv.org/abs/2512.18905</link>
      <description>arXiv:2512.18905v1 Announce Type: new 
Abstract: This paper proposes a weak Galerkin (WG) finite element method for elliptic interface problems defined on nonconvex polygonal partitions. The method features a built-in stabilizer and retains a simple, symmetric, and positive definite formulation. An optimal-order error estimate is rigorously derived in the discrete $H^1$ norm. Furthermore, a series of numerical experiments are provided to verify the theoretical results and to demonstrate the robustness and effectiveness of the proposed WG method for elliptic interface problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18905v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Chunmei Wang, Shangyou Zhang</dc:creator>
    </item>
    <item>
      <title>An asymptotically compatible unfitted finite element methods for nonlocal elliptic Interfaces: local limits and sharp error estimates</title>
      <link>https://arxiv.org/abs/2512.18939</link>
      <description>arXiv:2512.18939v1 Announce Type: new 
Abstract: This paper presents the development and analysis of an asymptotically compatible (AC) unfitted finite element method for one-dimensional nonlocal elliptic interface problems. The proposed method achieves optimal error estimates through three principal contributions: (i) an extended maximum principle, coupled with an asymptotic consistency analysis of the flux operator, which establishes second-order convergence of nonlocal solutions to their local counterparts in the maximum norm; (ii) a Nitsche-type formulation that directly incorporates nonlocal jump conditions into the weak form, enabling high accuracy without body-fitted meshes; and (iii) a rigorous proof of optimal convergence rates in both the energy and L2 norms via the nonlocal maximum principle, flux consistency, and a newly derived nonlocal Poincare inequality. Numerical experiments confirm the theoretical findings and demonstrate the robustness and efficiency of the proposed approach, thereby providing a foundation for extensions to higher dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18939v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haixia Dong, Ziqing Xie, Jiwei Zhang</dc:creator>
    </item>
    <item>
      <title>A TraceFEM $C^0$ Interior Penalty Method for the Surface Biharmonic Equation</title>
      <link>https://arxiv.org/abs/2512.18949</link>
      <description>arXiv:2512.18949v1 Announce Type: new 
Abstract: We construct and analyze a TraceFEM discretization for the surface biharmonic problem. The method utilizes standard quadratic Lagrange finite element spaces defined on a three-dimensional background mesh and a symmetric $C^0$ interior penalty formulation posed on a second-order polyhedral approximation of the surface. Stability is achieved through a combination of surface edge penalties and bulk-facet penalization of gradient and Hessian jumps. We prove optimal first-order convergence in a discrete $H^2$ norm and quadratic convergence in the $L^2$ norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18949v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Neilan, Hongzhi Wan</dc:creator>
    </item>
    <item>
      <title>A Spectral Low-Mode Reduced Method for Elliptic Problems</title>
      <link>https://arxiv.org/abs/2512.18955</link>
      <description>arXiv:2512.18955v1 Announce Type: new 
Abstract: We develop a spectral low-mode reduced solver for second-order elliptic boundary value problems with spatially varying diffusion coefficients. The approach projects standard finite difference or finite element discretization onto a global coarse space spanned by the lowest Dirichlet Laplacian eigenmodes, yielding an analytic reduced model that requires no training data and preserves coefficient heterogeneity through an exact Galerkin projection. The reduced solution is energy-optimal in the selected subspace and, for $H^2$-regular solutions, the truncation error associated with discarded modes satisfies a $\sqrt{\log M}/M$ decay in the $H_0^1$ norm. For uniformly stable reduced bases, the projected operator is well conditioned with respect to mesh refinement, and numerical experiments corroborate the predicted accuracy and demonstrate meaningful speedups over sparse direct solvers, with favorable performance relative to multigrid and deflation-based Krylov methods for heterogeneous coefficients in the tested setups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18955v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prosper Torsu</dc:creator>
    </item>
    <item>
      <title>Randomized time stepping of nonlinearly parametrized solutions of evolution problems</title>
      <link>https://arxiv.org/abs/2512.19009</link>
      <description>arXiv:2512.19009v1 Announce Type: new 
Abstract: The Dirac-Frenkel variational principle is a widely used building block for using nonlinear parametrizations in the context of model reduction and numerically solving partial differential equations; however, it typically leads to time-dependent least-squares problems that are poorly conditioned. This work introduces a randomized time stepping scheme that solves at each time step a low-dimensional, random projection of the parameter vector via sketching. The sketching has a regularization effect that leads to better conditioned least-squares problems and at the same time reduces the number of unknowns that need to be solved for at each time step. Numerical experiments with benchmark examples demonstrate that randomized time stepping via sketching achieves competitive accuracy and outperforms standard regularization in terms of runtime efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19009v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijun Dong, Paul Schwerdtner, Benjamin Peherstorfer</dc:creator>
    </item>
    <item>
      <title>Newton's method in adaptive iteratively linearized FEM</title>
      <link>https://arxiv.org/abs/2512.19357</link>
      <description>arXiv:2512.19357v1 Announce Type: new 
Abstract: This paper concerns the inclusion of Newton's method into an adaptive finite element method (FEM) for the solution of nonlinear partial differential equations (PDEs). It features an adaptive choice of the damping parameter in the Newton iteration for the discretized nonlinear problems on each level ensuring both global linear and local quadratic convergence. In contrast to energy-based arguments in the literature, a novel approach in the analysis considers the discrete dual norm of the residual as a computable measure for the linearization error. As a consequence, this paper provides the first convergence analysis with optimal rates of an adaptive iteratively linearized FEM beyond energy-minimization problems. The presented theory applies to strongly monotone operators with locally Lipschitz continuous Fr\'echet derivative. We present a class of semilinear PDEs fitting into this framework and provide numerical experiments to underline the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19357v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Bringmann, Maximilian Brunner, Dirk Praetorius</dc:creator>
    </item>
    <item>
      <title>A Cartesian Cut-Cell Two-Fluid Method for Two-Phase Diffusion Problems</title>
      <link>https://arxiv.org/abs/2512.19407</link>
      <description>arXiv:2512.19407v1 Announce Type: new 
Abstract: We present a Cartesian cut-cell finite-volume method for sharp-interface two-phase diffusion problems in static geometries. The formulation follows a two-fluid approach: independent diffusion equations are discretized in each phase on a fixed staggered Cartesian grid, while the phases are coupled through embedded interface conditions enforcing continuity of normal flux and a general jump law. Cut cells are treated by integrating the governing equations over phase-restricted control volumes and faces, yielding discrete divergence and gradient operators that are locally conservative within each phase. Interface coupling is achieved by introducing a small set of interfacial unknowns per cut cell on the embedded boundary; the resulting algebraic system involves only bulk and interfacial averages. A key feature of the method is the use of a reduced set of geometric information based solely on low-order moments (trimmed volumes, apertures and interface measures/centroids), allowing robust implementation without constructing explicitly cut-cell polytopes. The method supports steady (Poisson) and unsteady (diffusion) regimes and incorporates Dirichlet, Neumann, Robin boundary conditions and general jumps. We validate the scheme on one-, two- and three-dimensional mono- and diphasic benchmarks, including curved embedded boundaries, Robin conditions and strong property/jump contrasts. The results demonstrate the expected convergence behavior, sharp enforcement of interfacial laws and excellent conservation properties. Extensions to moving interfaces and Stefan-type free-boundary problems are natural perspectives of this framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19407v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Louis Libat, Can Sel\c{c}uk, Eric Ch\'enier, Vincent Le Chenadec</dc:creator>
    </item>
    <item>
      <title>Mixed formulation and structure-preserving discretization of Cosserat rod dynamics in a port-Hamiltonian framework</title>
      <link>https://arxiv.org/abs/2512.19408</link>
      <description>arXiv:2512.19408v1 Announce Type: new 
Abstract: An energy-based modeling framework for the nonlinear dynamics of spatial Cosserat rods undergoing large displacements and rotations is proposed. The mixed formulation features independent displacement, velocity and stress variables and is further objective and locking-free. Finite rotations are represented using a director formulation that avoids singularities and yields a constant mass matrix. This results in an infinite-dimensional nonlinear port-Hamiltonian (PH) system governed by partial differential-algebraic equations with a quadratic energy functional. Using a time-differentiated compliance form of the stress-strain relations allows for the imposition of kinematic constraints, such as inextensibility or shear-rigidity. A structure-preserving finite element discretization leads to a finite-dimensional system with PH structure, thus facilitating the design of an energy-momentum consistent integration scheme. Dissipative material behavior (via the generalized-Maxwell model) and non-standard actuation approaches (via pneumatic chambers or tendons) integrate naturally into the framework. As illustrated by selected numerical examples, the present framework establishes a new approach to energy-momentum consistent formulations in computational mechanics involving finite rotations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19408v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp L. Kinon, Simon R. Eugster, Peter Betsch</dc:creator>
    </item>
    <item>
      <title>A massively parallel non-overlapping Schwarz preconditioner for PolyDG methods in brain electrophysiology</title>
      <link>https://arxiv.org/abs/2512.19536</link>
      <description>arXiv:2512.19536v1 Announce Type: new 
Abstract: We investigate non-overlapping Schwarz preconditioners for the algebraic systems stemming from high-order discretizations of the coupled monodomain and Barreto-Cressman models, with applications to brain electrophysiology. The spatial discretization is based on a high-order Polytopal Discontinuous Galerkin (PolyDG) method, coupled with the Crank-Nicolson time discretization scheme with explicit extrapolation of the ion term. To improve solver efficiency, we consider additive Schwarz preconditioners within the PolyDG framework, which combines (massively parallel) local subdomain solvers with a coarse-grid correction. Numerical experiments demonstrate robustness with respect to the discretization parameters, as well as a significant reduction in iteration counts compared to the unpreconditioned solver. These features make the proposed approach well-suited for parallel large-scale simulations in brain electrophysiology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19536v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caterina B. Leimer Saglio, Stefano Pagani, Paola F. Antonietti</dc:creator>
    </item>
    <item>
      <title>Convergence analysis for non-iterative sequential schemes for Biot's model</title>
      <link>https://arxiv.org/abs/2512.19579</link>
      <description>arXiv:2512.19579v1 Announce Type: new 
Abstract: An alternative to the fully implicit or monolithic methods used for the solution of the coupling of fluid flow and deformation in porous media is a sequential approach in which the fully coupled system is broken into subproblems (flow and mechanics problems) that are solved one after the other. This fully explicit coupling approach is a very simple scheme which allows much flexibility in the implementation and has a lower computational cost, making it quite attractive in practice since smaller linear systems need to be solved in order to obtain the solution for the whole coupled poroelastic system. Due to the appealing advantages of these methods, intensive research is currently being carried out in this direction, as in the present work. Although the application of this type of method is very common in practice, there exist only a few works devoted to their theoretical analysis. In this work, we consider the so-called explicit fixed-stress split scheme, which consists of solving the flow problem first with time-lagging the displacement term, followed by the solution of the mechanics problem. To the best of our knowledge, we provide the first convergence analysis of the explicit fixed-stress split scheme for Biot's equations. In particular, we prove that this algorithm is optimally convergent if the considered finite element discretization satisfies an inf-sup condition. In addition, with the aim of designing the simplest scheme for solving Biot's model, we also propose a similar decoupled algorithm for piecewise linear finite elements for both variables which arises from the novel stabilization recently proposed in \cite{Pe2025}, and is demonstrated to be optimally convergent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19579v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaozhe Hu, Francisco J. Gaspar, Carmen Rodrigo</dc:creator>
    </item>
    <item>
      <title>A modified Brinkman penalization fictitious domain method for the unsteady Navier-Stokes equations</title>
      <link>https://arxiv.org/abs/2512.19580</link>
      <description>arXiv:2512.19580v1 Announce Type: new 
Abstract: This paper investigates a modification of the fictitious domain method with continuation in the lower-order coefficients for the unsteady Navier-Stokes equations governing the motion of an incompressible homogeneous fluid in a bounded 2D or 3D domain. The modification enables {a solution-dependent} choice of the critical parameter. Global-in-time existence and convergence of a weak solution to the auxiliary problem are proved, and local-in-time existence and convergence of a unique strong solution are established. For the strong solution, a new higher-order convergence rate estimate in the penalization parameter is obtained. The introduced framework allows us to apply a pointwise divergence free finite element method as a discretization technique, leading to strongly mass conservative discrete fictitious domain method. A numerical example illustrates the performance of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19580v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhanybek Baitulenov, Maxim Olshanskii, Almas Temirbekov, Nurlan Temirbekov, Syrym Kasenov</dc:creator>
    </item>
    <item>
      <title>Static size-effects meet the dynamic scattering properties of finite-sized mechanical metamaterials: a relaxed micromorphic study with parameter identification via two-stage static-dynamic optimization</title>
      <link>https://arxiv.org/abs/2512.19604</link>
      <description>arXiv:2512.19604v1 Announce Type: new 
Abstract: Mechanical metamaterials exhibit size-effects when a few unit-cells are subjected to static loading because no clear micro-macro scale separation holds and the characteristic length of the deformation becomes comparable to the unit-cell size. These size-effects typically manifest themselves as a strengthening of the response in a form summarized as "smaller is stiffer". Moreover, the dynamical behavior of mechanical metamaterials is very remarkable, featuring unique phenomena such as dispersive behavior and band-gaps where elastic waves cannot propagate over specific frequency ranges. In these frequency ranges, the wavelength becomes gradually comparable to the unit-cell size, giving rise to microstructure related phenomena which become particularly visible in the reflection/transmission patterns where an incident wave hits the metamaterial's interfaces. This raises the question of whether the static size-effects and dynamic reflection/transmission patterns are correlated.
  In this work, we investigate the interaction of the static size-effects and the dynamic scattering response of mechanical metamaterials by employing the relaxed micromorphic model. We introduce a two-stage optimization procedure to identify the material parameters. In the first stage, the static material parameters are identified by exploiting the static size-effects through a least squares fitting procedure based on the total energy. The dynamic parameters are determined in the second stage by fitting the dispersion curves of the relaxed micromorphic model to those of the fully discretized microstructure. At this second stage, we assess the results obtained by fitting the dispersion curves in one and in two propagation directions, for both the relaxed micromorphic model (RMM) with curvature and its reduced counterpart (RRMM) without curvature.
  The full abstract is presented in the paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19604v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohammad Sarhil, Leonardo Andres Perez Ramirez, Max Jendrik Voss, Angela Madeo</dc:creator>
    </item>
    <item>
      <title>Milstein-type Schemes for Hyperbolic SPDEs</title>
      <link>https://arxiv.org/abs/2512.19647</link>
      <description>arXiv:2512.19647v1 Announce Type: new 
Abstract: This article studies the temporal approximation of hyperbolic semilinear stochastic evolution equations with multiplicative Gaussian noise by Milstein-type schemes. We take the term hyperbolic to mean that the leading operator generates a contractive, not necessarily analytic $C_0$-semigroup. Optimal convergence rates are derived for the pathwise uniform strong error \[
  E_h^\infty := \Big(\mathbb{E}\max_{1\le j \le M}\|U_{t_j}-u_j\|_X^p\Big)^{1/p} \] on a Hilbert space $X$ for $p\in [2,\infty)$. Here, $U$ is the mild solution and $u_j$ its Milstein approximation at time $t_j=jh$ with step size $h&gt;0$ and final time $T=Mh&gt;0$. For sufficiently regular nonlinearity and noise, we establish strong convergence of order one, with the error satisfying $E_h^\infty\lesssim h\sqrt{\log(T/h)}$ for rational Milstein schemes and $E_h^\infty \lesssim h$ for exponential Milstein schemes. This extends previous results from parabolic to hyperbolic SPDEs and from exponential to rational Milstein schemes. Root-mean-square error estimates are strengthened to pathwise uniform estimates. Numerical experiments validate the convergence rates for the stochastic Schr\"odinger equation. Further applications to Maxwell's and transport equations are included.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19647v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.FA</category>
      <category>math.PR</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix Kastner, Katharina Klioba</dc:creator>
    </item>
    <item>
      <title>An interface crack in 1d piezoelectric quasicrystal under antiplane mechanical loading and electric field</title>
      <link>https://arxiv.org/abs/2512.17981</link>
      <description>arXiv:2512.17981v1 Announce Type: cross 
Abstract: The present study provides the consideration of a mode III interface crack in one-dimentional (1D) piezoelectric quasicrystal under antiplane phonon and phason loading and inplane electric field. Due to complex function approach all required electromechanical parameters are presented through vector-functions analytic in the whole complex plane except the crack region. The cases of electrically impermeable (insulated) and electrically limited permeable conditions on the crack faces are considered. In the first case a vector Hilbert problem in the complex plane is formulated and solved exactly and in the second one the quadratic equation with respect to the electric flux through the crack region is obtained additionally. Its solution permits to find phonon and phason stresses, displacement jumps (sliding) and also electric characteristics along the material interface. Analytical formulas are also obtained for the corresponding stress intensity factors related to each field. The numerical computations for three selected variants of the loading conditions was conducted and the resulting field distributions are visualised on the crack continuation beyond the crack and also inside of the crack region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17981v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.CV</category>
      <category>math.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.33108/visnyk_tntu2025.03.012</arxiv:DOI>
      <arxiv:journal_reference>Scientific Journal of TNTU (Tern.), vol. 119, no. 3, 2025, pp. 12-25</arxiv:journal_reference>
      <dc:creator>Mohammed Altoumaimi, V. V. Loboda</dc:creator>
    </item>
    <item>
      <title>Correcting quantum errors one gradient step at a time</title>
      <link>https://arxiv.org/abs/2512.18061</link>
      <description>arXiv:2512.18061v1 Announce Type: cross 
Abstract: In this work, we introduce a general, gradient-based method that optimises codewords for a given noise channel and fixed recovery. We do so by differentiating fidelity and descending on the complex coefficients using finite-difference Wirtinger gradients with soft penalties to promote orthonormalisation. We validate the gradients on symmetry checks (XXX/ZZZ repetition codes) and the $[[5, 1, 3]]$ code, then demonstrate substantial gains under isotropic Pauli noise with Petz recovery: fidelity improves from 0.783 to 0.915 in 100 steps for an isotropic Pauli noise of strength 0.05. The procedure is deterministic, highly parallelisable, and highly scalable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18061v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manav Seksaria, Anil Prabhakar</dc:creator>
    </item>
    <item>
      <title>Structure-Preserving Optimal Control of Open Quantum Systems via a Discrete Contact PMP</title>
      <link>https://arxiv.org/abs/2512.18879</link>
      <description>arXiv:2512.18879v1 Announce Type: cross 
Abstract: We develop a discrete Pontryagin Maximum Principle (PMP) for controlled open quantum systems governed by Lindblad dynamics, and introduce a second--order \emph{contact Lie--group variational integrator} (contact LGVI) that preserves both the CPTP (completely positive and trace--preserving) structure of the Lindblad flow and the contact geometry underlying the discrete PMP. A type--II discrete contact generating function produces a strict discrete contactomorphism under which the state, costate, and cost propagate in exact agreement with the variational structure of the discrete contact PMP.
  We apply this framework to the optimal control of a dissipative qubit and compare it with a non--geometric explicit RK2 discretization of the Lindblad equation. Although both schemes have the same formal order, the RK2 method accumulates geometric drift (loss of trace, positivity violations, and breakdown of the discrete contact form) that destabilizes PMP shooting iterations, especially under strong dissipation or long horizons. In contrast, the contact LGVI maintains exact CPTP structure and discrete contact geometry step by step, yielding stable, physically consistent, and geometrically faithful optimal control trajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18879v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leonardo Colombo</dc:creator>
    </item>
    <item>
      <title>Hybrid Stochastic Functional Differential Equations with Infinite Delay: Approximations and Numerics</title>
      <link>https://arxiv.org/abs/2512.18990</link>
      <description>arXiv:2512.18990v1 Announce Type: cross 
Abstract: This paper is to investigate if the solution of a hybrid stochastic functional differential equation (SFDE) with infinite delay can be approximated by the solution of the corresponding hybrid SFDE with finite delay. A positive result is established for a large class of highly nonlinear hybrid SFDEs with infinite delay. Our new theory makes it possible to numerically approximate the solution of the hybrid SFDE with infinite delay, via the numerical solution of the corresponding hybrid SFDE with finite delay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18990v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guozhen Li, Xiaoyue Li, Xuerong Mao, Guoting Song</dc:creator>
    </item>
    <item>
      <title>Self-Consistent Probability Flow for High-Dimensional Fokker-Planck Equations</title>
      <link>https://arxiv.org/abs/2512.19196</link>
      <description>arXiv:2512.19196v1 Announce Type: cross 
Abstract: Solving high-dimensional Fokker-Planck (FP) equations is a challenge in computational physics and stochastic dynamics, due to the curse of dimensionality (CoD) and the bottleneck of evaluating second-order diffusion terms. Existing deep learning approaches, such as Physics-Informed Neural Networks (PINNs), face computational challenges as dimensionality increases, driven by the $O(D^2)$ complexity of automatic differentiation for second-order derivatives. While recent probability flow approaches bypass this by learning score functions or matching velocity fields, they often involve serial computational operations or depend on sampling efficiency in complex distributions. To address these issues, we propose the Self-Consistent Probability Flow (SCPF) method. We reformulate the second-order FP equation into an equivalent first-order deterministic Probability Flow ODE (PF-ODE) constraint. Unlike score matching or velocity matching, SCPF solves this problem by minimizing the residual of the PF-ODE continuity equation, which avoids explicit Hessian computation. We leverage Continuous Normalizing Flows (CNF) combined with the Hutchinson Trace Estimator (HTE) to reduce the training complexity to linear scale $O(D)$, achieving an effective $O(1)$ wall-clock time on GPUs. To address data sparsity in high dimensions, we apply a generative adaptive sampling strategy and theoretically prove that dynamically aligning collocation points with the evolving probability mass is a necessary condition to bound the approximation error. Experiments on diverse benchmarks -- ranging from anisotropic Ornstein-Uhlenbeck (OU) processes and high-dimensional Brownian motions with time-varying diffusion terms, to Geometric OU processes featuring non-Gaussian solutions -- demonstrate that SCPF effectively mitigates the CoD, maintaining high accuracy and constant computational cost for problems up to 100 dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19196v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaolong Wu, Qifeng Liao</dc:creator>
    </item>
    <item>
      <title>Sprecher Networks: A Parameter-Efficient Kolmogorov-Arnold Architecture</title>
      <link>https://arxiv.org/abs/2512.19367</link>
      <description>arXiv:2512.19367v1 Announce Type: cross 
Abstract: We present Sprecher Networks (SNs), a family of trainable neural architectures inspired by the classical Kolmogorov-Arnold-Sprecher (KAS) construction for approximating multivariate continuous functions. Distinct from Multi-Layer Perceptrons (MLPs) with fixed node activations and Kolmogorov-Arnold Networks (KANs) featuring learnable edge activations, SNs utilize shared, learnable splines (monotonic and general) within structured blocks incorporating explicit shift parameters and mixing weights. Our approach directly realizes Sprecher's specific 1965 sum of shifted splines formula in its single-layer variant and extends it to deeper, multi-layer compositions. We further enhance the architecture with optional lateral mixing connections that enable intra-block communication between output dimensions, providing a parameter-efficient alternative to full attention mechanisms. Beyond parameter efficiency with $O(LN + LG)$ scaling (where $G$ is the knot count of the shared splines) versus MLPs' $O(LN^2)$, SNs admit a sequential evaluation strategy that reduces peak forward-intermediate memory from $O(N^2)$ to $O(N)$ (treating batch size as constant), making much wider architectures feasible under memory constraints. We demonstrate empirically that composing these blocks into deep networks leads to highly parameter and memory-efficient models, discuss theoretical motivations, and compare SNs with related architectures (MLPs, KANs, and networks with learnable node activations).</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19367v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian H\"agg, Kathl\'en Kohn, Giovanni Luca Marchetti, Boris Shapiro</dc:creator>
    </item>
    <item>
      <title>Initialization of a Polyharmonic Cascade, Launch and Testing</title>
      <link>https://arxiv.org/abs/2512.19524</link>
      <description>arXiv:2512.19524v1 Announce Type: cross 
Abstract: This paper concludes a series of studies on the polyharmonic cascade, a deep machine learning architecture theoretically derived from indifference principles and the theory of random functions. A universal initialization procedure is proposed, based on symmetric constellations in the form of hyperoctahedra with a central point. This initialization not only ensures stable training of cascades with tens and hundreds of layers (up to 500 layers without skip connections), but also radically simplifies the computations. Scalability and robustness are demonstrated on MNIST (98.3% without convolutions or augmentations), HIGGS (AUC approximately 0.885 on 11M examples), and Epsilon (AUC approximately 0.963 with 2000 features). All linear algebra is reduced to 2D operations and is efficiently executed on GPUs. A public repository and an archived snapshot are provided for full reproducibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19524v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuriy N. Bakhvalov</dc:creator>
    </item>
    <item>
      <title>A perturbed preconditioned gradient descent method for the unconstrained minimization of composite objectives</title>
      <link>https://arxiv.org/abs/2512.19532</link>
      <description>arXiv:2512.19532v1 Announce Type: cross 
Abstract: We introduce a perturbed preconditioned gradient descent (PPGD) method for the unconstrained minimization of a strongly convex objective $G$ with a locally Lipschitz continuous gradient. We assume that $G(v)=E(v)+F(v)$ and that the gradient of $F$ is only known approximately. Our analysis is conducted in infinite dimensions with a preconditioner built into the framework. We prove a linear rate of convergence, up to an error term dependent on the gradient approximation. We apply the PPGD to the stationary Cahn-Hilliard equations with variable mobility under periodic boundary conditions. Numerical experiments are presented to validate the theoretical convergence rates and explore how the mobility affects the computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19532v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jea-Hyun Park, Abner J. Salgado, Steven M. Wise</dc:creator>
    </item>
    <item>
      <title>Sampling recovery in $L_2$ and other norms</title>
      <link>https://arxiv.org/abs/2305.07539</link>
      <description>arXiv:2305.07539v5 Announce Type: replace 
Abstract: We study the recovery of functions in various norms, including $L_p$ with $1\le p\le\infty$, based on function evaluations. We obtain worst case error bounds for general classes of functions in terms of the best $L_2$-approximation from a given nested sequence of subspaces and the Christoffel function of these subspaces. In the case $p=\infty$, our results imply that linear sampling algorithms are optimal up to a constant factor for many reproducing kernel Hilbert spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.07539v5</guid>
      <category>math.NA</category>
      <category>cs.CC</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1090/mcom/4148</arxiv:DOI>
      <arxiv:journal_reference>Math. Comp. Published Online: October 6, 2025</arxiv:journal_reference>
      <dc:creator>David Krieg, Kateryna Pozharska, Mario Ullrich, Tino Ullrich</dc:creator>
    </item>
    <item>
      <title>Using Machine Learning to Design Time Step Size Controllers for Stable Time Integrators</title>
      <link>https://arxiv.org/abs/2312.01796</link>
      <description>arXiv:2312.01796v2 Announce Type: replace 
Abstract: We present a new method for developing time step controllers based on a technique from the field of machine learning. This method is applicable to stable time integrators that have an embedded scheme, i.e., that have local error estimation similar to Runge-Kutta pairs. To design good time step size controllers using these error estimates, we propose to use Bayesian optimization. In particular, we design a novel objective function that captures important properties such as tolerance convergence and computational stability. We apply our new approach to several modified Patankar--Runge--Kutta (MPRK) schemes and a Rosenbrock-type scheme, equipping them with controllers based on digital signal processing which extend classical PI and PID controllers. We demonstrate that the optimization process yields controllers that are at least as good as the best controllers chosen from a wide range of suggestions available for classical explicit and implicit time integration methods by providing work-precision diagrams on a variety of ordinary and partial differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01796v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Izgin, Hendrik Ranocha</dc:creator>
    </item>
    <item>
      <title>Novel approaches for the reliable and efficient numerical evaluation of Landau-type operators</title>
      <link>https://arxiv.org/abs/2402.02247</link>
      <description>arXiv:2402.02247v2 Announce Type: replace 
Abstract: When applying Hamiltonian operator splitting methods for the time integration of multi-species Vlasov-Maxwell-Landau systems, the reliable and efficient numerical approximation of the Landau equation represents a fundamental component of the entire algorithm. Substantial computational issues arise from the treatment of the physically most relevant three-dimensional case with Coulomb-type interaction. This work is concerned with the introduction and numerical comparison of novel approaches for the evaluation of the Landau collision operator and related integral operators with more general kernels. In the spirit of collocation, common tools are the identification of fundamental integrals, series expansions of the integral kernel and the density function on the main part of the velocity domain, and interpolation as well as quadrature approximation nearby the singularity of the kernel. Focusing on the favourable choice of the Fourier spectral method, their practical implementation uses the reduction to basic integrals, fast Fourier techniques, and summations along certain directions. Moreover, an important observation is that a significant percentage of the overall computational effort can be transferred to precomputations which are independent of the density function. For the purpose of exposition and numerical validation, the cases of constant, regular, and singular integral kernels are distinguished, and the procedure is adapted accordingly to the increasing complexity of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02247v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jose Antonio Carrillo, Mechthild Thalhammer</dc:creator>
    </item>
    <item>
      <title>An adaptive finite element multigrid solver using GPU acceleration</title>
      <link>https://arxiv.org/abs/2405.05047</link>
      <description>arXiv:2405.05047v3 Announce Type: replace 
Abstract: Adaptive finite elements combined with geometric multigrid solvers are one of the most efficient numerical methods for problems such as the instationary Navier-Stokes equations. Yet despite their efficiency, computations remain expensive and the simulation of, for example, complex flow problems can take many hours or days. GPUs provide an interesting avenue to speed up the calculations due to their very large theoretical performance. However, the large degree of parallelism and non-standard API make the use of GPUs in scientific computing challenging. In this work, we develop a GPU acceleration for the adaptive finite element library Gascoigne and study its effectiveness for different systems of partial differential equations. Our goal is thereby to integrate the GPU acceleration into the existing code with minimal changes, even when this requires a penalty in the GPU acceleration. Through the systematic formulation of all computations as linear algebra operations, we can employ GPU-accelerated linear algebra libraries, which simplifies the implementation and ensures the maintainability of the code while achieving very efficient GPU utilizations. Our results for a transport-diffusion equation, linear elasticity, and the instationary Navier-Stokes equations show substantial speedups of up to 20X compared to multi-core CPU implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05047v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Manuel Liebchen, Robert Jendersie, Utku Kaya, Christian Lessig, Thomas Richter</dc:creator>
    </item>
    <item>
      <title>Functional normalizing flow for statistical inverse problems of partial differential equations</title>
      <link>https://arxiv.org/abs/2411.13277</link>
      <description>arXiv:2411.13277v2 Announce Type: replace 
Abstract: Inverse problems of partial differential equations are ubiquitous across various scientific disciplines and can be formulated as statistical inference problems using Bayes' theorem. To address large-scale problems, it is crucial to develop discretization-invariant algorithms, which can be achieved by formulating methods directly in infinite-dimensional space. We propose a novel normalizing flow based infinite-dimensional variational inference method (NF-iVI) to extract posterior information efficiently. Specifically, by introducing well-defined transformations, the prior in Bayes' formula is transformed into post-transformed measures that approximate the posterior. To circumvent the issue of mutually singular probability measures, we formulate general conditions for the employed transformations. As guiding principles, these conditions yield four concrete transformations. Additionally, to minimize computational demands, we have developed a conditional normalizing flow variant, termed CNF-iVI, which is adapt at processing measurement data of varying dimensions while requiring minimal computational resources. We apply the proposed algorithms to three typical inverse problems governed by the simple smooth equation, the steady-state Darcy flow equation, and the electric impedance tomography. Numerical results confirm our theoretical findings, illustrate the efficiency of our algorithms, and verify the discretization-invariant property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13277v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Zhao, Haoyu Lu, Junxiong Jia, Tao Zhou</dc:creator>
    </item>
    <item>
      <title>Implementation of neural network operators with applications to remote sensing data</title>
      <link>https://arxiv.org/abs/2412.00375</link>
      <description>arXiv:2412.00375v2 Announce Type: replace 
Abstract: In this paper, we provide two algorithms based on the theory of multidimensional neural network (NN) operators activated by hyperbolic tangent sigmoidal functions. Theoretical results are recalled to justify the performance of the here implemented algorithms. Specifically, the first algorithm models multidimensional signals (such as digital images), while the second one addresses the problem of rescaling and enhancement of the considered data. We discuss several applications of the NN-based algorithms for modeling and rescaling/enhancement remote sensing data (represented as images), with numerical experiments conducted on a selection of remote sensing (RS) images from the (open access) RETINA dataset. A comparison with classical interpolation methods, such as bilinear and bicubic interpolation, shows that the proposed algorithms outperform the others, particularly in terms of the Structural Similarity Index (SSIM).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00375v2</guid>
      <category>math.NA</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Danilo Costarelli, Michele Piconi</dc:creator>
    </item>
    <item>
      <title>Linear minimum-variance approximants for noisy data</title>
      <link>https://arxiv.org/abs/2412.01287</link>
      <description>arXiv:2412.01287v4 Announce Type: replace 
Abstract: Inspired by recent developments in subdivision schemes founded on the Weighted Least Squares technique, we construct linear approximants for noisy data in which the weighting strategy minimizes the output variance, thereby establishing a direct correspondence with the Generalized Least Squares and the Minimum-Variance Formulas methodologies. By introducing annihilation-operators for polynomial spaces, we derive usable formulas that are optimal for general correlated non-uniform noise. We show that earlier subdivision rules are optimal for uncorrelated non-uniform noise and, finally, we present numerical evidence to confirm that, in the correlated case, the proposed approximants are better than those currently used in the subdivision literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01287v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.apnum.2025.12.002</arxiv:DOI>
      <dc:creator>Sergio L\'opez Ure\~na, Dionisio F. Y\'a\~nez</dc:creator>
    </item>
    <item>
      <title>Optimal sensor placement under model uncertainty in the weak-constraint 4D-Var framework</title>
      <link>https://arxiv.org/abs/2502.00150</link>
      <description>arXiv:2502.00150v3 Announce Type: replace 
Abstract: In data assimilation, the model may be subject to uncertainties and errors. The weak-constraint data assimilation framework enables incorporating model uncertainty in the dynamics of the governing equations. We propose a new framework for near-optimal sensor placement in the weak-constrained setting. This is achieved by first deriving a design criterion based on the expected information gain, which involves the Kullback-Leibler divergence from the forecast prior to the posterior distribution. An explicit formula for this criterion is provided, assuming that the model error and background are independent and Gaussian and the dynamics are linear. We discuss algorithmic approaches to efficiently evaluate this criterion through randomized approximations. To provide further insight and flexibility in computations, we also provide alternative expressions for the criteria. We provide an algorithm to find near-optimal experimental designs using column subset selection, including a randomized algorithm that avoids computing the adjoint of the forward operator. Through numerical experiments in one and two spatial dimensions, we show the effectiveness of our proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00150v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alen Alexanderian, Hugo D\'iaz, Vishwas Rao, Arvind K. Saibaba</dc:creator>
    </item>
    <item>
      <title>A Reynolds-semi-robust method with hybrid velocity and pressure for the unsteady incompressible Navier--Stokes equations</title>
      <link>https://arxiv.org/abs/2502.15293</link>
      <description>arXiv:2502.15293v2 Announce Type: replace 
Abstract: In this paper we propose and analyze a new Finite Element method for the solution of the two- and three-dimensional incompressible Navier--Stokes equations based on a hybrid discretization of both the velocity and pressure variables. The proposed method is pressure-robust, i.e., irrotational forcing terms do not affect the approximation of the velocity, and Reynolds-quasi-robust, with error estimates that, for smooth enough exact solutions, do not depend on the inverse of the viscosity. We carry out an in-depth convergence analysis highlighting pre-asymptotic convergence rates and validate the theoretical findings with a complete set of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15293v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1137/25M1736104</arxiv:DOI>
      <arxiv:journal_reference>SIAM J. Numer. Anal., 2025, Vol. 63, No. 6, pp. 2317--2342</arxiv:journal_reference>
      <dc:creator>Louren\c{c}o Beir\~ao da Veiga, Daniele A. Di Pietro, J\'er\^ome Droniou, Kirubell B. Haile, Thomas J. Radley</dc:creator>
    </item>
    <item>
      <title>Surface stability of a layered magnetoelastic half-space</title>
      <link>https://arxiv.org/abs/2505.10660</link>
      <description>arXiv:2505.10660v2 Announce Type: replace 
Abstract: We evaluate the conditions for surface stability of a layered magnetoelastic half-space subjected to large deformations and a magnetic field. After reviewing the fundamental measures of deformation and summarizing the magnetostatic equations in Eulerian and Lagrangian forms, we derive the constitutive relations from a total energy function dependent on the deformation gradient and Lagrangian magnetic induction. Energy principles yield the equilibrium equations, magnetic field equations, and boundary conditions. The second variation of the energy functional provides the incremental equations and conditions for stability analysis. Surface instability is studied by linearizing increments of deformation and magnetic induction about a finitely deformed state under a magnetic field normal to the surface. Four illustrative cases are considered: (i) a layered non-magnetizable half-space with varying stiffness contrast; (ii) the critical stretch of a magnetoelastic half-space as a function of magnetic induction; (iii) surface stability of a magneto-sensitive layer atop a non-magnetizable substrate; and (iv) bifurcation conditions in a two-layered magnetoelastic solid with different stiffness ratios. Graphical results are provided throughout.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10660v2</guid>
      <category>math.NA</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ijsolstr.2025.113807</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Solids and Structures, 327, 113807</arxiv:journal_reference>
      <dc:creator>Davood Shahsavari, Luis Dorfmann, Prashant Saxena</dc:creator>
    </item>
    <item>
      <title>A sparse $hp$-finite element method for piecewise-smooth differential equations with periodic boundary conditions</title>
      <link>https://arxiv.org/abs/2505.17849</link>
      <description>arXiv:2505.17849v2 Announce Type: replace 
Abstract: We develop an efficient $hp$-finite element method for piecewise-smooth differential equations with periodic boundary conditions, using orthogonal polynomials defined on circular arcs. The operators derived from this basis are banded and achieve optimal complexity regardless of $h$ or $p$, both for building the discretisation and solving the resulting linear system in the case where the operator is symmetric positive definite. The basis serves as a useful alternative to other bases such as the Fourier or integrated Legendre bases, especially for problems with discontinuities. We relate the convergence properties of these bases to regions of analyticity in the complex plane, and further use several differential equation examples to demonstrate these properties. The basis spans the low order eigenfunctions of constant coefficient differential operators, thereby achieving better smoothness properties for time-evolution partial differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17849v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel VandenHeuvel, Sheehan Olver</dc:creator>
    </item>
    <item>
      <title>Fast and Simple Multiclass Data Segmentation: An Eigendecomposition and Projection-Free Approach</title>
      <link>https://arxiv.org/abs/2508.09738</link>
      <description>arXiv:2508.09738v2 Announce Type: replace 
Abstract: Graph-based machine learning has seen an increased interest over the last decade with many connections to other fields of applied mathematics. Learning based on partial differential equations, such as the phase-field Allen-Cahn equation, allows efficient handling of semi-supervised learning approaches on graphs. The numerical solution of the graph Allen-Cahn equation via a convexity splitting or the Merriman-Bence-Osher (MBO) scheme, albeit being a widely used approach, requires the calculation of a graph Laplacian eigendecomposition and repeated projections over the unit simplex to maintain valid partitions. The computational efficiency of those methods is hence limited by those two bottlenecks in practice, especially when dealing with large-scale instances. In order to overcome these limitations, we propose a new framework combining a novel penalty-based reformulation of the segmentation problem, which ensures valid partitions (i.e., binary solutions) for appropriate parameter choices, with an eigendecomposition and projection-free optimization scheme, which has a small per-iteration complexity (by relying primarily on sparse matrix-vector products) and guarantees good convergence properties. Experiments on synthetic and real-world datasets related to data segmentation in networks and images demonstrate that the proposed framework achieves comparable or better accuracy than the CS and MBO methods while being significantly faster, particularly for large-scale problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09738v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chiara Faccio, Margherita Porcelli, Francesco Rinaldi, Martin Stoll</dc:creator>
    </item>
    <item>
      <title>Development of numerical methods for nonlinear hybrid stochastic functional differential equations with infinite delay</title>
      <link>https://arxiv.org/abs/2509.00475</link>
      <description>arXiv:2509.00475v3 Announce Type: replace 
Abstract: This paper addresses the challenging numerical simulation of nonlinear hybrid stochastic functional differential equations with infinite delays. We first propose an explicit scheme using space and time truncation, requiring only finite historical storage. Leveraging approximation theory, we prove the boundedness of the numerical solution's $p$th moment and establish its convergence, achieving a rate of $1/2$ order under polynomially growing coefficients. Furthermore, we refine the scheme to better capture the underlying exponential stability of the exact solution, in both moment and almost sure senses. Finally, numerical experiments are presented to validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00475v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guozhen Li, Xiaoyue Li, Xuerong Mao</dc:creator>
    </item>
    <item>
      <title>General transformation neural networks: A class of parametrized functions for high-dimensional function approximation</title>
      <link>https://arxiv.org/abs/2510.20142</link>
      <description>arXiv:2510.20142v2 Announce Type: replace 
Abstract: We propose a novel class of neural network-like parametrized functions, i.e., general transformation neural networks (GTNNs), for high-dimensional approximation. Conventional deep neural networks sometimes perform less accurately in approximation problems under gradient descent training, especially when the target function is oscillatory. To improve accuracy, we generalize the affine transformation of the abstract neuron to more general functions that serve as complex shape functions and have greater capacity. Specifically, we discuss three types of GTNNs in detail: the cubic, quadratic, and trigonometric transformation neural networks (CTNNs, QTNNs, and TTNNs). We perform an approximation error analysis of GTNNs, presenting their universal approximation properties for continuous functions and error bounds for smooth and Barron-type functions. Several numerical examples of regression problems and partial differential equations are presented, demonstrating that CTNNs/QTNNs/TTNNs achieve higher accuracy and greater robustness than conventional fully connected neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20142v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyang Wang, Yiqi Gu</dc:creator>
    </item>
    <item>
      <title>Error Estimates for Sparse Tensor Products of B-spline Approximation Spaces</title>
      <link>https://arxiv.org/abs/2510.21517</link>
      <description>arXiv:2510.21517v3 Announce Type: replace 
Abstract: This work introduces and analyzes B-spline approximation spaces defined on general geometric domains obtained through a mapping from a parameter domain. These spaces are constructed as sparse-grid tensor products of univariate spaces in the parameter domain and are mapped to the physical domain via a geometric parametrization. Both the univariate approximation spaces and the geometric mapping are built using maximally smooth B-splines. We construct two such spaces, employing either the sparse-grid combination technique or the hierarchical subspace decomposition of sparse-grid tensor products, and we prove their mathematical equivalence. Furthermore, we derive approximation error estimates and inverse inequalities that highlight the advantages of sparse-grid tensor products. Specifically, under suitable regularity assumptions on the solution, these spaces achieve the same approximation order as standard tensor product spaces while using significantly fewer degrees of freedom. Additionally, our estimates indicate that, in the case of non-tensor-product domains, stronger regularity assumptions on the solution -- particularly concerning isotropic (non-mixed) derivatives -- are required to achieve optimal convergence rates compared to sparse-grid methods defined on tensor-product domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21517v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cl\'ement Guillet</dc:creator>
    </item>
    <item>
      <title>A Robust GPU-Accelerated Kernel Compensation Solver with Novel Discretization for Photonic Crystals in Pseudochiral Media</title>
      <link>https://arxiv.org/abs/2511.17107</link>
      <description>arXiv:2511.17107v2 Announce Type: replace 
Abstract: This paper develops a robust solver for the Maxwell eigenproblem in 3D photonic crystals (PCs) with pseudochiral media. The solver employs the Kernel Compensation technique under the framework of Yee's scheme to eliminate null space and enable matrix-free, GPU-accelerated operations via 3D discrete Fourier transform (DFT). Furthermore, we propose a novel discretization for permittivity tensor containing off-diagonal entries and rigorously prove that the resulting matrix is Hermitian positive definite (HPD), which ensures the correctness of the kernel compensation technique. Numerical experiments on several benchmark examples are demonstrated to validate the robustness and accuracy of our scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17107v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenhao Jin, Hehu Xie</dc:creator>
    </item>
    <item>
      <title>The Reduced Basis Multigrid scheme for the Virtual Element Method</title>
      <link>https://arxiv.org/abs/2511.22219</link>
      <description>arXiv:2511.22219v2 Announce Type: replace 
Abstract: We present a non-nested W-cycle multigrid scheme for the lowest order Virtual Element Method on polygonal meshes. To avoid the implicit definition of the Virtual Element space, which poses several issues in the computation of intergrid operators that underpin multigrid methods, the proposed scheme uses a fully-conforming auxiliary space constructed by cheaply computing the virtual basis functions via the reduced basis method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22219v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paola F. Antonietti, Silvia Bertoluzza, Fabio Credali</dc:creator>
    </item>
    <item>
      <title>Interpretation of a Discrete de Rham method as a Finite Element System</title>
      <link>https://arxiv.org/abs/2512.05912</link>
      <description>arXiv:2512.05912v2 Announce Type: replace 
Abstract: We show that the DDR method can be interpreted as defining a computable consistent discrete $\mathrm{L}^2$ product on a conforming FES defined by PDEs. Without modifying the numerical method itself, this point of view provides an alternative approach to the analysis. The conformity and consistency properties we obtain are stronger than those previously shown, even in low dimensions. We can also recover some of the other results that have been proved about DDR, from those that have already been proved, in principle, in the general context of FES. We also bring VEM, the Virtual Element Method, into the discussion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05912v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Snorre H. Christiansen, Francesca Rapetti</dc:creator>
    </item>
    <item>
      <title>Projected Sobolev Natural Gradient Descent for Neural Variational Monte Carlo Solution of the Gross-Pitaevskii Equation</title>
      <link>https://arxiv.org/abs/2512.11339</link>
      <description>arXiv:2512.11339v2 Announce Type: replace 
Abstract: This paper proposes a neural variational Monte Carlo method based on deep neural networks to solve the Gross-Pitaevskii equation (GPE) via projected Sobolev natural gradient descent (NGD). Adopting an "optimize-then-discretize" strategy, we first apply a constraint-preserving continuous Riemannian gradient flow on an infinite-dimensional Riemannian manifold, which is subsequently mapped to the neural network parameter space via Galerkin projection. This process naturally induces a Sobolev energy metric that incorporates physical information, effectively mitigating stiffness during optimization. To address the explicit dependence on the normalization constant caused by the nonlinear interaction term in the GPE, we design a hybrid sampling strategy combining an integration stream and a MCMC stream to achieve precise estimation of the generalized Gram matrix and energy gradients. Numerical experiments on benchmark cases, including the harmonic oscillator potential in the strong interaction limit and multi-scale optical lattice potentials, demonstrate the high accuracy of the proposed method. Furthermore, it achieves an order-of-magnitude acceleration in convergence compared to standard optimizers like Adam, exhibiting superior robustness in handling strong nonlinearities and complex geometric constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11339v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenglong Bao, Chen Cui, Kai Jiang, Shi Shu</dc:creator>
    </item>
    <item>
      <title>Variational Markov chain mixtures with automatic component selection</title>
      <link>https://arxiv.org/abs/2406.04653</link>
      <description>arXiv:2406.04653v2 Announce Type: replace-cross 
Abstract: Markov state modeling has gained popularity in various scientific fields since it reduces complex time-series data sets into transitions between a few states. Yet common Markov state modeling frameworks assume a single Markov chain describes the data, so they suffer from an inability to discern heterogeneities. As an alternative, this paper models time-series data using a mixture of Markov chains, and it automatically determines the number of mixture components using the variational expectation-maximization algorithm.Variational EM simultaneously identifies the number of Markov chains and the dynamics of each chain without expensive model comparisons or posterior sampling. As a theoretical contribution, this paper identifies the natural limits of Markov state mixture modeling by proving a lower bound on the classification error. It then presents numerical experiments where variational EM achieves performance consistent with the theoretically optimal error scaling. The experiments are based on synthetic and observational data sets including Last.fm music listening, ultramarathon running, and gene expression. In each of the three data sets, variational EM leads to the identification of meaningful heterogeneities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04653v2</guid>
      <category>stat.ME</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher E. Miles, Robert J. Webber</dc:creator>
    </item>
    <item>
      <title>Continuum Attention for Neural Operators</title>
      <link>https://arxiv.org/abs/2406.06486</link>
      <description>arXiv:2406.06486v4 Announce Type: replace-cross 
Abstract: Transformers, and the attention mechanism in particular, have become ubiquitous in machine learning. Their success in modeling nonlocal, long-range correlations has led to their widespread adoption in natural language processing, computer vision, and time series problems. Neural operators, which map spaces of functions into spaces of functions, are necessarily both nonlinear and nonlocal if they are universal; it is thus natural to ask whether the attention mechanism can be used in the design of neural operators. Motivated by this, we study transformers in the function space setting. We formulate attention as a map between infinite dimensional function spaces and prove that the attention mechanism as implemented in practice is a Monte Carlo or finite difference approximation of this operator. The function space formulation allows for the design of transformer neural operators, a class of architectures designed to learn mappings between function spaces. In this paper, we state and prove the first universal approximation result for transformer neural operators, using only a slight modification of the architecture implemented in practice. The prohibitive cost of applying the attention operator to functions defined on multi-dimensional domains leads to the need for more efficient attention-based architectures. For this reason we also introduce a function space generalization of the patching strategy from computer vision, and introduce a class of associated neural operators. Numerical results, on an array of operator learning problems, demonstrate the promise of our approaches to function space formulations of attention and their use in neural operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06486v4</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edoardo Calvello, Nikola B. Kovachki, Matthew E. Levine, Andrew M. Stuart</dc:creator>
    </item>
    <item>
      <title>Stable EEG Source Estimation for Standardized Kalman Filter using Change Rate Tracking</title>
      <link>https://arxiv.org/abs/2504.01984</link>
      <description>arXiv:2504.01984v2 Announce Type: replace-cross 
Abstract: This article focuses on the measurement and evolution modeling of Standardized Kalman filtering for brain activity estimation using non-invasive electroencephalography data. Here, we propose new parameter tuning and a model that uses the rate of change in the brain activity distribution to improve the stability of otherwise accurate estimates. Namely, we propose a backward-differentiation-based measurement model for the change rate, which notably improves the filtering-parametrization-stability of the tracking. Simulated data and data from a real subject were used in experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01984v2</guid>
      <category>stat.AP</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Joonas Lahtinen</dc:creator>
    </item>
    <item>
      <title>Density estimation via periodic scaled Korobov kernel method with exponential decay condition</title>
      <link>https://arxiv.org/abs/2506.15419</link>
      <description>arXiv:2506.15419v2 Announce Type: replace-cross 
Abstract: We propose the periodic scaled Korobov kernel (PSKK) method for nonparametric density estimation on $\mathbb{R}^d$. By first wrapping the target density into a periodic version through modulo operation and subsequently applying kernel ridge regression in scaled Korobov spaces, we extend the kernel approach proposed by Kazashi and Nobile (SIAM J. Numer. Anal., 2023) and eliminate its requirement for inherent periodicity of the density function. This key modification enables effective estimation of densities defined on unbounded domains. We establish rigorous mean integrated squared error (MISE) bounds, proving that for densities with smoothness of order $\alpha$ and exponential decay, our PSKK method achieves an $\mathcal{O}(M^{-1/(1+1/(2\alpha)+\epsilon)})$ MISE convergence rate with an arbitrarily small $\epsilon&gt;0$. While matching the convergence rate of the previous kernel approach, our method applies to non-periodic distributions at the cost of stronger differentiability and exponential decay assumptions. Numerical experiments confirm the theoretical results and demonstrate a significant improvement over traditional kernel density estimation in large-sample regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15419v2</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyang Ye, Haoyuan Tan, Xiaoqun Wang, Zhijian He</dc:creator>
    </item>
    <item>
      <title>On the statistical convergence of N-body simulations of the Solar System</title>
      <link>https://arxiv.org/abs/2507.04987</link>
      <description>arXiv:2507.04987v2 Announce Type: replace-cross 
Abstract: Most direct N-body integrations of planetary systems use a symplectic integrator with a fixed timestep. A large timestep is desirable in order to speed up the numerical simulations. However, simulations yield unphysical results if the timestep is too large. Surprisingly, no systematic convergence study has been performed on long (Gyr) timescales. In this paper we present numerical experiments to determine the minimum timestep one has to use in long-term integrations of the Solar System in order to recover the system's fundamental secular frequencies and instability rate. We find that timesteps of up to 32 days, i.e. a third of Mercury's orbital period, yield physical results in an ensemble of 5 Gyr integrations. We argue that the chaotic diffusion that drives the Solar System's long-term evolution dominates over numerical diffusion and timestep resonances. Our results bolster confidence that the statistical results of most simulations in the literature are indeed physical and provide guidance on how to run time and energy efficient simulations while making sure results can be trusted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04987v2</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hanno Rein, Garett Brown, Mei Kanda</dc:creator>
    </item>
    <item>
      <title>GenUQ: Predictive Uncertainty Estimates via Generative Hyper-Networks</title>
      <link>https://arxiv.org/abs/2509.21605</link>
      <description>arXiv:2509.21605v2 Announce Type: replace-cross 
Abstract: Operator learning is a recently developed generalization of regression to mappings between functions. It promises to drastically reduce expensive numerical integration of PDEs to fast evaluations of mappings between functional states of a system, i.e., surrogate and reduced-order modeling. Operator learning has already found applications in several areas such as modeling sea ice, combustion, and atmospheric physics. Recent approaches towards integrating uncertainty quantification into the operator models have relied on likelihood based methods to infer parameter distributions from noisy data. However, stochastic operators may yield actions from which a likelihood is difficult or impossible to construct. In this paper, we introduce, GenUQ, a measure-theoretic approach to UQ that avoids constructing a likelihood by introducing a generative hyper-network model that produces parameter distributions consistent with observed data. We demonstrate that GenUQ outperforms other UQ methods in three example problems, recovering a manufactured operator, learning the solution operator to a stochastic elliptic PDE, and modeling the failure location of porous steel under tension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21605v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tian Yu Yen, Reese E. Jones, Ravi G. Patel</dc:creator>
    </item>
    <item>
      <title>Guaranteeing Higher Order Convergence Rates for Accelerated Wasserstein Gradient Flow Schemes</title>
      <link>https://arxiv.org/abs/2511.10884</link>
      <description>arXiv:2511.10884v2 Announce Type: replace-cross 
Abstract: In this paper, we study higher-order-accurate-in-time minimizing movements schemes for Wasserstein gradient flows. We introduce a novel accelerated second-order scheme, leveraging the differential structure of the Wasserstein space in both Eulerian and Lagrangian coordinates. For sufficiently smooth energy functionals, we show that our scheme provably achieves an optimal quadratic convergence rate. Under the weaker assumptions of Wasserstein differentiability and $\lambda$-displacement convexity (for any $\lambda\in \mathbb{R}$), we show that our scheme still achieves a first-order convergence rate and has strong numerical stability. In particular, we show that the energy is nearly monotone in general, while when the energy is $L$-smooth and $\lambda$-displacement convex (with $\lambda&gt;0$), we prove the energy is non-increasing and the norm of the Wasserstein gradient is exponentially decreasing along the iterates. Taken together, our work provides the first fully rigorous proof of accelerated second-order convergence rates for smooth functionals and shows that the scheme performs no worse than the classical scheme JKO scheme for functionals that are $\lambda$-displacement convex and Wasserstein differentiable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10884v2</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raymond Chu, Matt Jacobs</dc:creator>
    </item>
    <item>
      <title>Accurate Models of NVIDIA Tensor Cores</title>
      <link>https://arxiv.org/abs/2512.07004</link>
      <description>arXiv:2512.07004v2 Announce Type: replace-cross 
Abstract: Matrix multiplication is a fundamental operation in for both training of neural networks and inference. To accelerate matrix multiplication, Graphical Processing Units (GPUs) provide it implemented in hardware. Due to the increased throughput over the software-based matrix multiplication, the multipliers are increasingly used outside of AI, to accelerate various applications in scientific computing. However, matrix multipliers targeted at AI are at present not compliant with IEEE 754 floating-point arithmetic behaviour, with different vendors offering different numerical features. This leads to non-reproducible results across different generations of GPU architectures, at the matrix multiply-accumulate instruction level. To study numerical characteristics of matrix multipliers-such as rounding behaviour, accumulator width, normalization points, extra carry bits, and others-test vectors are typically constructed. Yet, these vectors may or may not distinguish between different hardware models, and due to limited hardware availability, their reliability across many different platforms remains largely untested. We present software models for emulating the inner product behavior of low- and mixed-precision matrix multipliers in the V100, A100, H100 and B200 data center GPUs in most supported input formats of interest to mixed-precision algorithm developers: 8-, 16-, and 19-bit floating point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07004v2</guid>
      <category>cs.MS</category>
      <category>cs.AR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faizan A. Khattak, Mantas Mikaitis</dc:creator>
    </item>
  </channel>
</rss>
