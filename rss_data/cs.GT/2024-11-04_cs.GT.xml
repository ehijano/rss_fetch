<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Nov 2024 05:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Constrained Fair and Efficient Allocations</title>
      <link>https://arxiv.org/abs/2411.00133</link>
      <description>arXiv:2411.00133v1 Announce Type: new 
Abstract: Fairness and efficiency have become the pillars of modern fair division research, but prior work on achieving both simultaneously is largely limited to the unconstrained setting. We study fair and efficient allocations of indivisible goods under additive valuations and various types of allocation feasibility constraints, and demonstrate the unreasonable effectiveness of the maximum Nash welfare (MNW) solution in this previously uncharted territory.
  Our main result is that MNW allocations are 1/2-envy-free up to one good (EF1) and Pareto optimal under the broad family of (arbitrary) matroid constraints. We extend these guarantees to complete MNW allocations for base-orderable matroid constraints, and to a family of non-matroidal constraints (which includes balancedness) using a novel "alternate worlds" technique. We establish tightness of our results by providing counterexamples for the satisfiability of certain stronger desiderata, but show an improved result for the special case of goods with copies (Gafni et al. 2023). Finally, we also establish novel best-of-both-worlds guarantees for goods with copies and balancedness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00133v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Cookson, Soroush Ebadian, Nisarg Shah</dc:creator>
    </item>
    <item>
      <title>Efficient Multi-Agent Delegated Search</title>
      <link>https://arxiv.org/abs/2411.00181</link>
      <description>arXiv:2411.00181v1 Announce Type: new 
Abstract: Consider a principal who wants to search through a space of stochastic solutions for one maximizing their utility. If the principal cannot conduct this search on their own, they may instead delegate this problem to an agent with distinct and potentially misaligned utilities. This is called delegated search, and the principal in such problems faces a mechanism design problem in which they must incentivize the agent to find and propose a solution maximizing the principal's expected utility. Following prior work in this area, we consider mechanisms without payments and aim to achieve a multiplicative approximation of the principal's utility when they solve the problem without delegation.
  In this work, we investigate a natural and recently studied generalization of this model to multiple agents and find nearly tight bounds on the principal's approximation as the number of agents increases. As one might expect, this approximation approaches 1 with increasing numbers of agents, but, somewhat surprisingly, we show that this is largely not due to direct competition among agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00181v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Curtis Bechtel, Shaddin Dughmi</dc:creator>
    </item>
    <item>
      <title>Towards Data Valuation via Asymmetric Data Shapley</title>
      <link>https://arxiv.org/abs/2411.00388</link>
      <description>arXiv:2411.00388v1 Announce Type: new 
Abstract: As data emerges as a vital driver of technological and economic advancements, a key challenge is accurately quantifying its value in algorithmic decision-making. The Shapley value, a well-established concept from cooperative game theory, has been widely adopted to assess the contribution of individual data sources in supervised machine learning. However, its symmetry axiom assumes all players in the cooperative game are homogeneous, which overlooks the complex structures and dependencies present in real-world datasets. To address this limitation, we extend the traditional data Shapley framework to asymmetric data Shapley, making it flexible enough to incorporate inherent structures within the datasets for structure-aware data valuation. We also introduce an efficient $k$-nearest neighbor-based algorithm for its exact computation. We demonstrate the practical applicability of our framework across various machine learning tasks and data market contexts. The code is available at: https://github.com/xzheng01/Asymmetric-Data-Shapley.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00388v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xi Zheng, Xiangyu Chang, Ruoxi Jia, Yong Tan</dc:creator>
    </item>
    <item>
      <title>Spatial public goods games on any population structure</title>
      <link>https://arxiv.org/abs/2411.00398</link>
      <description>arXiv:2411.00398v1 Announce Type: new 
Abstract: Understanding the emergence of cooperation in spatially structured populations has advanced significantly in the context of pairwise games, but the fundamental theory of group-based public goods games (PGGs) remains less explored. Here, we provide theoretical conditions under which cooperation thrive in spatial PGGs on any population structure, which are accurate under weak selection. We find that PGGs can support cooperation across all kinds of model details and on almost all network structures in contrast to pairwise games. For example, a class of networks that would otherwise fail to produce cooperation, such as star graphs, are particularly conducive to cooperation in spatial PGGs. This fundamental advantage of spatial PGGs derives from reciprocity through second-order interactions, allowing local structures such as the clustering coefficient to play positive roles. We also verify the robustness of spatial PGGs on empirical networks where pairwise games cannot support cooperation, which implies that PGGs could be a universal interaction mode in real-world systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00398v1</guid>
      <category>cs.GT</category>
      <category>nlin.CG</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chaoqian Wang, Qi Su</dc:creator>
    </item>
    <item>
      <title>Probabilistic Obstruction Temporal Logic: a Probabilistic Logic to Reason about Dynamic Models</title>
      <link>https://arxiv.org/abs/2411.00025</link>
      <description>arXiv:2411.00025v1 Announce Type: cross 
Abstract: In this paper, we propose a novel formalism called Probabilistic Obstruction Temporal Logic (POTL), which extends Obstruction Logic (OL) by incorporating probabilistic elements. POTL provides a robust framework for reasoning about the probabilistic behaviors and strategic interactions between attackers and defenders in environments where probabilistic events influence outcomes. We explore the model checking complexity of POTL and demonstrate that it is not higher than that of Probabilistic Computation Tree Logic (PCTL), making it both expressive and computationally feasible for cybersecurity and privacy applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00025v1</guid>
      <category>cs.LO</category>
      <category>cs.GT</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean Leneutre, Vadim Malvone, James Ortiz</dc:creator>
    </item>
    <item>
      <title>Towards the Usage of Window Counting Constraints in the Synthesis of Reactive Systems to Reduce State Space Explosion</title>
      <link>https://arxiv.org/abs/2411.00048</link>
      <description>arXiv:2411.00048v1 Announce Type: cross 
Abstract: The synthesis of reactive systems aims for the automated construction of strategies for systems that interact with their environment. Whereas the synthesis approach has the potential to change the development of reactive systems significantly due to the avoidance of manual implementation, it still suffers from a lack of efficient synthesis algorithms for many application scenarios. The translation of the system specification into an automaton that allows for strategy construction is nonelementary in the length of the specification in S1S and double exponential for LTL, raising the need of highly specialized algorithms.  In this paper, we present an approach on how to reduce this state space explosion in the construction of this automaton by exploiting a monotony property of specifications. For this, we introduce window counting constraints that allow for step-wise refinement or abstraction of specifications. In an iterating synthesis procedure, those window counting constraints are used to construct automata representing over- or under-approximations (depending on the counting constraint) of constraint-compliant behavior. Analysis results on winning regions of previous iterations are used to reduce the size of the next automaton, leading to an overall reduction of the state space explosion extend. We present the implementation results of the iterated synthesis for a zero-sum game setting as proof of concept. Furthermore, we discuss the current limitations of the approach in a zero-sum setting and sketch future work in non-zero-sum settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00048v1</guid>
      <category>cs.LO</category>
      <category>cs.GT</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.409.8</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 409, 2024, pp. 53-69</arxiv:journal_reference>
      <dc:creator>Linda Feeken, Martin Fr\"anzle</dc:creator>
    </item>
    <item>
      <title>ADAPT: A Game-Theoretic and Neuro-Symbolic Framework for Automated Distributed Adaptive Penetration Testing</title>
      <link>https://arxiv.org/abs/2411.00217</link>
      <description>arXiv:2411.00217v1 Announce Type: cross 
Abstract: The integration of AI into modern critical infrastructure systems, such as healthcare, has introduced new vulnerabilities that can significantly impact workflow, efficiency, and safety. Additionally, the increased connectivity has made traditional human-driven penetration testing insufficient for assessing risks and developing remediation strategies. Consequently, there is a pressing need for a distributed, adaptive, and efficient automated penetration testing framework that not only identifies vulnerabilities but also provides countermeasures to enhance security posture. This work presents ADAPT, a game-theoretic and neuro-symbolic framework for automated distributed adaptive penetration testing, specifically designed to address the unique cybersecurity challenges of AI-enabled healthcare infrastructure networks. We use a healthcare system case study to illustrate the methodologies within ADAPT. The proposed solution enables a learning-based risk assessment. Numerical experiments are used to demonstrate effective countermeasures against various tactical techniques employed by adversarial AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00217v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haozhe Lei, Yunfei Ge, Quanyan Zhu</dc:creator>
    </item>
    <item>
      <title>A decomposition from a substitutable many-to-one matching market to a one-to-one matching market</title>
      <link>https://arxiv.org/abs/2411.00564</link>
      <description>arXiv:2411.00564v1 Announce Type: cross 
Abstract: For a many-to-one market with substitutable preferences on the firm's side, based on the Aizerman-Malishevski decomposition, we define an associated one-to-one market. Given that the usual notion of stability for a one-to-one market does not fit well for this associated one-to-one market, we introduce a new notion of stability. This notion allows us to establish an isomorphism between the set of stable matchings in the many-to-one market and the matchings in the associated one-to-one market that meet this new stability criterion. Furthermore, we present an adaptation of the well-known deferred acceptance algorithm to compute a matching that satisfies this new notion of stability for the associated one-to-one market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00564v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Pablo Neme, Jorge Oviedo</dc:creator>
    </item>
    <item>
      <title>Learning in Markov Games with Adaptive Adversaries: Policy Regret, Fundamental Barriers, and Efficient Algorithms</title>
      <link>https://arxiv.org/abs/2411.00707</link>
      <description>arXiv:2411.00707v1 Announce Type: cross 
Abstract: We study learning in a dynamically evolving environment modeled as a Markov game between a learner and a strategic opponent that can adapt to the learner's strategies. While most existing works in Markov games focus on external regret as the learning objective, external regret becomes inadequate when the adversaries are adaptive. In this work, we focus on \emph{policy regret} -- a counterfactual notion that aims to compete with the return that would have been attained if the learner had followed the best fixed sequence of policy, in hindsight. We show that if the opponent has unbounded memory or if it is non-stationary, then sample-efficient learning is not possible. For memory-bounded and stationary, we show that learning is still statistically hard if the set of feasible strategies for the learner is exponentially large. To guarantee learnability, we introduce a new notion of \emph{consistent} adaptive adversaries, wherein, the adversary responds similarly to similar strategies of the learner. We provide algorithms that achieve $\sqrt{T}$ policy regret against memory-bounded, stationary, and consistent adversaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00707v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thanh Nguyen-Tang, Raman Arora</dc:creator>
    </item>
    <item>
      <title>Generalized Principal-Agent Problem with a Learning Agent</title>
      <link>https://arxiv.org/abs/2402.09721</link>
      <description>arXiv:2402.09721v4 Announce Type: replace 
Abstract: Classic principal-agent problems such as Stackelberg games, contract design, and Bayesian persuasion, often assume that the agent is able to best respond to the principal's committed strategy. We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction, we show that: (1) If the agent uses contextual no-regret learning algorithms with regret $\mathrm{Reg}(T)$, then the principal can guarantee utility at least $U^* - \Theta\big(\sqrt{\tfrac{\mathrm{Reg}(T)}{T}}\big)$, where $U^*$ is the principal's optimal utility in the classic model with a best-responding agent. (2) If the agent uses contextual no-swap-regret learning algorithms with swap-regret $\mathrm{SReg}(T)$, then the principal cannot obtain utility more than $U^* + O(\frac{\mathrm{SReg(T)}}{T})$. But (3) if the agent uses mean-based learning algorithms (which can be no-regret but not no-swap-regret), then the principal can sometimes do significantly better than $U^*$. These results not only refine previous results in Stackelberg games and contract design, but also lead to new results for Bayesian persuasion with a learning agent and all generalized principal-agent problems where the agent does not have private information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09721v4</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Lin, Yiling Chen</dc:creator>
    </item>
    <item>
      <title>Unveiling User Satisfaction and Creator Productivity Trade-Offs in Recommendation Platforms</title>
      <link>https://arxiv.org/abs/2410.23683</link>
      <description>arXiv:2410.23683v2 Announce Type: replace 
Abstract: On User-Generated Content (UGC) platforms, recommendation algorithms significantly impact creators' motivation to produce content as they compete for algorithmically allocated user traffic. This phenomenon subtly shapes the volume and diversity of the content pool, which is crucial for the platform's sustainability. In this work, we demonstrate, both theoretically and empirically, that a purely relevance-driven policy with low exploration strength boosts short-term user satisfaction but undermines the long-term richness of the content pool. In contrast, a more aggressive exploration policy may slightly compromise user satisfaction but promote higher content creation volume. Our findings reveal a fundamental trade-off between immediate user satisfaction and overall content production on UGC platforms. Building on this finding, we propose an efficient optimization method to identify the optimal exploration strength, balancing user and creator engagement. Our model can serve as a pre-deployment audit tool for recommendation algorithms on UGC platforms, helping to align their immediate objectives with sustainable, long-term goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23683v2</guid>
      <category>cs.GT</category>
      <category>cs.IR</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Yao, Yiming Liao, Jingzhou Liu, Shaoliang Nie, Qifan Wang, Haifeng Xu, Hongning Wang</dc:creator>
    </item>
    <item>
      <title>User-Creator Feature Polarization in Recommender Systems with Dual Influence</title>
      <link>https://arxiv.org/abs/2407.14094</link>
      <description>arXiv:2407.14094v2 Announce Type: replace-cross 
Abstract: Recommender systems serve the dual purpose of presenting relevant content to users and helping content creators reach their target audience. The dual nature of these systems naturally influences both users and creators: users' preferences are affected by the items they are recommended, while creators may be incentivized to alter their content to attract more users. We define a model, called user-creator feature dynamics, to capture the dual influence of recommender systems. We prove that a recommender system with dual influence is guaranteed to polarize, causing diversity loss in the system. We then investigate, both theoretically and empirically, approaches for mitigating polarization and promoting diversity in recommender systems. Unexpectedly, we find that common diversity-promoting approaches do not work in the presence of dual influence, while relevancy-optimizing methods like top-$k$ truncation can prevent polarization and improve diversity of the system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14094v2</guid>
      <category>cs.IR</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Lin, Kun Jin, Andrew Estornell, Xiaoying Zhang, Yiling Chen, Yang Liu</dc:creator>
    </item>
  </channel>
</rss>
