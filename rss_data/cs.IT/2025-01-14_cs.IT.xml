<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 15 Jan 2025 02:33:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Trends in urban flows: A transfer entropy approach</title>
      <link>https://arxiv.org/abs/2501.06316</link>
      <description>arXiv:2501.06316v1 Announce Type: new 
Abstract: The accurate estimation of human activity in cities is one of the first steps towards understanding the structure of the urban environment. Human activities are highly granular and dynamic in spatial and temporal dimensions. Estimating confidence is crucial for decision-making in numerous applications such as urban management, retail, transport planning and emergency management. Detecting general trends in the flow of people between spatial locations is neither obvious nor easy due to the high cost of capturing these movements without compromising the privacy of those involved. This research intends to address this problem by examining the movement of people in a SmartStreetSensors network at a fine spatial and temporal resolution using a Transfer Entropy approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06316v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ME</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Murcio, Balamurugan Soundararaj</dc:creator>
    </item>
    <item>
      <title>On the Rate-Distortion-Perception Function for Gaussian Processes</title>
      <link>https://arxiv.org/abs/2501.06363</link>
      <description>arXiv:2501.06363v1 Announce Type: new 
Abstract: In this paper, we investigate the rate-distortion-perception function (RDPF) of a source modeled by a Gaussian Process (GP) on a measure space $\Omega$ under mean squared error (MSE) distortion and squared Wasserstein-2 perception metrics. First, we show that the optimal reconstruction process is itself a GP, characterized by a covariance operator sharing the same set of eigenvectors of the source covariance operator. Similarly to the classical rate-distortion function, this allows us to formulate the RDPF problem in terms of the Karhunen-Lo\`eve transform coefficients of the involved GPs. Leveraging the similarities with the finite-dimensional Gaussian RDPF, we formulate an analytical tight upper bound for the RDPF for GPs, which recovers the optimal solution in the "perfect realism" regime. Lastly, in the case where the source is a stationary GP and $\Omega$ is the interval $[0, T]$ equipped with the Lebesgue measure, we derive an upper bound on the rate and the distortion for a fixed perceptual level and $T \to \infty$ as a function of the spectral density of the source process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06363v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Serra, Photios A. Stavrou, Marios Kountouris</dc:creator>
    </item>
    <item>
      <title>Energy-Aware Resource Allocation for Energy Harvesting Powered Wireless Sensor Nodes</title>
      <link>https://arxiv.org/abs/2501.06545</link>
      <description>arXiv:2501.06545v1 Announce Type: new 
Abstract: Low harvested energy poses a significant challenge to sustaining continuous communication in energy harvesting (EH)-powered wireless sensor networks. This is mainly due to intermittent and limited power availability from radio frequency signals. In this paper, we introduce a novel energy-aware resource allocation problem aimed at enabling the asynchronous accumulate-then-transmit protocol, offering an alternative to the extensively studied harvest-then-transmit approach. Specifically, we jointly optimize power allocation and time fraction dedicated to EH to maximize the average long-term system throughput, accounting for both data and energy queue lengths. By leveraging inner approximation and network utility maximization techniques, we develop a simple yet efficient iterative algorithm that guarantees at least a local optimum and achieves long-term utility improvement. Numerical results highlight the proposed approach's effectiveness in terms of both queue length and sustained system throughput.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06545v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ngoc M. Ngo, Trung T. Nguyen, Phuc H. Nguyen, Van-Dinh Nguyen</dc:creator>
    </item>
    <item>
      <title>A Permutation-Free Length 3 Decimal Check Digit Code</title>
      <link>https://arxiv.org/abs/2501.06641</link>
      <description>arXiv:2501.06641v1 Announce Type: new 
Abstract: In 1969 J. Verhoeff provided the first examples of a decimal error detecting code using a single check digit to provide protection against all single, transposition and adjacent twin errors. The three codes he presented are length 3-digit codes with 2 information digits. Existence of a 4-digit code would imply the existence of 10 such disjoint 3-digit codes. Apparently, not even a pair of such disjoint 3-digit codes is known. The code developed herein, has the property that the knowledge of any two digits is sufficient to determine the entire codeword even though their positions were unknown. This fulfills Verhoeff's desire to eliminate "cyclic errors". Phonetic errors, where 2 digit pairs of the forms X0 and 1X are interchanged, are also eliminated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06641v1</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Larry A. Dunning</dc:creator>
    </item>
    <item>
      <title>Theoretical Characterization of Effect of Masks in Snapshot Compressive Imaging</title>
      <link>https://arxiv.org/abs/2501.06653</link>
      <description>arXiv:2501.06653v1 Announce Type: new 
Abstract: Snapshot compressive imaging (SCI) refers to the recovery of three-dimensional data cubes-such as videos or hyperspectral images-from their two-dimensional projections, which are generated by a special encoding of the data with a mask. SCI systems commonly use binary-valued masks that follow certain physical constraints. Optimizing these masks subject to these constraints is expected to improve system performance. However, prior theoretical work on SCI systems focuses solely on independently and identically distributed (i.i.d.) Gaussian masks, which do not permit such optimization. On the other hand, existing practical mask optimizations rely on computationally intensive joint optimizations that provide limited insight into the role of masks and are expected to be sub-optimal due to the non-convexity and complexity of the optimization. In this paper, we analytically characterize the performance of SCI systems employing binary masks and leverage our analysis to optimize hardware parameters. Our findings provide a comprehensive and fundamental understanding of the role of binary masks - with both independent and dependent elements - and their optimization. We also present simulation results that confirm our theoretical findings and further illuminate different aspects of mask design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06653v1</guid>
      <category>cs.IT</category>
      <category>eess.IV</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mengyu Zhao, Shirin Jalali</dc:creator>
    </item>
    <item>
      <title>Average Reward Reinforcement Learning for Wireless Radio Resource Management</title>
      <link>https://arxiv.org/abs/2501.06700</link>
      <description>arXiv:2501.06700v1 Announce Type: new 
Abstract: In this paper, we address a crucial but often overlooked issue in applying reinforcement learning (RL) to radio resource management (RRM) in wireless communications: the mismatch between the discounted reward RL formulation and the undiscounted goal of wireless network optimization. To the best of our knowledge, we are the first to systematically investigate this discrepancy, starting with a discussion of the problem formulation followed by simulations that quantify the extent of the gap. To bridge this gap, we introduce the use of average reward RL, a method that aligns more closely with the long-term objectives of RRM. We propose a new method called the Average Reward Off policy Soft Actor Critic (ARO SAC) is an adaptation of the well known Soft Actor Critic algorithm in the average reward framework. This new method achieves significant performance improvement our simulation results demonstrate a 15% gain in the system performance over the traditional discounted reward RL approach, underscoring the potential of average reward RL in enhancing the efficiency and effectiveness of wireless network optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06700v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kun Yang, Jing Yang, Cong Shen</dc:creator>
    </item>
    <item>
      <title>Integrated Sensing and Edge AI: Realizing Intelligent Perception in 6G</title>
      <link>https://arxiv.org/abs/2501.06726</link>
      <description>arXiv:2501.06726v1 Announce Type: new 
Abstract: Sensing and edge artificial intelligence (AI) are envisioned as two essential and interconnected functions in sixth-generation (6G) mobile networks. On the one hand, sensing-empowered applications rely on powerful AI models to extract features and understand semantics from ubiquitous wireless sensors. On the other hand, the massive amount of sensory data serves as the fuel to continuously refine edge AI models. This deep integration of sensing and edge AI has given rise to a new task-oriented paradigm known as integrated sensing and edge AI (ISEA), which features a holistic design approach to communication, AI computation, and sensing for optimal sensing-task performance. In this article, we present a comprehensive survey for ISEA. We first provide technical preliminaries for sensing, edge AI, and new communication paradigms in ISEA. Then, we study several use cases of ISEA to demonstrate its practical relevance and introduce current standardization and industrial progress. Next, the design principles, metrics, tradeoffs, and architectures of ISEA are established, followed by a thorough overview of ISEA techniques, including digital air interface, over-the-air computation, and advanced signal processing. Its interplay with various 6G advancements, e.g., new physical-layer and networking techniques, are presented. Finally, we present future research opportunities in ISEA, including the integration of foundation models, convergence of ISEA and integrated sensing and communications (ISAC), and ultra-low-latency ISEA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06726v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyan Liu, Xu Chen, Hai Wu, Zhanwei Wang, Xianhao Chen, Dusit Niyato, Kaibin Huang</dc:creator>
    </item>
    <item>
      <title>Metaprism Design for Wireless Communications: Angle-Frequency Analysis, Physical Realizability Constraints, and Performance Optimization</title>
      <link>https://arxiv.org/abs/2501.06760</link>
      <description>arXiv:2501.06760v1 Announce Type: new 
Abstract: Recent advancements in smart radio environment technologies aim to enhance wireless network performance through the use of low-cost electromagnetic (EM) devices. Among these, reconfigurable intelligent surfaces (RIS) have garnered attention for their ability to modify incident waves via programmable scattering elements. An RIS is a nearly passive device, in which the tradeoff between performance, power consumption, and optimization overhead depend on how often the RIS needs to be reconfigured. This paper focuses on the metaprism (MTP), a static frequency-selective metasurface which relaxes the reconfiguration requirements of RISs and allows for the creation of different beams at various frequencies. In particular, we address the design of an ideal MTP based on its frequency-dependent reflection coefficients, defining the general properties necessary to achieve the desired beam steering function in the angle-frequency domain. We also discuss the limitations of previous studies that employed oversimplified models, which may compromise performance. Key contributions include a detailed exploration of the equivalence of the MTP to an ideal S-parameter multiport model and an analysis of its implementation using Foster's circuits. Additionally, we introduce a realistic multiport network model that incorporates aspects overlooked by ideal scattering models, along with an ad hoc optimization strategy for this model. The performance of the proposed optimization approach and circuits implementation are validated through simulations using a commercial full-wave EM simulator, confirming the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06760v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Silvia Palmucci, Andrea Abrardo, Davide Dardari, Alberto Toccafondi, Marco Di Renzo</dc:creator>
    </item>
    <item>
      <title>Optimizing Sequencing Coverage Depth in DNA Storage: Insights From DNA Storage Data</title>
      <link>https://arxiv.org/abs/2501.06801</link>
      <description>arXiv:2501.06801v1 Announce Type: new 
Abstract: DNA data storage is now being considered as a new archival storage method for its durability and high information density, but still facing some challenges like high costs and low throughput. By reducing sequencing sample size for decoding digital data, minimizing DNA coverage depth helps lower both costs and system latency. Previous studies have mainly focused on minimizing coverage depth in uniform distribution channels under theoretical assumptions. In contrast, our work uses real DNA storage experimental data to extend this problem to log-normal distribution channels, a conclusion derived from our PCR and sequencing data analysis. In this framework, we investigate both noiseless and noisy channels. We first demonstrate a detailed negative correlation between linear coding redundancy and the expected minimum sequencing coverage depth. Moreover, we observe that the probability of successfully decoding all data in a single sequencing run increases and then decreases as coding redundancy rises, when the sample size is optimized for complete decoding. Then we extend the lower bounds of DNA coverage depth from uniform to log-normal noisy channels. The findings of this study provide valuable insights for the efficient execution of DNA storage experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06801v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiying Cao, Xin Chen</dc:creator>
    </item>
    <item>
      <title>A General Framework for Error-controlled Unstructured Scientific Data Compression</title>
      <link>https://arxiv.org/abs/2501.06910</link>
      <description>arXiv:2501.06910v1 Announce Type: new 
Abstract: Data compression plays a key role in reducing storage and I/O costs. Traditional lossy methods primarily target data on rectilinear grids and cannot leverage the spatial coherence in unstructured mesh data, leading to suboptimal compression ratios. We present a multi-component, error-bounded compression framework designed to enhance the compression of floating-point unstructured mesh data, which is common in scientific applications. Our approach involves interpolating mesh data onto a rectilinear grid and then separately compressing the grid interpolation and the interpolation residuals. This method is general, independent of mesh types and typologies, and can be seamlessly integrated with existing lossy compressors for improved performance. We evaluated our framework across twelve variables from two synthetic datasets and two real-world simulation datasets. The results indicate that the multi-component framework consistently outperforms state-of-the-art lossy compressors on unstructured data, achieving, on average, a $2.3-3.5\times$ improvement in compression ratios, with error bounds ranging from $\num{1e-6}$ to $\num{1e-2}$. We further investigate the impact of hyperparameters, such as grid spacing and error allocation, to deliver optimal compression ratios in diverse datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06910v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/e-Science62913.2024.10678699</arxiv:DOI>
      <dc:creator>Qian Gong, Zhe Wang, Viktor Reshniak, Xin Liang, Jieyang Chen, Qing Liu, Tushar M. Athawale, Yi Ju, Anand Rangarajan, Sanjay Ranka, Norbert Podhorszki, Rick Archibald, Scott Klasky</dc:creator>
    </item>
    <item>
      <title>Decentralized Space Surveillance: Blockchain-Based Space Domain Awareness</title>
      <link>https://arxiv.org/abs/2501.06970</link>
      <description>arXiv:2501.06970v1 Announce Type: new 
Abstract: With the rapid expansion of space activities and the escalating accumulation of space debris, Space Domain Awareness (SDA) has become essential for sustaining safe space operations. This paper proposes a decentralized solution using satellite swarms and blockchain, where satellites (nodes) take on the roles of verifiers and approvers to validate and store debris-tracking data securely. Our simulations show that the network achieves optimal performance with around 30 nodes, balancing throughput and response time settling at 4.37 seconds. These results suggest that large-scale networks can be effectively managed by decoupling them into smaller, autonomous swarms, each optimized for specific tasks. Furthermore, we compare the performance of the decentralized swarm architecture with that of a fully shared role model and show significant improvements in scalability and response times when roles are decoupled.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06970v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nesrine Benchoubane, Nida Fidan, Gunes Karabulut Kurt, Enver Ozdemir</dc:creator>
    </item>
    <item>
      <title>Downlink OFDM-FAMA in 5G-NR Systems</title>
      <link>https://arxiv.org/abs/2501.06974</link>
      <description>arXiv:2501.06974v1 Announce Type: new 
Abstract: Fluid antenna multiple access (FAMA), enabled by the fluid antenna system (FAS), offers a new and straightforward solution to massive connectivity. Previous results on FAMA were primarily based on narrowband channels. This paper studies the adoption of FAMA within the fifth-generation (5G) orthogonal frequency division multiplexing (OFDM) framework, referred to as OFDM-FAMA, and evaluate its performance in broadband multipath channels. We first design the OFDM-FAMA system, taking into account 5G channel coding and OFDM modulation. Then the system's achievable rate is analyzed, and an algorithm to approximate the FAS configuration at each user is proposed based on the rate. Extensive link-level simulation results reveal that OFDM-FAMA can significantly improve the multiplexing gain over the OFDM system with fixed-position antenna (FPA) users, especially when robust channel coding is applied and the number of radio-frequency (RF) chains at each user is small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06974v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanjiang Hong, Kai-Kit Wong, Hao Xu, Yin Xu, Hyundong Shin, Ross Murch, Dazhi He, Wenjun Zhang</dc:creator>
    </item>
    <item>
      <title>Beam Structured Turbo Receiver for HF Skywave Massive MIMO</title>
      <link>https://arxiv.org/abs/2501.07041</link>
      <description>arXiv:2501.07041v1 Announce Type: new 
Abstract: In this paper, we investigate receiver design for high frequency (HF) skywave massive multiple-input multiple-output (MIMO) communications. We first establish a modified beam based channel model (BBCM) by performing uniform sampling for directional cosine with deterministic sampling interval, where the beam matrix is constructed using a phase-shifted discrete Fourier transform (DFT) matrix. Based on the modified BBCM, we propose a beam structured turbo receiver (BSTR) involving low-dimensional beam domain signal detection for grouped user terminals (UTs), which is proved to be asymptotically optimal in terms of minimizing mean-squared error (MSE). Moreover, we extend it to windowed BSTR by introducing a windowing approach for interference suppression and complexity reduction, and propose a well-designed energy-focusing window. We also present an efficient implementation of the windowed BSTR by exploiting the structure properties of the beam matrix and the beam domain channel sparsity. Simulation results validate the superior performance of the proposed receivers but with remarkably low complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07041v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linfeng Song, Ding Shi, Xiqi Gao, Geoffrey Ye Li, Xiang-Gen Xia</dc:creator>
    </item>
    <item>
      <title>Privacy-Preserving Data Quality Assessment for Time-Series IoT Sensors</title>
      <link>https://arxiv.org/abs/2501.07154</link>
      <description>arXiv:2501.07154v1 Announce Type: new 
Abstract: Data from Internet of Things (IoT) sensors has emerged as a key contributor to decision-making processes in various domains. However, the quality of the data is crucial to the effectiveness of applications built on it, and assessment of the data quality is heavily context-dependent. Further, preserving the privacy of the data during quality assessment is critical in domains where sensitive data is prevalent. This paper proposes a novel framework for automated, objective, and privacy-preserving data quality assessment of time-series data from IoT sensors deployed in smart cities. We leverage custom, autonomously computable metrics that parameterise the temporal performance and adherence to a declarative schema document to achieve objectivity. Additionally, we utilise a trusted execution environment to create a "data-blind" model that ensures individual privacy, eliminates assessee bias, and enhances adaptability across data types. This paper describes this data quality assessment methodology for IoT sensors, emphasising its relevance within the smart-city context while addressing the growing need for privacy in the face of extensive data collection practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07154v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/IoTaIS64014.2024.10799255</arxiv:DOI>
      <arxiv:journal_reference>2024 IEEE International Conference on Internet of Things and Intelligence Systems (IoTaIS), Bali, Indonesia, 2024, pp. 51-57</arxiv:journal_reference>
      <dc:creator>Novoneel Chakraborty, Abhay Sharma, Jyotirmoy Dutta, Hari Dilip Kumar</dc:creator>
    </item>
    <item>
      <title>Multiple-Satellite Cooperative Information Communication and Location Sensing in LEO Satellite Constellations</title>
      <link>https://arxiv.org/abs/2501.07220</link>
      <description>arXiv:2501.07220v1 Announce Type: new 
Abstract: Integrated sensing and communication (ISAC) and ubiquitous connectivity are two usage scenarios of sixth generation (6G) networks. In this context, low earth orbit (LEO) satellite constellations, as an important component of 6G networks, is expected to provide ISAC services across the globe. In this paper, we propose a novel dual-function LEO satellite constellation framework that realizes information communication for multiple user equipments (UEs) and location sensing for interested target simultaneously with the same hardware and spectrum. In order to improve both information transmission rate and location sensing accuracy within limited wireless resources under dynamic environment, we design a multiple-satellite cooperative information communication and location sensing algorithm by jointly optimizing communication beamforming and sensing waveform according to the characteristics of LEO satellite constellation. Finally, extensive simulation results are presented to demonstrate the competitive performance of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07220v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Qi Wang, Xiaoming Chen, Qiao Qi, Mili Li, Wolfgang Gerstacker</dc:creator>
    </item>
    <item>
      <title>Toward Universal Decoding of Binary Linear Block Codes via Enhanced Polar Transformations</title>
      <link>https://arxiv.org/abs/2501.07279</link>
      <description>arXiv:2501.07279v1 Announce Type: new 
Abstract: Binary linear block codes (BLBCs) are essential to modern communication, but their diverse structures often require multiple decoders, increasing complexity. This work introduces enhanced polar decoding ($\mathsf{PD}^+$), a universal soft decoding algorithm that transforms any BLBC into a polar-like code compatible with efficient polar code decoders such as successive cancellation list (SCL) decoding. Key innovations in $\mathsf{PD}^+$ include pruning polar kernels, shortening codes, and leveraging a simulated annealing algorithm to optimize transformations. These enable $\mathsf{PD}^+$ to achieve competitive or superior performance to state-of-the-art algorithms like OSD and GRAND across various codes, including extended BCH, extended Golay, and binary quadratic residue codes, with significantly lower complexity. Moreover, $\mathsf{PD}^+$ is designed to be forward-compatible with advancements in polar code decoding techniques and AI-driven search methods, making it a robust and versatile solution for universal BLBC decoding in both present and future systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07279v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chien-Ying Lin, Yu-Chih Huang, Shin-Lin Shieh, Po-Ning Chen</dc:creator>
    </item>
    <item>
      <title>Movable Antenna Enhanced Integrated Sensing and Communication Via Antenna Position Optimization</title>
      <link>https://arxiv.org/abs/2501.07318</link>
      <description>arXiv:2501.07318v2 Announce Type: new 
Abstract: In this paper, we propose an integrated sensing and communication (ISAC) system aided by the movable-antenna (MA) array, which can improve the communication and sensing performance via flexible antenna movement over conventional fixed-position antenna (FPA) array. First, we consider the downlink multiuser communication, where each user is randomly distributed within a given three-dimensional zone with local movement. To reduce the overhead of frequent antenna movement, the antenna position vector (APV) is designed based on users' statistical channel state information (CSI), so that the antennas only need to be moved in a large timescale. Then, for target sensing, the Cramer-Rao bounds (CRBs) of the estimation mean square error for different spatial angles of arrival (AoAs) are derived as functions of MAs' positions. Based on the above, we formulate an optimization problem to maximize the expected minimum achievable rate among all communication users, with given constraints on the maximum acceptable CRB thresholds for target sensing. An alternating optimization algorithm is proposed to iteratively optimize one of the horizontal and vertical APVs of the MA array with the other being fixed. Numerical results demonstrate that our proposed MA arrays can significantly enlarge the trade-off region between communication and sensing performance compared to conventional FPA arrays with different inter-antenna spacing. It is also revealed that the steering vectors of the designed MA arrays exhibit low correlation in the angular domain, thus effectively reducing channel correlation among communication users to enhance their achievable rates, while alleviating ambiguity in target angle estimation to achieve improved sensing accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07318v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenyan Ma, Lipeng Zhu, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Several Families of Entanglement-Assisted Quantum Quasi-Cyclic LDPC Codes</title>
      <link>https://arxiv.org/abs/2501.07363</link>
      <description>arXiv:2501.07363v1 Announce Type: new 
Abstract: We introduce several families of entanglement-assisted (EA) Calderbank-Shor-Steane (CSS) codes derived from two distinct classes of low-density parity-check (LDPC) codes. We derive two families of EA quantum QC-LDPC codes, namely, the spatially coupled (SC) and the non-spatially coupled cases. These two families are constructed by tiling permutation matrices of prime and composite orders. We establish several code properties along with conditions for guaranteed girth for the proposed code families. The Tanner graphs of the proposed EA quantum QC-LDPC and EA quantum QC-SC-LDPC codes have girths greater than four, which is required for good error correction performance. Some of the proposed families of codes require only \textit{minimal} Bell pairs to be shared across the quantum transceiver. Furthermore, we construct two families of EA quantum QC-LDPC codes based on a single classical code, with Tanner graphs having girths greater than six, further improving the error correction performance. We evaluate the performance of these codes using both depolarizing and Markovian noise models to assess the random and burst error performance. Using a modified version of the sum-product algorithm over a quaternary alphabet, we show how correlated Pauli errors can be handled within the decoding setup. Simulation results show that nearly an order of improvement in the error correction performance can be achieved with quaternary decoder compared to binary decoder over the depolarizing and Markovian error channels, thereby generalizing the approach of EA quantum QC-LDPC code designs to work with both random and burst quantum error models, useful in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07363v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pavan Kumar, Abhi Kumar Sharma, Shayan Srinivasa Garani</dc:creator>
    </item>
    <item>
      <title>Design and Analysis of a Concatenated Code for Intersymbol Interference Wiretap Channels</title>
      <link>https://arxiv.org/abs/2501.07561</link>
      <description>arXiv:2501.07561v1 Announce Type: new 
Abstract: We propose a two-stage concatenated coding scheme for reliable and information-theoretically secure communication over intersymbol interference wiretap channels. Motivated by the theoretical coding strategies that achieve the secrecy capacity, our scheme integrates low-density parity-check (LDPC) codes in the outer stage, forming a nested structure of wiretap codes, with trellis codes in the inner stage to improve achievable secure rates. The trellis code is specifically designed to transform the uniformly distributed codewords produced by the LDPC code stage into a Markov process, achieving tight lower bounds on the secrecy capacity. We further estimate the information leakage rate of the proposed coding scheme using an upper bound. To meet the weak secrecy criterion, we optimize degree distributions of the irregular LDPC codes at the outer stage, essentially driving the estimated upper bound on the information leakage rate to zero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07561v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aria Nouri, Reza Asvadi, Jun Chen</dc:creator>
    </item>
    <item>
      <title>Low-Complexity Detection of Multiple Preambles in the Presence of Mobility and Delay Spread</title>
      <link>https://arxiv.org/abs/2501.06355</link>
      <description>arXiv:2501.06355v1 Announce Type: cross 
Abstract: Current wireless infrastructure is optimized to support downlink applications. This paper anticipates the emergence of applications where engineering focus shifts from downlink to uplink. The current paradigm of scheduling users on reserved uplink resources is not able to deal efficiently with unpredictable traffic patterns. As a result, 3GPP introduced the 2-step RACH as a mechanism to enable grant-free (random) initial access. The first of the two steps is preamble detection in a RACH slot, and in this paper we describe a low-complexity algorithm for simultaneous detection of multiple preambles in the presence of mobility and delay spread. We provide a pathway to standards adoption by choosing ZC sequences as preambles, as ZC sequences already appear in 5G standards. We construct preambles by using the discrete Zak transform to pass from a ZC sequence of length MN in the TD to a quasi-periodic MxN array in the DD domain. There are MN quasi-periodic Dirac pulses, each corresponding to a Zak-OTFS carrier waveform, and the ZC preamble is simply the corresponding sum of Zak-OTFS carrier waveforms. We detect multiple preambles in the presence of mobility and delay spread by sampling the received signal on the MxN period grid in the DD domain. We approach detection as a compressed sensing problem. We represent a preamble as a column of length MN in the DD domain and apply discrete shifts in delay and Doppler to produce a block with O(MN) columns in the compressed sensing matrix. The superposition of multiple preambles determines a block sparse sum of columns in the sensing matrix. The correlation properties of ZC sequences result in a highly structured compressed sensing matrix, making it possible to identify constituent preambles using OST, which has complexity O(M^3N^3). In this paper, we describe an algorithm with complexity that is O(M^2N^2) in the size of an individual column.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06355v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandesh Rao Mattu, Beyza Dabak, Venkatesh Khammammetti, Robert Calderbank</dc:creator>
    </item>
    <item>
      <title>When xURLLC Meets NOMA: A Stochastic Network Calculus Perspective</title>
      <link>https://arxiv.org/abs/2501.06552</link>
      <description>arXiv:2501.06552v1 Announce Type: cross 
Abstract: The advent of next-generation ultra-reliable and low-latency communications (xURLLC) presents stringent and unprecedented requirements for key performance indicators (KPIs). As a disruptive technology, non-orthogonal multiple access (NOMA) harbors the potential to fulfill these stringent KPIs essential for xURLLC. However, the immaturity of research on the tail distributions of these KPIs significantly impedes the application of NOMA to xURLLC. Stochastic network calculus (SNC), as a potent methodology, is leveraged to provide dependable theoretical insights into tail distribution analysis and statistical QoS provisioning (SQP). In this article, we develop a NOMA-assisted uplink xURLLC network architecture that incorporates an SNC-based SQP theoretical framework (SNC-SQP) to support tail distribution analysis in terms of delay, age-of-information (AoI), and reliability. Based on SNC-SQP, an SQP-driven power optimization problem is proposed to minimize transmit power while guaranteeing xURLLC's KPIs on delay, AoI, reliability, and power consumption. Extensive simulations validate our proposed theoretical framework and demonstrate that the proposed power allocation scheme significantly reduces uplink transmit power and outperforms conventional schemes in terms of SQP performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06552v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuang Chen, Hancheng Lu, Langtin Qin, Yansha Deng, Arumugam Nallanathan</dc:creator>
    </item>
    <item>
      <title>Sequential Portfolio Selection under Latent Side Information-Dependence Structure: Optimality and Universal Learning Algorithms</title>
      <link>https://arxiv.org/abs/2501.06701</link>
      <description>arXiv:2501.06701v1 Announce Type: cross 
Abstract: This paper investigates the investment problem of constructing an optimal no-short sequential portfolio strategy in a market with a latent dependence structure between asset prices and partly unobservable side information, which is often high-dimensional. The results demonstrate that a dynamic strategy, which forms a portfolio based on perfect knowledge of the dependence structure and full market information over time, may not grow at a higher rate infinitely often than a constant strategy, which remains invariant over time. Specifically, if the market is stationary, implying that the dependence structure is statistically stable, the growth rate of an optimal dynamic strategy, utilizing the maximum capacity of the entire market information, almost surely decays over time into an equilibrium state, asymptotically converging to the growth rate of a constant strategy.
  Technically, this work reassesses the common belief that a constant strategy only attains the optimal limiting growth rate of dynamic strategies when the market process is identically and independently distributed. By analyzing the dynamic log-optimal portfolio strategy as the optimal benchmark in a stationary market with side information, we show that a random optimal constant strategy almost surely exists, even when a limiting growth rate for the dynamic strategy does not. Consequently, two approaches to learning algorithms for portfolio construction are discussed, demonstrating the safety of removing side information from the learning process while still guaranteeing an asymptotic growth rate comparable to that of the optimal dynamic strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06701v1</guid>
      <category>q-fin.MF</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Duy Khanh Lam</dc:creator>
    </item>
    <item>
      <title>Optimal Online Bookmaking for Binary Games</title>
      <link>https://arxiv.org/abs/2501.06923</link>
      <description>arXiv:2501.06923v1 Announce Type: cross 
Abstract: In online betting, the bookmaker can update the payoffs it offers on a particular event many times before the event takes place, and the updated payoffs may depend on the bets accumulated thus far. We study the problem of bookmaking with the goal of maximizing the return in the worst-case, with respect to the gamblers' behavior and the event's outcome. We formalize this problem as the \emph{Optimal Online Bookmaking game}, and provide the exact solution for the binary case. To this end, we develop the optimal bookmaking strategy, which relies on a new technique called bi-balancing trees, that assures that the house loss is the same for all \emph{decisive} betting sequences, where the gambler bets all its money on a single outcome in each round.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06923v1</guid>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alankrita Bhatt, Or Ordentlich, Oron Sabag</dc:creator>
    </item>
    <item>
      <title>Necessary and sufficient condition for constructing a single qudit insertion/deletion code and its decoding algorithm</title>
      <link>https://arxiv.org/abs/2501.07027</link>
      <description>arXiv:2501.07027v1 Announce Type: cross 
Abstract: This paper shows that Knill-Laflamme condition, known as a necessary and sufficient condition for quantum error-correction, can be applied to quantum errors where the number of particles changes before and after the error. This fact shows that correctabilities of single deletion errors and single insertion errors are equivalent. By applying Knill-Laflamme condition, we generalize the previously known correction conditions for single insertion and deletion errors to necessary and sufficient level. By giving an example that satisfies this condition, we construct a new single qudit insertion/deletion code and explain its decoding algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07027v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taro Shibayama</dc:creator>
    </item>
    <item>
      <title>Estimating quantum relative entropies on quantum computers</title>
      <link>https://arxiv.org/abs/2501.07292</link>
      <description>arXiv:2501.07292v1 Announce Type: cross 
Abstract: Quantum relative entropy, a quantum generalization of the well-known Kullback-Leibler divergence, serves as a fundamental measure of the distinguishability between quantum states and plays a pivotal role in quantum information science. Despite its importance, efficiently estimating quantum relative entropy between two quantum states on quantum computers remains a significant challenge. In this work, we propose the first quantum algorithm for estimating quantum relative entropy and Petz R\'{e}nyi divergence from two unknown quantum states on quantum computers, addressing open problems highlighted in [Phys. Rev. A 109, 032431 (2024)] and [IEEE Trans. Inf. Theory 70, 5653-5680 (2024)]. This is achieved by combining quadrature approximations of relative entropies, the variational representation of quantum f-divergences, and a new technique for parameterizing Hermitian polynomial operators to estimate their traces with quantum states. Notably, the circuit size of our algorithm is at most 2n+1 with n being the number of qubits in the quantum states and it is directly applicable to distributed scenarios, where quantum states to be compared are hosted on cross-platform quantum computers. We validate our algorithm through numerical simulations, laying the groundwork for its future deployment on quantum hardware devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07292v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Lu, Kun Fang</dc:creator>
    </item>
    <item>
      <title>Generalized Fractional Repetition Codes for Binary Coded Computations</title>
      <link>https://arxiv.org/abs/2109.10484</link>
      <description>arXiv:2109.10484v3 Announce Type: replace 
Abstract: This paper addresses the gradient coding and coded matrix multiplication problems in distributed optimization and coded computing. We present a numerically stable binary coding method which overcomes the drawbacks of the \textit{Fractional Repetition Coding} gradient coding method proposed by Tandon et al., and can also be leveraged by coded computing networks whose servers are of heterogeneous nature. Specifically, we propose a construction for fractional repetition gradient coding; while ensuring that the generator matrix remains close to perfectly balanced for any set of coded parameters, as well as a low complexity decoding step. The proposed binary encoding avoids operations over the real and complex numbers which are inherently numerically unstable, thereby enabling numerically stable distributed encodings of the partial gradients. We then make connections between gradient coding and coded matrix multiplication. Specifically, we show that any gradient coding scheme can be extended to coded matrix multiplication. Furthermore, we show how the proposed binary gradient coding scheme can be used to construct two different coded matrix multiplication schemes, each achieving different trade-offs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.10484v3</guid>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neophytos Charalambides, Hessam Mahdavifar, Alfred O. Hero III</dc:creator>
    </item>
    <item>
      <title>Static IRS Meets Distributed MIMO: A New Architecture for Dynamic Beamforming</title>
      <link>https://arxiv.org/abs/2304.11639</link>
      <description>arXiv:2304.11639v3 Announce Type: replace 
Abstract: Intelligent reflecting surface (IRS) has been considered as a revolutionary technology to enhance the wireless communication performance. To cater for multiple mobile users, adjusting IRS beamforming patterns over time, i.e., dynamic IRS beamforming (DIBF), is generally needed for achieving satisfactory performance, which results in high controlling power consumption and overhead. To avoid such cost, we propose a new architecture based on the static regulated IRS for wireless coverage enhancement, where the principle of distributed multiple-input multiple-output (D-MIMO) is integrated into the system to exploite the diversity of spatial directions provided by multiple access points (APs). For this new D-MIMO empowered static IRS architecture, the total target area is partitioned into several subareas and each subarea is served by an assigned AP. We consider to maximize the worst-case received power over all locations in the target area by jointly optimizing a single set of IRS beamforming pattern and AP-subarea association. Then, a two-step algorithm is proposed to obtain its high-quality solution. Theoretical analysis unveils that the fundamental squared power gain can still be achieved over all locations in the target area. The performance gap relative to the DIBF scheme is also analytically quantified. Numerical results validate our theoretical findings and demonstrate the effectiveness of our proposed design over benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.11639v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangji Chen, Qingqing Wu, Celimuge Wu, Mengnan Jian, Yijian Chen, Wen Chen</dc:creator>
    </item>
    <item>
      <title>Frame Codes for the Block-Erasure Channel -- Extended Version</title>
      <link>https://arxiv.org/abs/2405.01172</link>
      <description>arXiv:2405.01172v3 Announce Type: replace 
Abstract: Analog codes add redundancy by expanding the dimension using real/complex-valued operations. Frame theory provides a mathematical basis for constructing such codes, with diverse applications in non-orthogonal code-division multiple access (NOMA-CDMA), distributed computation, multiple description source coding, space-time coding (STC), and more. The channel model corresponding to these applications is a combination of noise and erasures. Recent analyses showed a useful connection between spectral random-matrix theory and large equiangular tight frames (ETFs) under random uniform erasures. In this work we generalize this model to a channel where the erasures come in blocks. This particularly fits NOMA-CDMA with multiple transmit antennas for each user and STC with known spatial grouping. We present a method to adjust ETF codes to suit block erasures, and find minimum intra-block-correlation frames which outperform ETFs in this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01172v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Itamar Jacoby, Ram Zamir</dc:creator>
    </item>
    <item>
      <title>High Rate Multivariate Polynomial Evaluation Codes</title>
      <link>https://arxiv.org/abs/2410.13470</link>
      <description>arXiv:2410.13470v2 Announce Type: replace 
Abstract: The classical Reed-Muller codes over a finite field $\mathbb{F}_q$ are based on evaluations of $m$-variate polynomials of degree at most $d$ over a product set $U^m$, for some $d$ less than $|U|$. Because of their good distance properties, as well as the ubiquity and expressive power of polynomials, these codes have played an influential role in coding theory and complexity theory. This is especially so in the setting of $U$ being ${\mathbb{F}}_q$ where they possess deep locality properties. However, these Reed-Muller codes have a significant limitation in terms of the rate achievable -- the rate cannot be more than $\frac{1}{m{!}} = \exp(-m \log m)$.
  In this work, we give the first constructions of multivariate polynomial evaluation codes which overcome the rate limitation -- concretely, we give explicit evaluation domains $S \subseteq \mathbb{F}_q^m$ on which evaluating $m$-variate polynomials of degree at most $d$ gives a good code. For $m= O(1)$, these new codes have relative distance $\Omega(1)$ and rate $1 - \epsilon$ for any $\epsilon &gt; 0$. In fact, we give two quite different constructions, and for both we develop efficient decoding algorithms for these codes that can decode from half the minimum distance.
  The first of these codes is based on evaluating multivariate polynomials on simplex-like sets whereas the second construction is more algebraic, and surprisingly (to us), has some strong locality properties, specifically, we show that they are locally testable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13470v2</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Swastik Kopparty, Mrinal Kumar, Harry Sha</dc:creator>
    </item>
    <item>
      <title>On Achievable Rates Over Noisy Nanopore Channels</title>
      <link>https://arxiv.org/abs/2501.02917</link>
      <description>arXiv:2501.02917v3 Announce Type: replace 
Abstract: In this paper, we consider a recent channel model of a nanopore sequencer proposed by McBain, Viterbo, and Saunderson (2024), termed the noisy nanopore channel (NNC). In essence, an NNC is a noisy duplication channel, whose input source has a specific Markov structure. We present bounds on the channel capacity of selected NNCs, via simple information-theoretic inequalities. In particular, we provide a (tight) lower bound on the capacity of the noiseless NCC and demonstrate that for an NNC with erasure noise, the capacity approaches $1$ for nanopore memories that scale roughly logarithmically in the length of the input sequence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02917v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V. Arvind Rameshwar, Nir Weinberger</dc:creator>
    </item>
    <item>
      <title>Generalized quantum data-syndrome codes and belief propagation decoding for phenomenological noise</title>
      <link>https://arxiv.org/abs/2310.12682</link>
      <description>arXiv:2310.12682v2 Announce Type: replace-cross 
Abstract: Quantum stabilizer codes often struggle with syndrome errors due to measurement imperfections. Typically, multiple rounds of syndrome extraction are employed to ensure reliable error information. In this paper, we consider phenomenological decoding problems, where data qubit errors may occur between extractions, and each measurement can be faulty. We introduce generalized quantum data-syndrome codes along with a generalized check matrix that integrates both quaternary and binary alphabets to represent diverse error sources. This results in a Tanner graph with mixed variable nodes, enabling the design of belief propagation (BP) decoding algorithms that effectively handle phenomenological errors. Importantly, our BP decoders are applicable to general sparse quantum codes. Through simulations, we achieve an error threshold of more than 3\% for quantum memory protected by rotated toric codes, using solely BP without post-processing. Our results indicate that $d$ rounds of syndrome extraction are sufficient for a toric code of distance $d$. We observe that at high error rates, fewer rounds of syndrome extraction tend to perform better, while more rounds improve performance at lower error rates. Additionally, we propose a method to construct effective redundant stabilizer checks for single-shot error correction. Our simulations show that BP decoding remains highly effective even with a high syndrome error rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12682v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kao-Yueh Kuo, Ching-Yi Lai</dc:creator>
    </item>
    <item>
      <title>Estimating the Decoding Failure Rate of Binary Regular Codes Using Iterative Decoding</title>
      <link>https://arxiv.org/abs/2401.16919</link>
      <description>arXiv:2401.16919v3 Announce Type: replace-cross 
Abstract: Providing closed form estimates of the decoding failure rate of iterative decoder for low- and moderate-density parity check codes has attracted significant interest in the research community over the years. This interest has raised recently due to the use of iterative decoders in post-quantum cryptosystems, where the desired decoding failure rates are impossible to estimate via Monte Carlo simulations. In this work, we propose a new technique to provide accurate estimates of the DFR of a two-iterations (parallel) bit flipping decoder, which is also employable for cryptographic purposes. In doing so, we successfully tackle the estimation of the bit flipping probabilities at the second decoder iteration, and provide a fitting estimate for the syndrome weight distribution at the first iteration. We numerically validate our results, providing comparisons of the modeled and simulated weight of the syndrome, incorrectly-guessed error bit distribution at the end of the first iteration, and two-iteration Decoding Failure Rates (DFR), both in the floor and waterfall regime for simulatable codes. Finally, we apply our method to estimate the DFR of LEDAcrypt parameters, showing improvements by factors larger than $2^{70}$ (for NIST category $1$) with respect to the previous estimation techniques. This allows for a $\approx 20$% shortening in public key and ciphertext sizes, at no security loss, making the smallest ciphertext for NIST category $1$ only $6$% larger than the one of BIKE. We note that the analyzed two-iterations decoder is applicable in BIKE, where swapping it with the current black-gray decoder (and adjusting the parameters) would provide strong IND-CCA$2$ guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16919v3</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alessandro Annechini, Alessandro Barenghi, Gerardo Pelosi</dc:creator>
    </item>
    <item>
      <title>Typicality, entropy and the generalization of statistical mechanics</title>
      <link>https://arxiv.org/abs/2409.06537</link>
      <description>arXiv:2409.06537v2 Announce Type: replace-cross 
Abstract: When at equilibrium, large-scale systems obey conventional thermodynamics because they belong to microscopic configurations (or states) that are typical. Crucially, the typical states usually represent only a small fraction of the total number of possible states, and yet the characterization of the set of typical states -- the typical set -- alone is sufficient to describe the macroscopic behavior of a given system. Consequently, the concept of typicality, and the associated Asymptotic Equipartition Property allow for a drastic reduction of the degrees of freedom needed for system's statistical description. The mathematical rationale for such a simplification in the description is due to the phenomenon of concentration of measure. The later emerges for equilibrium configurations thanks to very strict constraints on the underlying dynamics, such as weekly interacting and (almost) independent system constituents. The question naturally arises as to whether the concentration of measure and related typicality considerations can be extended and applied to more general complex systems, and if so, what mathematical structure can be expected in the ensuing generalized thermodynamics. In this paper we illustrate the relevance of the concept of typicality in the toy model context of the "thermalized" coin and show how this leads naturally to Shannon entropy. We also show an intriguing connection: The characterization of typical sets in terms of Renyi and Tsallis entropies naturally leads to the free energy and partition function, respectively, and makes their relationship explicit. Finally, we propose potential ways to generalize the concept of typicality to systems where the standard microscopic assumptions do not hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06537v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1140/epjb/s10051-024-00764-7</arxiv:DOI>
      <arxiv:journal_reference>Eur. Phys. J. B 97, 129 (2024)</arxiv:journal_reference>
      <dc:creator>Bernat Corominas-Murtra, Rudolf Hanel, Petr Jizba</dc:creator>
    </item>
    <item>
      <title>Fast Matrix Multiplication meets the Submodular Width</title>
      <link>https://arxiv.org/abs/2412.06189</link>
      <description>arXiv:2412.06189v3 Announce Type: replace-cross 
Abstract: One fundamental question in database theory is the following: Given a Boolean conjunctive query Q, what is the best complexity for computing the answer to Q in terms of the input database size N? When restricted to the class of combinatorial algorithms, it is known that the best known complexity for any query Q is captured by the submodular width of Q. However, beyond combinatorial algorithms, certain queries are known to admit faster algorithms that often involve a clever combination of fast matrix multiplication and data partitioning. Nevertheless, there is no systematic way to derive and analyze the complexity of such algorithms for arbitrary queries Q.
  In this work, we introduce a general framework that captures the best complexity for answering any Boolean conjunctive query Q using matrix multiplication. Our framework unifies both combinatorial and non-combinatorial techniques under the umbrella of information theory. It generalizes the notion of submodular width to a new stronger notion called the omega-submodular width that naturally incorporates the power of fast matrix multiplication. We describe a matching algorithm that computes the answer to any query Q in time corresponding to the omega-submodular width of Q. We show that our framework recovers the best known complexities for Boolean queries that have been studied in the literature, to the best of our knowledge, and also discovers new algorithms for some classes of queries that improve upon the best known complexities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06189v3</guid>
      <category>cs.DB</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 14 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahmoud Abo-Khamis, Xiao Hu, Dan Suciu</dc:creator>
    </item>
  </channel>
</rss>
