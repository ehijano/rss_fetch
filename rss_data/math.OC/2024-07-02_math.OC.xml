<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Jul 2024 04:01:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 02 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Approximate Solutions for Multi-Trip Route Planning in Time-Sensitive Situations</title>
      <link>https://arxiv.org/abs/2407.00173</link>
      <description>arXiv:2407.00173v1 Announce Type: new 
Abstract: We consider emergent situations that require transporting individuals from their locations to a facility using a single capacitated vehicle, where transportation duration has a negative impact on the individuals. A dispatcher determines routes to maximize total satisfaction. We call this problem the Ambulance Bus Routing Problem. We develop efficient approximate policies for the dispatcher to allocate individuals to multiple routes, characterize an optimal solution of the relaxed approximate model, and devise a heuristic to obtain a near-optimal integer solution quickly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00173v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bahar Cavdar, Joseph Geunes, Xiaofeng Nie, Yue Wang</dc:creator>
    </item>
    <item>
      <title>Shape optimization of non-matching isogeometric shells with moving intersections</title>
      <link>https://arxiv.org/abs/2407.00185</link>
      <description>arXiv:2407.00185v1 Announce Type: new 
Abstract: While shape optimization using isogeometric shells exhibits appealing features by integrating design geometries and analysis models, challenges arise when addressing computer-aided design (CAD) geometries comprised of multiple non-uniform rational B-splines (NURBS) patches, which are common in practice. The intractability stems from surface intersections within these CAD models. In this paper, we develop an approach for shape optimization of non-matching isogeometric shells incorporating intersection movement. Separately parametrized NURBS surfaces are modeled using Kirchhoff--Love shell theory and coupled using a penalty-based formulation. The optimization scheme allows shell patches to move without preserving relative location with other members during the shape optimization. This flexibility is achieved through an implicit state function, and analytical sensitivities are derived for the relative movement of shell patches. The introduction of differentiable intersections expands the design space and overcomes challenges associated with large mesh distortion, particularly when optimal shapes involve significant movement of patch intersections in physical space. Throughout optimization iterations, all members within the shell structures maintain the NURBS geometry representation, enabling efficient integration of analysis and design models. The optimization approach leverages the multilevel design concept by selecting a refined model for accurate analysis from a coarse design model while maintaining the same geometry. We adopt several example problems to verify the effectiveness of the proposed scheme and demonstrate its applicability to the optimization of the internal stiffeners of an aircraft wing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00185v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Zhao, John T. Hwang, J. S. Chen</dc:creator>
    </item>
    <item>
      <title>Quadratic Optimal Control of Graphon Q-noise Linear Systems</title>
      <link>https://arxiv.org/abs/2407.00212</link>
      <description>arXiv:2407.00212v1 Announce Type: new 
Abstract: The modelling of linear quadratic Gaussian optimal control problems on large complex networks is intractable computationally. Graphon theory provides an approach to overcome these issues by defining limit objects for infinite sequences of graphs permitting one to approximate arbitrarily large networks by infinite dimensional operators. This is extended to stochastic systems by the use of Q-noise, a generalization of Wiener processes in finite dimensional spaces to processes in function spaces. The optimal control of linear quadratic problems on graphon systems with Q-noise disturbances are defined and shown to be the limit of the corresponding finite graph optimal control problem. The theory is extended to low rank systems, and a fully worked special case is presented. In addition, the worst-case long-range average and infinite horizon discounted optimal control performance with respect to Q-noise distribution are computed for a small set of standard graphon limits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00212v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex Dunyak, Peter E. Caines</dc:creator>
    </item>
    <item>
      <title>Vector-valued robust stochastic control</title>
      <link>https://arxiv.org/abs/2407.00266</link>
      <description>arXiv:2407.00266v1 Announce Type: new 
Abstract: We study a dynamic stochastic control problem subject to Knightian uncertainty with multi-objective (vector-valued) criteria. Assuming the preferences across expected multi-loss vectors are represented by a given, yet general, preorder, we address the model uncertainty by adopting a robust or minimax perspective, minimizing expected loss across the worst-case model. For loss functions taking real (or scalar) values, there is no ambiguity in interpreting supremum and infimum. In contrast to the scalar case, major challenges for multi-loss control problems include properly defining and interpreting the notions of supremum and infimum, and addressing the non-uniqueness of these suprema and infima. To deal with these, we employ the notion of an ideal point vector-valued supremum for the robust part of the problem, while we view the control part as a multi-objective (or vector) optimization problem. Using a set-valued framework, we derive both a weak and strong version of the dynamic programming principle (DPP) or Bellman equations by taking the value function as the collection of all worst expected losses across all feasible actions. The weak version of Bellman's principle is proved under minimal assumptions. To establish a stronger version of DPP, we introduce the rectangularity property with respect to a general preorder. We also further study a particular, but important, case of component-wise partial order of vectors, for which we additionally derive DPP under a different set-valued notion for the value function, the so-called upper image of the multi-objective problem. Finally, we provide illustrative examples motivated by financial problems.
  These results will serve as a foundation for addressing time-inconsistent problems subject to model uncertainty through the lens of a set-valued framework, as well as for studying multi-portfolio allocation problems under model uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00266v1</guid>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Igor Cialenco, Gabriela Kov\'a\v{c}ov\'a</dc:creator>
    </item>
    <item>
      <title>Deterministic and Stochastic Frank-Wolfe Recursion on Probability Spaces</title>
      <link>https://arxiv.org/abs/2407.00307</link>
      <description>arXiv:2407.00307v1 Announce Type: new 
Abstract: Motivated by applications in emergency response and experimental design, we consider smooth stochastic optimization problems over probability measures supported on compact subsets of the Euclidean space. With the influence function as the variational object, we construct a deterministic Frank-Wolfe (dFW) recursion for probability spaces, made especially possible by a lemma that identifies a ``closed-form'' solution to the infinite-dimensional Frank-Wolfe sub-problem. Each iterate in dFW is expressed as a convex combination of the incumbent iterate and a Dirac measure concentrating on the minimum of the influence function at the incumbent iterate. To address common application contexts that have access only to Monte Carlo observations of the objective and influence function, we construct a stochastic Frank-Wolfe (sFW) variation that generates a random sequence of probability measures constructed using minima of increasingly accurate estimates of the influence function. We demonstrate that sFW's optimality gap sequence exhibits $O(k^{-1})$ iteration complexity almost surely and in expectation for smooth convex objectives, and $O(k^{-1/2})$ (in Frank-Wolfe gap) for smooth non-convex objectives. Furthermore, we show that an easy-to-implement fixed-step, fixed-sample version of (sFW) exhibits exponential convergence to $\varepsilon$-optimality. We end with a central limit theorem on the observed objective values at the sequence of generated random measures. To further intuition, we include several illustrative examples with exact influence function calculations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00307v1</guid>
      <category>math.OC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Yu, Shane G. Henderson, Raghu Pasupathy</dc:creator>
    </item>
    <item>
      <title>Multicriteria Optimization and Decision Making: Principles, Algorithms and Case Studies</title>
      <link>https://arxiv.org/abs/2407.00359</link>
      <description>arXiv:2407.00359v1 Announce Type: new 
Abstract: Real-world decision and optimization problems, often involve constraints and conflicting criteria. For example, choosing a travel method must balance speed, cost, environmental footprint, and convenience. Similarly, designing an industrial process must consider safety, environmental impact, and cost efficiency. Ideal solutions where all objectives are optimally met are rare; instead, we seek good compromises and aim to avoid lose-lose scenarios. Multicriteria optimization offers computational techniques to compute Pareto optimal solutions, aiding decision analysis and decision making. This reader offers an introduction to this topic and has been developed on the basis of the revised edition of the reader for the MSc computer science course "Multicriteria Optimization and Decision Analysis" at the Leiden Institute of Advanced Computer Science, Leiden University, The Netherlands. This course was taught annually by the first author from 2007 to 2023 as a single semester course with lectures and practicals. The introduction is organized in a unique didactic manner developed by the authors, starting from more simple concepts such as linear programming and single-point methods, and advancing from these to more difficult concepts such as optimality conditions for nonlinear optimization and set-oriented solution algorithms. Besides, we focus on the mathematical modeling and foundations rather than on specific algorithms, though not excluding the discussion of some representative examples of solution algorithms. Our aim was to make the material accessible to MSc students who do not study mathematics as their core discipline by introducing basic numerical analysis concepts when necessary and providing numerical examples for interesting cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00359v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Emmerich, Andr\'e Deutz</dc:creator>
    </item>
    <item>
      <title>Weighted mesh algorithms for general Markov decision processes: Convergence and tractability</title>
      <link>https://arxiv.org/abs/2407.00388</link>
      <description>arXiv:2407.00388v1 Announce Type: new 
Abstract: We introduce a mesh-type approach for tackling discrete-time, finite-horizon Markov Decision Processes (MDPs) characterized by state and action spaces that are general, encompassing both finite and infinite (yet suitably regular) subsets of Euclidean space. In particular, for bounded state and action spaces, our algorithm achieves a computational complexity that is tractable in the sense of Novak and Wozniakowski, and is polynomial in the time horizon. For unbounded state space the algorithm is "semi-tractable" in the sense that the complexity is proportional to $\epsilon^{-c}$ with some dimension independent $c\geq2$, for achieving an accuracy $\epsilon$, and polynomial in the time horizon with degree linear in the underlying dimension. As such the proposed approach has some flavor of the randomization method by Rust which deals with infinite horizon MDPs and uniform sampling in compact state space. However, the present approach is essentially different due to the finite horizon and a simulation procedure due to general transition distributions, and more general in the sense that it encompasses unbounded state space. To demonstrate the effectiveness of our algorithm, we provide illustrations based on Linear-Quadratic Gaussian (LQG) control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00388v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Denis Belomestny, John Schoenmakers</dc:creator>
    </item>
    <item>
      <title>Existence of attracting periodic orbits in 3-dimensional strongly 2-cooperative systems</title>
      <link>https://arxiv.org/abs/2407.00461</link>
      <description>arXiv:2407.00461v1 Announce Type: new 
Abstract: The flow of a $k$-cooperative system maps the set of vectors with up to~$(k-1)$ sign variations to itself. In particular, $1$-cooperative systems are just cooperative systems. Strongly $2$-cooperative systems satisfy a strong \Poincare-Bendixson property: any bounded solution that evolves in a compact set containing no equilibria converges to a periodic orbit. For $3$-dimensional strongly $2$-cooperative nonlinear systems, we provide a sufficient condition that guarantees the existence of an invariant compact set in the state space that includes an attracting periodic orbit. We show that our theoretical results unify and generalize known results on the existence of a periodic solution in two well-known models in biochemistry, a 3D Goodwin oscillator model and the 3D Field-Noyes ordinary-differential-equation (ODE) model for the Belousov-Zhabotinskii reaction, while simplifying the proofs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00461v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rami Katz, Giulia Giordano, Michael Margaliot</dc:creator>
    </item>
    <item>
      <title>Assessing the Value of Coupling Thermal Energy Storage with Air-Source Heat Pumps for Residential Space Heating in U.S. Cities</title>
      <link>https://arxiv.org/abs/2407.00527</link>
      <description>arXiv:2407.00527v1 Announce Type: new 
Abstract: Widespread air source heat pump (ASHP) adoption faces several challenges that on-site thermal energy storage (TES), particularly thermochemical salt hydrate TES, can mitigate. No techno-economic analyses for salt-hydrate-based TES in residential applications exist. We quantify the residential space heating value of four salt hydrate TES materials - MgSO4, MgCl2, K2CO3, and SrBr2 - coupled with ASHPs across 4,800 representative households in 12 U.S. cities by embedding salt-hydrate-specific Ragone plots into a techno-economic model of coupled ASHP-TES operations. In Detroit, salt hydrate TES is projected to reduce household annual electricity costs by up to $\$$241 (8$\%$). Cost savings from TES can differ by over an order of magnitude between households and salt hydrates. We identify the most promising salt in this study, SrBr2, due to its high energy density and low humidification parasitic load. Break-even capital costs of SrBr2-based TES range from $\$$13/kWh to $\$$17/kWh, making it the only salt hydrate studied to reach and exceed the U.S. Department of Energy's $\$$15/kWh TES cost target. Sensitivities highlight the importance of variable TES sizing and efficiency losses in the value of TES.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00527v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>An T. Pham, Bryan Kinzer, Ritvik Jain, Rohini Bala Chandran, Michael T. Craig</dc:creator>
    </item>
    <item>
      <title>Nash equilibrium in a singular stochastic game between two renewable power producers with price impact</title>
      <link>https://arxiv.org/abs/2407.00666</link>
      <description>arXiv:2407.00666v1 Announce Type: new 
Abstract: In this paper we solve the general problem, already formulated in Awerkin and Vargiolu (Decis. Econ. Finance 44(2), 2021) of finding a Nash equilibrium between two agents who can install irreversibly photovoltaic panels in order to maximize their profits of selling the produced electricity net of installation costs, in the case that their cumulative installations have an impact on power prices. Starting from a static version of the game, we find out that there exists a region in the state space where Nash equilibrium dictates that both players install, and in some cases this optimal installation strategy is non-unique. We then come back to the original continuous time problem, which needs a generalization of the Verification Theorem present in Awerkin and Vargiolu (Decis. Econ. Finance 44(2), 2021), taking into account a lack of smoothness of the value functions and the possible non-uniqueness of optimal strategies seen above. Finally, we explicitly construct the equilibrium strategies and the value functions, which depend on the two free boundaries which separate the region where each player installs or waits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00666v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefano Pagliarani, Antonello Pesce, Tiziano Vargiolu</dc:creator>
    </item>
    <item>
      <title>Gradient directions and relative inexactness in optimization and machine learning</title>
      <link>https://arxiv.org/abs/2407.00667</link>
      <description>arXiv:2407.00667v1 Announce Type: new 
Abstract: In this paper, we investigate the influence of noise giving an estimate of the gradient having a acute angle with the original. Noise amplitude has a relative model. The work offers both theoretical calculations and theorems, as well as experimental results. Classic machine learning problems were chosen as experiments -- linear and logistic regression, computer vision and natural language processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00667v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Artem Vasin</dc:creator>
    </item>
    <item>
      <title>Unified Control Framework for Optimization: A Fresh Perspective on Constrained Optimization, Optimization-based Control, and Parameter Estimation</title>
      <link>https://arxiv.org/abs/2407.00780</link>
      <description>arXiv:2407.00780v1 Announce Type: new 
Abstract: A common theme in all the above areas is designing a dynamical system to accomplish desired objectives, possibly in some predefined optimal way. Since control theory advances the idea of suitably modifying the behavior of a dynamical system, this paper explores the role of control theory in designing efficient algorithms (or dynamical systems) related to problems surrounding the optimization framework, including constrained optimization, optimization-based control, and parameter estimation. This amalgamation of control theory with the above-mentioned areas has been made possible by the recently introduced paradigm of Passivity and Immersion (P\&amp;I) based control. The generality and working of P\&amp;I, as compared to the existing approaches in control theory, are best introduced through the example presented below.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00780v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Revati Gunjal, Syed Shadab Nayyer, Sushama Wagh, Navdeep Singh</dc:creator>
    </item>
    <item>
      <title>Convergence of Descent Methods under Kurdyka-\L ojasiewicz Properties</title>
      <link>https://arxiv.org/abs/2407.00812</link>
      <description>arXiv:2407.00812v1 Announce Type: new 
Abstract: This paper develops the novel convergence analysis of a generic class of descent methods in nonsmooth and nonconvex optimization under several versions of the Kurdyka-\L ojasiewicz (KL) property. Along other results, we prove the finite termination of generic algorithms under the KL property with lower exponents. Specifications are given to convergence rates of some particular algorithms including inexact reduced gradient methods and the boosted algorithm in DC programming. It revealed, e.g., that the lower exponent KL property in the DC framework is incompatible with the gradient Lipschitz continuity for the plus function around a local minimizer. On the other hand, we show that the above inconsistency observation may fail if the Lipschitz continuity is replaced by merely the gradient continuity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00812v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>G. C. Bento, B. S. Mordukhovich, T. S. Mota, Yu. Nesterov</dc:creator>
    </item>
    <item>
      <title>Incorporating Service Reliability in Multi-depot Vehicle Scheduling</title>
      <link>https://arxiv.org/abs/2407.00836</link>
      <description>arXiv:2407.00836v1 Announce Type: new 
Abstract: The multi-depot vehicle scheduling problem (MDVSP) is a critical planning challenge for transit agencies. We introduce a novel approach to MDVSP by incorporating service reliability through chance-constrained programming (CCP), targeting the pivotal issue of travel time uncertainty and its impact on transit service quality. Our model guarantees service reliability measured by on-time performance (OTP), a primary metric for transit agencies, and fairness across different service areas.We propose an exact branch-and-cut (B&amp;C) scheme to solve our CCP model. We present several cut-generation procedures that exploit the underlying problem structure and analyze the relationship between the obtained cut families. Additionally, we design a Lagrangian-based heuristic to handle large-scale instances reflective of real-world transit operations. Our approach partitions the set of trips, each subset leading to a subproblem that can be efficiently solved with our B&amp;C algorithm, and then employs a procedure to combine the subproblem solutions to create a vehicle schedule that satisfies all the planning constraints of the MDVSP. Our empirical evaluation demonstrates the superiority of our stochastic variant in achieving cost-effective schedules with reliable OTP guarantees compared to alternatives commonly used by practitioners, as well as the computational benefits of our methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00836v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Margarita P. Castro, Merve Bodur, Amer Shalaby</dc:creator>
    </item>
    <item>
      <title>A Unified Approach to Extract Intepretable Rules from Tree Ensembles via Integer Programming</title>
      <link>https://arxiv.org/abs/2407.00843</link>
      <description>arXiv:2407.00843v1 Announce Type: new 
Abstract: Tree ensemble methods represent a popular machine learning model, known for their effectiveness in supervised classification and regression tasks. Their performance derives from aggregating predictions of multiple decision trees, which are renowned for their interpretability properties. However, tree ensemble methods do not reliably exhibit interpretable output. Our work aims to extract an optimized list of rules from a trained tree ensemble, providing the user with a condensed, interpretable model that retains most of the predictive power of the full model. Our approach consists of solving a clean and neat set partitioning problem formulated through Integer Programming. The proposed method works with either tabular or time series data, for both classification and regression tasks, and does not require parameter tuning under the most common setting. Through rigorous computational experiments, we offer statistically significant evidence that our method is competitive with other rule extraction methods and effectively handles time series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00843v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Bonasera, Emilio Carrizosa</dc:creator>
    </item>
    <item>
      <title>BattOpt: Optimal Facility Planning for Electric Vehicle Battery Recycling</title>
      <link>https://arxiv.org/abs/2407.00864</link>
      <description>arXiv:2407.00864v1 Announce Type: new 
Abstract: The electric vehicle (EV) battery supply chain will face challenges in sourcing scarce, expensive minerals required for manufacturing and in disposing of hazardous retired batteries. Integrating recycling technology into the supply chain has the potential to alleviate these issues; however, players in the battery market must design investment plans for recycling facilities. In this paper, we propose a two-stage stochastic optimization model for computing minimum cost recycling capacity decisions, in which retired batteries are recycled and recovered materials are used to manufacture new batteries. The model is a separable concave minimization subject to linear constraints, a class for which we design a new finitely convergent global optimization algorithm based on piecewise linear approximation that solves up to 10x faster than comparable algorithms. We propose an equivalent reformulation of the model that reduces the total number of variables by introducing integrality constraints. The reformulation can also be solved by our global algorithm with drastically reduced solve times. We detail a cut grouping strategy for Benders' decomposition in the second stage which improves convergence relative to single-cut and multi-cut implementations. To produce a set of second-stage scenarios, we design an approach for generating time-series projections for new battery demand, retired battery supply, and material costs. Analysis of the optimal solutions shows that effective investment in recycling can reduce battery manufacturing costs by 22% and reduce environmental impacts by up to 7%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00864v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Brun, Xu Andy Sun</dc:creator>
    </item>
    <item>
      <title>Infinite-dimensional Christoffel-Darboux polynomial kernels on Hilbert spaces</title>
      <link>https://arxiv.org/abs/2407.01021</link>
      <description>arXiv:2407.01021v1 Announce Type: new 
Abstract: In these notes, the Christoffel-Darboux polynomial kernel  is extended to infinite-dimensional Hilbert spaces, following as closely as possible its original finite-dimensional treatment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01021v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Didier Henrion (LAAS-POP)</dc:creator>
    </item>
    <item>
      <title>On Some Versions of Subspace Optimization Methods with Inexact Gradient Information</title>
      <link>https://arxiv.org/abs/2407.01051</link>
      <description>arXiv:2407.01051v1 Announce Type: new 
Abstract: It is well-known that accelerated gradient first order methods possess optimal complexity estimates for the class of convex smooth minimization problems. In many practical situations, it makes sense to work with inexact gradients. However, this can lead to the accumulation of corresponding inexactness in the theoretical estimates of the rate of convergence. We propose some modification of the methods for convex optimization with inexact gradient based on the subspace optimization such as Nemirovski's Conjugate Gradients and Sequential Subspace Optimization. We research the method convergence for different condition of inexactness both in gradient value and accuracy of subspace optimization problems. Besides this, we investigate generalization of this result to the class of quasar-convex (weakly-quasi-convex) functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01051v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ilya Kuruzov, Fedor Stonyakin</dc:creator>
    </item>
    <item>
      <title>Multistage stochastic optimization of a mono-site hydrogen infrastructure by decomposition techniques</title>
      <link>https://arxiv.org/abs/2407.01053</link>
      <description>arXiv:2407.01053v1 Announce Type: new 
Abstract: The development of hydrogen infrastructures requires to reduce their costs.  In this paper, we develop a multistage stochastic optimization model for the  management of a hydrogen infrastructure which consists of an electrolyser, a  compressor and a storage to serve a transportation demand. This infrastructure  is powered by three different sources: on-site photovoltaic panels (PV),  renewable energy through a power purchase agreement (PPA) and the power grid. We  consider uncertainties affecting on-site photovoltaic production and hydrogen  demand.  Renewable energy sources are emphasized in the hydrogen production  process to ensure eligibility for a subsidy, which is awarded if the proportion  of nonrenewable electricity usage stays under a predetermined threshold. We  solve the multistage stochastic optimization problem using a decomposition  method based on Lagrange duality. The numerical results indicate that the  solution to this problem, formulated as a policy, achieves a small duality gap,  thus proving the effectiveness of this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01053v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raian Lefgoum (CERMICS), Sezin Afsar (UMA), Pierre Carpentier (UMA), Jean-Philippe Chancelier (CERMICS), Michel de Lara (CERMICS)</dc:creator>
    </item>
    <item>
      <title>Sharper Exponential Convergence Rates for Sinkhorn's Algorithm in Continuous Settings</title>
      <link>https://arxiv.org/abs/2407.01202</link>
      <description>arXiv:2407.01202v1 Announce Type: new 
Abstract: We study the convergence rate of Sinkhorn's algorithm for solving entropy-regularized optimal transport problems when at least one of the probability measures, $\mu$, admits a density over $\mathbb{R}^d$. For a semi-concave cost function bounded by $c_{\infty}$ and a regularization parameter $\lambda &gt; 0$, we obtain exponential convergence guarantees on the dual sub-optimality gap with contraction rate polynomial in $\lambda/c_{\infty}$. This represents an exponential improvement over the known contraction rate $1 - \Theta(\exp(-c_{\infty}/\lambda))$ achievable via Hilbert's projective metric. Specifically, we prove a contraction rate value of $1-\Theta(\lambda^2/c_\infty^2)$ when $\mu$ has a bounded log-density. In some cases, such as when $\mu$ is log-concave and the cost function is $c(x,y)=-\langle x, y \rangle$, this rate improves to $1-\Theta(\lambda/c_\infty)$. The latter rate matches the one that we derive for the transport between isotropic Gaussian measures, indicating tightness in the dependency in $\lambda/c_\infty$. Our results are fully non-asymptotic and explicit in all the parameters of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01202v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>L\'ena\"ic Chizat, Alex Delalande, Tomas Va\v{s}kevi\v{c}ius</dc:creator>
    </item>
    <item>
      <title>Optimal Control of a Power Storage Facility with Variable Payoffs</title>
      <link>https://arxiv.org/abs/2407.01234</link>
      <description>arXiv:2407.01234v1 Announce Type: new 
Abstract: We present a methodology for determining the relationship between the optimal control points of a power storage facility and a number of different factors including storage level and temperature. The interaction between different factors is considered to allow for the identification of a precise optimal control strategy to maximise the profits of a power storage facility under a variety of different conditions. The methodology is based upon traditional stochastic techniques, however by working directly with excess demand data is model independent and does not require identification of the underlying process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01234v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fraser J W O'Brien, Timothy C Johnson</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Performative Optimization</title>
      <link>https://arxiv.org/abs/2407.01344</link>
      <description>arXiv:2407.01344v1 Announce Type: new 
Abstract: In this paper, we propose a general distributionally robust framework for performative optimization, where the selected decision can influence the probabilistic distribution of uncertain parameters. Our framework facilitates safe decision-making in scenarios with incomplete information about the underlying decision-dependent distributions, relying instead on accessible reference distributions. To tackle the challenge of decision-dependent uncertainty, we introduce an algorithm named repeated robust risk minimization. This algorithm decouples the decision variables associated with the ambiguity set from the expected loss, optimizing the latter at each iteration while keeping the former fixed to the previous decision. By leveraging the strong connection between distributionally robust optimization and regularization, we establish a linear convergence rate to a performatively stable point and provide a suboptimality performance guarantee for the proposed algorithm. Finally, we examine the performance of our proposed model through an experimental study in strategic classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01344v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhuangzhuang Jia, Yijie Wang, Roy Dong, Grani A. Hanasusanto</dc:creator>
    </item>
    <item>
      <title>Mechanism design for coordinating vehicle-based mobile sensing tasks within the ride-hailing platform</title>
      <link>https://arxiv.org/abs/2407.01363</link>
      <description>arXiv:2407.01363v1 Announce Type: new 
Abstract: This paper evaluates the benefit of integrating vehicle-based mobile crowd-sensing tasks into the ride-hailing system through the collaboration between the data user and the ride-hailing platform. In such a system, the ride-hailing platform commissions high-valued sensing tasks to idle drivers who can undertake either ride-hailing or sensing requests. Considering the different service requirements and time windows between sensing and ride-hailing requests, we design a staggered operation strategy for ride-hailing order matching and the sensing task assignment. The auction-based mechanisms are employed to minimize costs while incentivizing driver participation in mobile sensing. To address the budget deficit problem of the primal VCG-based task assignment mechanism, we refine the driver selection approach and tailor the payment rule by imposing additional budget constraints. We demonstrate the benefits of our proposed mechanism through a series of numerical experiments using the NYC Taxi data. Experimental results reveal the potential of the mechanism for achieving high completion rates of sensing tasks at low social costs without degrading ride-hailing services. Furthermore, drivers who participate in both mobile sensing tasks and ride-hailing requests may gain higher income, but this advantage may diminish with an increasing number of such drivers and higher demand for ride-hailing services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01363v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shenglin Liu, Qian Ge, Ke Han, Daisuke Fukuda, Takao Dantsuji</dc:creator>
    </item>
    <item>
      <title>Reinvestigating the R2 Indicator: Achieving Pareto Compliance by Integration</title>
      <link>https://arxiv.org/abs/2407.01504</link>
      <description>arXiv:2407.01504v1 Announce Type: new 
Abstract: In multi-objective optimization, set-based quality indicators are a cornerstone of benchmarking and performance assessment. They capture the quality of a set of trade-off solutions by reducing it to a scalar number. One of the most commonly used set-based metrics is the R2 indicator, which describes the expected utility of a solution set to a decision-maker under a distribution of utility functions. Typically, this indicator is applied by discretizing this distribution of utility functions, yielding a weakly Pareto-compliant indicator. In consequence, adding a nondominated or dominating solution to a solution set may - but does not have to - improve the indicator's value.
  In this paper, we reinvestigate the R2 indicator under the premise that we have a continuous, uniform distribution of (Tchebycheff) utility functions. We analyze its properties in detail, demonstrating that this continuous variant is indeed Pareto-compliant - that is, any beneficial solution will improve the metric's value. Additionally, we provide an efficient computational procedure to compute this metric for bi-objective problems in $\mathcal O (N \log N)$. As a result, this work contributes to the state-of-the-art Pareto-compliant unary performance metrics, such as the hypervolume indicator, offering an efficient and promising alternative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01504v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lennart Sch\"apermeier, Pascal Kerschke</dc:creator>
    </item>
    <item>
      <title>A mathematical model for droplet separation by surface tension using contact cantilevers -- applications to {\it{in situ}} diagnosis and treatment</title>
      <link>https://arxiv.org/abs/2407.00027</link>
      <description>arXiv:2407.00027v1 Announce Type: cross 
Abstract: This work provides an exact mathematical characterization of the meniscus formed by a liquid of density $\rho$ (model for tumor tissue) when probed with a cantilever device, operating by gravity (acceleration $g$) and with surface tension coefficient $\sigma$ (material-dependent for the specific choice of liquid and cantilever). The shape and extremal parameters (maximum height $\mathcal{H}$, break-off volume $\mathcal{V}$) of the meniscus formed, as functions of $\sigma, \rho$, are found by an exact analysis. Having knowledge of the explicit relationship between these parameters allows to perform in one procedure both diagnosis and treatment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00027v1</guid>
      <category>q-bio.TO</category>
      <category>math.OC</category>
      <category>physics.bio-ph</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sonia Elizabeth Teodorescu</dc:creator>
    </item>
    <item>
      <title>D&amp;A: Resource Optimisation in Personalised PageRank Computations Using Multi-Core Machines</title>
      <link>https://arxiv.org/abs/2407.00068</link>
      <description>arXiv:2407.00068v1 Announce Type: cross 
Abstract: Resource optimisation is commonly used in workload management, ensuring efficient and timely task completion utilising available resources. It serves to minimise costs, prompting the development of numerous algorithms tailored to this end. The majority of these techniques focus on scheduling and executing workloads effectively within the provided resource constraints. In this paper, we tackle this problem using another approach. We propose a novel framework D&amp;A to determine the number of cores required in completing a workload under time constraint. We first preprocess a small portion of queries to derive the number of required slots, allowing for the allocation of the remaining workloads into each slot. We introduce a scaling factor in handling the time fluctuation issue caused by random functions. We further establish a lower bound of the number of cores required under this scenario, serving as a baseline for comparison purposes. We examine the framework by computing personalised PageRank values involving intensive computations. Our experimental results show that D&amp;A surpasses the baseline, achieving reductions in the required number of cores ranging from 38.89% to 73.68% across benchmark datasets comprising millions of vertices and edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00068v1</guid>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kai Siong Yow, Chunbo Li</dc:creator>
    </item>
    <item>
      <title>Exploiting Structure in Quantum Relative Entropy Programs</title>
      <link>https://arxiv.org/abs/2407.00241</link>
      <description>arXiv:2407.00241v1 Announce Type: cross 
Abstract: Quantum relative entropy programs are convex optimization problems which minimize a linear functional over an affine section of the epigraph of the quantum relative entropy function. Recently, the self-concordance of a natural barrier function was proved for this set. This has opened up the opportunity to use interior-point methods for nonsymmetric cone programs to solve these optimization problems. In this paper, we show how common structures arising from applications in quantum information theory can be exploited to improve the efficiency of solving quantum relative entropy programs using interior-point methods. First, we show that the natural barrier function for the epigraph of the quantum relative entropy composed with positive linear operators is optimally self-concordant, even when these linear operators map to singular matrices. Second, we show how we can exploit a catalogue of common structures in these linear operators to compute the inverse Hessian products of the barrier function more efficiently. This step is typically the bottleneck when solving quantum relative entropy programs using interior-point methods, and therefore improving the efficiency of this step can significantly improve the computational performance of the algorithm. We demonstrate how these methods can be applied to important applications in quantum information theory, including quantum key distribution, quantum rate-distortion, quantum channel capacities, and estimating the ground state energy of Hamiltonians. Our numerical results show that these techniques improve computation times by up to several orders of magnitude, and allow previously intractable problems to be solved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00241v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kerry He, James Saunderson, Hamza Fawzi</dc:creator>
    </item>
    <item>
      <title>Safe and Stable Filter Design Using a Relaxed Compatibitlity Control Barrier -- Lyapunov Condition</title>
      <link>https://arxiv.org/abs/2407.00414</link>
      <description>arXiv:2407.00414v1 Announce Type: cross 
Abstract: In this paper, we propose a quadratic programming-based filter for safe and stable controller design, via a Control Barrier Function (CBF) and a Control Lyapunov Function (CLF). Our method guarantees safety and local asymptotic stability without the need for an asymptotically stabilizing control law. Feasibility of the proposed program is ensured under a mild regularity condition, termed relaxed compatibility between the CLF and CBF. The resulting optimal control law is guaranteed to be locally Lipschitz continuous. We also analyze the closed-loop behaviour by characterizing the equilibrium points, and verifying that there are no equilibrium points in the interior of the control invariant set except at the origin. For a polynomial system and a semi-algebraic safe set, we provide a sum-of-squares program to design a relaxed compatible pair of CLF and CBF. The proposed approach is compared with other methods in the literature using numerical examples, exhibits superior filter performance and guarantees safety and local stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00414v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Han Wang, Kostas Margellos, Antonis Papachristodoulou</dc:creator>
    </item>
    <item>
      <title>Toward Global Convergence of Gradient EM for Over-Parameterized Gaussian Mixture Models</title>
      <link>https://arxiv.org/abs/2407.00490</link>
      <description>arXiv:2407.00490v1 Announce Type: cross 
Abstract: We study the gradient Expectation-Maximization (EM) algorithm for Gaussian Mixture Models (GMM) in the over-parameterized setting, where a general GMM with $n&gt;1$ components learns from data that are generated by a single ground truth Gaussian distribution. While results for the special case of 2-Gaussian mixtures are well-known, a general global convergence analysis for arbitrary $n$ remains unresolved and faces several new technical barriers since the convergence becomes sub-linear and non-monotonic. To address these challenges, we construct a novel likelihood-based convergence analysis framework and rigorously prove that gradient EM converges globally with a sublinear rate $O(1/\sqrt{t})$. This is the first global convergence result for Gaussian mixtures with more than $2$ components. The sublinear convergence rate is due to the algorithmic nature of learning over-parameterized GMM with gradient EM. We also identify a new emerging technical challenge for learning general over-parameterized GMM: the existence of bad local regions that can trap gradient EM for an exponential number of steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00490v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Weihang Xu, Maryam Fazel, Simon S. Du</dc:creator>
    </item>
    <item>
      <title>DCI: An Accurate Quality Assessment Criteria for Protein Complex Structure Models</title>
      <link>https://arxiv.org/abs/2407.00560</link>
      <description>arXiv:2407.00560v1 Announce Type: cross 
Abstract: The structure of proteins is the basis for studying protein function and drug design. The emergence of AlphaFold 2 has greatly promoted the prediction of protein 3D structures, and it is of great significance to give an overall and accurate evaluation of the predicted models, especially the complex models. Among the existing methods for evaluating multimer structures, DockQ is the most commonly used. However, as a more suitable metric for complex docking, DockQ cannot provide a unique and accurate evaluation in the non-docking situation. Therefore, it is necessary to propose an evaluation strategy that can directly evaluate the whole complex without limitation and achieve good results. In this work, we proposed DCI score, a new evaluation strategy for protein complex structure models, which only bases on distance map and CI (contact-interface) map, DCI focuses on the prediction accuracy of the contact interface based on the overall evaluation of complex structure, is not inferior to DockQ in the evaluation accuracy according to CAPRI classification, and is able to handle the non-docking situation better than DockQ. Besides, we calculated DCI score on CASP datasets and compared it with CASP official assessment, which obtained good results. In addition, we found that DCI can better evaluate the overall structure deviation caused by interface prediction errors in the case of multi-chains. Our DCI is available at \url{https://gitee.com/WendaWang/DCI-score.git}, and the online-server is available at \url{http://mialab.ruc.edu.cn/DCIServer/}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00560v1</guid>
      <category>q-bio.BM</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenda Wang, Jiaqi Zhai, He Huang, Xinqi Gong</dc:creator>
    </item>
    <item>
      <title>Sum-of-norms regularized Nonnegative Matrix Factorization</title>
      <link>https://arxiv.org/abs/2407.00706</link>
      <description>arXiv:2407.00706v1 Announce Type: cross 
Abstract: When applying nonnegative matrix factorization (NMF), generally the rank parameter is unknown. Such rank in NMF, called the nonnegative rank, is usually estimated heuristically since computing the exact value of it is NP-hard. In this work, we propose an approximation method to estimate such rank while solving NMF on-the-fly. We use sum-of-norm (SON), a group-lasso structure that encourages pairwise similarity, to reduce the rank of a factor matrix where the rank is overestimated at the beginning. On various datasets, SON-NMF is able to reveal the correct nonnegative rank of the data without any prior knowledge nor tuning.
  SON-NMF is a nonconvx nonsmmoth non-separable non-proximable problem, solving it is nontrivial. First, as rank estimation in NMF is NP-hard, the proposed approach does not enjoy a lower computational complexity. Using a graph-theoretic argument, we prove that the complexity of the SON-NMF is almost irreducible. Second, the per-iteration cost of any algorithm solving SON-NMF is possibly high, which motivated us to propose a first-order BCD algorithm to approximately solve SON-NMF with a low per-iteration cost, in which we do so by the proximal average operator. Lastly, we propose a simple greedy method for post-processing.
  SON-NMF exhibits favourable features for applications. Beside the ability to automatically estimate the rank from data, SON-NMF can deal with rank-deficient data matrix, can detect weak component with small energy. Furthermore, on the application of hyperspectral imaging, SON-NMF handle the issue of spectral variability naturally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00706v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andersen Ang, Waqas Bin Hamed, Hans De Sterck</dc:creator>
    </item>
    <item>
      <title>Two results from Mandelbaum's paper: "The dynamic complementarity problem"</title>
      <link>https://arxiv.org/abs/2407.00833</link>
      <description>arXiv:2407.00833v1 Announce Type: cross 
Abstract: A draft of a paper by Mandelbaum, "The dynamic complementarity problem", was circulated in 1987, but has never been published. We give an exposition of two important results from that paper which are not readily accessible in the literature.
  The first is an example of a Skorokhod problem in two dimensions in the quadrant for which there is not uniqueness. The second is a proof of uniqueness for the Skorokhod problem in two dimensions in the quadrant in a critical case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00833v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard Bass</dc:creator>
    </item>
    <item>
      <title>Portfolio optimisation: bridging the gap between theory and practice</title>
      <link>https://arxiv.org/abs/2407.00887</link>
      <description>arXiv:2407.00887v1 Announce Type: cross 
Abstract: Portfolio optimisation is widely acknowledged for its significance in investment decision-making. Yet, existing methodologies face several limitations, among them converting optimal theoretical portfolios into real investment is not always straightforward. Several classes of exogenous (real-world) constraints have been proposed in literature with the intent of reducing the gap between theory and practice, which have worked to an extent.
  In this paper, we propose an optimisation-based framework which attempts to further reduce this gap. We have the explicit intention of producing portfolios that can be immediately converted into financial holdings. Our proposed framework is generic in the sense that it can be used in conjunction with any portfolio selection model, and consists of splitting the portfolio selection problem into two-stages. The main motivation behind this approach is in enabling automated investing with minimal human intervention, and thus the framework was built in such a way that real-world market features can be incorporated with relative ease. Among the novel contributions of this paper, this is the first work, to the best of our knowledge, to combine futures contracts and equities in a single framework, and also the first to consider borrowing costs in short positions.
  We present extensive computational results to illustrate the applicability of our approach and to evaluate its overall quality. Among these experiments, we observed that alternatives from literature are susceptible to numerical errors, whereas our approach effectively mitigates this issue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00887v1</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cristiano Arbex Valle</dc:creator>
    </item>
    <item>
      <title>Modified CMA-ES Algorithm for Multi-Modal Optimization: Incorporating Niching Strategies and Dynamic Adaptation Mechanism</title>
      <link>https://arxiv.org/abs/2407.00939</link>
      <description>arXiv:2407.00939v1 Announce Type: cross 
Abstract: This study modifies the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) algorithm for multi-modal optimization problems. The enhancements focus on addressing the challenges of multiple global minima, improving the algorithm's ability to maintain diversity and explore complex fitness landscapes. We incorporate niching strategies and dynamic adaptation mechanisms to refine the algorithm's performance in identifying and optimizing multiple global optima. The algorithm generates a population of candidate solutions by sampling from a multivariate normal distribution centered around the current mean vector, with the spread determined by the step size and covariance matrix. Each solution's fitness is evaluated as a weighted sum of its contributions to all global minima, maintaining population diversity and preventing premature convergence. We implemented the algorithm on 8 tunable composite functions for the GECCO 2024 Competition on Benchmarking Niching Methods for Multi-Modal Optimization (MMO), adhering to the competition's benchmarking framework. The results are presenting in many ways such as Peak Ratio, F1 score on various dimensions. They demonstrate the algorithm's robustness and effectiveness in handling both global optimization and MMO- specific challenges, providing a comprehensive solution for complex multi-modal optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00939v1</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wathsala Karunarathne, Indu Bala, Dikshit Chauhan, Matthew Roughan, Lewis Mitchell</dc:creator>
    </item>
    <item>
      <title>An Abstract Lyapunov Control Optimizer: Local Stabilization and Global Convergence</title>
      <link>https://arxiv.org/abs/2407.01019</link>
      <description>arXiv:2407.01019v1 Announce Type: cross 
Abstract: Recently, many machine learning optimizers have been analysed considering them as the asymptotic limit of some differential equations when the step size goes to zero. In other words, the optimizers can be seen as a finite difference scheme applied to a continuous dynamical system. But the major part of the results in the literature concerns constant step size algorithms. The main aim of this paper is to investigate the guarantees of the adaptive step size counterpart. In fact, this dynamical point of view can be used to design step size update rules, by choosing a discretization of the continuous equation that preserves its most relevant features. In this work, we analyse this kind of adaptive optimizers and prove their Lyapunov stability and convergence properties for any choice of hyperparameters. At the best of our knowledge, this paper introduces for the first time the use of continuous selection theory from general topology to overcome some of the intrinsic difficulties due to the non constant and non regular step size policies. The general framework developed gives many new results on adaptive and constant step size Momentum/Heavy-Ball and p-GD algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01019v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bilel Bensaid (IMB, CEA CESTA), Ga\"el Po\"ette (CEA CESTA), Rodolphe Turpault (IMB)</dc:creator>
    </item>
    <item>
      <title>A note on the maximization of the first Dirichlet eigenvalue for perforated planar domains</title>
      <link>https://arxiv.org/abs/2407.01237</link>
      <description>arXiv:2407.01237v1 Announce Type: cross 
Abstract: In this work we prove that given an open bounded set $\Omega \subset \mathbb{R}^2$ with a $C^2$ boundary, there exists $\epsilon := \epsilon(\Omega)$ small enough such that for all $0 &lt; \delta &lt; \epsilon$ the maximum of $\{\lambda_1(\Omega - B_{\delta}(x)):B_{\delta} \subset \Omega\}$ is never attained when the ball is close enough to the boundary. In particular it is not obtained when $B_\delta(x)$ is touching the boundary $\partial \Omega$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01237v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Dias</dc:creator>
    </item>
    <item>
      <title>Bundle type sub-Riemannian structures on holonomy bundles</title>
      <link>https://arxiv.org/abs/2407.01427</link>
      <description>arXiv:2407.01427v1 Announce Type: cross 
Abstract: In this paper, combining the Rashevsky-Chow-Sussmann (orbit) theorem with the Ambrose-Singer theorem, we introduce the notion of controllable principal connections on principal $G$-bundles. Using this concept, under a mild assumption of compactness, we estimate the Gromov-Hausdorff distance between principal $G$-bundles and certain reductive homogeneous $G$-spaces. In addition, we prove that every reduction of the structure group $G$ to a closed connected subgroup gives rise to a sequence of Riemannian metrics on the total space for which the underlying sequence of metric spaces converges, in the Gromov-Housdorff topology, to a normal reductive homogeneous $G$-space. This last finding allows one to detect the presence of certain reductive homogeneous $G$-spaces in the Gromov-Housdorff closure of the moduli space of Riemannian metrics of the total space of the bundle through topological invariants provided by obstruction theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01427v1</guid>
      <category>math.DG</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eder M. Correa, Giovane Galindo, Lino Grama</dc:creator>
    </item>
    <item>
      <title>How Clustering Affects the Convergence of Decentralized Optimization over Networks: A Monte-Carlo-based Approach</title>
      <link>https://arxiv.org/abs/2407.01460</link>
      <description>arXiv:2407.01460v1 Announce Type: cross 
Abstract: Decentralized algorithms have gained substantial interest owing to advancements in cloud computing, Internet of Things (IoT), intelligent transportation networks, and parallel processing over sensor networks. The convergence of such algorithms is directly related to specific properties of the underlying network topology. Specifically, the clustering coefficient is known to affect, for example, the controllability/observability and the epidemic growth over networks. In this work, we study the effects of the clustering coefficient on the convergence rate of networked optimization approaches. In this regard, we model the structure of large-scale distributed systems by random scale-free (SF) and clustered scale-free (CSF) networks and compare the convergence rate by tuning the network clustering coefficient. This is done by keeping other relevant network properties (such as power-law degree distribution, number of links, and average degree) unchanged. Monte-Carlo-based simulations are used to compare the convergence rate over many trials of SF graph topologies. Furthermore, to study the convergence rate over real case studies, we compare the clustering coefficient of some real-world networks with the eigenspectrum of the underlying network (as a measure of convergence rate). The results interestingly show higher convergence rate over low-clustered networks. This is significant as one can improve the learning rate of many existing decentralized machine-learning scenarios by tuning the network clustering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01460v1</guid>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammadreza Doostmohammadian, Shahaboddin Kharazmi, Hamid R. Rabiee</dc:creator>
    </item>
    <item>
      <title>Scalable Nested Optimization for Deep Learning</title>
      <link>https://arxiv.org/abs/2407.01526</link>
      <description>arXiv:2407.01526v1 Announce Type: cross 
Abstract: Gradient-based optimization has been critical to the success of machine learning, updating a single set of parameters to minimize a single loss. A growing number of applications rely on a generalization of this, where we have a bilevel or nested optimization of which subsets of parameters update on different objectives nested inside each other. We focus on motivating examples of hyperparameter optimization and generative adversarial networks. However, naively applying classical methods often fails when we look at solving these nested problems on a large scale. In this thesis, we build tools for nested optimization that scale to deep learning setups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01526v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan Lorraine</dc:creator>
    </item>
    <item>
      <title>Optimizing for Strategy Diversity in the Design of Video Games</title>
      <link>https://arxiv.org/abs/2106.11538</link>
      <description>arXiv:2106.11538v3 Announce Type: replace 
Abstract: We consider the problem of designing a linear program that has diverse solutions as the right-hand side varies. This problem arises in video game settings where designers aim to have players use different "weapons" or "tactics" as they progress. We model this design question as a choice over the constraint matrix $A$ and cost vector $c$ to maximize the number of possible \emph{supports} of unique optimal solutions (what we call "loadouts") of Linear Programs $\max\{c^\top x \mid Ax \le b, x \ge 0\}$ with nonnegative data considered over all resource vectors $b$. We provide an upper bound on the optimal number of loadouts and provide a family of constructions that have an asymptotically optimal number of loadouts. The upper bound is based on a connection between our problem and the study of triangulations of point sets arising from polyhedral combinatorics, and specifically the combinatorics of the cyclic polytope. Our asymptotically optimal construction also draws inspiration from the properties of the cyclic polytope.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.11538v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oussama Hanguir, Will Ma, Christopher Thomas Ryan, Jiangze Han</dc:creator>
    </item>
    <item>
      <title>Non-Euclidean Contraction Analysis of Continuous-Time Neural Networks</title>
      <link>https://arxiv.org/abs/2110.08298</link>
      <description>arXiv:2110.08298v5 Announce Type: replace 
Abstract: Critical questions in dynamical neuroscience and machine learning are related to the study of continuous-time neural networks and their stability, robustness, and computational efficiency. These properties can be simultaneously established via a contraction analysis. This paper develops a comprehensive non-Euclidean contraction theory for continuous-time neural networks. Specifically, we provide novel sufficient conditions for the contractivity of general classes of continuous-time neural networks including Hopfield, firing rate, Persidskii, Lur'e, and other neural networks with respect to the non-Euclidean $\ell_1/\ell_\infty$ norms. These sufficient conditions are based upon linear programming or, in some special cases, establishing the Hurwitzness of a particular Metzler matrix. To prove these sufficient conditions, we develop novel results on non-Euclidean logarithmic norms and a novel necessary and sufficient condition for contractivity of systems with locally Lipschitz dynamics. For each model, we apply our theoretical results to compute the optimal contraction rate and corresponding weighted non-Euclidean norm with respect to which the neural network is contracting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.08298v5</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Davydov, Anton V. Proskurnikov, Francesco Bullo</dc:creator>
    </item>
    <item>
      <title>Regularity theory and geometry of unbalanced optimal transport</title>
      <link>https://arxiv.org/abs/2112.11056</link>
      <description>arXiv:2112.11056v2 Announce Type: replace 
Abstract: Using the dual formulation only, we show that the regularity of unbalanced optimal transport also called entropy-transport inherits from the regularity of standard optimal transport. We provide detailed examples of Riemannian manifolds and costs for which unbalanced optimal transport is regular.Among all entropy-transport formulations, Wasserstein-Fisher-Rao (WFR) metric, also called Hellinger-Kantorovich, stands out since it admits a dynamic formulation, which extends the Benamou-Brenier formulation of optimal transport. After demonstrating the equivalence between dynamic and static formulations on a closed Riemannian manifold, we prove a polar factorization theorem, similar to the one due to Brenier and Mc-Cann. As a byproduct, we formulate the Monge-Amp{\`e}re equation associated with WFR metric, which also holds for more general costs. Last, we study the link between c-convex functions for the cost induced by the WFR metric and the cost on the cone. The main result is that the weak Ma-Trudinger-Wang condition on the cone implies the same condition on the manifold for the cost induced by WFR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.11056v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Gallou\"et (PARMA), Roberta Ghezzi (LIGM), Fran\c{c}ois-Xavier Vialard (LIGM)</dc:creator>
    </item>
    <item>
      <title>Complexity-optimal and parameter-free first-order methods for finding stationary points of composite optimization problems</title>
      <link>https://arxiv.org/abs/2205.13055</link>
      <description>arXiv:2205.13055v5 Announce Type: replace 
Abstract: This paper develops and analyzes an accelerated proximal descent method for finding stationary points of nonconvex composite optimization problems. The objective function is of the form $f+h$ where $h$ is a proper closed convex function, $f$ is a differentiable function on the domain of $h$, and $\nabla f$ is Lipschitz continuous on the domain of $h$. The main advantage of this method is that it is "parameter-free" in the sense that it does not require knowledge of the Lipschitz constant of $\nabla f$ or of any global topological properties of $f$. It is shown that the proposed method can obtain an $\varepsilon$-approximate stationary point with iteration complexity bounds that are optimal, up to logarithmic terms over $\varepsilon$, in both the convex and nonconvex settings. Some discussion is also given about how the proposed method can be leveraged in other existing optimization frameworks, such as min-max smoothing and penalty frameworks for constrained programming, to create more specialized parameter-free methods. Finally, numerical experiments are presented to support the practical viability of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.13055v5</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiwei Kong</dc:creator>
    </item>
    <item>
      <title>Accelerated Algorithms for Constrained Nonconvex-Nonconcave Min-Max Optimization and Comonotone Inclusion</title>
      <link>https://arxiv.org/abs/2206.05248</link>
      <description>arXiv:2206.05248v4 Announce Type: replace 
Abstract: We study constrained comonotone min-max optimization, a structured class of nonconvex-nonconcave min-max optimization problems, and their generalization to comonotone inclusion. In our first contribution, we extend the Extra Anchored Gradient (EAG) algorithm, originally proposed by Yoon and Ryu (2021) for unconstrained min-max optimization, to constrained comonotone min-max optimization and comonotone inclusion, achieving an optimal convergence rate of $O\left(\frac{1}{T}\right)$ among all first-order methods. Additionally, we prove that the algorithm's iterations converge to a point in the solution set. In our second contribution, we extend the Fast Extra Gradient (FEG) algorithm, as developed by Lee and Kim (2021), to constrained comonotone min-max optimization and comonotone inclusion, achieving the same $O\left(\frac{1}{T}\right)$ convergence rate. This rate is applicable to the broadest set of comonotone inclusion problems yet studied in the literature. Our analyses are based on simple potential function arguments, which might be useful for analyzing other accelerated algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.05248v4</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cai, Argyris Oikonomou, Weiqiang Zheng</dc:creator>
    </item>
    <item>
      <title>Towards Improving Unit Commitment Economics: An Add-On Tailor for Renewable Energy and Reserve Predictions</title>
      <link>https://arxiv.org/abs/2208.13065</link>
      <description>arXiv:2208.13065v3 Announce Type: replace 
Abstract: Generally, day-ahead unit commitment (UC) is conducted in a predict-then-optimize process: it starts by predicting the renewable energy source (RES) availability and system reserve requirements; given the predictions, the UC model is then optimized to determine the economic operation plans. In fact, predictions within the process are raw. In other words, if the predictions are further tailored to assist UC in making the economic operation plans against realizations of the RES and reserve requirements, UC economics will benefit significantly. To this end, this paper presents a cost-oriented tailor of RES-and-reserve predictions for UC, deployed as an add-on to the predict-then-optimize process. The RES-and-reserve tailor is trained by solving a bi-level mixed-integer programming model: the upper level trains the tailor based on its induced operating cost; the lower level, given tailored predictions, mimics the system operation process and feeds the induced operating cost back to the upper level; finally, the upper level evaluates the training quality according to the fed-back cost. Through this training, the tailor learns to customize the raw predictions into cost-oriented predictions. Moreover, the tailor can be embedded into the existing predict-then-optimize process as an add-on, improving the UC economics. Lastly, the presented method is compared to traditional, binary-relaxation, neural network-based, stochastic, and robust methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.13065v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xianbang Chen, Yikui Liu, Lei Wu</dc:creator>
    </item>
    <item>
      <title>A new geometric approach to multiobjective linear programming problems</title>
      <link>https://arxiv.org/abs/2210.10829</link>
      <description>arXiv:2210.10829v3 Announce Type: replace 
Abstract: In this paper, we present a novel method for solving multiobjective linear programming problems (MOLPP) that overcomes the need to calculate the optimal value of each objective function. This method is a follow-up to our previous work on sensitivity analysis, where we developed a new geometric approach. The first step of our approach is to divide the space of linear forms into a finite number of sets based on a fixed convex polygonal subset of $\mathbb{R}^{2}$. This is done using an equivalence relationship, which ensures that all the elements from a given equivalence class have the same optimal solution. We then characterize the equivalence classes of the quotient set using a geometric approach to sensitivity analysis. This step is crucial in identifying the ideal solution to the MOLPP. By using this approach, we can determine whether a given MOLPP has an ideal solution without the need to calculate the optimal value of each objective function. This is a significant improvement over existing methods, as it significantly reduces the computational complexity and time required to solve MOLPP.
  To illustrate our method, we provide a numerical example that demonstrates its effectiveness. Our method is simple, yet powerful, and can be easily applied to a wide range of MOLPP. This paper contributes to the field of optimization by presenting a new approach to solving MOLPP that is efficient, effective, and easy to implement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.10829v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.14708/ma.v51i1.7166</arxiv:DOI>
      <arxiv:journal_reference>Mathematica Applicanda 2023: 51(1), 3-12</arxiv:journal_reference>
      <dc:creator>Mustapha Kaci, Sonia Radjef</dc:creator>
    </item>
    <item>
      <title>Langevin dynamics based algorithm e-TH$\varepsilon$O POULA for stochastic optimization problems with discontinuous stochastic gradient</title>
      <link>https://arxiv.org/abs/2210.13193</link>
      <description>arXiv:2210.13193v3 Announce Type: replace 
Abstract: We introduce a new Langevin dynamics based algorithm, called e-TH$\varepsilon$O POULA, to solve optimization problems with discontinuous stochastic gradients which naturally appear in real-world applications such as quantile estimation, vector quantization, CVaR minimization, and regularized optimization problems involving ReLU neural networks. We demonstrate both theoretically and numerically the applicability of the e-TH$\varepsilon$O POULA algorithm. More precisely, under the conditions that the stochastic gradient is locally Lipschitz in average and satisfies a certain convexity at infinity condition, we establish non-asymptotic error bounds for e-TH$\varepsilon$O POULA in Wasserstein distances and provide a non-asymptotic estimate for the expected excess risk, which can be controlled to be arbitrarily small. Three key applications in finance and insurance are provided, namely, multi-period portfolio optimization, transfer learning in multi-period portfolio optimization, and insurance claim prediction, which involve neural networks with (Leaky)-ReLU activation functions. Numerical experiments conducted using real-world datasets illustrate the superior empirical performance of e-TH$\varepsilon$O POULA compared to SGLD, TUSLA, ADAM, and AMSGrad in terms of model accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.13193v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dong-Young Lim, Ariel Neufeld, Sotirios Sabanis, Ying Zhang</dc:creator>
    </item>
    <item>
      <title>Online Decision Making with Nonconvex Local and Convex Global Constraints</title>
      <link>https://arxiv.org/abs/2211.03997</link>
      <description>arXiv:2211.03997v2 Announce Type: replace 
Abstract: We study the online decision making problem (ODMP) as a natural generalization of online linear programming. In ODMP, a single decision maker undertakes a sequence of decisions over $T$ time steps. At each time step, the decision maker makes a locally feasible decision based on information available up to that point. The objective is to maximize the accumulated reward while satisfying some convex global constraints called goal constraints. The decision made at each step results in an $m$-dimensional vector that represents the contribution of this local decision to the goal constraints. In the online setting, these goal constraints are soft constraints that can be violated moderately. To handle potential nonconvexity and nonlinearity in ODMP, we propose a Fenchel dual-based online algorithm. At each time step, the algorithm requires solving a potentially nonconvex optimization problem over the local feasible set and a convex optimization problem over the goal set. Under certain stochastic input models, we show that the algorithm achieves $O(\sqrt{mT})$ goal constraint violation deterministically, and $\tilde{O}(\sqrt{mT})$ regret in expected reward. Numerical experiments on an online knapsack problem and an assortment optimization problem are conducted to demonstrate the potential of our proposed online algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.03997v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Chen, Oktay Gunluk, Andrea Lodi, Guanyi Wang</dc:creator>
    </item>
    <item>
      <title>Robust Analysis of Almost Sure Convergence of Zeroth-Order Mirror Descent Algorithm</title>
      <link>https://arxiv.org/abs/2303.09793</link>
      <description>arXiv:2303.09793v2 Announce Type: replace 
Abstract: This letter presents an almost sure convergence of the zeroth-order mirror descent algorithm. The algorithm admits non-smooth convex functions and a biased oracle which only provides noisy function value at any desired point. We approximate the subgradient of the objective function using Nesterov's Gaussian Approximation (NGA) with certain alternations suggested by some practical applications. We prove an almost sure convergence of the iterates' function value to the neighbourhood of optimal function value, which can not be made arbitrarily small, a manifestation of a biased oracle. This letter ends with a concentration inequality, which is a finite time analysis that predicts the likelihood that the function value of the iterates is in the neighbourhood of the optimal value at any finite iteration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.09793v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Anik Kumar Paul, Arun D Mahindrakar, Rachel K Kalaimani</dc:creator>
    </item>
    <item>
      <title>The natural ordering cone of a polyhedral convex set-valued objective mapping</title>
      <link>https://arxiv.org/abs/2305.15575</link>
      <description>arXiv:2305.15575v4 Announce Type: replace 
Abstract: For a given polyhedral convex set-valued mapping we define a polyhedral convex cone which we call the natural ordering cone. We show that the solution behavior of a polyhedral convex set optimization problem can be characterized by this cone. Under appropriate assumptions the natural ordering cone is proven to be the smallest ordering cone which makes a polyhedral convex set optimization problem solvable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.15575v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas L\"ohne</dc:creator>
    </item>
    <item>
      <title>How Can Energy Communities Provide Grid Services? A Dynamic Pricing Mechanism with Budget Balance, Individual Rationality, and Fair Allocation</title>
      <link>https://arxiv.org/abs/2309.05363</link>
      <description>arXiv:2309.05363v3 Announce Type: replace 
Abstract: Following recent Danish legislation promoting energy communities, we explore how to enable these communities to provide grid services to distribution system operators. In particular, we focus on "capacity limitation services", where we propose a bilateral agreement in which an energy community is given reduced grid import tariffs by setting a cap to its consumption level in certain hours. This requires a coordination mechanism between the community manager and the prosumers within the community. We enable this coordination by developing a bilevel optimization model to be solved by the community manager, aiming to set dynamic, i.e., time- and prosumer-differentiated, prices. This coordination mechanism enabled by dynamic pricing ensures desirable market properties including budget balance for the community manager and individual rationality for prosumers, while encouraging (but not guaranteeing) a fair allocation of collected benefits among prosumers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05363v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bennevis Crowley, Jalal Kazempour, Lesia Mitridati</dc:creator>
    </item>
    <item>
      <title>Face relative interior of convex sets in topological vector spaces</title>
      <link>https://arxiv.org/abs/2309.06699</link>
      <description>arXiv:2309.06699v2 Announce Type: replace 
Abstract: A new notion of face relative interior for convex sets in topological real vector spaces is introduced in this work. Face relative interior is grounded in the facial structure, and may capture the geometry of convex sets in topological vector spaces better than other generalisations of relative interior.
  We show that the face relative interior partitions convex sets into face relative interiors of their closure-equivalent faces (different to the partition generated by intrinsic cores), establish the conditions for nonemptiness of this new notion, compare the face relative interior with other concepts of convex interior and prove basic calculus rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.06699v2</guid>
      <category>math.OC</category>
      <category>math.GN</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Reinier D\'iaz Mill \'an, Vera Roshchina</dc:creator>
    </item>
    <item>
      <title>The pseudo-Boolean polytope and polynomial-size extended formulations for binary polynomial optimization</title>
      <link>https://arxiv.org/abs/2309.08693</link>
      <description>arXiv:2309.08693v2 Announce Type: replace 
Abstract: With the goal of obtaining strong relaxations for binary polynomial optimization problems, we introduce the pseudo-Boolean polytope defined as the convex hull of the set of binary points satisfying a collection of equations containing pseudo-Boolean functions. By representing the pseudo-Boolean polytope via a signed hypergraph, we obtain sufficient conditions under which this polytope has a polynomial-size extended formulation. Our new framework unifies and extends all prior results on the existence of polynomial-size extended formulations for the convex hull of the feasible region of binary polynomial optimization problems of degree at least three.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.08693v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Del Pia, Aida Khajavirad</dc:creator>
    </item>
    <item>
      <title>A solution method for arbitrary polyhedral convex set optimization problems</title>
      <link>https://arxiv.org/abs/2310.06602</link>
      <description>arXiv:2310.06602v2 Announce Type: replace 
Abstract: We provide a solution method for the polyhedral convex set optimization problem, that is, the problem to minimize a set-valued mapping with polyhedral convex graph with respect to a set ordering relation which is generated by a polyhedral convex cone . The method is proven to be correct and finite without any further assumption to the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06602v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas L\"ohne</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Optimal Transmission of Markov Sources: Belief Quantization vs Sliding Finite Window Codes</title>
      <link>https://arxiv.org/abs/2310.06742</link>
      <description>arXiv:2310.06742v2 Announce Type: replace 
Abstract: We study the problem of zero-delay coding for the transmission a Markov source over a noisy channel with feedback and present a rigorous reinforcement theoretic solution which is guaranteed to achieve near-optimality. To this end, we formulate the problem as a Markov decision process (MDP) where the state is a probability-measure valued predictor/belief and the actions are quantizer maps. This MDP formulation has been used to show the optimality of certain classes of encoder policies in prior work. Despite such an analytical approach in determining optimal policies, their computation is prohibitively complex due to the uncountable nature of the constructed state space and the lack of minorization or strong ergodicity results which are commonly assumed for average cost optimal stochastic control. These challenges invite rigorous reinforcement learning methods, which entail several open questions addressed in our paper. We present two complementary approaches for this problem. In the first approach, we approximate the set of all beliefs by a finite set and use nearest-neighbor quantization to obtain a finite state MDP, whose optimal policies become near-optimal for the original MDP as the quantization becomes arbitrarily fine. In the second approach, a sliding finite window of channel outputs and quantizers together with a prior belief state serve as the state of the MDP. We then approximate this state by marginalizing over all possible beliefs, so that our policies only use the finite window term to encode the source. Under an appropriate notion of predictor stability, we show that such policies are near-optimal for the zero-delay coding problem as the window length increases. We give sufficient conditions for predictor stability to hold. Finally, we propose a reinforcement learning algorithm to compute near-optimal policies and provide a detailed comparison of the coding policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06742v2</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liam Cregg, Fady Alajaji, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>Mean Field Analysis of Two-Party Governance: Competition versus Cooperation among Leaders</title>
      <link>https://arxiv.org/abs/2311.10354</link>
      <description>arXiv:2311.10354v3 Announce Type: replace 
Abstract: This article studies linear-quadratic Stackelberg games between two dominating players (or equivalently, leaders) and a large group of followers, each of whom interacts under a mean field game (MFG) framework. Unlike the conventional major-minor player game, the mean field term herein is endogenously affected by the two leaders simultaneously. These homogeneous followers are non-cooperative, whereas the two leaders can either compete or cooperate with each other, which are respectively formulated as a Nash and a Pareto game. The complete solutions of the leader-follower game can be expressed in terms of the solutions of some non-symmetric Riccati equations. Notably, our analysis suggests that both modes of interactions between leaders has their own merits and neither of them is always more favourable to the community of followers. In our knowledge, a comparative study of the effect of different modes of governance on the society is relatively rare in the existing literature, we here provide its first preliminary quantitative analysis; under a broad class of practically relevant models, we provide sufficient conditions to decide whether cooperation or competition between leaders is more favourable to the followers. Being in common with modern folklore, the relative merits of the two Stackelberg games depend on whether the interests between the two leaders and the followers align among themselves. Representative numerical examples are also supplemented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10354v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dantong Chu, Kenneth Tsz Hin Ng, Sheung Chi Phillip Yam, Harry Zheng</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimal Control Matching</title>
      <link>https://arxiv.org/abs/2312.02027</link>
      <description>arXiv:2312.02027v4 Announce Type: replace 
Abstract: Stochastic optimal control, which has the goal of driving the behavior of noisy systems, is broadly applicable in science, engineering and artificial intelligence. Our work introduces Stochastic Optimal Control Matching (SOCM), a novel Iterative Diffusion Optimization (IDO) technique for stochastic optimal control that stems from the same philosophy as the conditional score matching loss for diffusion models. That is, the control is learned via a least squares problem by trying to fit a matching vector field. The training loss, which is closely connected to the cross-entropy loss, is optimized with respect to both the control function and a family of reparameterization matrices which appear in the matching vector field. The optimization with respect to the reparameterization matrices aims at minimizing the variance of the matching vector field. Experimentally, our algorithm achieves lower error than all the existing IDO techniques for stochastic optimal control for three out of four control problems, in some cases by an order of magnitude. The key idea underlying SOCM is the path-wise reparameterization trick, a novel technique that may be of independent interest. Code at https://github.com/facebookresearch/SOC-matching</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02027v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carles Domingo-Enrich, Jiequn Han, Brandon Amos, Joan Bruna, Ricky T. Q. Chen</dc:creator>
    </item>
    <item>
      <title>How do the lengths of switching intervals influence the stability of a dynamical system?</title>
      <link>https://arxiv.org/abs/2312.10506</link>
      <description>arXiv:2312.10506v2 Announce Type: replace 
Abstract: If a linear switching system with frequent switches is stable, will it be stable under arbitrary switches? In general, the answer is negative. Nevertheless, this question can be answered in an explicit form for any concrete system. This is done by finding the mode-dependent critical lengths of switching intervals after which any enlargement does not influence the stability. The solution is given in terms of the exponential polynomials of least deviation from zero on a segment (``Chebyshev-like'' polynomials). By proving several theoretical results on exponential polynomial approximation we derive an algorithm for finding such polynomials and for computing the critical switching time. The convergence of the algorithm is estimated and numerical results are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.10506v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Vladimir Yu. Protasov, Rinat Kamalov</dc:creator>
    </item>
    <item>
      <title>Primal-Dual iLQR</title>
      <link>https://arxiv.org/abs/2403.00748</link>
      <description>arXiv:2403.00748v5 Announce Type: replace 
Abstract: We introduce a new algorithm for solving unconstrained discrete-time optimal control problems. Our method follows a direct multiple shooting approach, and consists of applying the SQP method together with an $\ell_2$ augmented Lagrangian primal-dual merit function. We use the LQR algorithm to efficiently solve the primal-dual Newton-KKT system. As our algorithm is a specialization of NPSQP, it inherits its generic properties, including global convergence, fast local convergence, and the lack of need for second order corrections or dimension expansions, improving on existing direct multiple shooting approaches such as acados, ALTRO, GNMS, FATROP, and FDDP. The solutions of the LQR-shaped subproblems posed by our algorithm can be be parallelized to run in time logarithmic in the number of stages, states, and controls. Moreover, as our method avoids sequential rollouts of the nonlinear dynamics, it can run in $O(1)$ parallel time per line search iteration. Therefore, this paper provides a practical, theoretically sound, and highly parallelizable (for example, with a GPU) method for solving nonlinear discrete-time optimal control problems. An open-source JAX implementation of this algorithm can be found on GitHub (joaospinto/primal_dual_ilqr).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00748v5</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jo\~ao Sousa-Pinto, Dominique Orban</dc:creator>
    </item>
    <item>
      <title>Stackelberg Games with $k$-Submodular Function under Distributional Risk-Receptiveness and Robustness</title>
      <link>https://arxiv.org/abs/2406.13023</link>
      <description>arXiv:2406.13023v3 Announce Type: replace 
Abstract: We study submodular optimization in adversarial context, applicable to machine learning problems such as feature selection using data susceptible to uncertainties and attacks. We focus on Stackelberg games between an attacker (or interdictor) and a defender where the attacker aims to minimize the defender's objective of maximizing a $k$-submodular function. We allow uncertainties arising from the success of attacks and inherent data noise, and address challenges due to incomplete knowledge of the probability distribution of random parameters. Specifically, we introduce Distributionally Risk-Averse $k$-Submodular Interdiction Problem (DRA $k$-SIP) and Distributionally Risk-Receptive $k$-Submodular Interdiction Problem (DRR $k$-SIP) along with finitely convergent exact algorithms for solving them. The DRA $k$-SIP solution allows risk-averse interdictor to develop robust strategies for real-world uncertainties. Conversely, DRR $k$-SIP solution suggests aggressive tactics for attackers, willing to embrace (distributional) risk to inflict maximum damage, identifying critical vulnerable components, which can be used for the defender's defensive strategies. The optimal values derived from both DRA $k$-SIP and DRR $k$-SIP offer a confidence interval-like range for the expected value of the defender's objective function, capturing distributional ambiguity. We conduct computational experiments using instances of feature selection and sensor placement problems, and Wisconsin breast cancer data and synthetic data, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13023v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seonghun Park, Manish Bansal</dc:creator>
    </item>
    <item>
      <title>A four-operator splitting algorithm for nonconvex and nonsmooth optimization</title>
      <link>https://arxiv.org/abs/2406.16025</link>
      <description>arXiv:2406.16025v3 Announce Type: replace 
Abstract: In this work, we address a class of nonconvex nonsmooth optimization problems where the objective function is the sum of two smooth functions (one of which is proximable) and two nonsmooth functions (one proper, closed and proximable, and the other continuous and weakly concave). We introduce a new splitting algorithm that extends the Davis-Yin splitting (DYS) algorithm to handle such four-term nonconvex nonsmooth problems. We prove that with appropriately chosen step sizes, our algorithm exhibits global subsequential convergence to stationary points with a stationarity measure converging at a rate of $1/k$. When specialized to the setting of the DYS algorithm, our results allow for larger stepsizes compared to existing bounds in the literature. Experimental results demonstrate the practical applicability and effectiveness of our proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16025v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Harold Alcantara, Ching-pei Lee, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>An exit contract optimization problem</title>
      <link>https://arxiv.org/abs/2108.09008</link>
      <description>arXiv:2108.09008v3 Announce Type: replace-cross 
Abstract: We study an exit contract design problem, where one provides a universal exit contract to multiple heterogeneous agents, with which each agent chooses an optimal (exit) stopping time. The problem consists in optimizing the universal exit contract w.r.t. some criterion depending on the contract as well as the agents' exit times. Under a technical monotonicity condition, and by using Bank-El Karoui's representation of stochastic processes, we are able to transform the initial contract optimization problem into an optimal control problem. The latter is also equivalent to an optimal multiple stopping problem and the existence of the optimal contract is proved. We next show that the problem in the continuous-time setting can be approximated by a sequence of discrete-time ones, which would induce a natural numerical approximation method. We finally discuss the optimaization problem over the class of all Markovian and/or continuous exit contracts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2108.09008v3</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xihao He, Xiaolu Tan, Jun Zou</dc:creator>
    </item>
    <item>
      <title>Federated Temporal Difference Learning with Linear Function Approximation under Environmental Heterogeneity</title>
      <link>https://arxiv.org/abs/2302.02212</link>
      <description>arXiv:2302.02212v2 Announce Type: replace-cross 
Abstract: We initiate the study of federated reinforcement learning under environmental heterogeneity by considering a policy evaluation problem. Our setup involves $N$ agents interacting with environments that share the same state and action space but differ in their reward functions and state transition kernels. Assuming agents can communicate via a central server, we ask: Does exchanging information expedite the process of evaluating a common policy? To answer this question, we provide the first comprehensive finite-time analysis of a federated temporal difference (TD) learning algorithm with linear function approximation, while accounting for Markovian sampling, heterogeneity in the agents' environments, and multiple local updates to save communication. Our analysis crucially relies on several novel ingredients: (i) deriving perturbation bounds on TD fixed points as a function of the heterogeneity in the agents' underlying Markov decision processes (MDPs); (ii) introducing a virtual MDP to closely approximate the dynamics of the federated TD algorithm; and (iii) using the virtual MDP to make explicit connections to federated optimization. Putting these pieces together, we rigorously prove that in a low-heterogeneity regime, exchanging model estimates leads to linear convergence speedups in the number of agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.02212v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Han Wang, Aritra Mitra, Hamed Hassani, George J. Pappas, James Anderson</dc:creator>
    </item>
    <item>
      <title>Minimax Excess Risk of First-Order Methods for Statistical Learning with Data-Dependent Oracles</title>
      <link>https://arxiv.org/abs/2307.04679</link>
      <description>arXiv:2307.04679v3 Announce Type: replace-cross 
Abstract: In this paper, our aim is to analyse the generalization capabilities of first-order methods for statistical learning in multiple, different yet related, scenarios including supervised learning, transfer learning, robust learning and federated learning. To do so, we provide sharp upper and lower bounds for the minimax excess risk of strongly convex and smooth statistical learning when the gradient is accessed through partial observations given by a data-dependent oracle. This novel class of oracles can query the gradient with any given data distribution, and is thus well suited to scenarios in which the training data distribution does not match the target (or test) distribution. In particular, our upper and lower bounds are proportional to the smallest mean square error achievable by gradient estimators, thus allowing us to easily derive multiple sharp bounds in the aforementioned scenarios using the extensive literature on parameter estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.04679v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin Scaman, Mathieu Even, Batiste Le Bars, Laurent Massouli\'e</dc:creator>
    </item>
    <item>
      <title>On the limit theory of mean field optimal stopping with non-Markov dynamics and common noise</title>
      <link>https://arxiv.org/abs/2310.00407</link>
      <description>arXiv:2310.00407v2 Announce Type: replace-cross 
Abstract: This paper focuses on a mean-field optimal stopping problem with non-Markov dynamics and common noise, inspired by Talbi, Touzi, and Zhang \cite{TalbiTouziZhang1,TalbiTouziZhang3}. The goal is to establish the limit theory and demonstrate the equivalence of the value functions between weak and strong formulations. The difference between the strong and weak formulations lies in the source of randomness determining the stopping time on a canonical space. In the strong formulation, the randomness of the stopping time originates from Brownian motions. In contrast, this may not necessarily be the case in the weak formulation. Additionally, a $(H)$-Hypothesis-type condition is introduced to guarantee the equivalence of the value functions. The limit theory encompasses the convergence of the value functions and solutions of the large population optimal stopping problem towards those of the mean-field limit, and it shows that every solution of the mean field optimal stopping problem can be approximated by solutions of the large population optimal stopping problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00407v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xihao He</dc:creator>
    </item>
    <item>
      <title>Random coordinate descent: a simple alternative for optimizing parameterized quantum circuits</title>
      <link>https://arxiv.org/abs/2311.00088</link>
      <description>arXiv:2311.00088v2 Announce Type: replace-cross 
Abstract: Variational quantum algorithms rely on the optimization of parameterized quantum circuits in noisy settings. The commonly used back-propagation procedure in classical machine learning is not directly applicable in this setting due to the collapse of quantum states after measurements. Thus, gradient estimations constitute a significant overhead in a gradient-based optimization of such quantum circuits. This paper introduces a random coordinate descent algorithm as a practical and easy-to-implement alternative to the full gradient descent algorithm. This algorithm only requires one partial derivative at each iteration. Motivated by the behavior of measurement noise in the practical optimization of parameterized quantum circuits, this paper presents an optimization problem setting that is amenable to analysis. Under this setting, the random coordinate descent algorithm exhibits the same level of stochastic stability as the full gradient approach, making it as resilient to noise. The complexity of the random coordinate descent method is generally no worse than that of the gradient descent and can be much better for various quantum optimization problems with anisotropic Lipschitz constants. Theoretical analysis and extensive numerical experiments validate our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00088v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiyan Ding, Taehee Ko, Jiahao Yao, Lin Lin, Xiantao Li</dc:creator>
    </item>
    <item>
      <title>Extended Flow Matching: a Method of Conditional Generation with Generalized Continuity Equation</title>
      <link>https://arxiv.org/abs/2402.18839</link>
      <description>arXiv:2402.18839v5 Announce Type: replace-cross 
Abstract: The task of conditional generation is one of the most important applications of generative models, and numerous methods have been developed to date based on the celebrated flow-based models. However, many flow-based models in use today are not built to allow one to introduce an explicit inductive bias to how the conditional distribution to be generated changes with respect to conditions. This can result in unexpected behavior in the task of style transfer, for example. In this research, we introduce extended flow matching (EFM), a direct extension of flow matching that learns a ``matrix field'' corresponding to the continuous map from the space of conditions to the space of distributions. We show that we can introduce inductive bias to the conditional generation through the matrix field and demonstrate this fact with MMOT-EFM, a version of EFM that aims to minimize the Dirichlet energy or the sensitivity of the distribution with respect to conditions. We will present our theory along with experimental results that support the competitiveness of EFM in conditional generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18839v5</guid>
      <category>cs.LG</category>
      <category>math.AP</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noboru Isobe, Masanori Koyama, Jinzhe Zhang, Kohei Hayashi, Kenji Fukumizu</dc:creator>
    </item>
    <item>
      <title>A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features</title>
      <link>https://arxiv.org/abs/2403.01046</link>
      <description>arXiv:2403.01046v3 Announce Type: replace-cross 
Abstract: We prove that training neural networks on 1-D data is equivalent to solving a convex Lasso problem with a fixed, explicitly defined dictionary matrix of features. The specific dictionary depends on the activation and depth. We consider 2 and 3-layer networks with piecewise linear activations, and rectangular and tree networks with sign activation and arbitrary depth. Interestingly in absolute value and symmetrized ReLU networks, a third layer creates features that represent reflections of training data about themselves. The Lasso representation sheds insight to globally optimal networks and the solution landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01046v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emi Zeger, Yifei Wang, Aaron Mishkin, Tolga Ergen, Emmanuel Cand\`es, Mert Pilanci</dc:creator>
    </item>
    <item>
      <title>Passive iFIR Filters for Data-Driven Control</title>
      <link>https://arxiv.org/abs/2403.06640</link>
      <description>arXiv:2403.06640v2 Announce Type: replace-cross 
Abstract: We consider the design of a new class of passive iFIR controllers given by the parallel action of an integrator and a finite impulse response filter. iFIRs are more expressive than PID controllers but retain their features and simplicity. The paper provides a model-free data-driven design for passive iFIR controllers based on virtual reference feedback tuning. Passivity is enforced through constrained optimization (three different formulations are discussed). The proposed design does not rely on large datasets or accurate plant models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06640v2</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2024.3408065</arxiv:DOI>
      <arxiv:journal_reference>IEEE Control Systems Letters, vol. 8, pp. 1289-1294, 2024</arxiv:journal_reference>
      <dc:creator>Zixing Wang, Yongkang Huo, Fulvio Forni</dc:creator>
    </item>
    <item>
      <title>Algorithms of constrained uniform approximation</title>
      <link>https://arxiv.org/abs/2403.16330</link>
      <description>arXiv:2403.16330v2 Announce Type: replace-cross 
Abstract: We address the problem of the best uniform approximation of a continuous function on a convex domain. The approximation is by linear combinations of a finite system of functions (not necessarily Chebyshev) under arbitrary linear constraints. By modifying the concept of alternance and of the Remez iterative procedure we present a method, which demonstrates its efficiency in numerical problems. The linear rate of convergence is proved under some favourable assumptions. A special attention is paid to systems of complex exponents, Gaussian functions, lacunar algebraic and trigonometric polynomials. Applications to signal processing, linear ODE, switching dynamical systems, and to Markov-Bernstein type inequalities are considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16330v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Vladimir Yu. Protasov, Rinat Kamalov</dc:creator>
    </item>
    <item>
      <title>Corrected Correlation Estimates for Meta-Analysis</title>
      <link>https://arxiv.org/abs/2404.11678</link>
      <description>arXiv:2404.11678v2 Announce Type: replace-cross 
Abstract: Meta-analysis allows rigorous aggregation of estimates and uncertainty across multiple studies. When a given study reports multiple estimates, such as log odds ratios (ORs) or log relative risks (RRs) across exposure groups, accounting for within-study correlations improves accuracy and efficiency of meta-analytic results. Canonical approaches of Greenland-Longnecker and Hamling estimate pseudo cases and non-cases for exposure groups to obtain within-study correlations. However, currently available implementations for both methods fail on simple examples.
  We review both GL and Hamling methods through the lens of optimization. For ORs, we provide modifications of each approach that ensure convergence for any feasible inputs. For GL, this is achieved through a new connection to entropic minimization. For Hamling, a modification leads to a provably solvable equivalent set of equations given a specific initialization. For each, we provide implementations a guaranteed to work for any feasible input.
  For RRs, we show the new GL approach is always guaranteed to succeed, but any Hamling approach may fail: we give counter-examples where no solutions exist. We derive a sufficient condition on reported RRs that guarantees success when reported variances are all equal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11678v2</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Johnson-V\'azquez, Alexander W. Hsu, Peng Zheng, Aleksandr Aravkin</dc:creator>
    </item>
    <item>
      <title>On the Convergence of Multi-objective Optimization under Generalized Smoothness</title>
      <link>https://arxiv.org/abs/2405.19440</link>
      <description>arXiv:2405.19440v3 Announce Type: replace-cross 
Abstract: Multi-objective optimization (MOO) is receiving more attention in various fields such as multi-task learning. Recent works provide some effective algorithms with theoretical analysis but they are limited by the standard $L$-smooth or bounded-gradient assumptions, which are typically unsatisfactory for neural networks, such as recurrent neural networks (RNNs) and transformers. In this paper, we study a more general and realistic class of $\ell$-smooth loss functions, where $\ell$ is a general non-decreasing function of gradient norm. We develop two novel single-loop algorithms for $\ell$-smooth MOO problems, Generalized Smooth Multi-objective Gradient descent (GSMGrad) and its stochastic variant, Stochastic Generalized Smooth Multi-objective Gradient descent (SGSMGrad), which approximate the conflict-avoidant (CA) direction that maximizes the minimum improvement among objectives. We provide a comprehensive convergence analysis of both algorithms and show that they converge to an $\epsilon$-accurate Pareto stationary point with a guaranteed $\epsilon$-level average CA distance (i.e., the gap between the updating direction and the CA direction) over all iterations, where totally $\mathcal{O}(\epsilon^{-2})$ and $\mathcal{O}(\epsilon^{-4})$ samples are needed for deterministic and stochastic settings, respectively. Our algorithms can also guarantee a tighter $\epsilon$-level CA distance in each iteration using more samples. Moreover, we propose a practical variant of GSMGrad named GSMGrad-FA using only constant-level time and space, while achieving the same performance guarantee as GSMGrad. Our experiments validate our theory and demonstrate the effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19440v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Zhang, Peiyao Xiao, Kaiyi Ji, Shaofeng Zou</dc:creator>
    </item>
    <item>
      <title>Model Predictive Control and Reinforcement Learning: A Unified Framework Based on Dynamic Programming</title>
      <link>https://arxiv.org/abs/2406.00592</link>
      <description>arXiv:2406.00592v3 Announce Type: replace-cross 
Abstract: In this paper we describe a new conceptual framework that connects approximate Dynamic Programming (DP), Model Predictive Control (MPC), and Reinforcement Learning (RL). This framework centers around two algorithms, which are designed largely independently of each other and operate in synergy through the powerful mechanism of Newton's method. We call them the off-line training and the on-line play algorithms. The names are borrowed from some of the major successes of RL involving games; primary examples are the recent (2017) AlphaZero program (which plays chess, [SHS17], [SSS17]), and the similarly structured and earlier (1990s) TD-Gammon program (which plays backgammon, [Tes94], [Tes95], [TeG96]). In these game contexts, the off-line training algorithm is the method used to teach the program how to evaluate positions and to generate good moves at any given position, while the on-line play algorithm is the method used to play in real time against human or computer opponents.
  Significantly, the synergy between off-line training and on-line play also underlies MPC (as well as other major classes of sequential decision problems), and indeed the MPC design architecture is very similar to the one of AlphaZero and TD-Gammon. This conceptual insight provides a vehicle for bridging the cultural gap between RL and MPC, and sheds new light on some fundamental issues in MPC. These include the enhancement of stability properties through rollout, the treatment of uncertainty through the use of certainty equivalence, the resilience of MPC in adaptive control settings that involve changing system parameters, and the insights provided by the superlinear performance bounds implied by Newton's method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00592v3</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dimitri P. Bertsekas</dc:creator>
    </item>
  </channel>
</rss>
