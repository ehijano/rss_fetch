<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 Oct 2025 01:41:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Sensing Performance Analysis in Cooperative Air-Ground ISAC Networks for LAE</title>
      <link>https://arxiv.org/abs/2510.03642</link>
      <description>arXiv:2510.03642v1 Announce Type: new 
Abstract: To support the development of low altitude economy, the air-ground integrated sensing and communication (ISAC) networks need to be constructed to provide reliable and robust communication and sensing services. In this paper, the sensing capabilities in the cooperative air-ground ISAC networks are evaluated in terms of area radar detection coverage probability under a constant false alarm rate, where the distribution of aggregated sensing interferences is analyzed as a key intermediate result. Compared with the analysis based on the strongest interferer approximation, taking the aggregated sensing interference into consideration is better suited for pico-cell scenarios with high base station density. Simulations are conducted to validate the analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03642v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihang Jiang, Xiaoyang Li, Guangxu Zhu, Xiaowen Cao, Kaifeng Han, Bingpeng Zhou, Xinyi Wang</dc:creator>
    </item>
    <item>
      <title>Privacy Enhancement in Over-the-Air Federated Learning via Adaptive Receive Scaling</title>
      <link>https://arxiv.org/abs/2510.03860</link>
      <description>arXiv:2510.03860v1 Announce Type: new 
Abstract: In Federated Learning (FL) with over-the-air aggregation, the quality of the signal received at the server critically depends on the receive scaling factors. While a larger scaling factor can reduce the effective noise power and improve training performance, it also compromises the privacy of devices by reducing uncertainty. In this work, we aim to adaptively design the receive scaling factors across training rounds to balance the trade-off between training convergence and privacy in an FL system under dynamic channel conditions. We formulate a stochastic optimization problem that minimizes the overall R\'enyi differential privacy (RDP) leakage over the entire training process, subject to a long-term constraint that ensures convergence of the global loss function. Our problem depends on unknown future information, and we observe that standard Lyapunov optimization is not applicable. Thus, we develop a new online algorithm, termed AdaScale, based on a sequence of novel per-round problems that can be solved efficiently. We further derive upper bounds on the dynamic regret and constraint violation of AdaSacle, establishing that it achieves diminishing dynamic regret in terms of time-averaged RDP leakage while ensuring convergence of FL training to a stationary point. Numerical experiments on canonical classification tasks show that our approach effectively reduces RDP and DP leakages compared with state-of-the-art benchmarks without compromising learning performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03860v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faeze Moradi Kalarde, Ben Liang, Min Dong, Yahia A. Eldemerdash Ahmed, Ho Ting Cheng</dc:creator>
    </item>
    <item>
      <title>Multi-Modal Multi-Task Semantic Communication: A Distributed Information Bottleneck Perspective</title>
      <link>https://arxiv.org/abs/2510.04000</link>
      <description>arXiv:2510.04000v1 Announce Type: new 
Abstract: Semantic communication (SemCom) shifts the focus from data transmission to meaning delivery, enabling efficient and intelligent communication.
  Existing AI-based coding schemes for multi-modal multi-task SemCom often require transmitters with full-modal data to participate in all receivers' tasks, which leads to redundant transmissions and conflicts with the physical limits of channel capacity and computational capability.
  In this paper, we propose PoM$^2$-DIB, a novel framework that extends the distributed information bottleneck (DIB) theory to address this problem.
  Unlike the typical DIB, this framework introduces modality selection as an additional key design variable, enabling a more flexible tradeoff between communication rate and inference quality.
  This extension selects only the most relevant modalities for task participation, adhering to the physical constraints, while following efficient DIB-based coding.
  To optimize selection and coding end-to-end, we relax modality selection into a probabilistic form, allowing the use of score function estimation with common randomness to enable optimizable coordinated decisions across distributed devices.
  Experimental results on public datasets verify that PoM$^2$-DIB achieves high inference quality compared to full-participation baselines in various tasks under physical limits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04000v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yujie Zhou, Yiwei Liao, Cheng Peng, Yong Xiao, Yingyu Li</dc:creator>
    </item>
    <item>
      <title>Volume-Based Lower Bounds to the Capacity of the Gaussian Channel Under Pointwise Additive Input Constraints</title>
      <link>https://arxiv.org/abs/2510.04095</link>
      <description>arXiv:2510.04095v1 Announce Type: new 
Abstract: We present a family of relatively simple and unified lower bounds on the capacity of the Gaussian channel under a set of pointwise additive input constraints. Specifically, the admissible channel input vectors $\bx = (x_1, \ldots, x_n)$ must satisfy $k$ additive cost constraints of the form $\sum_{i=1}^n \phi_j(x_i) \le n \Gamma_j$, $j = 1,2,\ldots,k$, which are enforced pointwise for every $\bx$, rather than merely in expectation. More generally, we also consider cost functions that depend on a sliding window of fixed length $m$, namely, $\sum_{i=m}^n \phi_j(x_i, x_{i-1}, \ldots, x_{i-m+1}) \le n \Gamma_j$, $j = 1,2,\ldots,k$, a formulation that naturally accommodates correlation constraints as well as a broad range of other constraints of practical relevance. We propose two classes of lower bounds, derived by two methodologies that both rely on the exact evaluation of the volume exponent associated with the set of input vectors satisfying the given constraints. This evaluation exploits extensions of the method of types to continuous alphabets, the saddle-point method of integration, and basic tools from large deviations theory. The first class of bounds is obtained via the entropy power inequality (EPI), and therefore applies exclusively to continuous-valued inputs. The second class, by contrast, is more general, and it applies to discrete input alphabets as well. It is based on a direct manipulation of mutual information, and it yields stronger and tighter bounds, though at the cost of greater technical complexity. Numerical examples illustrating both types of bounds are provided, and several extensions and refinements are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04095v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neri Merhav (Shitz), Shlomo Shamai (Shitz)</dc:creator>
    </item>
    <item>
      <title>Optimal frames for Phase Retrieval from Edge Vectors of Optimal Polygons</title>
      <link>https://arxiv.org/abs/2510.04099</link>
      <description>arXiv:2510.04099v1 Announce Type: new 
Abstract: This paper aims to characterize the optimal frame for phase retrieval, defined as the frame whose condition number for phase retrieval attains its minimal value. In the context of the two-dimensional real case, we reveal the connection between optimal frames for phase retrieval and the perimeter-maximizing isodiametric problem, originally proposed by Reinhardt in 1922. Our work establishes that every optimal solution to the perimeter-maximizing isodiametric problem inherently leads to an optimal frame in ${\mathbb R}^2$. By recasting the optimal polygons problem as one concerning the discrepancy of roots of unity, we characterize all optimal polygons. Building upon this connection, we then characterize all optimal frames with $m$ vectors in ${\mathbb R}^2$ for phase retrieval when $m \geq 3$ has an odd factor. As a key corollary, we show that the harmonic frame $E_m$ is {\em not} optimal for any even integer $m \geq 4$. This finding disproves a conjecture proposed by Xia, Xu, and Xu (Math. Comp., 90(356): 2931-2960). Previous work has established that the harmonic frame $E_m \subset {\mathbb R}^2$ is indeed optimal when $m$ is an odd integer.
  Exploring the connection between phase retrieval and discrete geometry, this paper aims to illuminate advancements in phase retrieval and offer new perspectives on the perimeter-maximizing isodiametric problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04099v1</guid>
      <category>cs.IT</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.IT</category>
      <category>math.MG</category>
      <category>math.NA</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiqiang Xu, Zili Xu, Xinyue Zhang</dc:creator>
    </item>
    <item>
      <title>Multiplicative Turing Ensembles, Pareto's Law, and Creativity</title>
      <link>https://arxiv.org/abs/2510.04167</link>
      <description>arXiv:2510.04167v1 Announce Type: new 
Abstract: We study integer-valued multiplicative dynamics driven by i.i.d. prime multipliers and connect their macroscopic statistics to universal codelengths. We introduce the Multiplicative Turing Ensemble (MTE) and show how it arises naturally - though not uniquely - from ensembles of probabilistic Turing machines. Our modeling principle is variational: taking Elias' Omega codelength as an energy and imposing maximum entropy constraints yields a canonical Gibbs prior on integers and, by restriction, on primes. Under mild tail assumptions, this prior induces exponential tails for log-multipliers (up to slowly varying corrections), which in turn generate Pareto tails for additive gaps. We also prove time-average laws for the Omega codelength along MTE trajectories. Empirically, on Debian and PyPI package size datasets, a scaled Omega prior achieves the lowest KL divergence against codelength histograms. Taken together, the theory-data comparison suggests a qualitative split: machine-adapted regimes (Gibbs-aligned, finite first moment) exhibit clean averaging behavior, whereas human-generated complexity appears to sit beyond this regime, with tails heavy enough to produce an unbounded first moment, and therefore no averaging of the same kind.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04167v1</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Kolpakov, Aidan Rocke</dc:creator>
    </item>
    <item>
      <title>Relative Divergence and Maximum Relative Divergence Principle for Grading Functions on Partially Ordered Sets</title>
      <link>https://arxiv.org/abs/2510.04314</link>
      <description>arXiv:2510.04314v1 Announce Type: new 
Abstract: Relative Divergence (RD) and Maximum Relative Divergence Principle (MRDP) for grading (order-comonotonic) functions (GF) on posets are used as an expression of Insufficient Reason Principle under the given prior information (IRP+). Classic Probability Theory formulas are presented as IRP+ solutions of MRDP problems on conjoined posets. RD definition principles are analyzed in relation to the poset structure. MRDP techniques are presented for standard posets: power sets, direct products of chains, etc. "Population group-testing" and "Single server of multiple queues" applications are stated and analyzed as "IRP+ by MRDP" problems on conjoined base posets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04314v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Dukhovny</dc:creator>
    </item>
    <item>
      <title>Compressed Newton-direction-based Thresholding Methods for Sparse Optimization Problems</title>
      <link>https://arxiv.org/abs/2510.04451</link>
      <description>arXiv:2510.04451v1 Announce Type: new 
Abstract: Thresholding algorithms for sparse optimization problems involve two key components: search directions and thresholding strategies. In this paper, we use the compressed Newton direction as a search direction, derived by confining the classical Newton step to a low-dimensional subspace and embedding it back into the full space with diagonal regularization. This approach significantly reduces the computational cost for finding the search direction while maintaining the efficiency of Newton-like methods. Based on this new search direction, we propose two major classes of algorithms by adopting hard or optimal thresholding: the compressed Newton-direction-based thresholding pursuit (CNHTP) and compressed Newton-direction-based optimal thresholding pursuit (CNOTP). We establish the global convergence of the proposed algorithms under the restricted isometry property. Experimental results demonstrate that the proposed algorithms perform comparably to several state-of-the-art methods in terms of success frequency and solution accuracy for solving the sparse optimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04451v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nan Meng, Yun-Bin Zhao</dc:creator>
    </item>
    <item>
      <title>Learning Function-to-Function Mappings: A Fourier Neural Operator for Next-Generation MIMO Systems</title>
      <link>https://arxiv.org/abs/2510.04664</link>
      <description>arXiv:2510.04664v1 Announce Type: new 
Abstract: Next-generation multiple-input multiple-output (MIMO) systems, characterized by extremely large-scale arrays, holographic surfaces, three-dimensional architectures, and flexible antennas, are poised to deliver unprecedented data rates, spectral efficiency and stability. However, these advancements introduce significant challenges for physical layer signal processing, stemming from complex near-field propagation, continuous aperture modeling, sub-wavelength antenna coupling effects, and dynamic channel conditions. Conventional model-based and deep learning approaches often struggle with the immense computational complexity and model inaccuracies inherent in these new regimes. This article proposes a Fourier neural operator (FNO) as a powerful and promising tool to address these challenges. The FNO learns function-to-function mappings between infinite-dimensional function spaces, making them exceptionally well-suited for modeling complex physical systems governed by partial differential equations based on electromagnetic wave propagation. We first present the fundamental principles of FNO, demonstrating its mesh-free nature and function-to-function ability to efficiently capture global dependencies in the Fourier domain. Furthermore, we explore a range of applications of FNO in physical-layer signal processing for next-generation MIMO systems. Representative case studies on channel modeling and estimation for novel MIMO architectures demonstrate the superior performance of FNO compared to state-of-the-art methods. Finally, we discuss open challenges and outline future research directions, positioning FNO as a promising technology for enabling the enormous potential of next-generation MIMO systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04664v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian Xiao, Ji Wang, Qi Sun, Qimei Cui, Xingwang Li, Dusit Niyato, Chih-Lin I</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Distributed Optimization With Feasible Set Privacy</title>
      <link>https://arxiv.org/abs/2510.05068</link>
      <description>arXiv:2510.05068v1 Announce Type: new 
Abstract: We consider the problem of decentralized constrained optimization with multiple agents $E_1,\ldots,E_N$ who jointly wish to learn the optimal solution set while keeping their feasible sets $\mathcal{P}_1,\ldots,\mathcal{P}_N$ private from each other. We assume that the objective function $f$ is known to all agents and each feasible set is a collection of points from a universal alphabet $\mathcal{P}_{alph}$. A designated agent (leader) starts the communication with the remaining (non-leader) agents, and is the first to retrieve the solution set. The leader searches for the solution by sending queries to and receiving answers from the non-leaders, such that the information on the individual feasible sets revealed to the leader should be no more than nominal, i.e., what is revealed from learning the solution set alone. We develop achievable schemes for obtaining the solution set at nominal information leakage, and characterize their communication costs under two communication setups between agents. In this work, we focus on two kinds of network setups: i) ring, where each agent communicates with two adjacent agents, and ii) star, where only the leader communicates with the remaining agents. We show that, if the leader first learns the joint feasible set through an existing private set intersection (PSI) protocol and then deduces the solution set, the information leaked to the leader is greater than nominal. Moreover, we draw connection of our schemes to threshold PSI (ThPSI), which is a PSI-variant where the intersection is revealed only when its cardinality is larger than a threshold value. Finally, for various realizations of $f$ mapped uniformly at random to a fixed range of values, our schemes are more communication-efficient with a high probability compared to retrieving the entire feasible set through PSI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05068v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shreya Meel, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Source PAC Coding for Low-latency Secret Key Generation in Short Blocklength Regime</title>
      <link>https://arxiv.org/abs/2510.03818</link>
      <description>arXiv:2510.03818v1 Announce Type: cross 
Abstract: Source polar coding is a potential solution for short blocklength-based low-latency key generation with limited sources, which is a critical aspect of six generation (6G) Internet of things. However, existing source coding schemes still suffer from significant degradation in key generation rate and reconciliation reliability in short blocklength regime. To address this issue, we introduce a multilevel source polarization-adjusted convolutional (PAC) coding framework. Furthermore, we propose a novel code construction algorithm that jointly leverages polarization effects and the maximum likelihood (ML) decoding error coefficient. Simulations demonstrate that the multilevel source PAC scheme with the proposed code construction achieves superior key generation rate under key disagreement constraints compared to conventional and multilevel source polar coding methods even in short blocklength regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03818v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lulu Song, Di Zhang, Tingting Zhang</dc:creator>
    </item>
    <item>
      <title>Pilot Contamination Attacks Detection with Machine Learning for Multi-User Massive MIMO</title>
      <link>https://arxiv.org/abs/2510.03831</link>
      <description>arXiv:2510.03831v1 Announce Type: cross 
Abstract: Massive multiple-input multiple-output (MMIMO) is essential to modern wireless communication systems, like 5G and 6G, but it is vulnerable to active eavesdropping attacks. One type of such attack is the pilot contamination attack (PCA), where a malicious user copies pilot signals from an authentic user during uplink, intentionally interfering with the base station's (BS) channel estimation accuracy. In this work, we propose to use a Decision Tree (DT) algorithm for PCA detection at the BS in a multi-user system. We present a methodology to generate training data for the DT classifier and select the best DT according to their depth. Then, we simulate different scenarios that could be encountered in practice and compare the DT to a classical technique based on likelihood ratio testing (LRT) submitted to the same scenarios. The results revealed that a DT with only one level of depth is sufficient to outperform the LRT. The DT shows a good performance regarding the probability of detection in noisy scenarios and when the malicious user transmits with low power, in which case the LRT fails to detect the PCA. We also show that the reason for the good performance of the DT is its ability to compute a threshold that separates PCA data from non-PCA data better than the LRT's threshold. Moreover, the DT does not necessitate prior knowledge of noise power or assumptions regarding the signal power of malicious users, prerequisites typically essential for LRT and other hypothesis testing methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03831v1</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s11235-024-01163-0</arxiv:DOI>
      <arxiv:journal_reference>Telecommun Syst 86, 797-809 (2024)</arxiv:journal_reference>
      <dc:creator>Pedro Ivo da Cruz, Dimitri Silva, Tito Spadini, Ricardo Suyama, Murilo Bellezoni Loiola</dc:creator>
    </item>
    <item>
      <title>Large Deviations Principle for Isoperimetry and Its Equivalence to Nonlinear Log-Sobolev Inequalities</title>
      <link>https://arxiv.org/abs/2510.04030</link>
      <description>arXiv:2510.04030v1 Announce Type: cross 
Abstract: We investigate the large deviations principle (which concerns sequences of exponentially small sets) for the isoperimetric problem on product Riemannian manifolds $M^{n}$ equipped with product probability measures $\nu^{\otimes n}$, where $M$ is a Riemannian manifold satisfying curvature-dimension bound $\mathrm{CD}(0,\infty)$. When the probability measure ${\nu}$ satisfies a specific light-tail condition, we establish an exact characterization of the large deviations asymptotics for the isoperimetric profile, which shows a precise equivalence between these asymptotic isoperimetric inequalities and nonlinear log-Sobolev inequalities. It is observed that the product of two relative entropy typical sets or their one-sided versions (or the product of two empirically typical sets) forms an asymptotically optimal solution to the isoperimetric problem. The proofs in this paper rely on tools from information theory, optimal transport, and geometric measure theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04030v1</guid>
      <category>math.MG</category>
      <category>cs.IT</category>
      <category>math.FA</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Yu</dc:creator>
    </item>
    <item>
      <title>Ambidextrous Degree Sequence Bounds for Pessimistic Cardinality Estimation</title>
      <link>https://arxiv.org/abs/2510.04249</link>
      <description>arXiv:2510.04249v1 Announce Type: cross 
Abstract: In a large database system, upper-bounding the cardinality of a join query is a crucial task called $\textit{pessimistic cardinality estimation}$. Recently, Abo Khamis, Nakos, Olteanu, and Suciu unified related works into the following dexterous framework. Step 1: Let $(X_1, \dotsc, X_n)$ be a random row of the join, equating $H(X_1, \dotsc, X_n)$ to the log of the join cardinality. Step 2: Upper-bound $H(X_1, \dotsc, X_n)$ using Shannon-type inequalities such as $H(X, Y, Z) \le H(X) + H(Y|X) + H(Z|Y)$. Step 3: Upper-bound $H(X_i) + p H(X_j | X_i)$ using the $p$-norm of the degree sequence of the underlying graph of a relation.
  While old bound in step 3 count "claws $\in$" in the underlying graph, we proposed $\textit{ambidextrous}$ bounds that count "claw pairs ${\ni}\!{-}\!{\in}$". The new bounds are provably not looser and empirically tighter: they overestimate by $x^{3/4}$ times when the old bounds overestimate by $x$ times. An example is counting friend triples in the $\texttt{com-Youtube}$ dataset, the best dexterous bound is $1.2 \cdot 10^9$, the best ambidextrous bound is $5.1 \cdot 10^8$, and the actual cardinality is $1.8 \cdot 10^7$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04249v1</guid>
      <category>cs.DB</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu-Ting Lin, Hsin-Po Wang</dc:creator>
    </item>
    <item>
      <title>Geometry of Distance Protection</title>
      <link>https://arxiv.org/abs/2510.04379</link>
      <description>arXiv:2510.04379v1 Announce Type: cross 
Abstract: Distance relays detect faults on transmission lines. They face uncertainty from the fault's location and resistance, as well as the current from the line's remote terminal. In this paper, we aggregate this uncertainty with the Minkowski sum. This allows us to explicitly model the power grid surrounding the relay's line, and in turn accommodate any mix of synchronous machines and inverter-based resources. To make the relay's task easier, inverters can inject perturbations, or auxiliary signals, such as negative-sequence current. We use Farkas' lemma to construct an optimization for designing inverter auxiliary signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04379v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Josh A. Taylor, Alejandro D. Dom\'inguez-Garc\'ia</dc:creator>
    </item>
    <item>
      <title>Partial Information Decomposition via Normalizing Flows in Latent Gaussian Distributions</title>
      <link>https://arxiv.org/abs/2510.04417</link>
      <description>arXiv:2510.04417v1 Announce Type: cross 
Abstract: The study of multimodality has garnered significant interest in fields where the analysis of interactions among multiple information sources can enhance predictive modeling, data fusion, and interpretability. Partial information decomposition (PID) has emerged as a useful information-theoretic framework to quantify the degree to which individual modalities independently, redundantly, or synergistically convey information about a target variable. However, existing PID methods depend on optimizing over a joint distribution constrained by estimated pairwise probability distributions, which are costly and inaccurate for continuous and high-dimensional modalities. Our first key insight is that the problem can be solved efficiently when the pairwise distributions are multivariate Gaussians, and we refer to this problem as Gaussian PID (GPID). We propose a new gradient-based algorithm that substantially improves the computational efficiency of GPID based on an alternative formulation of the underlying optimization problem. To generalize the applicability to non-Gaussian data, we learn information-preserving encoders to transform random variables of arbitrary input distributions into pairwise Gaussian random variables. Along the way, we resolved an open problem regarding the optimality of joint Gaussian solutions for GPID. Empirical validation in diverse synthetic examples demonstrates that our proposed method provides more accurate and efficient PID estimates than existing baselines. We further evaluate a series of large-scale multimodal benchmarks to show its utility in real-world applications of quantifying PID in multimodal datasets and selecting high-performing models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04417v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenyuan Zhao, Adithya Balachandran, Chao Tian, Paul Pu Liang</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Collaborative Intelligence: Dual-Dial Control for Reliable LLM Reasoning</title>
      <link>https://arxiv.org/abs/2510.04488</link>
      <description>arXiv:2510.04488v1 Announce Type: cross 
Abstract: Multi-agent debate often wastes compute by using a fixed adversarial stance, aggregating without deliberation, or stopping on heuristics. We introduce MACI, an active controller with two independent dials that decouple information from behavior: an information dial that gates evidence by quality, and a behavior dial that schedules contentiousness from exploration to consolidation. A moderator tracks disagreement, overlap, evidence quality, and argument quality, and halts when gains plateau. We provide theory-lite guarantees for nonincreasing dispersion and provable termination, with a budget-feasible scheduler. Across clinical diagnosis and news-bias tasks, MACI improves accuracy and calibration while reducing tokens, and converts residual uncertainty into precision RAG plans that specify what to retrieve next. We use a cross-family LLM judge (CRIT) as a conservative soft weight and stop signal, validated for order invariance and judge-swap stability; stability depends on using high-capability judges. MACI turns debate into a budget-aware, measurable, and provably terminating controller.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04488v1</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edward Y. Chang, Ethan Y. Chang</dc:creator>
    </item>
    <item>
      <title>Quantum capacity amplification via privacy</title>
      <link>https://arxiv.org/abs/2510.04527</link>
      <description>arXiv:2510.04527v1 Announce Type: cross 
Abstract: We investigate superadditivity of quantum capacity through private channels whose Choi-Jamiolkowski operators are private states. This perspective links the security structure of private states to quantum capacity and clarifies the role of the shield system: information encoded in the shield system that would otherwise leak to the environment can be recycled when paired with an assisting channel, thereby boosting capacity. Our main contributions are threefold: Firstly, we develop a general framework that provides a sufficient condition for capacity amplification, which is formulated in terms of the assisting channel's Holevo information. As examples, we give explicit, dimension and parameter dependent amplification thresholds for erasure and depolarizing channels. Secondly, assuming the Spin alignment conjecture, we derive a single-letter expression for the quantum capacity of a family of private channels that are neither degradable, anti-degradable, nor PPT; as an application, we construct channels with vanishing quantum capacity yet unbounded private capacity. Thirdly, we further analyze approximate private channels: we give an alternative proof of superactivation that extends its validity to a broader parameter regime, and, by combining amplification bounds with continuity estimates, we establish a metric separation showing that channels exhibiting capacity amplification have nonzero diamond distance from the set of anti-degradable channels, indicating that existing approximate (anti-)degradability bounds are not tight. We also revisit the computability of the regularized quantum capacity and modestly suggest that this fundamental question still remains open.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04527v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peixue Wu, Yunkai Wang</dc:creator>
    </item>
    <item>
      <title>Quantum Reverse Shannon Theorem Simplified</title>
      <link>https://arxiv.org/abs/2510.04552</link>
      <description>arXiv:2510.04552v1 Announce Type: cross 
Abstract: We revisit the quantum reverse Shannon theorem, a central result in quantum information theory that characterizes the resources needed to simulate quantum channels when entanglement is freely available. We derive a universal additive upper bound on the smoothed max-information in terms of the sandwiched R\'enyi mutual information. This bound yields tighter single-shot results, eliminates the need for the post-selection technique, and leads to a conceptually simpler proof of the quantum reverse Shannon theorem. By consolidating and streamlining earlier approaches, our result provides a clearer and more direct understanding of the resource costs of simulating quantum channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04552v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gilad Gour</dc:creator>
    </item>
    <item>
      <title>Semantic Channel Equalization Strategies for Deep Joint Source-Channel Coding</title>
      <link>https://arxiv.org/abs/2510.04674</link>
      <description>arXiv:2510.04674v1 Announce Type: cross 
Abstract: Deep joint source-channel coding (DeepJSCC) has emerged as a powerful paradigm for end-to-end semantic communications, jointly learning to compress and protect task-relevant features over noisy channels. However, existing DeepJSCC schemes assume a shared latent space at transmitter (TX) and receiver (RX) - an assumption that fails in multi-vendor deployments where encoders and decoders cannot be co-trained. This mismatch introduces "semantic noise", degrading reconstruction quality and downstream task performance. In this paper, we systematize and evaluate methods for semantic channel equalization for DeepJSCC, introducing an additional processing stage that aligns heterogeneous latent spaces under both physical and semantic impairments. We investigate three classes of aligners: (i) linear maps, which admit closed-form solutions; (ii) lightweight neural networks, offering greater expressiveness; and (iii) a Parseval-frame equalizer, which operates in zero-shot mode without the need for training. Through extensive experiments on image reconstruction over AWGN and fading channels, we quantify trade-offs among complexity, data efficiency, and fidelity, providing guidelines for deploying DeepJSCC in heterogeneous AI-native wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04674v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Pannacci, Simone Fiorellino, Mario Edoardo Pandolfo, Emilio Calvanese Strinati, Paolo Di Lorenzo</dc:creator>
    </item>
    <item>
      <title>The Geometry of Truth: Layer-wise Semantic Dynamics for Hallucination Detection in Large Language Models</title>
      <link>https://arxiv.org/abs/2510.04933</link>
      <description>arXiv:2510.04933v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) often produce fluent yet factually incorrect statements-a phenomenon known as hallucination-posing serious risks in high-stakes domains. We present Layer-wise Semantic Dynamics (LSD), a geometric framework for hallucination detection that analyzes the evolution of hidden-state semantics across transformer layers. Unlike prior methods that rely on multiple sampling passes or external verification sources, LSD operates intrinsically within the model's representational space. Using margin-based contrastive learning, LSD aligns hidden activations with ground-truth embeddings derived from a factual encoder, revealing a distinct separation in semantic trajectories: factual responses preserve stable alignment, while hallucinations exhibit pronounced semantic drift across depth. Evaluated on the TruthfulQA and synthetic factual-hallucination datasets, LSD achieves an F1-score of 0.92, AUROC of 0.96, and clustering accuracy of 0.89, outperforming SelfCheckGPT and Semantic Entropy baselines while requiring only a single forward pass. This efficiency yields a 5-20x speedup over sampling-based methods without sacrificing precision or interpretability. LSD offers a scalable, model-agnostic mechanism for real-time hallucination monitoring and provides new insights into the geometry of factual consistency within large language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04933v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Amir Hameed Mir</dc:creator>
    </item>
    <item>
      <title>My First Five Years of Faculty Career at the University of Delaware</title>
      <link>https://arxiv.org/abs/2510.05000</link>
      <description>arXiv:2510.05000v2 Announce Type: cross 
Abstract: In this short article, I would like to briefly summarize my research in the first 5 years in my university academia life in USA. I think that my research results obtained in these 5 years are the best in my career, at least which I like the most by myself. I wish that my experience in my junior academia career could be of some help to young researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05000v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiang-Gen Xia</dc:creator>
    </item>
    <item>
      <title>The Fisher metric as a metric on the cotangent bundle</title>
      <link>https://arxiv.org/abs/2310.13237</link>
      <description>arXiv:2310.13237v2 Announce Type: replace 
Abstract: The Fisher metric on a manifold of probability distributions is usually treated as a metric on the tangent bundle. In this paper, we focus on the metric on the cotangent bundle induced from the Fisher metric with calling it the Fisher co-metric. We show that the Fisher co-metric can be defined directly without going through the Fisher metric by establishing a natural correspondence between cotangent vectors and random variables. This definition clarifies a close relation between the Fisher co-metric and the variance/covariance of random variables, whereby the Cram\'{e}r-Rao inequality is trivialized. We also discuss the monotonicity and the invariance of the Fisher co-metric with respect to Markov maps, and present a theorem characterizing the co-metric by the invariance, which can be regarded as a cotangent version of \v{C}encov's characterization theorem for the Fisher metric. The obtained theorem can also viewed as giving a characterization of the variance/covariance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13237v2</guid>
      <category>cs.IT</category>
      <category>math.DG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s41884-023-00126-9</arxiv:DOI>
      <arxiv:journal_reference>Information Geometry (2024) 7:S651-S677</arxiv:journal_reference>
      <dc:creator>Hiroshi Nagaoka</dc:creator>
    </item>
    <item>
      <title>Conditional normality and finite-state dimensions revisited</title>
      <link>https://arxiv.org/abs/2403.01534</link>
      <description>arXiv:2403.01534v2 Announce Type: replace 
Abstract: The notion of a normal bit sequence was introduced by Borel in 1909; it was the first definition of an individual random object. Normality is a weak notion of randomness requiring only that all $2^n$ factors (substrings) of arbitrary length~$n$ appear with the same limit frequency $2^{-n}$. Later many stronger definitions of randomness were introduced, and in this context normality found its place as ``randomness against a finite-memory adversary''. A quantitative measure of finite-state compressibility was also introduced (the finite-state dimension) and normality means that the finite state dimension is maximal (equals~$1$).
  Recently Nandakumar, Pulari and S (2023) introduced the notion of relative finite-state dimension for a binary sequence with respect to some other binary sequence (treated as an oracle), and the corresponding notion of conditional (relative) normality. (Different notions of conditional randomness were considered before, but not for the finite memory case.) They establish equivalence between the block frequency and the gambling approaches to conditional normality and finite-state dimensions.
  In this note we revisit their definitions and explain how this equivalence can be obtained easily by generalizing known characterizations of (unconditional) normality and dimension in terms of compressibility (finite-state complexity), superadditive complexity measures and gambling (finite-state gales), thus also answering some questions left open in the above-mentioned paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01534v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Shen</dc:creator>
    </item>
    <item>
      <title>Stability of the Ghurye-Olkin Characterization of Vector Gaussian Distributions</title>
      <link>https://arxiv.org/abs/2405.01707</link>
      <description>arXiv:2405.01707v2 Announce Type: replace 
Abstract: The stability of the Ghurye-Olkin (GO) characterization of Gaussian vectors is analyzed using a partition of the vectors into equivalence classes defined by their matrix factors. The sum of the vectors in each class is near-Gaussian in the characteristic function (c.f.) domain if the GO independence condition is approximately met in the c.f. domain. All vectors have the property that any vector projection is near-Gaussian in the distribution function (d.f.) domain. The proofs of these c.f. and d.f. stabilities use tools that establish the stabilities of theorems by Kac-Bernstein and Cram\'er, respectively. The results are used to prove stability theorems for differential entropies of Gaussian vectors and blind source separation of non-Gaussian sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01707v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahdi Mahvari, Gerhard Kramer</dc:creator>
    </item>
    <item>
      <title>On the Reliability of Information Retrieval From MDS Coded Data in DNA Storage</title>
      <link>https://arxiv.org/abs/2502.06618</link>
      <description>arXiv:2502.06618v3 Announce Type: replace 
Abstract: This work presents a theoretical analysis of the probability of successfully retrieving data encoded with MDS codes (e.g., Reed-Solomon codes) in DNA storage systems. We study this probability under independent and identically distributed (i.i.d.) substitution errors, focusing on a common code design strategy that combines inner and outer MDS codes. Our analysis demonstrates how this probability depends on factors such as the total number of sequencing reads, their distribution across strands, the rates of the inner and outer codes, and the substitution error probabilities. These results provide actionable insights into optimizing DNA storage systems under reliability constraints, including determining the minimum number of sequencing reads needed for reliable data retrieval and identifying the optimal balance between the rates of inner and outer MDS codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06618v3</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Serge Kas Hanna</dc:creator>
    </item>
    <item>
      <title>A Contemporary Survey on Semantic Communications:Theory of Mind, Generative AI, and Deep Joint Source-Channel Coding</title>
      <link>https://arxiv.org/abs/2502.16468</link>
      <description>arXiv:2502.16468v3 Announce Type: replace 
Abstract: Semantic communication is emerging as the next pillar in wireless communication technology due to its transformative capabilities in reducing communication overhead, enhancing robustness, and enabling intelligent information exchange. The most significant obstacle lies in the lack of standardization across various research directions, leading to inconsistencies in interpretation, objectives, and evaluation. In this survey, we provide an in-depth overview of three leading directions in semantic communication, namely Theory of Mind-based semantic communication, Generative AI-driven semantic communication, and Deep Joint Source-Channel Coding (DJSCC)-based semantic communication. These directions have been extensively studied and developed by research institutes worldwide, and their effectiveness continues to improve alongside advances in communication and computing technologies. The ToM-based semantic communication enables communication agents to interact intelligently, infer each other's intentions, and gradually form a shared understanding. The GAI-based semantic communication leverages generative models to create and interpret content beyond traditional compression, allowing flexible semantic encoding and decoding tailored to specific tasks. The DJSCC-based semantic communication direction integrates DL models to jointly optimize the source and channel coding processes for efficient semantic information transfer. Next, we present a detailed survey of existing works under each direction and open research problems in semantic communication. Furthermore, we identify and analyze critical challenges, such as scalability and adaptability, that currently hinder the deployment of semantic communication systems. Finally, we discuss potential research opportunities and future directions such as quantum computing to further enhance the capabilities of semantic communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16468v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/COMST.2025.3616973</arxiv:DOI>
      <arxiv:journal_reference>IEEE Communications Surveys &amp; Tutorials, 2025</arxiv:journal_reference>
      <dc:creator>Loc X. Nguyen, Avi Deb Raha, Pyae Sone Aung, Dusit Niyato, Zhu Han, Choong Seon Hong</dc:creator>
    </item>
    <item>
      <title>Plotkin-like Bound and Explicit Function-Correcting Code Constructions for Lee Metric Channels</title>
      <link>https://arxiv.org/abs/2508.01702</link>
      <description>arXiv:2508.01702v3 Announce Type: replace 
Abstract: Function-Correcting Codes (FCCs) are a novel class of codes designed to protect function evaluations of messages against errors while minimizing redundancy. A theoretical framework for systematic FCCs to channels matched to the Lee metric has been studied recently, which introduced function-correcting Lee codes (FCLCs) and also derived upper and lower bounds on their optimal redundancy. In this paper, we first propose a Plotkin-like bound for irregular Lee-distance codes. We then construct explicit FCLCs for specific classes of functions, including the Lee weight, Lee weight distribution, modular sum, and locally bounded function. For these functions, lower bounds on redundancy are obtained, and our constructions are shown to be optimal in certain cases. Finally, a comparative analysis with classical Lee error-correcting codes and codes correcting errors in function values, demonstrates that FCLCs can significantly reduce redundancy while preserving function correctness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01702v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hareesh K., Rashid Ummer N. T., B. Sundar Rajan</dc:creator>
    </item>
    <item>
      <title>Sliding Window Codes: Near-Optimality and Q-Learning for Zero-Delay Coding</title>
      <link>https://arxiv.org/abs/2310.06742</link>
      <description>arXiv:2310.06742v4 Announce Type: replace-cross 
Abstract: We study the problem of zero-delay coding for the transmission of a Markov source over a noisy channel with feedback and present a reinforcement learning solution which is guaranteed to achieve near-optimality. To this end, we formulate the problem as a Markov decision process (MDP) where the state is a probability-measure valued predictor/belief and the actions are quantizer maps. This MDP formulation has been used to show the optimality of certain classes of encoder policies in prior work, but their computation is prohibitively complex due to the uncountable nature of the constructed state space and the lack of minorization or strong ergodicity results. These challenges invite rigorous reinforcement learning methods, which entail several open questions: can we approximate this MDP with a finite-state one with some performance guarantee? Can we ensure convergence of a reinforcement learning algorithm for this approximate MDP? What regularity assumptions are required for the above to hold? We address these questions as follows: we present an approximation of the belief MDP using a sliding finite window of channel outputs and quantizers. Under an appropriate notion of predictor stability, we show that policies based on this finite window are near-optimal, in the sense that the lowest distortion achievable by such a policy approaches the true lowest distortion as the window length increases. We give sufficient conditions for predictor stability to hold. Finally, we propose a Q-learning algorithm which provably converges to a near-optimal policy and provide a detailed comparison of~the sliding finite window scheme with another approximation scheme which quantizes the belief MDP in a nearest neighbor fashion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06742v4</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liam Cregg, Fady Alajaji, Serdar Yuksel</dc:creator>
    </item>
    <item>
      <title>Generalization of LiNGAM that allows confounding</title>
      <link>https://arxiv.org/abs/2401.16661</link>
      <description>arXiv:2401.16661v4 Announce Type: replace-cross 
Abstract: LiNGAM determines the variable order from cause to effect using additive noise models, but it faces challenges with confounding. Previous methods maintained LiNGAM's fundamental structure while trying to identify and address variables affected by confounding. As a result, these methods required significant computational resources regardless of the presence of confounding, and they did not ensure the detection of all confounding types. In contrast, this paper enhances LiNGAM by introducing LiNGAM-MMI, a method that quantifies the magnitude of confounding using KL divergence and arranges the variables to minimize its impact. This method efficiently achieves a globally optimal variable order through the shortest path problem formulation. LiNGAM-MMI processes data as efficiently as traditional LiNGAM in scenarios without confounding while effectively addressing confounding situations. Our experimental results suggest that LiNGAM-MMI more accurately determines the correct variable order, both in the presence and absence of confounding. The code is in the supplementary file in this link: https://github.com/SkyJoyTianle/ISIT2024.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16661v4</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/ISIT57864.2024.10619691</arxiv:DOI>
      <dc:creator>Joe Suzuki, Tian-Le Yang</dc:creator>
    </item>
    <item>
      <title>Learning to Bid in Non-Stationary Repeated First-Price Auctions</title>
      <link>https://arxiv.org/abs/2501.13358</link>
      <description>arXiv:2501.13358v3 Announce Type: replace-cross 
Abstract: First-price auctions have recently gained significant traction in digital advertising markets, exemplified by Google's transition from second-price to first-price auctions. Unlike in second-price auctions, where bidding one's private valuation is a dominant strategy, determining an optimal bidding strategy in first-price auctions is more complex. From a learning perspective, the learner (a specific bidder) can interact with the environment (other bidders, i.e., opponents) sequentially to infer their behaviors. Existing research often assumes specific environmental conditions and benchmarks performance against the best fixed policy (static benchmark). While this approach ensures strong learning guarantees, the static benchmark can deviate significantly from the optimal strategy in environments with even mild non-stationarity. To address such scenarios, a dynamic benchmark--representing the sum of the highest achievable rewards at each time step--offers a more suitable objective. However, achieving no-regret learning with respect to the dynamic benchmark requires additional constraints. By inspecting reward functions in online first-price auctions, we introduce two metrics to quantify the regularity of the sequence of opponents' highest bids, which serve as measures of non-stationarity. We provide a minimax-optimal characterization of the dynamic regret for the class of sequences of opponents' highest bids that satisfy either of these regularity constraints. Our main technical tool is the Optimistic Mirror Descent (OMD) framework with a novel optimism configuration, which is well-suited for achieving minimax-optimal dynamic regret rates in this context. We then use synthetic datasets to validate our theoretical guarantees and demonstrate that our methods outperform existing ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13358v3</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zihao Hu, Xiaoyu Fan, Yuan Yao, Jiheng Zhang, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>Notes on Deterministic and Stochastic Approaches in Electromagnetic Information Theory</title>
      <link>https://arxiv.org/abs/2508.16601</link>
      <description>arXiv:2508.16601v3 Announce Type: replace-cross 
Abstract: This paper investigates the relationship between the Number of Degrees of Freedom ($N_{\rm DoF}$) of the field in deterministic and stochastic source models within Electromagnetic Information Theory (EIT). Our findings demonstrate a fundamental connection between these two approaches. Specifically, we show that a deterministic model and a stochastic model with a spatially incoherent and homogeneous source yield not only the same $N_{\rm DoF}$ but also identical eigenvalues and basis functions for field representation. This key equivalence not only explains the effectiveness of deterministic approaches in EIT but also corroborates the use of classical electromagnetic methods within this new discipline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16601v3</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Donald Migliore</dc:creator>
    </item>
    <item>
      <title>An information metric for comparing and assessing informative interim decisions in sequential clinical trials</title>
      <link>https://arxiv.org/abs/2509.04904</link>
      <description>arXiv:2509.04904v3 Announce Type: replace-cross 
Abstract: Group sequential designs enable interim analyses and potential early stopping for efficacy or futility. While these adaptations improve trial efficiency and ethical considerations, they also introduce bias into the adapted analyses. We demonstrate how failing to account for informative interim decisions in the analysis can substantially affect posterior estimates of the treatment effect, often resulting in overly optimistic credible intervals aligned with the stopping decision. Drawing on information theory, we use the Kullback-Leibler divergence to quantify this distortion and highlight its use for post-hoc evaluation of informative interim decisions, with a focus on end-of-study inference. Unlike pointwise comparisons, this measure provides an integrated summary of this distortion on the whole parameter space. By comparing alternative decision boundaries and prior specifications, we illustrate how this measure can improve the understanding of trial results and inform the planning of future adaptive studies. We also introduce an expected version of this metric to support clinicians in choosing decision boundaries. This guidance complements traditional strategies based on type-I error rate control by offering insights into the distortion introduced to the treatment effect at each interim phase. The use of this pre-experimental measure is finally illustrated in a group sequential trial for evaluating a treatment for central nervous system disorders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.04904v3</guid>
      <category>stat.ME</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>G. Caruso, W. F. Rosenberger, P. Mozgunov, N. Flournoy</dc:creator>
    </item>
    <item>
      <title>NGGAN: Noise Generation GAN Based on the Practical Measurement Dataset for Narrowband Powerline Communications</title>
      <link>https://arxiv.org/abs/2510.01850</link>
      <description>arXiv:2510.01850v2 Announce Type: replace-cross 
Abstract: To effectively process impulse noise for narrowband powerline communications (NB-PLCs) transceivers, capturing comprehensive statistics of nonperiodic asynchronous impulsive noise (APIN) is a critical task. However, existing mathematical noise generative models only capture part of the characteristics of noise. In this study, we propose a novel generative adversarial network (GAN) called noise generation GAN (NGGAN) that learns the complicated characteristics of practically measured noise samples for data synthesis. To closely match the statistics of complicated noise over the NB-PLC systems, we measured the NB-PLC noise via the analog coupling and bandpass filtering circuits of a commercial NB-PLC modem to build a realistic dataset. To train NGGAN, we adhere to the following principles: 1) we design the length of input signals that the NGGAN model can fit to facilitate cyclostationary noise generation; 2) the Wasserstein distance is used as a loss function to enhance the similarity between the generated noise and training data; and 3) to measure the similarity performances of GAN-based models based on the mathematical and practically measured datasets, we conduct both quantitative and qualitative analyses. The training datasets include: 1) a piecewise spectral cyclostationary Gaussian model (PSCGM); 2) a frequency-shift (FRESH) filter; and 3) practical measurements from NB-PLC systems. Simulation results demonstrate that the generated noise samples from the proposed NGGAN are highly close to the real noise samples. The principal component analysis (PCA) scatter plots and Fr\'echet inception distance (FID) analysis have shown that NGGAN outperforms other GAN-based models by generating noise samples with superior fidelity and higher diversity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01850v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TIM.2024.3523361</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Instrumentation and Measurement, vol. 24, pp. 1-15, 2025</arxiv:journal_reference>
      <dc:creator>Ying-Ren Chien, Po-Heng Chou, You-Jie Peng, Chun-Yuan Huang, Hen-Wai Tsao, Yu Tsao</dc:creator>
    </item>
    <item>
      <title>Quantum Fisher information matrices from R\'enyi relative entropies</title>
      <link>https://arxiv.org/abs/2510.02218</link>
      <description>arXiv:2510.02218v2 Announce Type: replace-cross 
Abstract: Quantum generalizations of the Fisher information are important in quantum information science, with applications in high energy and condensed matter physics and in quantum estimation theory, machine learning, and optimization. One can derive a quantum generalization of the Fisher information matrix in a natural way as the Hessian matrix arising in a Taylor expansion of a smooth divergence. Such an approach is appealing for quantum information theorists, given the ubiquity of divergences in quantum information theory. In contrast to the classical case, there is not a unique quantum generalization of the Fisher information matrix, similar to how there is not a unique quantum generalization of the relative entropy or the R\'enyi relative entropy. In this paper, I derive information matrices arising from the log-Euclidean, $\alpha$-$z$, and geometric R\'enyi relative entropies, with the main technical tool for doing so being the method of divided differences for calculating matrix derivatives. Interestingly, for all non-negative values of the R\'enyi parameter $\alpha$, the log-Euclidean R\'enyi relative entropy leads to the Kubo-Mori information matrix, and the geometric R\'enyi relative entropy leads to the right-logarithmic derivative Fisher information matrix. Thus, the resulting information matrices obey the data-processing inequality for all non-negative values of the R\'enyi parameter $\alpha$ even though the original quantities do not. Additionally, I derive and establish basic properties of $\alpha$-$z$ information matrices resulting from the $\alpha$-$z$ R\'enyi relative entropies. For parameterized thermal states and time-evolved states, I establish formulas for their $\alpha$-$z$ information matrices and hybrid quantum-classical algorithms for estimating them, with applications in quantum Boltzmann machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02218v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>hep-th</category>
      <category>math.IT</category>
      <pubDate>Tue, 07 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark M. Wilde</dc:creator>
    </item>
  </channel>
</rss>
