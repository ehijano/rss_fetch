<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Oct 2025 04:02:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Efficient Probabilistic Visualization of Local Divergence of 2D Vector Fields with Independent Gaussian Uncertainty</title>
      <link>https://arxiv.org/abs/2510.01190</link>
      <description>arXiv:2510.01190v1 Announce Type: new 
Abstract: This work focuses on visualizing uncertainty of local divergence of two-dimensional vector fields. Divergence is one of the fundamental attributes of fluid flows, as it can help domain scientists analyze potential positions of sources (positive divergence) and sinks (negative divergence) in the flow. However, uncertainty inherent in vector field data can lead to erroneous divergence computations, adversely impacting downstream analysis. While Monte Carlo (MC) sampling is a classical approach for estimating divergence uncertainty, it suffers from slow convergence and poor scalability with increasing data size and sample counts. Thus, we present a two-fold contribution that tackles the challenges of slow convergence and limited scalability of the MC approach. (1) We derive a closed-form approach for highly efficient and accurate uncertainty visualization of local divergence, assuming independently Gaussian-distributed vector uncertainties. (2) We further integrate our approach into Viskores, a platform-portable parallel library, to accelerate uncertainty visualization. In our results, we demonstrate significantly enhanced efficiency and accuracy of our serial analytical (speed-up up to 1946X) and parallel Viskores (speed-up up to 19698X) algorithms over the classical serial MC approach. We also demonstrate qualitative improvements of our probabilistic divergence visualizations over traditional mean-field visualization, which disregards uncertainty. We validate the accuracy and efficiency of our methods on wind forecast and ocean simulation datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01190v1</guid>
      <category>stat.CO</category>
      <category>cs.HC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Timbwaoga A. J. Ouermi, Eric Li, Kenneth Moreland, Dave Pugmire, Chris R. Johnson, Tushar M. Athawale</dc:creator>
    </item>
    <item>
      <title>Knots and variance ordering of sequential Monte Carlo algorithms</title>
      <link>https://arxiv.org/abs/2510.01901</link>
      <description>arXiv:2510.01901v1 Announce Type: new 
Abstract: Sequential Monte Carlo algorithms, or particle filters, are widely used for approximating intractable integrals, particularly those arising in Bayesian inference and state-space models. We introduce a new variance reduction technique, the knot operator, which improves the efficiency of particle filters by incorporating potential function information into part, or all, of a transition kernel. The knot operator induces a partial ordering of Feynman-Kac models that implies an order on the asymptotic variance of particle filters, offering a new approach to algorithm design. We discuss connections to existing strategies for designing efficient particle filters, including model marginalisation. Our theory generalises such techniques and provides quantitative asymptotic variance ordering results. We revisit the fully-adapted (auxiliary) particle filter using our theory of knots to show how a small modification guarantees an asymptotic variance ordering for all relevant test functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01901v1</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joshua J Bon, Anthony Lee</dc:creator>
    </item>
    <item>
      <title>Scalable Asynchronous Federated Modeling for Spatial Data</title>
      <link>https://arxiv.org/abs/2510.01771</link>
      <description>arXiv:2510.01771v1 Announce Type: cross 
Abstract: Spatial data are central to applications such as environmental monitoring and urban planning, but are often distributed across devices where privacy and communication constraints limit direct sharing. Federated modeling offers a practical solution that preserves data privacy while enabling global modeling across distributed data sources. For instance, environmental sensor networks are privacy- and bandwidth-constrained, motivating federated spatial modeling that shares only privacy-preserving summaries to produce timely, high-resolution pollution maps without centralizing raw data. However, existing federated modeling approaches either ignore spatial dependence or rely on synchronous updates that suffer from stragglers in heterogeneous environments. This work proposes an asynchronous federated modeling framework for spatial data based on low-rank Gaussian process approximations. The method employs block-wise optimization and introduces strategies for gradient correction, adaptive aggregation, and stabilized updates. We establish linear convergence with explicit dependence on staleness, a result of standalone theoretical significance. Moreover, numerical experiments demonstrate that the asynchronous algorithm achieves synchronous performance under balanced resource allocation and significantly outperforms it in heterogeneous settings, showcasing superior robustness and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01771v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianwei Shi, Sameh Abdulah, Ying Sun, Marc G. Genton</dc:creator>
    </item>
    <item>
      <title>Compressed Bayesian Tensor Regression</title>
      <link>https://arxiv.org/abs/2510.01861</link>
      <description>arXiv:2510.01861v1 Announce Type: cross 
Abstract: To address the common problem of high dimensionality in tensor regressions, we introduce a generalized tensor random projection method that embeds high-dimensional tensor-valued covariates into low-dimensional subspaces with minimal loss of information about the responses. The method is flexible, allowing for tensor-wise, mode-wise, or combined random projections as special cases. A Bayesian inference framework is provided featuring the use of a hierarchical prior distribution and a low-rank representation of the parameter. Strong theoretical support is provided for the concentration properties of the random projection and posterior consistency of the Bayesian inference. An efficient Gibbs sampler is developed to perform inference on the compressed data. To mitigate the sensitivity introduced by random projections, Bayesian model averaging is employed, with normalising constants estimated using reverse logistic regression. An extensive simulation study is conducted to examine the effects of different tuning parameters. Simulations indicate, and the real data application confirms, that compressed Bayesian tensor regression can achieve better out-of-sample prediction while significantly reducing computational cost compared to standard Bayesian tensor regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01861v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roberto Casarin, Radu Craiu, Qing Wang</dc:creator>
    </item>
    <item>
      <title>A debiased Bernoulli factory and unbiased estimation of a probability</title>
      <link>https://arxiv.org/abs/2510.01941</link>
      <description>arXiv:2510.01941v1 Announce Type: cross 
Abstract: Given a known function $f : [0, 1] \mapsto (0, 1)$ and a random but almost surely finite number of independent, Ber$(x)$-distributed random variables with unknown $x \in [0, 1]$, we construct an unbiased, $[0, 1]$-valued estimator of the probability $f(x) \in (0, 1)$. Our estimator is based on so-called debiasing, or randomly truncating a telescopic series of consistent estimators. Constructing these consistent estimators from the coefficients of a particular Bernoulli factory for $f$ yields provable upper and lower bounds for our unbiased estimator. Our result can be thought of as a novel Bernoulli factory with the appealing property that the required number of Ber$(x)$-distributed random variates is independent of their outcomes, and also as constructive example of the so-called $f$-factory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01941v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jere Koskela, Toni Karvonen, Krzysztof {\L}atuszy\'nski, Dario Span\`o</dc:creator>
    </item>
    <item>
      <title>Online Multivariate Regularized Distributional Regression for High-dimensional Probabilistic Electricity Price Forecasting</title>
      <link>https://arxiv.org/abs/2504.02518</link>
      <description>arXiv:2504.02518v2 Announce Type: replace-cross 
Abstract: Probabilistic electricity price forecasting (PEPF) is vital for short-term electricity markets, yet the multivariate nature of day-ahead prices - spanning 24 consecutive hours - remains underexplored. At the same time, real-time decision-making requires methods that are both accurate and fast. We introduce an online algorithm for multivariate distributional regression models, allowing an efficient modelling of the conditional means, variances, and dependence structures of electricity prices. The approach combines multivariate distributional regression with online coordinate descent and LASSO-type regularization, enabling scalable estimation in high-dimensional covariate spaces. Additionally, we propose a regularized estimation path over increasingly complex dependence structures, allowing for early stopping and avoiding overfitting. In a case study of the German day-ahead market, our method outperforms a wide range of benchmarks, showing that modeling dependence improves both calibration and predictive accuracy. Furthermore, we analyse the trade-off between predictive accuracy and computational costs for batch and online estimation and provide an high-performing open-source Python implementation in the ondil package.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02518v2</guid>
      <category>stat.ML</category>
      <category>econ.EM</category>
      <category>q-fin.ST</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Hirsch</dc:creator>
    </item>
    <item>
      <title>How Much Is Too Much? Adaptive, Context-Aware Risk Detection in Naturalistic Driving</title>
      <link>https://arxiv.org/abs/2508.00888</link>
      <description>arXiv:2508.00888v3 Announce Type: replace-cross 
Abstract: Reliable risk identification based on driver behavior data underpins real-time safety feedback, fleet risk management, and evaluation of driver-assist systems. While naturalistic driving studies have become foundational for providing real-world driver behavior data, the existing frameworks for identifying risk based on such data have two fundamental limitations: (i) they rely on predefined time windows and fixed thresholds to disentangle risky and normal driving behavior, and (ii) they assume behavior is stationary across drivers and time, ignoring heterogeneity and temporal drift. In practice, these limitations can lead to timing errors and miscalibration in alerts, weak generalization to new drivers/routes/conditions, and higher false-alarm and miss rates, undermining driver trust and reducing safety intervention effectiveness. To address this gap, we propose a unified, context-aware framework that adapts labels and models over time and across drivers via rolling windows, joint optimization, dynamic calibration, and model fusion, tailored for time-stamped kinematic data. The framework is tested using two safety indicators, speed-weighted headway and harsh driving events, and three models: Random Forest, XGBoost, and Deep Neural Network (DNN). Speed-weighted headway yielded more stable and context-sensitive classifications than harsh-event counts. XGBoost maintained consistent performance under changing thresholds, whereas DNN achieved higher recall at lower thresholds but with greater variability across trials. The ensemble aggregated signals from multiple models into a single risk decision, balancing responsiveness to risky behavior with control of false alerts. Overall, the framework shows promise for adaptive, context-aware risk detection that can enhance real-time safety feedback and support driver-focused interventions in intelligent transportation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00888v3</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Hossein Kalantari, Eleonora Papadimitriou, Arkady Zgonnikov, Amir Pooyan Afghari</dc:creator>
    </item>
  </channel>
</rss>
