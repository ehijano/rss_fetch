<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Jun 2025 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>POCO: Scalable Neural Forecasting through Population Conditioning</title>
      <link>https://arxiv.org/abs/2506.14957</link>
      <description>arXiv:2506.14957v1 Announce Type: new 
Abstract: Predicting future neural activity is a core challenge in modeling brain dynamics, with applications ranging from scientific investigation to closed-loop neurotechnology. While recent models of population activity emphasize interpretability and behavioral decoding, neural forecasting-particularly across multi-session, spontaneous recordings-remains underexplored. We introduce POCO, a unified forecasting model that combines a lightweight univariate forecaster with a population-level encoder to capture both neuron-specific and brain-wide dynamics. Trained across five calcium imaging datasets spanning zebrafish, mice, and C. elegans, POCO achieves state-of-the-art accuracy at cellular resolution in spontaneous behaviors. After pre-training, POCO rapidly adapts to new recordings with minimal fine-tuning. Notably, POCO's learned unit embeddings recover biologically meaningful structure-such as brain region clustering-without any anatomical labels. Our comprehensive analysis reveals several key factors influencing performance, including context length, session diversity, and preprocessing. Together, these results position POCO as a scalable and adaptable approach for cross-session neural forecasting and offer actionable insights for future model design. By enabling accurate, generalizable forecasting models of neural dynamics across individuals and species, POCO lays the groundwork for adaptive neurotechnologies and large-scale efforts for neural foundation models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14957v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Duan, Hamza Tahir Chaudhry, Misha B. Ahrens, Christopher D Harvey, Matthew G Perich, Karl Deisseroth, Kanaka Rajan</dc:creator>
    </item>
    <item>
      <title>Learning Task-Agnostic Skill Bases to Uncover Motor Primitives in Animal Behaviors</title>
      <link>https://arxiv.org/abs/2506.15190</link>
      <description>arXiv:2506.15190v1 Announce Type: cross 
Abstract: Animals flexibly recombine a finite set of core motor primitives to meet diverse task demands, but existing behavior-segmentation methods oversimplify this process by imposing discrete syllables under restrictive generative assumptions. To reflect the animal behavior generation procedure, we introduce skill-based imitation learning (SKIL) for behavior understanding, a reinforcement learning-based imitation framework that (1) infers interpretable skill sets, i.e., latent basis functions of behavior, by leveraging representation learning on transition probabilities, and (2) parameterizes policies as dynamic mixtures of these skills. We validate our approach on a simple grid world, a discrete labyrinth, and unconstrained videos of freely moving animals. Across tasks, it identifies reusable skill components, learns continuously evolving compositional policies, and generates realistic trajectories beyond the capabilities of traditional discrete models. By exploiting generative behavior modeling with compositional representations, our method offers a concise, principled account of how complex animal behaviors emerge from dynamic combinations of fundamental motor primitives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15190v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiyi Wang, Jingyang Ke, Bo Dai, Anqi Wu</dc:creator>
    </item>
    <item>
      <title>Inverted Inference and Recursive Bootstrapping: A Primal-Dual Theory of Structured Cognition</title>
      <link>https://arxiv.org/abs/2404.01183</link>
      <description>arXiv:2404.01183v3 Announce Type: replace 
Abstract: This paper introduces a unifying framework that links the Context-Content Uncertainty Principle (CCUP) with optimal transport (OT) via primal-dual inference. We propose that cognitive representations are not static encodings but active dual constraints that shape feasible manifolds for learning and inference. Cognition is formalized as the dynamic alignment of high-entropy contexts with low-entropy content, implemented through cycle-consistent inference that minimizes conditional entropy. Central to this framework is the concept of inverted inference: a goal-driven mechanism that reverses the direction of conditioning to simulate latent trajectories consistent with internal goals. This asymmetric inference cycle closes the duality gap in constrained optimization, aligning context (primal variables) with content (dual constraints), and reframing inference as structure-constrained entropy minimization. Temporally, we introduce recursive bootstrapping, where each inference cycle sharpens the structural manifold for the next, forming memory chains that support path-dependent optimization and hierarchical goal decomposition. Spatially, we extend the model via hierarchical spatial bootstrapping, connecting to Hierarchical Navigable Small World (HNSW) graphs to enable sublinear retrieval of goal-consistent latent states. Altogether, this framework provides a computational theory of cognition in which dynamic alignment across time and space supports efficient generalization, abstraction, and adaptive planning. CCUP emerges as a scalable principle for both slow, recursive reasoning and fast, structure-aware recognition through layered primal-dual cycles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01183v3</guid>
      <category>q-bio.NC</category>
      <category>nlin.AO</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Xin Li</dc:creator>
    </item>
    <item>
      <title>The global communication pathways of the human brain transcend the cortical-subcortical-cerebellar division</title>
      <link>https://arxiv.org/abs/2505.22893</link>
      <description>arXiv:2505.22893v2 Announce Type: replace 
Abstract: Understanding how cortex, subcortex and cerebellum integrate is a major challenge for neuroscience, however, studies of the brain's structural connectivity have mostly focused on cortico-cortical links. Here, we used diffusion imaging to construct the structural connectome of the entire human brain including 360 cortical, 233 subcortical, and 125 cerebellar regions of interest (ROIs). We found that the brain forms a modular and hierarchical network architecture, organized into modules of mixed cortical, subcortical and/or cerebellar regions, and whose cross-modular pathways are centralized through highly connected hub ROIs (a `rich-club'). This global rich-club is subcortically dominated and, surprisingly, composed of hub ROIs from all subcortical structures rather than one region like the thalamus, centralizing the communication pathways. This study improves our understanding of the human brain's organization. It provides structural evidence to question the prevalent cortico-centric notion by revealing a connectome centered at the subcortex but made of transversal pathways.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22893v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julian Schulte, Mario Senden, Gustavo Deco, Xenia Kobeleva, Gorka Zamora-L\'opez</dc:creator>
    </item>
    <item>
      <title>Characterizing Neural Manifolds' Properties and Curvatures using Normalizing Flows</title>
      <link>https://arxiv.org/abs/2506.12187</link>
      <description>arXiv:2506.12187v2 Announce Type: replace 
Abstract: Neuronal activity is found to lie on low-dimensional manifolds embedded within the high-dimensional neuron space. Variants of principal component analysis are frequently employed to assess these manifolds. These methods are, however, limited by assuming a Gaussian data distribution and a flat manifold. In this study, we introduce a method designed to satisfy three core objectives: (1) extract coordinated activity across neurons, described either statistically as correlations or geometrically as manifolds; (2) identify a small number of latent variables capturing these structures; and (3) offer an analytical and interpretable framework characterizing statistical properties by a characteristic function and describing manifold geometry through a collection of charts.
  To this end, we employ Normalizing Flows (NFs), which learn an underlying probability distribution of data by an invertible mapping between data and latent space. Their simplicity and ability to compute exact likelihoods distinguish them from other generative networks. We adjust the NF's training objective to distinguish between relevant (in manifold) and noise dimensions (out of manifold). Additionally, we find that different behavioral states align with the components of the latent Gaussian mixture model, enabling their treatment as distinct curved manifolds. Subsequently, we approximate the network for each mixture component with a quadratic mapping, allowing us to characterize both neural manifold curvature and non-Gaussian correlations among recording channels.
  Applying the method to recordings in macaque visual cortex, we demonstrate that state-dependent manifolds are curved and exhibit complex statistical dependencies. Our approach thus enables an expressive description of neural population activity, uncovering non-linear interactions among groups of neurons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12187v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter Bouss, Sandra Nestler, Kirsten Fischer, Claudia Merger, Alexandre Ren\'e, Moritz Helias</dc:creator>
    </item>
    <item>
      <title>Thermodynamic bounds on energy use in Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2503.09980</link>
      <description>arXiv:2503.09980v2 Announce Type: replace-cross 
Abstract: While Landauer's principle sets a fundamental energy limit for irreversible digital computation, we show that Deep Neural Networks (DNNs) implemented on analog physical substrates can operate under markedly different thermodynamic constraints. We distinguish between two classes of analog systems: dynamic and quasi-static. In dynamic systems, energy dissipation arises from neuron resets, with a lower bound governed by Landauer's principle. To analyse a quasi-static analog platform, we construct an explicit mapping of a generic feedforward DNN onto a physical system described by a model Hamiltonian. In this framework, inference can proceed reversibly, with no minimum free energy cost imposed by thermodynamics. We further analyze the training process in quasi-static analog networks and derive a fundamental lower bound on its energy cost, rooted in the interplay between thermal and statistical noise. Our results suggest that while analog implementations can outperform digital ones during inference, the thermodynamic cost of training scales similarly in both paradigms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09980v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexei V. Tkachenko</dc:creator>
    </item>
    <item>
      <title>Decoding Saccadic Eye Movements from Brain Signals Using an Endovascular Neural Interface</title>
      <link>https://arxiv.org/abs/2506.07481</link>
      <description>arXiv:2506.07481v2 Announce Type: replace-cross 
Abstract: An Oculomotor Brain-Computer Interface (BCI) records neural activity from regions of the brain involved in planning eye movements and translates this activity into control commands. While previous successful oculomotor BCI studies primarily relied on invasive microelectrode implants in non-human primates, this study investigates the feasibility of an oculomotor BCI using a minimally invasive endovascular Stentrode device implanted near the supplementary motor area in a patient with amyotrophic lateral sclerosis (ALS). To achieve this, self-paced visually-guided and free-viewing saccade tasks were designed, in which the participant performed saccades in four directions (left, right, up, down), with simultaneous recording of endovascular EEG and eye gaze. The visually guided saccades were cued with visual stimuli, whereas the free-viewing saccades were self-directed without explicit cues. The results showed that while the neural responses of visually guided saccades overlapped with the cue-evoked potentials, the free-viewing saccades exhibited distinct saccade-related potentials that began shortly before eye movement, peaked approximately 50 ms after saccade onset, and persisted for around 200 ms. In the frequency domain, these responses appeared as a low-frequency synchronisation below 15 Hz. Classification of 'fixation vs. saccade' was robust, achieving mean area under the receiver operating characteristic curve (AUC) scores of 0.88 within sessions and 0.86 between sessions. In contrast, classifying saccade direction proved more challenging, yielding within-session AUC scores of 0.67 for four-class decoding and up to 0.75 for the best-performing binary comparisons (left vs. up and left vs. down). This proof-of-concept study demonstrates the feasibility of an endovascular oculomotor BCI in an ALS patient, establishing a foundation for future oculomotor BCI studies in human subjects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07481v2</guid>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Suleman Rasheed, James Bennett, Peter E. Yoo, Anthony N. Burkitt, David B. Grayden</dc:creator>
    </item>
  </channel>
</rss>
