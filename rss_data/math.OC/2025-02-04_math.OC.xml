<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Feb 2025 02:48:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Sustainable Multi-Modal Transportation and Routing focusing on Costs and Carbon Emissions Reduction</title>
      <link>https://arxiv.org/abs/2502.00056</link>
      <description>arXiv:2502.00056v1 Announce Type: new 
Abstract: Transportation plays a critical role in supply chain networks, directly impacting cost efficiency, delivery reliability, and environmental sustainability. This study provides an enhanced optimization model for transportation planning, emphasizing environmental sustainability and cost-efficiency. An Integer Linear Programming (ILP) model was developed to minimize the total transportation costs by considering organizational and third-party vehicles' operational and rental costs while incorporating constraints on carbon emissions. The model incorporates multi-modal transportation routing and emission caps to select the optimized number of organizational and rental vehicles of different modes in each route to ensure adherence to sustainability goals. Key innovations include adding carbon emission constraints and optimizing route selection to reduce overall emissions. The model was implemented using the Gurobi solver, and numerical analysis reveals a trade-off between cost minimization and carbon footprint reduction. The results indicate that adopting tight environmental policies increases the costs by around 8% on average while more than 95% of the vehicles utilized will be rented. These insights provide actionable guidance for industries aiming to enhance both economic performance and environmental responsibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00056v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saba Javanpour, A. Radman, Sarow Saeedi, Sina Feizi Karimabadi, Daniel A. Larson, Eric C. Jones</dc:creator>
    </item>
    <item>
      <title>A Lyapunov analysis of Korpelevich's extragradient method with fast and flexible extensions</title>
      <link>https://arxiv.org/abs/2502.00119</link>
      <description>arXiv:2502.00119v1 Announce Type: new 
Abstract: We present a Lyapunov analysis of Korpelevich's extragradient method and establish an $\mathcal{O}(1/k)$ last-iterate convergence rate. Building on this, we propose flexible extensions that combine extragradient steps with user-specified directions, guided by a line-search procedure derived from the same Lyapunov analysis. These methods retain global convergence under practical assumptions and can achieve superlinear rates when directions are chosen appropriately. Numerical experiments highlight the simplicity and efficiency of this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00119v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manu Upadhyaya, Puya Latafat, Pontus Giselsson</dc:creator>
    </item>
    <item>
      <title>Provably-Stable Neural Network-Based Control of Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2502.00248</link>
      <description>arXiv:2502.00248v1 Announce Type: new 
Abstract: In recent years, Neural Networks (NNs) have been employed to control nonlinear systems due to their potential capability in dealing with situations that might be difficult for conventional nonlinear control schemes. However, to the best of our knowledge, the current literature on NN-based control lacks theoretical guarantees for stability and tracking performance. This precludes the application of NN-based control schemes to systems where stringent stability and performance guarantees are required. To address this gap, this paper proposes a systematic and comprehensive methodology to design provably-stable NN-based control schemes for affine nonlinear systems. Rigorous analysis is provided to show that the proposed approach guarantees stability of the closed-loop system with the NN in the loop. Also, it is shown that the resulting NN-based control scheme ensures that system states asymptotically converge to a neighborhood around the desired equilibrium point, with a tunable proximity threshold. The proposed methodology is validated and evaluated via simulation studies on an inverted pendulum and experimental studies on a Parrot Bebop 2 drone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00248v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.engappai.2024.109252</arxiv:DOI>
      <arxiv:journal_reference>Engineering Applications of Artificial Intelligence, volume 138, pages 109252, year 2024</arxiv:journal_reference>
      <dc:creator>Anran Li, John P. Swensen, Mehdi Hosseinzadeh</dc:creator>
    </item>
    <item>
      <title>Engagement Zones for a Turn Constrained Pursuer</title>
      <link>https://arxiv.org/abs/2502.00364</link>
      <description>arXiv:2502.00364v1 Announce Type: new 
Abstract: This work derives two basic engagement zone models, describing regions of potential risk or capture for a mobile vehicle by a pursuer. The pursuer is modeled as having turn-constraints rather than simple motion. Turn-only (C-Paths) and turn-straight (CS-Paths) paths are considered for the pursuer of limited range. Following the derivation, a simulation of a vehicle avoiding the pursuer's engagement zone is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00364v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Thomas Chapman, Isaac E. Weintraub, Alexander Von Moll, Eloy Garcia</dc:creator>
    </item>
    <item>
      <title>A polynomial-based constrained solver for fuel-optimal low-thrust trajectory optimization</title>
      <link>https://arxiv.org/abs/2502.00398</link>
      <description>arXiv:2502.00398v1 Announce Type: new 
Abstract: Differential Dynamic Programming (DDP) is a trajectory optimization method, particularly resilient to poor initial guesses. However, its long run times compared to other methods make it less suitable for embedded systems. In this work, we introduce polynomial-based DDP methods capable of enforcing constraints while optimizing for fuel efficiency. Additionally, a polynomial-based Newton solver is implemented to enforce constraints with high precision. The proposed solver, Differential Algebra-based Differential Dynamic programming (DADDy), is validated and tested on various astrodynamics scenarios. Results demonstrate that DADDy achieves the same solutions as state-of-the-art DDP methods but with significantly reduced run times. Specifically, for the scenarios investigated in this work, the most stable method was able to achieve 100% convergence and achieved runtime reductions of 70% in the Sun-centered two-body problem, 23% to 94% in the Earth-Moon CR3BP, and 46\% to 59% in the Earth-centered two-body problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00398v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thomas Caleb, Roberto Armellin, Spencer Boone, St\'ephanie Lizy-Destrez</dc:creator>
    </item>
    <item>
      <title>Disturbance-to-state stabilization by output feedback of nonlinear ODE cascaded with a reaction-diffusion equation</title>
      <link>https://arxiv.org/abs/2502.00411</link>
      <description>arXiv:2502.00411v1 Announce Type: new 
Abstract: In this paper, we analyze the output stabilization problem for cascaded nonlinear ODE with $1-d$ heat diffusion equation affected by both in-domain and boundary perturbations. We assume that the only available part of states is the first components of the ODE-subsystem and one boundary of the heat-subsystem. The particularity of this system is two folds i) it contains a nonlinear additive term in the ODE-subsystem, and ii) it is affected by both boundary and in-domain perturbations signals.
  For such a system, and unlike the existing works, we succeeded to design an output observer-based feedback that guarantees not only asymptotic stabilization result but also a globally {\it disturbance-to-state stabilization} for our cascaded system. The output feedback is designed using an adequate backstepping transformation recently introduced for coupled ODE-heat equations combined with high-gain observer and high-gain controller.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00411v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdallah Ben Abdallah, Mohsen Dlala</dc:creator>
    </item>
    <item>
      <title>Distributed Primal-Dual Algorithms: Unification, Connections, and Insights</title>
      <link>https://arxiv.org/abs/2502.00470</link>
      <description>arXiv:2502.00470v1 Announce Type: new 
Abstract: We study primal-dual algorithms for general empirical risk minimization problems in distributed settings, focusing on two prominent classes of algorithms. The first class is the communication-efficient distributed dual coordinate ascent (CoCoA), derived from the coordinate ascent method for solving the dual problem. The second class is the alternating direction method of multipliers (ADMM), including consensus ADMM, linearized ADMM, and proximal ADMM. We demonstrate that both classes of algorithms can be transformed into a unified update form that involves only primal and dual variables. This discovery reveals key connections between the two classes of algorithms: CoCoA can be interpreted as a special case of proximal ADMM for solving the dual problem, while consensus ADMM is closely related to a proximal ADMM algorithm. This discovery provides the insight that by adjusting the augmented Lagrangian parameter, we can easily enable the ADMM variants to outperform the CoCoA variants. We further explore linearized versions of ADMM and analyze the effects of tuning parameters on these ADMM variants in the distributed setting. Our theoretical findings are supported by extensive simulation studies and real-world data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00470v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runxiong Wu, Dong Liu, Xueqin Wang, Andi Wang</dc:creator>
    </item>
    <item>
      <title>Fractional differential equations of a reaction-diffusion SIR model involving the Caputo-fractional time-derivative and a nonlinear diffusion operator</title>
      <link>https://arxiv.org/abs/2502.00509</link>
      <description>arXiv:2502.00509v1 Announce Type: new 
Abstract: The main aim of this study is to analyze a fractional parabolic SIR epidemic model of a reaction-diffusion, by using the nonlocal Caputo fractional time-fractional derivative and employing the $p$-Laplacian operator. The immunity is imposed through the vaccination program, which is regarded as a control variable. Finding the optimal control pair that reduces the number of sick people, the associated vaccination, and treatment expenses across a constrained time and space is our main study. The existence and uniqueness of the nonnegative solution for the spatiotemporal SIR model are established. It is also demonstrated that an optimal control exists. In addition, we obtain a description of the optimal control in terms of state and adjoint functions. Then, the optimality system is resolved by a discrete iterative scheme that converges after an appropriate test, similar to the forward-backward sweep method. Finally, numerical approximations are given to show the effectiveness of the proposed control program, which provides meaningful results using different values of the fractional order and $p$, respectively the order of the Caputo derivative and the $p$-Laplacian operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00509v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>q-bio.PE</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3934/eect.2025018</arxiv:DOI>
      <dc:creator>Achraf Zinihi, Moulay Rchid Sidi Ammi, Delfim F. M. Torres</dc:creator>
    </item>
    <item>
      <title>Derivatives of inertial methods for smooth functions</title>
      <link>https://arxiv.org/abs/2502.00522</link>
      <description>arXiv:2502.00522v1 Announce Type: new 
Abstract: In this paper, we consider the minimization of a $C^2-$smooth and strongly convex objective depending on a given parameter, which is usually found in many practical applications. We suppose that we desire to solve the problem with some inertial methods which cover a broader existing well-known inertial methods. Our main goal is to analyze the derivative of this algorithm as an infinite iterative process in the sense of ``automatic'' differentiation. This procedure is very common and has gain more attention recently. From a pure optimization perspective and under some mild premises, we show that any sequence generated by these inertial methods converge to the unique minimizer of the problem, which depends on the parameter. Moreover, we show a local linear convergence rate of the generated sequence. Concerning the differentiation of the scheme, we prove that the derivative of the sequence with respect to the parameter converges to the derivative of the limit of the sequence showing that any sequence is &lt;&lt;derivative stable&gt;&gt;. Finally, we investigate the rate at which the convergence occurs. We show that, this is locally linear with an error term tending to zero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00522v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Jacques Godeme</dc:creator>
    </item>
    <item>
      <title>A Projected Variable Smoothing for Weakly Convex Optimization and Supremum Functions</title>
      <link>https://arxiv.org/abs/2502.00525</link>
      <description>arXiv:2502.00525v1 Announce Type: new 
Abstract: In this paper, we address two main topics. First, we study the problem of minimizing the sum of a smooth function and the composition of a weakly convex function with a linear operator on a closed vector subspace. For this problem, we propose a projected variable smoothing algorithm and establish a complexity bound of $\mathcal{O}(\epsilon^{-3})$ to achieve an $\epsilon$-approximate solution. Second, we investigate the Moreau envelope and the proximity operator of functions defined as the supremum of weakly convex functions, and we compute the proximity operator in two important cases. In addition, we apply the proposed algorithm for solving a distributionally robust optimization problem, the LASSO with linear constraints, and the max dispersion problem. We illustrate numerical results for the max dispersion problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00525v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergio L\'opez-Rivera, Pedro P\'erez-Aros, Emilio Vilches</dc:creator>
    </item>
    <item>
      <title>Optimal control of quasilinear parabolic PDEs with gradient terms and pointwise constraints on the gradient of the state</title>
      <link>https://arxiv.org/abs/2502.00554</link>
      <description>arXiv:2502.00554v1 Announce Type: new 
Abstract: We derive existence results and first order necessary optimality conditions for optimal control problems governed by quasilinear parabolic PDEs with a class of first order nonlinearities that include for instance quadratic gradient terms. Pointwise in space and time or averaged in space and pointwise in time constraints on the gradient of the state control the growth of the nonlinear terms. We rely on and extend the improved regularity analysis for quasilinear parabolic PDEs on a whole scale of function spaces from [Hoppe et al, 2023]. In case of integral in space gradient-constraints we derive first-order optimality conditions under rather general regularity assumptions for domain, coefficients, and boundary conditions, similar to e.g. [Bonifacius and Neitzel, 2018]. In the case of pointwise in time and space gradient-constraints we use slightly stronger regularity assumptions leading to a classical smoother $W^{2,p}$-setting similar to [Casas and Chrysafinos, 2018].</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00554v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lucas Bonifacius, Fabian Hoppe, Hannes Meinlschmidt, Ira Neitzel</dc:creator>
    </item>
    <item>
      <title>Uniform-in-time weak propagation of chaos for consensus-based optimization</title>
      <link>https://arxiv.org/abs/2502.00582</link>
      <description>arXiv:2502.00582v1 Announce Type: new 
Abstract: We study the uniform-in-time weak propagation of chaos for the consensus-based optimization (CBO) method on a bounded searching domain. We apply the methodology for studying long-time behaviors of interacting particle systems developed in the work of Delarue and Tse (ArXiv:2104.14973). Our work shows that the weak error has order $O(N^{-1})$ uniformly in time, where $N$ denotes the number of particles. The main strategy behind the proofs are the decomposition of the weak errors using the linearized Fokker-Planck equations and the exponential decay of their Sobolev norms. Consequently, our result leads to the joint convergence of the empirical distribution of the CBO particle system to the Dirac-delta distribution at the global minimizer in population size and running time in Wasserstein-type metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00582v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Ibrahim Ekren, Hongyi Zhou</dc:creator>
    </item>
    <item>
      <title>Functional role of synchronization: A mean-field control perspective</title>
      <link>https://arxiv.org/abs/2502.00590</link>
      <description>arXiv:2502.00590v1 Announce Type: new 
Abstract: The broad goal of the research surveyed in this article is to develop methods for understanding the aggregate behavior of interconnected dynamical systems, as found in mathematical physics, neuroscience, economics, power systems and neural networks. Questions concern prediction of emergent (often unanticipated) phenomena, methods to formulate distributed control schemes to influence this behavior, and these topics prompt many other questions in the domain of learning. The area of mean field games, pioneered by Peter Caines, are well suited to addressing these topics. The approach is surveyed in the present paper within the context of controlled coupled oscillators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00590v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prashant Mehta, Sean Meyn</dc:creator>
    </item>
    <item>
      <title>Mirror Descent Under Generalized Smoothness</title>
      <link>https://arxiv.org/abs/2502.00753</link>
      <description>arXiv:2502.00753v1 Announce Type: new 
Abstract: Smoothness is crucial for attaining fast rates in first-order optimization. However, many optimization problems in modern machine learning involve non-smooth objectives. Recent studies relax the smoothness assumption by allowing the Lipschitz constant of the gradient to grow with respect to the gradient norm, which accommodates a broad range of objectives in practice. Despite this progress, existing generalizations of smoothness are restricted to Euclidean geometry with $\ell_2$-norm and only have theoretical guarantees for optimization in the Euclidean space. In this paper, we address this limitation by introducing a new $\ell*$-smoothness concept that measures the norm of Hessian in terms of a general norm and its dual, and establish convergence for mirror-descent-type algorithms, matching the rates under the classic smoothness. Notably, we propose a generalized self-bounding property that facilitates bounding the gradients via controlling suboptimality gaps, serving as a principal component for convergence analysis. Beyond deterministic optimization, we establish an anytime convergence for stochastic mirror descent based on a new bounded noise condition that encompasses the widely adopted bounded or affine noise assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00753v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dingzhi Yu, Wei Jiang, Yuanyu Wan, Lijun Zhang</dc:creator>
    </item>
    <item>
      <title>Mixed-Integer Optimization for Loopless Flux Distributions in Metabolic Networks</title>
      <link>https://arxiv.org/abs/2502.00807</link>
      <description>arXiv:2502.00807v1 Announce Type: new 
Abstract: Constraint-based metabolic models can be used to investigate the intracellular physiology of microorganisms. These models couple genes to reactions, and typically seek to predict metabolite fluxes that optimize some biologically important metric. Classical techniques, like Flux Balance Analysis (FBA), formulate the metabolism of a microbe as an optimization problem where growth rate is maximized. While FBA has found widespread use, it often leads to thermodynamically infeasible solutions that contain internal cycles (loops). To address this shortcoming, Loopless-Flux Balance Analysis (ll-FBA) seeks to predict flux distributions that do not contain these loops. ll-FBA is a disjunctive program, usually reformulated as a mixed-integer program, and is challenging to solve for biological models that often contain thousands of reactions and metabolites. In this paper, we compare various reformulations of ll-FBA and different solution approaches. %We discuss the use of intersection cuts and compare the performance of blocking cycles to decomposing the problem and to solving the convex hull formulation. Overall, the combinatorial Benders' decomposition is the most promising of the tested approaches with which we could solve most instances. However, the model size and numerical instability pose a challenge to the combinatorial Benders' method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00807v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannah Troppens, Mathieu Besan\c{c}on, St. Elmo Wilken, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>System Architecture Optimization Strategies: Dealing with Expensive Hierarchical Problems</title>
      <link>https://arxiv.org/abs/2502.00838</link>
      <description>arXiv:2502.00838v1 Announce Type: new 
Abstract: Choosing the right system architecture for the problem at hand is challenging due to the large design space and high uncertainty in the early stage of the design process. Formulating the architecting process as an optimization problem may mitigate some of these challenges. This work investigates strategies for solving System Architecture Optimization (SAO) problems: expensive, black-box, hierarchical, mixed-discrete, constrained, multi-objective problems that may be subject to hidden constraints. Imputation ratio, correction ratio, correction fraction, and max rate diversity metrics are defined for characterizing hierar chical design spaces. This work considers two classes of optimization algorithms for SAO: Multi-Objective Evolutionary Algorithms (MOEA) such as NSGA-II, and Bayesian Optimization (BO) algorithms. A new Gaussian process kernel is presented that enables modeling hierarchical categorical variables, extending previous work on modeling continuous and integer hierarchical variables. Next, a hierarchical sampling algorithm that uses design space hierarchy to group design vectors by active design variables is developed. Then, it is demonstrated that integrating more hierarchy information in the optimization algorithms yields better optimization results for BO algorithms. Several realistic single-objective and multi-objective test problems are used for investigations. Finally, the BO algorithm is applied to a jet engine architecture optimization problem. This work shows that the developed BO algorithm can effectively solve the problem with one order of magnitude less function evaluations than NSGA-II. The algorithms and problems used in this work are implemented in the open-source Python library SBArchOpt.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00838v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10898-024-01443-8</arxiv:DOI>
      <dc:creator>Jasper H. Bussemaker, Paul Saves, Nathalie Bartoli, Thierry Lefebvre, R\'emi Lafage</dc:creator>
    </item>
    <item>
      <title>High-Dimensional Bayesian Optimization Using Both Random and Supervised Embeddings</title>
      <link>https://arxiv.org/abs/2502.00854</link>
      <description>arXiv:2502.00854v1 Announce Type: new 
Abstract: Bayesian optimization (BO) is one of the most powerful strategies to solve computationally expensive-to-evaluate blackbox optimization problems. However, BO methods are conventionally used for optimization problems of small dimension because of the curse of dimensionality. In this paper, a high-dimensionnal optimization method incorporating linear embedding subspaces of small dimension is proposed to efficiently perform the optimization. An adaptive learning strategy for these linear embeddings is carried out in conjunction with the optimization. The resulting BO method, named efficient global optimization coupled with random and supervised embedding (EGORSE), combines in an adaptive way both random and supervised linear embeddings. EGORSE has been compared to state-of-the-art algorithms and tested on academic examples with a number of design variables ranging from 10 to 600. The obtained results show the high potential of EGORSE to solve high-dimensional blackbox optimization problems, in terms of both CPU time and the limited number of calls to the expensive blackbox simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00854v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.2514/1.J063488</arxiv:DOI>
      <arxiv:journal_reference>AIAA Journal 2025 63:1, 162-173</arxiv:journal_reference>
      <dc:creator>R\'emy Priem, Youssef Diouane, Nathalie Bartoli, Sylvain Dubreuil, Paul Saves</dc:creator>
    </item>
    <item>
      <title>Multivariable Stochastic Newton-Based Extremum Seeking with Delays</title>
      <link>https://arxiv.org/abs/2502.00861</link>
      <description>arXiv:2502.00861v1 Announce Type: new 
Abstract: This paper presents a Newton-based stochastic extremum-seeking control method for real-time optimization in multi-input systems with distinct input delays. It combines predictor-based feedback and Hessian inverse estimation via stochastic perturbations to enable delay compensation with user-defined convergence rates. The method ensures exponential stability and convergence near the unknown extremum, even under long delays. It extends to multi-input, single-output systems with cross-coupled channels. Stability is analyzed using backstepping and infinite-dimensional averaging. Numerical simulations demonstrate its effectiveness in handling time-delayed channels, showcasing both the challenges and benefits of real-time optimization in distributed parameter settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00861v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paulo Cesar Souza Silva, Paulo Cesar Pellanda, Tiago Roux Oliveira</dc:creator>
    </item>
    <item>
      <title>A Variational Inequality Approach to Independent Learning in Static Mean-Field Games</title>
      <link>https://arxiv.org/abs/2502.00915</link>
      <description>arXiv:2502.00915v1 Announce Type: new 
Abstract: Competitive games involving thousands or even millions of players are prevalent in real-world contexts, such as transportation, communications, and computer networks. However, learning in these large-scale multi-agent environments presents a grand challenge, often referred to as the "curse of many agents". In this paper, we formalize and analyze the Static Mean-Field Game (SMFG) under both full and bandit feedback, offering a generic framework for modeling large population interactions while enabling independent learning.
  We first establish close connections between SMFG and variational inequality (VI), showing that SMFG can be framed as a VI problem in the infinite agent limit. Building on the VI perspective, we propose independent learning and exploration algorithms that efficiently converge to approximate Nash equilibria, when dealing with a finite number of agents. Theoretically, we provide explicit finite sample complexity guarantees for independent learning across various feedback models in repeated play scenarios, assuming (strongly-)monotone payoffs. Numerically, we validate our results through both simulations and real-world applications in city traffic and network access management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00915v1</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Batuhan Yardim, Semih Cayci, Niao He</dc:creator>
    </item>
    <item>
      <title>Event-Triggered Newton-Based Extremum Seeking Control</title>
      <link>https://arxiv.org/abs/2502.00930</link>
      <description>arXiv:2502.00930v1 Announce Type: new 
Abstract: This paper proposes the incorporation of static event-triggered control in the actuation path of Newton-based extremum seeking and its comparison with the earlier gradient version. As in the continuous methods, the convergence rate of the gradient approach depends on the unknown Hessian of the nonlinear map to be optimized, whereas the proposed event-triggered Newton-based extremum seeking eliminates this dependence, becoming user-assignable. This is achieved by means of a dynamic estimator for the Hessian's inverse, implemented as a Riccati equation filter. Lyapunov stability and averaging theory for discontinuous systems are applied to analyze the closed-loop system. Local exponential practical stability is guaranteed to a small neighborhood of the extremum point of scalar and static maps. Numerical simulations illustrate the advantages of the proposed approach over the previous gradient method, including improved convergence speed, followed by a reduction in the amplitude and updating frequency of the control signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00930v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Hugo Pereira Rodrigues, Tiago Roux Oliveira, Miroslav Krstic, Paulo Tabuada</dc:creator>
    </item>
    <item>
      <title>On the Surprising Robustness of Sequential Convex Optimization for Contact-Implicit Motion Planning</title>
      <link>https://arxiv.org/abs/2502.01055</link>
      <description>arXiv:2502.01055v1 Announce Type: new 
Abstract: Contact-implicit motion planning-embedding contact sequencing as implicit complementarity constraints-holds the promise of leveraging continuous optimization to discover new contact patterns online. Nevertheless, the resulting optimization, being an instance of Mathematical Programming with Complementary Constraints, fails the classical constraint qualifications that are crucial for the convergence of popular numerical solvers. We present robust contact-implicit motion planning with sequential convex programming (CRISP), a solver that departs from the usual primal-dual algorithmic framework but instead only focuses on the primal problem. CRISP solves a convex quadratic program with an adaptive trust region radius at each iteration, and its convergence is evaluated by a merit function using weighted penalty. We (i) provide sufficient conditions on CRISP's convergence to first-order stationary points of the merit function; (ii) release a high-performance C++ implementation of CRISP with a generic nonlinear programming interface; and (iii) demonstrate CRISP's surprising robustness in solving contact-implicit planning with naive initialization. In fact, CRISP solves several contact-implicit problems with all-zero initialization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01055v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulin Li, Haoyu Han, Shucheng Kang, Jun Ma, Heng Yang</dc:creator>
    </item>
    <item>
      <title>A global approach for generalized semi-infinte programs with polyhedral parameter sets</title>
      <link>https://arxiv.org/abs/2502.01075</link>
      <description>arXiv:2502.01075v1 Announce Type: new 
Abstract: This paper studies generalized semi-infinite programs (GSIPs) defined with polyhedral parameter sets. Assume these GSIPs are given by polynomials. We propose a new approach to solve them as a disjunctive program. This approach is based on the Kurash-Kuhn-Tucker (KKT) conditions of the robust constraint and a technique called partial Lagrange multiplier expressions. We summarize a semidefinite algorithm and study its convergence properties. Numerical experiments are given to show the efficiency of our method. In addition, we checked its performance in gemstone cutting and robust control applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01075v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaomeng Hu, Jiawang Nie, Suhan Zhong</dc:creator>
    </item>
    <item>
      <title>A Minimax Optimal Controller for Positive Systems</title>
      <link>https://arxiv.org/abs/2502.01180</link>
      <description>arXiv:2502.01180v1 Announce Type: new 
Abstract: We present an explicit solution to the discrete-time Bellman equation for minimax optimal control of positive systems under unconstrained disturbances. The primary contribution of our result relies on deducing a bound for the disturbance penalty, which characterizes the existence of a finite solution to the problem class. Moreover, this constraint on the disturbance penalty reveals that, in scenarios where a solution is feasible, the problem converges to its equivalent minimization problem in the absence of disturbances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01180v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alba Gurpegui, Emma Tegling, Anders Rantzer</dc:creator>
    </item>
    <item>
      <title>Sparsity-driven Aggregation of Mixed Integer Programs</title>
      <link>https://arxiv.org/abs/2502.01192</link>
      <description>arXiv:2502.01192v2 Announce Type: new 
Abstract: Cutting planes are crucial for the performance of branch-and-cut algorithms for solving mixed-integer programming (MIP) problems, and linear row aggregation has been successfully applied to better leverage the potential of several major families of MIP cutting planes. This paper formulates the problem of finding good quality aggregations as an $\ell_0$-norm minimization problem and employs a combination of the lasso method and iterative reweighting to efficiently find sparse solutions corresponding to good aggregations. A comparative analysis of the proposed algorithm and the state-of-the-art greedy heuristic approach is presented, showing that the greedy heuristic implements a stepwise selection algorithm for the $\ell_0$-norm minimization problem. Further, we present an example where our approach succeeds, whereas the standard heuristic fails to find an aggregation with desired properties. The algorithm is implemented within the constraint integer programming solver SCIP, and computational experiments on the MIPLIB 2017 benchmark show that although the algorithm leads to slowdowns on relatively ``easier'' instances, our aggregation approach decreases the mean running time on a subset of challenging instances and leads to smaller branch-and-bound trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01192v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liding Xu, Gioni Mexi, Ksenia Bestuzheva</dc:creator>
    </item>
    <item>
      <title>Constrained non-linear estimation and links with stochastic filtering</title>
      <link>https://arxiv.org/abs/2502.01200</link>
      <description>arXiv:2502.01200v1 Announce Type: new 
Abstract: This article studies the problem of estimating the state variable of non-smooth subdifferential dynamics constrained in a bounded convex domain given some real-time observation. On the one hand, we show that the value function of the estimation problem is a viscosity solution of a Hamilton Jacobi Bellman equation whose sub and super solutions have different Neumann type boundary conditions. This intricacy arises from the non-reversibility in time of the non-smooth dynamics, and hinders the derivation of a comparison principle and the uniqueness of the solution in general. Nonetheless, we identify conditions on the drift (including zero drift) coefficient in the non-smooth dynamics that make such a derivation possible. On the other hand, we show in a general situation that the value function appears in the small noise limit of the corresponding stochastic filtering problem by establishing a large deviation result. We also give quantitative approximation results when replacing the non-smooth dynamics with a smooth penalised one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01200v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Louis-Pierre Chaintron (DMA), Laurent Mertz (CUHK), Philippe Moireau (CMAP), Hasnaa Zidani (LMI)</dc:creator>
    </item>
    <item>
      <title>Super-duality and necessary optimality conditions of order "infinity" in optimal control theory</title>
      <link>https://arxiv.org/abs/2502.01274</link>
      <description>arXiv:2502.01274v1 Announce Type: new 
Abstract: We systematically introduce an approach to the analysis and (numerical) solution of a broad class of nonlinear unconstrained optimal control problems, involving ordinary and distributed systems. Our approach relies on exact representations of the increments of the objective functional, drawing inspiration from the classical Weierstrass formula in Calculus of Variations. While such representations are straightforward to devise for state-linear problems (in vector spaces), they can also be extended to nonlinear models (in metric spaces) by immersing them into suitable linear "super-structures". We demonstrate that these increment formulas lead to necessary optimality conditions of an arbitrary order. Moreover, they enable to formulate optimality conditions of "infinite order", incorporating a kind of feedback mechanism. As a central result, we rigorously apply this general technique to the optimal control of nonlocal continuity equations in the space of probability measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01274v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolay Pogodaev, Maxim Staritsyn</dc:creator>
    </item>
    <item>
      <title>Non-Stationary Gradient Descent for Optimal Auto-Scaling in Serverless Platforms</title>
      <link>https://arxiv.org/abs/2502.01284</link>
      <description>arXiv:2502.01284v1 Announce Type: new 
Abstract: To efficiently manage serverless computing platforms, a key aspect is the auto-scaling of services, i.e., the set of computational resources allocated to a service adapts over time as a function of the traffic demand. The objective is to find a compromise between user-perceived performance and energy consumption. In this paper, we consider the \emph{scale-per-request} auto-scaling pattern and investigate how many function instances (or servers) should be spawned each time an \emph{unfortunate} job arrives, i.e., a job that finds all servers busy upon its arrival. We address this problem by following a stochastic optimization approach: we develop a stochastic gradient descent scheme of the Kiefer--Wolfowitz type that applies \emph{over a single run of the state evolution}. At each iteration, the proposed scheme computes an estimate of the number of servers to spawn each time an unfortunate job arrives to minimize some cost function. Under natural assumptions, we show that the sequence of estimates produced by our scheme is asymptotically optimal almost surely. In addition, we prove that its convergence rate is $O(n^{-2/3})$ where $n$ is the number of iterations.
  From a mathematical point of view, the stochastic optimization framework induced by auto-scaling exhibits non-standard aspects that we approach from a general point of view. We consider the setting where a controller can only get samples of the \emph{transient} -- rather than stationary -- behavior of the underlying stochastic system. To handle this difficulty, we develop arguments that exploit properties of the mixing time of the underlying Markov chain. By means of numerical simulations, we validate the proposed approach and quantify its gain with respect to common existing scale-up rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01284v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Anselmi Jonatha, Gaujal Bruno, Rebuffi Louis-Sebastien</dc:creator>
    </item>
    <item>
      <title>Optimization-based Coordination of Traffic Lights and Automated Vehicles at Intersections</title>
      <link>https://arxiv.org/abs/2502.01315</link>
      <description>arXiv:2502.01315v1 Announce Type: new 
Abstract: This paper tackles the challenge of coordinating traffic lights and automated vehicles at signalized intersections, formulated as a constrained finite-horizon optimal control problem. The problem falls into the category of mixed-integer nonlinear programming, posing challenges for solving large instances. To address this, we introduce a decomposition approach consisting of an upper-level problem for traffic light timing allocation and a set of lower-level problems that generate appropriate commands for automated vehicles in each intersection movement. By leveraging solutions from the lower-level problems and employing parametric optimization techniques, we solve the upper-level problem using a standard sequential quadratic programming approach. The paper concludes by presenting an illustrative numerical example that highlights the effectiveness of our algorithm compared to scenarios where no coordination between traffic lights and vehicles exists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01315v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Azita Dabiri, Giray \"On\"ur, Sebastien Gros, Bart De Schutter</dc:creator>
    </item>
    <item>
      <title>Diffusion at Absolute Zero: Langevin Sampling Using Successive Moreau Envelopes</title>
      <link>https://arxiv.org/abs/2502.01358</link>
      <description>arXiv:2502.01358v1 Announce Type: new 
Abstract: In this article we propose a novel method for sampling from Gibbs distributions of the form $\pi(x)\propto\exp(-U(x))$ with a potential $U(x)$. In particular, inspired by diffusion models we propose to consider a sequence $(\pi^{t_k})_k$ of approximations of the target density, for which $\pi^{t_k}\approx \pi$ for $k$ small and, on the other hand, $\pi^{t_k}$ exhibits favorable properties for sampling for $k$ large. This sequence is obtained by replacing parts of the potential $U$ by its Moreau envelopes. Sampling is performed in an Annealed Langevin type procedure, that is, sequentially sampling from $\pi^{t_k}$ for decreasing $k$, effectively guiding the samples from a simple starting density to the more complex target. In addition to a theoretical analysis we show experimental results supporting the efficacy of the method in terms of increased convergence speed and applicability to multi-modal densities $\pi$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01358v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Habring, Alexander Falk, Thomas Pock</dc:creator>
    </item>
    <item>
      <title>On finite convergence and minimizer extraction in moment relaxations with correlative sparsity</title>
      <link>https://arxiv.org/abs/2502.01410</link>
      <description>arXiv:2502.01410v1 Announce Type: new 
Abstract: We provide a new sufficient condition to detect the finite convergence of moment relaxations of polynomial optimization problems with correlative sparsity. The condition requires that certain moment matrices in the relaxation admit a flat extension, and that the variable cliques used to construct the relaxation satisfy a `running intersection' property. The proof also reveals an algorithm to extract at least as many minimizers for the original polynomial optimization problem as the smallest rank of the moment matrices in its relaxation. The necessity of the running intersection property is demonstrated with an illustrative example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01410v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giovanni Fantuzzi, Federico Fuentes</dc:creator>
    </item>
    <item>
      <title>Alternating direction method of multipliers for polynomial optimization</title>
      <link>https://arxiv.org/abs/2502.01439</link>
      <description>arXiv:2502.01439v1 Announce Type: new 
Abstract: Multivariate polynomial optimization is a prevalent model for a number of engineering problems. From a mathematical viewpoint, polynomial optimization is challenging because it is non-convex. The Lasserre's theory, based on semidefinite relaxations, provides an effective tool to overcome this issue and to achieve the global optimum. However, this approach can be computationally complex for medium and large scale problems. For this motivation, in this work, we investigate a local minimization approach, based on the alternating direction method of multipliers, which is low-complex, straightforward to implement, and prone to decentralization. The core of the work is the development of the algorithm tailored to polynomial optimization, along with the proof of its convergence. Through a numerical example we show a practical implementation and test the effectiveness of the proposed algorithm with respect to state-of-the-art methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01439v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>V. Cerone, S. M. Fosson, S. Pirrera, D. Regruto</dc:creator>
    </item>
    <item>
      <title>Deep learning adaptive Model Predictive Control of Fed-Batch Cultivations</title>
      <link>https://arxiv.org/abs/2502.01488</link>
      <description>arXiv:2502.01488v2 Announce Type: new 
Abstract: Bioprocesses are often characterised by nonlinear and uncertain dynamics, posing particular challenges for model predictive control (MPC) algorithms due to their computational demands when applied to nonlinear systems. Recent advances in optimal control theory have demonstrated that concepts from convex optimisation, tube MPC, and differences of convex functions (DC) enable efficient, robust online process control. Our approach is based on DC decompositions of nonlinear dynamics and successive linearisations around predicted trajectories. By convexity, the linearisation errors have tight bounds and can be treated as bounded disturbances within a robust tube MPC framework. We describe a systematic, data-driven method for computing DC model representations using deep learning neural networks with a special convex structure, and explain how the resulting MPC optimisation can be solved using convex programming. For the problem of maximising product formation in a cultivation with uncertain model parameters, we design a controller that ensures robust constraint satisfaction and allows online estimation of unknown model parameters. Our results indicate that this method is a promising solution for computationally tractable, robust MPC of bioprocesses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01488v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niels Krausch, Martin Doff-Sotta, Mark Cannon, Peter Neubauer, Mariano Nicolas Cruz Bournazou</dc:creator>
    </item>
    <item>
      <title>A uniform rate of convergence for the entropic potentials in the quadratic Euclidean setting</title>
      <link>https://arxiv.org/abs/2502.00084</link>
      <description>arXiv:2502.00084v1 Announce Type: cross 
Abstract: We bound the rate of uniform convergence in compact sets for both entropic potentials and their gradients towards the Brenier potential and its gradient, respectively. Both results hold in the quadratic Euclidean setting for absolutely continuous measures satisfying some convexity assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00084v1</guid>
      <category>math.CA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pablo L\'opez-Rivera</dc:creator>
    </item>
    <item>
      <title>Learning Difference-of-Convex Regularizers for Inverse Problems: A Flexible Framework with Theoretical Guarantees</title>
      <link>https://arxiv.org/abs/2502.00240</link>
      <description>arXiv:2502.00240v1 Announce Type: cross 
Abstract: Learning effective regularization is crucial for solving ill-posed inverse problems, which arise in a wide range of scientific and engineering applications. While data-driven methods that parameterize regularizers using deep neural networks have demonstrated strong empirical performance, they often result in highly nonconvex formulations that lack theoretical guarantees. Recent work has shown that incorporating structured nonconvexity into neural network-based regularizers, such as weak convexity, can strike a balance between empirical performance and theoretical tractability. In this paper, we demonstrate that a broader class of nonconvex functions, difference-of-convex (DC) functions, can yield improved empirical performance while retaining strong convergence guarantees. The DC structure enables the use of well-established optimization algorithms, such as the Difference-of-Convex Algorithm (DCA) and a Proximal Subgradient Method (PSM), which extend beyond standard gradient descent. Furthermore, we provide theoretical insights into the conditions under which optimal regularizers can be expressed as DC functions. Extensive experiments on computed tomography (CT) reconstruction tasks show that our approach achieves strong performance across sparse and limited-view settings, consistently outperforming other weakly supervised learned regularizers. Our code is available at \url{https://github.com/YasminZhang/ADCR}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00240v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasi Zhang, Oscar Leong</dc:creator>
    </item>
    <item>
      <title>Learning to Fuse Temporal Proximity Networks: A Case Study in Chimpanzee Social Interactions</title>
      <link>https://arxiv.org/abs/2502.00302</link>
      <description>arXiv:2502.00302v1 Announce Type: cross 
Abstract: How can we identify groups of primate individuals which could be conjectured to drive social structure? To address this question, one of us has collected a time series of data for social interactions between chimpanzees. Here we use a network representation, leading to the task of combining these data into a time series of a single weighted network per time stamp, where different proximities should be given different weights reflecting their relative importance. We optimize these proximity-type weights in a principled way, using an innovative loss function which rewards structural consistency across time. The approach is empirically validated by carefully designed synthetic data. Using statistical tests, we provide a way of identifying groups of individuals that stay related for a significant length of time. Applying the approach to the chimpanzee data set, we detect cliques in the animal social network time series, which can be validated by real-world intuition from prior research and qualitative observations by chimpanzee experts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00302v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yixuan He, Aaron Sandel, David Wipf, Mihai Cucuringu, John Mitani, Gesine Reinert</dc:creator>
    </item>
    <item>
      <title>HoP: Homeomorphic Polar Learning for Hard Constrained Optimization</title>
      <link>https://arxiv.org/abs/2502.00304</link>
      <description>arXiv:2502.00304v1 Announce Type: cross 
Abstract: Constrained optimization demands highly efficient solvers which promotes the development of learn-to-optimize (L2O) approaches. As a data-driven method, L2O leverages neural networks to efficiently produce approximate solutions. However, a significant challenge remains in ensuring both optimality and feasibility of neural networks' output. To tackle this issue, we introduce Homeomorphic Polar Learning (HoP) to solve the star-convex hard-constrained optimization by embedding homeomorphic mapping in neural networks. The bijective structure enables end-to-end training without extra penalty or correction. For performance evaluation, we evaluate HoP's performance across a variety of synthetic optimization tasks and real-world applications in wireless communications. In all cases, HoP achieves solutions closer to the optimum than existing L2O methods while strictly maintaining feasibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00304v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ke Deng, Hanwen Zhang, Jin Lu, Haijian Sun</dc:creator>
    </item>
    <item>
      <title>$k$-SVD with Gradient Descent</title>
      <link>https://arxiv.org/abs/2502.00320</link>
      <description>arXiv:2502.00320v1 Announce Type: cross 
Abstract: We show that a gradient-descent with a simple, universal rule for step-size selection provably finds $k$-SVD, i.e., the $k\geq 1$ largest singular values and corresponding vectors, of any matrix, despite nonconvexity. There has been substantial progress towards this in the past few years where existing results are able to establish such guarantees for the \emph{exact-parameterized} and \emph{over-parameterized} settings, with choice of oracle-provided step size. But guarantees for generic setting with a step size selection that does not require oracle-provided information has remained a challenge. We overcome this challenge and establish that gradient descent with an appealingly simple adaptive step size (akin to preconditioning) and random initialization enjoys global linear convergence for generic setting. Our convergence analysis reveals that the gradient method has an attracting region, and within this attracting region, the method behaves like Heron's method (a.k.a. the Babylonian method). Empirically, we validate the theoretical results. The emergence of modern compute infrastructure for iterative optimization coupled with this work is likely to provide means to solve $k$-SVD for very large matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00320v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emily Gan, Yassir Jedra, Devavrat Shah</dc:creator>
    </item>
    <item>
      <title>Sharp regularity of sub-Riemannian length-minimizing curves</title>
      <link>https://arxiv.org/abs/2502.00403</link>
      <description>arXiv:2502.00403v1 Announce Type: cross 
Abstract: A longstanding open question in sub-Riemannian geometry is the smoothness of (the arc-length parameterization of) length-minimizing curves. In [6], this question is negative answered, with an example of a $C^2$ but not $C^3$ length-minimizer of a real-analytic (even polynomial) sub-Riemannian structure. In this paper, we study a class of examples of sub-Riemannian structures that generalizes that presented in [6], and we prove that length-minimizing curves must be at least of class $C^2$ within these examples. In particular, we prove that Theorem 1.1 in [6] is sharp.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00403v1</guid>
      <category>math.DG</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Socionovo</dc:creator>
    </item>
    <item>
      <title>Efficient Over-parameterized Matrix Sensing from Noisy Measurements via Alternating Preconditioned Gradient Descent</title>
      <link>https://arxiv.org/abs/2502.00463</link>
      <description>arXiv:2502.00463v1 Announce Type: cross 
Abstract: We consider the noisy matrix sensing problem in the over-parameterization setting, where the estimated rank $r$ is larger than the true rank $r_\star$. Specifically, our main objective is to recover a matrix $ X_\star \in \mathbb{R}^{n_1 \times n_2} $ with rank $ r_\star $ from noisy measurements using an over-parameterized factorized form $ LR^\top $, where $ L \in \mathbb{R}^{n_1 \times r}, \, R \in \mathbb{R}^{n_2 \times r} $ and $ \min\{n_1, n_2\} \ge r &gt; r_\star $, with the true rank $ r_\star $ being unknown. Recently, preconditioning methods have been proposed to accelerate the convergence of matrix sensing problem compared to vanilla gradient descent, incorporating preconditioning terms $ (L^\top L + \lambda I)^{-1} $ and $ (R^\top R + \lambda I)^{-1} $ into the original gradient. However, these methods require careful tuning of the damping parameter $\lambda$ and are sensitive to initial points and step size. To address these limitations, we propose the alternating preconditioned gradient descent (APGD) algorithm, which alternately updates the two factor matrices, eliminating the need for the damping parameter and enabling faster convergence with larger step sizes. We theoretically prove that APGD achieves near-optimal error convergence at a linear rate, starting from arbitrary random initializations. Through extensive experiments, we validate our theoretical results and demonstrate that APGD outperforms other methods, achieving the fastest convergence rate. Notably, both our theoretical analysis and experimental results illustrate that APGD does not rely on the initialization procedure, making it more practical and versatile.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00463v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyu Liu, Zhi Han, Yandong Tang, Hai Zhang, Shaojie Tang, Yao Wang</dc:creator>
    </item>
    <item>
      <title>Evolution of Society Caused by Collective and Individual Decisions</title>
      <link>https://arxiv.org/abs/2502.00471</link>
      <description>arXiv:2502.00471v1 Announce Type: cross 
Abstract: Under the assumptions of the ViSE model, we investigate the welfare and performance of a society consisting of one group (a ``party'') and individualists. In the case of Gaussian proposal generators, the expected capital gains can be expressed in standard functions. The relative effectiveness of individualistic and group strategies of agents, as well as the benefits of the entire society, depend on the level of cooperation, the voting threshold, and the favorability of the environment. We focus on the evolution of society in neutral environments caused by changing its structure and the voting rule in the interests of agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00471v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pavel Chebotarev</dc:creator>
    </item>
    <item>
      <title>Stabilizability of 2D and 3D Navier-Stokes equations with memory around a non-constant steady state</title>
      <link>https://arxiv.org/abs/2502.00517</link>
      <description>arXiv:2502.00517v1 Announce Type: cross 
Abstract: In this article, we investigate the stabilizability of the two- and three-dimensional Navier-Stokes equations with memory effects around a non-constant steady state using a localized interior control. The system is first linearized around a non-constant steady state and then reformulated into a coupled system by introducing a new variable to handle the integral term. Due to the presence of variable coefficients in the linear operator, the rigorous computation of eigenvalues and eigenfunctions becomes infeasible. Therefore, we concentrate on the principal operator, and investigate its analyticity and spectral properties. We establish a feedback stabilization result for the principal system, ensuring a specific decay rate. Using the feedback operator derived from this analysis, we extend the approach to the full system, constructing a closed-loop system. By proving a suitable regularity result and applying a fixed-point argument, we ultimately demonstrate the stabilizability of the full system. We also discuss the stabilizability of the corresponding vorticity equation around a non-constant steady state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00517v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wasim Akram, Manika Bag, Manil T. Mohan</dc:creator>
    </item>
    <item>
      <title>Optimization for Neural Operators can Benefit from Width</title>
      <link>https://arxiv.org/abs/2502.00705</link>
      <description>arXiv:2502.00705v1 Announce Type: cross 
Abstract: Neural Operators that directly learn mappings between function spaces, such as Deep Operator Networks (DONs) and Fourier Neural Operators (FNOs), have received considerable attention. Despite the universal approximation guarantees for DONs and FNOs, there is currently no optimization convergence guarantee for learning such networks using gradient descent (GD). In this paper, we address this open problem by presenting a unified framework for optimization based on GD and applying it to establish convergence guarantees for both DONs and FNOs. In particular, we show that the losses associated with both of these neural operators satisfy two conditions -- restricted strong convexity (RSC) and smoothness -- that guarantee a decrease on their loss values due to GD. Remarkably, these two conditions are satisfied for each neural operator due to different reasons associated with the architectural differences of the respective models. One takeaway that emerges from the theory is that wider networks should lead to better optimization convergence for both DONs and FNOs. We present empirical results on canonical operator learning problems to support our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00705v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pedro Cisneros-Velarde, Bhavesh Shrimali, Arindam Banerjee</dc:creator>
    </item>
    <item>
      <title>ATA: Adaptive Task Allocation for Efficient Resource Management in Distributed Machine Learning</title>
      <link>https://arxiv.org/abs/2502.00775</link>
      <description>arXiv:2502.00775v1 Announce Type: cross 
Abstract: Asynchronous methods are fundamental for parallelizing computations in distributed machine learning. They aim to accelerate training by fully utilizing all available resources. However, their greedy approach can lead to inefficiencies using more computation than required, especially when computation times vary across devices. If the computation times were known in advance, training could be fast and resource-efficient by assigning more tasks to faster workers. The challenge lies in achieving this optimal allocation without prior knowledge of the computation time distributions. In this paper, we propose ATA (Adaptive Task Allocation), a method that adapts to heterogeneous and random distributions of worker computation times. Through rigorous theoretical analysis, we show that ATA identifies the optimal task allocation and performs comparably to methods with prior knowledge of computation times. Experimental results further demonstrate that ATA is resource-efficient, significantly reducing costs compared to the greedy approach, which can be arbitrarily expensive depending on the number of workers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00775v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Artavazd Maranjyan, El Mehdi Saad, Peter Richt\'arik, Francesco Orabona</dc:creator>
    </item>
    <item>
      <title>Worth Their Weight: Randomized and Regularized Block Kaczmarz Algorithms without Preprocessing</title>
      <link>https://arxiv.org/abs/2502.00882</link>
      <description>arXiv:2502.00882v1 Announce Type: cross 
Abstract: Due to the ever growing amounts of data leveraged for machine learning and scientific computing, it is increasingly important to develop algorithms that sample only a small portion of the data at a time. In the case of linear least-squares, the randomized block Kaczmarz method (RBK) is an appealing example of such an algorithm, but its convergence is only understood under sampling distributions that require potentially prohibitively expensive preprocessing steps. To address this limitation, we analyze RBK when the data is sampled uniformly, showing that its iterates converge in a Monte Carlo sense to a $\textit{weighted}$ least-squares solution. Unfortunately, for general problems the condition number of the weight matrix and the variance of the iterates can become arbitrarily large. We resolve these issues by incorporating regularization into the RBK iterations. Numerical experiments, including examples arising from natural gradient optimization, suggest that the regularized algorithm, ReBlocK, outperforms minibatch stochastic gradient descent for realistic problems that exhibit fast singular value decay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00882v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gil Goldshlager, Jiang Hu, Lin Lin</dc:creator>
    </item>
    <item>
      <title>Algorithmic Stability of Stochastic Gradient Descent with Momentum under Heavy-Tailed Noise</title>
      <link>https://arxiv.org/abs/2502.00885</link>
      <description>arXiv:2502.00885v1 Announce Type: cross 
Abstract: Understanding the generalization properties of optimization algorithms under heavy-tailed noise has gained growing attention. However, the existing theoretical results mainly focus on stochastic gradient descent (SGD) and the analysis of heavy-tailed optimizers beyond SGD is still missing. In this work, we establish generalization bounds for SGD with momentum (SGDm) under heavy-tailed gradient noise. We first consider the continuous-time limit of SGDm, i.e., a Levy-driven stochastic differential equation (SDE), and establish quantitative Wasserstein algorithmic stability bounds for a class of potentially non-convex loss functions. Our bounds reveal a remarkable observation: For quadratic loss functions, we show that SGDm admits a worse generalization bound in the presence of heavy-tailed noise, indicating that the interaction of momentum and heavy tails can be harmful for generalization. We then extend our analysis to discrete-time and develop a uniform-in-time discretization error bound, which, to our knowledge, is the first result of its kind for SDEs with degenerate noise. This result shows that, with appropriately chosen step-sizes, the discrete dynamics retain the generalization properties of the limiting SDE. We illustrate our theory on both synthetic quadratic problems and neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00885v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thanh Dang, Melih Barsbey, A K M Rokonuzzaman Sonet, Mert Gurbuzbalaban, Umut Simsekli, Lingjiong Zhu</dc:creator>
    </item>
    <item>
      <title>qNBO: quasi-Newton Meets Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2502.01076</link>
      <description>arXiv:2502.01076v1 Announce Type: cross 
Abstract: Bilevel optimization, addressing challenges in hierarchical learning tasks, has gained significant interest in machine learning. The practical implementation of the gradient descent method to bilevel optimization encounters computational hurdles, notably the computation of the exact lower-level solution and the inverse Hessian of the lower-level objective. Although these two aspects are inherently connected, existing methods typically handle them separately by solving the lower-level problem and a linear system for the inverse Hessian-vector product. In this paper, we introduce a general framework to address these computational challenges in a coordinated manner. Specifically, we leverage quasi-Newton algorithms to accelerate the resolution of the lower-level problem while efficiently approximating the inverse Hessian-vector product. Furthermore, by exploiting the superlinear convergence properties of BFGS, we establish the non-asymptotic convergence analysis of the BFGS adaptation within our framework. Numerical experiments demonstrate the comparable or superior performance of the proposed algorithms in real-world learning tasks, including hyperparameter optimization, data hyper-cleaning, and few-shot meta-learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01076v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sheng Fang, Yong-Jin Liu, Wei Yao, Chengming Yu, Jin Zhang</dc:creator>
    </item>
    <item>
      <title>A two-disk approach to the synthesis of coherent passive equalizers for linear quantum systems</title>
      <link>https://arxiv.org/abs/2502.01332</link>
      <description>arXiv:2502.01332v1 Announce Type: cross 
Abstract: The coherent equalization problem consists in designing a quantum system acting as a mean-square near optimal filter for a given quantum communication channel. The paper develops an improved method for the synthesis of transfer functions for such equalizing filters, based on a linear quantum system model of the channel. The method draws on a connection with the two-disk problem of ${H}_{\infty}$ control for classical (i.e., nonquantum) linear uncertain systems. Compared with the previous methods, the proposed method applies to a broader class of linear quantum communication channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01332v1</guid>
      <category>quant-ph</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valery Ugrinovskii, Shuixin Xiao</dc:creator>
    </item>
    <item>
      <title>PtyGenography: using generative models for regularization of the phase retrieval problem</title>
      <link>https://arxiv.org/abs/2502.01338</link>
      <description>arXiv:2502.01338v1 Announce Type: cross 
Abstract: In phase retrieval and similar inverse problems, the stability of solutions across different noise levels is crucial for applications. One approach to promote it is using signal priors in a form of a generative model as a regularization, at the expense of introducing a bias in the reconstruction. In this paper, we explore and compare the reconstruction properties of classical and generative inverse problem formulations. We propose a new unified reconstruction approach that mitigates overfitting to the generative model for varying noise levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01338v1</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.FA</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Selin Aslan, Tristan van Leeuwen, Allard Mosk, Palina Salanevich</dc:creator>
    </item>
    <item>
      <title>Faster Adaptive Optimization via Expected Gradient Outer Product Reparameterization</title>
      <link>https://arxiv.org/abs/2502.01594</link>
      <description>arXiv:2502.01594v1 Announce Type: cross 
Abstract: Adaptive optimization algorithms -- such as Adagrad, Adam, and their variants -- have found widespread use in machine learning, signal processing and many other settings. Several methods in this family are not rotationally equivariant, meaning that simple reparameterizations (i.e. change of basis) can drastically affect their convergence. However, their sensitivity to the choice of parameterization has not been systematically studied; it is not clear how to identify a "favorable" change of basis in which these methods perform best. In this paper we propose a reparameterization method and demonstrate both theoretically and empirically its potential to improve their convergence behavior. Our method is an orthonormal transformation based on the expected gradient outer product (EGOP) matrix, which can be approximated using either full-batch or stochastic gradient oracles. We show that for a broad class of functions, the sensitivity of adaptive algorithms to choice-of-basis is influenced by the decay of the EGOP matrix spectrum. We illustrate the potential impact of EGOP reparameterization by presenting empirical evidence and theoretical arguments that common machine learning tasks with "natural" data exhibit EGOP spectral decay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01594v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adela DePavia, Vasileios Charisopoulos, Rebecca Willett</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Performance of Stochastic Model Predictive Control</title>
      <link>https://arxiv.org/abs/2210.08599</link>
      <description>arXiv:2210.08599v3 Announce Type: replace 
Abstract: This article presents a dynamic regret analysis for stochastic model predictive control (SMPC) in linear systems with quadratic performance index and additive and multiplicative uncertainties. Under a finite support assumption, the problem can be cast as a finite-dimensional quadratic program, but the problem becomes quickly intractable as the problem size grows exponentially in the horizon length. SMPC aims to compute approximate solutions by solving a sequence of problems with truncated prediction horizons and committing the solution in a receding-horizon fashion. While this approach is widely used in practice, its performance relative to the optimal solution is not well understood. This article reports for the first time a rigorous near-optimal performance guarantee of SMPC: Under stabilizability and detectability conditions, the dynamic regret of SMPC is exponentially small in the prediction horizon length, allowing SMPC to achieve near-optimal performance at a substantially reduced computational expense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.08599v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sungho Shin, Sen Na, Mihai Anitescu</dc:creator>
    </item>
    <item>
      <title>Wasserstein medians: robustness, PDE characterization and numerics</title>
      <link>https://arxiv.org/abs/2307.01765</link>
      <description>arXiv:2307.01765v2 Announce Type: replace 
Abstract: We investigate the notion of Wasserstein median as an alternative to the Wasserstein barycenter, which has become popular but may be sensitive to outliers. In terms of robustness to corrupted data, we indeed show that Wasserstein medians have a breakdown point of approximately $\frac{1}{2}$. We give explicit constructions of Wasserstein medians in dimension one which enable us to obtain $L^p$ estimates (which do not hold in higher dimensions). We also address dual and multimarginal reformulations. In convex subsets of $\mathbb{R}^d$, we connect Wasserstein medians to a minimal (multi) flow problem \`a la Beckmann and a system of PDEs of Monge-Kantorovich-type, for which we propose a $p$-Laplacian approximation. Our analysis eventually leads to a new numerical method to compute Wasserstein medians, which is based on a Douglas-Rachford scheme applied to the minimal flow formulation of the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.01765v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>stat.AP</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/23M1624786</arxiv:DOI>
      <dc:creator>Guillaume Carlier, Enis Chenchene, Katharina Eichinger</dc:creator>
    </item>
    <item>
      <title>On the Convergence Rate of MCTS for the Optimal Value Estimation in Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2402.07063</link>
      <description>arXiv:2402.07063v2 Announce Type: replace 
Abstract: A recent theoretical analysis of a Monte-Carlo tree search (MCTS) method properly modified from the ``upper confidence bound applied to trees" (UCT) algorithm established a surprising result, due to a great deal of empirical successes reported from heuristic usage of UCT with relevant adjustments for various problem domains in the literature, that its rate of convergence of the expected absolute error to zero is $O(1/\sqrt{n})$ in estimating the optimal value at an initial state in a finite-horizon Markov decision process (MDP), where $n$ is the number of simulations. We strengthen this dispiriting slow convergence result by arguing within a simpler algorithmic framework in the perspective of MDP, apart from the usual MCTS description, that the simpler strategy, called ``upper confidence bound 1" (UCB1) for multi-armed bandit problems, when employed as an instance of MCTS by setting UCB1's arm set to be the policy set of the underlying MDP, has an asymptotically faster convergence-rate of $O(\ln n / n)$. We also point out that the UCT-based MCTS in general has the time and space complexities that depend on the size of the state space in the worst case, which contradicts the original design spirit of MCTS. Unless heuristically used, UCT-based MCTS has yet to have theoretical supports for its applicabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07063v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyeong Soo Chang</dc:creator>
    </item>
    <item>
      <title>Linear-Quadratic Mean Field Games in Hilbert spaces</title>
      <link>https://arxiv.org/abs/2402.14935</link>
      <description>arXiv:2402.14935v3 Announce Type: replace 
Abstract: This paper represents the first attempt to develop a theory for linear-quadratic mean field games in possibly infinite dimensional Hilbert spaces. As a starting point, we study the case, considered in most finite dimensional contributions on the topic, where the dependence on the distribution enters just in the objective functional through the mean. This feature allows, similarly to the finite dimensional case, to reduce the usual mean field game system to a Riccati equation and a forward-backward coupled system of abstract evolution equations. Such system is completely new in infinite dimension and no results have been proved on it so far. We show existence and uniqueness of solutions for such system, applying a delicate approximation procedure. We apply the results to a production output planning problem with delay in the control variable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.14935v3</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Salvatore Federico, Fausto Gozzi, Daria Ghilli</dc:creator>
    </item>
    <item>
      <title>Michell Truss and From 1-beam to k-beam</title>
      <link>https://arxiv.org/abs/2403.15915</link>
      <description>arXiv:2403.15915v2 Announce Type: replace 
Abstract: This paper generalizes the Michell Truss problem and Gangbo's paper from 1-dimension to higher dimensions using geometric measure theory.
  Given an elastic surface $S$ made of $(k-1)$-beams under an equilibriated system $F$ of external forces, then we ask the following two questions:
  1. What are the necessary and sufficient conditions for the existence of an elastic body made of $k$-beams whose forces on the surface balance $F$ and whose surfaces consist of $S$.
  2. What is an optimal design so that the total cost is a minimum?
  We've solved the existence question completely; and research is still in progress for the minimal question. In particular when $k=1$, it involves a system of beams joining a given finite collection of pointed forces. It was first introduced by A. Michell in 1904, then used in mechanical engineering, and recently popularized in many pure mathematics works by W. Gangbo, Prager, and others. Here we are going to generalize them to higher dimensional cases. We have already found the minimal solutions in terms of the flat chain complex and vector-valued currents. Right now we are studying the Calibration theory for future directions. I appreciate the discussion with Prof. Robert Hardt!</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15915v2</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Chengcheng Yang</dc:creator>
    </item>
    <item>
      <title>Reconstruction of unknown monotone nonlinear operators in semilinear elliptic models using optimal inputs</title>
      <link>https://arxiv.org/abs/2405.12153</link>
      <description>arXiv:2405.12153v2 Announce Type: replace 
Abstract: Physical models often contain unknown functions and relations. The goal of our work is to answer the question of how one should excite or control a system under consideration in an appropriate way to be able to reconstruct an unknown nonlinear relation. To answer this question, we propose a greedy reconstruction algorithm within an offline-online strategy. We apply this strategy to a two-dimensional semilinear elliptic model. Our identification is based on the application of several space-dependent excitations (also called controls). These specific controls are designed by the algorithm in order to obtain a deeper insight into the underlying physical problem and a more precise reconstruction of the unknown relation. We perform numerical simulations that demonstrate the effectiveness of our approach which is not limited to the current type of equation. Since our algorithm provides not only a way to determine unknown operators by existing data but also protocols for new experiments, it is a holistic concept to tackle the problem of improving physical models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12153v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jan Bartsch, Simon Buchwald, Gabriele Ciaramella, Stefan Volkwein</dc:creator>
    </item>
    <item>
      <title>Subsampled Ensemble Can Improve Generalization Tail Exponentially</title>
      <link>https://arxiv.org/abs/2405.14741</link>
      <description>arXiv:2405.14741v4 Announce Type: replace 
Abstract: Ensemble learning is a popular technique to improve the accuracy of machine learning models. It traditionally hinges on the rationale that aggregating multiple weak models can lead to better models with lower variance and hence higher stability, especially for discontinuous base learners. In this paper, we provide a new perspective on ensembling. By selecting the best model trained on subsamples via majority voting, we can attain exponentially decaying tails for the excess risk, even if the base learner suffers from slow (i.e., polynomial) decay rates. This tail enhancement power of ensembling is agnostic to the underlying base learner and is stronger than variance reduction in the sense of exhibiting rate improvement. We demonstrate how our ensemble methods can substantially improve out-of-sample performances in a range of numerical examples involving heavy-tailed data or intrinsically slow rates. Code for the proposed methods is available at https://github.com/mickeyhqian/VoteEnsemble.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14741v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Huajie Qian, Donghao Ying, Henry Lam, Wotao Yin</dc:creator>
    </item>
    <item>
      <title>A Novel Deflation Approach for Topology Optimization and Application for Optimization of Bipolar Plates of Electrolysis Cells</title>
      <link>https://arxiv.org/abs/2406.17491</link>
      <description>arXiv:2406.17491v2 Announce Type: replace 
Abstract: Topology optimization problems usually feature multiple local minimizers. To guarantee convergence to local minimizers that perform best globally or to find local solutions that are desirable for practical applications due to easy manufacturability or aesthetic designs, it is important to compute multiple local minimizers of topology optimization problems. Existing methods typically rely on Newton-type solvers during the optimization process, which makes them unsuitable for sensitivity-based topology optimization. In this paper, we introduce a novel deflation approach to systematically find multiple local minimizers of general topology optimization problems. The approach is based on a penalization of previously found local solutions in the objective. We validate our approach on the so-called two-pipes five-holes example. Finally, we introduce a model for the topology optimization of bipolar plates of hydrogen electrolysis cells and demonstrate that our deflation approach enables the discovery of novel designs for such plates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17491v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leon Baeck, Sebastian Blauth, Christian Leith\"auser, Ren\'e Pinnau, Kevin Sturm</dc:creator>
    </item>
    <item>
      <title>Frank-Wolfe meets Shapley-Folkman: a systematic approach for solving nonconvex separable problems with linear constraints</title>
      <link>https://arxiv.org/abs/2406.18282</link>
      <description>arXiv:2406.18282v2 Announce Type: replace 
Abstract: We consider separable nonconvex optimization problems under affine constraints. For these problems, the Shapley-Folkman theorem provides an upper bound on the duality gap as a function of the nonconvexity of the objective functions, but does not provide a systematic way to construct primal solutions satisfying that bound. In this work, we develop a two-stage approach to do so. The first stage approximates the optimal dual value with a large set of primal feasible solutions. In the second stage, this set is trimmed down to a primal solution by computing (approximate) Caratheodory representations. The main computational requirement of our method is tractability of the Fenchel conjugates of the component functions and their (sub)gradients. When the function domains are convex, the method recovers the classical duality gap bounds obtained via Shapley-Folkman. When the function domains are nonconvex, the method also recovers classical duality gap bounds from the literature, based on a more general notion of nonconvexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18282v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Dubois-Taine, Alexandre d'Aspremont</dc:creator>
    </item>
    <item>
      <title>Generalized replicator dynamics based on mean-field pairwise comparison dynamic</title>
      <link>https://arxiv.org/abs/2407.20751</link>
      <description>arXiv:2407.20751v2 Announce Type: replace 
Abstract: The pairwise comparison dynamic is a forward ordinary differential equation in a Banach space whose solution is a time-dependent probability measure to maximize utility based on a nonlinear and nonlocal protocol. It contains a wide class of evolutionary game models, such as replicator dynamics and its generalization. We present an inverse control approach to obtain a replicator-type pairwise comparison dynamic from the large discount limit of a mean field game (MFG) as a coupled forward-backward system. This methodology provides a new interpretation of replicator-type dynamics as a myopic perception limit of the dynamic programming. The cost function in the MFG is explicitly obtained to derive the generalized replicator dynamics. We present a finite difference method to compute these models such that the conservation and nonnegativity of the probability density and bounds of the value function can be numerically satisfied. We conduct a computational convergence study of a large discount limit, focusing on potential games and an energy management problem under several conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20751v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hidekazu Yoshioka</dc:creator>
    </item>
    <item>
      <title>On second-order variational analysis of variational convexity of prox-regular functions</title>
      <link>https://arxiv.org/abs/2408.13795</link>
      <description>arXiv:2408.13795v2 Announce Type: replace 
Abstract: Variational convexity, together with ist strong counterpart, of extended-real-valued functions has been recently introduced by Rockafellar. In this paper we present second-order characterizations of these properties, i.e., conditions using first-order generalized derivatives of the subgradient mapping. Up to now, such characterizations are only known under the assumptions of prox-regularity and subdifferential continuity and in this paper we discard the latter. To this aim we slightly modify the definitions of the generalized derivatives to be compatible with the $f$-attentive convergence appearing in the definition of subgradients. We formulate our results in terms of both coderivatives and subspace containing derivatives. We also give formulas for the exact bound of variational convexity and study relations between variational strong convexity, tilt-stable local minimizers and strong metric regularity of some truncation of the subgradient mapping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13795v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Helmut Gfrerer</dc:creator>
    </item>
    <item>
      <title>Parametrized Families of Resolvent Compositions</title>
      <link>https://arxiv.org/abs/2410.01090</link>
      <description>arXiv:2410.01090v2 Announce Type: replace 
Abstract: This paper presents an in-depth analysis of a parametrized version of the resolvent composition, an operation that combines a set-valued operator and a linear operator. We provide new properties and examples, and show that resolvent compositions can be interpreted as parallel compositions of perturbed operators. Additionally, we establish new monotonicity results, even in cases when the initial operator is not monotone. Finally, we derive asymptotic results regarding operator convergence, specifically focusing on graph-convergence and the $\rho$-Hausdorff distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01090v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Diego J. Cornejo</dc:creator>
    </item>
    <item>
      <title>Unified Breakdown Analysis for Byzantine Robust Gossip</title>
      <link>https://arxiv.org/abs/2410.10418</link>
      <description>arXiv:2410.10418v2 Announce Type: replace 
Abstract: In decentralized machine learning, different devices communicate in a peer-to-peer manner to collaboratively learn from each other's data. Such approaches are vulnerable to misbehaving (or Byzantine) devices. We introduce $\mathrm{F}\text{-}\rm RG$, a general framework for building robust decentralized algorithms with guarantees arising from robust-sum-like aggregation rules $\mathrm{F}$. We then investigate the notion of *breakdown point*, and show an upper bound on the number of adversaries that decentralized algorithms can tolerate. We introduce a practical robust aggregation rule, coined $\rm CS_{ours}$, such that $\rm CS_{ours}\text{-}RG$ has a near-optimal breakdown. Other choices of aggregation rules lead to existing algorithms such as $\rm ClippedGossip$ or $\rm NNA$. We give experimental evidence to validate the effectiveness of $\rm CS_{ours}\text{-}RG$ and highlight the gap with $\mathrm{NNA}$, in particular against a novel attack tailored to decentralized communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10418v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renaud Gaucher, Aymeric Dieuleveut, Hadrien Hendrikx</dc:creator>
    </item>
    <item>
      <title>On the numerical integration of the Fokker-Planck equation driven by a mechanical force and the Bismut-Elworthy-Li formula</title>
      <link>https://arxiv.org/abs/2411.08518</link>
      <description>arXiv:2411.08518v2 Announce Type: replace 
Abstract: Optimal control theory aims to find an optimal protocol to steer a system between assigned boundary conditions while minimizing a given cost functional in finite time. Equations arising from these types of problems are often non-linear and difficult to solve numerically. In this note, we describe numerical methods of integration for two partial differential equations that commonly arise in optimal control theory: the Fokker-Planck equation driven by a mechanical potential for which we use Girsanov theorem; and the Hamilton-Jacobi-Bellman, or dynamic programming, equation for which we find the gradient of its solution using the Bismut-Elworthy-Li formula. The computation of the gradient is necessary to specify the optimal protocol. Finally, we give an example application of the numerical techniques to solving an optimal control problem without spacial discretization using machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08518v2</guid>
      <category>math.OC</category>
      <category>cond-mat.stat-mech</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Sanders, Paolo Muratore-Ginanneschi</dc:creator>
    </item>
    <item>
      <title>Block Coordinate DC Programming</title>
      <link>https://arxiv.org/abs/2411.11664</link>
      <description>arXiv:2411.11664v2 Announce Type: replace 
Abstract: We introduce an extension of the Difference of Convex Algorithm (DCA) in the form of a block coordinate approach for problems with separable structure. For $n$ coordinate-blocks and $k$ iterations, our main result proves a non-asymptotic convergence rate of $O(n/k)$ for the proposed method. Furthermore, leveraging the connection between DCA and Expectation Maximization (EM), we propose a block coordinate EM algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11664v2</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hoomaan Maskan, Paniz Halvachi, Suvrit Sra, Alp Yurtsever</dc:creator>
    </item>
    <item>
      <title>De-singularity Subgradient for the $q$-th-Powered $\ell_p$-Norm Weber Location Problem</title>
      <link>https://arxiv.org/abs/2412.15546</link>
      <description>arXiv:2412.15546v2 Announce Type: replace 
Abstract: The Weber location problem is widely used in several artificial intelligence scenarios. However, the gradient of the objective does not exist at a considerable set of singular points. Recently, a de-singularity subgradient method has been proposed to fix this problem, but it can only handle the $q$-th-powered $\ell_2$-norm case ($1\leqslant q&lt;2$), which has only finite singular points. In this paper, we further establish the de-singularity subgradient for the $q$-th-powered $\ell_p$-norm case with $1\leqslant q\leqslant p$ and $1\leqslant p&lt;2$, which includes all the rest unsolved situations in this problem. This is a challenging task because the singular set is a continuum. The geometry of the objective function is also complicated so that the characterizations of the subgradients, minimum and descent direction are very difficult. We develop a $q$-th-powered $\ell_p$-norm Weiszfeld Algorithm without Singularity ($q$P$p$NWAWS) for this problem, which ensures convergence and the descent property of the objective function. Extensive experiments on six real-world data sets demonstrate that $q$P$p$NWAWS successfully solves the singularity problem and achieves a linear computational convergence rate in practical scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.15546v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhao-Rong Lai, Xiaotian Wu, Liangda Fang, Ziliang Chen, Cheng Li</dc:creator>
    </item>
    <item>
      <title>An accelerated gradient method with adaptive restart for convex multiobjective optimization problems</title>
      <link>https://arxiv.org/abs/2501.07863</link>
      <description>arXiv:2501.07863v4 Announce Type: replace 
Abstract: In this work, based on the continuous time approach, we propose an accelerated gradient method with adaptive residual restart for convex multiobjective optimization problems. For the first, we derive rigorously the continuous limit of the multiobjective accelerated proximal gradient method by Tanabe et al. [Comput. Optim. Appl., 2023]. It is a second-order ordinary differential equation (ODE) that involves a special projection operator and can be viewed as an extension of the ODE by Su et al. [J. Mach. Learn. Res., 2016] for Nesterov acceleration. Then, we introduce a novel accelerated multiobjective gradient (AMG) flow with tailored time scaling that adapts automatically to the convex case and the strongly convex case, and the exponential decay rate of a merit function along with the solution trajectory of AMG flow is established via the Lyapunov analysis. After that, we consider an implicit-explicit time discretization and obtain an accelerated multiobjective gradient method with a convex quadratic programming subproblem. The fast sublinear rate and linear rate are proved respectively for convex and strongly convex problems. In addition, we present an efficient residual based adaptive restart technique to overcome the oscillation issue and improve the convergence significantly. Numerical results are provided to validate the practical performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07863v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Luo, Liping Tang, Xinmin Yang</dc:creator>
    </item>
    <item>
      <title>Electricity Market Bidding for Renewable Electrolyzer Plants: An Opportunity Cost Approach</title>
      <link>https://arxiv.org/abs/2501.16844</link>
      <description>arXiv:2501.16844v2 Announce Type: replace 
Abstract: Hydrogen produced through electrolysis with renewable power is considered key to decarbonize several hard-to-electrify sectors. This work proposes a novel approach to model the active electricity market participation of co-located renewable energy and electrolyzer plants, based on opportunity-cost bidding. While a renewable energy plant typically has zero marginal cost, selling power to the grid carries a potential opportunity-cost of not producing hydrogen when it is co-located with a hydrogen electrolyzer. We first consider only the electrolyzer, and derive its revenue of consuming electricity based on the non-convex hydrogen production curve. We then consider the available renewable energy production and form a piece-wise linear cost curve representing the opportunity cost of selling (or revenue from consuming) various levels of electricity. This cost curve can be used to model a stand-alone electrolyzer or a co-located hydrogen and renewable energy plant participating in an electricity market. Our case study analyzes the effects of market-bidding electrolyzers on electricity markets and grid operations. We compare two strategies for a co-located electrolyzer-wind plant; one based on the proposed bid curve and one with a more conventional fixed electrolyzer consumption. The results show that electrolyzers that actively participate in the electricity market lower the average cost of electricity and the amount of curtailed renewable energy in the system compared with a fixed consumption case. However, the difference in total system emissions between the two strategies is insignificant. The specific impacts vary based on electrolyzer capacity and hydrogen price, which determines the location of the co-located plant in the electricity market merit order.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16844v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Gloppen Johnsen, Lesia Mitridati, Jalal Kazempour, Line Roald</dc:creator>
    </item>
    <item>
      <title>The Plateau Problem of Michell Trusses and Orthogonality in Springs</title>
      <link>https://arxiv.org/abs/2501.17214</link>
      <description>arXiv:2501.17214v2 Announce Type: replace 
Abstract: Given finitely many pointed forces in the plane. Suppose that these forces sum up to zero and their net torques also sum up to zero. One can show that there exists a system of springs whose boundary forces exactly counter-balance these pointed forces. We will generalize to higher dimensions using the Cauchy stress tensor for elastic materials.
  Given a system of springs, we can multiply the length of each spring with its corresponding spring constant and then sum these products up. The result is called the total mass of the system. We are interested in the Plateau problem of the existence of the minimal spring system given a boundary condition.
  This minimization problem was first introduced in 1904 by A. Michell. He showed that a minimizer could smear out. The Michell Truss became known in mechanical engineering. It raised attention in optimal design, such as minimizing costs in building bridges. In 1960s and 1970s, the problem was developed using PDE and convex analysis by introducing an equivalent dual maximization problem. In 2008, Bouchitt\'{e}, Gangbo, and Sppecher introduced lines of principal actions to generalize Hencky-Prandtle net to higher dimensional duality and proved that the minimizer can be found provided that it exists. In the unpublished notes of Gangbo, he also showed that if springs of the same kind are optimal.
  In this paper, we are going to solve the Plateau problem using two different tools in GMT: first, a minimizer can be viewed as a flat chain complex; second, a minimizer can also be viewed as a current. At the end, we are going to show one progress in discovering the topological properties of minimizers: compressed and stretched springs must be perpendicular to each other at non-boundary points.
  I appreciate my advisor Prof. Robert Hardt for communicating with me regularly on this problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17214v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengcheng Yang</dc:creator>
    </item>
    <item>
      <title>Slicing Unbalanced Optimal Transport</title>
      <link>https://arxiv.org/abs/2306.07176</link>
      <description>arXiv:2306.07176v2 Announce Type: replace-cross 
Abstract: Optimal transport (OT) is a powerful framework to compare probability measures, a fundamental task in many statistical and machine learning problems. Substantial advances have been made in designing OT variants which are either computationally and statistically more efficient or robust. Among them, sliced OT distances have been extensively used to mitigate optimal transport's cubic algorithmic complexity and curse of dimensionality. In parallel, unbalanced OT was designed to allow comparisons of more general positive measures, while being more robust to outliers. In this paper, we bridge the gap between those two concepts and develop a general framework for efficiently comparing positive measures. We notably formulate two different versions of sliced unbalanced OT, and study the associated topology and statistical properties. We then develop a GPU-friendly Frank-Wolfe like algorithm to compute the corresponding loss functions, and show that the resulting methodology is modular as it encompasses and extends prior related work. We finally conduct an empirical analysis of our loss functions and methodology on both synthetic and real datasets, to illustrate their computational efficiency, relevance and applicability to real-world scenarios including geophysical data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.07176v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cl\'ement Bonet, Kimia Nadjahi, Thibault S\'ejourn\'e, Kilian Fatras, Nicolas Courty</dc:creator>
    </item>
    <item>
      <title>Predictive and Prescriptive Analytics for Multi-Site Modeling of Frail and Elderly Patient Services</title>
      <link>https://arxiv.org/abs/2311.07283</link>
      <description>arXiv:2311.07283v2 Announce Type: replace-cross 
Abstract: Recent research has highlighted the potential of linking predictive and prescriptive analytics. However, it remains widely unexplored how both paradigms could benefit from one another to address today's major challenges in healthcare. One of these is smarter planning of resource capacities for frail and elderly inpatient wards, addressing the societal challenge of an aging population. Frail and elderly patients typically suffer from multimorbidity and require more care while receiving medical treatment. The aim of this research is to assess how various predictive and prescriptive analytical methods, both individually and in tandem, contribute to addressing the operational challenges within an area of healthcare that is growing in demand. Clinical and demographic patient attributes are gathered from more than 165,000 patient records and used to explain and predict length of stay. To that extent, we employ Classification and Regression Trees (CART) analysis to establish this relationship. On the prescriptive side, deterministic and two-stage stochastic programs are developed to determine how to optimally plan for beds and ward staff with the objective to minimize cost. Furthermore, the two analytical methodologies are linked by generating demand for the prescriptive models using the CART groupings. The results show the linked methodologies provided different but similar results compared to using averages and in doing so, captured a more realistic real-world variation in the patient length of stay. Our research reveals that healthcare managers should consider using predictive and prescriptive models to make more informed decisions. By combining predictive and prescriptive analytics, healthcare managers can move away from relying on averages and incorporate the unique characteristics of their patients to create more robust planning decisions, mitigating risks caused by variations in demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07283v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elizabeth Williams, Daniel Gartner, Paul Harper</dc:creator>
    </item>
    <item>
      <title>Momentum Does Not Reduce Stochastic Noise in Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2402.02325</link>
      <description>arXiv:2402.02325v4 Announce Type: replace-cross 
Abstract: For nonconvex objective functions, including those found in training deep neural networks, stochastic gradient descent (SGD) with momentum is said to converge faster and have better generalizability than SGD without momentum. In particular, adding momentum is thought to reduce stochastic noise. To verify this, we estimated the magnitude of gradient noise by using convergence analysis and an optimal batch size estimation formula and found that momentum does not reduce gradient noise. We also analyzed the effect of search direction noise, which is stochastic noise defined as the error between the search direction of the optimizer and the steepest descent direction, and found that it inherently smooths the objective function and that momentum does not reduce search direction noise either. Finally, an analysis of the degree of smoothing introduced by search direction noise revealed that adding momentum offers limited advantage to SGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02325v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naoki Sato, Hideaki Iiduka</dc:creator>
    </item>
    <item>
      <title>High dimensional analysis reveals conservative sharpening and a stochastic edge of stability</title>
      <link>https://arxiv.org/abs/2404.19261</link>
      <description>arXiv:2404.19261v2 Announce Type: replace-cross 
Abstract: Recent empirical and theoretical work has shown that the dynamics of the large eigenvalues of the training loss Hessian have some remarkably robust features across models and datasets in the full batch regime. There is often an early period of progressive sharpening where the large eigenvalues increase, followed by stabilization at a predictable value known as the edge of stability. Previous work showed that in the stochastic setting, the eigenvalues increase more slowly - a phenomenon we call conservative sharpening. We provide a theoretical analysis of a simple high-dimensional model which shows the origin of this slowdown. We also show that there is an alternative stochastic edge of stability which arises at small batch size that is sensitive to the trace of the Neural Tangent Kernel rather than the large Hessian eigenvalues. We conduct an experimental study which highlights the qualitative differences from the full batch phenomenology, and suggests that controlling the stochastic edge of stability can help optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19261v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>physics.data-an</category>
      <category>stat.TH</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Atish Agarwala, Jeffrey Pennington</dc:creator>
    </item>
    <item>
      <title>On the stability of gradient descent with second order dynamics for time-varying cost functions</title>
      <link>https://arxiv.org/abs/2405.13765</link>
      <description>arXiv:2405.13765v3 Announce Type: replace-cross 
Abstract: Gradient based optimization algorithms deployed in Machine Learning (ML) applications are often analyzed and compared by their convergence rates or regret bounds. While these rates and bounds convey valuable information they don't always directly translate to stability guarantees. Stability and similar concepts, like robustness, will become ever more important as we move towards deploying models in real-time and safety critical systems. In this work we build upon the results in Gaudio et al. 2021 and Moreu &amp; Annaswamy 2022 for gradient descent with second order dynamics when applied to explicitly time varying cost functions and provide more general stability guarantees. These more general results can aid in the design and certification of these optimization schemes so as to help ensure safe and reliable deployment for real-time learning applications. We also hope that the techniques provided here will stimulate and cross-fertilize the analysis that occurs on the same algorithms from the online learning and stochastic optimization communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13765v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research (2025).</arxiv:journal_reference>
      <dc:creator>Travis E. Gibson, Sawal Acharya, Anjali Parashar, Joseph E. Gaudio, Anurdha M. Annaswamy</dc:creator>
    </item>
    <item>
      <title>Gaussian Approximation and Multiplier Bootstrap for Polyak-Ruppert Averaged Linear Stochastic Approximation with Applications to TD Learning</title>
      <link>https://arxiv.org/abs/2405.16644</link>
      <description>arXiv:2405.16644v2 Announce Type: replace-cross 
Abstract: In this paper, we obtain the Berry-Esseen bound for multivariate normal approximation for the Polyak-Ruppert averaged iterates of the linear stochastic approximation (LSA) algorithm with decreasing step size. Moreover, we prove the non-asymptotic validity of the confidence intervals for parameter estimation with LSA based on multiplier bootstrap. This procedure updates the LSA estimate together with a set of randomly perturbed LSA estimates upon the arrival of subsequent observations. We illustrate our findings in the setting of temporal difference learning with linear function approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16644v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey Samsonov, Eric Moulines, Qi-Man Shao, Zhuo-Song Zhang, Alexey Naumov</dc:creator>
    </item>
    <item>
      <title>Prescribed exponential stabilization of scalar neutral differential equations: Application to neural control</title>
      <link>https://arxiv.org/abs/2406.13730</link>
      <description>arXiv:2406.13730v4 Announce Type: replace-cross 
Abstract: This paper presents a control-oriented delay-based modeling approach for the exponential stabilization of a scalar neutral functional differential equation, which is then applied to the local exponential stabilization of a one-layer neural network of Hopfield type with delayed feedback. The proposed approach utilizes a recently developed partial pole placement method for linear functional differential equations, leveraging the coexistence of real spectral values to explicitly prescribe the exponential decay of the closed-loop solution. While a delayed proportional (P) feedback control may achieve stabilization, it requires higher gains and only allows for a shorter maximum delay compared to the proportional-derivative (PD) feedback control presented in this work. The framework provides a practical illustration of the stabilization strategy, improving upon previous literature results that characterize the solution's exponential decay for simple real spectral values. This approach enhances neural stability in cases where the inherent dynamics are stable and offers a method to achieve local exponential stabilization with a prescribed decay rate when the inherent dynamics are unstable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13730v4</guid>
      <category>math.SP</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyprien Tamekue, Islam Boussaada, Karim Trabelsi</dc:creator>
    </item>
    <item>
      <title>Jacobian Descent for Multi-Objective Optimization</title>
      <link>https://arxiv.org/abs/2406.16232</link>
      <description>arXiv:2406.16232v3 Announce Type: replace-cross 
Abstract: Many optimization problems require balancing multiple conflicting objectives. As gradient descent is limited to single-objective optimization, we introduce its direct generalization: Jacobian descent (JD). This algorithm iteratively updates parameters using the Jacobian matrix of a vector-valued objective function, in which each row is the gradient of an individual objective. While several methods to combine gradients already exist in the literature, they are generally hindered when the objectives conflict. In contrast, we propose projecting gradients to fully resolve conflict while ensuring that they preserve an influence proportional to their norm. We prove significantly stronger convergence guarantees with this approach, supported by our empirical results. Our method also enables instance-wise risk minimization (IWRM), a novel learning paradigm in which the loss of each training example is considered a separate objective. Applied to simple image classification tasks, IWRM exhibits promising results compared to the direct minimization of the average loss. Additionally, we outline an efficient implementation of JD using the Gramian of the Jacobian matrix to reduce time and memory requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16232v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre Quinton, Val\'erian Rey</dc:creator>
    </item>
    <item>
      <title>Minimal work protocols for inertial particles in non-harmonic traps</title>
      <link>https://arxiv.org/abs/2407.15678</link>
      <description>arXiv:2407.15678v2 Announce Type: replace-cross 
Abstract: Progress in miniaturized technology allows us to control physical systems at nanoscale with remarkable precision. Experimental advancements have sparked interest in control problems in stochastic thermodynamics, typically concerning a time-dependent potential applied to a nanoparticle to reach a target stationary state in a given time with minimal energy cost. We study this problem for a particle subject to thermal fluctuations in a regime that takes into account the effects of inertia, and, building on the results of a previous work, provide a numerical method to find optimal controls even for non-Gaussian initial and final conditions, corresponding to non-harmonic confinements. The control protocol and the time-dependent position distribution are qualitatively different from the corresponding overdamped limit: in particular, a symmetry of the boundary conditions, which is preserved in the absence of inertia, turns out to be broken in the underdamped regime. We also show that the momentum mean tends to a constant value along the trajectory, except close to the boundary, while the evolution of the position mean and of the second moments is highly non-trivial. Our results also support that the lower bound on the optimal entropy production computed from the overdamped case is tight in the adiabatic limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15678v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Sanders, Marco Baldovin, Paolo Muratore-Ginanneschi</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Framework for Analyzing the Convergence of Adam: Bridging the Gap with SGD</title>
      <link>https://arxiv.org/abs/2410.04458</link>
      <description>arXiv:2410.04458v4 Announce Type: replace-cross 
Abstract: Adaptive Moment Estimation (Adam) is a cornerstone optimization algorithm in deep learning, widely recognized for its flexibility with adaptive learning rates and efficiency in handling large-scale data. However, despite its practical success, the theoretical understanding of Adam's convergence has been constrained by stringent assumptions, such as almost surely bounded stochastic gradients or uniformly bounded gradients, which are more restrictive than those typically required for analyzing stochastic gradient descent (SGD).
  In this paper, we introduce a novel and comprehensive framework for analyzing the convergence properties of Adam. This framework offers a versatile approach to establishing Adam's convergence. Specifically, we prove that Adam achieves asymptotic (last iterate sense) convergence in both the almost sure sense and the \(L_1\) sense under the relaxed assumptions typically used for SGD, namely \(L\)-smoothness and the ABC inequality. Meanwhile, under the same assumptions, we show that Adam attains non-asymptotic sample complexity bounds similar to those of SGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04458v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruinan Jin, Xiao Li, Yaoliang Yu, Baoxiang Wang</dc:creator>
    </item>
    <item>
      <title>Toward generalizable learning of all (linear) first-order methods via memory augmented Transformers</title>
      <link>https://arxiv.org/abs/2410.07263</link>
      <description>arXiv:2410.07263v3 Announce Type: replace-cross 
Abstract: We show that memory-augmented Transformers can implement the entire class of linear first-order methods (LFOMs), a class that contains gradient descent (GD) and more advanced methods such as conjugate gradient descent (CGD), momentum methods and all other variants that linearly combine past gradients. Building on prior work that studies how Transformers simulate GD, we provide theoretical and empirical evidence that memory-augmented Transformers can learn more advanced algorithms. We then take a first step toward turning the learned algorithms into actually usable methods by developing a mixture-of-experts (MoE) approach for test-time adaptation to out-of-distribution (OOD) samples. Lastly, we show that LFOMs can themselves be treated as learnable algorithms, whose parameters can be learned from data to attain strong performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07263v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanchayan Dutta (UC Davis), Suvrit Sra (TU Munich)</dc:creator>
    </item>
    <item>
      <title>Satellite Safe Margin: Fast solutions for Conjunction Analysis</title>
      <link>https://arxiv.org/abs/2410.24092</link>
      <description>arXiv:2410.24092v2 Announce Type: replace-cross 
Abstract: The amount of debris in orbit has increased significantly over the years. With the recent growth of interest in space exploration, conjunction assessment has become a central issue. One important metric to evaluate conjunction risk is the miss distance. However, this metric does not intrinsically take into account uncertainty distributions. Some work has been developed to consider the uncertainty associated with the position of the orbiting objects, in particular, to know if these uncertainty distributions overlap (e.g., ellipsoids when considering Gaussian distributions). With this work, we present fast solutions to not only check if the ellipsoids overlap but to compute the distance between them, which we call margin. We present two fast solution methods for two different paradigms: when the best-known data from both objects can be centralized (e.g., debris-satellite conjunctions) and when the most precise covariances cannot be shared (conjunctions of satellites owned by different operators). Our methods are both accurate and fast, being able to process 15,000 conjunctions per minute with the centralized solution and approximately 490 conjunctions per minute with the distributed solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24092v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ricardo N. Ferreira, Marta Guimar\~aes, Cl\'audia Soares</dc:creator>
    </item>
    <item>
      <title>Reducing the Large Set Threshold for Oertel's Conjecture on the Mixed-Integer Volume</title>
      <link>https://arxiv.org/abs/2411.11864</link>
      <description>arXiv:2411.11864v2 Announce Type: replace-cross 
Abstract: In 1960, Gr\"{u}nbaum proved that for any convex body $C\subset\mathbb{R}^d$ and every halfspace $H$ containing the centroid of $C$, one has that the volume of $H\cap C$ is at least a $\frac{1}{e}$-fraction of the volume of $C$. Recently, in 2014, Oertel conjectured that a similar result holds for mixed-integer convex sets. Concretely, he proposed that for any convex body $C\subset \mathbb{R}^{n+d}$, there should exist a point $\mathbf{x} \in S=C\cap(\mathbb{Z}^{n}\times\mathbb{R}^d)$ such that for every halfspace $H$ containing $\mathbf{x}$, one has that
  \[
  \mathcal{H}_d(H\cap S) \geq \frac{1}{2^n}\frac{1}{e}\mathcal{H}_d(S),
  \]
  where $\mathcal{H}_d$ denotes the $d$-dimensional Hausdorff measure. While the conjecture remains open, Basu and Oertel proved in 2017 that the above inequality holds true for sufficiently large sets, in terms of a measure known as the \emph{lattice width} of a set. In this work, by following a geometric approach, we improve this result by substantially reducing the threshold at which a set can be considered large. We reduce this threshold from an exponential to a polynomial dependency on the dimension, therefore significantly enlarging the family of mixed-integer convex sets over which Oertel's conjecture holds true.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11864v2</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andr\'es Cristi, David Salas</dc:creator>
    </item>
    <item>
      <title>Learning Provably Improves the Convergence of Gradient Descent</title>
      <link>https://arxiv.org/abs/2501.18092</link>
      <description>arXiv:2501.18092v2 Announce Type: replace-cross 
Abstract: As a specialized branch of deep learning, Learning to Optimize (L2O) tackles optimization problems by training DNN-based solvers. Despite achieving significant success in various scenarios, such as faster convergence in solving convex optimizations and improved optimality in addressing non-convex cases, there remains a deficiency in theoretical support. Current research heavily relies on stringent assumptions that do not align with the intricacies of the training process. To address this gap, our study aims to establish L2O's convergence through its training methodology. We demonstrate that learning an algorithm's hyperparameters significantly enhances its convergence. Focusing on the gradient descent (GD) algorithm for quadratic programming, we prove the convergence of L2O's training using the neural tangent kernel theory. Moreover, we conduct empirical evaluations using synthetic datasets. Our findings indicate exceeding 50\% outperformance over the GD methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18092v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 04 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qingyu Song, Wei Lin, Hong Xu</dc:creator>
    </item>
  </channel>
</rss>
