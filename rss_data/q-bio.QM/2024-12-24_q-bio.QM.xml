<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Dec 2024 02:35:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Cross-Attention Graph Neural Networks for Inferring Gene Regulatory Networks with Skewed Degree Distribution</title>
      <link>https://arxiv.org/abs/2412.16220</link>
      <description>arXiv:2412.16220v2 Announce Type: new 
Abstract: Inferencing Gene Regulatory Networks (GRNs) from gene expression data is a pivotal challenge in systems biology, and several innovative computational methods have been introduced. However, most of these studies have not considered the skewed degree distribution of genes. Specifically, some genes may regulate multiple target genes while some genes may be regulated by multiple regulator genes. Such a skewed degree distribution issue significantly complicates the application of directed graph embedding methods. To tackle this issue, we propose the Cross-Attention Complex Dual Graph Embedding Model (XATGRN). Our XATGRN employs a cross-attention mechanism to effectively capture intricate gene interactions from gene expression profiles. Additionally, it uses a Dual Complex Graph Embedding approach to manage the skewed degree distribution, thereby ensuring precise prediction of regulatory relationships and their directionality. Our model consistently outperforms existing state-of-the-art methods across various datasets, underscoring its efficacy in elucidating complex gene regulatory mechanisms. Our codes used in this paper are publicly available at: https://github.com/kikixiong/XATGRN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16220v2</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaqi Xiong, Nan Yin, Yifan Sun, Haoyang Li, Yingxu Wang, Duo Ai, Fang Pan, Shiyang Liang</dc:creator>
    </item>
    <item>
      <title>Homogenization of Ordinary Differential Equations for the Fast Prediction of Diabetes Progression</title>
      <link>https://arxiv.org/abs/2412.16261</link>
      <description>arXiv:2412.16261v1 Announce Type: new 
Abstract: The impact of physical activity on a person's progression to type 2 diabetes is multifaceted. Systems of ordinary differential equations have been crucial in simulating this progression. However, such models often operate on multiple timescales, making them computationally expensive when simulating long-term effects. To overcome this, we propose a homogenized version of a two-timescale model that captures the short- and long-term effects of physical activity on blood glucose regulation. By invoking the homogenized contribution of a physical activity session into the long-term effects, we reduce the full model from 12 to 7 state variables, while preserving its key dynamics. The homogenized model offers a computational speedup of over 1000 times, since a numerical solver can take time steps at the scale of the long-term effects. We prove that the error introduced by the homogenization is bounded over time and validate the theoretical findings through a simulation study. The significant reduction in computational time opens the door to apply the homogenized model in medical decision support systems. It supports the development of personalized physical activity plans that can effectively reduce the risk of developing type 2 diabetes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16261v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lea Multerer, Pierluigi Francesco De Paola, Marta Lenatti, Alessia Paglialonga, Laura Azzimonti</dc:creator>
    </item>
    <item>
      <title>VirusT5: Harnessing Large Language Models to Predicting SARS-CoV-2 Evolution</title>
      <link>https://arxiv.org/abs/2412.16262</link>
      <description>arXiv:2412.16262v1 Announce Type: new 
Abstract: During a virus's evolution,various regions of the genome are subjected to distinct levels of functional constraints.Combined with factors like codon bias and DNA repair efficiency,these constraints contribute to unique mutation patterns within the genome or a specific gene. In this project, we harnessed the power of Large Language Models(LLMs) to predict the evolution of SARS-CoV-2. By treating the mutation process from one generation to the next as a translation task, we trained a transformer model, called VirusT5, to capture the mutation patterns underlying SARS-CoV-2 evolution. We evaluated the VirusT5's ability to detect these mutation patterns including its ability to identify mutation hotspots and explored the potential of using VirusT5 to predict future virus variants. Our findings demonstrate the feasibility of using a large language model to model viral evolution as a translation process. This study establishes the groundbreaking concept of "mutation-as-translation," paving the way for new methodologies and tools for combating virus threats</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16262v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vishwajeet Marathe, Deewan Bajracharya, Changhui Yan</dc:creator>
    </item>
    <item>
      <title>SGAC: A Graph Neural Network Framework for Imbalanced and Structure-Aware AMP Classification</title>
      <link>https://arxiv.org/abs/2412.16276</link>
      <description>arXiv:2412.16276v1 Announce Type: new 
Abstract: Classifying antimicrobial peptides(AMPs) from the vast array of peptides mined from metagenomic sequencing data is a significant approach to addressing the issue of antibiotic resistance. However, current AMP classification methods, primarily relying on sequence-based data, neglect the spatial structure of peptides, thereby limiting the accurate classification of AMPs. Additionally, the number of known AMPs is significantly lower than that of non-AMPs, leading to imbalanced datasets that reduce predictive accuracy for AMPs. To alleviate these two limitations, we first employ Omegafold to predict the three-dimensional spatial structures of AMPs and non-AMPs, constructing peptide graphs based on the amino acids' C$_\alpha$ positions. Building upon this, we propose a novel classification model named Spatial GNN-based AMP Classifier (SGAC). Our SGAC model employs a graph encoder based on Graph Neural Networks (GNNs) to process peptide graphs, generating high-dimensional representations that capture essential features from the three-dimensional spatial structure of amino acids. Then, to address the inherent imbalanced datasets, SGAC first incorporates Weight-enhanced Contrastive Learning, which clusters similar peptides while ensuring separation between dissimilar ones, using weighted contributions to emphasize AMP-specific features. Furthermore, SGAC employs Weight-enhanced Pseudo-label Distillation to dynamically generate high-confidence pseudo labels for ambiguous peptides, further refining predictions and promoting balanced learning between AMPs and non-AMPs. Experiments on publicly available AMP and non-AMP datasets demonstrate that SGAC significantly outperforms traditional sequence-based methods and achieves state-of-the-art performance among graph-based models, validating its effectiveness in AMP classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16276v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingxu Wang, Victor Liang, Nan Yin, Siwei Liu, Eran Segal</dc:creator>
    </item>
    <item>
      <title>Stochastic Model of siRNA Endosomal Escape Mediated by Fusogenic Peptides in OVCAR-3</title>
      <link>https://arxiv.org/abs/2412.16309</link>
      <description>arXiv:2412.16309v1 Announce Type: new 
Abstract: Gene silencing via small interfering RNA (siRNA) represents a transformative tool in cancer therapy, offering specificity and reduced off-target effects compared to conventional treatments. A crucial step in siRNA-based therapies is endosomal escape, the release of siRNA from endosomes into the cytoplasm. Quantifying endosomal escape is challenging due to the dynamic nature of the process and limitations in imaging and analytical techniques. Traditional methods often rely on fluorescence intensity measurements or manual image processing, which are time-intensive and fail to capture continuous dynamics. This paper presents a novel computational framework that integrates automated image processing to analyze time-lapse fluorescent microscopy data of endosomal escape, hierarchical Bayesian inference, and stochastic simulations. Our method employs image segmentation techniques such as binary masks, Gaussian filters, and multichannel color quantification to extract precise spatial and temporal data from microscopy images. Using a hierarchical Bayesian approach, we estimate the parameters of a compartmental model that describes endosomal escape dynamics, accounting for variability over time. These parameters inform a Gillespie stochastic simulation algorithm, ensuring realistic simulations of siRNA release events over time. Our framework provides a scalable and reproducible method for quantifying endosomal escape. The model captures uncertainty and variability in parameter estimation, and endosomal escape dynamics. Additionally, synthetic data generation allows researchers to validate experimental findings and explore alternative conditions without extensive laboratory work. This integrated approach not only improves the accuracy of endosomal escape quantification but also provides predictive insights for optimizing siRNA delivery systems and advancing gene therapy research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16309v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nisha Yadav (School of Mathematical and Statistical Sciences, Clemson University), Jessica Boulos (Department of Bioengineering, Clemson University), Keisha Cook (School of Mathematical and Statistical Sciences, Clemson University), Angela Alexander-Bryant (Department of Bioengineering, Clemson University)</dc:creator>
    </item>
    <item>
      <title>A Classification Benchmark for Artificial Intelligence Detection of Laryngeal Cancer from Patient Speech</title>
      <link>https://arxiv.org/abs/2412.16267</link>
      <description>arXiv:2412.16267v1 Announce Type: cross 
Abstract: Cases of laryngeal cancer are predicted to rise significantly in the coming years. Current diagnostic pathways cause many patients to be incorrectly referred to urgent suspected cancer pathways, putting undue stress on both patients and the medical system.
  Artificial intelligence offers a promising solution by enabling non-invasive detection of laryngeal cancer from patient speech, which could help prioritise referrals more effectively and reduce inappropriate referrals of non-cancer patients. To realise this potential, open science is crucial. A major barrier in this field is the lack of open-source datasets and reproducible benchmarks, forcing researchers to start from scratch. Our work addresses this challenge by introducing a benchmark suite comprising 36 models trained and evaluated on open-source datasets. These models are accessible in a public repository, providing a foundation for future research. They evaluate three different algorithms and three audio feature sets, offering a comprehensive benchmarking framework. We propose standardised metrics and evaluation methodologies to ensure consistent and comparable results across future studies.
  The presented models include both audio-only inputs and multimodal inputs that incorporate demographic and symptom data, enabling their application to datasets with diverse patient information. By providing these benchmarks, future researchers can evaluate their datasets, refine the models, and use them as a foundation for more advanced approaches. This work aims to provide a baseline for establishing reproducible benchmarks, enabling researchers to compare new methods against these standards and ultimately advancing the development of AI tools for detecting laryngeal cancer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16267v1</guid>
      <category>cs.SD</category>
      <category>cs.LG</category>
      <category>eess.AS</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mary Paterson, James Moor, Luisa Cutillo</dc:creator>
    </item>
    <item>
      <title>Three mechanistically different variability and noise sources in the trial-to-trial fluctuations of responses to brain stimulation</title>
      <link>https://arxiv.org/abs/2412.16997</link>
      <description>arXiv:2412.16997v1 Announce Type: cross 
Abstract: Motor-evoked potentials (MEPs) are among the few directly observable responses to external brain stimulation and serve a variety of applications, often in the form of input-output (IO) curves. Previous statistical models with two variability sources inherently consider the small MEPs at the low-side plateau as part of the neural recruitment properties. However, recent studies demonstrated that small MEP responses under resting conditions are contaminated and over-shadowed by background noise of mostly technical quality, e.g., caused by the amplifier, and suggested that the neural recruitment curve should continue below this noise level. This work intends to separate physiological variability from background noise and improve the description of recruitment behaviour. We developed a triple-variability-source model around a logarithmic logistic function without a lower plateau and incorporated an additional source for background noise. Compared to models with two or fewer variability sources, our approach better described IO characteristics, evidenced by lower Bayesian Information Criterion scores across all subjects and pulse shapes. The model independently extracted hidden variability information across the stimulated neural system and isolated it from background noise, which led to an accurate estimation of the IO curve parameters. This new model offers a robust tool to analyse brain stimulation IO curves in clinical and experimental neuroscience and reduces the risk of spurious results from inappropriate statistical methods. The presented model together with the corresponding calibration method provides a more accurate representation of MEP responses and variability sources, advances our understanding of cortical excitability, and may improve the assessment of neuromodulation effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16997v1</guid>
      <category>q-bio.NC</category>
      <category>eess.SP</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ke Ma, Siwei Liu, Mengjie Qin, Stefan Goetz</dc:creator>
    </item>
    <item>
      <title>A CNN Approach to Polygenic Risk Prediction of Kidney Stone Formation</title>
      <link>https://arxiv.org/abs/2412.17559</link>
      <description>arXiv:2412.17559v1 Announce Type: cross 
Abstract: Kidney stones are a common and debilitating health issue, and genetic factors play a crucial role in determining susceptibility. While Genome-Wide Association Studies (GWAS) have identified numerous single nucleotide polymorphisms (SNPs) linked to kidney stone risk, translating these findings into effective clinical tools remains a challenge. In this study, we explore the potential of deep learning techniques, particularly Convolutional Neural Networks (CNNs), to enhance Polygenic Risk Score (PRS) models for predicting kidney stone susceptibility. Using a curated dataset of kidney stone-associated SNPs from a recent GWAS, we apply CNNs to model non-linear genetic interactions and improve prediction accuracy. Our approach includes SNP selection, genotype filtering, and model training using a dataset of 560 individuals, divided into training and testing subsets. We compare our CNN-based model with traditional machine learning models, including logistic regression, random forest, and support vector machines, demonstrating that the CNN outperforms these models in terms of classification accuracy and ROC-AUC. The proposed model achieved a validation accuracy of 62%, with an ROC-AUC of 0.68, suggesting its potential for improving genetic-based risk prediction for kidney stones. This study contributes to the growing field of genomics-driven precision medicine and highlights the promise of deep learning in enhancing PRS models for complex diseases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17559v1</guid>
      <category>q-bio.GN</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amr Salem, Anirban Mondal</dc:creator>
    </item>
    <item>
      <title>TSEML: A task-specific embedding-based method for few-shot classification of cancer molecular subtypes</title>
      <link>https://arxiv.org/abs/2412.13228</link>
      <description>arXiv:2412.13228v2 Announce Type: replace 
Abstract: Molecular subtyping of cancer is recognized as a critical and challenging upstream task for personalized therapy. Existing deep learning methods have achieved significant performance in this domain when abundant data samples are available. However, the acquisition of densely labeled samples for cancer molecular subtypes remains a significant challenge for conventional data-intensive deep learning approaches. In this work, we focus on the few-shot molecular subtype prediction problem in heterogeneous and small cancer datasets, aiming to enhance precise diagnosis and personalized treatment. We first construct a new few-shot dataset for cancer molecular subtype classification and auxiliary cancer classification, named TCGA Few-Shot, from existing publicly available datasets. To effectively leverage the relevant knowledge from both tasks, we introduce a task-specific embedding-based meta-learning framework (TSEML). TSEML leverages the synergistic strengths of a model-agnostic meta-learning (MAML) approach and a prototypical network (ProtoNet) to capture diverse and fine-grained features. Comparative experiments conducted on the TCGA Few-Shot dataset demonstrate that our TSEML framework achieves superior performance in addressing the problem of few-shot molecular subtype classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13228v2</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>BIBM 2024</arxiv:journal_reference>
      <dc:creator>Ran Su, Rui Shi, Hui Cui, Ping Xuan, Chengyan Fang, Xikang Feng, Qiangguo Jin</dc:creator>
    </item>
    <item>
      <title>waveOrder: generalist framework for label-agnostic computational microscopy</title>
      <link>https://arxiv.org/abs/2412.09775</link>
      <description>arXiv:2412.09775v2 Announce Type: replace-cross 
Abstract: Correlative computational microscopy is accelerating the mapping of dynamic biological systems by integrating morphological and molecular measurements across spatial scales, from organelles to entire organisms. Visualization, measurement, and prediction of interactions among the components of biological systems can be accelerated by generalist computational imaging frameworks that relax the trade-offs imposed by multiplex dynamic imaging. This work reports a generalist framework for wave optical imaging of the architectural order (waveOrder) among biomolecules for encoding and decoding multiple specimen properties from a minimal set of acquired channels, with or without fluorescent labels. waveOrder expresses material properties in terms of elegant physically motivated basis vectors directly interpretable as phase, absorption, birefringence, diattenuation, and fluorophore density; and it expresses image data in terms of directly measurable Stokes parameters. We report a corresponding multi-channel reconstruction algorithm to recover specimen properties in multiple contrast modes. With this framework, we implement multiple 3D computational microscopy methods, including quantitative phase imaging, quantitative label-free imaging with phase and polarization, and fluorescence deconvolution imaging, across scales ranging from organelles to whole zebrafish. These advances are available via an extensible open-source computational imaging library, waveOrder, and a napari plugin, recOrder.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09775v2</guid>
      <category>physics.optics</category>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Talon Chandler, Eduardo Hirata-Miyasaki, Ivan E. Ivanov, Ziwen Liu, Deepika Sundarraman, Allyson Quinn Ryan, Adrian Jacobo, Keir Balla, Shalin B. Mehta</dc:creator>
    </item>
  </channel>
</rss>
