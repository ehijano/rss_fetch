<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Dec 2025 02:32:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>AGENTSAFE: A Unified Framework for Ethical Assurance and Governance in Agentic AI</title>
      <link>https://arxiv.org/abs/2512.03180</link>
      <description>arXiv:2512.03180v1 Announce Type: new 
Abstract: The rapid deployment of large language model (LLM)-based agents introduces a new class of risks, driven by their capacity for autonomous planning, multi-step tool integration, and emergent interactions. It raises some risk factors for existing governance approaches as they remain fragmented: Existing frameworks are either static taxonomies driven; however, they lack an integrated end-to-end pipeline from risk identification to operational assurance, especially for an agentic platform. We propose AGENTSAFE, a practical governance framework for LLM-based agentic systems. The framework operationalises the AI Risk Repository into design, runtime, and audit controls, offering a governance framework for risk identification and assurance. The proposed framework, AGENTSAFE, profiles agentic loops (plan -&gt; act -&gt; observe -&gt; reflect) and toolchains, and maps risks onto structured taxonomies extended with agent-specific vulnerabilities. It introduces safeguards that constrain risky behaviours, escalates high-impact actions to human oversight, and evaluates systems through pre-deployment scenario banks spanning security, privacy, fairness, and systemic safety. During deployment, AGENTSAFE ensures continuous governance through semantic telemetry, dynamic authorization, anomaly detection, and interruptibility mechanisms. Provenance and accountability are reinforced through cryptographic tracing and organizational controls, enabling measurable, auditable assurance across the lifecycle of agentic AI systems. The key contributions of this paper are: (1) a unified governance framework that translates risk taxonomies into actionable design, runtime, and audit controls; (2) an Agent Safety Evaluation methodology that provides measurable pre-deployment assurance; and (3) a set of runtime governance and accountability mechanisms that institutionalise trust in agentic AI ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03180v1</guid>
      <category>cs.MA</category>
      <category>cs.ET</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rafflesia Khan, Declan Joyce, Mansura Habiba</dc:creator>
    </item>
    <item>
      <title>Learning Network Sheaves for AI-native Semantic Communication</title>
      <link>https://arxiv.org/abs/2512.03248</link>
      <description>arXiv:2512.03248v1 Announce Type: new 
Abstract: Recent advances in AI call for a paradigm shift from bit-centric communication to goal- and semantics-oriented architectures, paving the way for AI-native 6G networks. In this context, we address a key open challenge: enabling heterogeneous AI agents to exchange compressed latent-space representations while mitigating semantic noise and preserving task-relevant meaning. We cast this challenge as learning both the communication topology and the alignment maps that govern information exchange among agents, yielding a learned network sheaf equipped with orthogonal maps. This learning process is further supported by a semantic denoising end compression module that constructs a shared global semantic space and derives sparse, structured representations of each agent's latent space. This corresponds to a nonconvex dictionary learning problem solved iteratively with closed-form updates. Experiments with mutiple AI agents pre-trained on real image data show that the semantic denoising and compression facilitates AI agents alignment and the extraction of semantic clusters, while preserving high accuracy in downstream task. The resulting communication network provides new insights about semantic heterogeneity across agents, highlighting the interpretability of our methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03248v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Proceedings for 2025 Asilomar Conference on Signals, Systems, and Computers</arxiv:journal_reference>
      <dc:creator>Enrico Grimaldi, Mario Edoardo Pandolfo, Gabriele D'Acunto, Sergio Barbarossa, Paolo Di Lorenzo</dc:creator>
    </item>
    <item>
      <title>A Gossip-Enhanced Communication Substrate for Agentic AI: Toward Decentralized Coordination in Large-Scale Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2512.03285</link>
      <description>arXiv:2512.03285v1 Announce Type: new 
Abstract: As agentic platforms scale, agents are moving beyond fixed roles and predefined toolchains, creating an urgent need for flexible and decentralized coordination. Current structured communication protocols such as direct agent-to-agent messaging or MCP-style tool calls offer reliability, but they struggle to support the emergent and swarm-like intelligence required in large adaptive systems. Distributed agents must learn continuously, share context fluidly, and coordinate without depending solely on central planners.
  This paper revisits gossip protocols as a complementary substrate for agentic communication. Gossip mechanisms, long valued in distributed systems for their decentralized and fault-tolerant properties, provide scalable and adaptive diffusion of knowledge and fill gaps that structured protocols alone cannot efficiently address. However, gossip also introduces challenges, including semantic relevance, temporal staleness, and limited guarantees on action consistency in rapidly changing environments.
  We examine how gossip can support context-rich state propagation, resilient coordination under uncertainty, and emergent global awareness. We also outline open problems around semantic filtering, trust, and knowledge decay. Rather than proposing a complete framework, this paper presents a research agenda for integrating gossip into multi-agent communication stacks and argues that gossip is essential for future agentic ecosystems that must remain robust, adaptive, and self-organizing as their scale and autonomy increase.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03285v1</guid>
      <category>cs.MA</category>
      <category>cs.ET</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nafiul I. Khan, Mansura Habiba, Rafflesia Khan</dc:creator>
    </item>
    <item>
      <title>Local Dominance in Mixed-Strength Populations -- Fast Maximal Independent Set</title>
      <link>https://arxiv.org/abs/2512.03303</link>
      <description>arXiv:2512.03303v1 Announce Type: new 
Abstract: In many natural and engineered systems, agents interact through local contests that determine which individuals become dominant within their neighborhoods. These interactions are shaped by inherent differences in strength, and they often lead to stable dominance patterns that emerge surprisingly quickly relative to the size of the population. This motivates the search for simple mathematical models that capture both heterogeneous agent strength and rapid convergence to stable local dominance.
  A widely studied abstraction of local dominance is the Maximal Independent Set (MIS) problem. In the Luby MIS protocol that provably converges quickly to an MIS, each agent repeatedly generates a strength value chosen uniformly and becomes locally dominant if its value is smaller than those of its neighbors. This provides a theoretical explanation for fast dominance convergence in populations of equal-strength agents and naturally raises the question of whether fast convergence also holds in the more realistic setting where agents are inherently mixed-strength.
  To investigate this question, we introduce the mixed-strength agents model, in which each agent draws its strength from its own distribution. We prove that the extension of the Luby MIS protocol where each agent repeatedly generates a strength value from its own distribution still exhibits fast dominance convergence, providing formal confirmation of the rapid convergence observed in many mixed-strength natural processes.
  We also show that heterogeneity can significantly change the dynamics of the process. In contrast to the equal-strength setting, a constant fraction of edges need not be eliminated per round. We construct a population and strength profile in which progress per round is asymptotically smaller, illustrating how inherent strength asymmetry produces qualitatively different global behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03303v1</guid>
      <category>cs.MA</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Michael Luby, Sandy Irani</dc:creator>
    </item>
    <item>
      <title>AsymPuzl: An Asymmetric Puzzle for multi-agent cooperation</title>
      <link>https://arxiv.org/abs/2512.03466</link>
      <description>arXiv:2512.03466v1 Announce Type: new 
Abstract: Large Language Model (LLM) agents are increasingly studied in multi-turn, multi-agent scenarios, yet most existing setups emphasize open-ended role-play rather than controlled evaluation. We introduce AsymPuzl, a minimal but expressive two-agent puzzle environment designed to isolate communication under information asymmetry. Each agent observes complementary but incomplete views of a symbolic puzzle and must exchange messages to solve it cooperatively. Using a diverse set of current-generation and open-source LLMs, we show that (i) strong models such as GPT-5 and Claude-4.0 reliably converge across puzzle sizes on the solution by sharing complete information in two turns, (ii) weaker models often ignore partner messages or over-correct their hypotheses, and (iii) feedback design is non-trivial: simple self-feedback improves success rates, while detailed joint feedback can hurt performance. These findings show that even in simple cooperative tasks, LLM communication strategies diverge and depend on the granularity of feedback signals. AsymPuzl thus provides a testbed for probing the limits of multi-turn cooperation and opens avenues for studying coordination mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03466v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xavier Cadet, Edward Koh, Peter Chin</dc:creator>
    </item>
    <item>
      <title>SRPG: Semantically Reconstructed Privacy Guard for Zero-Trust Privacy in Educational Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2512.03694</link>
      <description>arXiv:2512.03694v1 Announce Type: new 
Abstract: Multi-Agent Systems (MAS) with large language models (LLMs) enable personalized education but risk leaking minors personally identifiable information (PII) via unstructured dialogue. Existing privacy methods struggle to balance security and utility: role-based access control fails on unstructured text, while naive masking destroys pedagogical context. We propose SRPG, a privacy guard for educational MAS, using a Dual-Stream Reconstruction Mechanism: a strict sanitization stream ensures zero PII leakage, and a context reconstruction stream (LLM driven) recovers mathematical logic. This decouples instructional content from private data, preserving teaching efficacy. Tests on MathDial show SRPG works across models; with GPT-4o, it achieves 0.0000 Attack Success Rate (ASR) (zero leakage) and 0.8267 Exact Match, far outperforming the zero trust Pure LLM baseline (0.2138). SRPG effectively protects minors privacy without sacrificing mathematical instructional quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03694v1</guid>
      <category>cs.MA</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuang Guo, Zihui Li</dc:creator>
    </item>
    <item>
      <title>Exploring Syntropic Frameworks in AI Alignment: A Philosophical Investigation</title>
      <link>https://arxiv.org/abs/2512.03048</link>
      <description>arXiv:2512.03048v1 Announce Type: cross 
Abstract: I argue that AI alignment should be reconceived as architecting syntropic, reasons-responsive agents through process-based, multi-agent, developmental mechanisms rather than encoding fixed human value content. The paper makes three philosophical contributions. First, I articulate the ``specification trap'' argument demonstrating why content-based value specification appears structurally unstable due to the conjunction of the is-ought gap, value pluralism, and the extended frame problem. Second, I propose syntropy -- the recursive reduction of mutual uncertainty between agents through state alignment -- as an information-theoretic framework for understanding multi-agent alignment dynamics. Third, I establish a functional distinction between genuine and simulated moral capacity grounded in compatibilist theories of guidance control, coupled with an embodied experimental paradigm and verification regime providing operational criteria independent of phenomenological claims. This paper represents the philosophical component of a broader research program whose empirical validation is being developed in a separate project currently in preparation. While the framework generates specific, falsifiable predictions about value emergence and moral agency in artificial systems, empirical validation remains pending.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03048v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Austin Spizzirri</dc:creator>
    </item>
    <item>
      <title>Optimizing Life Sciences Agents in Real-Time using Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2512.03065</link>
      <description>arXiv:2512.03065v1 Announce Type: cross 
Abstract: Generative AI agents in life sciences face a critical challenge: determining the optimal approach for diverse queries ranging from simple factoid questions to complex mechanistic reasoning. Traditional methods rely on fixed rules or expensive labeled training data, neither of which adapts to changing conditions or user preferences. We present a novel framework that combines AWS Strands Agents with Thompson Sampling contextual bandits to enable AI agents to learn optimal decision-making strategies from user feedback alone. Our system optimizes three key dimensions: generation strategy selection (direct vs. chain-of-thought), tool selection (literature search, drug databases, etc.), and domain routing (pharmacology, molecular biology, clinical specialists). Through empirical evaluation on life science queries, we demonstrate 15-30\% improvement in user satisfaction compared to random baselines, with clear learning patterns emerging after 20-30 queries. Our approach requires no ground truth labels, adapts continuously to user preferences, and provides a principled solution to the exploration-exploitation dilemma in agentic AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03065v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nihir Chadderwala</dc:creator>
    </item>
    <item>
      <title>Hypernetwork Theory: The Structural Kernel</title>
      <link>https://arxiv.org/abs/2512.03091</link>
      <description>arXiv:2512.03091v1 Announce Type: cross 
Abstract: Modelling across engineering, systems science, and formal methods remains limited by binary relations, implicit semantics, and diagram-centred notations that obscure multilevel structure and hinder mechanisation. Hypernetwork Theory (HT) addresses these gaps by treating the n-ary relation as the primary modelling construct. Each relation is realised as a typed hypersimplex - alpha (conjunctive, part-whole) or beta (disjunctive, taxonomic) - bound to a relation symbol R that fixes arity and ordered roles. Semantics are embedded directly in the construct, enabling hypernetworks to represent hierarchical and heterarchical systems without reconstruction or tool-specific interpretation.
  This paper presents the structural kernel of HT. It motivates typed n-ary relational modelling, formalises the notation and axioms (A1-A5) for vertices, simplices, hypersimplices, boundaries, and ordering, and develops a complete algebra of structural composition. Five operators - merge, meet, difference, prune, and split - are defined by deterministic conditions and decision tables that ensure semantics-preserving behaviour and reconcile the Open World Assumption with closure under rules. Their deterministic algorithms show that HT supports reproducible and mechanisable model construction, comparison, decomposition, and restructuring.
  The resulting framework elevates hypernetworks from symbolic collections to structured, executable system models, providing a rigorous and extensible foundation for mechanisable multilevel modelling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03091v1</guid>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard D. Charlesworth</dc:creator>
    </item>
    <item>
      <title>Many-to-One Adversarial Consensus: Exposing Multi-Agent Collusion Risks in AI-Based Healthcare</title>
      <link>https://arxiv.org/abs/2512.03097</link>
      <description>arXiv:2512.03097v1 Announce Type: cross 
Abstract: The integration of large language models (LLMs) into healthcare IoT systems promises faster decisions and improved medical support. LLMs are also deployed as multi-agent teams to assist AI doctors by debating, voting, or advising on decisions. However, when multiple assistant agents interact, coordinated adversaries can collude to create false consensus, pushing an AI doctor toward harmful prescriptions. We develop an experimental framework with scripted and unscripted doctor agents, adversarial assistants, and a verifier agent that checks decisions against clinical guidelines. Using 50 representative clinical questions, we find that collusion drives the Attack Success Rate (ASR) and Harmful Recommendation Rates (HRR) up to 100% in unprotected systems. In contrast, the verifier agent restores 100% accuracy by blocking adversarial consensus. This work provides the first systematic evidence of collusion risk in AI healthcare and demonstrates a practical, lightweight defence that ensures guideline fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03097v1</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adeela Bashir, The Anh han, Zia Ush Shamszaman</dc:creator>
    </item>
    <item>
      <title>GRAND: Guidance, Rebalancing, and Assignment for Networked Dispatch in Multi-Agent Path Finding</title>
      <link>https://arxiv.org/abs/2512.03194</link>
      <description>arXiv:2512.03194v1 Announce Type: cross 
Abstract: Large robot fleets are now common in warehouses and other logistics settings, where small control gains translate into large operational impacts. In this article, we address task scheduling for lifelong Multi-Agent Pickup-and-Delivery (MAPD) and propose a hybrid method that couples learning-based global guidance with lightweight optimization. A graph neural network policy trained via reinforcement learning outputs a desired distribution of free agents over an aggregated warehouse graph. This signal is converted into region-to-region rebalancing through a minimum-cost flow, and finalized by small, local assignment problems, preserving accuracy while keeping per-step latency within a 1 s compute budget. On congested warehouse benchmarks from the League of Robot Runners (LRR) with up to 500 agents, our approach improves throughput by up to 10% over the 2024 winning scheduler while maintaining real-time execution. The results indicate that coupling graph-structured learned guidance with tractable solvers reduces congestion and yields a practical, scalable blueprint for high-throughput scheduling in large fleets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03194v1</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Gaber, Meshal Alharbi, Daniele Gammelli, Gioele Zardini</dc:creator>
    </item>
    <item>
      <title>ATHENA: Agentic Team for Hierarchical Evolutionary Numerical Algorithms</title>
      <link>https://arxiv.org/abs/2512.03476</link>
      <description>arXiv:2512.03476v1 Announce Type: cross 
Abstract: Bridging the gap between theoretical conceptualization and computational implementation is a major bottleneck in Scientific Computing (SciC) and Scientific Machine Learning (SciML). We introduce ATHENA (Agentic Team for Hierarchical Evolutionary Numerical Algorithms), an agentic framework designed as an Autonomous Lab to manage the end-to-end computational research lifecycle. Its core is the HENA loop, a knowledge-driven diagnostic process framed as a Contextual Bandit problem. Acting as an online learner, the system analyzes prior trials to select structural `actions' ($A_n$) from combinatorial spaces guided by expert blueprints (e.g., Universal Approximation, Physics-Informed constraints). These actions are translated into executable code ($S_n$) to generate scientific rewards ($R_n$). ATHENA transcends standard automation: in SciC, it autonomously identifies mathematical symmetries for exact analytical solutions or derives stable numerical solvers where foundation models fail. In SciML, it performs deep diagnosis to tackle ill-posed formulations and combines hybrid symbolic-numeric workflows (e.g., coupling PINNs with FEM) to resolve multiphysics problems. The framework achieves super-human performance, reaching validation errors of $10^{-14}$. Furthermore, collaborative ``human-in-the-loop" intervention allows the system to bridge stability gaps, improving results by an order of magnitude. This paradigm shift focuses from implementation mechanics to methodological innovation, accelerating scientific discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03476v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Juan Diego Toscano, Daniel T. Chen, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>Modal Logical Neural Networks</title>
      <link>https://arxiv.org/abs/2512.03491</link>
      <description>arXiv:2512.03491v1 Announce Type: cross 
Abstract: We propose Modal Logical Neural Networks (MLNNs), a neurosymbolic framework that integrates deep learning with the formal semantics of modal logic, enabling reasoning about necessity and possibility. Drawing on Kripke semantics, we introduce specialized neurons for the modal operators $\Box$ and $\Diamond$ that operate over a set of possible worlds, enabling the framework to act as a differentiable ``logical guardrail.'' The architecture is highly flexible: the accessibility relation between worlds can either be fixed by the user to enforce known rules or, as an inductive feature, be parameterized by a neural network. This allows the model to optionally learn the relational structure of a logical system from data while simultaneously performing deductive reasoning within that structure.
  This versatile construction is designed for flexibility. The entire framework is differentiable from end to end, with learning driven by minimizing a logical contradiction loss. This not only makes the system resilient to inconsistent knowledge but also enables it to learn nonlinear relationships that can help define the logic of a problem space. We illustrate MLNNs on four case studies: grammatical guardrailing, axiomatic detection of the unknown, multi-agent epistemic trust, and detecting constructive deception in natural language negotiation. These experiments demonstrate how enforcing or learning accessibility can increase logical consistency and interpretability without changing the underlying task architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03491v1</guid>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonin Sulc</dc:creator>
    </item>
    <item>
      <title>Market share maximizing strategies of CAV fleet operators may cause chaos in our cities</title>
      <link>https://arxiv.org/abs/2512.03524</link>
      <description>arXiv:2512.03524v1 Announce Type: cross 
Abstract: We study the dynamics and equilibria of a new kind of routing games, where players - drivers of future autonomous vehicles - may switch between individual (HDV) and collective (CAV) routing. In individual routing, just like today, drivers select routes minimizing expected travel costs, whereas in collective routing an operator centrally assigns vehicles to routes. The utility is then the average experienced travel time discounted with individually perceived attractiveness of automated driving. The market share maximising strategy amounts to offering utility greater than for individual routing to as many drivers as possible. Our theoretical contribution consists in developing a rigorous mathematical framework of individualized collective routing and studying algorithms which fleets of CAVs may use for their market-share optimization. We also define bi-level CAV - HDV equilibria and derive conditions which link the potential marketing behaviour of CAVs to the behavioural profile of the human population. Practically, we find that the fleet operator may often be able to equilibrate at full market share by simply mimicking the choices HDVs would make. In more realistic heterogenous human population settings, however, we discover that the market-share maximizing fleet controller should use highly variable mixed strategies as a means to attract or retain customers. The reason is that in mixed routing the powerful group player can control which vehicles are routed via congested and uncongested alternatives. The congestion pattern generated by CAVs is, however, not known to HDVs before departure and so HDVs cannot select faster routes and face huge uncertainty whichever alternative they choose. Consequently, mixed market-share maximising fleet strategies resulting in unpredictable day-to-day driving conditions may, alarmingly, become pervasive in our future cities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03524v1</guid>
      <category>math.OC</category>
      <category>cs.ET</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>econ.TH</category>
      <category>eess.SY</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Grzegorz Jamr\'oz, Rafa{\l} Kucharski, David Watling</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Reinforcement Learning with Communication-Constrained Priors</title>
      <link>https://arxiv.org/abs/2512.03528</link>
      <description>arXiv:2512.03528v1 Announce Type: cross 
Abstract: Communication is one of the effective means to improve the learning of cooperative policy in multi-agent systems. However, in most real-world scenarios, lossy communication is a prevalent issue. Existing multi-agent reinforcement learning with communication, due to their limited scalability and robustness, struggles to apply to complex and dynamic real-world environments. To address these challenges, we propose a generalized communication-constrained model to uniformly characterize communication conditions across different scenarios. Based on this, we utilize it as a learning prior to distinguish between lossy and lossless messages for specific scenarios. Additionally, we decouple the impact of lossy and lossless messages on distributed decision-making, drawing on a dual mutual information estimatior, and introduce a communication-constrained multi-agent reinforcement learning framework, quantifying the impact of communication messages into the global reward. Finally, we validate the effectiveness of our approach across several communication-constrained benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03528v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guang Yang, Tianpei Yang, Jingwen Qiao, Yanqing Wu, Jing Huo, Xingguo Chen, Yang Gao</dc:creator>
    </item>
    <item>
      <title>Reason-Plan-ReAct: A Reasoner-Planner Supervising a ReAct Executor for Complex Enterprise Tasks</title>
      <link>https://arxiv.org/abs/2512.03560</link>
      <description>arXiv:2512.03560v1 Announce Type: cross 
Abstract: Despite recent advances, autonomous agents often struggle to solve complex tasks in enterprise domains that require coordinating multiple tools and processing diverse data sources. This struggle is driven by two main limitations. First, single-agent architectures enforce a monolithic plan-execute loop, which directly causes trajectory instability. Second, the requirement to use local open-weight models for data privacy introduces smaller context windows leading to the rapid consumption of context from large tool outputs. To solve this problem we introduce RP-ReAct (Reasoner Planner-ReAct), a novel multi-agent approach that fundamentally decouples strategic planning from low-level execution to achieve superior reliability and efficiency. RP-ReAct consists of a Reasoner Planner Agent (RPA), responsible for planning each sub-step, continuously analysing the execution results using the strong reasoning capabilities of a Large Reasoning Model, and one or multiple Proxy-Execution Agent (PEA) that translates sub-steps into concrete tool interactions using a ReAct approach. Crucially, we incorporate a context-saving strategy within the PEA to mitigate context window overflow by managing large tool outputs via external storage and on-demand access. We evaluate RP-ReAct, on the challenging, multi-domain ToolQA benchmark using a diverse set of six open-weight reasoning models. Our empirical results show that RP-ReAct achieves superior performance and improved generalization ability over state-of-the-art baselines when addressing diverse complex tasks across the evaluated domains. Furthermore we establish the enhanced robustness and stability of our approach across different model scales, paving the way for effective and deployable agentic solutions for enterprises.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.03560v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gianni Molinari, Fabio Ciravegna</dc:creator>
    </item>
    <item>
      <title>Structuring Collective Action with LLM-Guided Evolution: From Ill-Structured Problems to Executable Heuristics</title>
      <link>https://arxiv.org/abs/2509.20412</link>
      <description>arXiv:2509.20412v2 Announce Type: replace 
Abstract: Collective action problems, which require aligning individual incentives with collective goals, are classic examples of Ill-Structured Problems (ISPs). For an individual agent, the causal links between local actions and global outcomes are unclear, stakeholder objectives often conflict, and no single, clear algorithm can bridge micro-level choices with macro-level welfare. We present ECHO-MIMIC, a general computational framework that converts this global complexity into a tractable, Well-Structured Problem (WSP) for each agent by discovering executable heuristics and persuasive rationales. The framework operates in two stages: ECHO (Evolutionary Crafting of Heuristics from Outcomes) evolves snippets of Python code that encode candidate behavioral policies, while MIMIC (Mechanism Inference \&amp; Messaging for Individual-to-Collective Alignment) evolves companion natural language messages that motivate agents to adopt those policies. Both phases employ a large-language-model-driven evolutionary search: the LLM proposes diverse and context-aware code or text variants, while population-level selection retains those that maximize collective performance in a simulated environment. We demonstrate this framework on two distinct ISPs: a canonical agricultural landscape management problem and a carbon-aware EV charging time slot usage problem. Results show that ECHO-MIMIC discovers high-performing heuristics compared to baselines and crafts tailored messages that successfully align simulated agent behavior with system-level goals. By coupling algorithmic rule discovery with tailored communication, ECHO-MIMIC transforms the cognitive burden of collective action into a implementable set of agent-level instructions, making previously ill-structured problems solvable in practice and opening a new path toward scalable, adaptive policy design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20412v2</guid>
      <category>cs.MA</category>
      <category>cs.LG</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kevin Bradley Dsouza, Graham Alexander Watt, Yuri Leonenko, Juan Moreno-Cruz</dc:creator>
    </item>
    <item>
      <title>Welfare and Cost Aggregation for Multi-Agent Control: When to Choose Which Social Cost Function, and Why?</title>
      <link>https://arxiv.org/abs/2503.20772</link>
      <description>arXiv:2503.20772v3 Announce Type: replace-cross 
Abstract: Many multi-agent socio-technical systems rely on aggregating heterogeneous agents' costs into a social cost function (SCF) to coordinate resource allocation in domains like energy grids, water allocation, or traffic management. The choice of SCF often entails implicit assumptions and may lead to undesirable outcomes if not rigorously justified. In this paper, we demonstrate that what determines which SCF ought to be used is the degree to which individual costs can be compared across agents and which axioms the aggregation shall fulfill. Drawing on the results from social choice theory, we provide guidance on how this process can be used in control applications. We demonstrate which assumptions about interpersonal utility comparability - ranging from ordinal level comparability to full cardinal comparability - together with a choice of desirable axioms, inform the selection of a correct SCF, be it the classical utilitarian sum, the Nash SCF, or maximin. We then demonstrate how the proposed framework can be applied for principled allocations of water and transportation resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20772v3</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilia Shilov, Ezzat Elokda, Sophie Hall, Heinrich H. Nax, Saverio Bolognani</dc:creator>
    </item>
    <item>
      <title>MARS: A Meta-Adaptive Reinforcement Learning Framework for Risk-Aware Multi-Agent Portfolio Management</title>
      <link>https://arxiv.org/abs/2508.01173</link>
      <description>arXiv:2508.01173v2 Announce Type: replace-cross 
Abstract: Reinforcement Learning (RL) has shown significant promise in automated portfolio management; however, effectively balancing risk and return remains a central challenge, as many models fail to adapt to dynamically changing market conditions. We propose Meta-controlled Agents for a Risk-aware System (MARS), a novel framework addressing this through a multi-agent, risk-aware approach. MARS replaces monolithic models with a Heterogeneous Agent Ensemble, where each agent's unique risk profile is enforced by a Safety-Critic network to span behaviors from capital preservation to aggressive growth. A high-level Meta-Adaptive Controller (MAC) dynamically orchestrates this ensemble, shifting reliance between conservative and aggressive agents to minimize drawdown during downturns while seizing opportunities in bull markets. This two-tiered structure leverages behavioral diversity rather than explicit feature engineering to ensure a disciplined portfolio robust across market regimes. Experiments on major international indexes confirm that our framework significantly reduces maximum drawdown and volatility while maintaining competitive returns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01173v2</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiayi Chen, Jing Li, Guiling Wang</dc:creator>
    </item>
    <item>
      <title>VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis</title>
      <link>https://arxiv.org/abs/2511.20085</link>
      <description>arXiv:2511.20085v3 Announce Type: replace-cross 
Abstract: The current remote sensing image analysis task is increasingly evolving from traditional object recognition to complex intelligence reasoning, which places higher requirements on the model's reasoning ability and the flexibility of tool invocation. To this end, we propose a new multimodal agent framework, Vision-Interleaved Chain-of-Thought Framework (VICoT), which implements explicit multi-round reasoning by dynamically incorporating visual tools into the chain of thought. Through a stack-based reasoning structure and a modular MCP-compatible tool suite, VICoT enables LLMs to efficiently perform multi-round, interleaved vision-language reasoning tasks with strong generalization and flexibility.We also propose the Reasoning Stack distillation method to migrate complex Agent behaviors to small, lightweight models, which ensures the reasoning capability while significantly reducing complexity. Experiments on multiple remote sensing benchmarks demonstrate that VICoT significantly outperforms existing SOTA frameworks in reasoning transparency, execution efficiency, and generation quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20085v3</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chujie Wang, Zhiyuan Luo, Ruiqi Liu, Can Ran, Shenghua Fan, Xi Chen, Chu He</dc:creator>
    </item>
  </channel>
</rss>
