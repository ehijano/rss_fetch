<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 16 Sep 2024 04:00:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Towards Scalable Quantum Networks</title>
      <link>https://arxiv.org/abs/2409.08416</link>
      <description>arXiv:2409.08416v1 Announce Type: new 
Abstract: This paper presents a comprehensive study on the scalability challenges and opportunities in quantum communication networks, with the goal of determining parameters that impact networks most as well as the trends that appear when scaling networks. We design simulations of quantum networks comprised of router nodes made up of trapped-ion qubits, separated by quantum repeaters in the form of Bell State Measurement (BSM) nodes. Such networks hold the promise of securely sharing quantum information and enabling high-power distributed quantum computing. Despite the promises, quantum networks encounter scalability issues due to noise and operational errors. Through a modular approach, our research aims to surmount these challenges, focusing on effects from scaling node counts and separation distances while monitoring low-quality communication arising from decoherence effects. We aim to pinpoint the critical features within networks essential for advancing scalable, large-scale quantum computing systems. Our findings underscore the impact of several network parameters on scalability, highlighting a critical insight into the trade-offs between the number of repeaters and the quality of entanglement generated. This paper lays the groundwork for future explorations into optimized quantum network designs and protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08416v1</guid>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Connor Howe, Mohsin Aziz, Ali Anwar</dc:creator>
    </item>
    <item>
      <title>Farmer.Chat: Scaling AI-Powered Agricultural Services for Smallholder Farmers</title>
      <link>https://arxiv.org/abs/2409.08916</link>
      <description>arXiv:2409.08916v1 Announce Type: new 
Abstract: Small and medium-sized agricultural holders face challenges like limited access to localized, timely information, impacting productivity and sustainability. Traditional extension services, which rely on in-person agents, struggle with scalability and timely delivery, especially in remote areas. We introduce Farmer.Chat, a generative AI-powered chatbot designed to address these issues. Leveraging Generative AI, Farmer.Chat offers personalized, reliable, and contextually relevant advice, overcoming limitations of previous chatbots in deterministic dialogue flows, language support, and unstructured data processing. Deployed in four countries, Farmer.Chat has engaged over 15,000 farmers and answered over 300,000 queries. This paper highlights how Farmer.Chat's innovative use of GenAI enhances agricultural service scalability and effectiveness. Our evaluation, combining quantitative analysis and qualitative insights, highlights Farmer.Chat's effectiveness in improving farming practices, enhancing trust, response quality, and user engagement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08916v1</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Namita Singh, Jacqueline Wang'ombe, Nereah Okanga, Tetyana Zelenska, Jona Repishti, Jayasankar G K, Sanjeev Mishra, Rajsekar Manokaran, Vineet Singh, Mohammed Irfan Rafiq, Rikin Gandhi, Akshay Nambi</dc:creator>
    </item>
    <item>
      <title>LightSABRE: A Lightweight and Enhanced SABRE Algorithm</title>
      <link>https://arxiv.org/abs/2409.08368</link>
      <description>arXiv:2409.08368v1 Announce Type: cross 
Abstract: We introduce LightSABRE, a significant enhancement of the SABRE algorithm that advances both runtime efficiency and circuit quality. LightSABRE addresses the increasing demands of modern quantum hardware, which can now accommodate complex scenarios, and circuits with millions of gates. Through iterative development within Qiskit, primarily using the Rust programming language, we have achieved a version of the algorithm in Qiskit 1.2.0 that is approximately 200 times faster than the implementation in Qiskit 0.20.1, which already introduced key improvements like the release valve mechanism. Additionally, when compared to the SABRE algorithm presented in Li et al., LightSABRE delivers an average decrease of 18.9\% in SWAP gate count across the same benchmark circuits. Unlike SABRE, which struggles with scalability and convergence on large circuits, LightSABRE delivers consistently high-quality routing solutions, enabling the efficient execution of large quantum circuits on near-term and future quantum devices. LightSABRE's improvements in speed, scalability, and quality position it as a critical tool for optimizing quantum circuits in the context of evolving quantum hardware and error correction techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08368v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henry Zou, Matthew Treinish, Kevin Hartman, Alexander Ivrii, Jake Lishman</dc:creator>
    </item>
    <item>
      <title>E-QUARTIC: Energy Efficient Edge Ensemble of Convolutional Neural Networks for Resource-Optimized Learning</title>
      <link>https://arxiv.org/abs/2409.08369</link>
      <description>arXiv:2409.08369v1 Announce Type: cross 
Abstract: Ensemble learning is a meta-learning approach that combines the predictions of multiple learners, demonstrating improved accuracy and robustness. Nevertheless, ensembling models like Convolutional Neural Networks (CNNs) result in high memory and computing overhead, preventing their deployment in embedded systems. These devices are usually equipped with small batteries that provide power supply and might include energy-harvesting modules that extract energy from the environment. In this work, we propose E-QUARTIC, a novel Energy Efficient Edge Ensembling framework to build ensembles of CNNs targeting Artificial Intelligence (AI)-based embedded systems. Our design outperforms single-instance CNN baselines and state-of-the-art edge AI solutions, improving accuracy and adapting to varying energy conditions while maintaining similar memory requirements. Then, we leverage the multi-CNN structure of the designed ensemble to implement an energy-aware model selection policy in energy-harvesting AI systems. We show that our solution outperforms the state-of-the-art by reducing system failure rate by up to 40% while ensuring higher average output qualities. Ultimately, we show that the proposed design enables concurrent on-device training and high-quality inference execution at the edge, limiting the performance and energy overheads to less than 0.04%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08369v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.PF</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Le Zhang, Onat Gungor, Flavio Ponzina, Tajana Rosing</dc:creator>
    </item>
    <item>
      <title>Graph-Based Pulse Representation for Diverse Quantum Control Hardware</title>
      <link>https://arxiv.org/abs/2409.08407</link>
      <description>arXiv:2409.08407v1 Announce Type: cross 
Abstract: Pulse-level control of quantum systems is critical for enabling gate implementations, calibration procedures, and Hamiltonian evolution which fundamentally are not supported by the traditional circuit model. This level of control necessitates both efficient generation and representation. In this work, we propose pulselib - a graph-based pulse-level representation. A graph structure, with nodes consisting of parametrized fundamental waveforms, stores all the high-level pulse information while staying flexible for translation into hardware-specific inputs. We motivate pulselib by comparing its feature set and information flow through the pulse layer of the software stack with currently available pulse representations. We describe the architecture of this proposed representation that mimics the abstract syntax tree (AST) model from classical compilation pipelines. Finally, we outline applications like trapped-ion-specific gate and shelving pulse schemes whose constraints and implementation can be written and represented due to pulselib's graph-based architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08407v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aniket S. Dalvi, Leon Riesebos, Jacob Whitlow, Kenneth R. Brown</dc:creator>
    </item>
    <item>
      <title>The Better Solution Probability Metric: Optimizing QAOA to Outperform its Warm-Start Solution</title>
      <link>https://arxiv.org/abs/2409.09012</link>
      <description>arXiv:2409.09012v1 Announce Type: cross 
Abstract: This paper presents a numerical simulation investigation of the Warm-Start Quantum Approximate Optimization Algorithm (QAOA) as proposed by Tate et al. [1], focusing on its application to 3-regular Max-Cut problems. Our study demonstrates that Warm-Start QAOA consistently outperforms theoretical lower bounds on approximation ratios across various tilt angles, highlighting its potential in practical scenarios beyond worst-case predictions. Despite these improvements, Warm-Start QAOA with traditional parameters optimized for expectation value does not exceed the performance of the initial classical solution. To address this, we introduce an alternative parameter optimization objective, the Better Solution Probability (BSP) metric. Our results show that BSP-optimized Warm-Start QAOA identifies solutions at non-trivial tilt angles that are better than even the best classically found warm-start solutions with non-vanishing probabilities. These findings underscore the importance of both theoretical and empirical analyses in refining QAOA and exploring its potential for quantum advantage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09012v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sean Feeney, Reuben Tate, Stephan Eidenbenz</dc:creator>
    </item>
    <item>
      <title>Mitigating Transient Bullwhip Effects Under Imperfect Demand Forecasts</title>
      <link>https://arxiv.org/abs/2404.01090</link>
      <description>arXiv:2404.01090v2 Announce Type: replace 
Abstract: Motivated by how forecast errors exacerbate order fluctuations in supply chains, we leverage robust feedback controller synthesis to characterize, compute, and minimize the worst-case order fluctuation experienced by an individual supply chain vendor. Assuming bounded forecast errors and demand fluctuations, we model forecast error and demand fluctuations as inputs to linear inventory dynamics, and use the $\ell_\infty$ gain to define a transient Bullwhip measure. In contrast to the existing Bullwhip measure, the transient Bullwhip measure explicitly depends on the forecast error. This enables us to separately quantify the transient Bullwhip measure's sensitivity to forecast error and demand fluctuations. To compute the controller that minimizes the worst-case peak gain, we formulate an optimization problem with bilinear matrix inequalities and show that it is equivalent to minimizing a quasi-convex function on a bounded domain. We simulate our model for vendors with non-zero perishable rates and order backlogging rates, and prove that the transient Bullwhip measure can be bounded by a monotonic quasi-convex function whose dependency on the product backlog rate and perishing rate is verified in simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01090v2</guid>
      <category>cs.ET</category>
      <category>math.OC</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah H. Q. Li, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Design and execution of quantum circuits using tens of superconducting qubits and thousands of gates for dense Ising optimization problems</title>
      <link>https://arxiv.org/abs/2308.12423</link>
      <description>arXiv:2308.12423v4 Announce Type: replace-cross 
Abstract: We develop a hardware-efficient ansatz for variational optimization, derived from existing ansatze in the literature, that parametrizes subsets of all interactions in the Cost Hamiltonian in each layer. We treat gate orderings as a variational parameter and observe that doing so can provide significant performance boosts in experiments. We carried out experimental runs of a compilation-optimized implementation of fully-connected Sherrington-Kirkpatrick Hamiltonians on a 50-qubit linear-chain subsystem of Rigetti Aspen-M-3 transmon processor. Our results indicate that, for the best circuit designs tested, the average performance at optimized angles and gate orderings increases with circuit depth (using more parameters), despite the presence of a high level of noise. We report performance significantly better than using a random guess oracle for circuits involving up to approx 5000 two-qubit and approx 5000 one-qubit native gates. We additionally discuss various takeaways of our results toward more effective utilization of current and future quantum processors for optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.12423v4</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filip B. Maciejewski, Stuart Hadfield, Benjamin Hall, Mark Hodson, Maxime Dupont, Bram Evert, James Sud, M. Sohaib Alam, Zhihui Wang, Stephen Jeffrey, Bhuvanesh Sundar, P. Aaron Lott, Shon Grabbe, Eleanor G. Rieffel, Matthew J. Reagor, Davide Venturelli</dc:creator>
    </item>
    <item>
      <title>Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus</title>
      <link>https://arxiv.org/abs/2403.11793</link>
      <description>arXiv:2403.11793v2 Announce Type: replace-cross 
Abstract: The existing methods for evaluating the inference abilities of Large Language Models (LLMs) have been results-centric, making it difficult to assess the inference process. We introduce a new approach using the Abstraction and Reasoning Corpus (ARC) dataset to evaluate the inference and contextual understanding abilities of large language models in a process-centric manner. ARC demands rigorous logical structures for problem-solving, making it a benchmark that facilitates the comparison of model inference abilities with humans. Experimental results confirm that while large language models possess weak inference abilities, they still lag in terms of logical coherence, compositionality, and productivity. Our experiments highlight the reasoning capabilities of LLMs, proposing development paths for achieving human-level reasoning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11793v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.SC</category>
      <pubDate>Mon, 16 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seungpil Lee, Woochang Sim, Donghyeon Shin, Wongyu Seo, Jiwon Park, Seokki Lee, Sanha Hwang, Sejin Kim, Sundong Kim</dc:creator>
    </item>
  </channel>
</rss>
