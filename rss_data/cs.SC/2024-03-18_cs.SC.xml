<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SC</link>
    <description>cs.SC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 18 Mar 2024 04:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 18 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Structural Preprocessing Method for Nonlinear Differential-Algebraic Equations Using Linear Symbolic Matrices</title>
      <link>https://arxiv.org/abs/2403.10260</link>
      <description>arXiv:2403.10260v1 Announce Type: new 
Abstract: Differential-algebraic equations (DAEs) have been used in modeling various dynamical systems in science and engineering. Several preprocessing methods for DAEs, such as consistent initialization and index reduction, use structural information on DAEs. Unfortunately, these methods may fail when the system Jacobian, which is a functional matrix, derived from the DAE is singular.
  To transform a DAE with a singular system Jacobian into a nonsingular system, several regularization methods have been proposed. Most of all existing regularization methods rely on symbolic computation to eliminate the system Jacobian for finding a certificate of singularity, resulting in much computational time. Iwata--Oki--Takamatsu (2019) proposed a method (IOT-method) to find a certificate without symbolic computations. The IOT method approximates the system Jacobian by a simpler symbolic matrix, called a layered mixed matrix, which admits a fast combinatorial algorithm for singularity testing. However, it often overlooks the singularity of the system Jacobian since the approximation largely discards algebraic relationships among entries in the original system Jacobian.
  In this study, we propose a new regularization method extending the idea of the IOT method. Instead of layered mixed matrices, our method approximates the system Jacobian by more expressive symbolic matrices, called rank-1 coefficient mixed (1CM) matrices. This makes our method more widely applicable. We give a fast combinatorial algorithm for finding a singularity certificate of 1CM-matrices, which is free from symbolic elimination. Our method is also advantageous in that it globally preserves the solution set to the DAE. Through numerical experiments, we confirmed that our method runs fast for large-scale DAEs from real instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10260v1</guid>
      <category>cs.SC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taihei Oki, Yujin Song</dc:creator>
    </item>
    <item>
      <title>Cognitive Architectures for Language Agents</title>
      <link>https://arxiv.org/abs/2309.02427</link>
      <description>arXiv:2309.02427v3 Announce Type: replace-cross 
Abstract: Recent efforts have augmented large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning, leading to a new class of language agents. While these agents have achieved substantial empirical success, we lack a systematic framework to organize existing agents and plan future developments. In this paper, we draw on the rich history of cognitive science and symbolic artificial intelligence to propose Cognitive Architectures for Language Agents (CoALA). CoALA describes a language agent with modular memory components, a structured action space to interact with internal memory and external environments, and a generalized decision-making process to choose actions. We use CoALA to retrospectively survey and organize a large body of recent work, and prospectively identify actionable directions towards more capable agents. Taken together, CoALA contextualizes today's language agents within the broader history of AI and outlines a path towards language-based general intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.02427v3</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.SC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Theodore R. Sumers, Shunyu Yao, Karthik Narasimhan, Thomas L. Griffiths</dc:creator>
    </item>
  </channel>
</rss>
