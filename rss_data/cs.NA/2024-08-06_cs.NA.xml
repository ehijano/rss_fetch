<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Aug 2024 04:01:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 06 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A conservative, implicit solver for 0D-2V multi-species nonlinear Fokker-Planck collision equations</title>
      <link>https://arxiv.org/abs/2408.01616</link>
      <description>arXiv:2408.01616v1 Announce Type: new 
Abstract: In this study, we present an optimal implicit algorithm designed to accurately solve the multi-species nonlinear 0D-2V axisymmetric Fokker-Planck-Rosenbluth (FRP) collision equation while preserving mass, momentum, and energy. We rely on the nonlinear Shkarofsky's formula of FRP (FRPS) collision operator in terms of Legendre polynomial expansions. The key to our meshfree approach is the adoption of the Legendre polynomial expansion for the angular direction and King function (Eq.\EQ{King}) expansion for the velocity axis direction. The Legendre polynomial expansion will converge exponentially and the King method, a moment convergence algorithm, could ensure the conservation with high precision in discrete form. Additionally, a post-step projection to manifolds is employed to exactly enforce symmetries of the collision operators. Through solving several typical problems across various nonequilibrium configurations, we demonstrate the superior performance and high accuracy of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01616v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.plasm-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanpeng Wang, Jianyuan Xiao, Yifeng Zheng, Zhihui Zou, Pengfei Zhang, Ge Zhuang</dc:creator>
    </item>
    <item>
      <title>Using Linearized Optimal Transport to Predict the Evolution of Stochastic Particle Systems</title>
      <link>https://arxiv.org/abs/2408.01857</link>
      <description>arXiv:2408.01857v1 Announce Type: new 
Abstract: We develop an algorithm to approximate the time evolution of a probability measure without explicitly learning an operator that governs the evolution. A particular application of interest is discrete measures $\mu_t^N$ that arise from particle systems. In many such situations, the individual particles move chaotically on short time scales, making it difficult to learn the dynamics of a governing operator, but the bulk distribution $\mu_t^N$ approximates an absolutely continuous measure $\mu_t$ that evolves ``smoothly.'' If $\mu_t$ is known on some time interval, then linearized optimal transport theory provides an Euler-like scheme for approximating the evolution of $\mu_t$ using its ``tangent vector field'' (represented as a time-dependent vector field on $\mathbb R^d$), which can be computed as a limit of optimal transport maps. We propose an analog of this Euler approximation to predict the evolution of the discrete measure $\mu_t^N$ (without knowing $\mu_t$). To approximate the analogous tangent vector field, we use a finite difference over a time step that sits between the two time scales of the system -- long enough for the large-$N$ evolution ($\mu_t$) to emerge but short enough to satisfactorily approximate the derivative object used in the Euler scheme. By allowing the limiting behavior to emerge, the optimal transport maps closely approximate the vector field describing the bulk distribution's smooth evolution instead of the individual particles' more chaotic movements. We demonstrate the efficacy of this approach with two illustrative examples, Gaussian diffusion and a cell chemotaxis model, and show that our method succeeds in predicting the bulk behavior over relatively large steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01857v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Karris, Evangelos A. Nikitopoulos, Ioannis Kevrekidis, Seungjoon Lee, Alexander Cloninger</dc:creator>
    </item>
    <item>
      <title>Partial-differential-algebraic equations of nonlinear dynamics by Physics-Informed Neural-Network: (I) Operator splitting and framework assessment</title>
      <link>https://arxiv.org/abs/2408.01914</link>
      <description>arXiv:2408.01914v1 Announce Type: new 
Abstract: Several forms for constructing novel physics-informed neural-networks (PINN) for the solution of partial-differential-algebraic equations based on derivative operator splitting are proposed, using the nonlinear Kirchhoff rod as a prototype for demonstration. The open-source DeepXDE is likely the most well documented framework with many examples. Yet, we encountered some pathological problems and proposed novel methods to resolve them. Among these novel methods are the PDE forms, which evolve from the lower-level form with fewer unknown dependent variables to higher-level form with more dependent variables, in addition to those from lower-level forms. Traditionally, the highest-level form, the balance-of-momenta form, is the starting point for (hand) deriving the lowest-level form through a tedious (and error prone) process of successive substitutions. The next step in a finite element method is to discretize the lowest-level form upon forming a weak form and linearization with appropriate interpolation functions, followed by their implementation in a code and testing. The time-consuming tedium in all of these steps could be bypassed by applying the proposed novel PINN directly to the highest-level form. We developed a script based on JAX. While our JAX script did not show the pathological problems of DDE-T (DDE with TensorFlow backend), it is slower than DDE-T. That DDE-T itself being more efficient in higher-level form than in lower-level form makes working directly with higher-level form even more attractive in addition to the advantages mentioned further above. Since coming up with an appropriate learning-rate schedule for a good solution is more art than science, we systematically codified in detail our experience running optimization through a normalization/standardization of the network-training process so readers can reproduce our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01914v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Loc Vu-Quoc, Alexander Humer</dc:creator>
    </item>
    <item>
      <title>A Fast Fourier-Galerkin Method for Solving Boundary Integral Equations on Torus-Shaped Surfaces</title>
      <link>https://arxiv.org/abs/2408.02199</link>
      <description>arXiv:2408.02199v1 Announce Type: new 
Abstract: In this paper, we introduce a fast Fourier-Galerkin method for solving boundary integral equations on torus-shaped surfaces, which are diffeomorphic to a torus. We analyze the properties of the integral operator's kernel to derive the decay pattern of the entries in the representation matrix. Leveraging this decay pattern, we devise a truncation strategy that efficiently compresses the dense representation matrix of the integral operator into a sparser form containing only $\mathcal{O}(N\ln^2 N)$ nonzero entries, where $N$ denotes the degrees of freedom of the discretization method. We prove that this truncation strategy achieves a quasi-optimal convergence order of $\mathcal{O}(N^{-p/2}\ln N)$, with $p$ representing the degree of regularity of the exact solution to the boundary integral equation. Additionally, we confirm that the truncation strategy preserves stability throughout the solution process. Numerical experiments validate our theoretical findings and demonstrate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02199v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiying Fang, Ying Jiang, Jiafeng Su</dc:creator>
    </item>
    <item>
      <title>Scalable Multilevel Monte Carlo Methods Exploiting Parallel Redistribution on Coarse Levels</title>
      <link>https://arxiv.org/abs/2408.02241</link>
      <description>arXiv:2408.02241v1 Announce Type: new 
Abstract: We study an element agglomeration coarsening strategy that requires data redistribution at coarse levels when the number of coarse elements becomes smaller than the used computational units (cores). The overall procedure generates coarse elements (general unstructured unions of fine grid elements) within the framework of element-based algebraic multigrid methods (or AMGe) studied previously. The AMGe generated coarse spaces have the ability to exhibit approximation properties of the same order as the fine-level ones since by construction they contain the piecewise polynomials of the same order as the fine level ones. These approximation properties are key for the successful use of AMGe in multilevel solvers for nonlinear partial differential equations as well as for multilevel Monte Carlo (MLMC) simulations. The ability to coarsen without being constrained by the number of available cores, as described in the present paper, allows to improve the scalability of these solvers as well as in the overall MLMC method. The paper illustrates this latter fact with detailed scalability study of MLMC simulations applied to model Darcy equations with a stochastic log-normal permeability field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02241v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hillary R. Fairbanks, Delyan Z. Kalchev, Chak Shing Lee, Panayot S. Vassilevski</dc:creator>
    </item>
    <item>
      <title>Accelerated 3D Maxwell Integral Equation Solver using the Interpolated Factored Green Function Method</title>
      <link>https://arxiv.org/abs/2408.02274</link>
      <description>arXiv:2408.02274v1 Announce Type: new 
Abstract: This article presents an $O(N\log N)$ method for numerical solution of Maxwell's equations for dielectric scatterers using a 3D boundary integral equation (BIE) method. The underlying BIE method used is based on a hybrid Nystr\"{o}m-collocation method using Chebyshev polynomials. It is well known that such an approach produces a dense linear system, which requires $O(N^2)$ operations in each step of an iterative solver. In this work, we propose an approach using the recently introduced Interpolated Factored Green's Function (IFGF) acceleration strategy to reduce the cost of each iteration to $O(N\log N)$. To the best of our knowledge, this paper presents the first ever application of the IFGF method to fully-vectorial 3D Maxwell problems. The Chebyshev-based integral solver and IFGF method are first introduced, followed by the extension of the scalar IFGF to the vectorial Maxwell case. Several examples are presented verifying the $O(N\log N)$ computational complexity of the approach, including scattering from spheres, complex CAD models, and nanophotonic waveguiding devices. In one particular example with more than 6 million unknowns, the accelerated IFGF solver runs 42x faster than the unaccelerated method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02274v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jagabandhu Paul, Constantine Sideris</dc:creator>
    </item>
    <item>
      <title>High-performance computing for the BGK model of the Boltzmann equation with a meshfree Arbitrary Lagrangian-Eulerian (ALE) method</title>
      <link>https://arxiv.org/abs/2408.02350</link>
      <description>arXiv:2408.02350v1 Announce Type: new 
Abstract: In this paper, we present high-performance computing for the BGK model of the Boltzmann equations with a meshfree method. We use the Arbitrary-Lagrangian-Eulerian (ALE) method, where the approximation of spatial derivatives and the reconstruction of a function is based on the weighted least squares method. We have used the Graphics Processing Unit (GPU) to accelerate the code and compared with the CPU code. Two and three dimensional driven cavity problems are solved, where we have obtained the speed up up to 307 times and 127 times in two and three dimensional cases, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02350v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Panchatchram Mariappan, Klaas Willems, Gangadhara Boregowda, Sudarshan Tiwari, Axel Klar</dc:creator>
    </item>
    <item>
      <title>Hybrid Surrogate Models: Circumventing Gibbs Phenomenon for Partial Differential Equations with Finite Shock-Type Discontinuities</title>
      <link>https://arxiv.org/abs/2408.02497</link>
      <description>arXiv:2408.02497v1 Announce Type: new 
Abstract: We introduce the concept of Hybrid Surrogate Models (HSMs) -- combining multivariate polynomials with Heavyside functions -- as approximates of functions with finitely many jump discontinuities. We exploit the HSMs for formulating a variational optimization approach, solving non-regular partial differential equations (PDEs) with non-continuous shock-type solutions. The HSM technique simultaneously obtains a parametrization of the position and the height of the shocks as well as the solution of the PDE. We show that the HSM technique circumvents the notorious Gibbs phenomenon, which limits the accuracy that classic numerical methods reach. Numerical experiments, addressing linear and non-linearly propagating shocks, demonstrate the strong approximation power of the HSM technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02497v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Juan-Esteban Suarez Cardona, Shashank Reddy, Michael Hecht</dc:creator>
    </item>
    <item>
      <title>The Immersed Boundary Conformal Method for Kirchhoff-Love and Reissner-Mindlin shells</title>
      <link>https://arxiv.org/abs/2408.02530</link>
      <description>arXiv:2408.02530v1 Announce Type: new 
Abstract: This work utilizes the Immersed Boundary Conformal Method (IBCM) to analyze Kirchhoff-Love and Reissner-Mindlin shell structures within an immersed domain framework. Immersed boundary methods involve embedding complex geometries within a background grid, which allows for great flexibility in modeling intricate shapes and features despite the simplicity of the approach. The IBCM method introduces additional layers conformal to the boundaries, allowing for the strong imposition of Dirichlet boundary conditions and facilitating local refinement. In this study, the construction of boundary layers is combined with high-degree spline-based approximation spaces to further increase efficiency. The Nitsche method, employing non-symmetric average operators, is used to couple the boundary layers with the inner patch, while stabilizing the formulation with minimal penalty parameters. High-order quadrature rules are applied for integration over cut elements and patch interfaces. Numerical experiments demonstrate the efficiency and accuracy of the proposed formulation, highlighting its potential for complex shell structures modeled through Kirchhoff-Love and Reissner-Mindlin theories. These tests include the generation of conformal interfaces, the coupling of Kirchhoff-Love and Reissner-Mindlin theories, and the simulation of a damaged shell.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02530v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuliano Guarino, Alberto Milazzo, Annalisa Buffa, Pablo Antolin</dc:creator>
    </item>
    <item>
      <title>Structure-preserving approximations of the Serre-Green-Naghdi equations in standard and hyperbolic form</title>
      <link>https://arxiv.org/abs/2408.02665</link>
      <description>arXiv:2408.02665v1 Announce Type: new 
Abstract: We develop structure-preserving numerical methods for the Serre-Green-Naghdi equations, a model for weakly dispersive free-surface waves. We consider both the classical form, requiring the inversion of a non-linear elliptic operator, and a hyperbolic approximation of the equations, allowing fully explicit time stepping. Systems for both flat and variable topography are studied. Our novel numerical methods conserve both the total water mass and the total energy. In addition, the methods for the original Serre-Green-Naghdi equations conserve the total momentum for flat bathymetry. For variable topography, all the methods proposed are well-balanced for the lake-at-rest state. We provide a theoretical setting allowing us to construct schemes of any kind (finite difference, finite element, discontinuous Galerkin, spectral, etc.) as long as summation-by-parts operators are available in the chosen setting. Energy-stable variants are proposed by adding a consistent high-order artificial viscosity term. The proposed methods are validated through a large set of benchmarks to verify all the theoretical properties. Whenever possible, comparisons with exact, reference numerical, or experimental data are carried out. The impressive advantage of structure preservation, and in particular energy preservation, to resolve accurately dispersive wave propagation on very coarse meshes is demonstrated by several of the tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02665v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hendrik Ranocha, Mario Ricchiuto</dc:creator>
    </item>
    <item>
      <title>Physics-Informed Geometry-Aware Neural Operator</title>
      <link>https://arxiv.org/abs/2408.01600</link>
      <description>arXiv:2408.01600v1 Announce Type: cross 
Abstract: Engineering design problems often involve solving parametric Partial Differential Equations (PDEs) under variable PDE parameters and domain geometry. Recently, neural operators have shown promise in learning PDE operators and quickly predicting the PDE solutions. However, training these neural operators typically requires large datasets, the acquisition of which can be prohibitively expensive. To overcome this, physics-informed training offers an alternative way of building neural operators, eliminating the high computational costs associated with Finite Element generation of training data. Nevertheless, current physics-informed neural operators struggle with limitations, either in handling varying domain geometries or varying PDE parameters. In this research, we introduce a novel method, the Physics-Informed Geometry-Aware Neural Operator (PI-GANO), designed to simultaneously generalize across both PDE parameters and domain geometries. We adopt a geometry encoder to capture the domain geometry features, and design a novel pipeline to integrate this component within the existing DCON architecture. Numerical results demonstrate the accuracy and efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01600v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiheng Zhong, Hadi Meidani</dc:creator>
    </item>
    <item>
      <title>Effect of Uniform and Non-uniform wall heating on Three-Dimensional Magneto-Hydrodynamics Natural Convection and Entropy Generation: A computational study using New Higher Order Super Compact Scheme</title>
      <link>https://arxiv.org/abs/2408.01853</link>
      <description>arXiv:2408.01853v1 Announce Type: cross 
Abstract: Current research work deals with the effect of uniform and non-uniform wall heating on magnetohydrodynamic (MHD) natural convection within a three-dimensional (3D) cavity filled with molten lithium. A new Higher-Order Super Compact (HOSC) finite difference scheme is used to analyze the thermal behavior under both heating scenarios. After the quantitative and qualitative validations, the computed results are analyzed for a range of Hartman number ($Ha = 25, 50, 100, 150$) and Rayleigh number ($Ra = 10^3, 10^4, 10^5$) with fixed $Pr=0.065$ (molten lithium). Three distinct heating scenarios, i.e., uniform heating ($T_h = 1$), $y$-dependent non-uniform heating ($T_h = sin(\pi y$)), and a combination of $y$ and $z$-dependent non-uniform heating ($T_h = sin(\pi y)sin(\pi z)$) are investigated on the left wall ($x=0$) of the cubic cavity. It is found that variations in the $Ha$ and $Ra$, along with distinct thermal boundary conditions, exert significant effects on both the temperature distribution and flow field inside the 3D cubical cavity. Specifically, an increase in $Ra$ corresponds to enhanced heat transfer, highlighting the dominance of convection. Conversely, an increase in $Ha$ leads to a reduction in heat transfer due to the deceleration of fluid velocity. The scenario in which walls are uniformly heated exhibits the most significant total entropy generation. It is observed that with an increase in the $Ra$, the Bejan number ($Be$) decreases, which ultimately leads to an increase in total entropy generation. The implementation of the new HOSC scheme in this analysis showcases its effectiveness in capturing the complexities of 3D MHD-driven natural convection and entropy generation. This study offers significant information that might help improve the optimization and design of relevant engineering systems. Thus, our work stands out as genuinely novel and pioneering in its approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01853v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ashwani Punia, Rajendra K. Ray</dc:creator>
    </item>
    <item>
      <title>Sparse identification of time delay systems via pseudospectral collocation</title>
      <link>https://arxiv.org/abs/2408.01971</link>
      <description>arXiv:2408.01971v1 Announce Type: cross 
Abstract: We present a pragmatic approach to the sparse identification of nonlinear dynamics for systems with discrete delays. It relies on approximating the underlying delay model with a system of ordinary differential equations via pseudospectral collocation. To minimize the reconstruction error, the new strategy avoids optimizing all possible multiple unknown delays, identifying only the maximum one. The computational burden is thus greatly reduced, improving the performance of recent implementations that work directly on the delay system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01971v1</guid>
      <category>math.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enrico Bozzo, Dimitri Breda, Muhammad Tanveer</dc:creator>
    </item>
    <item>
      <title>A Sharp Convergence Theory for The Probability Flow ODEs of Diffusion Models</title>
      <link>https://arxiv.org/abs/2408.02320</link>
      <description>arXiv:2408.02320v1 Announce Type: cross 
Abstract: Diffusion models, which convert noise into new data instances by learning to reverse a diffusion process, have become a cornerstone in contemporary generative modeling. In this work, we develop non-asymptotic convergence theory for a popular diffusion-based sampler (i.e., the probability flow ODE sampler) in discrete time, assuming access to $\ell_2$-accurate estimates of the (Stein) score functions. For distributions in $\mathbb{R}^d$, we prove that $d/\varepsilon$ iterations -- modulo some logarithmic and lower-order terms -- are sufficient to approximate the target distribution to within $\varepsilon$ total-variation distance. This is the first result establishing nearly linear dimension-dependency (in $d$) for the probability flow ODE sampler. Imposing only minimal assumptions on the target data distribution (e.g., no smoothness assumption is imposed), our results also characterize how $\ell_2$ score estimation errors affect the quality of the data generation processes. In contrast to prior works, our theory is developed based on an elementary yet versatile non-asymptotic approach without the need of resorting to SDE and ODE toolboxes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02320v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>eess.SP</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gen Li, Yuting Wei, Yuejie Chi, Yuxin Chen</dc:creator>
    </item>
    <item>
      <title>Nonlocal particle approximation for linear and fast diffusion equations</title>
      <link>https://arxiv.org/abs/2408.02345</link>
      <description>arXiv:2408.02345v1 Announce Type: cross 
Abstract: We construct deterministic particle solutions for linear and fast diffusion equations using a nonlocal approximation. We exploit the $2$-Wasserstein gradient flow structure of the equations in order to obtain the nonlocal approximating PDEs by regularising the corresponding internal energy with suitably chosen mollifying kernels, either compactly or globally supported. Weak solutions are obtained by the JKO scheme. From the technical point of view, we improve known commutator estimates, fundamental in the nonlocal-to-local limit, to include globally supported kernels which, in particular cases, allow us to justify the limit without any further perturbation needed. Furthermore, we prove geodesic convexity of the nonlocal energies in order to prove convergence of the particle solutions to the nonlocal equations towards weak solutions of the local equations. We overcome the crucial difficulty of dealing with the singularity of the first variation of the free energies at the origin. As a byproduct, we provide convergence rates expressed as a scaling relationship between the number of particles and the localisation parameter. The analysis we perform leverages the fact that globally supported kernels yield a better convergence rate compared to compactly supported kernels. Our result is relevant in statistics, more precisely in sampling Gibbs and heavy-tailed distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02345v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jos\'e Antonio Carrillo, Antonio Esposito, Jakub Skrzeczkowski, Jeremy Sheung-Him Wu</dc:creator>
    </item>
    <item>
      <title>Learning the Latent dynamics of Fluid flows from High-Fidelity Numerical Simulations using Parsimonious Diffusion Maps</title>
      <link>https://arxiv.org/abs/2408.02630</link>
      <description>arXiv:2408.02630v1 Announce Type: cross 
Abstract: We use parsimonious diffusion maps (PDMs) to discover the latent dynamics of high-fidelity Navier-Stokes simulations with a focus on the 2D fluidic pinball problem. By varying the Reynolds number, different flow regimes emerge, ranging from steady symmetric flows to quasi-periodic asymmetric and turbulence. We show, that the proposed non-linear manifold learning scheme, identifies in a crisp manner the expected intrinsic dimension of the underlying emerging dynamics over the parameter space. In particular, PDMs, estimate that the emergent dynamics in the oscillatory regime can be captured by just two variables, while in the chaotic regime, the dominant modes are three as anticipated by the normal form theory. On the other hand, proper orthogonal decomposition (POD)/PCA, most commonly used for dimensionality reduction in fluid mechanics, does not provide such a crisp separation between the dominant modes. To validate the performance of PDMs, we also computed the reconstruction error, by constructing a decoder using Geometric Harmonics. We show that the proposed scheme outperforms the POD/PCA over the whole Reynolds number range. Thus, we believe that the proposed scheme will allow for the development of more accurate reduced order models for high-fidelity fluid dynamics simulators, thus relaxing the curse of dimensionality in numerical analysis tasks such as bifurcation analysis, optimization and control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02630v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Della Pia, Dimitris Patsatzis, Lucia Russo, Constantinos Siettos</dc:creator>
    </item>
    <item>
      <title>Stopping Criteria for the Conjugate Gradient Algorithm in High-Order Finite Element Methods</title>
      <link>https://arxiv.org/abs/2305.10965</link>
      <description>arXiv:2305.10965v2 Announce Type: replace 
Abstract: We consider stopping criteria that balance algebraic and discretization errors for the conjugate gradient algorithm applied to high-order finite element discretizations of Poisson problems. Firstly, we introduce a new stopping criterion that suggests stopping when the norm of the linear system residual is less than a small fraction of an error indicator derived directly from the residual. This indicator shares the same mesh size and polynomial degree scaling as the norm of the residual, resulting in a robust criterion regardless of the mesh size, the polynomial degree, and the shape regularity of the mesh. Secondly, for solving Poisson problems with highly variable piecewise constant coefficients, we introduce a subdomain-based criterion that recommends stopping when the norm of the linear system residual restricted to each subdomain is smaller than the corresponding indicator also restricted to that subdomain. Reliability and efficiency theorems for the first criterion are established. Numerical experiments, including tests with highly variable piecewise constant coefficients and a GPU-accelerated three-dimensional elliptic solver, demonstrate that the proposed criteria efficiently avoid both premature termination and over-solving.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.10965v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yichen Guo, Eric de Sturler, Tim Warburton</dc:creator>
    </item>
    <item>
      <title>Condition numbers for the Moore-Penrose inverse and the least squares problem involving rank-structured matrices</title>
      <link>https://arxiv.org/abs/2306.12177</link>
      <description>arXiv:2306.12177v3 Announce Type: replace 
Abstract: Perturbation theory plays a crucial role in sensitivity analysis, which is extensively used to assess the robustness of numerical techniques. To quantify the relative sensitivity of any problem, it becomes essential to investigate structured condition numbers (CNs) via componentwise perturbation theory. This paper addresses and analyzes structured mixed condition number (MCN) and componentwise condition number (CCN) for the Moore-Penrose (M-P) inverse and the minimum norm least squares (MNLS) solution involving rank-structured matrices, which include the Cauchy-Vandermonde (CV) matrices and {1, 1}-quasiseparable (QS) matrices. A general framework has been developed to compute the upper bounds for MCN and CCN of rank deficient parameterized matrices. This framework leads to faster computation of upper bounds of structured CNs for CV and {1, 1}-QS matrices. Furthermore, comparisons of obtained upper bounds are investigated theoretically and experimentally. In addition, the structured effective CNs for the M-P inverse and the MNLS solution of {1, 1}-QS matrices are presented. Numerical tests reveal the reliability of the proposed upper bounds as well as demonstrate that the structured effective CNs are computationally less expensive and can be substantially smaller compared to the unstructured CNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.12177v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sk. Safique Ahmad, Pinki Khatun</dc:creator>
    </item>
    <item>
      <title>Solving PDEs on Spheres with Physics-Informed Convolutional Neural Networks</title>
      <link>https://arxiv.org/abs/2308.09605</link>
      <description>arXiv:2308.09605v2 Announce Type: replace 
Abstract: Physics-informed neural networks (PINNs) have been demonstrated to be efficient in solving partial differential equations (PDEs) from a variety of experimental perspectives. Some recent studies have also proposed PINN algorithms for PDEs on surfaces, including spheres. However, theoretical understanding of the numerical performance of PINNs, especially PINNs on surfaces or manifolds, is still lacking. In this paper, we establish rigorous analysis of the physics-informed convolutional neural network (PICNN) for solving PDEs on the sphere. By using and improving the latest approximation results of deep convolutional neural networks and spherical harmonic analysis, we prove an upper bound for the approximation error with respect to the Sobolev norm. Subsequently, we integrate this with innovative localization complexity analysis to establish fast convergence rates for PICNN. Our theoretical results are also confirmed and supplemented by our experiments. In light of these findings, we explore potential strategies for circumventing the curse of dimensionality that arises when solving high-dimensional PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.09605v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guanhang Lei, Zhen Lei, Lei Shi, Chenyu Zeng, Ding-Xuan Zhou</dc:creator>
    </item>
    <item>
      <title>Orthogonal Block Kaczmarz Algorithm Based on Preprocessing Technology</title>
      <link>https://arxiv.org/abs/2401.00672</link>
      <description>arXiv:2401.00672v3 Announce Type: replace 
Abstract: In this paper, a new simple and fast orthogonal block Kaczmarz (POBK) algorithm based on preprocessing techniques is proposed to solve large-scale sparse linear systems Ax = f. Firstly, the sparse Reverse Cuthill-McKee Algorithm (RCM) is used to preprocess the linear system, and then a new partitioning strategy is proposed to divide the mutually orthogonal blocks into one category, which greatly reduces computational complexity. In addition, we provide a theoretical proof of the convergence of the POBK algorithm and analyze its faster convergence. Finally, numerical simulations demonstrate that our method outperforms the latest Kaczmarz methods such as GRBK, RBK(k), GREBK(k), and aRBK in terms of CPU time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00672v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu-Fang Liang, Hou-Biao Li</dc:creator>
    </item>
    <item>
      <title>On the improved convergence of lifted distributional Gauss curvature from Regge elements</title>
      <link>https://arxiv.org/abs/2401.12734</link>
      <description>arXiv:2401.12734v2 Announce Type: replace 
Abstract: Although Regge finite element functions are not continuous, useful generalizations of nonlinear derivatives like the curvature, can be defined using them. This paper is devoted to studying the convergence of the finite element lifting of a generalized (distributional) Gauss curvature defined using a metric tensor approximation in the Regge finite element space. Specifically, we investigate the interplay between the polynomial degree of the curvature lifting by Lagrange elements and the degree of the metric tensor in the Regge finite element space. Previously, a superconvergence result, where convergence rate of one order higher than expected, was obtained when the approximate metric is the canonical Regge interpolant of the exact metric. In this work, we show that an even higher order can be obtained if the degree of the curvature lifting is reduced by one polynomial degree and if at least linear Regge elements are used. These improved convergence rates are confirmed by numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12734v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jay Gopalakrishnan, Michael Neunteufel, Joachim Sch\"oberl, Max Wardetzky</dc:creator>
    </item>
    <item>
      <title>Discovering Artificial Viscosity Models for Discontinuous Galerkin Approximation of Conservation Laws using Physics-Informed Machine Learning</title>
      <link>https://arxiv.org/abs/2402.16517</link>
      <description>arXiv:2402.16517v2 Announce Type: replace 
Abstract: Finite element-based high-order solvers of conservation laws offer large accuracy but face challenges near discontinuities due to the Gibbs phenomenon. Artificial viscosity is a popular and effective solution to this problem based on physical insight. In this work, we present a physics-informed machine learning algorithm to automate the discovery of artificial viscosity models in a non-supervised paradigm. The algorithm is inspired by reinforcement learning and trains a neural network acting cell-by-cell (the viscosity model) by minimizing a loss defined as the difference with respect to a reference solution thanks to automatic differentiation. This enables a dataset-free training procedure. We prove that the algorithm is effective by integrating it into a state-of-the-art Runge-Kutta discontinuous Galerkin solver. We showcase several numerical tests on scalar and vectorial problems, such as Burgers' and Euler's equations in one and two dimensions. Results demonstrate that the proposed approach trains a model that is able to outperform classical viscosity models. Moreover, we show that the learnt artificial viscosity model is able to generalize across different problems and parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16517v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Caldana, Paola F. Antonietti, Luca Dede'</dc:creator>
    </item>
    <item>
      <title>Numerical approximations of a lattice Boltzmann scheme with a family of partial differential equations</title>
      <link>https://arxiv.org/abs/2403.19231</link>
      <description>arXiv:2403.19231v2 Announce Type: replace 
Abstract: In this contribution, we address the numerical solutions of high-order asymptotic equivalent partial differential equations with the results of a lattice Boltzmann scheme for an inhomogeneous advection problem in one spatial dimension. We first derive a family of equivalent partial differential equations at various orders, and we compare the lattice Boltzmann experimental results with a spectral approximation of the differential equations. For an unsteady situation, we show that the initialization scheme at a sufficiently high order of the microscopic moments plays a crucial role to observe an asymptotic error consistent with the orderof approximation. For a stationary long-time limit, we observe that the measured asymptotic error converges with a reduced order of precision compared to the one suggested by asymptotic analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19231v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bruce M Boghosian (LMO, LMSSC), Fran\c{c}ois Dubois (LMO, LMSSC), Pierre Lallemand (CSRC)</dc:creator>
    </item>
    <item>
      <title>Neural networks for bifurcation and linear stability analysis of steady states in partial differential equations</title>
      <link>https://arxiv.org/abs/2407.19707</link>
      <description>arXiv:2407.19707v3 Announce Type: replace 
Abstract: This research introduces an extended application of neural networks for solving nonlinear partial differential equations (PDEs). A neural network, combined with a pseudo-arclength continuation, is proposed to construct bifurcation diagrams from parameterized nonlinear PDEs. Additionally, a neural network approach is also presented for solving eigenvalue problems to analyze solution linear stability, focusing on identifying the largest eigenvalue. The effectiveness of the proposed neural network is examined through experiments on the Bratu equation and the Burgers equation. Results from a finite difference method are also presented as comparison. Varying numbers of grid points are employed in each case to assess the behavior and accuracy of both the neural network and the finite difference method. The experimental results demonstrate that the proposed neural network produces better solutions, generates more accurate bifurcation diagrams, has reasonable computational times, and proves effective for linear stability analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19707v3</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Muhammad Luthfi Shahab, Hadi Susanto</dc:creator>
    </item>
    <item>
      <title>Mixed precision HODLR matrices</title>
      <link>https://arxiv.org/abs/2407.21637</link>
      <description>arXiv:2407.21637v2 Announce Type: replace 
Abstract: Hierarchical matrix computations have attracted significant attention in the science and engineering community as exploiting data-sparse structures can significantly reduce the computational complexity of many important kernels. One particularly popular option within this class is the Hierarchical Off-Diagonal Low-Rank (HODLR) format. In this paper, we show that the off-diagonal blocks of HODLR matrices that are approximated by low-rank matrices can be represented in low precision without degenerating the quality of the overall approximation (with the error growth bounded by a factor of $2$). We also present an adaptive-precision scheme for constructing and storing HODLR matrices, and we prove that the use of mixed precision does not compromise the numerical stability of the resulting HOLDR matrix--vector product and LU factorization. That is, the resulting error in these computations is not significantly greater than the case where we use one precision (say, double) for constructing and storing the HOLDR matrix. Our analyses further give insight on how one must choose the working precision in HOLDR matrix computations relative to the approximation error in order to not observe the effects of finite precision. Intuitively, when a HOLDR matrix is subject to a high degree of approximation error, subsequent computations can be performed in a lower precision without detriment. We demonstrate the validity of our theoretical results through a range of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21637v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erin Carson, Xinye Chen, Xiaobo Liu</dc:creator>
    </item>
    <item>
      <title>Unexpected fault activation in underground gas storage. Part II: Definition of safe operational bandwidths</title>
      <link>https://arxiv.org/abs/2408.01049</link>
      <description>arXiv:2408.01049v2 Announce Type: replace 
Abstract: Underground gas storage is a versatile tool for managing energy resources and addressing pressing environmental concerns. While natural gas is stored in geological formations since the beginning of the 20th century, hydrogen has recently been considered as a potential candidate toward a more flexible and sustainable energy infrastructure. Furthermore, these formations can also be used to sequester environmentally harmful gases such as CO2 securely. When such operations are implemented in faulted basins, however, safety concerns may arise due to the possible reactivation of pre-existing faults, which could result in (micro)-seismicity events. In the Netherlands, it has been recently noted that fault reactivation can occur "unexpectedly" during the life of an underground gas storage (UGS) site, even when stress conditions are not expected to cause a failure. The present two-part work aims to develop a modeling framework to investigate the physical mechanisms causing such occurrences and define a safe operational bandwidth for pore pressure variation for UGS operations in the faulted reservoirs of the Rotliegend formation, the Netherlands. In this paper, we investigate in detail the mechanisms and crucial factors that result in fault reactivation at various stages of a UGS project. The mathematical and numerical model described in Part 1 is used, also accounting for the effect of geochemical dissolution on reservoir and caprock weakening. The study investigates the risks of fault activation caused by the storage of different fluids for various purposes, such as long-term CO2 sequestration, CH4 and N2 injection and extraction cycles, and N2 permanent storage. The results show how geomechanical properties and reservoir operating conditions may increase the risk of fault reactivation at various UGS stages. Finally, operational guidelines for improving secure storage operations are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01049v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Selena Baldan, Massimiliano Ferronato, Andrea Franceschini, Carlo Janna, Claudia Zoccarato, Matteo Frigo, Giovanni Isotton, Cristiano Collettini, Chiara Deangeli, Vera Rocca, Francesca Verga, Pietro Teatini</dc:creator>
    </item>
    <item>
      <title>Mode-wise Principal Subspace Pursuit and Matrix Spiked Covariance Model</title>
      <link>https://arxiv.org/abs/2307.00575</link>
      <description>arXiv:2307.00575v2 Announce Type: replace-cross 
Abstract: This paper introduces a novel framework called Mode-wise Principal Subspace Pursuit (MOP-UP) to extract hidden variations in both the row and column dimensions for matrix data. To enhance the understanding of the framework, we introduce a class of matrix-variate spiked covariance models that serve as inspiration for the development of the MOP-UP algorithm. The MOP-UP algorithm consists of two steps: Average Subspace Capture (ASC) and Alternating Projection (AP). These steps are specifically designed to capture the row-wise and column-wise dimension-reduced subspaces which contain the most informative features of the data. ASC utilizes a novel average projection operator as initialization and achieves exact recovery in the noiseless setting. We analyze the convergence and non-asymptotic error bounds of MOP-UP, introducing a blockwise matrix eigenvalue perturbation bound that proves the desired bound, where classic perturbation bounds fail. The effectiveness and practical merits of the proposed framework are demonstrated through experiments on both simulated and real datasets. Lastly, we discuss generalizations of our approach to higher-order data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.00575v2</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Runshi Tang, Ming Yuan, Anru R. Zhang</dc:creator>
    </item>
    <item>
      <title>Kolmogorov Arnold Informed neural network: A physics-informed deep learning framework for solving forward and inverse problems based on Kolmogorov Arnold Networks</title>
      <link>https://arxiv.org/abs/2406.11045</link>
      <description>arXiv:2406.11045v2 Announce Type: replace-cross 
Abstract: AI for partial differential equations (PDEs) has garnered significant attention, particularly with the emergence of Physics-informed neural networks (PINNs). The recent advent of Kolmogorov-Arnold Network (KAN) indicates that there is potential to revisit and enhance the previously MLP-based PINNs. Compared to MLPs, KANs offer interpretability and require fewer parameters. PDEs can be described in various forms, such as strong form, energy form, and inverse form. While mathematically equivalent, these forms are not computationally equivalent, making the exploration of different PDE formulations significant in computational physics. Thus, we propose different PDE forms based on KAN instead of MLP, termed Kolmogorov-Arnold-Informed Neural Network (KINN) for solving forward and inverse problems. We systematically compare MLP and KAN in various numerical examples of PDEs, including multi-scale, singularity, stress concentration, nonlinear hyperelasticity, heterogeneous, and complex geometry problems. Our results demonstrate that KINN significantly outperforms MLP regarding accuracy and convergence speed for numerous PDEs in computational solid mechanics, except for the complex geometry problem. This highlights KINN's potential for more efficient and accurate PDE solutions in AI for PDEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11045v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizheng Wang, Jia Sun, Jinshuai Bai, Cosmin Anitescu, Mohammad Sadegh Eshaghi, Xiaoying Zhuang, Timon Rabczuk, Yinghua Liu</dc:creator>
    </item>
  </channel>
</rss>
