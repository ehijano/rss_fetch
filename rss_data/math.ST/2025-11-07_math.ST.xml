<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Nov 2025 05:00:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Behrens--Fisher problem revisited</title>
      <link>https://arxiv.org/abs/2511.03951</link>
      <description>arXiv:2511.03951v1 Announce Type: new 
Abstract: We revisit the two-sample Behrens--Fisher problem -- testing equality of means when two normal populations have unequal, unknown variances -- and derive a compact expression for the null distribution of the classical test statistic. The key step is a Mellin--Barnes factorization that decouples the square root of a weighted sum of independent chi-square variates, thereby collapsing a challenging two-dimensional integral to a tractable single-contour integral. Closing the contour yields a residue series that terminates whenever either sample's degrees of freedom is odd. A complementary Euler--Beta reduction identifies the density as a Gauss hypergeometric function with explicit parameters, yielding a numerically stable form that recovers Student's $t$ under equal variances. Ramanujan's master theorem supplies exact inverse-power tail coefficients, which bound Lugannani--Rice saddle-point approximation errors and support reliable tail analyses. Our result subsumes the hypergeometric density derived by Nel {\etal}, and extends it with a concise cdf and analytic tail expansions; their algebraic special cases coincide with our truncated residue series. Using our derived expressions, we tabulate exact two-sided critical values over a broad grid of sample sizes and variance ratios that reveal the parameter surface on which the well-known Welch's approximation switches from conservative to liberal, quantifying its maximum size distortion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03951v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nagananda K G, Jong Sung Kim</dc:creator>
    </item>
    <item>
      <title>Finding Planted Cycles in a Random Graph</title>
      <link>https://arxiv.org/abs/2511.04058</link>
      <description>arXiv:2511.04058v1 Announce Type: new 
Abstract: In this paper, we study the problem of finding a collection of planted cycles in an \ER random graph $G \sim \mathcal{G}(n, \lambda/n)$, in analogy to the famous Planted Clique Problem. When the cycles are planted on a uniformly random subset of $\delta n$ vertices, we show that almost-exact recovery (that is, recovering all but a vanishing fraction of planted-cycle edges as $n \to \infty$) is information-theoretically possible if $\lambda &lt; \frac{1}{(\sqrt{2 \delta} + \sqrt{1-\delta})^2}$ and impossible if $\lambda &gt; \frac{1}{(\sqrt{2 \delta} + \sqrt{1-\delta})^2}$. Moreover, despite the worst-case computational hardness of finding long cycles, we design a polynomial-time algorithm that attains almost exact recovery when $\lambda &lt; \frac{1}{(\sqrt{2 \delta} + \sqrt{1-\delta})^2}$. This stands in stark contrast to the Planted Clique Problem, where a significant computational-statistical gap is widely conjectured.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04058v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Gaudio, Colin Sandon, Jiaming Xu, Dana Yang</dc:creator>
    </item>
    <item>
      <title>A Generalized Back-Door Criterion for Linear Regression</title>
      <link>https://arxiv.org/abs/2511.04060</link>
      <description>arXiv:2511.04060v1 Announce Type: new 
Abstract: What assumptions about the data-generating process are required to permit a causal interpretation of partial regression coefficients? To answer this question, this paper generalizes Pearl's single-door and back-door criteria and proposes a new criterion, which enables the identification of total or partial causal effects. In addition, this paper elucidates the mechanism of post-treatment bias, showing that a repeated sequence of nodes can be a potential source of this bias. The results apply to linear data-generating processes represented by directed acyclic graphs with distribution-free error terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04060v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masato Shimokawa</dc:creator>
    </item>
    <item>
      <title>Goodness-of-fit testing of the distribution of posterior classification probabilities for validating model-based clustering</title>
      <link>https://arxiv.org/abs/2511.04206</link>
      <description>arXiv:2511.04206v1 Announce Type: new 
Abstract: We present the first method for assessing the relevance of a model-based clustering result in both parametric and non-parametric frameworks. The method directly aligns with the clustering objective by assessing how well the conditional probabilities of cluster memberships, as defined by the mixture model, fit the data. By focusing on these conditional probabilities, the procedure applies to any type and dimension of data and any mixture model. The testing procedure requires only a consistent estimator of the parameters and the associated conditional probabilities of classification for each observation. Its implementation is straightforward, as no additional estimator is needed. Under the null hypothesis, the method relies on the fact that any functional transformation of the posterior probabilities of classification has the same expectation under both the model being tested and the true model. This goodness-of-fit procedure is based on a empirical likelihood method with an increasing number of moment conditions to asymptotically detect any alternative. Data are split into blocks to account for the use of a parameter estimator, and the empirical log-likelihood ratio is computed for each block. By analyzing the deviation of the maximum empirical log-likelihood ratios, the exact asymptotic significance level of the goodnessof-fit procedure is obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04206v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Salima El Kolei (CREST), Matthieu Marbac (LMBA)</dc:creator>
    </item>
    <item>
      <title>Rates of Convergence of Maximum Smoothed Log-Likelihood Estimators for Semi-Parametric Multivariate Mixtures</title>
      <link>https://arxiv.org/abs/2511.04226</link>
      <description>arXiv:2511.04226v1 Announce Type: new 
Abstract: Theoretical guarantees are established for a standard estimator in a semi-parametric finite mixture model, where each component density is modeled as a product of univariate densities under a conditional independence assumption. The focus is on the estimator that maximizes a smoothed log-likelihood function, which can be efficiently computed using a majorization-minimization algorithm. This smoothed likelihood applies a nonlinear regularization operator defined as the exponential of a kernel convolution on the logarithm of each component density. Consistency of the estimators is demonstrated by leveraging classical M-estimation frameworks under mild regularity conditions. Subsequently, convergence rates for both finite- and infinite-dimensional parameters are derived by exploiting structural properties of the smoothed likelihood, the behavior of the iterative optimization algorithm, and a thorough study of the profile smoothed likelihood. This work provides the first rigorous theoretical guarantees for this estimation approach, bridging the gap between practical algorithms and statistical theory in semi-parametric mixture modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04226v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marie Du Roy de Chaumaray, Michael Levine, Matthieu Marbac</dc:creator>
    </item>
    <item>
      <title>An Approximate Bayesian Approach to Optimal Input Signal Design for System Identification</title>
      <link>https://arxiv.org/abs/2511.04425</link>
      <description>arXiv:2511.04425v1 Announce Type: new 
Abstract: The design of informatively rich input signals is essential for accurate system identification, yet classical Fisher-information-based methods are inherently local and often inadequate in the presence of significant model uncertainty and nonlinearity. This paper develops a Bayesian approach that uses the mutual information (MI) between observations and parameters as the utility function. To address the computational intractability of the MI, we maximize a tractable MI lower bound. The method is then applied to the design of an input signals for the identification of quasi-linear stochastic dynamical systems. Evaluating the MI lower bound requires inversion of large covariance matrices whose dimensions scale with the number of data points $N$. To overcome this problem, an algorithm that reduces the dimension of the matrices to be inverted by a factor of $N$ is developed, making the approach feasible for long experiments. The proposed Bayesian method is compared with the average D-optimal design method, a semi-Bayesian approach, and its advantages are demonstrated. The effectiveness of the proposed method is further illustrated through four examples, including atomic sensor models, where the input signals that generates large MI are especially important for reducing the estimation error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04425v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.3390/e27101041</arxiv:DOI>
      <arxiv:journal_reference>This is an extended and corrected version of the article already published in Entropy (MDPI), 2025, 27(10), 1041; https://www.mdpi.com/1099-4300/27/10/1041</arxiv:journal_reference>
      <dc:creator>Piotr Bania, Anna W\'ojcik</dc:creator>
    </item>
    <item>
      <title>Asymptotics for Reinforced Stochastic Processes on Hierarchical Networks</title>
      <link>https://arxiv.org/abs/2511.04562</link>
      <description>arXiv:2511.04562v1 Announce Type: new 
Abstract: In this paper, we analyze the asymptotic behavior of a system of interacting reinforced stochastic processes $({\bf Z}_n, {\bf N}_n)_n$ on a directed network of $N$ agents. The system is defined by the coupled dynamics ${\bf Z}_{n+1}=(1-r_{n}){\bf Z}_{n}+r_{n}{\bf X}_{n+1}$ and ${\bf N}_{n+1}=(1-\frac{1}{n+1}){\bf N}_n+\frac{1}{n+1}{\bf X}_{n+1}$, where agent actions $\mathbb{P}(X_{n+1,j}=1\mid{\cal F}_n)=\sum_{h} w_{hj}Z_{nh}$ are governed by a column-normalized adjacency matrix ${\bf W}$, and $r_n \sim cn^{-\gamma}$ with $\gamma \in (1/2, 1]$. Existing asymptotic theory has largely been restricted to irreducible and diagonalizable ${\bf W}$. We extend this analysis to the broader and more practical class of reducible and non-diagonalizable matrices ${\bf W}$ possessing a block upper-triangular form, which models hierarchical influence. We first establish synchronization, proving $({\bf Z}^\top_n, {\bf N}^\top_n)^\top \to Z_\infty {\bf 1}$ almost surely, where the distribution of the limit $Z_\infty$ is shown to be determined solely by the internal dynamics of the leading subgroup. Furthermore, we establish a joint central limit theorem for $({\bf Z}_n,{\bf N}_n)_n$, revealing how the spectral properties and Jordan block structure of ${\bf W}$ govern second-order fluctuations. We demonstrate that the convergence rates and the limiting covariance structure exhibit a phase transition dependent on $\gamma$ and the spectral properties of ${\bf W}$. Crucially, we explicitly characterize how the non-diagonalizability of ${\bf W}$ fundamentally alters the asymptotic covariance and introduces new logarithmic scaling factors in the critical case ($\gamma=1$). These results provide a probabilistic foundation for statistical inference on such hierarchical network structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04562v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Yang, Dandan Jiang, Jiang Hu, Zhidong Bai</dc:creator>
    </item>
    <item>
      <title>Asymptotics of constrained $M$-estimation under convexity</title>
      <link>https://arxiv.org/abs/2511.04612</link>
      <description>arXiv:2511.04612v1 Announce Type: new 
Abstract: M-estimation, aka empirical risk minimization, is at the heart of statistics and machine learning: Classification, regression, location estimation, etc. Asymptotic theory is well understood when the loss satisfies some smoothness assumptions and its derivatives are dominated locally. However, these conditions are typically technical and can be too restrictive or heavy to check. Here, we consider the case of a convex loss function, which may not even be differentiable: We establish an asymptotic theory for M-estimation with convex loss (which needs not be differentiable) under convex constraints. We show that the asymptotic distributions of the corresponding M-estimators depend on an interplay between the loss function and the boundary structure of the set of constraints. We extend our results to U-estimators, building on the asymptotic theory of U-statistics. Applications of our work include, among other, robust location/scatter estimation, estimation of deepest points relative to depth functions such as Oja's depth, etc.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04612v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor-Emmanuel Brunel</dc:creator>
    </item>
    <item>
      <title>Adaptive Geometric Regression for High-Dimensional Structured Data</title>
      <link>https://arxiv.org/abs/2511.03817</link>
      <description>arXiv:2511.03817v1 Announce Type: cross 
Abstract: We present a geometric framework for regression on structured high-dimensional
  data that shifts the analysis from the ambient space to a geometric object
  capturing the data's intrinsic structure. The method addresses a fundamental
  challenge in analyzing datasets with high ambient dimension but low intrinsic
  dimension, such as microbiome compositions, where traditional approaches fail
  to capture the underlying geometric structure. Starting from a k-nearest
  neighbor covering of the feature space, the geometry evolves iteratively
  through heat diffusion and response-coherence modulation, concentrating mass
  within regions where the response varies smoothly while creating diffusion
  barriers where the response changes rapidly. This iterative refinement
  produces conditional expectation estimates that respect both the intrinsic
  geometry of the feature space and the structure of the response.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03817v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pawel Gajer, Jacques Ravel</dc:creator>
    </item>
    <item>
      <title>Higher-Order Causal Structure Learning with Additive Models</title>
      <link>https://arxiv.org/abs/2511.03831</link>
      <description>arXiv:2511.03831v1 Announce Type: cross 
Abstract: Causal structure learning has long been the central task of inferring causal insights from data. Despite the abundance of real-world processes exhibiting higher-order mechanisms, however, an explicit treatment of interactions in causal discovery has received little attention. In this work, we focus on extending the causal additive model (CAM) to additive models with higher-order interactions. This second level of modularity we introduce to the structure learning problem is most easily represented by a directed acyclic hypergraph which extends the DAG. We introduce the necessary definitions and theoretical tools to handle the novel structure we introduce and then provide identifiability results for the hyper DAG, extending the typical Markov equivalence classes. We next provide insights into why learning the more complex hypergraph structure may actually lead to better empirical results. In particular, more restrictive assumptions like CAM correspond to easier-to-learn hyper DAGs and better finite sample complexity. We finally develop an extension of the greedy CAM algorithm which can handle the more complex hyper DAG search space and demonstrate its empirical usefulness in synthetic experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03831v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Enouen, Yujia Zheng, Ignavier Ng, Yan Liu, Kun Zhang</dc:creator>
    </item>
    <item>
      <title>Conditional Score Learning for Quickest Change Detection in Markov Transition Kernels</title>
      <link>https://arxiv.org/abs/2511.03953</link>
      <description>arXiv:2511.03953v1 Announce Type: cross 
Abstract: We address the problem of quickest change detection in Markov processes with unknown transition kernels. The key idea is to learn the conditional score $\nabla_{\mathbf{y}} \log p(\mathbf{y}|\mathbf{x})$ directly from sample pairs $( \mathbf{x},\mathbf{y})$, where both $\mathbf{x}$ and $\mathbf{y}$ are high-dimensional data generated by the same transition kernel. In this way, we avoid explicit likelihood evaluation and provide a practical way to learn the transition dynamics. Based on this estimation, we develop a score-based CUSUM procedure that uses conditional Hyvarinen score differences to detect changes in the kernel. To ensure bounded increments, we propose a truncated version of the statistic. With Hoeffding's inequality for uniformly ergodic Markov processes, we prove exponential lower bounds on the mean time to false alarm. We also prove asymptotic upper bounds on detection delay. These results give both theoretical guarantees and practical feasibility for score-based detection in high-dimensional Markov models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03953v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wuxia Chen, Taposh Banerjee, Vahid Tarokh</dc:creator>
    </item>
    <item>
      <title>Score-Based Quickest Change Detection and Fault Identification for Multi-Stream Signals</title>
      <link>https://arxiv.org/abs/2511.03967</link>
      <description>arXiv:2511.03967v1 Announce Type: cross 
Abstract: This paper introduces an approach to multi-stream quickest change detection and fault isolation for unnormalized and score-based statistical models. Traditional optimal algorithms in the quickest change detection literature require explicit pre-change and post-change distributions to calculate the likelihood ratio of the observations, which can be computationally expensive for higher-dimensional data and sometimes even infeasible for complex machine learning models. To address these challenges, we propose the min-SCUSUM method, a Hyvarinen score-based algorithm that computes the difference of score functions in place of log-likelihood ratios. We provide a delay and false alarm analysis of the proposed algorithm, showing that its asymptotic performance depends on the Fisher divergence between the pre- and post-change distributions. Furthermore, we establish an upper bound on the probability of fault misidentification in distinguishing the affected stream from the unaffected ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03967v1</guid>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wuxia Chen, Sean Moushegian, Vahid Tarokh, Taposh Banerjee</dc:creator>
    </item>
    <item>
      <title>A Survey on Noise-Based Communication</title>
      <link>https://arxiv.org/abs/2511.04011</link>
      <description>arXiv:2511.04011v1 Announce Type: cross 
Abstract: The proliferation of sixth-generation (6G) networks and the massive Internet of Things (IoT) demand wireless communication technologies that are ultra-low-power, secure, and covert. Noise-based communication has emerged as a transformative paradigm that meets these demands by encoding information directly into the statistical properties of noise, rather than using traditional deterministic carriers. This survey provides a comprehensive synthesis of this field, systematically exploring its fundamental principles and key methodologies, including thermal noise modulation (TherMod), noise modulation (NoiseMod) and its variants, and the Kirchhoff-law-Johnson-noise (KLJN) secure key exchange. We address critical practical challenges such as channel estimation and hardware implementation, and highlight emerging applications in simultaneous wireless information and power transfer (SWIPT) and non-orthogonal multiple access (NOMA). Our analysis confirms that noise-based systems offer unparalleled advantages in energy efficiency and covertness, and we conclude by outlining future research directions to realize their potential for enabling the next generation of autonomous and secure wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04011v1</guid>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Higo T. P. Da Silva, Hugerles S. Silva, Felipe A. P. Figueiredo, Andre A. Dos Anjos, Rausley A. A. Souza</dc:creator>
    </item>
    <item>
      <title>Estimation of Independent Component Analysis Systems</title>
      <link>https://arxiv.org/abs/2511.04273</link>
      <description>arXiv:2511.04273v1 Announce Type: cross 
Abstract: Although approaches to Independent Component Analysis (ICA) based on characteristic function seem theoretically elegant, they may suffer from implementational challenges because of numerical integration steps or selection of tuning parameters. Extending previously considered objective functions and leveraging results from the continuum Generalized Method of Moments of Carrasco and Florens (2000), I derive an optimal estimator that can take a tractable form and thus bypass these concerns. The method shares advantages with characteristic function approaches -- it does not require the existence of higher-order moments or parametric restrictions -- while retaining computational feasibility and asymptotic efficiency. The results are adapted to handle a possible first step that delivers estimated sensors. Finally, a by-product of the approach is a specification test that is valuable in many ICA applications. The method's effectiveness is illustrated through simulations, where the estimator outperforms efficient GMM, JADE, or FastICA, and an application to the estimation of Structural Vector Autoregressions (SVAR), a workhorse of the macroeconometric time series literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04273v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Starck</dc:creator>
    </item>
    <item>
      <title>On the relationship between MESP and 0/1 D-Opt and their upper bounds</title>
      <link>https://arxiv.org/abs/2511.04350</link>
      <description>arXiv:2511.04350v1 Announce Type: cross 
Abstract: We establish strong connections between two fundamental nonlinear 0/1 optimization problems coming from the area of experimental design, namely maximum entropy sampling and 0/1 D-Optimality. The connections are based on maps between instances, and we analyze the behavior of these maps. Using these maps, we transport basic upper-bounding methods between these two problems, and we are able to establish new domination results and other inequalities relating various basic upper bounds. Further, we establish results relating how different branch-and-bound schemes based on these maps compare. Additionally, we observe some surprising numerical results, where bounding methods that did not seem promising in their direct application to real-data MESP instances, are now useful for MESP instances that come from 0/1 D-Optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04350v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Ponte, Marcia Fampa, Jon Lee</dc:creator>
    </item>
    <item>
      <title>Riesz Regression As Direct Density Ratio Estimation</title>
      <link>https://arxiv.org/abs/2511.04568</link>
      <description>arXiv:2511.04568v1 Announce Type: cross 
Abstract: Riesz regression has garnered attention as a tool in debiased machine learning for causal and structural parameter estimation (Chernozhukov et al., 2021). This study shows that Riesz regression is closely related to direct density-ratio estimation (DRE) in important cases, including average treat- ment effect (ATE) estimation. Specifically, the idea and objective in Riesz regression coincide with the one in least-squares importance fitting (LSIF, Kanamori et al., 2009) in direct density-ratio estimation. While Riesz regression is general in the sense that it can be applied to Riesz representer estimation in a wide class of problems, the equivalence with DRE allows us to directly import exist- ing results in specific cases, including convergence-rate analyses, the selection of loss functions via Bregman-divergence minimization, and regularization techniques for flexible models, such as neural networks. Conversely, insights about the Riesz representer in debiased machine learning broaden the applications of direct density-ratio estimation methods. This paper consolidates our prior results in Kato (2025a) and Kato (2025b).</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04568v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Masahiro Kato</dc:creator>
    </item>
    <item>
      <title>Geometric Decomposition of Statistical Inference through Gradient Flow and Co-Monotonicity Measures</title>
      <link>https://arxiv.org/abs/2511.04599</link>
      <description>arXiv:2511.04599v1 Announce Type: cross 
Abstract: Understanding feature-outcome associations in high-dimensional data remains
  challenging when relationships vary across subpopulations, yet standard
  methods assuming global associations miss context-dependent patterns, reducing
  statistical power and interpretability. We develop a geometric decomposition
  framework offering two strategies for partitioning inference problems into
  regional analyses on data-derived Riemannian graphs. Gradient flow
  decomposition uses path-monotonicity-validated discrete Morse theory to
  partition samples into basins where outcomes exhibit monotonic behavior.
  Co-monotonicity decomposition leverages association structure: vertex-level
  coefficients measuring directional concordance between outcome and features,
  or between feature pairs, define embeddings of samples into association space.
  These embeddings induce Riemannian k-NN graphs on which biclustering
  identifies co-monotonicity cells (coherent regions) and feature modules. This
  extends naturally to multi-modal integration across multiple feature sets.
  Both strategies apply independently or jointly, with Bayesian posterior
  sampling providing credible intervals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04599v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pawel Gajer, Jacques Ravel</dc:creator>
    </item>
    <item>
      <title>Numerical method to solve impulse control problems for partially observed piecewise deterministic Markov processes</title>
      <link>https://arxiv.org/abs/2112.09408</link>
      <description>arXiv:2112.09408v3 Announce Type: replace 
Abstract: Designing efficient and rigorous numerical methods for sequential decision-making under uncertainty is a difficult problem that arises in many applications frameworks. In this paper we focus on the numerical solution of a subclass of impulse control problem for piecewise deterministic Markov process (PDMP) when the jump times are hidden. We first state the problem as a partially observed Markov decision process (POMDP) on a continuous state space and with controlled transition kernels corresponding to some specific skeleton chains of the PDMP. Then we proceed to build a numerically tractable approximation of the POMDP by tailor-made discretizations of the state spaces. The main difficulty in evaluating the discretization error comes from the possible random jumps of the PDMP between consecutive epochs of the POMDP and requires special care. Finally we discuss the practical construction of discretization grids and illustrate our method on simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.09408v3</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alice Cleynen, Beno\^ite de Saporta</dc:creator>
    </item>
    <item>
      <title>Non-asymptotic Estimates for Markov Transition Matrices via Spectral Gap Methods</title>
      <link>https://arxiv.org/abs/2408.05963</link>
      <description>arXiv:2408.05963v3 Announce Type: replace 
Abstract: We establish non-asymptotic error bounds for the classical Maximal Likelihood Estimation of the transition matrix of a given Markov chain. Meanwhile, in the reversible case, we propose a new reversibility-preserving online Symmetric Counting Estimation of the transition matrix with non-asymptotic deviation bounds. Our analysis is based on a convergence study of certain Markov chains on the length-2 path spaces induced by the original Markov chain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05963v3</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>De Huang, Xiangyuan Li</dc:creator>
    </item>
    <item>
      <title>On Vector Field Reconstruction from Noisy ODE in High Ambient Dimension</title>
      <link>https://arxiv.org/abs/2503.08355</link>
      <description>arXiv:2503.08355v4 Announce Type: replace 
Abstract: This work investigates the nonparametric estimation of the vector field of a noisy Ordinary Differential Equation (ODE) in high-dimensional ambient spaces, under the assumption that the initial conditions are sampled from a lower-dimensional structure. Specifically, let \( f:\mathbb{R}^{D}\to\mathbb{R}^{D} \) denote the vector field of the autonomous ODE \( y' = f(y) \). We observe noisy trajectories \( \tilde{y}_{X_i}(t_j) = y_{X_i}(t_j) + \varepsilon_{i,j} \), where \( y_{X_i}(t_j) \) is the solution at time \( t_j \) with initial condition \( y(0)=X_i \), the \( X_i \) are drawn from a \((a,b)\)-standard distribution \( \mu \), and \( \varepsilon_{i,j} \) denotes noise. From a minimax perspective, we study the reconstruction of \( f \) within the envelope of trajectories generated by the support of \( \mu \). We proposed an estimator combining flow reconstruction with derivative estimation techniques from nonparametric regression. Under mild regularity assumptions on \( f \), we establish convergence rates that depend on the temporal resolution, the number of initial conditions, and the parameter \( b \), which controls the mass concentration of \( \mu \). These rates are then shown to be minimax optimal (up to logarithmic factors) and illustrate how the proposed approach mitigates the curse of dimensionality. Additionally, we illustrate the computational and statistical efficiency of our estimator through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08355v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo Henneuse</dc:creator>
    </item>
    <item>
      <title>High-dimensional Gaussian and bootstrap approximations for robust means</title>
      <link>https://arxiv.org/abs/2504.08435</link>
      <description>arXiv:2504.08435v3 Announce Type: replace 
Abstract: Recent years have witnessed much progress on Gaussian and bootstrap approximations to the distribution of sums of independent random vectors with dimension $d$ large relative to the sample size $n$. However, for any number of moments $m&gt;2$ that the summands may possess, there exist distributions such that these approximations break down if $d$ grows faster than the polynomial barrier $n^{\frac{m}{2}-1}$. In this paper, we establish Gaussian and bootstrap approximations to the distributions of winsorized and trimmed means that allow $d$ to grow at an exponential rate in $n$ as long as $m&gt;2$ moments exist. The approximations remain valid under some amount of adversarial contamination. Our implementations of the winsorized and trimmed means do not require knowledge of $m$. As a consequence, the performance of the approximation guarantees ``adapts'' to $m$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08435v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anders Bredahl Kock, David Preinerstorfer</dc:creator>
    </item>
    <item>
      <title>Winsorized mean estimation with heavy tails and adversarial contamination</title>
      <link>https://arxiv.org/abs/2504.08482</link>
      <description>arXiv:2504.08482v2 Announce Type: replace 
Abstract: Finite-sample upper bounds on the estimation error of a winsorized mean estimator of the population mean in the presence of heavy tails and adversarial contamination are established. In comparison to existing results, the winsorized mean estimator we study avoids a sample splitting device and winsorizes substantially fewer observations, which improves its applicability and practical performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08482v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Anders Bredahl Kock, David Preinerstorfer</dc:creator>
    </item>
    <item>
      <title>Statistical Properties of Rectified Flow</title>
      <link>https://arxiv.org/abs/2511.03193</link>
      <description>arXiv:2511.03193v2 Announce Type: replace 
Abstract: Rectified flow (Liu et al., 2022; Liu, 2022; Wu et al., 2023) is a method for defining a transport map between two distributions, and enjoys popularity in machine learning, although theoretical results supporting the validity of these methods are scant. The rectified flow can be regarded as an approximation to optimal transport, but in contrast to other transport methods that require optimization over a function space, computing the rectified flow only requires standard statistical tools such as regression or density estimation. Because of this, one can leverage standard data analysis tools for regression and density estimation to develop empirical versions of transport maps. We study some structural properties of the rectified flow, including existence, uniqueness, and regularity, as well as the related statistical properties, such as rates of convergence and central limit theorems, for some selected estimators. To do so, we analyze separately the bounded and unbounded cases as each presents unique challenges. In both cases, we are able to establish convergence at faster rates than the ones for the usual nonparametric regression and density estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.03193v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gonzalo Mena, Arun Kumar Kuchibhotla, Larry Wasserman</dc:creator>
    </item>
    <item>
      <title>Low-rank Tensor Autoregressive Predictor for Third-Order Time-Series Forecasting</title>
      <link>https://arxiv.org/abs/2403.02835</link>
      <description>arXiv:2403.02835v2 Announce Type: replace-cross 
Abstract: Recently, tensor time-series forecasting has gained increasing attention, whose core requirement is how to perform dimensionality reduction. In this paper, we establish a least square optimization model by combining tensor singular value decomposition (t-SVD) with autoregression (AR) to forecast third-order tensor time-series, which has great benefit in computational complexity and dimensionality reduction. We divide such an optimization problem using fast Fourier transformation and t-SVD into four decoupled subproblems, whose variables include regressive coefficient, f-diagonal tensor, left and right orthogonal tensors, and propose an efficient forecasting algorithm via alternating minimization strategy, called Low-rank Tensor Autoregressive Predictor (LOTAP), in which each subproblem has a closed-form solution. Numerical experiments indicate that, compared to Tucker-decomposition-based algorithms, LOTAP achieves a speed improvement ranging from $2$ to $6$ times while maintaining accurate forecasting performance in all four baseline tasks. In addition, this algorithm is applicable to a wider range of tensor forecasting tasks because of its more effective dimensionality reduction ability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02835v2</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoning Wang, Liping Zhang</dc:creator>
    </item>
    <item>
      <title>Canonical Correlation Analysis: review</title>
      <link>https://arxiv.org/abs/2411.15625</link>
      <description>arXiv:2411.15625v2 Announce Type: replace-cross 
Abstract: For over a century canonical correlations, variables, and related concepts have been studied across various fields, with contributions dating back to Jordan [1875] and Hotelling [1936]. This text surveys the evolution of canonical correlation analysis, a fundamental statistical tool, beginning with its foundational theorems and progressing to recent developments and open research problems. Along the way we introduce and review methods, notions, and fundamental concepts from linear algebra, random matrix theory, and high-dimensional statistics, placing particular emphasis on rigorous mathematical treatment.
  The survey is intended for technically proficient graduate students and other researchers with an interest in this area. The content is organized into five chapters, supplemented by six sets of exercises found in Chapter 6. These exercises introduce additional material, reinforce key concepts, and serve to bridge ideas across chapters. We recommend the following sequence: first, solve Problem Set 0, then proceed with Chapter 1, solve Problem Set 1, and so on through the text.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15625v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Bykhovskaya, Vadim Gorin</dc:creator>
    </item>
    <item>
      <title>The nature of mathematical models</title>
      <link>https://arxiv.org/abs/2502.07948</link>
      <description>arXiv:2502.07948v2 Announce Type: replace-cross 
Abstract: Modeling has become a widespread, useful tool in mathematics applied to diverse fields, from physics to economics to biomedicine. Practitioners of modeling may use algebraic or differential equations, to the elements of which they attribute an intuitive relationship with some relevant aspect of reality they wish to represent. More sophisticated expressions may include stochasticity, either as observation error or system noise. However, a clear, unambiguous mathematical definition of what a model is and of what is the relationship between the model and the real-life phenomena it purports to represent has so far not been formulated. The present work aims to fill this gap, motivating the definition of a mathematical model as an operator on a Hilbert space of random variables, identifying the experimental realization as the map between the theoretical space of model construction and the computational space of statistical model identification, and tracing the relationship of the geometry of the model manifold in the abstract setting with the corresponding geometry of the prediction surfaces in statistical estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07948v2</guid>
      <category>stat.OT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andrea De Gaetano</dc:creator>
    </item>
    <item>
      <title>Convergence-divergence models: Generalizations of phylogenetic trees modeling gene flow over time</title>
      <link>https://arxiv.org/abs/2504.07384</link>
      <description>arXiv:2504.07384v2 Announce Type: replace-cross 
Abstract: Phylogenetic trees are simple models of evolutionary processes. They describe conditionally independent divergent evolution from common ancestors. However, they often lack the flexibility to represent processes like introgressive hybridization, which leads to gene flow between taxa. Phylogenetic networks generalize trees but typically assume that ancestral taxa merge instantaneously to form ``hybrid'' descendants. In contrast, convergence-divergence models retain a single underlying ``principal tree'' and permit gene flow over arbitrary time frames. They can also model other biological processes leading to taxa becoming more similar, such as replicated evolution. We present novel maximum likelihood algorithms to infer most aspects of $N$-taxon convergence-divergence models - many consistently - using a quartet-based approach. All algorithms use $4$-taxon convergence-divergence models, inferred from subsets of the $N$ taxa using a model selection criterion. The first algorithm infers an $N$-taxon principal tree; the second infers sets of converging taxa; and the third infers model parameters - root probabilities, edge lengths and convergence parameters. The algorithms can be applied to multiple sequence alignments restricted to genes or genomic windows or to gene presence/absence datasets. We demonstrate that convergence-divergence models can be accurately recovered from simulated data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07384v2</guid>
      <category>q-bio.PE</category>
      <category>math.ST</category>
      <category>q-bio.QM</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan D. Mitchell, Barbara R. Holland</dc:creator>
    </item>
    <item>
      <title>Regularized least squares learning with heavy-tailed noise is minimax optimal</title>
      <link>https://arxiv.org/abs/2505.14214</link>
      <description>arXiv:2505.14214v3 Announce Type: replace-cross 
Abstract: This paper examines the performance of ridge regression in reproducing kernel Hilbert spaces in the presence of noise that exhibits a finite number of higher moments. We establish excess risk bounds consisting of subgaussian and polynomial terms based on the well known integral operator framework. The dominant subgaussian component allows to achieve convergence rates that have previously only been derived under subexponential noise - a prevalent assumption in related work from the last two decades. These rates are optimal under standard eigenvalue decay conditions, demonstrating the asymptotic robustness of regularized least squares against heavy-tailed noise. Our derivations are based on a Fuk-Nagaev inequality for Hilbert-space valued random variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14214v3</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mattes Mollenhauer, Nicole M\"ucke, Dimitri Meunier, Arthur Gretton</dc:creator>
    </item>
    <item>
      <title>Fisher-Rao distances between finite-energy signals in Gaussian noise</title>
      <link>https://arxiv.org/abs/2505.14611</link>
      <description>arXiv:2505.14611v2 Announce Type: replace-cross 
Abstract: This paper proposes representing finite-energy signals observed within a given bandwidth as parameters of a probability distribution and employing the information-geometric framework to compute the Fisher-Rao distance between these signals, considered as distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14611v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Franck Florin</dc:creator>
    </item>
    <item>
      <title>Sample complexity of optimal transport barycenters with discrete support</title>
      <link>https://arxiv.org/abs/2505.21274</link>
      <description>arXiv:2505.21274v2 Announce Type: replace-cross 
Abstract: Computational implementation of optimal transport barycenters for a set of target probability measures requires a form of approximation, a widespread solution being empirical approximation of measures. We provide an $O(\sqrt{N/n})$ statistical generalization bounds for the empirical sparse optimal transport barycenters problem, where $N$ is the maximum cardinality of the barycenter (sparse support) and $n$ is the sample size of the target measures empirical approximation. Our analysis includes various optimal transport divergences including Wasserstein, Sinkhorn and Sliced-Wasserstein. We discuss the application of our result to specific settings including K-means, constrained K-means, free and fixed support Wasserstein barycenters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21274v2</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>L\'eo Portales, Edouard Pauwels, Elsa Cazelles</dc:creator>
    </item>
    <item>
      <title>Spectra of high-dimensional sparse random geometric graphs</title>
      <link>https://arxiv.org/abs/2507.06556</link>
      <description>arXiv:2507.06556v2 Announce Type: replace-cross 
Abstract: We analyze the spectral properties of the high-dimensional random geometric graph $\mathcal G(n, d, p)$, formed by sampling $n$ i.i.d vectors $\{v_i\}_{i=1}^{n}$ uniformly on a $d$-dimensional unit sphere and connecting each pair $\{i,j\}$ whenever $\langle v_i, v_j \rangle \geq \tau$ so that $p=\mathbb P(\langle v_i,v_j\rangle \geq \tau)$. This model defines a nonlinear random matrix ensemble with dependent entries. We show that if $d =\omega( np\log^{2}(1/p))$ and $np\to\infty$, the limiting spectral distribution of the normalized adjacency matrix $\frac{A}{\sqrt{np(1-p)}}$ is the semicircle law. To our knowledge, this is the first such result for $G(n, d, p)$ in the sparse regime. In the constant sparsity case $p=\alpha/n$, we further show that if $d=\omega(\log^2(n))$ the limiting spectral distribution of $A$ in $G(n,\alpha/n)$ coincides with that of the Erd\H{o}s-R\'{e}nyi graph $\mathcal G(n,\alpha/n)$.
  Our approach combines the classical moment method in random matrix theory with a novel recursive decomposition of closed-walk graphs, leveraging block-cut trees and ear decompositions, to control the moments of the empirical spectral distribution. A refined high trace analysis further yields a near-optimal bound on the second eigenvalue when $np=\Omega(\log^4 (n))$, removing technical conditions previously imposed in (Liu et al. 2023). As an application, we demonstrate that this improved eigenvalue bound sharpens the parameter requirements on $d$ and $p$ for spontaneous synchronization on random geometric graphs in (Abdalla et al. 2024) under the homogeneous Kuramoto model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06556v2</guid>
      <category>math.PR</category>
      <category>math.CO</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Cao, Yizhe Zhu</dc:creator>
    </item>
  </channel>
</rss>
