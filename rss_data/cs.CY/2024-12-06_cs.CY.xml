<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Dec 2024 05:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Back-filling Missing Data When Predicting Domestic Electricity Consumption From Smart Meter Data</title>
      <link>https://arxiv.org/abs/2412.03574</link>
      <description>arXiv:2412.03574v1 Announce Type: new 
Abstract: This study uses data from domestic electricity smart meters to estimate annual electricity bills for a whole year. We develop a method for back-filling data smart meter for up to six missing months for users who have less than one year of smart meter data, ensuring reliable estimates of annual consumption. We identify five distinct electricity consumption user profiles for homes based on day, night, and peak usage patterns, highlighting the economic advantages of Time-of-Use (ToU) tariffs over fixed tariffs for most users, especially those with higher nighttime consumption. Ultimately, the results of this study empowers consumers to manage their energy use effectively and to make informed choices regarding electricity tariff plans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03574v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xianjuan Chen, Shuxiang Cai, Alan F. Smeaton</dc:creator>
    </item>
    <item>
      <title>Ethical Challenges and Evolving Strategies in the Integration of Artificial Intelligence into Clinical Practice</title>
      <link>https://arxiv.org/abs/2412.03576</link>
      <description>arXiv:2412.03576v1 Announce Type: new 
Abstract: Artificial intelligence (AI) has rapidly transformed various sectors, including healthcare, where it holds the potential to revolutionize clinical practice and improve patient outcomes. However, its integration into medical settings brings significant ethical challenges that need careful consideration. This paper examines the current state of AI in healthcare, focusing on five critical ethical concerns: justice and fairness, transparency, patient consent and confidentiality, accountability, and patient-centered and equitable care. These concerns are particularly pressing as AI systems can perpetuate or even exacerbate existing biases, often resulting from non-representative datasets and opaque model development processes. The paper explores how bias, lack of transparency, and challenges in maintaining patient trust can undermine the effectiveness and fairness of AI applications in healthcare. In addition, we review existing frameworks for the regulation and deployment of AI, identifying gaps that limit the widespread adoption of these systems in a just and equitable manner. Our analysis provides recommendations to address these ethical challenges, emphasizing the need for fairness in algorithm design, transparency in model decision-making, and patient-centered approaches to consent and data privacy. By highlighting the importance of continuous ethical scrutiny and collaboration between AI developers, clinicians, and ethicists, we outline pathways for achieving more responsible and inclusive AI implementation in healthcare. These strategies, if adopted, could enhance both the clinical value of AI and the trustworthiness of AI systems among patients and healthcare professionals, ensuring that these technologies serve all populations equitably.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03576v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ellison B. Weiner, Irene Dankwa-Mullan, William A. Nelson, Saeed Hassanpour</dc:creator>
    </item>
    <item>
      <title>Towards a Practical Ethics of Generative AI in Creative Production Processes</title>
      <link>https://arxiv.org/abs/2412.03579</link>
      <description>arXiv:2412.03579v1 Announce Type: new 
Abstract: The increasing integration of artificial intelligence into various domains, including design and creative processes, raises significant ethical questions. While AI ethics is often examined from the perspective of technology developers, less attention has been paid to the practical ethical considerations faced by technology users, particularly in design contexts. This paper introduces a framework for addressing ethical challenges in creative production processes, such as the Double Diamond design model. Drawing on six major ethical theories - virtue ethics, deontology, utilitarianism, contract theory, care ethics, and existentialism - we develop a "compass" to navigate and reflect on the ethical dimensions of AI in design. The framework highlights the importance of responsibility, anticipation, and reflection across both the AI lifecycle and each stage of the creative process. We argue that by adopting a playful and exploratory approach to AI, while remaining anchored in core ethical principles, designers can responsibly harness the potential of AI technologies without overburdening or compromising their creative processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03579v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Geert Hofman</dc:creator>
    </item>
    <item>
      <title>Exploring Non-Linear Effects of Built Environment on Travel Using an Integrated Machine Learning and Inferential Modeling Approach: A Three-Wave Repeated Cross-Sectional Study</title>
      <link>https://arxiv.org/abs/2412.03582</link>
      <description>arXiv:2412.03582v1 Announce Type: new 
Abstract: This study investigates the dynamic relationship between the built environment and travel in Austin, Texas, over a 20-year period. Using three waves of household travel surveys from 1997, 2006, and 2017, the research employs a repeated cross-sectional approach to address the limitations of traditional longitudinal and cross-sectional studies. Methodologically, it integrates machine learning and inferential modeling to uncover non-linear relationships and threshold effects of built environment characteristics on travel. Findings reveal that the built environment serves as a sustainable tool for managing travel in the long term, contributing 50% or more to the total feature importance in predicting individual travel-surpassing the combined effects of personal and household characteristics. Increased transit accessibility, local and regional destination accessibility, population and employment density, and diversity significantly reduce travel, particularly within their identified thresholds, though the magnitude of their influence varies across time periods. These findings highlight the potential of smart growth policies-such as expanding transit accessibility, promoting high-density and mixed-use development, and discouraging single-use development and peripheral sprawl-as effective strategies to reduce car dependency and manage travel demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03582v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niaz Mahmud Zafri, Ming Zhang</dc:creator>
    </item>
    <item>
      <title>Assessing Changes in Thinking about Troubleshooting in Physical Computing: A Clinical Interview Protocol with Failure Artifacts Scenarios</title>
      <link>https://arxiv.org/abs/2412.03687</link>
      <description>arXiv:2412.03687v1 Announce Type: new 
Abstract: Purpose: The purpose of this paper is to examine how a clinical interview protocol with failure artifact scenarios can capture changes in high school students' explanations of troubleshooting processes in physical computing activities. We focus on physical computing since finding and fixing hardware and software bugs is a highly contextual practice that involves multiple interconnected domains and skills. Approach: We developed and piloted a "failure artifact scenarios" clinical interview protocol. Youth were presented with buggy physical computing projects over video calls and asked for suggestions on how to fix them without having access to the actual project or its code. We applied this clinical interview protocol before and after an eight-week-long physical computing (more specifically, electronic textiles) unit. We analyzed matching pre- and post-interviews from 18 students at four different schools. Findings: Our findings demonstrate how the protocol can capture change in students' thinking about troubleshooting by eliciting students' explanations of specificity of domain knowledge of problems, multimodality of physical computing, iterative testing of failure artifact scenarios, and concreteness of troubleshooting and problem solving processes. Originality: Beyond tests and surveys used to assess debugging, which traditionally focus on correctness or student beliefs, our "failure artifact scenarios" clinical interview protocol reveals student troubleshooting-related thinking processes when encountering buggy projects. As an assessment tool, it may be useful to evaluate the change and development of students' abilities over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03687v1</guid>
      <category>cs.CY</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luis Morales-Navarro, Deborah A. Fields, Yasmin B. Kafai, Deepali Barapatre</dc:creator>
    </item>
    <item>
      <title>A Multi-agent Simulation for the Mass School Shootings</title>
      <link>https://arxiv.org/abs/2412.03882</link>
      <description>arXiv:2412.03882v1 Announce Type: new 
Abstract: The increasing frequency of mass school shootings in the United States has been raised as a critical concern. Active shooters kill innocent students and educators in schools. These tragic events highlight the urgent need for effective strategies to minimize casualties. This study aims to address the challenge of simulating and assessing potential mitigation measures by developing a multi-agent simulation model. Our model is designed to estimate casualty rates and evacuation efficiency during active shooter scenarios within school buildings. The simulation evaluates the impact of a gun detection system on safety outcomes. By simulating school shooting incidents with and without this system, we observe a significant improvement in evacuation rates, which increased from 16.6% to 66.6%. Furthermore, the Gun Detection System reduced the average casualty rate from 24.0% to 12.2% within a period of six minutes, based on a simulated environment with 100 students. We conducted a total of 48 simulations across three different floor layouts, varying the number of students and time intervals to assess the system's adaptability. We anticipate that the research will provide a starting point for demonstrating that a gunshot detection system can significantly improve both evacuation rates and casualty reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03882v1</guid>
      <category>cs.CY</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Dai, Yash Singh, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Artificial intelligence and the internal processes of creativity</title>
      <link>https://arxiv.org/abs/2412.04366</link>
      <description>arXiv:2412.04366v1 Announce Type: new 
Abstract: Artificial intelligence (AI) systems capable of generating creative outputs are reshaping our understanding of creativity. This shift presents an opportunity for creativity researchers to reevaluate the key components of the creative process. In particular, the advanced capabilities of AI underscore the importance of studying the internal processes of creativity. This paper explores the neurobiological machinery that underlies these internal processes and describes the experiential component of creativity. It is concluded that although the products of artificial and human creativity can be similar, the internal processes are different. The paper also discusses how AI may negatively affect the internal processes of human creativity, such as the development of skills, the integration of knowledge, and the diversity of ideas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04366v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jaan Aru</dc:creator>
    </item>
    <item>
      <title>A Water Efficiency Dataset for African Data Centers</title>
      <link>https://arxiv.org/abs/2412.03716</link>
      <description>arXiv:2412.03716v1 Announce Type: cross 
Abstract: AI computing and data centers consume a large amount of freshwater, both directly for cooling and indirectly for electricity generation. While most attention has been paid to developed countries such as the U.S., this paper presents the first-of-its-kind dataset that combines nation-level weather and electricity generation data to estimate water usage efficiency for data centers in 41 African countries across five different climate regions. We also use our dataset to evaluate and estimate the water consumption of inference on two large language models (i.e., Llama-3-70B and GPT-4) in 11 selected African countries. Our findings show that writing a 10-page report using Llama-3-70B could consume about \textbf{0.7 liters} of water, while the water consumption by GPT-4 for the same task may go up to about 60 liters. For writing a medium-length email of 120-200 words, Llama-3-70B and GPT-4 could consume about \textbf{0.13 liters} and 3 liters of water, respectively. Interestingly, given the same AI model, 8 out of the 11 selected African countries consume less water than the global average, mainly because of lower water intensities for electricity generation. However, water consumption can be substantially higher in some African countries with a steppe climate than the U.S. and global averages, prompting more attention when deploying AI computing in these countries. Our dataset is publicly available on \href{https://huggingface.co/datasets/masterlion/WaterEfficientDatasetForAfricanCountries/tree/main}{Hugging Face}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03716v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Noah Shumba, Opelo Tshekiso, Pengfei Li, Giulia Fanti, Shaolei Ren</dc:creator>
    </item>
    <item>
      <title>A Benchmark for Math Misconceptions: Bridging Gaps in Middle School Algebra with AI-Supported Instruction</title>
      <link>https://arxiv.org/abs/2412.03765</link>
      <description>arXiv:2412.03765v1 Announce Type: cross 
Abstract: This study introduces an evaluation benchmark for middle school algebra to be used in artificial intelligence(AI) based educational platforms. The goal is to support the design of AI systems that can enhance learner conceptual understanding of algebra by taking into account their current level of algebra comprehension. The data set comprises 55 misconceptions about algebra, common errors, and 220 diagnostic examples identified in previous peer-reviewed studies. We provide an example application using a large language model, observing a range of precision and recall scores depending on the topic and experimental setup that reaches 83.9% when including educator feedback and restricting it by topic. We found that topics such as ratios and proportions prove as difficult for LLMs as they are for students. We included a human assessment of LLMs results and feedback from five middle school math educators on the clarity and occurrence of misconceptions in the dataset and the potential use of AI in conjunction with the dataset. Most educators (80% or more) indicated that they encounter these misconceptions among their students, suggesting the relevance of the data set to teaching middle school algebra. Despite varying familiarity with AI tools, four out of five educators expressed interest in using the data set with AI to diagnose student misconceptions or train teachers. The results emphasize the importance of topic-constrained testing, the need for multimodal approaches, and the relevance of human expertise to gain practical insights when using AI for human learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03765v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Otero Nancy, Druga Stefania, Lan Andrew</dc:creator>
    </item>
    <item>
      <title>Prompt Engineering Guidance for Conceptual Agent-based Model Extraction using Large Language Models</title>
      <link>https://arxiv.org/abs/2412.04056</link>
      <description>arXiv:2412.04056v1 Announce Type: cross 
Abstract: This document contains detailed information about the prompts used in the experimental process discussed in the paper "Toward Automating Agent-based Model Generation: A Benchmark for Model Extraction using Question-Answering Techniques". The paper aims to utilize Question-answering (QA) models to extract the necessary information to implement Agent-based Modeling (ABM) from conceptual models. It presents the extracted information in formats that can be read by both humans and computers (i.e., JavaScript Object Notation (JSON)), enabling manual use by humans and auto-code generation by Large Language Models (LLM).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04056v1</guid>
      <category>cs.MA</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siamak Khatami, Christopher Frantz</dc:creator>
    </item>
    <item>
      <title>Towards Comprehensive Legislative Requirements for Cyber Physical Systems Testing in the European Union</title>
      <link>https://arxiv.org/abs/2412.04132</link>
      <description>arXiv:2412.04132v1 Announce Type: cross 
Abstract: While procedures prevail on the European market for the greater good of its citizens, it might be daunting when trying to introduce a product, whether innovative or not. In the current world, Cyber-Physical Systems (CPSs) are ubiquitous in our daily lives. Cars can provide intrusive assistance as they can brake or turn wheels on their own, buildings are getting smarter to optimize energy consumption, smart cities are emerging to facilitate information sharing and orchestrate the response to emergency situations, etc. As the presence of such tools will grow in the coming years and people will rely even more on CPSs, we certainly need to ensure that they are safe and reliable for users or everybody else, which is why regulations are so important. However, compliance should not act as a barrier to new actors coming to the European market. Nor should it prevent current actors from keeping systems deemed compliant when introduced while obsolete at the time they are used. While the individual elements we point out might not bring novelty in the various research areas we cover (EU policies, requirements engineering, business engineering, and software engineering), this paper identifies the challenges related to building and testing a CPS with respect to applicable laws and discusses the difficulty of automating the response to those challenges, such as finding a relevant legal text, paying for mentioned materials or identifying the level of compliance to a legal text. Our analysis of the holistic context when considering the compliance testing of CPS provides an overview enabling more effective decision-making as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04132v1</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Nguyen, Manon Knockaert, Michael Lognoul, Xavier Devroey</dc:creator>
    </item>
    <item>
      <title>Understanding Student Sentiment on Mental Health Support in Colleges Using Large Language Models</title>
      <link>https://arxiv.org/abs/2412.04326</link>
      <description>arXiv:2412.04326v1 Announce Type: cross 
Abstract: Mental health support in colleges is vital in educating students by offering counseling services and organizing supportive events. However, evaluating its effectiveness faces challenges like data collection difficulties and lack of standardized metrics, limiting research scope. Student feedback is crucial for evaluation but often relies on qualitative analysis without systematic investigation using advanced machine learning methods. This paper uses public Student Voice Survey data to analyze student sentiments on mental health support with large language models (LLMs). We created a sentiment analysis dataset, SMILE-College, with human-machine collaboration. The investigation of both traditional machine learning methods and state-of-the-art LLMs showed the best performance of GPT-3.5 and BERT on this new dataset. The analysis highlights challenges in accurately predicting response sentiments and offers practical insights on how LLMs can enhance mental health-related research and improve college mental health services. This data-driven approach will facilitate efficient and informed mental health support evaluation, management, and decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04326v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Palak Sood, Chengyang He, Divyanshu Gupta, Yue Ning, Ping Wang</dc:creator>
    </item>
    <item>
      <title>User-item fairness tradeoffs in recommendations</title>
      <link>https://arxiv.org/abs/2412.04466</link>
      <description>arXiv:2412.04466v1 Announce Type: cross 
Abstract: In the basic recommendation paradigm, the most (predicted) relevant item is recommended to each user. This may result in some items receiving lower exposure than they "should"; to counter this, several algorithmic approaches have been developed to ensure item fairness. These approaches necessarily degrade recommendations for some users to improve outcomes for items, leading to user fairness concerns. In turn, a recent line of work has focused on developing algorithms for multi-sided fairness, to jointly optimize user fairness, item fairness, and overall recommendation quality. This induces the question: what is the tradeoff between these objectives, and what are the characteristics of (multi-objective) optimal solutions? Theoretically, we develop a model of recommendations with user and item fairness objectives and characterize the solutions of fairness-constrained optimization. We identify two phenomena: (a) when user preferences are diverse, there is "free" item and user fairness; and (b) users whose preferences are misestimated can be especially disadvantaged by item fairness constraints. Empirically, we prototype a recommendation system for preprints on arXiv and implement our framework, measuring the phenomena in practice and showing how these phenomena inform the design of markets with recommendation systems-intermediated matching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04466v1</guid>
      <category>cs.IR</category>
      <category>cs.CY</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sophie Greenwood, Sudalakshmee Chiniah, Nikhil Garg</dc:creator>
    </item>
    <item>
      <title>LLM-Mirror: A Generated-Persona Approach for Survey Pre-Testing</title>
      <link>https://arxiv.org/abs/2412.03162</link>
      <description>arXiv:2412.03162v2 Announce Type: replace 
Abstract: Surveys are widely used in social sciences to understand human behavior, but their implementation often involves iterative adjustments that demand significant effort and resources. To this end, researchers have increasingly turned to large language models (LLMs) to simulate human behavior. While existing studies have focused on distributional similarities, individual-level comparisons remain underexplored. Building upon prior work, we investigate whether providing LLMs with respondents' prior information can replicate both statistical distributions and individual decision-making patterns using Partial Least Squares Structural Equation Modeling (PLS-SEM), a well-established causal analysis method. We also introduce the concept of the LLM-Mirror, user personas generated by supplying respondent-specific information to the LLM. By comparing responses generated by the LLM-Mirror with actual individual survey responses, we assess its effectiveness in replicating individual-level outcomes. Our findings show that: (1) PLS-SEM analysis shows LLM-generated responses align with human responses, (2) LLMs, when provided with respondent-specific information, are capable of reproducing individual human responses, and (3) LLM-Mirror responses closely follow human responses at the individual level. These findings highlight the potential of LLMs as a complementary tool for pre-testing surveys and optimizing research design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03162v2</guid>
      <category>cs.CY</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sunwoong Kim, Jongho Jeong, Jin Soo Han, Donghyuk Shin</dc:creator>
    </item>
    <item>
      <title>The Market Consequences of Perceived Strategic Generosity: An Empirical Examination of NFT Charity Fundraisers</title>
      <link>https://arxiv.org/abs/2401.12064</link>
      <description>arXiv:2401.12064v2 Announce Type: replace-cross 
Abstract: Crypto donations now represent a significant fraction of charitable giving worldwide. Nonfungible token (NFT) charity fundraisers, which involve the sale of NFTs of artistic works with the proceeds donated to philanthropic causes, have emerged as a novel development in this space. A unique aspect of NFT charity fundraisers is the significant potential for donors to reap financial gains from the rising value of purchased NFTs. Questions may arise about donors' motivations in these charity fundraisers, potentially resulting in a negative social image. NFT charity fundraisers thus offer a unique opportunity to understand the economic consequences of a donor's social image. We investigate these effects in the context of a large NFT charity fundraiser. We identify the causal effect of purchasing an NFT within the charity fundraiser on a donor's later market outcomes by leveraging random variation in transaction processing times on the blockchain. Further, we demonstrate a clear pattern of heterogeneity based on an individual's decision to relist (versus hold) the purchased charity NFTs (a sign of perceived strategic generosity) and based on an individual's social exposure within the NFT marketplace. We show that charity-NFT 're-listers' experience significant penalties in the market regarding the prices they can command for their other NFTs, particularly among those who are more socially exposed. Finally, we report the results of a scenario-based online experiment, which again support our findings, highlighting that the re-listing a charity NFT for sale at a profit leads others to perceive their initial donation as strategic generosity and reduces those others' willingness to purchase NFTs from the donor. Our study underscores the growing importance of digital visibility and traceability, features that characterize crypto-philanthropy, and online philanthropy more broadly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12064v2</guid>
      <category>econ.GN</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 06 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chen Liang, Murat Tunc, Gordon Burtch</dc:creator>
    </item>
  </channel>
</rss>
