<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 May 2024 01:44:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 29 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Container pre-marshalling problem minimizing CV@R under uncertainty of ship arrival times</title>
      <link>https://arxiv.org/abs/2405.17576</link>
      <description>arXiv:2405.17576v1 Announce Type: new 
Abstract: This paper is concerned with the container pre-marshalling problem, which involves relocating containers in the storage area so that they can be efficiently loaded onto ships without reshuffles. In reality, however, ship arrival times are affected by various external factors, which can cause the order of container retrieval to be different from the initial plan. To represent such uncertainty, we generate multiple scenarios from a multivariate probability distribution of ship arrival times. We derive a mixed-integer linear optimization model to find an optimal container layout such that the conditional value-at-risk is minimized for the number of misplaced containers responsible for reshuffles. Moreover, we devise an exact algorithm based on the cutting-plane method to handle large-scale problems. Numerical experiments using synthetic datasets demonstrate that our method can produce high-quality container layouts compared with the conventional robust optimization model. Additionally, our algorithm can speed up the computation of solving large-scale problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17576v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daiki Ikuma, Shunnosuke Ikeda, Noriyoshi Sukegawa, Yuichi Takano</dc:creator>
    </item>
    <item>
      <title>Adjustable Robust Nonlinear Network Design under Demand Uncertainties</title>
      <link>https://arxiv.org/abs/2405.17867</link>
      <description>arXiv:2405.17867v1 Announce Type: new 
Abstract: We study network design problems for nonlinear and nonconvex flow models under demand uncertainties. To this end, we apply the concept of adjustable robust optimization to compute a network design that admits a feasible transport for all, possibly infinitely many, demand scenarios within a given uncertainty set. For solving the corresponding adjustable robust mixed-integer nonlinear optimization problem, we show that a given network design is robust feasible, i.e., it admits a feasible transport for all demand uncertainties, if and only if a finite number of worst-case demand scenarios can be routed through the network. We compute these worst-case scenarios by solving polynomially many nonlinear optimization problems. Embedding this result for robust feasibility in an adversarial approach leads to an exact algorithm that computes an optimal robust network design in a finite number of iterations. Since all of the results are valid for general potential-based flows, the approach can be applied to different utility networks such as gas, hydrogen, or water networks. We finally demonstrate the applicability of the method by computing robust gas networks that are protected from future demand fluctuations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17867v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Th\"urauf, Julia Gr\"ubel, Martin Schmidt</dc:creator>
    </item>
    <item>
      <title>BO4IO: A Bayesian optimization approach to inverse optimization with uncertainty quantification</title>
      <link>https://arxiv.org/abs/2405.17875</link>
      <description>arXiv:2405.17875v1 Announce Type: new 
Abstract: This work addresses data-driven inverse optimization (IO), where the goal is to estimate unknown parameters in an optimization model from observed decisions that can be assumed to be optimal or near-optimal solutions to the optimization problem. The IO problem is commonly formulated as a large-scale bilevel program that is notoriously difficult to solve. Deviating from traditional exact solution methods, we propose a derivative-free optimization approach based on Bayesian optimization, which we call BO4IO, to solve general IO problems. We treat the IO loss function as a black box and approximate it with a Gaussian process model. Using the predicted posterior function, an acquisition function is minimized at each iteration to query new candidate solutions and sequentially converge to the optimal parameter estimates. The main advantages of using Bayesian optimization for IO are two-fold: (i) it circumvents the need of complex reformulations of the bilevel program or specialized algorithms and can hence enable computational tractability even when the underlying optimization problem is nonconvex or involves discrete variables, and (ii) it allows approximations of the profile likelihood, which provide uncertainty quantification on the IO parameter estimates. We apply the proposed method to three computational case studies, covering different classes of forward optimization problems ranging from convex nonlinear to nonconvex mixed-integer nonlinear programs. Our extensive computational results demonstrate the efficacy and robustness of BO4IO to accurately estimate unknown model parameters from small and noisy datasets. In addition, the proposed profile likelihood analysis has proven to be effective in providing good approximations of the confidence intervals on the parameter estimates and assessing the identifiability of the unknown parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17875v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yen-An Lu, Wei-Shou Hu, Joel A. Paulson, Qi Zhang</dc:creator>
    </item>
    <item>
      <title>Data-Driven Predictive Control and MPC: Do we achieve optimality?</title>
      <link>https://arxiv.org/abs/2405.17892</link>
      <description>arXiv:2405.17892v1 Announce Type: new 
Abstract: In this paper, we explore the interplay between Predictive Control and closed-loop optimality, spanning from Model Predictive Control to Data-Driven Predictive Control. Predictive Control in general relies on some form of prediction scheme on the real system trajectories. However, these predictions may not accurately capture the real system dynamics, for e.g., due to stochasticity, resulting in sub-optimal control policies. This lack of optimality is a critical issue in case of problems with economic objectives. We address this by providing sufficient conditions on the underlying prediction scheme such that a Predictive Controller can achieve closed-loop optimality. However, these conditions do not readily extend to Data-Driven Predictive Control. In this context of closed-loop optimality, we conclude that the factor distinguishing the approaches within Data-Driven Predictive Control is if they can be cast as a sequential decision-making process or not, rather than the dichotomy of model-based vs. model-free. Furthermore, we show that the conventional approach of improving the prediction accuracy from data may not guarantee optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17892v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Akhil S Anand, Shambhuraj Sawant, Dirk Reinhardt, Sebastien Gros</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimization Schemes for Performative Prediction with Nonconvex Loss</title>
      <link>https://arxiv.org/abs/2405.17922</link>
      <description>arXiv:2405.17922v1 Announce Type: new 
Abstract: This paper studies a risk minimization problem with decision dependent data distribution. The problem pertains to the performative prediction setting where a trained model can affect the outcome that the model estimates. Such dependency creates a feedback loop that influences the stability of optimization algorithms such as stochastic gradient descent (SGD). We present the first study on performative prediction with smooth but possibly non-convex loss. We analyze a greedy deployment scheme with SGD (SGD-GD). Note that in the literature, SGD-GD is often studied with strongly convex loss. We first propose the definition of stationary performative stable (SPS) solutions through relaxing the popular performative stable condition. We then prove that SGD-GD converges to a biased SPS solution in expectation. We consider two conditions of sensitivity on the distribution shifts: (i) the sensitivity is characterized by Wasserstein-1 distance and the loss is Lipschitz w.r.t.~data samples, or (ii) the sensitivity is characterized by $\chi^2$-divergence and the loss is bounded. In both conditions, the bias levels are proportional to stochastic gradient's variance and sensitivity level. Our analysis is extended to a lazy deployment scheme where models are deployed once per several SGD updates, and we show that it converges to a bias-free SPS solution. Numerical experiments corroborate our theories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17922v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Li, Hoi-To Wai</dc:creator>
    </item>
    <item>
      <title>Lower Bounds and Optimal Algorithms for Non-Smooth Convex Decentralized Optimization over Time-Varying Networks</title>
      <link>https://arxiv.org/abs/2405.18031</link>
      <description>arXiv:2405.18031v1 Announce Type: new 
Abstract: We consider the task of minimizing the sum of convex functions stored in a decentralized manner across the nodes of a communication network. This problem is relatively well-studied in the scenario when the objective functions are smooth, or the links of the network are fixed in time, or both. In particular, lower bounds on the number of decentralized communications and (sub)gradient computations required to solve the problem have been established, along with matching optimal algorithms. However, the remaining and most challenging setting of non-smooth decentralized optimization over time-varying networks is largely underexplored, as neither lower bounds nor optimal algorithms are known in the literature. We resolve this fundamental gap with the following contributions: (i) we establish the first lower bounds on the communication and subgradient computation complexities of solving non-smooth convex decentralized optimization problems over time-varying networks; (ii) we develop the first optimal algorithm that matches these lower bounds and offers substantially improved theoretical performance compared to the existing state of the art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18031v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitry Kovalev, Ekaterina Borodich, Alexander Gasnikov, Dmitrii Feoktistov</dc:creator>
    </item>
    <item>
      <title>Coupling Analysis of the Asymptotic Behaviour of a Primal-Dual Langevin Algorithm</title>
      <link>https://arxiv.org/abs/2405.18098</link>
      <description>arXiv:2405.18098v2 Announce Type: new 
Abstract: We analyze a recently proposed algorithm for the problem of sampling from probability distributions $\mu^\ast$ in $\mathbb{R}^d$ with a Lebesgue density of the form $\mu^\ast(x) \propto \exp(-f(Kx)-g(x))$, where $K$ is a linear operator and $f,g$ convex and non-smooth. The algorithm is a generalization of the primal-dual hybrid gradient (PDHG) convex optimization algorithm to a sampling scheme. We analyze the method's continuous time limit, an SDE in the joint primal-dual variable. We give mild conditions under which the corresponding Fokker-Planck equation converges to a unique stationary state, which however does not concentrate in the dual variable and consequently does not have $\mu^\ast$ as its primal marginal. Under a smoothness assumption on $f$, we show that the scheme converges to the purely primal overdamped Langevin diffusion in the limit of small primal and large dual step sizes. We further prove that the target can never be the primal marginal of the invariant solution for any modification of the SDE with space-homogeneous diffusion coefficient. A correction with inhomogeneous diffusion coefficient and the correct invariant solution is proposed, but the scheme requires the same smoothness assumptions on $f$ and is numerically inferior to overdamped Langevin diffusion. We demonstrate our findings numerically, first on small-scale examples in which we can exactly verify the theoretical results, and subsequently on typical examples of larger scale from Bayesian imaging inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18098v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Burger, Matthias J. Ehrhardt, Lorenz Kuger, Lukas Weigand</dc:creator>
    </item>
    <item>
      <title>Data-Driven Distributionally Robust System Level Synthesis</title>
      <link>https://arxiv.org/abs/2405.18142</link>
      <description>arXiv:2405.18142v1 Announce Type: new 
Abstract: We present a novel approach for the control of uncertain, linear time-invariant systems, which are perturbed by potentially unbounded, additive disturbances. We propose a \emph{doubly robust} data-driven state-feedback controller to ensure reliable performance against both model mismatch and disturbance distribution uncertainty. Our controller, which leverages the System Level Synthesis parameterization, is designed as the solution to a distributionally robust finite-horizon optimal control problem. The goal is to minimize a cost function while satisfying constraints against the worst-case realization of the uncertainty, which is quantified using distributional ambiguity sets. The latter are defined as balls in the Wasserstein metric centered on the predictive empirical distribution computed from a set of collected trajectory data. By harnessing techniques from robust control and distributionally robust optimization, we characterize the distributional shift between the predictive and the actual closed-loop distributions, and highlight its dependency on the model mismatch and the uncertainty about the disturbance distribution. We also provide bounds on the number of samples required to achieve a desired confidence level and propose a tractable approximate formulation for the doubly robust data-driven controller. To demonstrate the effectiveness of our approach, we present a numerical example showcasing the performance of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18142v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesco Micheli, Anastasios Tsiamis, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Recurrent Natural Policy Gradient for POMDPs</title>
      <link>https://arxiv.org/abs/2405.18221</link>
      <description>arXiv:2405.18221v1 Announce Type: new 
Abstract: In this paper, we study a natural policy gradient method based on recurrent neural networks (RNNs) for partially-observable Markov decision processes, whereby RNNs are used for policy parameterization and policy evaluation to address curse of dimensionality in non-Markovian reinforcement learning. We present finite-time and finite-width analyses for both the critic (recurrent temporal difference learning), and correspondingly-operated recurrent natural policy gradient method in the near-initialization regime. Our analysis demonstrates the efficiency of RNNs for problems with short-term memory with explicit bounds on the required network widths and sample complexity, and points out the challenges in the case of long-term dependencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18221v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Semih Cayci, Atilla Eryilmaz</dc:creator>
    </item>
    <item>
      <title>Synchronization on circles and spheres with nonlinear interactions</title>
      <link>https://arxiv.org/abs/2405.18273</link>
      <description>arXiv:2405.18273v1 Announce Type: new 
Abstract: We consider the dynamics of $n$ points on a sphere in $\mathbb{R}^d$ ($d \geq 2$) which attract each other according to a function $\varphi$ of their inner products. When $\varphi$ is linear ($\varphi(t) = t$), the points converge to a common value (i.e., synchronize) in various connectivity scenarios: this is part of classical work on Kuramoto oscillator networks. When $\varphi$ is exponential ($\varphi(t) = e^{\beta t}$), these dynamics correspond to a limit of how idealized transformers process data, as described by Geshkovski et al. (2024). Accordingly, they ask whether synchronization occurs for exponential $\varphi$.
  In the context of consensus for multi-agent control, Markdahl et al. (2018) show that for $d \geq 3$ (spheres), if the interaction graph is connected and $\varphi$ is increasing and convex, then the system synchronizes. What is the situation on circles ($d=2$)? First, we show that $\varphi$ being increasing and convex is no longer sufficient. Then we identify a new condition (that the Taylor coefficients of $\varphi'$ are decreasing) under which we do have synchronization on the circle. In so doing, we provide some answers to the open problems posed by Geshkovski et al. (2024).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18273v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christopher Criscitiello, Quentin Rebjock, Andrew D. McRae, Nicolas Boumal</dc:creator>
    </item>
    <item>
      <title>Geometry of Critical Sets and Existence of Saddle Branches for Two-layer Neural Networks</title>
      <link>https://arxiv.org/abs/2405.17501</link>
      <description>arXiv:2405.17501v1 Announce Type: cross 
Abstract: This paper presents a comprehensive analysis of critical point sets in two-layer neural networks. To study such complex entities, we introduce the critical embedding operator and critical reduction operator as our tools. Given a critical point, we use these operators to uncover the whole underlying critical set representing the same output function, which exhibits a hierarchical structure. Furthermore, we prove existence of saddle branches for any critical set whose output function can be represented by a narrower network. Our results provide a solid foundation to the further study of optimization and training behavior of neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17501v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Leyang Zhang, Yaoyu Zhang, Tao Luo</dc:creator>
    </item>
    <item>
      <title>Fully Subexponential Time Approximation Scheme for Product Partition</title>
      <link>https://arxiv.org/abs/2405.17692</link>
      <description>arXiv:2405.17692v1 Announce Type: cross 
Abstract: In this paper we study the Product Partition Problem (PPP), i.e. we are given a set of $n$ natural numbers represented on $m$ bits each and we are asked if a subset exists such that the product of the numbers in the subset equals the product of the numbers not in the subset. Our approach is to obtain the integer factorization of each number. This is the subexponential step. We then form a matrix with the exponents of the primes and propose a novel procedure which modifies the given numbers in such a way that their integer factorization contains sufficient primes to facilitate the search for the solution to the partition problem, while maintaining a similar product. We show that the required time and memory to run the proposed algorithm is subexponential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17692v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marius Costandin</dc:creator>
    </item>
    <item>
      <title>Tamed Langevin sampling under weaker conditions</title>
      <link>https://arxiv.org/abs/2405.17693</link>
      <description>arXiv:2405.17693v1 Announce Type: cross 
Abstract: Motivated by applications to deep learning which often fail standard Lipschitz smoothness requirements, we examine the problem of sampling from distributions that are not log-concave and are only weakly dissipative, with log-gradients allowed to grow superlinearly at infinity. In terms of structure, we only assume that the target distribution satisfies either a log-Sobolev or a Poincar\'e inequality and a local Lipschitz smoothness assumption with modulus growing possibly polynomially at infinity. This set of assumptions greatly exceeds the operational limits of the "vanilla" unadjusted Langevin algorithm (ULA), making sampling from such distributions a highly involved affair. To account for this, we introduce a taming scheme which is tailored to the growth and decay properties of the target distribution, and we provide explicit non-asymptotic guarantees for the proposed sampler in terms of the Kullback-Leibler (KL) divergence, total variation, and Wasserstein distance to the target distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17693v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iosif Lytras, Panayotis Mertikopoulos</dc:creator>
    </item>
    <item>
      <title>Regression Equilibrium in Electricity Markets</title>
      <link>https://arxiv.org/abs/2405.17753</link>
      <description>arXiv:2405.17753v1 Announce Type: cross 
Abstract: Renewable power producers participating in electricity markets build forecasting models independently, relying on their own data, model and feature preferences. In this paper, we argue that in renewable-dominated markets, such an uncoordinated approach to forecasting results in substantial opportunity costs for stochastic producers and additional operating costs for the power system. As a solution, we introduce Regression Equilibrium--a welfare-optimal state of electricity markets under uncertainty, where profit-seeking stochastic producers do not benefit by unilaterally deviating from their equilibrium forecast models. While the regression equilibrium maximizes the private welfare, i.e., the average profit of stochastic producers across the day-ahead and real-time markets, it also aligns with the socially optimal, least-cost dispatch solution for the system. We base the equilibrium analysis on the theory of variational inequalities, providing results on the existence and uniqueness of regression equilibrium in energy-only markets. We also devise two methods for computing the regression equilibrium: centralized optimization and a decentralized ADMM-based algorithm that preserves the privacy of regression datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17753v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladimir Dvorkin</dc:creator>
    </item>
    <item>
      <title>Double Variance Reduction: A Smoothing Trick for Composite Optimization Problems without First-Order Gradient</title>
      <link>https://arxiv.org/abs/2405.17761</link>
      <description>arXiv:2405.17761v1 Announce Type: cross 
Abstract: Variance reduction techniques are designed to decrease the sampling variance, thereby accelerating convergence rates of first-order (FO) and zeroth-order (ZO) optimization methods. However, in composite optimization problems, ZO methods encounter an additional variance called the coordinate-wise variance, which stems from the random gradient estimation. To reduce this variance, prior works require estimating all partial derivatives, essentially approximating FO information. This approach demands O(d) function evaluations (d is the dimension size), which incurs substantial computational costs and is prohibitive in high-dimensional scenarios. This paper proposes the Zeroth-order Proximal Double Variance Reduction (ZPDVR) method, which utilizes the averaging trick to reduce both sampling and coordinate-wise variances. Compared to prior methods, ZPDVR relies solely on random gradient estimates, calls the stochastic zeroth-order oracle (SZO) in expectation $\mathcal{O}(1)$ times per iteration, and achieves the optimal $\mathcal{O}(d(n + \kappa)\log (\frac{1}{\epsilon}))$ SZO query complexity in the strongly convex and smooth setting, where $\kappa$ represents the condition number and $\epsilon$ is the desired accuracy. Empirical results validate ZPDVR's linear convergence and demonstrate its superior performance over other related methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17761v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Di, Haishan Ye, Yueling Zhang, Xiangyu Chang, Guang Dai, Ivor W. Tsang</dc:creator>
    </item>
    <item>
      <title>A new class of evolution multivalued quasi-variational inequalities I: existence and nonsmooth optimal control</title>
      <link>https://arxiv.org/abs/2405.17810</link>
      <description>arXiv:2405.17810v1 Announce Type: cross 
Abstract: In this paper, we consider a new kind of evolution multivalued quasi-variational inequalities with feedback effect and a nonlinear bifunction which contain several (evolution) quasi-variational/hemivariational inequalities as special cases. The main contribution of this paper is twofold. The first goal is to establish a novel framework for proving the existence of solutions and the compactness of solution set to the evolution multivalued quasi-variational inequalities, under quite mild assumptions. Whereas, the second contribution is to introduce and study a nonlinear and nonsmooth optimal control problem governed by an evolution multivalued quasi-variational inequality, and then to obtain the sufficient conditions for guaranteeing the solvability of the nonlinear and nonsmooth optimal control problem under consideration. Such nonlinear and nonsmooth optimal control problem could as a useful model to explore the simultaneous distributed-boundary optimal control problems driven by evolution multivalued quasi-variational inequalities, and optimal parameters identification for evolution multivalued quasi-variational inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17810v1</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengda Zeng, Vicen\c{t}iu D. R\u{a}dulescu</dc:creator>
    </item>
    <item>
      <title>Constrained monotone mean--variance investment-reinsurance under the Cram\'er--Lundberg model with random coefficients</title>
      <link>https://arxiv.org/abs/2405.17841</link>
      <description>arXiv:2405.17841v2 Announce Type: cross 
Abstract: This paper studies an optimal investment-reinsurance problem for an insurer (she) under the Cram\'er--Lundberg model with monotone mean--variance (MMV) criterion. At any time, the insurer can purchase reinsurance (or acquire new business) and invest in a security market consisting of a risk-free asset and multiple risky assets whose excess return rate and volatility rate are allowed to be random. The trading strategy is subject to a general convex cone constraint, encompassing no-shorting constraint as a special case. The optimal investment-reinsurance strategy and optimal value for the MMV problem are deduced by solving certain backward stochastic differential equations with jumps. In the literature, it is known that models with MMV criterion and mean--variance criterion lead to the same optimal strategy and optimal value when the wealth process is continuous. Our result shows that the conclusion remains true even if the wealth process has compensated Poisson jumps and the market coefficients are random.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17841v2</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.sysconle.2024.105796</arxiv:DOI>
      <dc:creator>Xiaomin Shi, Zuo Quan Xu</dc:creator>
    </item>
    <item>
      <title>Decentralized Directed Collaboration for Personalized Federated Learning</title>
      <link>https://arxiv.org/abs/2405.17876</link>
      <description>arXiv:2405.17876v1 Announce Type: cross 
Abstract: Personalized Federated Learning (PFL) is proposed to find the greatest personalized models for each client. To avoid the central failure and communication bottleneck in the server-based FL, we concentrate on the Decentralized Personalized Federated Learning (DPFL) that performs distributed model training in a Peer-to-Peer (P2P) manner. Most personalized works in DPFL are based on undirected and symmetric topologies, however, the data, computation and communication resources heterogeneity result in large variances in the personalized models, which lead the undirected aggregation to suboptimal personalized performance and unguaranteed convergence. To address these issues, we propose a directed collaboration DPFL framework by incorporating stochastic gradient push and partial model personalized, called \textbf{D}ecentralized \textbf{Fed}erated \textbf{P}artial \textbf{G}radient \textbf{P}ush (\textbf{DFedPGP}). It personalizes the linear classifier in the modern deep model to customize the local solution and learns a consensus representation in a fully decentralized manner. Clients only share gradients with a subset of neighbors based on the directed and asymmetric topologies, which guarantees flexible choices for resource efficiency and better convergence. Theoretically, we show that the proposed DFedPGP achieves a superior convergence rate of $\mathcal{O}(\frac{1}{\sqrt{T}})$ in the general non-convex setting, and prove the tighter connectivity among clients will speed up the convergence. The proposed method achieves state-of-the-art (SOTA) accuracy in both data and computation heterogeneity scenarios, demonstrating the efficiency of the directed collaboration and partial gradient push.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17876v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingqi Liu, Yifan Shi, Qinglun Li, Baoyuan Wu, Xueqian Wang, Li Shen</dc:creator>
    </item>
    <item>
      <title>When is exponential asymptotic optimality achievable in average-reward restless bandits?</title>
      <link>https://arxiv.org/abs/2405.17882</link>
      <description>arXiv:2405.17882v1 Announce Type: cross 
Abstract: We consider the discrete-time infinite-horizon average-reward restless bandit problem. We propose a novel policy that maintains two dynamic subsets of arms: one subset of arms has a nearly optimal state distribution and takes actions according to an Optimal Local Control routine; the other subset of arms is driven towards the optimal state distribution and gradually merged into the first subset. We show that our policy is asymptotically optimal with an $O(\exp(-C N))$ optimality gap for an $N$-armed problem, under the mild assumptions of aperiodic-unichain, non-degeneracy, and local stability. Our policy is the first to achieve exponential asymptotic optimality under the above set of easy-to-verify assumptions, whereas prior work either requires a strong Global Attractor assumption or only achieves an $O(1/\sqrt{N})$ optimality gap. We further discuss the fundamental obstacles in significantly weakening our assumptions. In particular, we prove a lower bound showing that local stability is fundamental for exponential asymptotic optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17882v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yige Hong, Qiaomin Xie, Yudong Chen, Weina Wang</dc:creator>
    </item>
    <item>
      <title>A Pontryagin Perspective on Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2405.18100</link>
      <description>arXiv:2405.18100v1 Announce Type: cross 
Abstract: Reinforcement learning has traditionally focused on learning state-dependent policies to solve optimal control problems in a closed-loop fashion. In this work, we introduce the paradigm of open-loop reinforcement learning where a fixed action sequence is learned instead. We present three new algorithms: one robust model-based method and two sample-efficient model-free methods. Rather than basing our algorithms on Bellman's equation from dynamic programming, our work builds on Pontryagin's principle from the theory of open-loop optimal control. We provide convergence guarantees and evaluate all methods empirically on a pendulum swing-up task, as well as on two high-dimensional MuJoCo tasks, demonstrating remarkable performance compared to existing baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18100v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Onno Eberhard, Claire Vernade, Michael Muehlebach</dc:creator>
    </item>
    <item>
      <title>Mutation-Bias Learning in Games</title>
      <link>https://arxiv.org/abs/2405.18190</link>
      <description>arXiv:2405.18190v1 Announce Type: cross 
Abstract: We present two variants of a multi-agent reinforcement learning algorithm based on evolutionary game theoretic considerations. The intentional simplicity of one variant enables us to prove results on its relationship to a system of ordinary differential equations of replicator-mutator dynamics type, allowing us to present proofs on the algorithm's convergence conditions in various settings via its ODE counterpart. The more complicated variant enables comparisons to Q-learning based algorithms. We compare both variants experimentally to WoLF-PHC and frequency-adjusted Q-learning on a range of settings, illustrating cases of increasing dimensionality where our variants preserve convergence in contrast to more complicated algorithms. The availability of analytic results provides a degree of transferability of results as compared to purely empirical case studies, illustrating the general utility of a dynamical systems perspective on multi-agent reinforcement learning when addressing questions of convergence and reliable generalisation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18190v1</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johann Bauer, Sheldon West, Eduardo Alonso, Mark Broom</dc:creator>
    </item>
    <item>
      <title>Adam with model exponential moving average is effective for nonconvex optimization</title>
      <link>https://arxiv.org/abs/2405.18199</link>
      <description>arXiv:2405.18199v1 Announce Type: cross 
Abstract: In this work, we offer a theoretical analysis of two modern optimization techniques for training large and complex models: (i) adaptive optimization algorithms, such as Adam, and (ii) the model exponential moving average (EMA). Specifically, we demonstrate that a clipped version of Adam with model EMA achieves the optimal convergence rates in various nonconvex optimization settings, both smooth and nonsmooth. Moreover, when the scale varies significantly across different coordinates, we demonstrate that the coordinate-wise adaptivity of Adam is provably advantageous. Notably, unlike previous analyses of Adam, our analysis crucially relies on its core elements -- momentum and discounting factors -- as well as model EMA, motivating their wide applications in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18199v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kwangjun Ahn, Ashok Cutkosky</dc:creator>
    </item>
    <item>
      <title>From Learning to Optimize to Learning Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2405.18222</link>
      <description>arXiv:2405.18222v1 Announce Type: cross 
Abstract: Towards designing learned optimization algorithms that are usable beyond their training setting, we identify key principles that classical algorithms obey, but have up to now, not been used for Learning to Optimize (L2O). Following these principles, we provide a general design pipeline, taking into account data, architecture and learning strategy, and thereby enabling a synergy between classical optimization and L2O, resulting in a philosophy of Learning Optimization Algorithms. As a consequence our learned algorithms perform well far beyond problems from the training distribution. We demonstrate the success of these novel principles by designing a new learning-enhanced BFGS algorithm and provide numerical experiments evidencing its adaptation to many settings at test time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18222v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Camille Castera, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Sensor-Based Distributionally Robust Control for Safe Robot Navigation in Dynamic Environments</title>
      <link>https://arxiv.org/abs/2405.18251</link>
      <description>arXiv:2405.18251v1 Announce Type: cross 
Abstract: We introduce a novel method for safe mobile robot navigation in dynamic, unknown environments, utilizing onboard sensing to impose safety constraints without the need for accurate map reconstruction. Traditional methods typically rely on detailed map information to synthesize safe stabilizing controls for mobile robots, which can be computationally demanding and less effective, particularly in dynamic operational conditions. By leveraging recent advances in distributionally robust optimization, we develop a distributionally robust control barrier function (DR-CBF) constraint that directly processes range sensor data to impose safety constraints. Coupling this with a control Lyapunov function (CLF) for path tracking, we demonstrate that our CLF-DR-CBF control synthesis method achieves safe, efficient, and robust navigation in uncertain dynamic environments. We demonstrate the effectiveness of our approach in simulated and real autonomous robot navigation experiments, marking a substantial advancement in real-time safety guarantees for mobile robots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18251v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kehan Long, Yinzhuang Yi, Zhirui Dai, Sylvia Herbert, Jorge Cort\'es, Nikolay Atanasov</dc:creator>
    </item>
    <item>
      <title>A Topological Approach to Simple Descriptions of Convex Hulls of Sets Defined by Three Quadrics</title>
      <link>https://arxiv.org/abs/2405.18282</link>
      <description>arXiv:2405.18282v1 Announce Type: cross 
Abstract: We study the convex hull of a set $S\subset \mathbb{R}^n$ defined by three quadratic inequalities. A simple way of generating inequalities valid on $S$ is to take nonnegative linear combinations of the defining inequalities of $S$. We call such inequalities aggregations. We introduce a new technique relating aggregations to properties of the spectral curve, i.e. the curve defined by the vanishing of the determinant polynomial, and utilizing known spectral sequences (Agrachev and Lerario, 2012). We find new families beyond those identified in (Dey, Mu\~noz, and Serrano, 2022; Blekherman, Dey, and Sun, 2024), where the convex hull is defined by aggregations. We also prove a characterization of the emptiness of the projective variety defined by $3$ homogeneous quadratics in terms of the spectral curve generalizing results of (Agrachev, 1988).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18282v1</guid>
      <category>math.AG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Grigoriy Blekherman, Alex Dunbar</dc:creator>
    </item>
    <item>
      <title>Three quantitative versions of the P\'al inequality</title>
      <link>https://arxiv.org/abs/2405.18294</link>
      <description>arXiv:2405.18294v1 Announce Type: cross 
Abstract: The P\'al inequality is a classical result which asserts that among all planar convex sets of given width the equilateral triangle is the one of minimal area. In this paper we prove three quantitative versions of this inequality, by quantifying how the closeness of the area of a convex set, of certain width, to the minimal value implies its closeness to the equilateral triangle. As a by-product, we also present a novel result concerning a quantitative inequality for the inradius of a set, under minimal width constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18294v1</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilaria Lucardesi, Davide Zucco</dc:creator>
    </item>
    <item>
      <title>A Hessian-Aware Stochastic Differential Equation for Modelling SGD</title>
      <link>https://arxiv.org/abs/2405.18373</link>
      <description>arXiv:2405.18373v1 Announce Type: cross 
Abstract: Continuous-time approximation of Stochastic Gradient Descent (SGD) is a crucial tool to study its escaping behaviors from stationary points. However, existing stochastic differential equation (SDE) models fail to fully capture these behaviors, even for simple quadratic objectives. Built on a novel stochastic backward error analysis framework, we derive the Hessian-Aware Stochastic Modified Equation (HA-SME), an SDE that incorporates Hessian information of the objective function into both its drift and diffusion terms. Our analysis shows that HA-SME matches the order-best approximation error guarantee among existing SDE models in the literature, while achieving a significantly reduced dependence on the smoothness parameter of the objective. Further, for quadratic objectives, under mild conditions, HA-SME is proved to be the first SDE model that recovers exactly the SGD dynamics in the distributional sense. Consequently, when the local landscape near a stationary point can be approximated by quadratics, HA-SME is expected to accurately predict the local escaping behaviors of SGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18373v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Li, Zebang Shen, Liang Zhang, Niao He</dc:creator>
    </item>
    <item>
      <title>Efficient Stochastic Approximation of Minimax Excess Risk Optimization</title>
      <link>https://arxiv.org/abs/2306.00026</link>
      <description>arXiv:2306.00026v2 Announce Type: replace 
Abstract: While traditional distributionally robust optimization (DRO) aims to minimize the maximal risk over a set of distributions, Agarwal and Zhang (2022) recently proposed a variant that replaces risk with excess risk. Compared to DRO, the new formulation$\unicode{x2013}$minimax excess risk optimization (MERO) has the advantage of suppressing the effect of heterogeneous noise in different distributions. However, the choice of excess risk leads to a very challenging minimax optimization problem, and currently there exists only an inefficient algorithm for empirical MERO. In this paper, we develop efficient stochastic approximation approaches which directly target MERO. Specifically, we leverage techniques from stochastic convex optimization to estimate the minimal risk of every distribution, and solve MERO as a stochastic convex-concave optimization (SCCO) problem with biased gradients. The presence of bias makes existing theoretical guarantees of SCCO inapplicable, and fortunately, we demonstrate that the bias, caused by the estimation error of the minimal risk, is under-control. Thus, MERO can still be optimized with a nearly optimal convergence rate. Moreover, we investigate a practical scenario where the quantity of samples drawn from each distribution may differ, and propose a stochastic approach that delivers distribution-dependent convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.00026v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Zhang, Haomin Bai, Wei-Wei Tu, Ping Yang, Yao Hu</dc:creator>
    </item>
    <item>
      <title>Entropic mean-field min-max problems via Best Response flow</title>
      <link>https://arxiv.org/abs/2306.03033</link>
      <description>arXiv:2306.03033v3 Announce Type: replace 
Abstract: We investigate the convergence properties of a continuous-time optimization method, the \textit{Mean-Field Best Response} flow, for solving convex-concave min-max games with entropy regularization. We introduce suitable Lyapunov functions to establish exponential convergence to the unique mixed Nash equilibrium. Additionally, we demonstrate the convergence of the fictitious play flow as a by-product of our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03033v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Razvan-Andrei Lascu, Mateusz B. Majka, {\L}ukasz Szpruch</dc:creator>
    </item>
    <item>
      <title>Hierarchical Framework for Space Exploration Campaign Schedule Optimization</title>
      <link>https://arxiv.org/abs/2308.00632</link>
      <description>arXiv:2308.00632v2 Announce Type: replace 
Abstract: Space exploration plans are becoming increasingly complex as public agencies and private companies target deep-space locations, such as cislunar space and beyond, which require long-duration missions and many supporting systems and payloads. Optimizing multi-mission exploration campaigns is challenging due to the large number of required launches as well as their sequencing and compatibility requirements, making the conventional space logistics formulations not scalable. To tackle this challenge, this paper proposes an alternative approach that leverages a two-level hierarchical optimization algorithm: a genetic algorithm is used to explore the campaign scheduling solution space, and each of the solutions is then evaluated using a time-expanded multi-commodity flow mixed-integer linear program. A number of case studies, focusing on the Artemis lunar exploration program, demonstrate how the method can be used to analyze potential campaign architectures. The method enables a potential mission planner to study the sensitivity of a campaign to program-level parameters such as logistics vehicle availability and performance, payload launch windows, and in-situ resource utilization infrastructure efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.00632v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.2514/1.A35828</arxiv:DOI>
      <dc:creator>Nicholas Gollins, Koki Ho</dc:creator>
    </item>
    <item>
      <title>Towards Global Solutions for Nonconvex Two-Stage Stochastic Programs: A Polynomial Lower Approximation Approach</title>
      <link>https://arxiv.org/abs/2310.04243</link>
      <description>arXiv:2310.04243v3 Announce Type: replace 
Abstract: This paper tackles the challenging problem of finding global optimal solutions for two-stage stochastic programs with continuous decision variables and nonconvex recourse functions. We introduce a two-phase approach. The first phase involves the construction of a polynomial lower bound for the recourse function through a linear optimization problem over a nonnegative polynomial cone. Given the complex structure of this cone, we employ semidefinite relaxations with quadratic modules to facilitate our computations. In the second phase, we solve a surrogate first-stage problem by substituting the original recourse function with the polynomial lower approximation obtained in the first phase. Our method is particularly advantageous for two reasons: it not only generates global lower bounds for the nonconvex stochastic program, aiding in the certificate of global optimality for prospective solutions like stationary solutions computed from other methods, but it also yields an explicit polynomial approximation for the recourse function through the solution of a linear conic optimization problem, where the number of variables is independent of the support of the underlying random vector. Therefore, our approach is particularly suitable for the case where the random vector follows a continuous distribution or when dealing with a large number of scenarios. Numerical experiments are conducted to demonstrate the effectiveness of our proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04243v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Suhan Zhong, Ying Cui, Jiawang Nie</dc:creator>
    </item>
    <item>
      <title>Parallelized Conflict Graph Cut Generation</title>
      <link>https://arxiv.org/abs/2311.03706</link>
      <description>arXiv:2311.03706v3 Announce Type: replace 
Abstract: A conflict graph represents logical relations between binary variables, and effective use of the graph can significantly accelerate branch-and-cut solvers for mixed-integer programming (MIP). In this paper we develop efficient parallel conflict graph management: conflict detection; maximal clique generation; clique extension; and clique merging. We leverage parallel computing in order to intensify computational effort on the conflict graph, thereby generating a much larger pool of cutting planes than what can be practically achieved in serial. Computational experiments demonstrate that the expanded pool of cuts enabled by parallel computing lead to substantial reductions in total MIP solve time, especially for more challenging cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03706v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yongzheng Dai, Chen Chen</dc:creator>
    </item>
    <item>
      <title>Mirror Descent-Ascent for mean-field min-max problems</title>
      <link>https://arxiv.org/abs/2402.08106</link>
      <description>arXiv:2402.08106v2 Announce Type: replace 
Abstract: We study two variants of the mirror descent-ascent algorithm for solving min-max problems on the space of measures: simultaneous and sequential. We work under assumptions of convexity-concavity and relative smoothness of the payoff function with respect to a suitable Bregman divergence, defined on the space of measures via flat derivatives. We show that the convergence rates to mixed Nash equilibria, measured in the Nikaid\`o-Isoda error, are of order $\mathcal{O}\left(N^{-1/2}\right)$ and $\mathcal{O}\left(N^{-2/3}\right)$ for the simultaneous and sequential schemes, respectively, which is in line with the state-of-the-art results for related finite-dimensional algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08106v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Razvan-Andrei Lascu, Mateusz B. Majka, {\L}ukasz Szpruch</dc:creator>
    </item>
    <item>
      <title>Strengthening Lasserre's Hierarchy in Real and Complex Polynomial Optimization</title>
      <link>https://arxiv.org/abs/2404.07125</link>
      <description>arXiv:2404.07125v2 Announce Type: replace 
Abstract: This paper studies shift operators which arises from extractions of solutions for Lasserre's hierarchy. First, we establish a connection between multiplication operators and shift operators. More importantly, we derive new positive semidefinite conditions of rank-one moment sequences via shift operators, and utilize these conditions to strengthen Lasserre's hierarchy for real and complex polynomial optimization. Furthermore, we integrate the strengthening technique with correlative sparsity and sign symmetries present in polynomial optimization problems. Extensive numerical experiments show that our strengthening technique can significantly improve the bound (especially for complex polynomial optimization) and allows to achieve global optimality at lower relaxation orders, thus providing substantial computational savings and considerable speedup.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07125v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Wang</dc:creator>
    </item>
    <item>
      <title>Analysis of Decentralized Stochastic Successive Convex Approximation for composite non-convex problems</title>
      <link>https://arxiv.org/abs/2405.07100</link>
      <description>arXiv:2405.07100v2 Announce Type: replace 
Abstract: This work considers the decentralized successive convex approximation (SCA) method for minimizing stochastic non-convex objectives subject to convex constraints, along with possibly non-smooth convex regularizers. Although SCA has been widely applied in decentralized settings, its stochastic first order (SFO) complexity is unknown, and it is thought to be slower than the centralized momentum-enhanced SCA variants. In this work, we advance the state-of-the-art for SCA methods by proposing an accelerated variant, namely the \textbf{D}ecentralized \textbf{M}omentum-based \textbf{S}tochastic \textbf{SCA} (\textbf{D-MSSCA}) and analyze its SFO complexity. The proposed algorithm entails creating a stochastic surrogate of the objective at every iteration, which is minimized at each node separately. Remarkably, the D-MSSCA achieves an SFO complexity of $\mathcal{O}(\epsilon^{-3/2})$ to reach an $\epsilon$-stationary point, which is at par with the SFO complexity lower bound for unconstrained stochastic non-convex optimization in centralized setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07100v2</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Basil M. Idrees, Shivangi Dubey Sharma, Ketan Rajawat</dc:creator>
    </item>
    <item>
      <title>On the integrality gap of the Complete Metric Steiner Tree Problem via a novel formulation</title>
      <link>https://arxiv.org/abs/2405.13773</link>
      <description>arXiv:2405.13773v2 Announce Type: replace 
Abstract: In this work, we compute the lower bound of the integrality gap of the Metric Steiner Tree Problem (MSTP) on a graph for some small values of number of nodes and terminals. After debating about some limitations of the most used formulation for the Steiner Tree Problem, namely the Bidirected Cut Formulation, we introduce a novel formulation, that we named Complete Metric formulation, tailored for the metric case. We prove some interesting properties of this formulation and characterize some types of vertices. Finally, we define a linear program (LP) by adapting a method already used in the context of the Travelling Salesman Problem. This LP takes as input a vertex of the polytope of the CM relaxation and provides an MSTP instance such that (a) the optimal solution is precisely that vertex and (b) among all of the instances having that vertex as its optimal solution, the selected instance is the one having the highest integrality gap. We propose two heuristics for generating vertices to provide inputs for our procedure. In conclusion, we raise several conjectures and open questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13773v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ambrogio Maria Bernardelli, Eleonora Vercesi, Stefano Gualandi, Monaldo Mastrolilli, Luca Maria Gambardella</dc:creator>
    </item>
    <item>
      <title>Exploring Jacobian Inexactness in Second-Order Methods for Variational Inequalities: Lower Bounds, Optimal Algorithms and Quasi-Newton Approximations</title>
      <link>https://arxiv.org/abs/2405.15990</link>
      <description>arXiv:2405.15990v2 Announce Type: replace 
Abstract: Variational inequalities represent a broad class of problems, including minimization and min-max problems, commonly found in machine learning. Existing second-order and high-order methods for variational inequalities require precise computation of derivatives, often resulting in prohibitively high iteration costs. In this work, we study the impact of Jacobian inaccuracy on second-order methods. For the smooth and monotone case, we establish a lower bound with explicit dependence on the level of Jacobian inaccuracy and propose an optimal algorithm for this key setting. When derivatives are exact, our method converges at the same rate as exact optimal second-order methods. To reduce the cost of solving the auxiliary problem, which arises in all high-order methods with global convergence, we introduce several Quasi-Newton approximations. Our method with Quasi-Newton updates achieves a global sublinear convergence rate. We extend our approach with a tensor generalization for inexact high-order derivatives and support the theory with experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15990v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Artem Agafonov, Petr Ostroukhov, Roman Mozhaev, Konstantin Yakovlev, Eduard Gorbunov, Martin Tak\'a\v{c}, Alexander Gasnikov, Dmitry Kamzolov</dc:creator>
    </item>
    <item>
      <title>A Novel Privacy Enhancement Scheme with Dynamic Quantization for Federated Learning</title>
      <link>https://arxiv.org/abs/2405.16058</link>
      <description>arXiv:2405.16058v2 Announce Type: replace 
Abstract: Federated learning (FL) has been widely regarded as a promising paradigm for privacy preservation of raw data in machine learning. Although, the data privacy in FL is locally protected to some extent, it is still a desideratum to enhance privacy and alleviate communication overhead caused by repetitively transmitting model parameters. Typically, these challenges are addressed separately, or jointly via a unified scheme that consists of noise-injected privacy mechanism and communication compression, which may lead to model corruption due to the introduced composite noise. In this work, we propose a novel model-splitting privacy-preserving FL (MSP-FL) scheme to achieve private FL with precise accuracy guarantee. Based upon MSP-FL, we further propose a model-splitting privacy-preserving FL with dynamic quantization (MSPDQ-FL) to mitigate the communication overhead, which incorporates a shrinking quantization interval to reduce the quantization error. We provide privacy and convergence analysis for both MSP-FL and MSPDQ-FL under non-i.i.d. dataset, partial clients participation and finite quantization level. Numerical results are presented to validate the superiority of the proposed schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16058v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Wang, Xianghui Cao, Shi Jin, Mo-Yuen Chow</dc:creator>
    </item>
    <item>
      <title>Analysis of Multiscale Reinforcement Q-Learning Algorithms for Mean Field Control Games</title>
      <link>https://arxiv.org/abs/2405.17017</link>
      <description>arXiv:2405.17017v2 Announce Type: replace 
Abstract: Mean Field Control Games (MFCG), introduced in [Angiuli et al., 2022a], represent competitive games between a large number of large collaborative groups of agents in the infinite limit of number and size of groups. In this paper, we prove the convergence of a three-timescale Reinforcement Q-Learning (RL) algorithm to solve MFCG in a model-free approach from the point of view of representative agents. Our analysis uses a Q-table for finite state and action spaces updated at each discrete time-step over an infinite horizon. In [Angiuli et al., 2023], we proved convergence of two-timescale algorithms for MFG and MFC separately highlighting the need to follow multiple population distributions in the MFC case. Here, we integrate this feature for MFCG as well as three rates of update decreasing to zero in the proper ratios. Our technique of proof uses a generalization to three timescales of the two-timescale analysis in [Borkar, 1997]. We give a simple example satisfying the various hypothesis made in the proof of convergence and illustrating the performance of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17017v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Angiuli, Jean-Pierre Fouque, Mathieu Lauri\`ere, Mengrui Zhang</dc:creator>
    </item>
    <item>
      <title>Automated Market Making and Loss-Versus-Rebalancing</title>
      <link>https://arxiv.org/abs/2208.06046</link>
      <description>arXiv:2208.06046v5 Announce Type: replace-cross 
Abstract: We consider the market microstructure of automated market makers (AMMs) from the perspective of liquidity providers (LPs). Our central contribution is a ``Black-Scholes formula for AMMs''. We identify the main adverse selection cost incurred by LPs, which we call ``loss-versus-rebalancing'' (LVR, pronounced ``lever''). LVR captures costs incurred by AMM LPs due to stale prices that are picked off by better informed arbitrageurs. We derive closed-form expressions for LVR applicable to all automated market makers. Our model is quantitatively realistic, matching actual LP returns empirically, and shows how CFMM protocols can be redesigned to reduce or eliminate LVR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.06046v5</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <category>q-fin.PR</category>
      <category>q-fin.TR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason Milionis, Ciamac C. Moallemi, Tim Roughgarden, Anthony Lee Zhang</dc:creator>
    </item>
    <item>
      <title>Finding Pareto Efficient Redistricting Plans with Short Bursts</title>
      <link>https://arxiv.org/abs/2304.00427</link>
      <description>arXiv:2304.00427v2 Announce Type: replace-cross 
Abstract: Redistricting practitioners must balance many competing constraints and criteria when drawing district boundaries. To aid in this process, researchers have developed many methods for optimizing districting plans according to one or more criteria. This research note extends a recently-proposed single-criterion optimization method, short bursts (Cannon et al., 2023), to handle the multi-criterion case, and in doing so approximate the Pareto frontier for any set of constraints. We study the empirical performance of the method in a realistic setting and find it behaves as expected and is not very sensitive to algorithmic parameters. The proposed approach, which is implemented in open-source software, should allow researchers and practitioners to better understand the tradeoffs inherent to the redistricting process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.00427v2</guid>
      <category>cs.CY</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cory McCartan</dc:creator>
    </item>
    <item>
      <title>Sliced optimal transport: is it a suitable replacement?</title>
      <link>https://arxiv.org/abs/2311.15874</link>
      <description>arXiv:2311.15874v3 Announce Type: replace-cross 
Abstract: We introduce a one-parameter family of metrics on the space of Borel probability measures on Euclidean space with finite $p$th moment for $1\leq p &lt;\infty$, called the $\textit{sliced Monge--Kantorovich metrics}$, which include the sliced Wasserstein and max-sliced Wasserstein metrics. We then show that these are complete, separable metric spaces that are topologically equivalent to the classical Monge--Kantorovich metrics and these metrics have a dual representation. However, we also prove these sliced metrics are $\textit{not}$ bi-Lipschitz equivalent to the classical ones in most cases, and also the spaces are (except for an endpoint case) $\textit{not}$ geodesic. The completeness, duality, and non-geodesicness are new even in the sliced and max-sliced Wasserstein cases, and non bi-Lipschitz equivalence is only known for a few specific cases. In particular this indicates that sliced and max-sliced Wasserstein metrics are not suitable direct replacements for the classical Monge--Kantorovich metrics in problems where the specific metric or geodesic structure are critical.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15874v3</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Kitagawa, Asuka Takatsu</dc:creator>
    </item>
    <item>
      <title>Role of Momentum in Smoothing Objective Function and Generalizability of Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2402.02325</link>
      <description>arXiv:2402.02325v3 Announce Type: replace-cross 
Abstract: For nonconvex objective functions, including deep neural networks, stochastic gradient descent (SGD) with momentum has fast convergence and excellent generalizability, but a theoretical explanation for this is lacking. In contrast to previous studies that defined the stochastic noise that occurs during optimization as the variance of the stochastic gradient, we define it as the gap between the search direction of the optimizer and the steepest descent direction and show that its level dominates generalizability of the model. We also show that the stochastic noise in SGD with momentum smoothes the objective function, the degree of which is determined by the learning rate, the batch size, the momentum factor, the variance of the stochastic gradient, and the upper bound of the gradient norm. By numerically deriving the stochastic noise level in SGD and SGD with momentum, we provide theoretical findings that help explain the training dynamics of SGD with momentum, which were not explained by previous studies on convergence and stability. We also provide experimental results supporting our assertion that model generalizability depends on the stochastic noise level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02325v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naoki Sato, Hideaki Iiduka</dc:creator>
    </item>
    <item>
      <title>MetaOptimize: A Framework for Optimizing Step Sizes and Other Meta-parameters</title>
      <link>https://arxiv.org/abs/2402.02342</link>
      <description>arXiv:2402.02342v4 Announce Type: replace-cross 
Abstract: This paper addresses the challenge of optimizing meta-parameters (i.e., hyperparameters) in machine learning algorithms, a critical factor influencing training efficiency and model performance. Moving away from the computationally expensive traditional meta-parameter search methods, we introduce MetaOptimize framework that dynamically adjusts meta-parameters, particularly step sizes (also known as learning rates), during training. More specifically, MetaOptimize can wrap around any first-order optimization algorithm, tuning step sizes on the fly to minimize a specific form of regret that accounts for long-term effect of step sizes on training, through a discounted sum of future losses. We also introduce low complexity variants of MetaOptimize that, in conjunction with its adaptability to multiple optimization algorithms, demonstrate performance competitive to those of best hand-crafted learning rate schedules across various machine learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02342v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arsalan Sharifnassab, Saber Salehkaleybar, Richard Sutton</dc:creator>
    </item>
    <item>
      <title>AdAdaGrad: Adaptive Batch Size Schemes for Adaptive Gradient Methods</title>
      <link>https://arxiv.org/abs/2402.11215</link>
      <description>arXiv:2402.11215v3 Announce Type: replace-cross 
Abstract: The choice of batch sizes in minibatch stochastic gradient optimizers is critical in large-scale model training for both optimization and generalization performance. Although large-batch training is arguably the dominant training paradigm for large-scale deep learning due to hardware advances, the generalization performance of the model deteriorates compared to small-batch training, leading to the so-called "generalization gap" phenomenon. To mitigate this, we investigate adaptive batch size strategies derived from adaptive sampling methods, originally developed only for stochastic gradient descent. Given the significant interplay between learning rates and batch sizes, and considering the prevalence of adaptive gradient methods in deep learning, we emphasize the need for adaptive batch size strategies in these contexts. We introduce AdAdaGrad and its scalar variant AdAdaGradNorm, which progressively increase batch sizes during training, while model updates are performed using AdaGrad and AdaGradNorm. We prove that AdAdaGradNorm converges with high probability at a rate of $\mathscr{O}(1/K)$ to find a first-order stationary point of smooth nonconvex functions within $K$ iterations. AdAdaGrad also demonstrates similar convergence properties when integrated with a novel coordinate-wise variant of our adaptive batch size strategies. We corroborate our theoretical claims by performing image classification experiments, highlighting the merits of the proposed schemes in terms of both training efficiency and model generalization. Our work unveils the potential of adaptive batch size strategies for adaptive gradient optimizers in large-scale model training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11215v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Tsz-Kit Lau, Han Liu, Mladen Kolar</dc:creator>
    </item>
    <item>
      <title>LoRA Training in the NTK Regime has No Spurious Local Minima</title>
      <link>https://arxiv.org/abs/2402.11867</link>
      <description>arXiv:2402.11867v3 Announce Type: replace-cross 
Abstract: Low-rank adaptation (LoRA) has become the standard approach for parameter-efficient fine-tuning of large language models (LLM), but our theoretical understanding of LoRA has been limited. In this work, we theoretically analyze LoRA fine-tuning in the neural tangent kernel (NTK) regime with $N$ data points, showing: (i) full fine-tuning (without LoRA) admits a low-rank solution of rank $r\lesssim \sqrt{N}$; (ii) using LoRA with rank $r\gtrsim \sqrt{N}$ eliminates spurious local minima, allowing gradient descent to find the low-rank solutions; (iii) the low-rank solution found using LoRA generalizes well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11867v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Uijeong Jang, Jason D. Lee, Ernest K. Ryu</dc:creator>
    </item>
    <item>
      <title>Elliptic Reconstruction and A Posteriori Error Estimates for Parabolic Variational Inequalities</title>
      <link>https://arxiv.org/abs/2402.17724</link>
      <description>arXiv:2402.17724v2 Announce Type: replace-cross 
Abstract: Elliptic reconstruction property, originally introduced by Makridakis and Nochetto for linear parabolic problems, is a well-known tool to derive optimal a posteriori error estimates. No such results are known for nonlinear and nonsmooth problems such as parabolic variational inequalities (VIs). This article establishes the elliptic reconstruction property for parabolic VIs and derives a posteriori error estimates in $L^{\infty}(0,T;L^{2}(\Omega))$. The estimator consists of discrete complementarity terms and standard residual. As an application, the residual-type error estimates are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17724v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harbir Antil, Rohit Khandelwal</dc:creator>
    </item>
    <item>
      <title>Optimistic Safety for Online Convex Optimization with Unknown Linear Constraints</title>
      <link>https://arxiv.org/abs/2403.05786</link>
      <description>arXiv:2403.05786v2 Announce Type: replace-cross 
Abstract: We study the problem of online convex optimization (OCO) under unknown linear constraints that are either static, or stochastically time-varying. For this problem, we introduce an algorithm that we term Optimistically Safe OCO (OSOCO) and show that it enjoys $\tilde{\mathcal{O}}(\sqrt{T})$ regret and no constraint violation. In the case of static linear constraints, this improves on the previous best known $\tilde{\mathcal{O}}(T^{2/3})$ regret with only slightly stronger assumptions. In the case of stochastic time-varying constraints, our work supplements existing results that show $\mathcal{O}(\sqrt{T})$ regret and $\mathcal{O}(\sqrt{T})$ cumulative violation under more general convex constraints albeit a less general feedback model. In addition to our theoretical guarantees, we also give numerical results comparing the performance of OSOCO to existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05786v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Spencer Hutchinson, Tianyi Chen, Mahnoosh Alizadeh</dc:creator>
    </item>
  </channel>
</rss>
