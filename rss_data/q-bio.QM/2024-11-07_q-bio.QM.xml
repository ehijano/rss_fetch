<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Nov 2024 02:53:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Causal Framework for Precision Rehabilitation</title>
      <link>https://arxiv.org/abs/2411.03919</link>
      <description>arXiv:2411.03919v1 Announce Type: new 
Abstract: Precision rehabilitation offers the promise of an evidence-based approach for optimizing individual rehabilitation to improve long-term functional outcomes. Emerging techniques, including those driven by artificial intelligence, are rapidly expanding our ability to quantify the different domains of function during rehabilitation, other encounters with healthcare, and in the community. While this seems poised to usher rehabilitation into the era of big data and should be a powerful driver of precision rehabilitation, our field lacks a coherent framework to utilize these data and deliver on this promise. We propose a framework that builds upon multiple existing pillars to fill this gap. Our framework aims to identify the Optimal Dynamic Treatment Regimens (ODTR), or the decision-making strategy that takes in the range of available measurements and biomarkers to identify interventions likely to maximize long-term function. This is achieved by designing and fitting causal models, which extend the Computational Neurorehabilitation framework using tools from causal inference. These causal models can learn from heterogeneous data from different silos, which must include detailed documentation of interventions, such as using the Rehabilitation Treatment Specification System. The models then serve as digital twins of patient recovery trajectories, which can be used to learn the ODTR. Our causal modeling framework also emphasizes quantitatively linking changes across levels of the functioning to ensure that interventions can be precisely selected based on careful measurement of impairments while also being selected to maximize outcomes that are meaningful to patients and stakeholders. We believe this approach can provide a unifying framework to leverage growing big rehabilitation data and AI-powered measurements to produce precision rehabilitation treatments that can improve clinical outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03919v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>R. James Cotton, Bryant A. Seamon, Richard L. Segal, Randal D. Davis, Amrita Sahu, Michelle M. McLeod, Pablo Celnik, Sharon L. Ramey</dc:creator>
    </item>
    <item>
      <title>TockyPrep: Data Preprocessing Methods for Flow Cytometric Fluorescent Timer Analysis</title>
      <link>https://arxiv.org/abs/2411.04111</link>
      <description>arXiv:2411.04111v1 Announce Type: new 
Abstract: Background: Fluorescent Timer proteins, which display time-dependent changes in their emission spectra, are invaluable for analyzing the temporal dynamics of cellular events at the single-cell level. We previously developed the Timer-of-cell-kinetics-and-activity (Tocky) tools, utilizing a specific Timer protein, Fast-FT, to monitor temporal changes in cellular activities. Despite their potential, the analysis of Timer fluorescence in flow cytometry is frequently compromised by variability in instrument settings and the absence of standardized preprocessing methods. The development and implementation of effective data preprocessing methods remain to be achieved.
  Results: In this study, we introduce the R package that automates the data preprocessing of Timer fluorescence data from flow cytometry experiments for quantitative analysis at single-cell level. Our aim is to standardize Timer data analysis to enhance reproducibility and accuracy across different experimental setups. The package includes a trigonometric transformation method to elucidate the dynamics of Fluorescent Timer proteins. We have identified the normalization of immature and mature Timer fluorescence data as essential for robust analysis, clarifying how this normalization affects the analysis of Timer maturation. These preprocessing methods are all encapsulated within the TockyPrep R package.
  Conclusions: TockyPrep is available for distribution via GitHub at https://github.com/MonoTockyLab/TockyPrep, providing tools for data preprocessing and basic visualization of Timer fluorescence data. This toolkit is expected to enhance the utility of experimental systems utilizing Fluorescent Timer proteins, including the Tocky tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04111v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masahiro Ono</dc:creator>
    </item>
    <item>
      <title>Pathway-Guided Optimization of Deep Generative Molecular Design Models for Cancer Therapy</title>
      <link>https://arxiv.org/abs/2411.03460</link>
      <description>arXiv:2411.03460v1 Announce Type: cross 
Abstract: The data-driven drug design problem can be formulated as an optimization task of a potentially expensive black-box objective function over a huge high-dimensional and structured molecular space. The junction tree variational autoencoder (JTVAE) has been shown to be an efficient generative model that can be used for suggesting legitimate novel drug-like small molecules with improved properties. While the performance of the generative molecular design (GMD) scheme strongly depends on the initial training data, one can improve its sampling efficiency for suggesting better molecules with enhanced properties by optimizing the latent space. In this work, we propose how mechanistic models - such as pathway models described by differential equations - can be used for effective latent space optimization(LSO) of JTVAEs and other similar models for GMD. To demonstrate the potential of our proposed approach, we show how a pharmacodynamic model, assessing the therapeutic efficacy of a drug-like small molecule by predicting how it modulates a cancer pathway, can be incorporated for effective LSO of data-driven models for GMD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03460v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alif Bin Abdul Qayyum, Susan D. Mertins, Amanda K. Paulson, Nathan M. Urban, Byung-Jun Yoon</dc:creator>
    </item>
    <item>
      <title>Automating Exploratory Proteomics Research via Language Models</title>
      <link>https://arxiv.org/abs/2411.03743</link>
      <description>arXiv:2411.03743v1 Announce Type: cross 
Abstract: With the development of artificial intelligence, its contribution to science is evolving from simulating a complex problem to automating entire research processes and producing novel discoveries. Achieving this advancement requires both specialized general models grounded in real-world scientific data and iterative, exploratory frameworks that mirror human scientific methodologies. In this paper, we present PROTEUS, a fully automated system for scientific discovery from raw proteomics data. PROTEUS uses large language models (LLMs) to perform hierarchical planning, execute specialized bioinformatics tools, and iteratively refine analysis workflows to generate high-quality scientific hypotheses. The system takes proteomics datasets as input and produces a comprehensive set of research objectives, analysis results, and novel biological hypotheses without human intervention. We evaluated PROTEUS on 12 proteomics datasets collected from various biological samples (e.g. immune cells, tumors) and different sample types (single-cell and bulk), generating 191 scientific hypotheses. These were assessed using both automatic LLM-based scoring on 5 metrics and detailed reviews from human experts. Results demonstrate that PROTEUS consistently produces reliable, logically coherent results that align well with existing literature while also proposing novel, evaluable hypotheses. The system's flexible architecture facilitates seamless integration of diverse analysis tools and adaptation to different proteomics data types. By automating complex proteomics analysis workflows and hypothesis generation, PROTEUS has the potential to considerably accelerate the pace of scientific discovery in proteomics research, enabling researchers to efficiently explore large-scale datasets and uncover biological insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03743v1</guid>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ning Ding, Shang Qu, Linhai Xie, Yifei Li, Zaoqu Liu, Kaiyan Zhang, Yibai Xiong, Yuxin Zuo, Zhangren Chen, Ermo Hua, Xingtai Lv, Youbang Sun, Yang Li, Dong Li, Fuchu He, Bowen Zhou</dc:creator>
    </item>
    <item>
      <title>DART-PIM: DNA read mApping acceleRaTor Using Processing-In-Memory</title>
      <link>https://arxiv.org/abs/2411.03832</link>
      <description>arXiv:2411.03832v1 Announce Type: cross 
Abstract: Genome analysis has revolutionized fields such as personalized medicine and forensics. Modern sequencing machines generate vast amounts of fragmented strings of genome data called reads. The alignment of these reads into a complete DNA sequence of an organism (the read mapping process) requires extensive data transfer between processing units and memory, leading to execution bottlenecks. Prior studies have primarily focused on accelerating specific stages of the read-mapping task. Conversely, this paper introduces a holistic framework called DART-PIM that accelerates the entire read-mapping process. DART-PIM facilitates digital processing-in-memory (PIM) for an end-to-end acceleration of the entire read-mapping process, from indexing using a unique data organization schema to filtering and read alignment with an optimized Wagner Fischer algorithm. A comprehensive performance evaluation with real genomic data shows that DART-PIM achieves a 5.7x and 257x improvement in throughput and a 92x and 27x energy efficiency enhancement compared to state-of-the-art GPU and PIM implementations, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03832v1</guid>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 07 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rotem Ben-Hur, Orian Leitersdorf, Ronny Ronen, Lidor Goldshmidt, Idan Magram, Lior Kaplun, Leonid Yavitz, Shahar Kvatinsky</dc:creator>
    </item>
  </channel>
</rss>
