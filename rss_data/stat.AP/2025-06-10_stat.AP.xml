<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Jun 2025 04:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A New Lifetime Distribution: Exponentiated Exponential-Pareto-HalfNormal Mixture Model for Biomedical Applications</title>
      <link>https://arxiv.org/abs/2506.08313</link>
      <description>arXiv:2506.08313v1 Announce Type: new 
Abstract: This study introduces the Exponentiated-Exponential-Pareto-Half Normal Mixture Distribution (EEPHND), a novel hybrid model developed to overcome the limitations of classical distributions in modeling complex real-world data. By compounding the Exponentiated-Exponential-Pareto (EEP) and Half-Normal distributions through a mixture mechanism, EEPHND effectively captures both early-time symmetry and long-tail behavior, features which are commonly observed in survival and reliability data. The model offers closed-form expressions for its probability density, cumulative distribution, survival and hazard functions, moments, and reliability metrics, ensuring analytical traceability and interpretability in the presence of censoring and heterogeneous risk dynamics. When applied to a real-world lung cancer dataset, EEPHND outperformed competing models in both goodness-of-fit and predictive accuracy, achieving a Concordance Index (CI) of 0.9997. These results highlight its potential as a flexible and powerful tool for survival analysis and biomedical engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08313v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oriyomi Ahmad Hassan, Aisha Tunrayo Maradesa, Abdulazeez Toyosi Alabi, Oyejide Surajudeen Salam, Ajani Busari, Akinwale Victor Famotire, Habeeb Abiodun Afolabi, Solomon Adeleke, Abayomi Ayodele Akomolafe</dc:creator>
    </item>
    <item>
      <title>Unveiling the Impact of Social and Environmental Determinants of Health on Lung Function Decline in Cystic Fibrosis through Data Integration using the US Registry</title>
      <link>https://arxiv.org/abs/2506.08731</link>
      <description>arXiv:2506.08731v1 Announce Type: new 
Abstract: Integrating diverse data sources offers a comprehensive view of patient health and holds potential for improving clinical decision-making. In Cystic Fibrosis (CF), which is a genetic disorder primarily affecting the lungs, biomarkers that track lung function decline such as FEV1 serve as important predictors for assessing disease progression. Prior research has shown that incorporating social and environmental determinants of health improves prognostic accuracy. To investigate the lung function decline among individuals with CF, we integrate data from the U.S. Cystic Fibrosis Foundation Patient Registry with social and environmental health information. Our analysis focuses on the relationship between lung function and the deprivation index, a composite measure of socioeconomic status.
  We used advanced multivariate mixed-effects models, which allow for the joint modelling of multiple longitudinal outcomes with flexible functional forms. This methodology provides an understanding of interrelationships among outcomes, addressing the complexities of dynamic health data. We examine whether this relationship varies with patients' exposure duration to high-deprivation areas, analyzing data across time and within individual US states. Results show a strong relation between lung function and the area under the deprivation index curve across all states. These results underscore the importance of integrating social and environmental determinants of health into clinical models of disease progression. By accounting for broader contextual factors, healthcare providers can gain deeper insights into disease trajectories and design more targeted intervention strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08731v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eleni-Rosalina Andrinopoulou, Emrah Gecili, Rhonda D Szczesniak</dc:creator>
    </item>
    <item>
      <title>Yau-YauAL: A computer tool for solving nonlinear filtering problems</title>
      <link>https://arxiv.org/abs/2506.08976</link>
      <description>arXiv:2506.08976v1 Announce Type: new 
Abstract: The Yau-Yau nonlinear filter has increasingly emerged as a powerful tool to study stochastic complex systems. To leverage it to a wider spectrum of application scenarios, we pack the Yau-Yau filtering ALgorithms (YauYauAL) into a package of computer software. Yau-YauAL was written in R, designed to simplify the implementation of the Yau-Yau filter for solving nonlinear filtering problems. Combining R's accessibility with C++ (via Rcpp) for computational efficiency, YauYauAL provides an intuitive Shiny-based interface that enables real-time parameter adjustment and result visualization. At its core, YauYauAL employs finite difference methods to numerically solve the Kolmogorov forward equation, ensuring a stable and accurate solution even for complex systems. YauYauAL's modular design and open-source framework further encourage customization and community-driven development. YauYauAL aims to bridge the gap between theoretical nonlinear filtering methods and practical applications, without requiring expertise in differential equation solving or programming, fostering its broader impact on various scientific fields, such as signal processing, finance, medicine, and biology among a long list.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08976v1</guid>
      <category>stat.AP</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu Wang, Shuyuan Xu, Xueda Wei, Xinrui Luo, Stephen Shing-Toung Yau, Shing-Tung Yau, Rongling Wu</dc:creator>
    </item>
    <item>
      <title>Sensor Fusion for Track Geometry Monitoring: Integrating On-Board Data and Degradation Models via Kalman Filtering</title>
      <link>https://arxiv.org/abs/2506.08028</link>
      <description>arXiv:2506.08028v1 Announce Type: cross 
Abstract: Track geometry monitoring is essential for maintaining the safety and efficiency of railway operations. While Track Recording Cars (TRCs) provide accurate measurements of track geometry indicators, their limited availability and high operational costs restrict frequent monitoring across large rail networks. Recent advancements in on-board sensor systems installed on in-service trains offer a cost-effective alternative by enabling high-frequency, albeit less accurate, data collection. This study proposes a method to enhance the reliability of track geometry predictions by integrating low-accuracy sensor signals with degradation models through a Kalman filter framework. An experimental campaign using a low-cost sensor system mounted on a TRC evaluates the proposed approach. The results demonstrate that incorporating frequent sensor data significantly reduces prediction uncertainty, even when the data is noisy. The study also investigates how the frequency of data recording influences the size of the credible prediction interval, providing guidance on the optimal deployment of on-board sensors for effective track monitoring and maintenance planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08028v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>stat.AP</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huy Truong-Ba, Jacky Chin, Michael E. Cholette, Pietro Borghesani</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning from Human Feedback with High-Confidence Safety Constraints</title>
      <link>https://arxiv.org/abs/2506.08266</link>
      <description>arXiv:2506.08266v1 Announce Type: cross 
Abstract: Existing approaches to language model alignment often treat safety as a tradeoff against helpfulness, which can lead to unacceptable responses in sensitive domains. To ensure reliable performance in such settings, we propose High-Confidence Safe Reinforcement Learning from Human Feedback (HC-RLHF), a method that provides high-confidence safety guarantees while maximizing helpfulness. Similar to previous methods, HC-RLHF explicitly decouples human preferences into helpfulness and harmlessness (safety), which are learned by training a reward model and a cost model, respectively. It then employs a two-step process to find safe solutions. In the first step, it optimizes the reward function under an intentionally pessimistic version of the cost constraint. In the second step, the trained model undergoes a safety test to verify whether its performance stays within an upper-confidence bound of the actual cost constraint. We provide a theoretical analysis of HC-RLHF, including proof that it will not return an unsafe solution with a probability greater than a user-specified threshold. For our empirical analysis, we apply HC-RLHF to align three different language models (Qwen2-1.5B, Qwen2.5-3B, and LLaMa3.2-3B) with human preferences. Our results demonstrate that HC-RLHF produces safe models with high probability and can improve harmlessness and helpfulness compared to previous methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08266v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>stat.AP</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yaswanth Chittepu, Blossom Metevier, Will Schwarzer, Austin Hoag, Scott Niekum, Philip S. Thomas</dc:creator>
    </item>
    <item>
      <title>Flexible and Efficient Drift Detection without Labels</title>
      <link>https://arxiv.org/abs/2506.08734</link>
      <description>arXiv:2506.08734v1 Announce Type: cross 
Abstract: Machine learning models are being increasingly used to automate decisions in almost every domain, and ensuring the performance of these models is crucial for ensuring high quality machine learning enabled services. Ensuring concept drift is detected early is thus of the highest importance. A lot of research on concept drift has focused on the supervised case that assumes the true labels of supervised tasks are available immediately after making predictions. Controlling for false positives while monitoring the performance of predictive models used to make inference from extremely large datasets periodically, where the true labels are not instantly available, becomes extremely challenging. We propose a flexible and efficient concept drift detection algorithm that uses classical statistical process control in a label-less setting to accurately detect concept drifts. We shown empirically that under computational constraints, our approach has better statistical power than previous known methods. Furthermore, we introduce a new drift detection framework to model the scenario of detecting drift (without labels) given prior detections, and show our how our drift detection algorithm can be incorporated effectively into this framework. We demonstrate promising performance via numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08734v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nelvin Tan, Yu-Ching Shih, Dong Yang, Amol Salunkhe</dc:creator>
    </item>
    <item>
      <title>A calibrated BISG for inferring race from surname and geolocation</title>
      <link>https://arxiv.org/abs/2304.09126</link>
      <description>arXiv:2304.09126v4 Announce Type: replace 
Abstract: Bayesian Improved Surname Geocoding (BISG) is a ubiquitous tool for predicting race and ethnicity using an individual's geolocation and surname. Here we demonstrate that statistical dependence of surname and geolocation within racial/ethnic categories in the United States results in biases for minority subpopulations, and we introduce a raking-based improvement. Our method augments the data used by BISG--distributions of race by geolocation and race by surname--with the distribution of surname by geolocation obtained from state voter files. We validate our algorithm on state voter registration lists that contain self-identified race/ethnicity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.09126v4</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philip Greengard, Andrew Gelman</dc:creator>
    </item>
    <item>
      <title>A primer on inference and prediction with epidemic renewal models and sequential Monte Carlo</title>
      <link>https://arxiv.org/abs/2503.18875</link>
      <description>arXiv:2503.18875v2 Announce Type: replace-cross 
Abstract: Renewal models are widely used in statistical epidemiology as semi-mechanistic models of disease transmission. While primarily used for estimating the instantaneous reproduction number, they can also be used for generating projections, estimating elimination probabilities, modelling the effect of interventions, and more. We demonstrate how simple sequential Monte Carlo methods (also known as particle filters) can be used to perform inference on these models. Our goal is to acquaint a reader who has a working knowledge of statistical inference with these methods and models and to provide a practical guide to their implementation. We focus on these methods' flexibility and their ability to handle multiple statistical and other biases simultaneously. We leverage this flexibility to unify existing methods for estimating the instantaneous reproduction number and generating projections. A companion website SMC and epidemic renewal models provides additional worked examples, self-contained code to reproduce the examples presented here, and additional materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18875v2</guid>
      <category>stat.ME</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nicholas Steyn, Kris V. Parag, Robin N. Thompson, Christl A. Donnelly</dc:creator>
    </item>
    <item>
      <title>Continuous Temporal Learning of Probability Distributions via Neural ODEs with Applications in Continuous Glucose Monitoring Data</title>
      <link>https://arxiv.org/abs/2505.08698</link>
      <description>arXiv:2505.08698v2 Announce Type: replace-cross 
Abstract: Modeling the dynamics of probability distributions from time-dependent data samples is a fundamental problem in many fields, including digital health. The goal is to analyze how the distribution of a biomarker, such as glucose, changes over time and how these changes may reflect the progression of chronic diseases like diabetes. We introduce a probabilistic model based on a Gaussian mixture that captures the evolution of a continuous-time stochastic process. Our approach combines a non-parametric estimate of the distribution, obtained with Maximum Mean Discrepancy (MMD), and a Neural Ordinary Differential Equation (Neural ODE) that governs the temporal evolution of the mixture weights. The model is highly interpretable, detects subtle distribution shifts, and remains computationally efficient. Simulation studies show that our method matches or surpasses the estimation accuracy of state-of-the-art, less interpretable techniques such as normalizing flows and non-parametric kernel density estimators. We further demonstrate its utility using data from a digital clinical trial, revealing how interventions affect the time-dependent distribution of glucose levels. The proposed method enables rigorous comparisons between control and treatment groups from both mathematical and clinical perspectives, offering novel longitudinal characterizations that existing approaches cannot achieve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08698v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Antonio \'Alvarez-L\'opez, Marcos Matabuena</dc:creator>
    </item>
    <item>
      <title>Robust Distributed Estimation: Extending Gossip Algorithms to Ranking and Trimmed Means</title>
      <link>https://arxiv.org/abs/2505.17836</link>
      <description>arXiv:2505.17836v4 Announce Type: replace-cross 
Abstract: This paper addresses the problem of robust estimation in gossip algorithms over arbitrary communication graphs. Gossip algorithms are fully decentralized, relying only on local neighbor-to-neighbor communication, making them well-suited for situations where communication is constrained. A fundamental challenge in existing mean-based gossip algorithms is their vulnerability to malicious or corrupted nodes. In this paper, we show that an outlier-robust mean can be computed by globally estimating a robust statistic. More specifically, we propose a novel gossip algorithm for rank estimation, referred to as \textsc{GoRank}, and leverage it to design a gossip procedure dedicated to trimmed mean estimation, coined \textsc{GoTrim}. In addition to a detailed description of the proposed methods, a key contribution of our work is a precise convergence analysis: we establish an $\mathcal{O}(1/t)$ rate for rank estimation and an $\mathcal{O}((\log t)/\sqrt{t})$ rate for trimmed mean estimation, where by $t$ is meant the number of iterations. Moreover, we provide a breakdown point analysis of \textsc{GoTrim}. We empirically validate our theoretical results through experiments on diverse network topologies, data distributions and contamination schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17836v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Van Elst, Igor Colin, Stephan Cl\'emen\c{c}on</dc:creator>
    </item>
  </channel>
</rss>
