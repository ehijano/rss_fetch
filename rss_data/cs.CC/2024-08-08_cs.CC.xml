<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 09 Aug 2024 01:35:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 08 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the geometry of $k$-SAT solutions: what more can PPZ and Sch\"oning's algorithms do?</title>
      <link>https://arxiv.org/abs/2408.03465</link>
      <description>arXiv:2408.03465v1 Announce Type: new 
Abstract: Given a $k$-CNF formula and an integer $s$, we study algorithms that obtain $s$ solutions to the formula that are maximally dispersed. For $s=2$, the problem of computing the diameter of a $k$-CNF formula was initiated by Creszenzi and Rossi, who showed strong hardness results even for $k=2$. Assuming SETH, the current best upper bound [Angelsmark and Thapper '04] goes to $4^n$ as $k \rightarrow \infty$. As our first result, we give exact algorithms for using the Fast Fourier Transform and clique-finding that run in $O^*(2^{(s-1)n})$ and $O^*(s^2 |\Omega_{F}|^{\omega \lceil s/3 \rceil})$ respectively, where $|\Omega_{F}|$ is the size of the solution space of the formula $F$ and $\omega$ is the matrix multiplication exponent.
  As our main result, we re-analyze the popular PPZ (Paturi, Pudlak, Zane '97) and Sch\"{o}ning's ('02) algorithms (which find one solution in time $O^*(2^{\varepsilon_{k}n})$ for $\varepsilon_{k} \approx 1-\Theta(1/k)$), and show that in the same time, they can be used to approximate the diameter as well as the dispersion ($s&gt;2$) problems. While we need to modify Sch\"{o}ning's original algorithm, we show that the PPZ algorithm, without any modification, samples solutions in a geometric sense. We believe that this property may be of independent interest.
  Finally, we present algorithms to output approximately diverse, approximately optimal solutions to NP-complete optimization problems running in time $\text{poly}(s)O^*(2^{\varepsilon n})$ with $\varepsilon&lt;1$ for several problems such as Minimum Hitting Set and Feedback Vertex Set. For these problems, all existing exact methods for finding optimal diverse solutions have a runtime with at least an exponential dependence on the number of solutions $s$. Our methods find bi-approximations with polynomial dependence on $s$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03465v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Per Austrin, Ioana O. Bercea, Mayank Goswami, Nutan Limaye, Adarsh Srinivasan</dc:creator>
    </item>
    <item>
      <title>Artifical intelligence and inherent mathematical difficulty</title>
      <link>https://arxiv.org/abs/2408.03345</link>
      <description>arXiv:2408.03345v1 Announce Type: cross 
Abstract: This paper explores the relationship of artificial intelligence to the task of resolving open questions in mathematics. We first present an updated version of a traditional argument that limitative results from computability and complexity theory show that proof discovery is an inherently difficult problem. We then illustrate how several recent applications of artificial intelligence-inspired methods -- respectively involving automated theorem proving, SAT-solvers, and large language models -- do indeed raise novel questions about the nature of mathematical proof. We also argue that the results obtained by such techniques do not tell against our basic argument. This is so because they are embodiments of brute force search and are thus capable of deciding only statements of low logical complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03345v1</guid>
      <category>math.HO</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>math.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Walter Dean (University of Warwick), Alberto Naibo (Universit\'e Paris 1 Panth\'eon-Sorbonne)</dc:creator>
    </item>
    <item>
      <title>Hard to Explain: On the Computational Hardness of In-Distribution Model Interpretation</title>
      <link>https://arxiv.org/abs/2408.03915</link>
      <description>arXiv:2408.03915v1 Announce Type: cross 
Abstract: The ability to interpret Machine Learning (ML) models is becoming increasingly essential. However, despite significant progress in the field, there remains a lack of rigorous characterization regarding the innate interpretability of different models. In an attempt to bridge this gap, recent work has demonstrated that it is possible to formally assess interpretability by studying the computational complexity of explaining the decisions of various models. In this setting, if explanations for a particular model can be obtained efficiently, the model is considered interpretable (since it can be explained ``easily''). However, if generating explanations over an ML model is computationally intractable, it is considered uninterpretable. Prior research identified two key factors that influence the complexity of interpreting an ML model: (i) the type of the model (e.g., neural networks, decision trees, etc.); and (ii) the form of explanation (e.g., contrastive explanations, Shapley values, etc.). In this work, we claim that a third, important factor must also be considered for this analysis -- the underlying distribution over which the explanation is obtained. Considering the underlying distribution is key in avoiding explanations that are socially misaligned, i.e., convey information that is biased and unhelpful to users. We demonstrate the significant influence of the underlying distribution on the resulting overall interpretation complexity, in two settings: (i) prediction models paired with an external out-of-distribution (OOD) detector; and (ii) prediction models designed to inherently generate socially aligned explanations. Our findings prove that the expressiveness of the distribution can significantly influence the overall complexity of interpretation, and identify essential prerequisites that a model must possess to generate socially aligned explanations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03915v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guy Amir, Shahaf Bassan, Guy Katz</dc:creator>
    </item>
    <item>
      <title>Quantum Advantages in (n,d)-&gt;1 Random Access Codes</title>
      <link>https://arxiv.org/abs/1510.03045</link>
      <description>arXiv:1510.03045v2 Announce Type: replace-cross 
Abstract: A random access code (RAC), corresponding to a communication primitive with various applications in quantum information theory, is an instance of a preparation-and-measurement scenario. In this work, we consider (n,d)-RACs constituting an "n"-length string, constructed from a "d" size set of letters, and send an encoding of the string in a single d-level physical system and present their quantum advantages. We first characterize optimal classical RACs, proving that the well-known classical strategy known as majority-encoding-identity-decoding is indeed optimal. We then construct a quantum protocol by exploiting only two incompatible measurements, the minimal requirement, and show the advantages beyond the classical one. We also discuss the generality of our results and whether quantum advantages are valid for all types of (n, d)-&gt;1 RACs.</description>
      <guid isPermaLink="false">oai:arXiv.org:1510.03045v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andris Ambainis, Dmitry Kravchenko, Sk Sazim, Joonwoo Bae, Ashutosh Rai</dc:creator>
    </item>
    <item>
      <title>Circuit-to-Hamiltonian from tensor networks and fault tolerance</title>
      <link>https://arxiv.org/abs/2309.16475</link>
      <description>arXiv:2309.16475v2 Announce Type: replace-cross 
Abstract: We define a map from an arbitrary quantum circuit to a local Hamiltonian whose ground state encodes the quantum computation. All previous maps relied on the Feynman-Kitaev construction, which introduces an ancillary `clock register' to track the computational steps. Our construction, on the other hand, relies on injective tensor networks with associated parent Hamiltonians, avoiding the introduction of a clock register. This comes at the cost of the ground state containing only a noisy version of the quantum computation, with independent stochastic noise. We can remedy this - making our construction robust - by using quantum fault tolerance. In addition to the stochastic noise, we show that any state with energy density exponentially small in the circuit depth encodes a noisy version of the quantum computation with adversarial noise. We also show that any `combinatorial state' with energy density polynomially small in depth encodes the quantum computation with adversarial noise. This serves as evidence that any state with energy density polynomially small in depth has a similar property. As applications, we give a new proof of the QMA-completeness of the local Hamiltonian problem (with logarithmic locality) and show that contracting injective tensor networks to additive error is BQP-hard. We also discuss the implication of our construction to the quantum PCP conjecture, combining with an observation that QMA verification can be done in logarithmic depth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.16475v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3618260.3649690</arxiv:DOI>
      <arxiv:journal_reference>In Proceedings of the 56th Annual ACM Symposium on Theory of Computing (STOC 2024), pp. 585-595</arxiv:journal_reference>
      <dc:creator>Anurag Anshu, Nikolas P. Breuckmann, Quynh T. Nguyen</dc:creator>
    </item>
  </channel>
</rss>
