<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 05 May 2025 04:00:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Dynamic and Distributed Routing in IoT Networks based on Multi-Objective Q-Learning</title>
      <link>https://arxiv.org/abs/2505.00918</link>
      <description>arXiv:2505.00918v1 Announce Type: new 
Abstract: The last few decades have witnessed a rapid increase in IoT devices owing to their wide range of applications, such as smart healthcare monitoring systems, smart cities, and environmental monitoring. A critical task in IoT networks is sensing and transmitting information over the network. The IoT nodes gather data by sensing the environment and then transmit this data to a destination node via multi-hop communication, following some routing protocols. These protocols are usually designed to optimize possibly contradictory objectives, such as maximizing packet delivery ratio and energy efficiency. While most literature has focused on optimizing a static objective that remains unchanged, many real-world IoT applications require adapting to rapidly shifting priorities. For example, in monitoring systems, some transmissions are time-critical and require a high priority on low latency, while other transmissions are less urgent and instead prioritize energy efficiency. To meet such dynamic demands, we propose novel dynamic and distributed routing based on multiobjective Q-learning that can adapt to changes in preferences in real-time. Our algorithm builds on ideas from both multi-objective optimization and Q-learning. We also propose a novel greedy interpolation policy scheme to take near-optimal decisions for unexpected preference changes. The proposed scheme can approximate and utilize the Pareto-efficient solutions for dynamic preferences, thus utilizing past knowledge to adapt to unpredictable preferences quickly during runtime. Simulation results show that the proposed scheme outperforms state-of-the-art algorithms for various exploration strategies, preference variation patterns, and important metrics like overall reward, energy efficiency, and packet delivery ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00918v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shubham Vaishnav, Praveen Kumar Donta, Sindri Magn\'usson</dc:creator>
    </item>
    <item>
      <title>ConflictSync: Bandwidth Efficient Synchronization of Divergent State</title>
      <link>https://arxiv.org/abs/2505.01144</link>
      <description>arXiv:2505.01144v1 Announce Type: new 
Abstract: State-based Conflict-free Replicated Data Types (CRDTs) are widely used in distributed systems to ensure high availability without coordination. However, their naive synchronization strategy - transmitting the full state - incurs high communication costs. Existing optimizations like delta-CRDTs reduce this overhead but rely on external metadata that must be garbage collected to prevent unbounded growth, at the cost of full state transmissions after network partitions.
  This paper presents ConflictSync, the first digest-driven synchronization algorithm for state-based CRDTs. We reduce synchronization to the set reconciliation of irredundant join decompositions and build on existing work in rateless set reconciliation. To support CRDTs, we generalize set reconciliation to variable-sized elements, and further introduce a novel combination of Bloom filters with Rateless Invertible Bloom Lookup Tables to address inefficiencies at low similarity levels.
  Our evaluation shows that ConflictSync reduces total data transfer by up to 18 times compared to traditional state-based synchronization. Bloom filter prefiltering reduces overhead by up to 50% compared to pure rateless reconciliation at 0% similarity, while pure rateless reconciliation performs better above 93% similarity. We characterize the trade-off between similarity level and Bloom filter size, identifying optimal configurations for different synchronization scenarios.
  Although developed for CRDTs, ConflictSync applies to any synchronization problem where states can be decomposed into sets of constituent components, analogous to join decompositions, making it suitable for a wide range of distributed data models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01144v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pedro Silva Gomes, Miguel Boaventura Rodrigues, Carlos Baquero</dc:creator>
    </item>
    <item>
      <title>CaGR-RAG: Context-aware Query Grouping for Disk-based Vector Search in RAG Systems</title>
      <link>https://arxiv.org/abs/2505.01164</link>
      <description>arXiv:2505.01164v1 Announce Type: new 
Abstract: Modern embedding models capture both semantic and syntactic structures of queries, often mapping different queries to similar regions in vector space. This results in non-uniform cluster access patterns in disk-based vector search systems, particularly in Retrieval Augmented Generation (RAG) framework. While existing approaches optimize individual queries, they overlook the impact of cluster access patterns, failing to account for the locality effects of queries that access similar clusters. This oversight reduces cache efficiency and increases search latency due to excessive disk I/O. To address this, we introduce CaGR-RAG, a context-aware query grouping mechanism that organizes queries based on shared cluster access patterns. Additionally, it incorporates opportunistic cluster prefetching to minimize cache misses during transitions between query groups, further optimizing retrieval performance. Experimental results show that CaGR-RAG reduces 99th percentile tail latency by up to 51.55% while consistently maintaining a higher cache hit ratio than the baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01164v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yeonwoo Jeong, Kyuli Park, Hyunji Cho, Sungyong Park</dc:creator>
    </item>
    <item>
      <title>Distributed Quantum Circuit Cutting for Hybrid Quantum-Classical High-Performance Computing</title>
      <link>https://arxiv.org/abs/2505.01184</link>
      <description>arXiv:2505.01184v1 Announce Type: new 
Abstract: Most quantum computers today are constrained by hardware limitations, particularly the number of available qubits, causing significant challenges for executing large-scale quantum algorithms. Circuit cutting has emerged as a key technique to overcome these limitations by decomposing large quantum circuits into smaller subcircuits that can be executed independently and later reconstructed. In this work, we introduce Qdislib, a distributed and flexible library for quantum circuit cutting, designed to seamlessly integrate with hybrid quantum-classical high-performance computing (HPC) systems. Qdislib employs a graph-based representation of quantum circuits to enable efficient partitioning, manipulation and execution, supporting both wire cutting and gate cutting techniques. The library is compatible with multiple quantum computing libraries, including Qiskit and Qibo, and leverages distributed computing frameworks to execute subcircuits across CPUs, GPUs, and quantum processing units (QPUs) in a fully parallelized manner. We present a proof of concept demonstrating how Qdislib enables the distributed execution of quantum circuits across heterogeneous computing resources, showcasing its potential for scalable quantum-classical workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01184v1</guid>
      <category>cs.DC</category>
      <category>quant-ph</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mar Tejedor, Berta Casas, Javier Conejero, Alba Cervera-Lierta, Rosa M. Badia</dc:creator>
    </item>
    <item>
      <title>A Space-Time Trade-off for Fast Self-Stabilizing Leader Election in Population Protocols</title>
      <link>https://arxiv.org/abs/2505.01210</link>
      <description>arXiv:2505.01210v1 Announce Type: new 
Abstract: We consider the problem of self-stabilizing leader election in the population model by Angluin, Aspnes, Diamadi, Fischer, and Peralta (JDistComp '06). The population model is a well-established and powerful model for asynchronous, distributed computation with a large number of applications. For self-stabilizing leader election, the population of $n$ anonymous agents, interacting in uniformly random pairs, must stabilize with a single leader from any possible initial configuration.
  The focus of this paper is to develop time-efficient self-stabilizing protocols whilst minimizing the number of states. We present a parametrized protocol, which, for a suitable setting, achieves the asymptotically optimal time $O(\log n)$ using $2^{O(n^2\log n)}$ states (throughout the paper, ``time'' refers to ``parallel time'', i.e., the number of pairwise interactions divided by $n$). This is a significant improvement over the previously best protocol Sublinear-Time-SSR due to Burman, Chen, Chen, Doty, Nowak, Severson, and Xu (PODC '21), which requires $2^{O(n^{\log n}\log n)}$ states for the same time bound. In general, for $1\le r\le n/2$, our protocol requires $2^{O(r^2\log{n})}$ states and stabilizes in time $O((n\log{n})/r)$, w.h.p.; the above result is achieved for $r=\Theta(n)$. For $r=\log^2n$ our protocol requires only sub-linear time using only $2^{O(\log^3 n)}$ states, resolving an open problem stated in that paper. Sublinear-Time-SSR requires $O(\log n\cdot n^{1/(H+1)})$ time using $2^{\Theta(n^H) \cdot \log n}$ states for all $1\le H\le\Theta(\log n)$.
  Similar to previous works, it solves leader election by assigning a unique rank from $1$ through $n$ to each agent. The principal bottleneck for self-stabilizing ranking usually is to detect if there exist agents with the same rank. One of our main conceptual contributions is a novel technique for collision detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01210v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henry Austin, Petra Berenbrink, Tom Friedetzky, Thorsten G\"otte, Lukas Hintze</dc:creator>
    </item>
    <item>
      <title>A Self-Healing and Fault-Tolerant Cloud-based Digital Twin Processing Management Model</title>
      <link>https://arxiv.org/abs/2505.01215</link>
      <description>arXiv:2505.01215v1 Announce Type: new 
Abstract: Digital twins, integral to cloud platforms, bridge physical and virtual worlds, fostering collaboration among stakeholders in manufacturing and processing. However, the cloud platforms face challenges like service outages, vulnerabilities, and resource contention, hindering critical digital twin application development. The existing research works have limited focus on reliability and fault tolerance in digital twin processing. In this context, this paper proposed a novel Self-healing and Faulttolerant cloud-based Digital Twin processing Management (SF-DTM) model. It employs collaborative digital twin tasks resource requirement estimation unit which utilizes newly devised Federated learning with cosine Similarity integration (SimiFed). Further, SF-DTM incorporates a self-healing fault-tolerance strategy employing a frequent sequence fault-prone pattern analytics unit for deciding the most admissible VM allocation. The implementation and evaluation of SF-DTM model using real traces demonstrates its effectiveness and resilience, revealing improved availability, higher Mean Time Between Failure (MTBF), and lower Mean Time To Repair (MTTR) compared with non-SF-DTM approaches, enhancing collaborative DT application management. SF-DTM improved the services availability up to 13.2% over non-SF-DTM-based DT processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01215v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TII.2025.3540498</arxiv:DOI>
      <arxiv:journal_reference>IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS 2025</arxiv:journal_reference>
      <dc:creator>Deepika Saxena, Ashutosh Kumar Singh</dc:creator>
    </item>
    <item>
      <title>Towards Optimal Deterministic LOCAL Algorithms on Trees</title>
      <link>https://arxiv.org/abs/2505.01410</link>
      <description>arXiv:2505.01410v1 Announce Type: new 
Abstract: While obtaining optimal algorithms for the most important problems in the LOCAL model has been one of the central goals in the area of distributed algorithms since its infancy, tight complexity bounds are elusive for many problems even when considering \emph{deterministic} complexities on \emph{trees}. We take a step towards remedying this issue by providing a way to relate the complexity of a problem $\Pi$ on trees to its truly local complexity, which is the (asymptotically) smallest function $f$ such that $\Pi$ can be solved in $O(f(\Delta)+\log^*n)$ rounds. More specifically, we develop a transformation that takes an algorithm $\mathcal A$ for $\Pi$ with a runtime of $O(f(\Delta)+\log^*n)$ rounds as input and transforms it into an $O(f(g(n))+\log^* n)$-round algorithm $\mathcal{A}'$ on trees, where $g$ is the function that satisfies $g(n)^{f(g(n))}=n$. If $f$ is the truly local complexity of $\Pi$ (i.e., if $\mathcal{A}$ is asymptotically optimal), then $\mathcal{A}'$ is an asymptotically optimal algorithm on trees, conditioned on a natural assumption on the nature of the worst-case instances of $\Pi$. Our transformation works for any member of a wide class of problems, including the most important symmetry-breaking problems. As an example of our transformation we obtain the first strongly sublogarithmic algorithm for $(\text{edge-degree+1})$-edge coloring (and therefore also $(2\Delta-1)$-edge coloring) on trees, exhibiting a runtime of $O(\log^{12/13} n)$ rounds. This breaks through the $\Omega(\log n/\log\log n)$-barrier that is a fundamental lower bound for other symmetry-breaking problems such as maximal independent set or maximal matching (that already holds on trees), and proves a separation between these problems and the aforementioned edge coloring problems on trees. We extend a subset of our results to graphs of bounded arboricity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01410v1</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Brandt, Ananth Narayanan</dc:creator>
    </item>
    <item>
      <title>SemSpaceFL: A Collaborative Hierarchical Federated Learning Framework for Semantic Communication in 6G LEO Satellites</title>
      <link>https://arxiv.org/abs/2505.00966</link>
      <description>arXiv:2505.00966v1 Announce Type: cross 
Abstract: The advent of the sixth-generation (6G) wireless networks, enhanced by artificial intelligence, promises ubiquitous connectivity through Low Earth Orbit (LEO) satellites. These satellites are capable of collecting vast amounts of geographically diverse and real-time data, which can be immensely valuable for training intelligent models. However, limited inter-satellite communication and data privacy constraints hinder data collection on a single server for training. Therefore, we propose SemSpaceFL, a novel hierarchical federated learning (HFL) framework for LEO satellite networks, with integrated semantic communication capabilities. Our framework introduces a two-tier aggregation architecture where satellite models are first aggregated at regional gateways before final consolidation at a cloud server, which explicitly accounts for satellite mobility patterns and energy constraints. The key innovation lies in our novel aggregation approach, which dynamically adjusts the contribution of each satellite based on its trajectory and association with different gateways, which ensures stable model convergence despite the highly dynamic nature of LEO constellations. To further enhance communication efficiency, we incorporate semantic encoding-decoding techniques trained through the proposed HFL framework, which enables intelligent data compression while maintaining signal integrity. Our experimental results demonstrate that the proposed aggregation strategy achieves superior performance and faster convergence compared to existing benchmarks, while effectively managing the challenges of satellite mobility and energy limitations in dynamic LEO networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00966v1</guid>
      <category>cs.IT</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Loc X. Nguyen, Sheikh Salman Hassan, Yu Min Park, Yan Kyaw Tun, Zhu Han, Choong Seon Hong</dc:creator>
    </item>
    <item>
      <title>Accelerating Deep Neural Network Training via Distributed Hybrid Order Optimization</title>
      <link>https://arxiv.org/abs/2505.00982</link>
      <description>arXiv:2505.00982v1 Announce Type: cross 
Abstract: Scaling deep neural network (DNN) training to more devices can reduce time-to-solution. However, it is impractical for users with limited computing resources. FOSI, as a hybrid order optimizer, converges faster than conventional optimizers by taking advantage of both gradient information and curvature information when updating the DNN model. Therefore, it provides a new chance for accelerating DNN training in the resource-constrained setting. In this paper, we explore its distributed design, namely DHO$_2$, including distributed calculation of curvature information and model update with partial curvature information to accelerate DNN training with a low memory burden. To further reduce the training time, we design a novel strategy to parallelize the calculation of curvature information and the model update on different devices. Experimentally, our distributed design can achieve an approximate linear reduction of memory burden on each device with the increase of the device number. Meanwhile, it achieves $1.4\times\sim2.1\times$ speedup in the total training time compared with other distributed designs based on conventional first- and second-order optimizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00982v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shunxian Gu, Chaoqun You, Bangbang Ren, Lailong Luo, Junxu Xia, Deke Guo</dc:creator>
    </item>
    <item>
      <title>Nesterov Method for Asynchronous Pipeline Parallel Optimization</title>
      <link>https://arxiv.org/abs/2505.01099</link>
      <description>arXiv:2505.01099v1 Announce Type: cross 
Abstract: Pipeline Parallelism (PP) enables large neural network training on small, interconnected devices by splitting the model into multiple stages. To maximize pipeline utilization, asynchronous optimization is appealing as it offers 100% pipeline utilization by construction. However, it is inherently challenging as the weights and gradients are no longer synchronized, leading to stale (or delayed) gradients. To alleviate this, we introduce a variant of Nesterov Accelerated Gradient (NAG) for asynchronous optimization in PP. Specifically, we modify the look-ahead step in NAG to effectively address the staleness in gradients. We theoretically prove that our approach converges at a sublinear rate in the presence of fixed delay in gradients. Our experiments on large-scale language modelling tasks using decoder-only architectures with up to 1B parameters, demonstrate that our approach significantly outperforms existing asynchronous methods, even surpassing the synchronous baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01099v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thalaiyasingam Ajanthan, Sameera Ramasinghe, Yan Zuo, Gil Avraham, Alexander Long</dc:creator>
    </item>
    <item>
      <title>Secure Cluster-Based Hierarchical Federated Learning in Vehicular Networks</title>
      <link>https://arxiv.org/abs/2505.01186</link>
      <description>arXiv:2505.01186v1 Announce Type: cross 
Abstract: Hierarchical Federated Learning (HFL) has recently emerged as a promising solution for intelligent decision-making in vehicular networks, helping to address challenges such as limited communication resources, high vehicle mobility, and data heterogeneity. However, HFL remains vulnerable to adversarial and unreliable vehicles, whose misleading updates can significantly compromise the integrity and convergence of the global model. To address these challenges, we propose a novel defense framework that integrates dynamic vehicle selection with robust anomaly detection within a cluster-based HFL architecture, specifically designed to counter Gaussian noise and gradient ascent attacks. The framework performs a comprehensive reliability assessment for each vehicle by evaluating historical accuracy, contribution frequency, and anomaly records. Anomaly detection combines Z-score and cosine similarity analyses on model updates to identify both statistical outliers and directional deviations in model updates. To further refine detection, an adaptive thresholding mechanism is incorporated into the cosine similarity metric, dynamically adjusting the threshold based on the historical accuracy of each vehicle to enforce stricter standards for consistently high-performing vehicles. In addition, a weighted gradient averaging mechanism is implemented, which assigns higher weights to gradient updates from more trustworthy vehicles. To defend against coordinated attacks, a cross-cluster consistency check is applied to identify collaborative attacks in which multiple compromised clusters coordinate misleading updates. Together, these mechanisms form a multi-level defense strategy to filter out malicious contributions effectively. Simulation results show that the proposed algorithm significantly reduces convergence time compared to benchmark methods across both 1-hop and 3-hop topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01186v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Saeid HaghighiFard, Sinem Coleri</dc:creator>
    </item>
    <item>
      <title>Notes on Theory of Distributed Systems</title>
      <link>https://arxiv.org/abs/2001.04235</link>
      <description>arXiv:2001.04235v5 Announce Type: replace 
Abstract: Notes for the Yale course CPSC 465/565 Theory of Distributed Systems.

Table of Contents: 1 Introduction, 2 Model, 3 Broadcast and convergecast, 4 Distributed breadth-first search, 5 Leader election, 6 Causal ordering and logical clocks, 7 Synchronizers, 8 Coordinated attack, 9 Synchronous agreement, 10 Byzantine agreement, 11 Impossibility of asynchronous agreement, 12 Paxos, 13 Failure detectors, 14 Quorum systems, 15 Permissionless systems, 16 Model, 17 Distributed shared memory, 18 Mutual exclusion, 19 The wait-free hierarchy, 20 Atomic snapshots, 21 Lower bounds on perturbable objects, 22 Restricted-use objects, 23 Common2, 24 Randomized consensus and test-and-set, 25 Renaming, 26 Software transactional memory, 27 Obstruction-freedom, 28 BG simulation, 29 Topological methods, 30 Approximate agreement, 31 Overview, 32 Self-stabilization, 33 Distributed graph algorithms, 34 Population protocols, 35 Mobile robots, 36 Beeping</description>
      <guid isPermaLink="false">oai:arXiv.org:2001.04235v5</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>James Aspnes</dc:creator>
    </item>
    <item>
      <title>FlexLLM: A System for Co-Serving Large Language Model Inference and Parameter-Efficient Finetuning</title>
      <link>https://arxiv.org/abs/2402.18789</link>
      <description>arXiv:2402.18789v2 Announce Type: replace 
Abstract: Finetuning large language models (LLMs) is essential for task adaptation, yet serving stacks today isolate inference and finetuning on separate GPU clusters -- wasting resources and under-utilizing hardware. We introduce FlexLLM, the first system to co-serve LLM inference and PEFT-based finetuning on shared GPUs by fusing computation at the token level. The static compilation optimizations in FlexLLM -- dependent parallelization and graph pruning significantly shrink activation memory, leading to end-to-end GPU memory savings by up to 80%. At runtime, a novel token-level finetuning mechanism paired with a hybrid token scheduler dynamically interleaves inference and training tokens within each co-serving iteration, meeting strict latency SLOs while maximizing utilization. In end-to-end benchmarks on LLaMA-3.1-8B, Qwen-2.5-14B, and Qwen-2.5-32B, FlexLLM sustains the inference SLO requirements up to 20 req/s, and improves finetuning throughput by 1.9-4.8x under heavy inference workloads and 2.5-6.8x under light loads, preserving over 76% of peak finetuning progress even at peak demand. The source code of FlexLLM is publicly available at https://github.com/flexflow/FlexFlow/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18789v2</guid>
      <category>cs.DC</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriele Oliaro, Xupeng Miao, Xinhao Cheng, Vineeth Kada, Ruohan Gao, Yingyi Huang, Remi Delacourt, April Yang, Yingcheng Wang, Mengdi Wu, Colin Unger, Zhihao Jia</dc:creator>
    </item>
    <item>
      <title>Minimalist Leader Election Under Weak Communication</title>
      <link>https://arxiv.org/abs/2502.12697</link>
      <description>arXiv:2502.12697v2 Announce Type: replace 
Abstract: We propose a protocol to solve Leader Election within weak communication models such as the beeping model or the stone-age model. Unlike most previous work, our algorithm operates on only six states, does not require unique identifiers, and assumes no prior knowledge of the network's size or topology, i.e., it is uniform. We show that under our protocol, the system almost surely converges to a configuration in which a single node is in a leader state. With high probability, this occurs in fewer than $O(D^2 \log n)$ rounds, where $D$ is the network diameter. We also show that this can be decreased to $O(D \log n)$ when a constant factor approximation of $D$ is known. The main drawbacks of our approach are a $\Tilde{\Omega}(D)$ overhead in the running time compared to algorithms with stronger requirements, and the fact that nodes are unaware of when a single-leader configuration is reached. Nevertheless, the minimal assumptions and natural appeal of our solution make it particularly well-suited for implementation in the simplest distributed systems, especially biological ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12697v2</guid>
      <category>cs.DC</category>
      <pubDate>Mon, 05 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robin Vacus, Isabella Ziccardi</dc:creator>
    </item>
  </channel>
</rss>
