<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Oct 2025 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Query Optimization in the Wild: Realities and Trends</title>
      <link>https://arxiv.org/abs/2510.20082</link>
      <description>arXiv:2510.20082v1 Announce Type: new 
Abstract: For nearly half a century, the core design of query optimizers in industrial database systems has remained remarkably stable, relying on foundational principles from System R and the Volcano/Cascades framework. However, the rise of cloud computing, massive data volumes, and unified data platforms has exposed the limitations of this traditional, monolithic architecture. Taking an industrial perspective, this paper reviews the past and present of query optimization in production systems and identifies the challenges they face today. Then this paper highlights three key trends gaining momentum in the industry that promise to address these challenges. First, a tighter feedback loop between query optimization and query execution is being used to improve the robustness of query performance. Second, the scope of optimization is expanding from a single query to entire workloads through the convergence of query optimization and workload optimization. Third, and perhaps most transformatively, the industry is moving from monolithic designs to composable architectures that foster agility and cross-engine collaboration. Together, these trends chart a clear path toward a more dynamic, holistic, and adaptable future for query optimization in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20082v1</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanyuan Tian</dc:creator>
    </item>
    <item>
      <title>UREM: A High-performance Unified and Resilient Enhancement Method for Multi- and High-Dimensional Indexes</title>
      <link>https://arxiv.org/abs/2510.20110</link>
      <description>arXiv:2510.20110v1 Announce Type: new 
Abstract: Numerous multi- or high-dimensional indexes with distinct advantages have been proposed on various platforms to meet application requirements. To achieve higher-performance queries, most indexes employ enhancement methods, including structure-oriented and layout-oriented enhancement methods. Existing structure-oriented methods tailored to specific indexes work well under static workloads but lack generality and degrade under dynamic workloads. The layout-oriented methods exhibit good generality and perform well under dynamic workloads, but exhibit suboptimal performance under static workloads. Therefore, it is an open challenge to develop a unified and resilient enhancement method that can improve query performance for different indexes adaptively under different scenarios. In this paper, we propose UREM, which is the first high-performance Unified and Resilient Enhancement Method designed for both multi- and high-dimensional indexes, capable of adapting to different scenarios. Specifically, UREM (1) can be uniformly applied with different indexes on various platforms; (2) enhances the query performance of indexes by layout optimization under static workloads; (3) enables indexes to stabilize performance when queries shift through partial layout reorganization. We evaluate UREM on 20 widely used indexes. Experimental results demonstrate that UREM improves the query performance of multi- and high-dimensional indexes by up to 5.73x and 9.18x under static workloads, and by an average of 5.72x and 9.47x under dynamic workloads. Moreover, some traditional indexes enhanced by UREM even achieve performance comparable to or even surpassing that of recent advanced indexes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20110v1</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming Sheng, Shuliang Wang, Yong Zhang, Yi Luo, Xianbo Liu, Zeming Li</dc:creator>
    </item>
    <item>
      <title>RAG-Stack: Co-Optimizing RAG Quality and Performance From the Vector Database Perspective</title>
      <link>https://arxiv.org/abs/2510.20296</link>
      <description>arXiv:2510.20296v1 Announce Type: new 
Abstract: Retrieval-augmented generation (RAG) has emerged as one of the most prominent applications of vector databases. By integrating documents retrieved from a database into the prompt of a large language model (LLM), RAG enables more reliable and informative content generation. While there has been extensive research on vector databases, many open research problems remain once they are considered in the wider context of end-to-end RAG pipelines. One practical yet challenging problem is how to jointly optimize both system performance and generation quality in RAG, which is significantly more complex than it appears due to the numerous knobs on both the algorithmic side (spanning models and databases) and the systems side (from software to hardware). In this paper, we present RAG-Stack, a three-pillar blueprint for quality-performance co-optimization in RAG systems. RAG-Stack comprises: (1) RAG-IR, an intermediate representation that serves as an abstraction layer to decouple quality and performance aspects; (2) RAG-CM, a cost model for estimating system performance given an RAG-IR; and (3) RAG-PE, a plan exploration algorithm that searches for high-quality, high-performance RAG configurations. We believe this three-pillar blueprint will become the de facto paradigm for RAG quality-performance co-optimization in the years to come.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20296v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenqi Jiang</dc:creator>
    </item>
    <item>
      <title>Hybrid Mixed Integer Linear Programming for Large-Scale Join Order Optimisation</title>
      <link>https://arxiv.org/abs/2510.20308</link>
      <description>arXiv:2510.20308v1 Announce Type: new 
Abstract: Finding optimal join orders is among the most crucial steps to be performed by query optimisers. Though extensively studied in data management research, the problem remains far from solved: While query optimisers rely on exhaustive search methods to determine ideal solutions for small problems, such methods reach their limits once queries grow in size. Yet, large queries become increasingly common in real-world scenarios, and require suitable methods to generate efficient execution plans. While a variety of heuristics have been proposed for large-scale query optimisation, they suffer from degrading solution quality as queries grow in size, or feature highly sub-optimal worst-case behavior, as we will show.
  We propose a novel method based on the paradigm of mixed integer linear programming (MILP): By deriving a novel MILP model capable of optimising arbitrary bushy tree structures, we address the limitations of existing MILP methods for join ordering, and can rely on highly optimised MILP solvers to derive efficient tree structures that elude competing methods. To ensure optimisation efficiency, we embed our MILP method into a hybrid framework, which applies MILP solvers precisely where they provide the greatest advantage over competitors, while relying on more efficient methods for less complex optimisation steps. Thereby, our approach gracefully scales to extremely large query sizes joining up to 100 relations, and consistently achieves the most robust plan quality among a large variety of competing join ordering methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20308v1</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manuel Sch\"onberger, Immanuel Trummer, Wolfgang Mauerer</dc:creator>
    </item>
    <item>
      <title>An Empirical Study on Database Usage in Microservices</title>
      <link>https://arxiv.org/abs/2510.20582</link>
      <description>arXiv:2510.20582v1 Announce Type: new 
Abstract: Microservices architectures are an integral part of modern software development. Their adoption brings significant changes to database management. Instead of relying on a single database, a microservices architecture is typically composed of multiple, smaller, heterogeneous, and distributed DBs. In these data-intensive systems, the variety and combination of database categories and technologies play a crucial role in storing and managing data. While data management in microservices is a major challenge, research literature is scarce.
  We present an empirical study on how databases are used in microservices. On the dataset we collected (and released as open data for future research), considering 15 years of microservices, we examine ca. 1,000 GitHub projects that use databases selected among 180 technologies from 14 categories. We perform a comprehensive analysis of current practices, providing researchers and practitioners with empirical evidence to better understand database usage in microservices. We report 18 findings and 9 recommendations. We show that microservices predominantly use Relational, Key-Value, Document, and Search databases. Notably, 52% of microservices combine multiple database categories. Complexity correlates with database count, with older systems favoring Relational databases and newer ones increasingly adopting Key-Value and Document technologies. Niche databases (e.g., EventStoreDB, PostGIS), while not widespread, are often combined with a mainstream one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20582v1</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maxime Andr\'e (University of Namur, Belgium), Marco Raglianti (REVEAL @ Software Institute - USI, Lugano, Switzerland), Souhaila Serbout (University of Zurich, Switzerland), Anthony Cleve (University of Namur, Belgium), Michele Lanza (REVEAL @ Software Institute - USI, Lugano, Switzerland)</dc:creator>
    </item>
    <item>
      <title>Balanced Popularity in Multi-Product Billboard Advertisement</title>
      <link>https://arxiv.org/abs/2510.20600</link>
      <description>arXiv:2510.20600v1 Announce Type: new 
Abstract: The billboard advertisement has emerged as an effective out-of-home advertisement technique where the objective is to choose a limited number of slots to play some advertisement content (e.g., animation, video, etc.) with the hope that the content will be visible to a large number of travelers, and this will be helpful to earn more revenue. In this paper, we study a variant of the influential slot selection problem where the advertiser wants to promote multiple products. Formally, we call this problem the \textsc{Multi-Product Influence Maximization Problem for the Balanced Popularity} Problem. The input to our problem is a trajectory and a billboard database, as well as a budget for each product. The goal here is to choose a subset of slots for each product such that the aggregated influence of all the products gets maximized subject to the following two constraints: total selection cost for each product is less than or equal to the allocated budget for that product, and the difference between the influence for any two products is less than or equal to a given threshold. We show that the problem is NP-hard to solve optimally. We formulate this problem as a linear programming problem and use linear programming relaxation with randomized rounding. Further, we propose a greedy-based heuristic with balance correction to solve this problem. We conduct a number of experiments with real-world trajectory and billboard datasets, and the results are reported. From the reported results, we observe that the proposed solution approaches lead to more influence compared to many baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20600v1</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dildar Ali, Suman Banerjee, Yamuna Prasad</dc:creator>
    </item>
    <item>
      <title>Downsizing Diffusion Models for Cardinality Estimation</title>
      <link>https://arxiv.org/abs/2510.20681</link>
      <description>arXiv:2510.20681v1 Announce Type: new 
Abstract: Inspired by the performance of score-based diffusion models in estimating complex text, video, and image distributions with thousands of dimensions, we introduce Accelerated Diffusion Cardest (ADC), the first joint distribution cardinality estimator based on a downsized diffusion model.
  To calculate the pointwise density value of data distributions, ADC's density estimator uses a formula that evaluates log-likelihood by integrating the score function, a gradient mapping which ADC has learned to efficiently approximate using its lightweight score estimator. To answer ranged queries, ADC's selectivity estimator first predicts their selectivity using a Gaussian Mixture Model (GMM), then uses importance sampling Monte Carlo to correct its predictions with more accurate pointwise density values calculated by the density estimator. ADC+ further trains a decision tree to identify the high-volume, high-selectivity queries that the GMM alone can predict very accurately, in which case it skips the correction phase to prevent Monte Carlo from adding more variance. Doing so lowers median Q-error and cuts per-query latency by 25 percent, making ADC+ usually twice as fast as Naru, arguably the state-of-the-art joint distribution cardinality estimator.
  Numerical experiments using well-established benchmarks show that on all real-world datasets tested, ADC+ is capable of rivaling Naru and outperforming MSCN, DeepDB, LW-Tree, and LW-NN using around 66 percent their storage space, being at least 3 times as accurate as MSCN on 95th and 99th percentile error. Furthermore, on a synthetic dataset where attributes exhibit complex, multilateral correlations, ADC and ADC+ are considerably robust while almost every other learned model suffered significant accuracy declines. In this case, ADC+ performs better than any other tested model, being 10 times as accurate as Naru on 95th and 99th percentile error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20681v1</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinhe Mu, Zhaoqi Zhou, Zaijiu Shang, Chuan Zhou, Gang Fu, Guiying Yan, Guoliang Li, Zhiming Ma</dc:creator>
    </item>
    <item>
      <title>RELATE: A Schema-Agnostic Perceiver Encoder for Multimodal Relational Graphs</title>
      <link>https://arxiv.org/abs/2510.19954</link>
      <description>arXiv:2510.19954v1 Announce Type: cross 
Abstract: Relational multi-table data is common in domains such as e-commerce, healthcare, and scientific research, and can be naturally represented as heterogeneous temporal graphs with multi-modal node attributes. Existing graph neural networks (GNNs) rely on schema-specific feature encoders, requiring separate modules for each node type and feature column, which hinders scalability and parameter sharing. We introduce RELATE (Relational Encoder for Latent Aggregation of Typed Entities), a schema-agnostic, plug-and-play feature encoder that can be used with any general purpose GNN. RELATE employs shared modality-specific encoders for categorical, numerical, textual, and temporal attributes, followed by a Perceiver-style cross-attention module that aggregates features into a fixed-size, permutation-invariant node representation. We evaluate RELATE on ReLGNN and HGT in the RelBench benchmark, where it achieves performance within 3% of schema-specific encoders while reducing parameter counts by up to 5x. This design supports varying schemas and enables multi-dataset pretraining for general-purpose GNNs, paving the way toward foundation models for relational graph data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19954v1</guid>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph Meyer, Divyansha Lachi, Reza Mohammadi, Roshan Reddy Upendra, Eva L. Dyer, Mark Li, Tom Palczewski</dc:creator>
    </item>
    <item>
      <title>FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic</title>
      <link>https://arxiv.org/abs/2510.20467</link>
      <description>arXiv:2510.20467v1 Announce Type: cross 
Abstract: Knowledge graph alignment is the task of matching equivalent entities (that is, instances and classes) and relations across two knowledge graphs. Most existing methods focus on pure entity-level alignment, computing the similarity of entities in some embedding space. They lack interpretable reasoning and need training data to work. In this paper, we propose FLORA, a simple yet effective method that (1) is unsupervised, i.e., does not require training data, (2) provides a holistic alignment for entities and relations iteratively, (3) is based on fuzzy logic and thus delivers interpretable results, (4) provably converges, (5) allows dangling entities, i.e., entities without a counterpart in the other KG, and (6) achieves state-of-the-art results on major benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20467v1</guid>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>The 24th International Semantic Web Conference (ISWC), Nov 2025, Nara / Japan, Japan</arxiv:journal_reference>
      <dc:creator>Yiwen Peng (IP Paris), Thomas Bonald (IP Paris), Fabian M. Suchanek (IP Paris)</dc:creator>
    </item>
    <item>
      <title>My Ontologist: Evaluating BFO-Based AI for Definition Support</title>
      <link>https://arxiv.org/abs/2407.17657</link>
      <description>arXiv:2407.17657v3 Announce Type: replace 
Abstract: Generative artificial intelligence (AI), exemplified by the release of GPT-3.5 in 2022, has significantly advanced the potential applications of large language models (LLMs), including in the realms of ontology development and knowledge graph creation. Ontologies, which are structured frameworks for organizing information, and knowledge graphs, which combine ontologies with actual data, are essential for enabling interoperability and automated reasoning. However, current research has largely overlooked the generation of ontologies extending from established upper-level frameworks like the Basic Formal Ontology (BFO), risking the creation of non-integrable ontology silos. This study explores the extent to which LLMs, particularly GPT-4, can support ontologists trained in BFO. Through iterative development of a specialized GPT model named "My Ontologist," we aimed to generate BFO-conformant ontologies. Initial versions faced challenges in maintaining definition conventions and leveraging foundational texts effectively. My Ontologist 3.0 showed promise by adhering to structured rules and modular ontology suites, yet the release of GPT-4o disrupted this progress by altering the model's behavior. Our findings underscore the importance of aligning LLM-generated ontologies with top-level standards and highlight the complexities of integrating evolving AI capabilities in ontology engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17657v3</guid>
      <category>cs.DB</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carter Benson, Alec Sculley, Austin Liebers, John Beverley</dc:creator>
    </item>
    <item>
      <title>Reflex: Faster Secure Collaborative Analytics via Controlled Intermediate Result Size Disclosure</title>
      <link>https://arxiv.org/abs/2503.20932</link>
      <description>arXiv:2503.20932v2 Announce Type: replace 
Abstract: Secure Multi-Party Computation (MPC) enables collaborative analytics without exposing private data. However, OLAP queries under MPC remain prohibitively slow due to oblivious execution and padding of intermediate results with filler tuples. We present Reflex, the first framework that enables configurable trimming of intermediate results across different query operators -- joins, selections, and aggregations -- within full query plans. At its core is the Resizer operator, which can be inserted between any oblivious operators to selectively remove filler tuples under MPC using user-defined probabilistic strategies. To make privacy trade-offs interpretable, we introduce a new metric that quantifies the number of observations an attacker would need to infer the true intermediate result sizes. Reflex thus makes the performance-privacy space of secure analytics navigable, allowing users to balance efficiency and protection. Experiments show substantial runtime reductions while maintaining quantifiable privacy guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20932v2</guid>
      <category>cs.DB</category>
      <category>cs.CR</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Long Gu, Shaza Zeitouni, Carsten Binnig, Zsolt Istv\'an</dc:creator>
    </item>
    <item>
      <title>Efficiently Constructing Sparse Navigable Graphs</title>
      <link>https://arxiv.org/abs/2507.13296</link>
      <description>arXiv:2507.13296v2 Announce Type: replace-cross 
Abstract: Graph-based nearest neighbor search methods have seen a surge of popularity in recent years, offering state-of-the-art performance across a wide variety of applications. Central to these methods is the task of constructing a sparse navigable search graph for a given dataset endowed with a distance function. Unfortunately, doing so is computationally expensive, so heuristics are universally used in practice.
  In this work, we initiate the study of fast algorithms with provable guarantees for search graph construction. For a dataset with $n$ data points, the problem of constructing an optimally sparse navigable graph can be framed as $n$ separate but highly correlated minimum set cover instances. This yields a naive $O(n^3)$ time greedy algorithm that returns a navigable graph whose sparsity is at most $O(\log n)$ higher than optimal. We improve significantly on this baseline, taking advantage of correlation between the set cover instances to leverage techniques from streaming and sublinear-time set cover algorithms. By also introducing problem-specific pre-processing techniques, we obtain an $\tilde{O}(n^2)$ time algorithm for constructing an $O(\log n)$-approximate sparsest navigable graph under any distance function.
  The runtime of our method is optimal up to logarithmic factors under the Strong Exponential Time Hypothesis via a reduction from Monochromatic Closest Pair. Moreover, we prove that, as with general set cover, obtaining better than an $O(\log n)$-approximation is NP-hard, despite the significant additional structure present in the navigable graph problem. Finally, we show that our approach can also beat cubic time for the closely related and practically important problems of constructing $\alpha$-shortcut reachable and $\tau$-monotonic graphs, which are also used for nearest neighbor search. For such graphs, we obtain $\tilde{O}(n^{2.5})$ time or better algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13296v2</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <category>cs.IR</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Conway, Laxman Dhulipala, Martin Farach-Colton, Rob Johnson, Ben Landrum, Christopher Musco, Yarin Shechter, Torsten Suel, Richard Wen</dc:creator>
    </item>
    <item>
      <title>Relational Transformer: Toward Zero-Shot Foundation Models for Relational Data</title>
      <link>https://arxiv.org/abs/2510.06377</link>
      <description>arXiv:2510.06377v2 Announce Type: replace-cross 
Abstract: Pretrained transformers readily adapt to new sequence modeling tasks via zero-shot prompting, but relational domains still lack architectures that transfer across datasets and tasks. The core challenge is the diversity of relational data, with varying heterogeneous schemas, graph structures and functional dependencies. In this paper, we present the Relational Transformer (RT) architecture, which can be pretrained on diverse relational databases and directly applied to unseen datasets and tasks without task- or dataset-specific fine-tuning, or retrieval of in-context examples. RT (i) tokenizes cells with table/column metadata, (ii) is pretrained via masked token prediction, and (iii) utilizes a novel Relational Attention mechanism over columns, rows, and primary-foreign key links. Pretrained on RelBench datasets spanning tasks such as churn and sales forecasting, RT attains strong zero-shot performance, averaging 93% of fully supervised AUROC on binary classification tasks with a single forward pass of a 22M parameter model, as opposed to 84% for a 27B LLM. Fine-tuning yields state-of-the-art results with high sample efficiency. Our experiments show that RT's zero-shot transfer harnesses task-table context, relational attention patterns and schema semantics. Overall, RT provides a practical path toward foundation models for relational data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06377v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Fri, 24 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rishabh Ranjan, Valter Hudovernik, Mark Znidar, Charilaos Kanatsoulis, Roshan Upendra, Mahmoud Mohammadi, Joe Meyer, Tom Palczewski, Carlos Guestrin, Jure Leskovec</dc:creator>
    </item>
  </channel>
</rss>
