<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 May 2025 04:00:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Doubly robust augmented weighting estimators for the analysis of externally controlled single-arm trials and unanchored indirect treatment comparisons</title>
      <link>https://arxiv.org/abs/2505.00113</link>
      <description>arXiv:2505.00113v1 Announce Type: new 
Abstract: Externally controlled single-arm trials are critical to assess treatment efficacy across therapeutic indications for which randomized controlled trials are not feasible. A closely-related research design, the unanchored indirect treatment comparison, is often required for disconnected treatment networks in health technology assessment. We present a unified causal inference framework for both research designs. We develop a novel estimator that augments a popular weighting approach based on entropy balancing -- matching-adjusted indirect comparison (MAIC) -- by fitting a model for the conditional outcome expectation. The predictions of the outcome model are combined with the entropy balancing MAIC weights. While the standard MAIC estimator is singly robust where the outcome model is non-linear, our augmented MAIC approach is doubly robust, providing increased robustness against model misspecification. This is demonstrated in a simulation study with binary outcomes and a logistic outcome model, where the augmented estimator demonstrates its doubly robust property, while exhibiting higher precision than all non-augmented weighting estimators and near-identical precision to G-computation. We describe the extension of our estimator to the setting with unavailable individual participant data for the external control, illustrating it through an applied example. Our findings reinforce the understanding that entropy balancing-based approaches have desirable properties compared to standard ``modeling'' approaches to weighting, but should be augmented to improve protection against bias and guarantee double robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00113v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harlan Campbell, Antonio Remiro-Az\'ocar</dc:creator>
    </item>
    <item>
      <title>Bayesian Discrepancy Measure: Higher-order and Skewed approximations</title>
      <link>https://arxiv.org/abs/2505.00185</link>
      <description>arXiv:2505.00185v1 Announce Type: new 
Abstract: The aim of this paper is to discuss both higher-order asymptotic expansions and skewed approximations for the Bayesian Discrepancy Measure for testing precise statistical hypotheses. In particular, we derive results on third-order asymptotic approximations and skewed approximations for univariate posterior distributions, also in the presence of nuisance parameters, demonstrating improved accuracy in capturing posterior shape with little additional computational cost over simple first-order approximations. For the third-order approximations, connections to frequentist inference via matching priors are highlighted. Moreover, the definition of the Bayesian Discrepancy Measure and the proposed methodology are extended to the multivariate setting, employing tractable skew-normal posterior approximations obtained via derivative matching at the mode. Accurate multivariate approximations for the Bayesian Discrepancy Measure are then derived by defining credible regions based on the Optimal Transport map, that transforms the skew-normal approximation to a standard multivariate normal distribution. The performance and practical benefits of these higher-order and skewed approximations are illustrated through two examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00185v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elena Bortolato, Francesco Bertolino, Monica Musio, Laura Ventura</dc:creator>
    </item>
    <item>
      <title>Robust Estimation and Inference in Hybrid Controlled Trials for Binary Outcomes: A Case Study on Non-Small Cell Lung Cancer</title>
      <link>https://arxiv.org/abs/2505.00217</link>
      <description>arXiv:2505.00217v1 Announce Type: new 
Abstract: Hybrid controlled trials (HCTs), which augment randomized controlled trials (RCTs) with external controls (ECs), are increasingly receiving attention as a way to address limited power, slow accrual, and ethical concerns in clinical research. However, borrowing from ECs raises critical statistical challenges in estimation and inference, especially for binary outcomes where hidden bias is harder to detect and estimands such as risk difference, risk ratio, and odds ratio are of primary interest. We propose a novel framework that combines doubly robust estimators for various estimands under covariate shift of ECs with conformal selective borrowing (CSB) to address outcome incomparability. CSB uses conformal inference with nearest-neighbor-based conformal scores and their label-conditional extensions to perform finite-sample exact individual-level EC selection, addressing the limited information in binary outcomes. To ensure strict type I error rate control for testing treatment effects while gaining power, we use a Fisher randomization test with the CSB estimator as the test statistic. Extensive simulations demonstrate the robust performance of our methods. We apply our method to data from CALGB 9633 and the National Cancer Database to evaluate chemotherapy effects in Stage IB non-small-cell lung cancer patients and show that the proposed method effectively mitigates hidden bias introduced by full-borrowing approaches, strictly controls the type I error rate, and improves the power over RCT-only analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00217v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jiajun Liu, Ke Zhu, Shu Yang, Xiaofei Wang</dc:creator>
    </item>
    <item>
      <title>Local Quasi-Exponential Growth Models: Kernel Differential Equation Regression and Sparse Data</title>
      <link>https://arxiv.org/abs/2505.00231</link>
      <description>arXiv:2505.00231v1 Announce Type: new 
Abstract: Local polynomial regression struggles with several challenges when dealing with sparse data. The difficulty in capturing local features of the underlying function can lead to a potential misrepresentation of the true relationship. Additionally, with limited data points in local neighborhoods, the variance of estimators can increase significantly. Local polynomial regression also requires a substantial amount of data to produce good models, making it less efficient for sparse datasets. This paper employs a differential equation-constrained regression approach, introduced by \citet{ding2014estimation}, for local quasi-exponential growth models. By incorporating first-order differential equations, this method extends the sparse design capacity of local polynomial regression while reducing bias and variance. We discuss the asymptotic biases and variances of kernel estimators using first-degree Taylor polynomials. Model comparisons are conducted using mouse tumor growth data, along with simulation studies under various scenarios that simulate quasi-exponential growth with different noise levels and growth rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00231v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chunlei Ge, W. John Braun</dc:creator>
    </item>
    <item>
      <title>Functional Multidimensional Scaling</title>
      <link>https://arxiv.org/abs/2505.00253</link>
      <description>arXiv:2505.00253v1 Announce Type: new 
Abstract: This article introduces a functional method for lower-dimensional smooth representations in terms of time-varying dissimilarities. The method incorporates dissimilarity representation in multidimensional scaling and smoothness approach of functional data analysis by using cubic B-spline basis functions. The model is designed to arrive at optimal representations with an iterative procedure such that dissimilarities evaluated by estimated representations are almost the same as original dissimilarities of objects in a low dimension which is easier for people to recognize. To solve expensive computation in optimization, we propose a computationally efficient method by taking gradient steps with respect to individual sub-functions of target functions using a Stochastic Gradient Descent algorithm. Keywords: Multidimensional Scaling, Functional Data Analysis, Statistical Modeling, Quasi-Newton Method, Stochastic Gradient Descent</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00253v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liting Li</dc:creator>
    </item>
    <item>
      <title>High Dimensional Ensemble Kalman Filter</title>
      <link>https://arxiv.org/abs/2505.00283</link>
      <description>arXiv:2505.00283v1 Announce Type: new 
Abstract: The ensemble Kalman Filter (EnKF), as a fundamental data assimilation approach, has been widely used in many fields of earth science, engineering and beyond. However, there are several unknown theoretical aspects of the EnKF, especially when the state variable is of high dimensional accompanied with high resolution observation and physical models. This paper first proposes several high dimensional EnKF methods which provide consistent estimators for the important forecast error covariance and the Kalman gain matrix. It then studies the theoretical properties of the EnKF under both the fixed and high dimensional state variables, which provides the mean square errors of the analysis states to the underlying oracle states offered by the Kalman filter and gives the much needed insight into the roles played by forecast error covariance on the accuracy of the EnKF. The accuracy of the data assimilation under the misspecified physical model is also considered. Numerical studies on the Lorenz-96 and the Shallow Water Equation models illustrate that the proposed high dimensional EnKF algorithms perform better than the standard EnKF methods as they provide more robust and accurate assimilated results. The high dimensional EnKF is applied to assimilate sea temperature in Northwest Pacific, which showed more accurate out-sample performance than the existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00283v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shouxia Wang, Song Xi Chen, Hao-Xuan Sun</dc:creator>
    </item>
    <item>
      <title>Geodesic Synthetic Control Methods for Random Objects and Functional Data</title>
      <link>https://arxiv.org/abs/2505.00331</link>
      <description>arXiv:2505.00331v1 Announce Type: new 
Abstract: We introduce a geodesic synthetic control method for causal inference that extends existing synthetic control methods to scenarios where outcomes are elements in a geodesic metric space rather than scalars. Examples of such outcomes include distributions, compositions, networks, trees and functional data, among other data types that can be viewed as elements of a geodesic metric space given a suitable metric. We extend this further to geodesic synthetic difference-in-differences that builds on the established synthetic difference-in-differences for Euclidean outcomes. This estimator generalizes both the geodesic synthetic control method and a previously proposed geodesic difference-in-differences method and exhibits a double robustness property. The proposed geodesic synthetic control method is illustrated through comprehensive simulation studies and applications to the employment composition changes following the 2011 Great East Japan Earthquake, and the impact of abortion liberalization policy on fertility patterns in East Germany. We illustrate the proposed geodesic synthetic difference-in-differences by studying the consequences of the Soviet Union's collapse on age-at-death distributions for males and females.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00331v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daisuke Kurisu, Yidong Zhou, Taisuke Otsu, Hans-Georg M\"uller</dc:creator>
    </item>
    <item>
      <title>Matrix Healy Plot: A Practical Tool for Visual Assessment of Matrix-Variate Normality</title>
      <link>https://arxiv.org/abs/2505.00361</link>
      <description>arXiv:2505.00361v1 Announce Type: new 
Abstract: Matrix-valued data, where each observation is represented as a matrix, frequently arises in various scientific disciplines. Modeling such data often relies on matrix-variate normal distributions, making matrix-variate normality testing crucial for valid statistical inference. Recently, the Distance-Distance (DD) plot has been introduced as a graphical tool for visually assessing matrix-variate normality. However, the Mahalanobis squared distances (MSD) used in the DD plot require vectorizing matrix observations, restricting its applicability to cases where the dimension of the vectorized data does not exceed the sample size. To address this limitation, we propose a novel graphical method called the Matrix Healy (MHealy) plot, an extension of the Healy plot for vector-valued data. This new plot is based on more accurate matrix-based MSD that leverages the inherent structure of matrix data. Consequently, it offers a more reliable visual assessment. Importantly, the MHealy plot eliminates the sample size restriction of the DD plot and hence more applicable to matrix-valued data. Empirical results demonstrate its effectiveness and practicality compared to the DD plot across various scenarios, particularly in cases where the DD plot is not available due to limited sample sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00361v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fen Jiang, Jianhua Zhao, Changchun Shang, Xuan Ma, Yue Wang, Ye Tao</dc:creator>
    </item>
    <item>
      <title>Spatial vertical regression for spatial panel data: Evaluating the effect of the Florentine tramway's first line on commercial vitality</title>
      <link>https://arxiv.org/abs/2505.00450</link>
      <description>arXiv:2505.00450v1 Announce Type: new 
Abstract: Synthetic control methods are commonly used in panel data settings to evaluate the effect of an intervention. In many of these cases, the treated and control units correspond to spatial units such as regions or neighborhoods. Our approach addresses the challenge of understanding how an intervention applied at specific locations influences the surrounding area. Traditional synthetic control applications may struggle with defining the effective area of impact, the extent of treatment propagation across space, and the variation of effects with distance from the treatment sites. To address these challenges, we introduce Spatial Vertical Regression (SVR) within the Bayesian paradigm. This innovative approach allows us to accurately predict the outcomes in varying proximities to the treatment sites, while meticulously accounting for the spatial structure inherent in the data. Specifically, rooted on the vertical regression framework of the synthetic control method, SVR employs a Gaussian process to ensure that the imputation of missing potential outcomes for areas of different distance around the treatment sites is spatially coherent, reflecting the expectation that nearby areas experience similar outcomes and have similar relationships to control areas. This approach is particularly pertinent to our study on the Florentine tramway's first line construction. We study its influence on the local commercial landscape, focusing on how business prevalence varies at different distances from the tram stops.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00450v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giulio Grossi, Alessandra Mattei, Georgia Papadogeorgou</dc:creator>
    </item>
    <item>
      <title>Robust Parameter Estimation in Dynamical Systems by Stochastic Differential Equations</title>
      <link>https://arxiv.org/abs/2505.00491</link>
      <description>arXiv:2505.00491v1 Announce Type: new 
Abstract: Ordinary and stochastic differential equations (ODEs and SDEs) are widely used to model continuous-time processes across various scientific fields. While ODEs offer interpretability and simplicity, SDEs incorporate randomness, providing robustness to noise and model misspecifications. Recent research highlights the statistical advantages of SDEs, such as improved parameter identifiability and stability under perturbations. This paper investigates the robustness of parameter estimation in SDEs versus ODEs under three types of model misspecifications: unrecognized noise sources, external perturbations, and simplified models. Furthermore, the effect of missing data is explored. Through simulations and an analysis of Danish COVID-19 data, we demonstrate that SDEs yield more stable and reliable parameter estimates, making them a strong alternative to traditional ODE modeling in the presence of uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00491v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingchuan Sun, Susanne Ditlevsen</dc:creator>
    </item>
    <item>
      <title>Ground Orthogonal Arrays and Their Applications</title>
      <link>https://arxiv.org/abs/2505.00536</link>
      <description>arXiv:2505.00536v1 Announce Type: new 
Abstract: In computer experiments, it has become a standard practice to select the inputs that spread out as uniformly as possible over the design space. The resulting designs are called space-filling designs and they are undoubtedly desirable choices when there is no prior knowledge on how the input variables affect the response and the objective of experiments is global fitting. When there is some prior knowledge on the underlying true function of the system or what statistical models are more appropriate, a natural question is, are there more suitable designs than vanilla space-filling designs? In this article, we provide an answer for the cases where there are no interactions between the factors from disjoint groups of variables. In other words, we consider the design issue when the underlying functional form of the system or the statistical model to be used is additive where each component depends on one group of variables from a set of disjoint groups. For such cases, we recommend using {\em grouped orthogonal arrays.} Several construction methods are provided and many designs are tabulated for practical use. Compared with existing techniques in the literature, our construction methods can generate many more designs with flexible run sizes and better within-group projection properties for any prime power number of levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00536v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Statistica Sinica, 2025</arxiv:journal_reference>
      <dc:creator>Guangzhou Chen, Yuanzhen He, C. Devon Lin, Fasheng Sun</dc:creator>
    </item>
    <item>
      <title>EW D-optimal Designs for Experiments with Mixed Factors</title>
      <link>https://arxiv.org/abs/2505.00629</link>
      <description>arXiv:2505.00629v1 Announce Type: new 
Abstract: We consider EW D-optimal designs as robust designs for experiments under a general parametric model with discrete and continuous factors. When a pilot study is available, we recommend sample-based EW D-optimal designs for subsequent experiments. Otherwise, we recommend EW D-optimal designs under a prior distribution for model parameters. We propose an EW ForLion algorithm for finding EW D-optimal designs under a general parametric model, and justify that the designs found by our algorithm are EW D-optimal. To facilitate potential users in practice, we also develop a rounding algorithm that converts an approximate design with mixed factors to an exact design with prespecified grid points and the number of experimental units. By applying our algorithms for real experiments under multinomial logistic models or generalized linear models, we show that our designs are highly efficient with respect to locally D-optimal designs and more robust against parameter value misspecifications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00629v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siting Lin, Yifei Huang, Jie Yang</dc:creator>
    </item>
    <item>
      <title>SOMA: a novel sampler for exchangeable variables</title>
      <link>https://arxiv.org/abs/2505.00635</link>
      <description>arXiv:2505.00635v1 Announce Type: new 
Abstract: The problem of sampling exchangeable random variables arises in many Bayesian inference tasks, especially in data imputation given a privatized summary statistics. These permutation-invariant joint distributions often have dependency structures that make sampling challenging. Component-wise sampling strategies, such as Metropolis-within-Gibbs, can mix slowly because they consider only comparing a proposed point with one component at a time. In this work, we propose a novel Single-Offer-Multiple-Attempts (SOMA) sampler that is tailored to sampling permutation invariant distributions. The core intuition of SOMA is that a proposed point unsuitable to replace one component might still be a good candidate to replace some other component in the joint distribution. SOMA first makes a singer offer, and then simultaneously considers attempts to replace each component of the current state with the single offer, before making the final acceptance or rejection decision. We provide an acceptance lower bound of SOMA and, using a coupling method, derive the convergence rate upper bound of SOMA in the two-dimensional case. We validate theoretical findings with numerical simulations, including a demonstration on differentially private Bayesian linear regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00635v1</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifei Xiong, Nianqiao Phyllis Ju</dc:creator>
    </item>
    <item>
      <title>Kernel-Based Ensemble Gaussian Mixture Probability Hypothesis Density Filter</title>
      <link>https://arxiv.org/abs/2505.00131</link>
      <description>arXiv:2505.00131v1 Announce Type: cross 
Abstract: In this work, a kernel-based Ensemble Gaussian Mixture Probability Hypothesis Density (EnGM-PHD) filter is presented for multi-target filtering applications. The EnGM-PHD filter combines the Gaussian-mixture-based techniques of the Gaussian Mixture Probability Hypothesis Density (GM-PHD) filter with the particle-based techniques of the Sequential Monte Carlo Probability Hypothesis Density (SMC-PHD) filter. It achieves this by obtaining particles from the posterior intensity function, propagating them through the system dynamics, and then using Kernel Density Estimation (KDE) techniques to approximate the Gaussian mixture of the prior intensity function. This approach guarantees convergence to the true intensity function in the limit of the number of components. Moreover, in the special case of a single target with no births, deaths, clutter, and perfect detection probability, the EnGM-PHD filter reduces to the standard Ensemble Gaussian Mixture Filter (EnGMF). In the presented experiment, the results indicate that the EnGM-PHD filter achieves better multi-target filtering performance than both the GM-PHD and SMC-PHD filters while using the same number of components or particles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00131v1</guid>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dalton Durant, Renato Zanetti</dc:creator>
    </item>
    <item>
      <title>Conformal changepoint localization</title>
      <link>https://arxiv.org/abs/2505.00292</link>
      <description>arXiv:2505.00292v1 Announce Type: cross 
Abstract: Changepoint localization is the problem of estimating the index at which a change occurred in the data generating distribution of an ordered list of data, or declaring that no change occurred. We present the broadly applicable CONCH (CONformal CHangepoint localization) algorithm, which uses a matrix of conformal p-values to produce a confidence interval for a (single) changepoint under the mild assumption that the pre-change and post-change distributions are each exchangeable. We exemplify the CONCH algorithm on a variety of synthetic and real-world datasets, including using black-box pre-trained classifiers to detect changes in sequences of images or text.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00292v1</guid>
      <category>math.ST</category>
      <category>eess.SP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanjit Dandapanthula, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning with Continuous Actions Under Unmeasured Confounding</title>
      <link>https://arxiv.org/abs/2505.00304</link>
      <description>arXiv:2505.00304v1 Announce Type: cross 
Abstract: This paper addresses the challenge of offline policy learning in reinforcement learning with continuous action spaces when unmeasured confounders are present. While most existing research focuses on policy evaluation within partially observable Markov decision processes (POMDPs) and assumes discrete action spaces, we advance this field by establishing a novel identification result to enable the nonparametric estimation of policy value for a given target policy under an infinite-horizon framework. Leveraging this identification, we develop a minimax estimator and introduce a policy-gradient-based algorithm to identify the in-class optimal policy that maximizes the estimated policy value. Furthermore, we provide theoretical results regarding the consistency, finite-sample error bound, and regret bound of the resulting optimal policy. Extensive simulations and a real-world application using the German Family Panel data demonstrate the effectiveness of our proposed methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00304v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhan Li, Eugene Han, Yifan Hu, Wenzhuo Zhou, Zhengling Qi, Yifan Cui, Ruoqing Zhu</dc:creator>
    </item>
    <item>
      <title>Statistical Learning for Heterogeneous Treatment Effects: Pretraining, Prognosis, and Prediction</title>
      <link>https://arxiv.org/abs/2505.00310</link>
      <description>arXiv:2505.00310v1 Announce Type: cross 
Abstract: Robust estimation of heterogeneous treatment effects is a fundamental challenge for optimal decision-making in domains ranging from personalized medicine to educational policy. In recent years, predictive machine learning has emerged as a valuable toolbox for causal estimation, enabling more flexible effect estimation. However, accurately estimating conditional average treatment effects (CATE) remains a major challenge, particularly in the presence of many covariates. In this article, we propose pretraining strategies that leverages a phenomenon in real-world applications: factors that are prognostic of the outcome are frequently also predictive of treatment effect heterogeneity. In medicine, for example, components of the same biological signaling pathways frequently influence both baseline risk and treatment response. Specifically, we demonstrate our approach within the R-learner framework, which estimates the CATE by solving individual prediction problems based on a residualized loss. We use this structure to incorporate "side information" and develop models that can exploit synergies between risk prediction and causal effect estimation. In settings where these synergies are present, this cross-task learning enables more accurate signal detection: yields lower estimation error, reduced false discovery rates, and higher power for detecting heterogeneity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00310v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maximilian Schuessler, Erik Sverdrup, Robert Tibshirani</dc:creator>
    </item>
    <item>
      <title>Optimal Vector Compressed Sensing Using James Stein Shrinkage</title>
      <link>https://arxiv.org/abs/2505.00326</link>
      <description>arXiv:2505.00326v1 Announce Type: cross 
Abstract: The trend in modern science and technology is to take vector measurements rather than scalars, ruthlessly scaling to ever higher dimensional vectors. For about two decades now, traditional scalar Compressed Sensing has been synonymous with a Convex Optimization based procedure called Basis Pursuit. In the vector recovery case, the natural tendency is to return to a straightforward vector extension of Basis Pursuit, also based on Convex Optimization. However, Convex Optimization is provably suboptimal, particularly when $B$ is large. In this paper, we propose SteinSense, a lightweight iterative algorithm, which is provably optimal when $B$ is large. It does not have any tuning parameter, does not need any training data, requires zero knowledge of sparsity, is embarrassingly simple to implement, and all of this makes it easily scalable to high vector dimensions. We conduct a massive volume of both real and synthetic experiments that confirm the efficacy of SteinSense, and also provide theoretical justification based on ideas from Approximate Message Passing. Fascinatingly, we discover that SteinSense is quite robust, delivering the same quality of performance on real data, and even under substantial departures from conditions under which existing theory holds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00326v1</guid>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Apratim Dey, David Donoho</dc:creator>
    </item>
    <item>
      <title>On the Distribution of the Sample Covariance from a Matrix Normal Population</title>
      <link>https://arxiv.org/abs/2505.00470</link>
      <description>arXiv:2505.00470v1 Announce Type: cross 
Abstract: This paper discusses the joint distribution of sample variances and covariances, expressed in quadratic forms in a matrix population arising in comparing the differences among groups under homogeneity of variance. One major concern of this article is to compare $K$ different populations, by assuming that the mean values of $x_{11}^{(k)}, x_{12}^{(k)}, \dots, x_{1p}^{(k)}, x_{21}^{(k)}, x_{22}^{(k)}, \dots$, $x_{2p}^{(k)},\dots, x_{n1}^{(k)},x_{n2}^{(k)},\dots,$ $x_{np}^{(k)}$ in each population are $M^{(k)}$ ($n\times p$), $k = 1,2,\dots,K$ and $M$($n\times p$) a fixed matrix, with this hypothesis $$H_0: M^{(1)} = M^{(2)} = \dots = M^{(k)} = M,$$ when the inter-group covariances are neglected and the intra-group covariances are equal. The $N$ intra-group variances and $\frac{1}{2} N (N - 1)$ intra-group covariances where $N = np$ are classified into four categories $T_{1}$, $T_{1\frac{1}{2}}$, $T_{2}$ and $T_{3}$ according to the spectral forms of the precision matrix. The joint distribution of the sample variances and covariances is derived under these four scenarios. Besides, the moment generating function and the joint distribution of latent roots are explicitly calculated. %The distribution of non-central means with known covariance is calculated as an application to the one-sample analysis of variance, with its exact power tabulated up to order two. As an application, we consider a classification problem in the discriminant analysis where the two populations should have different intra-group covariances. The distribution of the ratio of two quadratic forms is considered both in the central and non-central cases, with their exact power tabulated for different $n$ and $p$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00470v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Haoming Wang</dc:creator>
    </item>
    <item>
      <title>The matryoshka doll prior: principled multiplicity correction in Bayesian model comparison</title>
      <link>https://arxiv.org/abs/1511.04745</link>
      <description>arXiv:1511.04745v4 Announce Type: replace 
Abstract: This paper introduces a general and principled construction of model space priors with a focus on regression problems. The proposed formulation regards each model as a `local` null hypothesis whose alternatives are the set of models that nest it. Assuming constant odds between any `local` null and its alternatives provides a natural isomorphism of model spaces (like a matryoshka doll), constituting an intuitive way to correct for test multiplicity. This isomorphism yields the Poisson distribution as the unique limiting distribution over model dimension under mild assumptions. We compare this model space prior theoretically and in simulations to widely adopted Beta-Binomial constructions. We show that the proposed prior yields a `just-right` multiplicity correction that induces a desirable complexity penalization profile.</description>
      <guid isPermaLink="false">oai:arXiv.org:1511.04745v4</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andrew J Womack, Daniel Taylor-Rodriguez, Claudio Fuentes</dc:creator>
    </item>
    <item>
      <title>Domain Adaptation Optimized for Robustness in Mixture Populations</title>
      <link>https://arxiv.org/abs/2407.20073</link>
      <description>arXiv:2407.20073v2 Announce Type: replace 
Abstract: While domain adaptation methods address data shifts, most assume target populations align with at least one source population, neglecting mixtures that combine sources influenced by factors like demographics. Additional challenges in electronic health record (EHR)-based studies include unobserved outcomes and the need to explain population mixtures using broader clinical characteristics than those in standard risk models. To address these challenges under shifts in both covariate distributions and outcome models, we propose a novel framework: Domain Adaptation Optimized for Robustness in Mixture populations (DORM). Leveraging partially labeled source data, DORM constructs an initial target outcome model under a joint source-mixture assumption. To enhance generalizability to future target populations that may deviate from the joint source-mixture approximation, DORM incorporates a group adversarial learning step to derive a final estimate, optimizing its worst-case performance within a convex uncertainty set built around the initial target model. In addition, this robust domain adaptation procedure is assisted by high-dimensional surrogates that enhance transferability in EHR studies. When a small set of gold-standard or noisy labels is available from the target population, a tuning strategy is implemented to refine the uncertainty set, mitigating conservativeness and further improving performance for the specific target population. Statistical convergence and predictive accuracy of our method are quantified through asymptotic studies. Simulation and real-world studies demonstrate the out-performance of our method over existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20073v2</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keyao Zhan, Xin Xiong, Zijian Guo, Tianxi Cai, Molei Liu</dc:creator>
    </item>
    <item>
      <title>Bayesian Model Averaging in Causal Instrumental Variable Models</title>
      <link>https://arxiv.org/abs/2504.13520</link>
      <description>arXiv:2504.13520v2 Announce Type: replace 
Abstract: Instrumental variables are a popular tool to infer causal effects under unobserved confounding, but choosing suitable instruments is challenging in practice. We propose gIVBMA, a Bayesian model averaging procedure that addresses this challenge by averaging across different sets of instrumental variables and covariates in a structural equation model. Our approach extends previous work through a scale-invariant prior structure and accommodates non-Gaussian outcomes and treatments, offering greater flexibility than existing methods. The computational strategy uses conditional Bayes factors to update models separately for the outcome and treatments. We prove that this model selection procedure is consistent. By explicitly accounting for model uncertainty, gIVBMA allows instruments and covariates to switch roles and provides robustness against invalid instruments. In simulation experiments, gIVBMA outperforms current state-of-the-art methods. We demonstrate its usefulness in two empirical applications: the effects of malaria and institutions on income per capita and the returns to schooling. A software implementation of gIVBMA is available in Julia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13520v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gregor Steiner, Mark Steel</dc:creator>
    </item>
    <item>
      <title>Two-parameter superposable S-curves</title>
      <link>https://arxiv.org/abs/2504.19488</link>
      <description>arXiv:2504.19488v2 Announce Type: replace 
Abstract: Straight line equation $y=mx$ with slope $m$, when singularly perturbed as $ay^3+y=mx$ with a positive parameter $a$, results in S-shaped curves or S-curves on a real plane. As $a\rightarrow 0$, we get back $y=mx$ which is a cumulative distribution function of a continuous uniform distribution that describes the occurrence of every event in an interval to be equally probable. As $a\rightarrow\infty$, the derivative of $y$ has finite support only at $y=0$ resembling a degenerate distribution. Based on these arguments, in this work, we propose that these S-curves can represent maximum entropy uniform distribution to a zero entropy single value. We also argue that these S-curves are superposable as they are only parametrically nonlinear but fundamentally linear. So far, the superposed forms have been used to capture the patterns of natural systems such as nonlinear dynamics of biological growth and kinetics of enzyme reactions. Here, we attempt to use the S-curve and its superposed form as statistical models. We fit the models on a classical dataset containing flower measurements of iris plants and analyze their usefulness in pattern recognition. Based on these models, we claim that any non-uniform pattern can be represented as a singular perturbation to uniform distribution. However, our parametric estimation procedure have some limitations such as sensitivity to initial conditions depending on the data at hand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19488v2</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vijay Prakash S</dc:creator>
    </item>
    <item>
      <title>Identification and estimation of vaccine effectiveness in the test-negative design under equi-confounding</title>
      <link>https://arxiv.org/abs/2504.20360</link>
      <description>arXiv:2504.20360v2 Announce Type: replace 
Abstract: The test-negative design (TND) is frequently used to evaluate vaccine effectiveness in real-world settings. In a TND study, individuals with similar symptoms who seek care are tested for the disease of interest, and vaccine effectiveness is estimated by comparing the vaccination history of test-positive cases and test-negative controls. Traditional approaches justify the TND by assuming either (a) receiving a test is a perfect proxy for unmeasured health-seeking behavior or (b) vaccination is unconfounded given measured covariates -- both of which may be unrealistic in practice. In this paper, we return to the original motivation for the TND and propose an alternative justification based on the assumption of odds ratio equi-confounding, where unmeasured confounders influence test-positive and test-negative individuals equivalently on the odds ratio scale. We discuss the implications of this assumption for TND design and provide alternative estimators for the marginal risk ratio among the vaccinated under equi-confounding, including estimators based on outcome modeling and inverse probability weighting as well as a semiparametric estimator that is doubly-robust. When the equi-confounding assumption does not hold, we suggest a sensitivity analysis that parameterizes the magnitude of the deviation on the odds ratio scale. We conduct a simulation study to evaluate the empirical performance of our proposed estimators under a wide range of scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.20360v2</guid>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Christopher B. Boyer, Kendrick Qijun Li, Xu Shi, Eric J. Tchetgen Tchetgen</dc:creator>
    </item>
    <item>
      <title>While-alive regression analysis of composite survival endpoints</title>
      <link>https://arxiv.org/abs/2504.21710</link>
      <description>arXiv:2504.21710v2 Announce Type: replace 
Abstract: Composite endpoints, which combine two or more distinct outcomes, are frequently used in clinical trials to enhance the event rate and improve the statistical power. In the recent literature, the while-alive cumulative frequency measure offers a strong alternative to define composite survival outcomes, by relating the average event rate to the survival time. Although non-parametric methods have been proposed for two-sample comparisons between cumulative frequency measures in clinical trials, limited attention has been given to regression methods that directly address time-varying effects in while-alive measures for composite survival outcomes. Motivated by an individually randomized trial (HF-ACTION) and a cluster randomized trial (STRIDE), we address this gap by developing a regression framework for while-alive measures for composite survival outcomes that include a terminal component event. Our regression approach uses splines to model time-varying association between covariates and a while-alive loss rate of all component events, and can be applied to both independent and clustered data. We derive the asymptotic properties of the regression estimator in each setting and evaluate its performance through simulations. Finally, we apply our regression method to analyze data from the HF-ACTION individually randomized trial and the STRIDE cluster randomized trial. The proposed methods are implemented in the WAreg R package.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21710v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Fang, Hajime Uno, Fan Li</dc:creator>
    </item>
    <item>
      <title>Time-Uniform Self-Normalized Concentration for Vector-Valued Processes</title>
      <link>https://arxiv.org/abs/2310.09100</link>
      <description>arXiv:2310.09100v2 Announce Type: replace-cross 
Abstract: Self-normalized processes arise naturally in many learning-related tasks. While self-normalized concentration has been extensively studied for scalar-valued processes, there are few results for multidimensional processes outside of the sub-Gaussian setting. In this work, we construct a general, self-normalized inequality for multivariate processes that satisfy a simple yet broad sub-$\psi$ tail condition, which generalizes assumptions based on cumulant generating functions. From this general inequality, we derive an upper law of the iterated logarithm for sub-$\psi$ vector-valued processes, which is tight up to small constants. We show how our inequality can be leveraged to derive a variety of novel, self-normalized concentration inequalities under both light and heavy-tailed observations. Further, we provide applications in prototypical statistical tasks, such as parameter estimation in online linear regression, autoregressive modeling, and bounded mean estimation via a new (multivariate) empirical Bernstein concentration inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09100v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Justin Whitehouse, Zhiwei Steven Wu, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Omitted Labels Induce Nontransitive Paradoxes in Causality</title>
      <link>https://arxiv.org/abs/2311.06840</link>
      <description>arXiv:2311.06840v4 Announce Type: replace-cross 
Abstract: We explore "omitted label contexts," in which training data is limited to a subset of the possible labels. This setting is standard among specialized human experts or specific, focused studies. By studying Simpson's paradox, we observe that ``correct'' adjustments sometimes require non-exchangeable treatment and control groups. A generalization of Simpson's paradox leads us to study networks of conclusions drawn from different contexts, within which a paradox of nontransitivity arises. We prove that the space of possible nontransitive structures in these networks exactly corresponds to structures that form from aggregating ranked-choice votes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06840v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.SI</category>
      <category>math.IT</category>
      <category>stat.ME</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bijan Mazaheri, Siddharth Jain, Matthew Cook, Jehoshua Bruck</dc:creator>
    </item>
    <item>
      <title>Orthogonal Causal Calibration</title>
      <link>https://arxiv.org/abs/2406.01933</link>
      <description>arXiv:2406.01933v2 Announce Type: replace-cross 
Abstract: Estimates of heterogeneous treatment effects such as conditional average treatment effects (CATEs) and conditional quantile treatment effects (CQTEs) play an important role in real-world decision making. Given this importance, one should ensure these estimates are calibrated. While there is a rich literature on calibrating estimators of non-causal parameters, very few methods have been derived for calibrating estimators of causal parameters, or more generally estimators of quantities involving nuisance parameters. In this work, we develop general algorithms for reducing the task of causal calibration to that of calibrating a standard (non-causal) predictive model.
  Throughout, we study a notion of calibration defined with respect to an arbitrary, nuisance-dependent loss $\ell$, under which we say an estimator $\theta$ is calibrated if its predictions cannot be changed on any level set to decrease loss. For losses $\ell$ satisfying a condition called universal orthogonality, we present a simple algorithm that transforms partially-observed data into generalized pseudo-outcomes and applies any off-the-shelf calibration procedure. For losses $\ell$ satisfying a weaker assumption called conditional orthogonality, we provide a similar sample splitting algorithm the performs empirical risk minimization over an appropriately defined class of functions. Convergence of both algorithms follows from a generic, two term upper bound of the calibration error of any model. We demonstrate the practical applicability of our results in experiments on both observational and synthetic data. Our results are exceedingly general, showing that essentially any existing calibration algorithm can be used in causal settings, with additional loss only arising from errors in nuisance estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01933v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Justin Whitehouse, Christopher Jung, Vasilis Syrgkanis, Bryan Wilder, Zhiwei Steven Wu</dc:creator>
    </item>
    <item>
      <title>Locally minimax optimal and dimension-agnostic discrete argmin inference</title>
      <link>https://arxiv.org/abs/2503.21639</link>
      <description>arXiv:2503.21639v2 Announce Type: replace-cross 
Abstract: This paper tackles a fundamental inference problem: given $n$ observations from a $d$ dimensional vector with unknown mean $\boldsymbol{\mu}$, we must form a confidence set for the index (or indices) corresponding to the smallest component of $\boldsymbol{\mu}$. By duality, we reduce this to testing, for each $r$ in $1,\ldots,d$, whether $\mu_r$ is the smallest. Based on the sample splitting and self-normalization approach of Kim and Ramdas (2024), we propose "dimension-agnostic" tests that maintain validity regardless of how $d$ scales with $n$, and regardless of arbitrary ties in $\boldsymbol{\mu}$. Notably, our validity holds under mild moment conditions, requiring little more than finiteness of a second moment, and permitting possibly strong dependence between coordinates. In addition, we establish the local minimax separation rate for this problem, which adapts to the cardinality of a confusion set, and show that the proposed tests attain this rate. Furthermore, we develop robust variants that continue to achieve the same minimax rate under heavy-tailed distributions with only finite second moments. Empirical results on simulated and real data illustrate the strong performance of our approach in terms of type I error control and power compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21639v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilmun Kim, Aaditya Ramdas</dc:creator>
    </item>
  </channel>
</rss>
