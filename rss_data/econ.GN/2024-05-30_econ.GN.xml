<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.GN</link>
    <description>econ.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 May 2024 04:03:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 31 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Accuracy of Domain Specific and Descriptive Analysis Generated by Large Language Models</title>
      <link>https://arxiv.org/abs/2405.19578</link>
      <description>arXiv:2405.19578v1 Announce Type: cross 
Abstract: Large language models (LLMs) have attracted considerable attention as they are capable of showcasing impressive capabilities generating comparable high-quality responses to human inputs. LLMs, can not only compose textual scripts such as emails and essays but also executable programming code. Contrary, the automated reasoning capability of these LLMs in performing statistically-driven descriptive analysis, particularly on user-specific data and as personal assistants to users with limited background knowledge in an application domain who would like to carry out basic, as well as advanced statistical and domain-specific analysis is not yet fully explored. More importantly, the performance of these LLMs has not been compared and discussed in detail when domain-specific data analysis tasks are needed. This study, consequently, explores whether LLMs can be used as generative AI-based personal assistants to users with minimal background knowledge in an application domain infer key data insights. To demonstrate the performance of the LLMs, the study reports a case study through which descriptive statistical analysis, as well as Natural Language Processing (NLP) based investigations, are performed on a number of phishing emails with the objective of comparing the accuracy of the results generated by LLMs to the ones produced by analysts. The experimental results show that LangChain and the Generative Pre-trained Transformer (GPT-4) excel in numerical reasoning tasks i.e., temporal statistical analysis, achieve competitive correlation with human judgments on feature engineering tasks while struggle to some extent on domain specific knowledge reasoning, where domain-specific knowledge is required.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19578v1</guid>
      <category>cs.CE</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Denish Omondi Otieno, Faranak Abri, Sima Siami-Namini, Akbar Siami Namin</dc:creator>
    </item>
    <item>
      <title>The Sponge Cake Dilemma over the Nile: Achieving Fairness in Resource Allocation with Cake Cutting Algorithms</title>
      <link>https://arxiv.org/abs/2310.11472</link>
      <description>arXiv:2310.11472v2 Announce Type: replace 
Abstract: This article explores the intricate dynamics of the Nile Basin dispute, a complex conflict involving Egypt, Ethiopia, and Sudan. Our central argument is that we can gain unique insights into this dispute by employing the principles of game theory and the Steinhaus cake-cutting problem - a mathematical model of fair division. These theoretical frameworks offer a novel perspective to understand the motivations and potential actions of the involved nations. More importantly, these concepts can illuminate potential pathways toward a resolution that ensures equitable resource allocation and maintains regional stability. We will analyze the conflict and explore potential solutions to this enduring dispute through this lens.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11472v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dwayne Woods</dc:creator>
    </item>
    <item>
      <title>Is the EJRA proportionate and therefore justified? A critical review of the EJRA policy at Cambridge</title>
      <link>https://arxiv.org/abs/2405.14611</link>
      <description>arXiv:2405.14611v2 Announce Type: replace 
Abstract: This paper critically evaluates the HESA (Higher Education Statistics Agency) Data Report for the Employer Justified Retirement Age (EJRA) Review Group at the University of Cambridge (Cambridge 2024), identifying significant methodological flaws and misinterpretations. Our analysis reveals issues such as application of data filters only to the Cambridge sample, inconsistent variable treatment, and erroneous statistical conclusions. The Report suggests EJRA increased job creation rates at Cambridge, but we show Cambridge consistently had lower job creation rates for Established Academic Careers compared to other Russell Group universities, both before and after EJRA implementation in 2011. This suggests that EJRA is not a significant factor driving job creation rates. Since other universities without an EJRA exhibit higher job creation rates, this suggests job creation can be sustained without such a policy. We conclude that the EJRA did not achieve its intended goal of increasing opportunities for young academics and may have exacerbated existing disparities compared to other leading universities. We recommend EJRA be abolished at Cambridge since it does not meet its justified aims and could be viewed as unlawful age discrimination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14611v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Oliver Linton, Raghavendra Rau, Patrick Baert, Peter Bossaerts, Jon Crowcroft, G. R. Evans, Paul Ewart, Nick Gay, Paul Kattuman, Stefan Scholtes, Hamid Sabourian, Richard J. Smith</dc:creator>
    </item>
    <item>
      <title>Manipulation and Peer Mechanisms: A Survey</title>
      <link>https://arxiv.org/abs/2210.01984</link>
      <description>arXiv:2210.01984v3 Announce Type: replace-cross 
Abstract: In peer mechanisms, the competitors for a prize also determine who wins. Each competitor may be asked to rank, grade, or nominate peers for the prize. Since the prize can be valuable, such as financial aid, course grades, or an award at a conference, competitors may be tempted to manipulate the mechanism. We survey approaches to prevent or discourage the manipulation of peer mechanisms. We conclude our survey by identifying several important research challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.01984v3</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Olckers, Toby Walsh</dc:creator>
    </item>
  </channel>
</rss>
