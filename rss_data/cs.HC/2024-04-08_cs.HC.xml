<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Apr 2024 04:00:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>HIV Client Perspectives on Digital Health in Malawi</title>
      <link>https://arxiv.org/abs/2404.04444</link>
      <description>arXiv:2404.04444v1 Announce Type: new 
Abstract: eHealth has strong potential to advance HIV care in low- and middle-income countries. Given the sensitivity of HIV-related information and the risks associated with unintended HIV status disclosure, clients' privacy perceptions towards eHealth applications should be examined to develop client-centered technologies. Through focus group discussions with antiretroviral therapy (ART) clients from Lighthouse Trust, Malawi's public HIV care program, we explored perceptions of data security and privacy, including their understanding of data flow and their concerns about data confidentiality across several layers of data use. Our findings highlight the broad privacy concerns that affect ART clients' day-to-day choices, clients' trust in Malawi's health system, and their acceptance of, and familiarity with, point-of-care technologies used in HIV care. Based on our findings, we provide recommendations for building robust digital health systems in low- and middle-income countries with limited resources, nascent privacy regulations, and political will to take action to protect client data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04444v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3613904.3642245</arxiv:DOI>
      <dc:creator>Lisa Orii, Caryl Feldacker, Jacqueline Madalitso Huwa, Agness Thawani, Evelyn Viola, Christine Kiruthu-Kamamia, Odala Sande, Hannock Tweya, Richard Anderson</dc:creator>
    </item>
    <item>
      <title>Majority Voting of Doctors Improves Appropriateness of AI Reliance in Pathology</title>
      <link>https://arxiv.org/abs/2404.04485</link>
      <description>arXiv:2404.04485v1 Announce Type: new 
Abstract: As Artificial Intelligence (AI) making advancements in medical decision-making, there is a growing need to ensure doctors develop appropriate reliance on AI to avoid adverse outcomes. However, existing methods in enabling appropriate AI reliance might encounter challenges while being applied in the medical domain. With this regard, this work employs and provides the validation of an alternative approach -- majority voting -- to facilitate appropriate reliance on AI in medical decision-making. This is achieved by a multi-institutional user study involving 32 medical professionals with various backgrounds, focusing on the pathology task of visually detecting a pattern, mitoses, in tumor images. Here, the majority voting process was conducted by synthesizing decisions under AI assistance from a group of pathology doctors (pathologists). Two metrics were used to evaluate the appropriateness of AI reliance: Relative AI Reliance (RAIR) and Relative Self-Reliance (RSR). Results showed that even with groups of three pathologists, majority-voted decisions significantly increased both RAIR and RSR -- by approximately 9% and 31%, respectively -- compared to decisions made by one pathologist collaborating with AI. This increased appropriateness resulted in better precision and recall in the detection of mitoses. While our study is centered on pathology, we believe these insights can be extended to general high-stakes decision-making processes involving similar visual tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04485v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongyan Gu. Chunxu Yang, Shino Magaki, Neda Zarrin-Khameh, Nelli S. Lakis, Inma Cobos, Negar Khanlou, Xinhai R. Zhang, Jasmeet Assi, Joshua T. Byers, Ameer Hamza, Karam Han, Anders Meyer, Hilda Mirbaha, Carrie A. Mohila, Todd M. Stevens, Sara L. Stone, Wenzhong Yan, Mohammad Haeri, Xiang 'Anthony' Chen</dc:creator>
    </item>
    <item>
      <title>Language Models as Critical Thinking Tools: A Case Study of Philosophers</title>
      <link>https://arxiv.org/abs/2404.04516</link>
      <description>arXiv:2404.04516v1 Announce Type: new 
Abstract: Current work in language models (LMs) helps us speed up or even skip thinking by accelerating and automating cognitive work. But can LMs help us with critical thinking -- thinking in deeper, more reflective ways which challenge assumptions, clarify ideas, and engineer new concepts? We treat philosophy as a case study in critical thinking, and interview 21 professional philosophers about how they engage in critical thinking and on their experiences with LMs. We find that philosophers do not find LMs to be useful because they lack a sense of selfhood (memory, beliefs, consistency) and initiative (curiosity, proactivity). We propose the selfhood-initiative model for critical thinking tools to characterize this gap. Using the model, we formulate three roles LMs could play as critical thinking tools: the Interlocutor, the Monitor, and the Respondent. We hope that our work inspires LM researchers to further develop LMs as critical thinking tools and philosophers and other 'critical thinkers' to imagine intellectually substantive uses of LMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04516v1</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andre Ye, Jared Moore, Rose Novick, Amy X. Zhang</dc:creator>
    </item>
    <item>
      <title>A Map of Exploring Human Interaction patterns with LLM: Insights into Collaboration and Creativity</title>
      <link>https://arxiv.org/abs/2404.04570</link>
      <description>arXiv:2404.04570v1 Announce Type: new 
Abstract: The outstanding performance capabilities of large language model have driven the evolution of current AI system interaction patterns. This has led to considerable discussion within the Human-AI Interaction (HAII) community. Numerous studies explore this interaction from technical, design, and empirical perspectives. However, the majority of current literature reviews concentrate on interactions across the wider spectrum of AI, with limited attention given to the specific realm of interaction with LLM. We searched for articles on human interaction with LLM, selecting 110 relevant publications meeting consensus definition of Human-AI interaction. Subsequently, we developed a comprehensive Mapping Procedure, structured in five distinct stages, to systematically analyze and categorize the collected publications. Applying this methodical approach, we meticulously mapped the chosen studies, culminating in a detailed and insightful representation of the research landscape. Overall, our review presents an novel approach, introducing a distinctive mapping method, specifically tailored to evaluate human-LLM interaction patterns. We conducted a comprehensive analysis of the current research in related fields, employing clustering techniques for categorization, which enabled us to clearly delineate the status and challenges prevalent in each identified area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04570v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiayang Li, Jiale Li</dc:creator>
    </item>
    <item>
      <title>TeleAware Robot: Designing Awareness-augmented Telepresence Robot for Remote Collaborative Locomotion</title>
      <link>https://arxiv.org/abs/2404.04579</link>
      <description>arXiv:2404.04579v1 Announce Type: new 
Abstract: Telepresence robots can be used to support users to navigate an environment remotely and share the visiting experience with their social partners. Although such systems allow users to see and hear the remote environment and communicate with their partners via live video feed, this does not provide enough awareness of the environment and their remote partner's activities. In this paper, we introduce an awareness framework for collaborative locomotion in scenarios of onsite and remote users visiting a place together. From an observational study of small groups of people visiting exhibitions, we derived four design goals for enhancing the environmental and social awareness between social partners, and developed a set of awareness-enhancing techniques to add to a standard telepresence robot - named TeleAware robot. Through a controlled experiment simulating a guided exhibition visiting task, TeleAware robot showed the ability to lower the workload, facilitate closer social proximity, and improve mutual awareness and social presence compared with the standard one. We discuss the impact of mobility and roles of local and remote users, and provide insights for the future design of awareness-enhancing telepresence robot systems that facilitate collaborative locomotion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04579v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:journal_reference>IMUWT 2024</arxiv:journal_reference>
      <dc:creator>Ruyi Li, Yaxin Zhu, Min Liu, Yihang Zeng, Shanning Zhuang, Jiayi Fu, Yi Lu, Guyue Zhou, Can Liu, Jiangtao Gong</dc:creator>
    </item>
    <item>
      <title>Analyzing LLM Usage in an Advanced Computing Class in India</title>
      <link>https://arxiv.org/abs/2404.04603</link>
      <description>arXiv:2404.04603v1 Announce Type: new 
Abstract: This paper investigates the usage patterns of undergraduate and graduate students when engaging with large language models (LLMs) to tackle programming assignments in the context of advanced computing courses. Existing work predominantly focuses on the influence of LLMs in introductory programming contexts. Additionally, there is a scarcity of studies analyzing actual conversations between students and LLMs. Our study provides a comprehensive quantitative and qualitative analysis of raw interactions between students and LLMs within an advanced computing course (Distributed Systems) at an Indian University. We further complement this by conducting student interviews to gain deeper insights into their usage patterns. Our study shows that students make use of large language models (LLMs) in various ways: generating code or debugging code by identifying and fixing errors. They also copy and paste assignment descriptions into LLM interfaces for specific solutions, ask conceptual questions about complex programming ideas or theoretical concepts, and generate test cases to check code functionality and robustness. Our analysis includes over 4,000 prompts from 411 students and conducting interviews with 10 students. Our analysis shows that LLMs excel at generating boilerplate code and assisting in debugging, while students handle the integration of components and system troubleshooting. This aligns with the learning objectives of advanced computing courses, which are oriented towards teaching students how to build systems and troubleshoot, with less emphasis on generating code from scratch. Therefore, LLM tools can be leveraged to increase student productivity, as shown by the data we collected. This study contributes to the ongoing discussion on LLM use in education, advocating for their usefulness in advanced computing courses to complement higher-level learning and productivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04603v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaitanya Arora, Utkarsh Venaik, Pavit Singh, Sahil Goyal, Jatin Tyagi, Shyama Goel, Ujjwal Singhal, Dhruv Kumar</dc:creator>
    </item>
    <item>
      <title>Designing for Complementarity: A Conceptual Framework to Go Beyond the Current Paradigm of Using XAI in Healthcare</title>
      <link>https://arxiv.org/abs/2404.04638</link>
      <description>arXiv:2404.04638v1 Announce Type: new 
Abstract: The widespread use of Artificial Intelligence-based tools in the healthcare sector raises many ethical and legal problems, one of the main reasons being their black-box nature and therefore the seemingly opacity and inscrutability of their characteristics and decision-making process. Literature extensively discusses how this can lead to phenomena of over-reliance and under-reliance, ultimately limiting the adoption of AI. We addressed these issues by building a theoretical framework based on three concepts: Feature Importance, Counterexample Explanations, and Similar-Case Explanations. Grounded in the literature, the model was deployed within a case study in which, using a participatory design approach, we designed and developed a high-fidelity prototype. Through the co-design and development of the prototype and the underlying model, we advanced the knowledge on how to design AI-based systems for enabling complementarity in the decision-making process in the healthcare domain. Our work aims at contributing to the current discourse on designing AI systems to support clinicians' decision-making processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04638v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elisa Rubegni, Omran Ayoub, Stefania Maria Rita Rizzo, Marco Barbero, Guenda Bernegger, Francesca Faraci, Francesca Mangili, Emiliano Soldini, Pierpaolo Trimboli, Alessandro Facchini</dc:creator>
    </item>
    <item>
      <title>"Don't Step on My Toes": Resolving Editing Conflicts in Real-Time Collaboration in Computational Notebooks</title>
      <link>https://arxiv.org/abs/2404.04695</link>
      <description>arXiv:2404.04695v1 Announce Type: new 
Abstract: Real-time collaborative editing in computational notebooks can improve the efficiency of teamwork for data scientists. However, working together through synchronous editing of notebooks introduces new challenges. Data scientists may inadvertently interfere with each others' work by altering the shared codebase and runtime state if they do not set up a social protocol for working together and monitoring their collaborators' progress. In this paper, we propose a real-time collaborative editing model for resolving conflict edits in computational notebooks that introduces three levels of edit protection to help collaborators avoid introducing errors to both the program source code and changes to the runtime state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04695v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3643796.3648453</arxiv:DOI>
      <dc:creator>April Yi Wang, Zihan Wu, Christopher Brooks, Steve Oney</dc:creator>
    </item>
    <item>
      <title>Balancing Information Perception with Yin-Yang: Agent-Based Information Neutrality Model for Recommendation Systems</title>
      <link>https://arxiv.org/abs/2404.04906</link>
      <description>arXiv:2404.04906v1 Announce Type: new 
Abstract: While preference-based recommendation algorithms effectively enhance user engagement by recommending personalized content, they often result in the creation of ``filter bubbles''. These bubbles restrict the range of information users interact with, inadvertently reinforcing their existing viewpoints. Previous research has focused on modifying these underlying algorithms to tackle this issue. Yet, approaches that maintain the integrity of the original algorithms remain largely unexplored. This paper introduces an Agent-based Information Neutrality model grounded in the Yin-Yang theory, namely, AbIN. This innovative approach targets the imbalance in information perception within existing recommendation systems. It is designed to integrate with these preference-based systems, ensuring the delivery of recommendations with neutral information. Our empirical evaluation of this model proved its efficacy, showcasing its capacity to expand information diversity while respecting user preferences. Consequently, AbIN emerges as an instrumental tool in mitigating the negative impact of filter bubbles on information consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04906v1</guid>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengyan Wang, Yuxuan Hu, Shiqing Wu, Weihua Li, Quan Bai, Verica Rupar</dc:creator>
    </item>
    <item>
      <title>Towards Developing Brain-Computer Interfaces for People with Multiple Sclerosis</title>
      <link>https://arxiv.org/abs/2404.04965</link>
      <description>arXiv:2404.04965v1 Announce Type: new 
Abstract: Multiple Sclerosis (MS) is a severely disabling condition that leads to various neurological symptoms. A Brain-Computer Interface (BCI) may substitute some lost function; however, there is a lack of BCI research in people with MS. To progress this research area effectively and efficiently, we aimed to evaluate user needs and assess the feasibility and user-centric requirements of a BCI for people with MS. We conducted an online survey of 34 people with MS to qualitatively assess user preferences and establish the initial steps of user-centred design. The survey aimed to understand their interest and preferences in BCI and bionic applications. We demonstrated widespread interest for BCI applications in all stages of MS, with a preference for a non-invasive (n = 12) or minimally invasive (n = 15) BCI over carer assistance (n = 6). Qualitative assessment indicated that this preference was not influenced by level of independence. Additionally, strong interest was noted in bionic technology for sensory and autonomic functions. Considering the potential to enhance independence and quality of life for people living with MS, the results emphasise the importance of user-centred design for future advancement of BCIs that account for the unique pathological changes associated with MS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04965v1</guid>
      <category>cs.HC</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>John S. Russo (Department of Biomedical Engineering, The University of Melbourne, Melbourne, Australia), Tim Mahoney (Department of Biomedical Engineering, The University of Melbourne, Melbourne, Australia), Kirill Kokorin (Department of Biomedical Engineering, The University of Melbourne, Melbourne, Australia, Graeme Clark Institute, The University of Melbourne, Melbourne, Australia), Ashley Reynolds (Department of Biomedical Engineering, The University of Melbourne, Melbourne, Australia, Department of Neurosciences, St. Vincents Hospital, The University of Melbourne, Melbourne, Australia), Chin-Hsuan Sophie Lin (Melbourne School of Psychological Sciences, The University of Melbourne, Melbourne, Australia), Sam E. John (Department of Biomedical Engineering, The University of Melbourne, Melbourne, Australia, Graeme Clark Institute, The University of Melbourne, Melbourne, Australia), David B. Grayden (Department of Biomedical Engineering, The University of Melbourne, Melbourne, Australia, Graeme Clark Institute, The University of Melbourne, Melbourne, Australia, Department of Medicine, St. Vincents Hospital, The University of Melbourne, Melbourne, Australia)</dc:creator>
    </item>
    <item>
      <title>Reduction of Forgetting by Contextual Variation During Encoding Using 360-Degree Video-Based Immersive Virtual Environments</title>
      <link>https://arxiv.org/abs/2404.05007</link>
      <description>arXiv:2404.05007v1 Announce Type: new 
Abstract: Recall impairment in a different environmental context from learning is called context-dependent forgetting. Two learning methods have been proposed to prevent context-dependent forgetting: reinstatement and decontextualization. Reinstatement matches the environmental context between learning and retrieval, whereas decontextualization involves repeated learning in various environmental contexts and eliminates the context dependency of memory. Conventionally, these methods have been validated by switching between physical rooms. However, in this study, we use immersive virtual environments (IVEs) as the environmental context assisted by virtual reality (VR), which is known for its low cost and high reproducibility compared to traditional manipulation. Whereas most existing studies using VR have failed to reveal the reinstatement effect, we test its occurrence using a 360-degree video-based IVE with improved familiarity and realism instead of a computer graphics-based IVE. Furthermore, we are the first to address decontextualization using VR. Our experiment showed that repeated learning in the same constant IVE as retrieval did not significantly reduce forgetting compared to repeated learning in different constant IVEs. Conversely, repeated learning in various IVEs significantly reduced forgetting than repeated learning in constant IVEs. These findings contribute to the design of IVEs for VR-based applications, particularly in educational settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05007v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takato Mizuho, Takuji Narumi, Hideaki Kuzuoka</dc:creator>
    </item>
    <item>
      <title>Co-design Accessible Public Robots: Insights from People with Mobility Disability, Robotic Practitioners and Their Collaborations</title>
      <link>https://arxiv.org/abs/2404.05050</link>
      <description>arXiv:2404.05050v1 Announce Type: new 
Abstract: Sidewalk robots are increasingly common across the globe. Yet, their operation on public paths poses challenges for people with mobility disabilities (PwMD) who face barriers to accessibility, such as insufficient curb cuts. We interviewed 15 PwMD to understand how they perceive sidewalk robots. Findings indicated that PwMD feel they have to compete for space on the sidewalk when robots are introduced. We next interviewed eight robotics practitioners to learn about their attitudes towards accessibility. Practitioners described how issues often stem from robotic companies addressing accessibility only after problems arise. Both interview groups underscored the importance of integrating accessibility from the outset. Building on this finding, we held four co-design workshops with PwMD and practitioners in pairs. These convenings brought to bear accessibility needs around robots operating in public spaces and in the public interest. Our study aims to set the stage for a more inclusive future around public service robots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05050v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Howard Ziyu Han, Franklin Mingzhe Li, Alesandra Baca Vazquez, Daragh Byrne, Nikolas Martelaro, Sarah E Fox</dc:creator>
    </item>
    <item>
      <title>Chart What I Say: Exploring Cross-Modality Prompt Alignment in AI-Assisted Chart Authoring</title>
      <link>https://arxiv.org/abs/2404.05103</link>
      <description>arXiv:2404.05103v1 Announce Type: new 
Abstract: Recent chart-authoring systems, such as Amazon Q in QuickSight and Copilot for Power BI, demonstrate an emergent focus on supporting natural language input to share meaningful insights from data through chart creation. Currently, chart-authoring systems tend to integrate voice input capabilities by relying on speech-to-text transcription, processing spoken and typed input similarly. However, cross-modality input comparisons in other interaction domains suggest that the structure of spoken and typed-in interactions could notably differ, reflecting variations in user expectations based on interface affordances. Thus, in this work, we compare spoken and typed instructions for chart creation. Findings suggest that while both text and voice instructions cover chart elements and element organization, voice descriptions have a variety of command formats, element characteristics, and complex linguistic features. Based on these findings, we developed guidelines for designing voice-based authoring-oriented systems and additional features that can be incorporated into existing text-based systems to support speech modality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05103v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3613905.3650921</arxiv:DOI>
      <dc:creator>Nazar Ponochevnyi, Anastasia Kuzminykh</dc:creator>
    </item>
    <item>
      <title>Evaluation of an LLM in Identifying Logical Fallacies: A Call for Rigor When Adopting LLMs in HCI Research</title>
      <link>https://arxiv.org/abs/2404.05213</link>
      <description>arXiv:2404.05213v1 Announce Type: new 
Abstract: There is increasing interest in the adoption of LLMs in HCI research. However, LLMs may often be regarded as a panacea because of their powerful capabilities with an accompanying oversight on whether they are suitable for their intended tasks. We contend that LLMs should be adopted in a critical manner following rigorous evaluation. Accordingly, we present the evaluation of an LLM in identifying logical fallacies that will form part of a digital misinformation intervention. By comparing to a labeled dataset, we found that GPT-4 achieves an accuracy of 0.79, and for our intended use case that excludes invalid or unidentified instances, an accuracy of 0.90. This gives us the confidence to proceed with the application of the LLM while keeping in mind the areas where it still falls short. The paper describes our evaluation approach, results and reflections on the use of the LLM for our intended task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05213v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gionnieve Lim, Simon T. Perrault</dc:creator>
    </item>
    <item>
      <title>Fair Machine Guidance to Enhance Fair Decision Making in Biased People</title>
      <link>https://arxiv.org/abs/2404.05228</link>
      <description>arXiv:2404.05228v1 Announce Type: new 
Abstract: Teaching unbiased decision-making is crucial for addressing biased decision-making in daily life. Although both raising awareness of personal biases and providing guidance on unbiased decision-making are essential, the latter topics remains under-researched. In this study, we developed and evaluated an AI system aimed at educating individuals on making unbiased decisions using fairness-aware machine learning. In a between-subjects experimental design, 99 participants who were prone to bias performed personal assessment tasks. They were divided into two groups: a) those who received AI guidance for fair decision-making before the task and b) those who received no such guidance but were informed of their biases. The results suggest that although several participants doubted the fairness of the AI system, fair machine guidance prompted them to reassess their views regarding fairness, reflect on their biases, and modify their decision-making criteria. Our findings provide insights into the design of AI systems for guiding fair decision-making in humans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05228v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3613904.3642627</arxiv:DOI>
      <dc:creator>Mingzhe Yang, Hiromi Arai, Naomi Yamashita, Yukino Baba</dc:creator>
    </item>
    <item>
      <title>Exploiting Preference Elicitation in Interactive and User-centered Algorithmic Recourse: An Initial Exploration</title>
      <link>https://arxiv.org/abs/2404.05270</link>
      <description>arXiv:2404.05270v1 Announce Type: new 
Abstract: Algorithmic Recourse aims to provide actionable explanations, or recourse plans, to overturn potentially unfavourable decisions taken by automated machine learning models. In this paper, we propose an interaction paradigm based on a guided interaction pattern aimed at both eliciting the users' preferences and heading them toward effective recourse interventions. In a fictional task of money lending, we compare this approach with an exploratory interaction pattern based on a combination of alternative plans and the possibility of freely changing the configurations by the users themselves. Our results suggest that users may recognize that the guided interaction paradigm improves efficiency. However, they also feel less freedom to experiment with "what-if" scenarios. Nevertheless, the time spent on the purely exploratory interface tends to be perceived as a lack of efficiency, which reduces attractiveness, perspicuity, and dependability. Conversely, for the guided interface, more time on the interface seems to increase its attractiveness, perspicuity, and dependability while not impacting the perceived efficiency. That might suggest that this type of interfaces should combine these two approaches by trying to support exploratory behavior while gently pushing toward a guided effective solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05270v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seyedehdelaram Esfahani, Giovanni De Toni, Bruno Lepri, Andrea Passerini, Katya Tentori, Massimo Zancanaro</dc:creator>
    </item>
    <item>
      <title>Indexing Analytics to Instances: How Integrating a Dashboard can Support Design Education</title>
      <link>https://arxiv.org/abs/2404.05417</link>
      <description>arXiv:2404.05417v1 Announce Type: new 
Abstract: We investigate how to use AI-based analytics to support design education. The analytics at hand measure multiscale design, that is, students' use of space and scale to visually and conceptually organize their design work. With the goal of making the analytics intelligible to instructors, we developed a research artifact integrating a design analytics dashboard with design instances, and the design environment that students use to create them. We theorize about how Suchman's notion of mutual intelligibility requires contextualized investigation of AI in order to develop findings about how analytics work for people. We studied the research artifact in 5 situated course contexts, in 3 departments. A total of 236 students used the multiscale design environment. The 9 instructors who taught those students experienced the analytics via the new research artifact.
  We derive findings from a qualitative analysis of interviews with instructors regarding their experiences. Instructors reflected on how the analytics and their presentation in the dashboard have the potential to affect design education. We develop research implications addressing: (1) how indexing design analytics in the dashboard to actual design work instances helps design instructors reflect on what they mean and, more broadly, is a technique for how AI-based design analytics can support instructors' assessment and feedback experiences in situated course contexts; and (2) how multiscale design analytics, in particular, have the potential to support design education. By indexing, we mean linking which provides context, here connecting the numbers of the analytics with visually annotated design work instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05417v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajit Jain, Andruid Kerne, Nic Lupfer, Gabriel Britain, Aaron Perrine, Yoonsuck Choe, John Keyser, Ruihong Huang, Jinsil Seo, Annie Sungkajun, Robert Lightfoot, Timothy McGuire</dc:creator>
    </item>
    <item>
      <title>Re-Ranking News Comments by Constructiveness and Curiosity Significantly Increases Perceived Respect, Trustworthiness, and Interest</title>
      <link>https://arxiv.org/abs/2404.05429</link>
      <description>arXiv:2404.05429v1 Announce Type: new 
Abstract: Online commenting platforms have commonly developed systems to address online harms by removing and down-ranking content. An alternative, under-explored approach is to focus on up-ranking content to proactively prioritize prosocial commentary and set better conversational norms. We present a study with 460 English-speaking US-based news readers to understand the effects of re-ranking comments by constructiveness, curiosity, and personal stories on a variety of outcomes related to willingness to participate and engage, as well as perceived credibility and polarization in a comment section. In our rich-media survey experiment, participants across these four ranking conditions and a control group reviewed prototypes of comment sections of a Politics op-ed and Dining article. We found that outcomes varied significantly by article type. Up-ranking curiosity and constructiveness improved a number of measures for the Politics article, including perceived \textit{Respect}, \textit{Trustworthiness}, and \textit{Interestingness} of the comment section. Constructiveness also increased perceptions that the comments were favorable to Republicans, with no condition worsening perceptions of partisans. Additionally, in the Dining article, personal stories and constructiveness rankings significantly improved the perceived informativeness of the comments. Overall, these findings indicate that incorporating prosocial qualities of speech into ranking could be a promising approach to promote healthier, less polarized dialogue in online comment sections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05429v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emily Saltz, Zaria Howard, Tin Acosta</dc:creator>
    </item>
    <item>
      <title>Unlocking Adaptive User Experience with Generative AI</title>
      <link>https://arxiv.org/abs/2404.05442</link>
      <description>arXiv:2404.05442v1 Announce Type: new 
Abstract: Developing user-centred applications that address diverse user needs requires rigorous user research. This is time, effort and cost-consuming. With the recent rise of generative AI techniques based on Large Language Models (LLMs), there is a possibility that these powerful tools can be used to develop adaptive interfaces. This paper presents a novel approach to develop user personas and adaptive interface candidates for a specific domain using ChatGPT. We develop user personas and adaptive interfaces using both ChatGPT and a traditional manual process and compare these outcomes. To obtain data for the personas we collected data from 37 survey participants and 4 interviews in collaboration with a not-for-profit organisation. The comparison of ChatGPT generated content and manual content indicates promising results that encourage using LLMs in the adaptive interfaces design process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05442v1</guid>
      <category>cs.HC</category>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yutan Huang, Tanjila Kanij, Anuradha Madugalla, Shruti Mahajan, Chetan Arora, John Grundy</dc:creator>
    </item>
    <item>
      <title>Interactive Formal Specification for Mathematical Problems of Engineers</title>
      <link>https://arxiv.org/abs/2404.05462</link>
      <description>arXiv:2404.05462v1 Announce Type: new 
Abstract: The paper presents the second part of a precise description of the prototype  that has been developed in the course of the ISAC project over the last  two decades. This part describes the "specify-phase", while the first part describing the "solve-phase" is already published.
  In the specify-phase a student interactively constructs a formal specification. The ISAC prototype implements formal specifications as established in theoretical computer science, however, the input language for the construction  avoids requiring users to have knowledge of logic; this makes the system useful for various engineering faculties (and also for high school).
  The paper discusses not only ISAC's design of the specify-phase in detail, but also gives a brief introduction to implementation with the aim of advertising the re-use of formal frameworks (inclusive respective front-ends) with their generic tools for language definition and their rich pool of software  components for formal mathematics.
</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05462v1</guid>
      <category>cs.HC</category>
      <category>cs.LO</category>
      <category>cs.MS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.400.8</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 400, 2024, pp. 120-138</arxiv:journal_reference>
      <dc:creator>Walther Neuper (JKU - Johannes Kepler Universit\"at Linz)</dc:creator>
    </item>
    <item>
      <title>Eye Tracking on Text Reading with Visual Enhancements</title>
      <link>https://arxiv.org/abs/2404.05572</link>
      <description>arXiv:2404.05572v1 Announce Type: new 
Abstract: The interplay between text and visualization is gaining importance for media where traditional text is enriched by visual elements to improve readability and emphasize facts. In two controlled eye-tracking experiments ($N=12$), we approach answers to the question: How do visualization techniques influence reading behavior? We compare plain text to that marked with highlights, icons, and word-sized data visualizations. We assess quantitative metrics~(eye movement, completion time, error rate) and subjective feedback~(personal preference and ratings). The results indicate that visualization techniques, especially in the first experiment, show promising trends for improved reading behavior. The results also show the need for further research to make reading more effective and inform suggestions for future studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05572v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3649902.3653521</arxiv:DOI>
      <dc:creator>Franziska Huth, Maurice Koch, Miriam Awad, Daniel Weiskopf, Kuno Kurzhals</dc:creator>
    </item>
    <item>
      <title>What AIs are not Learning (and Why)</title>
      <link>https://arxiv.org/abs/2404.04267</link>
      <description>arXiv:2404.04267v1 Announce Type: cross 
Abstract: What applications is AI ready for? Advances in deep learning and generative approaches have produced AI that learn from massive online data and outperform manually built AIs. Some AIs outperform people. It is easy (but misleading) to conclude that today's AI technologies can learn to do everything. Conversely, it is striking that big data, deep learning, and generative AI have had so little impact on robotics. For example, today's autonomous robots do not learn to provide home care or to be nursing assistants. Instead, current projects rely on mathematical models, planning frameworks, and reinforcement learning. These methods have not lead to the leaps in performance and generality seen with deep learning. Today's AIs do not learn to do such applications because they do not collect, use, and effectively generalize the necessary experiential data by interacting with the world including people. Aspirationally, robotic AIs would learn experientially, learn from people, serve people broadly, and collaborate with them. Getting to such a future requires understanding the opportunity and creating a path to get there. A path forward would combine multimodal sensing and motor control technology from robotics with deep learning technology adapted for embodied systems. Analogous to foundation classes in deep learning, it would create experiential foundation classes. Success would greatly increase the broad utility of AI robots and grow the market for them. This would lead to lower costs and democratize AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04267v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark Stefik</dc:creator>
    </item>
    <item>
      <title>Designing for Human-Agent Alignment: Understanding what humans want from their agents</title>
      <link>https://arxiv.org/abs/2404.04289</link>
      <description>arXiv:2404.04289v1 Announce Type: cross 
Abstract: Our ability to build autonomous agents that leverage Generative AI continues to increase by the day. As builders and users of such agents it is unclear what parameters we need to align on before the agents start performing tasks on our behalf. To discover these parameters, we ran a qualitative empirical research study about designing agents that can negotiate during a fictional yet relatable task of selling a camera online. We found that for an agent to perform the task successfully, humans/users and agents need to align over 6 dimensions: 1) Knowledge Schema Alignment 2) Autonomy and Agency Alignment 3) Operational Alignment and Training 4) Reputational Heuristics Alignment 5) Ethics Alignment and 6) Human Engagement Alignment. These empirical findings expand previous work related to process and specification alignment and the need for values and safety in Human-AI interactions. Subsequently we discuss three design directions for designers who are imagining a world filled with Human-Agent collaborations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04289v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3613905.3650948</arxiv:DOI>
      <dc:creator>Nitesh Goyal, Minsuk Chang, Michael Terry</dc:creator>
    </item>
    <item>
      <title>Navigating the Landscape of Hint Generation Research: From the Past to the Future</title>
      <link>https://arxiv.org/abs/2404.04728</link>
      <description>arXiv:2404.04728v1 Announce Type: cross 
Abstract: Digital education has gained popularity in the last decade, especially after the COVID-19 pandemic. With the improving capabilities of large language models to reason and communicate with users, envisioning intelligent tutoring systems (ITSs) that can facilitate self-learning is not very far-fetched. One integral component to fulfill this vision is the ability to give accurate and effective feedback via hints to scaffold the learning process. In this survey article, we present a comprehensive review of prior research on hint generation, aiming to bridge the gap between research in education and cognitive science, and research in AI and Natural Language Processing. Informed by our findings, we propose a formal definition of the hint generation task, and discuss the roadmap of building an effective hint generation system aligned with the formal definition, including open challenges, future directions and ethical considerations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04728v1</guid>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anubhav Jangra, Jamshid Mozafari, Adam Jatowt, Smaranda Muresan</dc:creator>
    </item>
    <item>
      <title>Allowing humans to interactively guide machines where to look does not always improve a human-AI team's classification accuracy</title>
      <link>https://arxiv.org/abs/2404.05238</link>
      <description>arXiv:2404.05238v1 Announce Type: cross 
Abstract: Via thousands of papers in Explainable AI (XAI), attention maps \cite{vaswani2017attention} and feature attribution maps \cite{bansal2020sam} have been established as a common means for explaining the input features that are important to AI's decisions. It is an interesting but unexplored question whether allowing users to edit the importance scores of input features at test time would improve the human-AI team's accuracy on downstream tasks. In this paper, we address this question by taking CHM-Corr, a state-of-the-art, ante-hoc explanation method \cite{taesiri2022visual} that first predicts patch-wise correspondences between the input and the training-set images, and then uses them to make classification decisions. We build an interactive interface on top of CHM-Corr, enabling users to directly edit the initial feature attribution map provided by CHM-Corr. Via our CHM-Corr++ interface, users gain insights into if, when, and how the model changes its outputs, enhancing understanding beyond static explanations. Our user study with 18 machine learning researchers who performed $\sim$1,400 decisions shows that our interactive approach does not improve user accuracy on CUB-200 bird image classification over static explanations. This challenges the belief that interactivity inherently boosts XAI effectiveness~\cite{sokol2020one,sun2022exploring,shen2024towards,singh2024rethinking,mindlin2024beyond,lakkaraju2022rethinking,cheng2019explaining,liu2021understanding} and raises needs for future research. Our work contributes to the field by open-sourcing an interactive tool for manipulating model attention, and it lays the groundwork for future research to enable effective human-AI interaction in computer vision. We release code and data on \href{https://anonymous.4open.science/r/CHMCorrPlusPlus/}{github}. Our interface are available \href{http://137.184.82.109:7080/}{here}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05238v1</guid>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giang Nguyen, Mohammad Reza Taesiri, Sunnie S. Y. Kim, Anh Nguyen</dc:creator>
    </item>
    <item>
      <title>WebXR, A-Frame and Networked-Aframe as a Basis for an Open Metaverse: A Conceptual Architecture</title>
      <link>https://arxiv.org/abs/2404.05317</link>
      <description>arXiv:2404.05317v1 Announce Type: cross 
Abstract: This work proposes a WebXR-based cross-platform conceptual architecture, leveraging the A-Frame and Networked-Aframe frameworks, in order to facilitate the development of an open, accessible, and interoperable metaverse. By introducing the concept of spatial web app, this research contributes to the discourse on the metaverse, offering an architecture that democratizes access to virtual environments and extended reality through the web, and aligns with Tim Berners-Lee's original vision of the World Wide Web as an open platform in the digital realm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05317v1</guid>
      <category>cs.CV</category>
      <category>cs.GR</category>
      <category>cs.HC</category>
      <category>cs.MM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Macario</dc:creator>
    </item>
    <item>
      <title>Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs</title>
      <link>https://arxiv.org/abs/2404.05719</link>
      <description>arXiv:2404.05719v1 Announce Type: cross 
Abstract: Recent advancements in multimodal large language models (MLLMs) have been noteworthy, yet, these general-domain MLLMs often fall short in their ability to comprehend and interact effectively with user interface (UI) screens. In this paper, we present Ferret-UI, a new MLLM tailored for enhanced understanding of mobile UI screens, equipped with referring, grounding, and reasoning capabilities. Given that UI screens typically exhibit a more elongated aspect ratio and contain smaller objects of interest (e.g., icons, texts) than natural images, we incorporate "any resolution" on top of Ferret to magnify details and leverage enhanced visual features. Specifically, each screen is divided into 2 sub-images based on the original aspect ratio (i.e., horizontal division for portrait screens and vertical division for landscape screens). Both sub-images are encoded separately before being sent to LLMs. We meticulously gather training samples from an extensive range of elementary UI tasks, such as icon recognition, find text, and widget listing. These samples are formatted for instruction-following with region annotations to facilitate precise referring and grounding. To augment the model's reasoning ability, we further compile a dataset for advanced tasks, including detailed description, perception/interaction conversations, and function inference. After training on the curated datasets, Ferret-UI exhibits outstanding comprehension of UI screens and the capability to execute open-ended instructions. For model evaluation, we establish a comprehensive benchmark encompassing all the aforementioned tasks. Ferret-UI excels not only beyond most open-source UI MLLMs, but also surpasses GPT-4V on all the elementary UI tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05719v1</guid>
      <category>cs.CV</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keen You, Haotian Zhang, Eldon Schoop, Floris Weers, Amanda Swearngin, Jeffrey Nichols, Yinfei Yang, Zhe Gan</dc:creator>
    </item>
    <item>
      <title>Local Perceptions and Practices of News Sharing and Fake News</title>
      <link>https://arxiv.org/abs/2010.07607</link>
      <description>arXiv:2010.07607v2 Announce Type: replace 
Abstract: Fake news is a prevalent problem, particularly in digital media, that undermines trust and cooperation among people. As a variety of global mitigation efforts arise, the understanding of how people consider fake news becomes important, especially in local contexts. To that end, we carried out a survey with 75 participants in Singapore to understand people's perceptions of and practices with news (real and fake). Locally, fake news was found to be more pervasive in instant messaging apps than in social media, with the problem attributed more strongly to sharing than to creation. Good news sharing practices were generally observed. Highest trust was reported in government communication platforms across 11 media items. These results show that Singapore possesses a peculiar sociocultural scene, suggesting that efforts directed towards locally relevant measures may be more effective in addressing fake news in Singapore. We detail the survey results and recommended directions in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.07607v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3462204.3481767</arxiv:DOI>
      <arxiv:journal_reference>CSCW 2021</arxiv:journal_reference>
      <dc:creator>Gionnieve Lim, Simon T. Perrault</dc:creator>
    </item>
    <item>
      <title>Learning from Crowds with Crowd-Kit</title>
      <link>https://arxiv.org/abs/2109.08584</link>
      <description>arXiv:2109.08584v4 Announce Type: replace 
Abstract: This paper presents Crowd-Kit, a general-purpose computational quality control toolkit for crowdsourcing. Crowd-Kit provides efficient and convenient implementations of popular quality control algorithms in Python, including methods for truth inference, deep learning from crowds, and data quality estimation. Our toolkit supports multiple modalities of answers and provides dataset loaders and example notebooks for faster prototyping. We extensively evaluated our toolkit on several datasets of different natures, enabling benchmarking computational quality control methods in a uniform, systematic, and reproducible way using the same codebase. We release our code and data under the Apache License 2.0 at https://github.com/Toloka/crowd-kit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.08584v4</guid>
      <category>cs.HC</category>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.21105/joss.06227</arxiv:DOI>
      <arxiv:journal_reference>Journal of Open Source Software (2024), 9(96), 6227</arxiv:journal_reference>
      <dc:creator>Dmitry Ustalov, Nikita Pavlichenko, Boris Tseitlin</dc:creator>
    </item>
    <item>
      <title>Versatile User Identification in Extended Reality using Pretrained Similarity-Learning</title>
      <link>https://arxiv.org/abs/2302.07517</link>
      <description>arXiv:2302.07517v5 Announce Type: replace 
Abstract: Different approaches in machine learning have proven useful for user verification and identification based on motion data in eXtended Reality (XR). However, their real-world application still faces significant challenges concerning versatility, i.e., in terms of extensibility and generalization capability. This article presents a solution that is both extensible to new users without expensive retraining, and that generalizes well across different sessions, devices, and user tasks. To this end, we developed a similarity-learning model and pretrained it on the "Who Is Alyx?" dataset. This dataset features a wide array of actions from users playing the VR game "Half-Life: Alyx". In contrast to previous works, we used a dedicated set of users for model validation and final evaluation. Furthermore, we extended this evaluation using an independent dataset that features completely different users, tasks, and three different XR devices. In comparison with a traditional classification-learning baseline, our model shows superior performance, especially in scenarios with limited enrollment data. The pretraining process allows easy deployment in a diverse range of XR applications while maintaining high versatility. Looking ahead, our methodology can facilitate the easy integration of pretrained motion-based identification models into 3D engines: dedicated plugins for Unreal and Unity promise straightforward and quick adoption of these advanced models in the future, even for those lacking expertise in motion analysis and machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.07517v5</guid>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Christian Rack, Konstantin Kobs, Tamara Fernando, Andreas Hotho, Marc Erich Latoschik</dc:creator>
    </item>
    <item>
      <title>Towards AI-Architecture Liberty: A Comprehensive Survey on Designing and Collaborating Virtual Architecture by Deep Learning in the Metaverse</title>
      <link>https://arxiv.org/abs/2305.00510</link>
      <description>arXiv:2305.00510v3 Announce Type: replace 
Abstract: 3D shape generation techniques leveraging deep learning have garnered significant interest from both the computer vision and architectural design communities, promising to enrich the content of the future metaverse. However, research on virtual architectural design remains limited, particularly regarding human-AI collaboration and deep learning-assisted design. We first illuminate the principles, generation techniques, and current literature of virtual architecture, focusing on challenges such as datasets, multimodality, design intuition, and generative frameworks. In our survey, we reviewed 187 related articles (80.7\% of articles published between 2018 and 2022) covering architectural research, virtual environments, and technical approaches. This survey investigates the latest approaches to 3D object generation with deep generative models (DGMs) and summarizes four characteristics of deep-learning generation approaches for virtual architecture. According to our analysis of the survey, we expound on four research agendas, including agency, communication, user consideration, and integrating tools, and highlight three important enablers of ubiquitous interaction with immersive systems in deep learning-assisted architectural generation. Our work contributes to fostering understanding between designers and deep learning techniques, broadening access to human-AI collaboration. We advocate for interdisciplinary efforts to address this timely research topic, facilitating content designing and generation in the metaverse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00510v3</guid>
      <category>cs.HC</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Anqi Wang, Jiahua Dong, Lik-Hang Lee, Jiachuan Shen, Pan Hui</dc:creator>
    </item>
    <item>
      <title>HIFuzz: Human Interaction Fuzzing for small Unmanned Aerial Vehicles</title>
      <link>https://arxiv.org/abs/2310.12058</link>
      <description>arXiv:2310.12058v2 Announce Type: replace 
Abstract: Small Unmanned Aerial Systems (sUAS) must meet rigorous safety standards when deployed in high-stress emergency response scenarios; however many reported accidents have involved humans in the loop. In this paper, we, therefore, present the HiFuzz testing framework, which uses fuzz testing to identify system vulnerabilities associated with human interactions. HiFuzz includes three distinct levels that progress from a low-cost, limited-fidelity, large-scale, no-hazard environment, using fully simulated Proxy Human Agents, via an intermediate level, where proxy humans are replaced with real humans, to a high-stakes, high-cost, real-world environment. Through applying HiFuzz to an autonomous multi-sUAS system-under-test, we show that each test level serves a unique purpose in revealing vulnerabilities and making the system more robust with respect to human mistakes. While HiFuzz is designed for testing sUAS systems, we further discuss its potential for use in other Cyber-Physical Systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12058v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3613904.3642958</arxiv:DOI>
      <dc:creator>Theodore Chambers, Michael Vierhauser, Ankit Agrawal, Michael Murphy, Jason Matthew Brauer, Salil Purandare, Myra B. Cohen, Jane Cleland-Huang</dc:creator>
    </item>
    <item>
      <title>How Can Large Language Models Enable Better Socially Assistive Human-Robot Interaction: A Brief Survey</title>
      <link>https://arxiv.org/abs/2404.00938</link>
      <description>arXiv:2404.00938v2 Announce Type: replace 
Abstract: Socially assistive robots (SARs) have shown great success in providing personalized cognitive-affective support for user populations with special needs such as older adults, children with autism spectrum disorder (ASD), and individuals with mental health challenges. The large body of work on SAR demonstrates its potential to provide at-home support that complements clinic-based interventions delivered by mental health professionals, making these interventions more effective and accessible. However, there are still several major technical challenges that hinder SAR-mediated interactions and interventions from reaching human-level social intelligence and efficacy. With the recent advances in large language models (LLMs), there is an increased potential for novel applications within the field of SAR that can significantly expand the current capabilities of SARs. However, incorporating LLMs introduces new risks and ethical concerns that have not yet been encountered, and must be carefully be addressed to safely deploy these more advanced systems. In this work, we aim to conduct a brief survey on the use of LLMs in SAR technologies, and discuss the potentials and risks of applying LLMs to the following three major technical challenges of SAR: 1) natural language dialog; 2) multimodal understanding; 3) LLMs as robot policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00938v2</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhonghao Shi, Ellen Landrum, Amy O' Connell, Mina Kian, Leticia Pinto-Alva, Kaleen Shrestha, Xiaoyuan Zhu, Maja J Matari\'c</dc:creator>
    </item>
    <item>
      <title>Gen4DS: Workshop on Data Storytelling in an Era of Generative AI</title>
      <link>https://arxiv.org/abs/2404.01622</link>
      <description>arXiv:2404.01622v2 Announce Type: replace 
Abstract: Storytelling is an ancient and precious human ability that has been rejuvenated in the digital age. Over the last decade, there has been a notable surge in the recognition and application of data storytelling, both in academia and industry. Recently, the rapid development of generative AI has brought new opportunities and challenges to this field, sparking numerous new questions. These questions may not necessarily be quickly transformed into papers, but we believe it is necessary to promptly discuss them to help the community better clarify important issues and research agendas for the future. We thus invite you to join our workshop (Gen4DS) to discuss questions such as: How can generative AI facilitate the creation of data stories? How might generative AI alter the workflow of data storytellers? What are the pitfalls and risks of incorporating AI in storytelling? We have designed both paper presentations and interactive activities (including hands-on creation, group discussion pods, and debates on controversial issues) for the workshop. We hope that participants will learn about the latest advances and pioneering work in data storytelling, engage in critical conversations with each other, and have an enjoyable, unforgettable, and meaningful experience at the event.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01622v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.GR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xingyu Lan, Leni Yang, Zezhong Wang, Yun Wang, Danqing Shi, Sheelagh Carpendale</dc:creator>
    </item>
    <item>
      <title>Zero-Shot Segmentation of Eye Features Using the Segment Anything Model (SAM)</title>
      <link>https://arxiv.org/abs/2311.08077</link>
      <description>arXiv:2311.08077v2 Announce Type: replace-cross 
Abstract: The advent of foundation models signals a new era in artificial intelligence. The Segment Anything Model (SAM) is the first foundation model for image segmentation. In this study, we evaluate SAM's ability to segment features from eye images recorded in virtual reality setups. The increasing requirement for annotated eye-image datasets presents a significant opportunity for SAM to redefine the landscape of data annotation in gaze estimation. Our investigation centers on SAM's zero-shot learning abilities and the effectiveness of prompts like bounding boxes or point clicks. Our results are consistent with studies in other domains, demonstrating that SAM's segmentation effectiveness can be on-par with specialized models depending on the feature, with prompts improving its performance, evidenced by an IoU of 93.34% for pupil segmentation in one dataset. Foundation models like SAM could revolutionize gaze estimation by enabling quick and easy image segmentation, reducing reliance on specialized models and extensive manual annotation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.08077v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3654704</arxiv:DOI>
      <dc:creator>Virmarie Maquiling, Sean Anthony Byrne, Diederick C. Niehorster, Marcus Nystr\"om, Enkelejda Kasneci</dc:creator>
    </item>
    <item>
      <title>Evaluating Task-oriented Dialogue Systems: A Systematic Review of Measures, Constructs and their Operationalisations</title>
      <link>https://arxiv.org/abs/2312.13871</link>
      <description>arXiv:2312.13871v2 Announce Type: replace-cross 
Abstract: This review gives an extensive overview of evaluation methods for task-oriented dialogue systems, paying special attention to practical applications of dialogue systems, for example for customer service. The review (1) provides an overview of the used constructs and metrics in previous work, (2) discusses challenges in the context of dialogue system evaluation and (3) develops a research agenda for the future of dialogue system evaluation. We conducted a systematic review of four databases (ACL, ACM, IEEE and Web of Science), which after screening resulted in 122 studies. Those studies were carefully analysed for the constructs and methods they proposed for evaluation. We found a wide variety in both constructs and methods. Especially the operationalisation is not always clearly reported. Newer developments concerning large language models are discussed in two contexts: to power dialogue systems and to use in the evaluation process. We hope that future work will take a more critical approach to the operationalisation and specification of the used constructs. To work towards this aim, this review ends with recommendations for evaluation and suggestions for outstanding questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13871v2</guid>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anouck Braggaar, Christine Liebrecht, Emiel van Miltenburg, Emiel Krahmer</dc:creator>
    </item>
    <item>
      <title>Robot Interaction Behavior Generation based on Social Motion Forecasting for Human-Robot Interaction</title>
      <link>https://arxiv.org/abs/2402.04768</link>
      <description>arXiv:2402.04768v2 Announce Type: replace-cross 
Abstract: Integrating robots into populated environments is a complex challenge that requires an understanding of human social dynamics. In this work, we propose to model social motion forecasting in a shared human-robot representation space, which facilitates us to synthesize robot motions that interact with humans in social scenarios despite not observing any robot in the motion training. We develop a transformer-based architecture called ECHO, which operates in the aforementioned shared space to predict the future motions of the agents encountered in social scenarios. Contrary to prior works, we reformulate the social motion problem as the refinement of the predicted individual motions based on the surrounding agents, which facilitates the training while allowing for single-motion forecasting when only one human is in the scene. We evaluate our model in multi-person and human-robot motion forecasting tasks and obtain state-of-the-art performance by a large margin while being efficient and performing in real-time. Additionally, our qualitative results showcase the effectiveness of our approach in generating human-robot interaction behaviors that can be controlled via text commands. Webpage: https://evm7.github.io/ECHO/</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04768v2</guid>
      <category>cs.RO</category>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Esteve Valls Mascaro, Yashuai Yan, Dongheui Lee</dc:creator>
    </item>
    <item>
      <title>The Journey to Trustworthy AI- Part 1: Pursuit of Pragmatic Frameworks</title>
      <link>https://arxiv.org/abs/2403.15457</link>
      <description>arXiv:2403.15457v2 Announce Type: replace-cross 
Abstract: This paper reviews Trustworthy Artificial Intelligence (TAI) and its various definitions. Considering the principles respected in any society, TAI is often characterized by a few attributes, some of which have led to confusion in regulatory or engineering contexts. We argue against using terms such as Responsible or Ethical AI as substitutes for TAI. And to help clarify any confusion, we suggest leaving them behind. Given the subjectivity and complexity inherent in TAI, developing a universal framework is deemed infeasible. Instead, we advocate for approaches centered on addressing key attributes and properties such as fairness, bias, risk, security, explainability, and reliability. We examine the ongoing regulatory landscape, with a focus on initiatives in the EU, China, and the USA. We recognize that differences in AI regulations based on geopolitical and geographical reasons pose an additional challenge for multinational companies. We identify risk as a core factor in AI regulation and TAI. For example, as outlined in the EU-AI Act, organizations must gauge the risk level of their AI products to act accordingly (or risk hefty fines). We compare modalities of TAI implementation and how multiple cross-functional teams are engaged in the overall process. Thus, a brute force approach for enacting TAI renders its efficiency and agility, moot. To address this, we introduce our framework Set-Formalize-Measure-Act (SFMA). Our solution highlights the importance of transforming TAI-aware metrics, drivers of TAI, stakeholders, and business/legal requirements into actual benchmarks or tests. Finally, over-regulation driven by panic of powerful AI models can, in fact, harm TAI too. Based on GitHub user-activity data, in 2023, AI open-source projects rose to top projects by contributor account. Enabling innovation in TAI hinges on the independent contributions of the open-source community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15457v2</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mohamad M Nasr-Azadani, Jean-Luc Chatelain</dc:creator>
    </item>
  </channel>
</rss>
