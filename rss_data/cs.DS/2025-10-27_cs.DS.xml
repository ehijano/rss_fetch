<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 Oct 2025 03:00:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Hardness of Approximation for Shortest Path with Vector Costs</title>
      <link>https://arxiv.org/abs/2510.21058</link>
      <description>arXiv:2510.21058v1 Announce Type: new 
Abstract: We obtain hardness of approximation results for the $\ell_p$-Shortest Path problem, a variant of the classic Shortest Path problem with vector costs. For every integer $p \in [2,\infty)$, we show a hardness of $\Omega(p(\log n / \log^2\log n)^{1-1/p})$ for both polynomial- and quasi-polynomial-time approximation algorithms. This nearly matches the approximation factor of $O(p(\log n / \log\log n)^{1-1/p})$ achieved by a quasi-polynomial-time algorithm of Makarychev, Ovsiankin, and Tani (ICALP 2025). No hardness of approximation results were previously known for any $p &lt; \infty$. We also present results for the case where $p$ is a function of $n$. For $p = \infty$, we establish a hardness of $\tilde\Omega(\log^2 n)$, improving upon the previous $\tilde\Omega(\log n)$ hardness result. Our result nearly matches the $O(\log^2 n)$ approximation guarantee of the quasi-polynomial-time algorithm by Li, Xu, and Zhang (ICALP 2025). Finally, we present asymptotic bounds on higher-order Bell numbers, which might be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21058v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charlie Carlson, Yury Makarychev, Ron Mosenzon</dc:creator>
    </item>
    <item>
      <title>A Unified Approach to Submodular Maximization Under Noise</title>
      <link>https://arxiv.org/abs/2510.21128</link>
      <description>arXiv:2510.21128v1 Announce Type: new 
Abstract: We consider the problem of maximizing a submodular function with access to a noisy value oracle for the function instead of an exact value oracle. Similar to prior work, we assume that the noisy oracle is persistent in that multiple calls to the oracle for a specific set always return the same value. In this model, Hassidim and Singer (2017) design a $(1-1/e)$-approximation algorithm for monotone submodular maximization subject to a cardinality constraint, and Huang et al (2022) design a $(1-1/e)/2$-approximation algorithm for monotone submodular maximization subject to any arbitrary matroid constraint. In this paper, we design a meta-algorithm that allows us to take any "robust" algorithm for exact submodular maximization as a black box and transform it into an algorithm for the noisy setting while retaining the approximation guarantee. By using the meta-algorithm with the measured continuous greedy algorithm, we obtain a $(1-1/e)$-approximation (resp. $1/e$-approximation) for monotone (resp. non-monotone) submodular maximization subject to a matroid constraint under noise. Furthermore, by using the meta-algorithm with the double greedy algorithm, we obtain a $1/2$-approximation for unconstrained (non-monotone) submodular maximization under noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21128v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kshipra Bhawalkar, Yang Cai, Zhe Feng, Christopher Liaw, Tao Lin</dc:creator>
    </item>
    <item>
      <title>Unsplittable Cost Flows from Unweighted Error-Bounded Variants</title>
      <link>https://arxiv.org/abs/2510.21287</link>
      <description>arXiv:2510.21287v1 Announce Type: new 
Abstract: A famous conjecture of Goemans on single-source unsplittable flows states that one can turn any fractional flow into an unsplittable one of no higher cost, while increasing the load on any arc by at most the maximum demand. Despite extensive work on the topic, only limited progress has been made. Recently, Morell and Skutella suggested an alternative conjecture, stating that one can turn any fractional flow into an unsplittable one without changing the load on any arc by more than the maximum demand.
  We show that their conjecture implies Goemans' conjecture (with a violation of twice the maximum demand). To this end, we generalize a technique of Linhares and Swamy, used to obtain a low-cost chain-constrained spanning tree from an algorithm without cost guarantees. Whereas Linhares and Swamy's proof relies on Langrangian duality, we provide a very simple elementary proof of a generalized version, which we hope to be of independent interest. Moreover, we show how this technique can also be used in the context of the weighted ring loading problem, showing that cost-unaware approximation algorithms can be transformed into approximation algorithms with additional cost guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21287v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaitanya Swamy, Vera Traub, Laura Vargas Koch, Rico Zenklusen</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Distributed Edge Coloring and Orientation Problems</title>
      <link>https://arxiv.org/abs/2510.21327</link>
      <description>arXiv:2510.21327v1 Announce Type: new 
Abstract: Understanding the role of randomness when solving locally checkable labeling (LCL) problems in the LOCAL model has been one of the top priorities in the research on distributed graph algorithms in recent years. For LCL problems in bounded-degree graphs, it is known that randomness cannot help more than polynomially, except in one case: if the deterministic complexity of an LCL problem is in $\Omega(\log n)$ and its randomized complexity is in $o(\log n)$, then the randomized complexity is guaranteed to be $poly(\log \log n)$. However, the fundamental question of \emph{which} problems with a deterministic complexity of $\Omega(\log n)$ can be solved exponentially faster using randomization still remains wide open.
  We make a step towards answering this question by studying a simple, but natural class of LCL problems: so-called degree splitting problems. These problems come in two varieties: coloring problems where the edges of a graph have to be colored with $2$ colors and orientation problems where each edge needs to be oriented. For $\Delta$-regular graphs (where $\Delta=O(1)$), we obtain the following results.
  - We gave an exact characterization of the randomized complexity of all problems where the edges need to be colored with two colors, say red and blue, and which have a deterministic complexity of $O(\log n)$. - For edge orientation problems, we give a partial characterization of the problems that have a randomized complexity of $\Omega(\log n)$ and the problems that have a randomized complexity of $poly\log\log n$.
  While our results are cleanest to state for the $\Delta$-regular case, all our algorithms naturally generalize to nodes of any degree $d&lt;\Delta$ in general graphs of maximum degree $\Delta$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21327v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Brandt, Fabian Kuhn, Zahra Parsaeian</dc:creator>
    </item>
    <item>
      <title>Approximate minimization of interpretations in fuzzy description logics under the G\"odel semantics</title>
      <link>https://arxiv.org/abs/2510.21423</link>
      <description>arXiv:2510.21423v1 Announce Type: new 
Abstract: The problem of minimizing fuzzy interpretations in fuzzy description logics (FDLs) is important both theoretically and practically. For instance, fuzzy or weighted social networks can be modeled as fuzzy interpretations, where individuals represent actors and roles capture interactions. Minimizing such interpretations yields more compact representations, which can significantly improve the efficiency of reasoning and analysis tasks in knowledge-based systems. We present the first algorithm that minimizes a finite fuzzy interpretation while preserving fuzzy concept assertions in FDLs without the Baaz projection operator and the universal role, under the G\"odel semantics. The considered class of FDLs ranges from the sublogic of $f\!\mathcal{ALC}$ without the union operator and universal restriction to the FDL that extends $f\!\mathcal{ALC}_{reg}$ with inverse roles and nominals. Our algorithm is given in an extended form that supports approximate preservation: it minimizes a finite fuzzy interpretation $\mathcal{I}$ while preserving fuzzy concept assertions up to a degree $\gamma \in (0,1]$. Its time complexity is $O((m\log{l} + n)\log{n})$, where $n$ is the size of the domain of $\mathcal{I}$, $m$ is the number of nonzero instances of atomic roles in $\mathcal{I}$, and $l$ is the number of distinct fuzzy values used in such instances plus 2.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21423v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linh Anh Nguyen</dc:creator>
    </item>
    <item>
      <title>Placing Green Bridges Optimally, with Close-Range Habitats in Sparse Graphs</title>
      <link>https://arxiv.org/abs/2510.21540</link>
      <description>arXiv:2510.21540v1 Announce Type: new 
Abstract: We study a network design problem motivated by the challenge of placing wildlife crossings to reconnect fragmented habitats of animal species, which is among the 17 goals towards sustainable development by the UN: Given a graph, whose vertices represent the fragmented habitat areas and whose edges represent possible green bridge locations (with costs), and the habitable vertex set for each species' habitat, the goal is to find the cheapest set of edges such that each species' habitat is sufficiently connected. We focus on the established variant where a habitat is considered sufficiently connected if it has diameter two in the solution and study its complexity in cases justified by our setting namely small habitat sizes on planar graphs and graphs of small maximum degree $\Delta$. We provide efficient algorithms and NP-hardness results for different values of $\Delta$ and maximum habitat sizes on general and planar graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21540v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Wallisch, Till Fluschnik, Leon Kellerhals</dc:creator>
    </item>
    <item>
      <title>Beyond Smoothed Analysis: Analyzing the Simplex Method by the Book</title>
      <link>https://arxiv.org/abs/2510.21613</link>
      <description>arXiv:2510.21613v1 Announce Type: new 
Abstract: Narrowing the gap between theory and practice is a longstanding goal of the algorithm analysis community. To further progress our understanding of how algorithms work in practice, we propose a new algorithm analysis framework that we call by the book analysis. In contrast to earlier frameworks, by the book analysis not only models an algorithm's input data, but also the algorithm itself. Results from by the book analysis are meant to correspond well with established knowledge of an algorithm's practical behavior, as they are meant to be grounded in observations from implementations, input modeling best practices, and measurements on practical benchmark instances. We apply our framework to the simplex method, an algorithm which is beloved for its excellent performance in practice and notorious for its high running time under worst-case analysis. The simplex method similarly showcased the state of the art framework smoothed analysis (Spielman and Teng, STOC'01). We explain how our framework overcomes several weaknesses of smoothed analysis and we prove that under input scaling assumptions, feasibility tolerances and other design principles used by simplex method implementations, the simplex method indeed attains a polynomial running time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21613v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eleon Bach, Alexander E. Black, Sophie Huiberts, Sean Kafer</dc:creator>
    </item>
    <item>
      <title>O(1)-Distortion Planar Emulators for String Graphs</title>
      <link>https://arxiv.org/abs/2510.21700</link>
      <description>arXiv:2510.21700v1 Announce Type: new 
Abstract: We show that every unweighted string graph $G$ has an $O(1)$-distortion planar emulator: that is, there exists an (edge-weighted) planar graph $H$ with $V(H) = V(G)$, such that every pair of vertices $(u,v)$ satisfies $\delta_G(u,v) \le \delta_H(u,v) \le O(1) \cdot \delta_G(u,v).$</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21700v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.MG</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hsien-Chih Chang, Jonathan Conroy, Zihan Tan, Da Wei Zheng</dc:creator>
    </item>
    <item>
      <title>Online Multi-Class Selection with Group Fairness Guarantee</title>
      <link>https://arxiv.org/abs/2510.21055</link>
      <description>arXiv:2510.21055v1 Announce Type: cross 
Abstract: We study the online multi-class selection problem with group fairness guarantees, where limited resources must be allocated to sequentially arriving agents. Our work addresses two key limitations in the existing literature. First, we introduce a novel lossless rounding scheme that ensures the integral algorithm achieves the same expected performance as any fractional solution. Second, we explicitly address the challenges introduced by agents who belong to multiple classes. To this end, we develop a randomized algorithm based on a relax-and-round framework. The algorithm first computes a fractional solution using a resource reservation approach -- referred to as the set-aside mechanism -- to enforce fairness across classes. The subsequent rounding step preserves these fairness guarantees without degrading performance. Additionally, we propose a learning-augmented variant that incorporates untrusted machine-learned predictions to better balance fairness and efficiency in practical settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21055v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faraz Zargari, Hossein Nekouyan, Lyndon Hallett, Bo Sun, Xiaoqi Tan</dc:creator>
    </item>
    <item>
      <title>Universal Maximum Likelihood (List) Decoding via Fast Vector-Matrix Multiplication</title>
      <link>https://arxiv.org/abs/2510.21414</link>
      <description>arXiv:2510.21414v1 Announce Type: cross 
Abstract: Maximum-likelihood (ML) decoding for arbitrary block codes remains fundamentally hard, with worst-case time complexity-measured by the total number of multiplications-being no better than straightforward exhaustive search, which requires $q^{k} n$ operations for an $[n,k]_q$ code. This paper introduces a simple, code-agnostic framework that reduces the worst-case complexity by a factor of $n$, down to $q^{k}$ operations, a highly desirable reduction in practice. The result holds for both linear and nonlinear block codes over general memoryless channels and under both hard-decision and soft-decision decoding. It naturally extends to intersymbol-interference (ISI) channels and ML list decoding with only a negligible increase in complexity. Our core insight is that, upon receipt of each sequence at the receiver, the conditional probability of that sequence for each codeword in the codebook (i.e., the \emph{likelihood}) can be expressed as the inner product of two carefully constructed vectors -- the first depending on the received sequence, and the second on that codeword itself. As a result, evaluating the likelihoods for all codewords in the codebook reduces to a single vector-matrix multiplication, and ML decoding (MLD) becomes the simple task of picking the maximum entry in the resulting vector. The only non-trivial cost lies in the vector-matrix product. However, our matrix construction allows the use of the Mailman algorithm to reduce this cost. This time reduction is achieved at the cost of high space complexity, requiring $\mathcal{O}(q^{k+1} n)$ space to store the pre-computed codebook matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21414v1</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Ly, Emina Soljanin</dc:creator>
    </item>
    <item>
      <title>Relative-error unateness testing</title>
      <link>https://arxiv.org/abs/2510.21589</link>
      <description>arXiv:2510.21589v1 Announce Type: cross 
Abstract: The model of relative-error property testing of Boolean functions has been the subject of significant recent research effort [CDH+24][CPPS25a][CPPS25b] In this paper we consider the problem of relative-error testing an unknown and arbitrary $f: \{0,1\}^n \to \{0,1\}$ for the property of being a unate function, i.e. a function that is either monotone non-increasing or monotone non-decreasing in each of the $n$ input variables.
  Our first result is a one-sided non-adaptive algorithm for this problem that makes $\tilde{O}(\log(N)/\epsilon)$ samples and queries, where $N=|f^{-1}(1)|$ is the number of satisfying assignments of the function that is being tested and the value of $N$ is given as an input parameter to the algorithm.
  Building on this algorithm, we next give a one-sided adaptive algorithm for this problem that does not need to be given the value of $N$ and with high probability makes $\tilde{O}(\log(N)/\epsilon)$ samples and queries.
  We also give lower bounds for both adaptive and non-adaptive two-sided algorithms that are given the value of $N$ up to a constant multiplicative factor. In the non-adaptive case, our lower bounds essentially match the complexity of the algorithm that we provide.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21589v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Chen, Diptaksho Palit, Kabir Peshawaria, William Pires, Rocco A. Servedio, Yiding Zhang</dc:creator>
    </item>
    <item>
      <title>Approximate counting of permutation patterns</title>
      <link>https://arxiv.org/abs/2411.04718</link>
      <description>arXiv:2411.04718v3 Announce Type: replace 
Abstract: We consider the problem of counting the copies of a length-$k$ pattern $\sigma$ in a sequence $f \colon [n] \to \mathbb{R}$, where a copy is a subset of indices $i_1 &lt; \ldots &lt; i_k \in [n]$ such that $f(i_j) &lt; f(i_\ell)$ if and only if $\sigma(j) &lt; \sigma(\ell)$. This problem is motivated by a range of connections and applications in ranking, nonparametric statistics, combinatorics, and fine-grained complexity, especially when $k$ is a small fixed constant.
  Recent advances have significantly improved our understanding of counting and detecting patterns. Guillemot and Marx [2014] obtained an $O(n)$ time algorithm for the detection variant for any fixed $k$. Their proof has laid the foundations for the discovery of the twin-width, a concept that has notably advanced parameterized complexity in recent years. Counting, in contrast, is harder: it has a conditional lower bound of $n^{\Omega(k / \log k)}$ [Berendsohn, Kozma, and Marx, 2019] and is expected to be polynomially harder than detection as early as $k = 4$, given its equivalence to counting $4$-cycles in graphs [Dudek and Gawrychowski, 2020].
  In this work, we design a deterministic near-linear time $(1+\varepsilon)$-approximation algorithm for counting $\sigma$-copies in $f$ for all $k \leq 5$. Combined with the conditional lower bound for $k=4$, this establishes the first known separation between approximate and exact pattern counting. Interestingly, while neither the sequence $f$ nor the pattern $\sigma$ are monotone, our algorithm makes extensive use of coresets for monotone functions [Har-Peled, 2006]. Along the way, we develop a near-optimal data structure for $(1+\varepsilon)$-approximate increasing pair range queries in the plane, which exhibits a conditional separation from the exact case and may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04718v3</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Omri Ben-Eliezer, Slobodan Mitrovi\'c, Pranjal Srivastava</dc:creator>
    </item>
    <item>
      <title>Overcomplete Tensor Decomposition via Koszul-Young Flattenings</title>
      <link>https://arxiv.org/abs/2411.14344</link>
      <description>arXiv:2411.14344v2 Announce Type: replace 
Abstract: Motivated by connections between algebraic complexity lower bounds and tensor decompositions, we investigate Koszul-Young flattenings, which are the main ingredient in recent lower bounds for matrix multiplication. Based on this tool we give a new algorithm for decomposing an $n_1 \times n_2 \times n_3$ tensor as the sum of a minimal number of rank-1 terms, and certifying uniqueness of this decomposition. For $n_1 \le n_2 \le n_3$ with $n_1 \to \infty$ and $n_3/n_2 = O(1)$, our algorithm is guaranteed to succeed when the tensor rank is bounded by $r \le (1-\epsilon)(n_2 + n_3)$ for an arbitrary $\epsilon &gt; 0$, provided the tensor components are generically chosen. For any fixed $\epsilon$, the runtime is polynomial in $n_3$. When $n_2 = n_3 = n$, our condition on the rank gives a factor-of-2 improvement over the classical simultaneous diagonalization algorithm, which requires $r \le n$, and also improves on the recent algorithm of Koiran (2024) which requires $r \le 4n/3$. It also improves on the PhD thesis of Persu (2018) which solves rank detection for $r \leq 3n/2$.
  We complement our upper bounds by showing limitations, in particular that no flattening of the style we consider can surpass rank $n_2 + n_3$. Furthermore, for $n \times n \times n$ tensors, we show that an even more general class of degree-$d$ polynomial flattenings cannot surpass rank $Cn$ for a constant $C = C(d)$. This suggests that for tensor decompositions, the case of generic components may be fundamentally harder than that of random components, where efficient decomposition is possible even in highly overcomplete settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14344v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pravesh K. Kothari, Ankur Moitra, Alexander S. Wein</dc:creator>
    </item>
    <item>
      <title>Global Predecessor Indexing: Avoiding Binary Search in Weighted Job Scheduling</title>
      <link>https://arxiv.org/abs/2506.22922</link>
      <description>arXiv:2506.22922v2 Announce Type: replace 
Abstract: We present an improved solution to the Weighted Job Scheduling (WJS) problem. While the classical dynamic programming (DP) solution for $n$ jobs runs in $O(n \log(n))$ time due to comparison-based sorting and per-job binary search, we eliminate the binary search bottleneck. In its place, we introduce a novel multi-phase preprocessing technique called \emph{Global Predecessor Indexing (GPI)}, which computes the latest non-overlapping job (i.e., the predecessor) for all jobs via a two-pointer linear-time pass after sorting. This yields a time complexity of $O(S(n) + n)$ where $S(n)$ is the time to sort all jobs. GPI enables direct use in the classical DP recurrence. When combined with linear-time sorting, GPI yields a complete $O(n)$ solution. Even with comparison-based sorting, GPI significantly outperforms the classical solution in practice by avoiding repeated binary searches in favor of the more cache-efficient extra sort and two-pointer pass.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22922v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amit Joshi</dc:creator>
    </item>
    <item>
      <title>The Low-Degree Hardness of Finding Large Independent Sets in Sparse Random Hypergraphs</title>
      <link>https://arxiv.org/abs/2404.03842</link>
      <description>arXiv:2404.03842v3 Announce Type: replace-cross 
Abstract: We study the algorithmic task of finding large independent sets in Erdos-Renyi $r$-uniform hypergraphs on $n$ vertices having average degree $d$. Krivelevich and Sudakov showed that the maximum independent set has density $\left(\frac{r\log d}{(r-1)d}\right)^{1/(r-1)}$. We show that the class of low-degree polynomial algorithms can find independent sets of density $\left(\frac{\log d}{(r-1)d}\right)^{1/(r-1)}$ but no larger. This extends and generalizes earlier results of Gamarnik and Sudan, Rahman and Virag, and Wein on graphs, and answers a question of Bal and Bennett. We conjecture that this statistical-computational gap holds for this problem.
  Additionally, we explore the universality of this gap by examining $r$-partite hypergraphs. A hypergraph $H=(V,E)$ is $r$-partite if there is a partition $V=V_1\cup\cdots\cup V_r$ such that each edge contains exactly one vertex from each set $V_i$. We consider the problem of finding large balanced independent sets (independent sets containing the same number of vertices in each partition) in random $r$-partite hypergraphs with $n$ vertices in each partition and average degree $d$. We prove that the maximum balanced independent set has density $\left(\frac{r\log d}{(r-1)d}\right)^{1/(r-1)}$ asymptotically. Furthermore, we prove an analogous low-degree computational threshold of $\left(\frac{\log d}{(r-1)d}\right)^{1/(r-1)}$. Our results recover and generalize recent work of Perkins and the second author on bipartite graphs.
  While the graph case has been extensively studied, this work is the first to consider statistical-computational gaps of optimization problems on random hypergraphs. Our results suggest that these gaps persist for larger uniformities as well as across many models. A somewhat surprising aspect of the gap for balanced independent sets is that the algorithm achieving the lower bound is a simple degree-1 polynomial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03842v3</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhishek Dhawan, Yuzhou Wang</dc:creator>
    </item>
    <item>
      <title>Learning Linear Attention in Polynomial Time</title>
      <link>https://arxiv.org/abs/2410.10101</link>
      <description>arXiv:2410.10101v4 Announce Type: replace-cross 
Abstract: Previous research has explored the computational expressivity of Transformer models in simulating Boolean circuits or Turing machines. However, the learnability of these simulators from observational data has remained an open question. Our study addresses this gap by providing the first polynomial-time learnability results (specifically strong, agnostic PAC learning) for single-layer Transformers with linear attention. We show that linear attention may be viewed as a linear predictor in a suitably defined RKHS. As a consequence, the problem of learning any linear transformer may be converted into the problem of learning an ordinary linear predictor in an expanded feature space, and any such predictor may be converted back into a multiheaded linear transformer. Moving to generalization, we show how to efficiently identify training datasets for which every empirical risk minimizer is equivalent (up to trivial symmetries) to the linear Transformer that generated the data, thereby guaranteeing the learned model will correctly generalize across all inputs. Finally, we provide examples of computations expressible via linear attention and therefore polynomial-time learnable, including associative memories, finite automata, and a class of Universal Turing Machine (UTMs) with polynomially bounded computation histories. We empirically validate our theoretical findings on three tasks: learning random linear attention networks, key--value associations, and learning to execute finite automata. Our findings bridge a critical gap between theoretical expressivity and learnability of Transformers, and show that flexible and general models of computation are efficiently learnable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10101v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DS</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Morris Yau, Ekin Aky\"urek, Jiayuan Mao, Joshua B. Tenenbaum, Stefanie Jegelka, Jacob Andreas</dc:creator>
    </item>
    <item>
      <title>Improved Regret and Contextual Linear Extension for Pandora's Box and Prophet Inequality</title>
      <link>https://arxiv.org/abs/2505.18828</link>
      <description>arXiv:2505.18828v2 Announce Type: replace-cross 
Abstract: We study the Pandora's Box problem in an online learning setting with semi-bandit feedback. In each round, the learner sequentially pays to open up to $n$ boxes with unknown reward distributions, observes rewards upon opening, and decides when to stop. The utility of the learner is the maximum observed reward minus the cumulative cost of opened boxes, and the goal is to minimize regret defined as the gap between the cumulative expected utility and that of the optimal policy. We propose a new algorithm that achieves $\widetilde{O}(\sqrt{nT})$ regret after $T$ rounds, which improves the $\widetilde{O}(n\sqrt{T})$ bound of Agarwal et al. [2024] and matches the known lower bound up to logarithmic factors. To better capture real-life applications, we then extend our results to a natural but challenging contextual linear setting, where each box's expected reward is linear in some known but time-varying $d$-dimensional context and the noise distribution is fixed over time. We design an algorithm that learns both the linear function and the noise distributions, achieving $\widetilde{O}(nd\sqrt{T})$ regret. Finally, we show that our techniques also apply to the online Prophet Inequality problem, where the learner must decide immediately whether or not to accept a revealed reward. In both non-contextual and contextual settings, our approach achieves similar improvements and regret bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18828v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Mon, 27 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyan Liu, Ziyun Chen, Kun Wang, Haipeng Luo, Lillian J. Ratliff</dc:creator>
    </item>
  </channel>
</rss>
