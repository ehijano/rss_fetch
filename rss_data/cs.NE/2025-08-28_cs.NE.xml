<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 29 Aug 2025 04:00:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Task-Aware Tuning of Time Constants in Spiking Neural Networks for Multimodal Classification</title>
      <link>https://arxiv.org/abs/2508.20121</link>
      <description>arXiv:2508.20121v1 Announce Type: new 
Abstract: Spiking Neural Networks (SNNs) are promising candidates for low-power edge computing in domains such as wearable sensing and time-series analysis. A key neuronal parameter, the leaky time constant (LTC), governs temporal integration of information in Leaky Integrateand-Fire (LIF) neurons, yet its impact on feedforward SNN performance across different data modalities remains underexplored. This study investigates the role of LTC in a temporally adaptive feedforward SNN applied to static image, dynamic image, and biosignal time-series classification. Presented experiments demonstrate that LTCs critically affect inference accuracy, synaptic weight distributions, and firing dynamics. For static and dynamic images, intermediate LTCs yield higher accuracy and compact, centered weight histograms, reflecting stable feature encoding. In time-series tasks, optimal LTCs enhance temporal feature retention and result in broader weight sparsity, allowing for tolerance of LTC variations. The provided results show that inference accuracy peaks at specific LTC ranges, with significant degradation beyond this optimal band due to over-integration or excessive forgetting. Firing rate analysis reveals a strong interplay between LTC, network depth, and energy efficiency, underscoring the importance of balanced spiking activity. These findings reveal that task-specific LTC tuning is essential for efficient spike coding and robust learning. The results provide practical guidelines for hardware-aware SNN optimization and highlight how neuronal time constants can be designed to match task dynamics. This work contributes toward scalable, ultra-lowpower SNN deployment for real-time classification tasks in neuromorphic computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20121v1</guid>
      <category>cs.NE</category>
      <category>cs.SY</category>
      <category>eess.IV</category>
      <category>eess.SY</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chiu-Chang Cheng, Kapil Bhardwaj, Ya-Ning Chang, Sayani Majumdar, Chao-Hung Wang</dc:creator>
    </item>
    <item>
      <title>Spatio-Temporal Pruning for Compressed Spiking Large Language Models</title>
      <link>https://arxiv.org/abs/2508.20122</link>
      <description>arXiv:2508.20122v1 Announce Type: new 
Abstract: Large Language Models (LLMs) present significant challenges for deployment in energy-constrained environments due to their large model sizes and high inference latency. Spiking Neural Networks (SNNs), inspired by the sparse event-driven neural processing and energy-efficient information transmission in the brain, offer a promising alternative for achieving low-power computing. Integrating the event-driven efficiency of spiking neurons with the advanced capabilities of LLMs represents a promising direction for power-efficient LLMs. This work specifically delves into the design of compressed spiking LLMs. Here, we revisit spatial and temporal pruning from the perspective of SNNs and propose a novel spatio-temporal pruning framework for Spiking LLMs to optimize computational efficiency while preserving high performance. Our spatial pruning technique reduces the number of active neurons and attention heads, effectively lowering the computational complexity of the model. Meanwhile, temporal pruning minimizes inference latency by dynamically adjusting the number of timesteps required for different layers. By combining these approaches with other compression techniques, we present the first work in the domain of Spiking LLMs to jointly explore spatial pruning, temporal pruning, extreme quantization and knowledge distillation strategies. Extensive experimental evaluation of our proposed framework for SpikingBERT on the large-scale GLUE benchmark demonstrates the efficacy of our approach in terms of computational operations and inference latency. Our approach offers a compelling solution for real-time, low-power natural language processing applications, making Spiking LLMs more practical for deployment on edge devices and in power-constrained settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20122v1</guid>
      <category>cs.NE</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yi Jiang, Malyaban Bal, Brian Matejek, Susmit Jha, Adam Cobb, Abhronil Sengupta</dc:creator>
    </item>
    <item>
      <title>Particle swarm optimization for online sparse streaming feature selection under uncertainty</title>
      <link>https://arxiv.org/abs/2508.20123</link>
      <description>arXiv:2508.20123v1 Announce Type: new 
Abstract: In real-world applications involving high-dimensional streaming data, online streaming feature selection (OSFS) is widely adopted. Yet, practical deployments frequently face data incompleteness due to sensor failures or technical constraints. While online sparse streaming feature selection (OS2FS) mitigates this issue via latent factor analysis-based imputation, existing methods struggle with uncertain feature-label correlations, leading to inflexible models and degraded performance. To address these gaps, this work proposes POS2FS-an uncertainty-aware online sparse streaming feature selection framework enhanced by particle swarm optimization (PSO). The approach introduces: 1) PSO-driven supervision to reduce uncertainty in feature-label relationships; 2) Three-way decision theory to manage feature fuzziness in supervised learning. Rigorous testing on six real-world datasets confirms POS2FS outperforms conventional OSFS and OS2FS techniques, delivering higher accuracy through more robust feature subset selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20123v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiyang Xu</dc:creator>
    </item>
    <item>
      <title>Improving Liver Disease Diagnosis with SNNDeep: A Custom Spiking Neural Network Using Diverse Learning Algorithms</title>
      <link>https://arxiv.org/abs/2508.20125</link>
      <description>arXiv:2508.20125v1 Announce Type: new 
Abstract: Purpose: Spiking neural networks (SNNs) have recently gained attention as energy-efficient, biologically plausible alternatives to conventional deep learning models. Their application in high-stakes biomedical imaging remains almost entirely unexplored. Methods: This study introduces SNNDeep, the first tailored SNN specifically optimized for binary classification of liver health status from computed tomography (CT) features. To ensure clinical relevance and broad generalizability, the model was developed and evaluated using the Task03\Liver dataset from the Medical Segmentation Decathlon (MSD), a standardized benchmark widely used for assessing performance across diverse medical imaging tasks. We benchmark three fundamentally different learning algorithms, namely Surrogate Gradient Learning, the Tempotron rule, and Bio-Inspired Active Learning across three architectural variants: a fully customized low-level model built from scratch, and two implementations using leading SNN frameworks, i.e., snnTorch and SpikingJelly. Hyperparameter optimization was performed using Optuna. Results: Our results demonstrate that the custom-built SNNDeep consistently outperforms framework-based implementations, achieving a maximum validation accuracy of 98.35%, superior adaptability across learning rules, and significantly reduced training overhead. Conclusion:This study provides the first empirical evidence that low-level, highly tunable SNNs can surpass standard frameworks in medical imaging, especially in data-limited, temporally constrained diagnostic settings, thereby opening a new pathway for neuro-inspired AI in precision medicine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20125v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zofia Rudnicka, Janusz Szczepanski, Agnieszka Pregowska</dc:creator>
    </item>
    <item>
      <title>Ecological Cycle Optimizer: A novel nature-inspired metaheuristic algorithm for global optimization</title>
      <link>https://arxiv.org/abs/2508.20458</link>
      <description>arXiv:2508.20458v1 Announce Type: new 
Abstract: This article proposes the Ecological Cycle Optimizer (ECO), a novel metaheuristic algorithm inspired by energy flow and material cycling in ecosystems. ECO draws an analogy between the dynamic process of solving optimization problems and ecological cycling. Unique update strategies are designed for the producer, consumer and decomposer, aiming to enhance the balance between exploration and exploitation processes. Through these strategies, ECO is able to achieve the global optimum, simulating the evolution of an ecological system toward its optimal state of stability and balance. Moreover, the performance of ECO is evaluated against five highly cited algorithms-CS, HS, PSO, GWO, and WOA-on 23 classical unconstrained optimization problems and 24 constrained optimization problems from IEEE CEC-2006 test suite, verifying its effectiveness in addressing various global optimization tasks. Furthermore, 50 recently developed metaheuristic algorithms are selected to form the algorithm pool, and comprehensive experiments are conducted on IEEE CEC-2014 and CEC-2017 test suites. Among these, five top-performing algorithms, namely ARO, CFOA, CSA, WSO, and INFO, are chosen for an in-depth comparison with the ECO on the IEEE CEC-2020 test suite, verifying the ECO's exceptional optimization performance. Finally, in order to validate the practical applicability of ECO in complex real-world problems, five state-of-the-art algorithms, including NSM-SFS, FDB-SFS, FDB-AGDE, L-SHADE, and LRFDB-COA, along with four best-performing algorithms from the "CEC2020 competition on real-world single objective constrained optimization", namely SASS, sCMAgES, EnMODE, and COLSHADE, are selected for comparative experiments on five engineering problems from CEC-2020-RW test suite (real-world engineering problems), demonstrating that ECO achieves performance comparable to those of advanced algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20458v1</guid>
      <category>cs.NE</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boyu Ma, Jiaxiao Shi, Yiming Ji, Zhengpu Wang</dc:creator>
    </item>
    <item>
      <title>Encoding Tactile Stimuli for Organoid Intelligence in Braille Recognition</title>
      <link>https://arxiv.org/abs/2508.20850</link>
      <description>arXiv:2508.20850v1 Announce Type: new 
Abstract: This study proposes a generalizable encoding strategy that maps tactile sensor data to electrical stimulation patterns, enabling neural organoids to perform an open-loop artificial tactile Braille classification task. Human forebrain organoids cultured on a low-density microelectrode array (MEA) are systematically stimulated to characterize the relationship between electrical stimulation parameters (number of pulse, phase amplitude, phase duration, and trigger delay) and organoid responses, measured as spike activity and spatial displacement of the center of activity. Implemented on event-based tactile inputs recorded from the Evetac sensor, our system achieved an average Braille letter classification accuracy of 61 percent with a single organoid, which increased significantly to 83 percent when responses from a three-organoid ensemble were combined. Additionally, the multi-organoid configuration demonstrated enhanced robustness against various types of artificially introduced noise. This research demonstrates the potential of organoids as low-power, adaptive bio-hybrid computational elements and provides a foundational encoding framework for future scalable bio-hybrid computing architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20850v1</guid>
      <category>cs.NE</category>
      <category>cs.ET</category>
      <category>cs.RO</category>
      <pubDate>Fri, 29 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianyi Liu (School of Engineering Mathematics and Technology, University of Bristol, United Kingdom), Hemma Philamore (School of Engineering Mathematics and Technology, University of Bristol, United Kingdom), Benjamin Ward-Cherrier (School of Engineering Mathematics and Technology, University of Bristol, United Kingdom)</dc:creator>
    </item>
  </channel>
</rss>
