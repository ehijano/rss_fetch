<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 22 Nov 2024 05:00:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Throughput Maximization for Movable Antenna Systems with Movement Delay Consideration</title>
      <link>https://arxiv.org/abs/2411.13785</link>
      <description>arXiv:2411.13785v1 Announce Type: new 
Abstract: In this paper, we model the minimum achievable throughput within a transmission block of restricted duration and aim to maximize it in movable antenna (MA)-enabled multiuser downlink communications. Particularly, we account for the antenna moving delay caused by mechanical movement, which has not been fully considered in previous studies, and reveal the trade-off between the delay and signal-to-interference-plus-noise ratio at users. To this end, we first consider a single-user setup to analyze the necessity of antenna movement. By quantizing the virtual angles of arrival, we derive the requisite region size for antenna moving, design the initial MA position, and elucidate the relationship between quantization resolution and moving region size. Furthermore, an efficient algorithm is developed to optimize MA position via successive convex approximation, which is subsequently extended to the general multiuser setup. Numerical results demonstrate that the proposed algorithms outperform fixed-position antenna schemes and existing ones without consideration of movement delay. Additionally, our algorithms exhibit excellent adaptability and stability across various transmission block durations and moving region sizes, and are robust to different antenna moving speeds. This allows the hardware cost of MA-aided systems to be reduced by employing low rotational speed motors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13785v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Honghao Wang, Qingqing Wu, Ying Gao, Wen Chen, Weidong Mei, Guojie Hu, Lexi Xu</dc:creator>
    </item>
    <item>
      <title>Iterative decoding of short BCH codes and its post-processing</title>
      <link>https://arxiv.org/abs/2411.13876</link>
      <description>arXiv:2411.13876v1 Announce Type: new 
Abstract: Effective iterative decoding of short BCH codes faces two primary challenges: identifying an appropriate parity-check matrix and accelerating decoder convergence. To address these issues, we propose a systematic scheme to derive an optimized parity-check matrix through a heuristic approach. This involves a series of binary sum and row shift operations, resulting in a low-density, quasi-regular column weight distribution with a reduced number of shortest cycles in the underlying redundant Tanner graph. For the revised normalized min-sum decoder, we concurrently integrate three types of random permutations into the alternated messages across iterations, leading to significantly faster convergence compared to existing methods. Furthermore, by utilizing the iterative trajectories of failed normalized min-sum decoding, we enhance the reliability measurement of codeword bits with the assistance of a neural network model from prior work, which accommodates more failures for the post-processing of ordered statistics decoding. Additionally, we report the types of undetected errors for the design of iterative decoders for short BCH codes, which potentially challenge efforts to approach the maximum likelihood limit. Extensive simulations demonstrate that the proposed hybrid framework achieves an attractive balance between performance, latency, and complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13876v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Guangwen Li, Xiao Yu</dc:creator>
    </item>
    <item>
      <title>Sparse Zero Correlation Zone Arrays for Training Design in Spatial Modulation Systems</title>
      <link>https://arxiv.org/abs/2411.13878</link>
      <description>arXiv:2411.13878v1 Announce Type: new 
Abstract: This paper presents a novel training matrix design for spatial modulation (SM) systems, by introducing a new class of two-dimensional (2D) arrays called sparse zero correlation zone (SZCZ) arrays. An SZCZ array is characterized by a majority of zero entries and exhibits the zero periodic auto- and cross-correlation zone properties across any two rows. With these unique properties, we show that SZCZ arrays can be effectively used as training matrices for SM systems. Additionally, direct constructions of SZCZ arrays with large ZCZ widths and controllable sparsity levels based on 2D restricted generalized Boolean functions (RGBFs) are proposed. Compared with existing training schemes, the proposed SZCZ-based training matrices have larger ZCZ widths, thereby offering greater tolerance for delay spread in multipath channels. Simulation results demonstrate that the proposed SZCZ-based training design exhibits superior channel estimation performance over frequency-selective fading channels compared to existing alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13878v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cheng-Yu Pai, Zilong Liu, Chao-Yu Chen</dc:creator>
    </item>
    <item>
      <title>Performance Analysis of STAR-RIS-Assisted Cell-Free Massive MIMO Systems with Electromagnetic Interference and Phase Errors</title>
      <link>https://arxiv.org/abs/2411.14030</link>
      <description>arXiv:2411.14030v1 Announce Type: new 
Abstract: Simultaneous Transmitting and Reflecting Reconfigurable Intelligent Surfaces (STAR-RISs) are being explored for the next generation of sixth-generation (6G) networks. A promising configuration for their deployment is within cell-free massive multiple-input multiple-output (MIMO) systems. However, despite the advantages that STAR-RISs could bring, challenges such as electromagnetic interference (EMI) and phase errors may lead to significant performance degradation. In this paper, we investigate the impact of EMI and phase errors on STAR-RIS-assisted cell-free massive MIMO systems and propose techniques to mitigate these effects. We introduce a novel projected gradient descent (GD) algorithm for STAR-RIS coefficient matrix design by minimizing the local channel estimation normalised mean square error. We also derive the closed-form expressions of the uplink and downlink spectral efficiency (SE) to analyze system performance with EMI and phase errors, in which fractional power control methods are applied for performance improvement. The results reveal that the projected GD algorithm can effectively tackle EMI and phase errors to improve estimation accuracy and compensate for performance degradation with nearly $10\%\sim20\%$ SE improvement. Moreover, increasing access points (APs), antennas per AP, and STAR-RIS elements can also improve SE performance. Applying STAR-RIS in the proposed system achieves a larger $25\%$-likely SE than conventional RISs. However, the advantages of employing more STAR-RIS elements are reduced when EMI is severe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14030v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Qian, Ross Murch, Khaled B. Letaief</dc:creator>
    </item>
    <item>
      <title>Determining the covering radius of all generalized Zetterberg codes in odd characteristic</title>
      <link>https://arxiv.org/abs/2411.14087</link>
      <description>arXiv:2411.14087v1 Announce Type: new 
Abstract: For an integer $s\ge 1$, let $\mathcal{C}_s(q_0)$ be the generalized Zetterberg code of length $q_0^s+1$ over the finite field $\F_{q_0}$ of odd characteristic. Recently, Shi, Helleseth, and \"{O}zbudak (IEEE Trans. Inf. Theory 69(11): 7025-7048, 2023) determined the covering radius of $\mathcal{C}_s(q_0)$ for $q_0^s \not \equiv 7 \pmod{8}$, and left the remaining case as an open problem. In this paper, we develop a general technique involving arithmetic of finite fields and algebraic curves over finite fields to determine the covering radius of all generalized Zetterberg codes for $q_0^s \equiv 7 \pmod{8}$, which therefore solves this open problem. We also introduce the concept of twisted half generalized Zetterberg codes of length $\frac{q_0^s+1}{2}$, and show the same results hold for them. As a result, we obtain some quasi-perfect codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14087v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minjia Shi, Shitao Li, Tor Helleseth, Ferruh Ozbudak</dc:creator>
    </item>
    <item>
      <title>Channel Customization for Low-Complexity CSI Acquisition in Multi-RIS-Assisted MIMO Systems</title>
      <link>https://arxiv.org/abs/2411.14088</link>
      <description>arXiv:2411.14088v1 Announce Type: new 
Abstract: The deployment of multiple reconfigurable intelligent surfaces (RISs) enhances the propagation environment by improving channel quality, but it also complicates channel estimation. Following the conventional wireless communication system design, which involves full channel state information (CSI) acquisition followed by RIS configuration, can reduce transmission efficiency due to substantial pilot overhead and computational complexity. This study introduces an innovative approach that integrates CSI acquisition and RIS configuration, leveraging the channel-altering capabilities of the RIS to reduce both the overhead and complexity of CSI acquisition. The focus is on multi-RIS-assisted systems, featuring both direct and reflected propagation paths. By applying a fast-varying reflection sequence during RIS configuration for channel training, the complex problem of channel estimation is decomposed into simpler, independent tasks. These fast-varying reflections effectively isolate transmit signals from different paths, streamlining the CSI acquisition process for both uplink and downlink communications with reduced complexity. In uplink scenarios, a positioning-based algorithm derives partial CSI, informing the adjustment of RIS parameters to create a sparse reflection channel, enabling precise reconstruction of the uplink channel. Downlink communication benefits from this strategically tailored reflection channel, allowing effective CSI acquisition with fewer pilot signals. Simulation results highlight the proposed methodology's ability to accurately reconstruct the reflection channel with minimal impact on the normalized mean square error while simultaneously enhancing spectral efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14088v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weicong Chen, Yu Han, Chao-Kai Wen, Xiao Li, Shi Jin</dc:creator>
    </item>
    <item>
      <title>Multi-terminal Strong Coordination subject to Secrecy Constraints</title>
      <link>https://arxiv.org/abs/2411.14123</link>
      <description>arXiv:2411.14123v1 Announce Type: new 
Abstract: A fundamental problem in decentralized networked systems is to coordinate actions of different agents so that they reach a state of agreement. In such applications, it is additionally desirable that the actions at various nodes may not be anticipated by malicious eavesdroppers. Motivated by this, we investigate the problem of secure multi-terminal strong coordination aided by a multiple-access wiretap channel. In this setup, independent and identically distributed copies of correlated sources are observed by two transmitters who encode the channel inputs to the MAC-WT. The legitimate receiver observing the channel output and side information correlated with the sources must produce approximately i.i.d. copies of an output variable jointly distributed with the sources. Furthermore, we demand that an external eavesdropper learns essentially nothin g about the sources and the simulated output sequence by observing its own MAC-WT output. This setting is aided by the presence of independent pairwise shared randomness between each encoder and the legitimate decoder, that is unavailable to the eavesdropper. We derive an achievable rate region based on a combination of coordination coding and wiretap coding, along with an outer bound. The inner bound is shown to be tight and a complete characterization is derived for the special case when the sources are conditionally independent given the decoder side information and the legitimate channel is composed of deterministic links. Further, we also analyze a more general scenario with possible encoder cooperation, where one of the encoders can non-causally crib from the other encoders input, for which an achievable rate region is proposed. We then explicitly compute the rate regions for an example both with and without cribbing between the encoders, and demonstrate that cribbing strictly improves upon the achievable rate region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14123v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viswanathan Ramachandran, Tobias J. Oechtering, Mikael Skoglund</dc:creator>
    </item>
    <item>
      <title>Schr\"odinger Bridge Problem for Jump Diffusions</title>
      <link>https://arxiv.org/abs/2411.13765</link>
      <description>arXiv:2411.13765v1 Announce Type: cross 
Abstract: The Schr\"odinger bridge problem (SBP) seeks to find the measure $\hat{\mathbf{P}}$ on a certain path space which interpolates between state-space distributions $\rho_0$ at time $0$ and $\rho_T$ at time $T$ while minimizing the KL divergence (relative entropy) to a reference path measure $\mathbf{R}$. In this work, we tackle the SBP in the case when $\mathbf{R}$ is the path measure of a jump diffusion. Under mild assumptions, with both the operator theory approach and the stochastic calculus techniques, we establish an $h$-transform theory for jump diffusions and devise an approximation method to achieve the jump-diffusion SBP solution $\hat{\mathbf{P}}$ as the strong-convergence limit of a sequence of harmonic $h$-transforms. To the best of our knowledge, these results are novel in the study of SBP. Moreover, the $h$-transform framework and the approximation method developed in this work are robust and applicable to a relatively general class of jump diffusions. In addition, we examine the SBP of particular types of jump diffusions under additional regularity conditions and extend the existing results on the SBP from the diffusion case to the jump-diffusion setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13765v1</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrei Zlotchevski, Linan Chen</dc:creator>
    </item>
    <item>
      <title>Exponentially Consistent Nonparametric Clustering of Data Streams</title>
      <link>https://arxiv.org/abs/2411.13922</link>
      <description>arXiv:2411.13922v1 Announce Type: cross 
Abstract: In this paper, we consider nonparametric clustering of $M$ independent and identically distributed (i.i.d.) data streams generated from unknown distributions. The distributions of the $M$ data streams belong to $K$ underlying distribution clusters. Existing results on exponentially consistent nonparametric clustering algorithms, like single linkage-based (SLINK) clustering and $k$-medoids distribution clustering, assume that the maximum intra-cluster distance ($d_L$) is smaller than the minimum inter-cluster distance ($d_H$). First, in the fixed sample size (FSS) setting, we show that exponential consistency can be achieved for SLINK clustering under a less strict assumption, $d_I &lt; d_H$, where $d_I$ is the maximum distance between any two sub-clusters of a cluster that partition the cluster. Note that $d_I &lt; d_L$ in general. Our results show that SLINK is exponentially consistent for a larger class of problems than $k$-medoids distribution clustering. We also identify examples where $k$-medoids clustering is unable to find the true clusters, but SLINK is exponentially consistent. Then, we propose a sequential clustering algorithm, named SLINK-SEQ, based on SLINK and prove that it is also exponentially consistent. Simulation results show that the SLINK-SEQ algorithm requires fewer expected number of samples than the FSS SLINK algorithm for the same probability of error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13922v1</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bhupender Singh, Ananth Ram Rajagopalan, Srikrishna Bhashyam</dc:creator>
    </item>
    <item>
      <title>A $k^{\frac{q}{q-2}}$ Lower Bound for Odd Query Locally Decodable Codes from Bipartite Kikuchi Graphs</title>
      <link>https://arxiv.org/abs/2411.14276</link>
      <description>arXiv:2411.14276v1 Announce Type: cross 
Abstract: A code $C \colon \{0,1\}^k \to \{0,1\}^n$ is a $q$-query locally decodable code ($q$-LDC) if one can recover any chosen bit $b_i$ of the message $b \in \{0,1\}^k$ with good confidence by querying a corrupted string $\tilde{x}$ of the codeword $x = C(b)$ in at most $q$ coordinates. For $2$ queries, the Hadamard code is a $2$-LDC of length $n = 2^k$, and this code is in fact essentially optimal. For $q \geq 3$, there is a large gap in our understanding: the best constructions achieve $n = \exp(k^{o(1)})$, while prior to the recent work of [AGKM23], the best lower bounds were $n \geq \tilde{\Omega}(k^{\frac{q}{q-2}})$ for $q$ even and $n \geq \tilde{\Omega}(k^{\frac{q+1}{q-1}})$ for $q$ odd.
  The recent work of [AGKM23] used spectral methods to prove a lower bound of $n \geq \tilde{\Omega}(k^3)$ for $q = 3$, thus achieving the "$k^{\frac{q}{q-2}}$ bound" for an odd value of $q$. However, their proof does not extend to any odd $q \geq 5$. In this paper, we prove a $q$-LDC lower bound of $n \geq \tilde{\Omega}(k^{\frac{q}{q-2}})$ for any odd $q$. Our key technical idea is the use of an imbalanced bipartite Kikuchi graph, which gives a simpler method to analyze spectral refutations of odd arity XOR without using the standard "Cauchy-Schwarz trick", a trick that typically produces random matrices with correlated entries and makes the analysis for odd arity XOR significantly more complicated than even arity XOR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14276v1</guid>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oliver Janzer, Peter Manohar</dc:creator>
    </item>
    <item>
      <title>Hypothesis testing of symmetry in quantum dynamics</title>
      <link>https://arxiv.org/abs/2411.14292</link>
      <description>arXiv:2411.14292v1 Announce Type: cross 
Abstract: Symmetry plays a crucial role in quantum physics, dictating the behavior and dynamics of physical systems. In this paper, We develop a hypothesis-testing framework for quantum dynamics symmetry using a limited number of queries to the unknown unitary operation and establish the quantum max-relative entropy lower bound for the type-II error. We construct optimal ancilla-free protocols that achieve optimal type-II error probability for testing time-reversal symmetry (T-symmetry) and diagonal symmetry (Z-symmetry) with limited queries. Contrasting with the advantages of indefinite causal order strategies in various quantum information processing tasks, we show that parallel, adaptive, and indefinite causal order strategies have equal power for our tasks. We establish optimal protocols for T-symmetry testing and Z-symmetry testing for 6 and 5 queries, respectively, from which we infer that the type-II error exhibits a decay rate of $\mathcal{O}(m^{-2})$ with respect to the number of queries $m$. This represents a significant improvement over the basic repetition protocols without using global entanglement, where the error decays at a slower rate of $\mathcal{O}(m^{-1})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14292v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu-Ao Chen, Chenghong Zhu, Keming He, Yingjian Liu, Xin Wang</dc:creator>
    </item>
    <item>
      <title>Learning Fair Robustness via Domain Mixup</title>
      <link>https://arxiv.org/abs/2411.14424</link>
      <description>arXiv:2411.14424v1 Announce Type: cross 
Abstract: Adversarial training is one of the predominant techniques for training classifiers that are robust to adversarial attacks. Recent work, however has found that adversarial training, which makes the overall classifier robust, it does not necessarily provide equal amount of robustness for all classes. In this paper, we propose the use of mixup for the problem of learning fair robust classifiers, which can provide similar robustness across all classes. Specifically, the idea is to mix inputs from the same classes and perform adversarial training on mixed up inputs. We present a theoretical analysis of this idea for the case of linear classifiers and show that mixup combined with adversarial training can provably reduce the class-wise robustness disparity. This method not only contributes to reducing the disparity in class-wise adversarial risk, but also the class-wise natural risk. Complementing our theoretical analysis, we also provide experimental results on both synthetic data and the real world dataset (CIFAR-10), which shows improvement in class wise disparities for both natural and adversarial risks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14424v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meiyu Zhong, Ravi Tandon</dc:creator>
    </item>
    <item>
      <title>Full Duplex Joint Communications and Sensing for 6G: Opportunities and Challenges</title>
      <link>https://arxiv.org/abs/2308.07266</link>
      <description>arXiv:2308.07266v2 Announce Type: replace 
Abstract: The paradigm of joint communications and sensing (JCAS) envisions a revolutionary integration of communication and radar functionalities within a unified hardware platform. This novel concept not only opens up unprecedented interoperability opportunities, but also exhibits unique design challenges. To this end, the success of JCAS is highly dependent on efficient full-duplex (FD) operation, which has the potential to enable simultaneous transmission and reception within the same frequency band. While JCAS research is lately expanding, there still exist relevant directions of investigation that hold tremendous potential to profoundly transform the sixth generation (6G), and beyond, cellular networks. This article presents new opportunities and challenges brought up by FD-enabled JCAS, taking into account the key technical peculiarities of FD systems. Unlike simplified JCAS scenarios, we delve into the most comprehensive configuration, encompassing uplink and downlink users, as well as monostatic and bistatic radars, all harmoniously coexisting to jointly push the boundaries of both communications and sensing. The performance improvements resulting from this advancement bring forth numerous new challenges, each meticulously examined and expounded upon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07266v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chandan Kumar Sheemar, Sourabh Solanki, George C. Alexandropoulos, Eva Lagunas, Jorge Querol, Symeon Chatzinotas, Bj\"orn Ottersten</dc:creator>
    </item>
    <item>
      <title>Wireless 6G Connectivity for Massive Number of Devices and Critical Services</title>
      <link>https://arxiv.org/abs/2401.01127</link>
      <description>arXiv:2401.01127v5 Announce Type: replace 
Abstract: Compared to the generations up to 4G, whose main focus was on broadband and coverage aspects, 5G has expanded the scope of wireless cellular systems towards embracing two new types of connectivity: massive machine-type communication (mMTC) and ultra-reliable low-latency communications (URLLC). This paper discusses the possible evolution of these two types of connectivity within the umbrella of 6G wireless systems. The paper consists of three parts. The first part deals with the connectivity for a massive number of devices. While mMTC research in 5G predominantly focuses on the problem of uncoordinated access in the uplink for a large number of devices, the traffic patterns in 6G may become more symmetric, leading to closed-loop massive connectivity. One of the drivers for this is distributed learning/inference. The second part of the paper discusses the evolution of wireless connectivity for critical services. While latency and reliability are tightly coupled in 5G, 6G will support a variety of safety critical control applications with different types of timing requirements, as evidenced by the emergence of metrics related to information freshness and information value. Additionally, ensuring ultra-high reliability for safety critical control applications requires modeling and estimation of the tail statistics of the wireless channel, queue length, and delay. The fulfillment of these stringent requirements calls for the development of novel AI-based techniques, incorporating optimization theory, explainable AI, generative AI and digital twins. The third part analyzes the coexistence of massive connectivity and critical services. We will consider scenarios in which a massive number of devices need to support traffic patterns of mixed criticality. This is followed by a discussion about the management of wireless resources shared by services with different criticality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01127v5</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/JPROC.2024.3484529</arxiv:DOI>
      <dc:creator>Anders E. Kal{\o}r, Giuseppe Durisi, Sinem Coleri, Stefan Parkvall, Wei Yu, Andreas Mueller, Petar Popovski</dc:creator>
    </item>
    <item>
      <title>Towards a Theory of Pragmatic Information</title>
      <link>https://arxiv.org/abs/2403.12324</link>
      <description>arXiv:2403.12324v5 Announce Type: replace 
Abstract: Standard information theory says nothing about how much meaning is conveyed by a message. We fill this gap with a rigorously justifiable, quantitative definition of ``pragmatic information'', the amount of meaning in a message relevant to a particular decision. We posit that such a message updates a random variable, $\omega$, that informs the decision. The pragmatic information of a single message is then defined as the Kulbach-Leibler divergence between the apriori and aposteriori probabilities of $\omega$; the pragmatic information of a message ensemble is the expected value of the pragmatic information of the ensemble's component messages. We justify these definitions by proving that the pragmatic information of a single message is the expected difference between the shortest binary encoding of $\omega$ under the a priori and a posteriori distributions, and that the average of the pragmatic values of individual messages, when sampled a large number of times from the ensemble, approaches its expected value.
  Pragmatic information is non-negative and additive for independent decisions and ``pragmatically independent'' messages. Also, pragmatic information is the information analogue of free energy: just as free energy quantifies the part of a system's total energy available to do useful work, so pragmatic information quantifies the information actually used in making a decision.
  We sketch 3 applications: the single play of a slot machine, a.k.a. a ``one armed bandit'', with an unknown payout probability; a characterization of the rate of biological evolution in the so-called ``quasi-species'' model; and a reformulation of the efficient market hypothesis of finance. We note the importance of the computational capacity of the receiver in each case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12324v5</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edward D. Weinberger</dc:creator>
    </item>
    <item>
      <title>Perfect Subset Privacy in Polynomial Computation via Reed-Muller Information Super-sets</title>
      <link>https://arxiv.org/abs/2405.05567</link>
      <description>arXiv:2405.05567v2 Announce Type: replace 
Abstract: Delegating large-scale computations to service providers is a common practice which raises privacy concerns. This paper studies information-theoretic privacy-preserving delegation of data to a service provider, who may further delegate the computation to auxiliary worker nodes, in order to compute a polynomial over that data at a later point in time. We study techniques which are compatible with robust management of distributed computation systems, an area known as coded computing. Privacy in coded computing, however, has traditionally addressed the problem of colluding workers, and assumed that the server that administrates the computation is trusted. This viewpoint of privacy does not accurately reflect real-world privacy concerns, since normally, the service provider as a whole (i.e., the administrator and the worker nodes) form one cohesive entity which itself poses a privacy risk. This paper aims to shift the focus of privacy in coded computing to safeguarding the privacy of the user against the service provider as a whole, instead of merely against colluding workers inside the service provider. To this end, we leverage the recently defined notion of perfect subset privacy, which guarantees zero information leakage from all subsets of the data up to a certain size. Using known techniques from Reed-Muller decoding, we provide a scheme which enables polynomial computation with perfect subset privacy in straggler-free systems. Furthermore, by studying information super-sets in Reed-Muller codes, which may be of independent interest, we extend the previous scheme to tolerate straggling worker nodes inside the service provider.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05567v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zirui Deng, Vinayak Ramkumar, Netanel Raviv</dc:creator>
    </item>
    <item>
      <title>Fluid Antenna Multiple Access Assisted Integrated Data and Energy Transfer: Outage and Multiplexing Gain Analysis</title>
      <link>https://arxiv.org/abs/2407.10548</link>
      <description>arXiv:2407.10548v3 Announce Type: replace 
Abstract: Fluid antenna multiple access (FAMA) exploits the spatial opportunities in wireless channels to overcome multiuser interference by position (a.k.a.~port) switching, which can achieve better performance compared to traditional fixed multiple-input multiple-output (MIMO) systems. Additionally, integrated data and energy transfer (IDET) is capable of providing both wireless data transfer (WDT) and wireless energy transfer (WET) services towards low-power devices. In this paper, a FAMA-assisted IDET system is investigated, where a base station (BS) equipped with $N$ fixed antennas provides dedicated IDET services towards $N$ user equipments (UEs). Each UE is equipped with a single fluid antenna, while the power splitting (PS) approach is conceived for coordinating WDT and WET. The outage probabilities of both WDT and WET are derived and approximated into closed-forms, where the fluid antenna (FA) at each UE selects the optimal port to achieve the maximum signal-to-interference-plus-noise ratio (SINR) or the energy harvesting power (EHP). The IDET outage probabilities are defined and subsequently derived and approximated into closed-forms. Further, multiplexing gains of the proposed system are defined and analyzed to evaluate the performace. Numerical results validate the theoretical analysis, while also illustrate that the trade-off is achieved between WDT and WET performance by exploiting different port selection strategies. Furthermore, the number of UEs should be optimized to achieve better IDET performance of the system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10548v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao Lin, Yizhe Zhao, Halvin Yang, Jie Hu, Kai-Kit Wong</dc:creator>
    </item>
    <item>
      <title>Puncturing Quantum Stabilizer Codes</title>
      <link>https://arxiv.org/abs/2410.17754</link>
      <description>arXiv:2410.17754v2 Announce Type: replace 
Abstract: Classical coding theory contains several techniques to obtain new codes from other codes, including puncturing and shortening. For quantum codes, a form of puncturing is known, but its description is based on the code space rather than its generators. In this work, we generalize the puncturing procedure to allow more freedom in the choice of which coded states are kept and which are removed. We describe this puncturing by focusing on the stabilizer matrix containing the generators of the code. In this way, we are able to explicitly describe the stabilizer matrix of the punctured code given the stabilizer matrix of the original stabilizer code. The additional freedom in the procedure also opens up new ways to construct new codes from old, and we present several ways to utilize this for the search of codes with good or even optimal parameters. In particular, we use the construction to obtain codes whose parameters exceed the best previously known. Lastly, we generalize the proof of the Griesmer bound from the classical setting to stabilizer codes since the proof relies heavily on the puncturing technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17754v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.RA</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaron Skovsted Gundersen, Ren\'e B{\o}dker Christensen, Markus Grassl, Petar Popovski, Rafa{\l} Wisniewski</dc:creator>
    </item>
    <item>
      <title>GRAMEP: an alignment-free method based on the Maximum Entropy Principle for identifying SNPs</title>
      <link>https://arxiv.org/abs/2405.01715</link>
      <description>arXiv:2405.01715v2 Announce Type: replace-cross 
Abstract: Background: Advances in high throughput sequencing technologies provide a huge number of genomes to be analyzed. Thus, computational methods play a crucial role in analyzing and extracting knowledge from the data generated. Investigating genomic mutations is critical because of their impact on chromosomal evolution, genetic disorders, and diseases. It is common to adopt aligning sequences for analyzing genomic variations. However, this approach can be computationally expensive and restrictive in scenarios with large datasets. Results: We present a novel method for identifying single nucleotide polymorphisms (SNPs) in DNA sequences from assembled genomes. This study proposes GRAMEP, an alignment-free approach that adopts the principle of maximum entropy to discover the most informative k-mers specific to a genome or set of sequences under investigation. The informative k-mers enable the detection of variant-specific mutations in comparison to a reference genome or other set of sequences. In addition, our method offers the possibility of classifying novel sequences with no need for organism-specific information. GRAMEP demonstrated high accuracy in both in silico simulations and analyses of viral genomes, including Dengue, HIV, and SARS-CoV-2. Our approach maintained accurate SARS-CoV-2 variant identification while demonstrating a lower computational cost compared to methods with the same purpose. Conclusions: GRAMEP is an open and user-friendly software based on maximum entropy that provides an efficient alignment-free approach to identifying and classifying unique genomic subsequences and SNPs with high accuracy, offering advantages over comparative methods. The instructions for use, applicability, and usability of GRAMEP are open access at https://github.com/omatheuspimenta/GRAMEP</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01715v2</guid>
      <category>q-bio.GN</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Matheus Henrique Pimenta-Zanon, Andr\'e Yoshiaki Kashiwabara, Andr\'e Lu\'is Laforga Vanzela, Fabricio Martins Lopes</dc:creator>
    </item>
    <item>
      <title>Coprime Bivariate Bicycle Codes</title>
      <link>https://arxiv.org/abs/2408.10001</link>
      <description>arXiv:2408.10001v3 Announce Type: replace-cross 
Abstract: This work (1) proposes a novel numerical algorithm to accelerate the search process for good Bivariate Bicycle (BB) codes and (2) defines a new subclass of BB codes suitable for quantum error correction. The proposed acceleration search algorithm reduces the search space by excluding some equivalent codes from the search space, as well as setting thresholds to drop bad codes at an early stage. A number of new BB codes found by this algorithm are reported. The proposed subclass of BB codes employs coprimes to construct groups via polynomials as the basis for the BB code, rather than using the standard BB codes with unconstrained constructors. In contrast to vanilla BB codes, where parameters remain unknown prior to code discovery, the rate of the proposed code can be determined beforehand by specifying a factor polynomial as an input to the numerical search algorithm. Using this coprime BB construction, we found a number of surprisingly short to medium-length codes that were previously unknown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10001v3</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ming Wang, Frank Mueller</dc:creator>
    </item>
    <item>
      <title>High-distance codes with transversal Clifford and T-gates</title>
      <link>https://arxiv.org/abs/2408.12752</link>
      <description>arXiv:2408.12752v2 Announce Type: replace-cross 
Abstract: The non-local interactions in several quantum devices allow for the realization of more compact quantum encodings while retaining the same degree of protection against noise. Anticipating that short to medium-length codes will soon be realizable, it is important to construct stabilizer codes that, for a given code distance, admit fault-tolerant implementations of logical gates with the fewest number of physical qubits. We extract high-distance doubly even codes from the quantum quadratic-residue code family that admit a transversal implementation of the single-qubit Clifford group and block transversal implementation of the full Clifford group. Applying a doubling procedure [arXiv:1509.03239] to such codes yields a family of high-distance weak triply even codes which admit a transversal implementation of the logical $\texttt{T}$-gate. Relaxing the triply even property, we also obtain a family of triorthogonal codes which requires an even lower overhead at the cost of additional Clifford gates to achieve the same logical operation. To our knowledge, our doubly even and triorthogonal families are the shortest qubit stabilizer codes of the same distance that can realize their respective gates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12752v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.NT</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shubham P. Jain, Victor V. Albert</dc:creator>
    </item>
    <item>
      <title>Refining Ky Fan's majorization relation with linear programming</title>
      <link>https://arxiv.org/abs/2410.18254</link>
      <description>arXiv:2410.18254v2 Announce Type: replace-cross 
Abstract: A separable version of Ky Fan's majorization relation is proven for a sum of two operators that are each a tensor product of two positive semi-definite operators. In order to prove it, upper bounds are established for the relevant largest eigenvalue sums in terms of the optimal values of certain linear programs. The objective function of these linear programs is the dual of the direct sum of the spectra of the summands. The feasible sets are bounded polyhedra determined by positive numbers, called alignment terms, that quantify the overlaps between pairs of largest eigenvalue spaces of the summands. By appealing to geometric considerations, tight upper bounds are established on the alignment terms of tensor products of positive semi-definite operators. As an application, the spin alignment conjecture in quantum information theory is affirmatively resolved to the 2-letter level. Consequently, the coherent information of platypus channels is additive to the 2-letter level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18254v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.RA</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad A. Alhejji</dc:creator>
    </item>
    <item>
      <title>Learning multivariate Gaussians with imperfect advice</title>
      <link>https://arxiv.org/abs/2411.12700</link>
      <description>arXiv:2411.12700v2 Announce Type: replace-cross 
Abstract: We revisit the problem of distribution learning within the framework of learning-augmented algorithms. In this setting, we explore the scenario where a probability distribution is provided as potentially inaccurate advice on the true, unknown distribution. Our objective is to develop learning algorithms whose sample complexity decreases as the quality of the advice improves, thereby surpassing standard learning lower bounds when the advice is sufficiently accurate.
  Specifically, we demonstrate that this outcome is achievable for the problem of learning a multivariate Gaussian distribution $N(\boldsymbol{\mu}, \boldsymbol{\Sigma})$ in the PAC learning setting. Classically, in the advice-free setting, $\tilde{\Theta}(d^2/\varepsilon^2)$ samples are sufficient and worst case necessary to learn $d$-dimensional Gaussians up to TV distance $\varepsilon$ with constant probability. When we are additionally given a parameter $\tilde{\boldsymbol{\Sigma}}$ as advice, we show that $\tilde{O}(d^{2-\beta}/\varepsilon^2)$ samples suffices whenever $\| \tilde{\boldsymbol{\Sigma}}^{-1/2} \boldsymbol{\Sigma} \tilde{\boldsymbol{\Sigma}}^{-1/2} - \boldsymbol{I_d} \|_1 \leq \varepsilon d^{1-\beta}$ (where $\|\cdot\|_1$ denotes the entrywise $\ell_1$ norm) for any $\beta &gt; 0$, yielding a polynomial improvement over the advice-free setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12700v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Fri, 22 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnab Bhattacharyya, Davin Choo, Philips George John, Themis Gouleakis</dc:creator>
    </item>
  </channel>
</rss>
