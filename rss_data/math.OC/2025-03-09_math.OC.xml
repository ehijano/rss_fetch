<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 10 Mar 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Extended Version: Non-Preemptive Scheduling of Flexible Loads in Smart Grids via Convex Optimization</title>
      <link>https://arxiv.org/abs/2503.04909</link>
      <description>arXiv:2503.04909v1 Announce Type: new 
Abstract: This paper studies the scheduling of a large population of non-preemptive flexible electric loads, each of which has a flexible starting time but once started will follow a fixed load shape until completion. We first formulate the scheduling problem as a mixed-integer convex program (MICP), then propose an efficient polynomial time relaxation-adjustment-rounding algorithm for solving the problem. The key novelty of the proposed method lies in its adjustment step, which uses a graph-based algorithm to navigate within the set of optimal points of the convex relaxation while reducing the number of fractional entries in the solution. We establish mathematically that our algorithm yields solutions that are near optimal for a finite number of loads and with its sub-optimality independent of the number of loads. Consequently, the proposed method is asymptotically optimal in a per-load cost sense when the number of loads increases. Despite the gap between the MICP and its convex relaxation, we establish that the solution of the proposed algorithm can be decentralized by marginal prices of the convex relaxation. We also develop and analyze variants of the proposed algorithm for settings with uncertainty and with time-varying realistic load shapes. Finally, we numerically evaluate the proposed algorithm in a case study for the non-preemptive scheduling of electric vehicles charging loads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04909v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mehdi Davoudi, Mingyu Chen, Junjie Qin</dc:creator>
    </item>
    <item>
      <title>SPDE Games Driven by a Brownian Sheet with Applications to Pollution Minimization</title>
      <link>https://arxiv.org/abs/2503.04993</link>
      <description>arXiv:2503.04993v1 Announce Type: new 
Abstract: This paper studies a nonzero-sum stochastic differential game in the context of shared spatial-domain pollution control. The pollution dynamics are governed by a stochastic partial differential equation (SPDE) driven by a Brownian sheet, capturing the stochastic nature of environmental fluctuations. Two players, representing different regions, aim to minimize their respective cost functionals, which balance pollution penalties with the cost of implementing control strategies.
  The nonzero-sum framework reflects the interdependent yet conflicting objectives of the players, where both cooperation and competition influence the outcomes. We derive necessary and sufficient conditions for Nash equilibrium strategies, using a maximum principle approach. This approach involves the introduction of a new pair of adjoint variables, (L_1, L_2), which do not appear in a corresponding formulation with the classical (1-parameter) Brownian motion.
  Finally, we apply our results to two case studies in pollution control, demonstrating how spatial and stochastic dynamics shape the equilibrium strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04993v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nacira Agram, Bernt {\O}ksendal, Frank Proske, Olena Tymoshenko</dc:creator>
    </item>
    <item>
      <title>Self-Supervised Penalty-Based Learning for Robust Constrained Optimization</title>
      <link>https://arxiv.org/abs/2503.05175</link>
      <description>arXiv:2503.05175v1 Announce Type: new 
Abstract: We propose a new methodology for parameterized constrained robust optimization, an important class of optimization problems under uncertainty, based on learning with a self-supervised penalty-based loss function. Whereas supervised learning requires pre-solved instances for training, our approach leverages a custom loss function derived from the exact penalty method in optimization to learn an approximation, typically defined by a neural network model, of the parameterized optimal solution mapping. Additionally, we adapt our approach to robust constrained combinatorial optimization problems by incorporating a surrogate linear cost over mixed integer domains, and a smooth approximations thereof, into the final layer of the network architecture. We perform computational experiments to test our approach on three different applications: multidimensional knapsack with continuous variables, combinatorial multidimensional knapsack with discrete variables, and an inventory management problem. Our results demonstrate that our self-supervised approach is able to effectively learn neural network approximations whose inference time is significantly smaller than the computation time of traditional solvers for this class of robust optimization problems. Furthermore, our results demonstrate that by varying the penalty parameter we are able to effectively balance the trade-off between sub-optimality and robust feasibility of the obtained solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05175v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wyame Benslimane, Paul Grigas</dc:creator>
    </item>
    <item>
      <title>A Gap Penalty Reformulation for Mathematical Programming with Complementarity Constraints: Convergence Analysis</title>
      <link>https://arxiv.org/abs/2503.05181</link>
      <description>arXiv:2503.05181v1 Announce Type: new 
Abstract: Our recent study [1] proposed a new penalty method to solve the mathematical programming with complementarity constraints (MPCC). This method reformulates the MPCC as a parameterized nonlinear programming (NLP) called gap penalty reformulation and solves a sequence of gap penalty reformulations with an increasing penalty parameter. This letter studies the convergence behavior of the new penalty method. We prove that it converges to a strongly stationary point of MPCC, provided that: (1) The MPCC linear independence constraint qualification holds; (2) The upper-level strict complementarity condition holds; (3) The gap penalty reformulation satisfies the second-order necessary conditions in terms of the second-order directional derivative. Since the strong stationarity is used to identify the local minimum of MPCC, our convergence analysis indicates that the new penalty method is capable of finding an MPCC solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05181v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kangyu Lin, Toshiyuki Ohtsuka</dc:creator>
    </item>
    <item>
      <title>Constrained Reinforcement Learning for the Dynamic Inventory Routing Problem under Stochastic Supply and Demand</title>
      <link>https://arxiv.org/abs/2503.05276</link>
      <description>arXiv:2503.05276v1 Announce Type: new 
Abstract: Green hydrogen has multiple use cases and is produced from renewable energy, such as solar or wind energy. It can be stored in large quantities, decoupling renewable energy generation from its use, and is therefore considered essential for achieving a climate-neutral economy. The intermittency of renewable energy generation and the stochastic nature of demand are, however, challenging factors for the dynamic planning of hydrogen storage and transportation. This holds particularly in the early-adoption phase when hydrogen distribution occurs through vehicle-based networks. We therefore address the Dynamic Inventory Routing Problem (DIRP) under stochastic supply and demand with direct deliveries for the vehicle-based distribution of hydrogen. To solve this problem, we propose a Constrained Reinforcement Learning (CRL) framework that integrates constraints into the learning process and incorporates parameterized post-decision state value predictions. Additionally, we introduce Lookahead-based CRL (LCRL), which improves decision-making over a multi-period horizon to enhance short-term planning while maintaining the value predictions. Our computational experiments demonstrate the efficacy of CRL and LCRL across diverse instances. Our learning methods provide near-optimal solutions on small scale instances that are solved via value iteration. Furthermore, both methods outperform typical deep learning approaches such as Proximal Policy Optimization, as well as classical inventory heuristics, such as (s,S)-policy-based and Power-of-Two-based heuristics. Furthermore, LCRL achieves a 10% improvement over CRL on average, albeit with higher computational requirements. Analyses of optimal replenishment policies reveal that accounting for stochastic supply and demand influences these policies, showing the importance of our addition to the DIRP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05276v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Umur Hasturk, Albert H. Schrotenboer, Kees Jan Roodbergen, Evrim Ursavas</dc:creator>
    </item>
    <item>
      <title>Identification of Feasible Regions Using R-Functions</title>
      <link>https://arxiv.org/abs/2503.05510</link>
      <description>arXiv:2503.05510v1 Announce Type: new 
Abstract: The primary objective of flexibility analysis is to identify and define the feasibility region, which represents the range of operational conditions (e.g., variations in process parameters) that ensure safe, reliable, and feasible process performance. This work introduces a novel flexibility analysis method that requires only that model constraints (e.g., defining product Critical Quality Attributes or process Key Performance Indicators) be explicitly provided or approximated by a closed-form function, such as a multivariate polynomial model. The method is based on V.L. Rvachev's R-functions, enabling an explicit analytical representation of the feasibility region without relying on complex optimization-based approaches. R-functions offer a framework for describing intricate geometric shapes and performing operations on them using implicit functions and inequality constraints. The theory of R-functions facilitates the identification of feasibility regions through algebraic manipulation, making it a more practical alternative to traditional optimization-based methods. The effectiveness of the proposed approach is demonstrated using a suite of well-known test cases from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05510v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Segei Kucherenko, Nilay Shah, Oleksiy Klymenko</dc:creator>
    </item>
    <item>
      <title>Multi-asset optimal trade execution with stochastic cross-effects: An Obizhaeva-Wang-type framework</title>
      <link>https://arxiv.org/abs/2503.05594</link>
      <description>arXiv:2503.05594v1 Announce Type: new 
Abstract: We analyze a continuous-time optimal trade execution problem in multiple assets where the price impact and the resilience can be matrix-valued stochastic processes that incorporate cross-impact effects. In addition, we allow for stochastic terminal and running targets. Initially, we formulate the optimal trade execution task as a stochastic control problem with a finite-variation control process that acts as an integrator both in the state dynamics and in the cost functional. We then extend this problem continuously to a stochastic control problem with progressively measurable controls. By identifying this extended problem as equivalent to a certain linear-quadratic stochastic control problem, we can use established results in linear-quadratic stochastic control to solve the extended problem. This work generalizes [Ackermann, Kruse, Urusov; FinancStoch'24] from the single-asset setting to the multi-asset case. In particular, we reveal cross-hedging effects, showing that it can be optimal to trade in an asset despite having no initial position. Moreover, as a subsetting we discuss a multi-asset variant of the model in [Obizhaeva, Wang; JFinancMark'13].</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05594v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.MF</category>
      <category>q-fin.TR</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Ackermann, Thomas Kruse, Mikhail Urusov</dc:creator>
    </item>
    <item>
      <title>Control analysis and synthesis for general control-affine systems</title>
      <link>https://arxiv.org/abs/2503.05606</link>
      <description>arXiv:2503.05606v1 Announce Type: new 
Abstract: This paper provides controllability analysis and control synthesis for general control-affine systems, potentially subject to a bounded perturbation. We establish sufficient controllability conditions based on a proper generalization of the controllability Gramian for linear systems. Under these sufficient conditions, control syntheses are developed. We provide two control input constructions for a given system, either of which can steer the system from a given initial state to any desired target state within a finite time horizon. As in our analysis, in the case of linearity, these syntheses are reduced to common control inputs based on the controllability of Gramian. Additionally, we derive a sharp upper bound on the $L^2$-norm of these control functions, allowing us to derive insights into the energy required to enact control. The work advances the theory of nonlinear controllability and provides an analytical framework that facilitates numerical verification and practical implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05606v1</guid>
      <category>math.OC</category>
      <category>math.CA</category>
      <category>math.DS</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyprien Tamekue, ShiNung Ching</dc:creator>
    </item>
    <item>
      <title>BoGrape: Bayesian optimization over graphs with shortest-path encoded</title>
      <link>https://arxiv.org/abs/2503.05642</link>
      <description>arXiv:2503.05642v1 Announce Type: new 
Abstract: Graph-structured data play an important role across science and industry. This paper asks: how can we optimize over graphs, for instance to find the best graph structure and/or node features that minimize an expensive-to-evaluate black-box objective? Such problem settings arise, e.g., in molecular design, neural architecture search, and sensor placement. Bayesian optimization is a powerful tool for optimizing black-box functions, and existing technologies can be applied to optimize functions over nodes of a single fixed graph. We present Bayesian optimization acquisition functions for a class of shortest-path kernels and formulate them as mixed-integer optimization problems, enabling global exploration of the graph domain while maintaining solution feasibility when problem-specific constraints are present. We demonstrate our proposed approach, BoGrape, on several molecular design case studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05642v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilin Xie, Shiqiang Zhang, Jixiang Qing, Ruth Misener, Calvin Tsay</dc:creator>
    </item>
    <item>
      <title>The latent variable proximal point algorithm for variational problems with inequality constraints</title>
      <link>https://arxiv.org/abs/2503.05672</link>
      <description>arXiv:2503.05672v1 Announce Type: new 
Abstract: The latent variable proximal point (LVPP) algorithm is a framework for solving infinite-dimensional variational problems with pointwise inequality constraints. The algorithm is a saddle point reformulation of the Bregman proximal point algorithm. At the continuous level, the two formulations are equivalent, but the saddle point formulation is more amenable to discretization because it introduces a structure-preserving transformation between a latent function space and the feasible set. Working in this latent space is much more convenient for enforcing inequality constraints than the feasible set, as discretizations can employ general linear combinations of suitable basis functions, and nonlinear solvers can involve general additive updates. LVPP yields numerical methods with observed mesh-independence for obstacle problems, contact, fracture, plasticity, and others besides; in many cases, for the first time. The framework also extends to more complex constraints, providing means to enforce convexity in the Monge--Amp\`ere equation and handling quasi-variational inequalities, where the underlying constraint depends implicitly on the unknown solution. In this paper, we describe the LVPP algorithm in a general form and apply it to twelve problems from across mathematics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05672v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J{\o}rgen S. Dokken, Patrick E. Farrell, Brendan Keith, Ioannis P. A. Papadopoulos, Thomas M. Surowiec</dc:creator>
    </item>
    <item>
      <title>Spectral-Spatial Extraction through Layered Tensor Decomposition for Hyperspectral Anomaly Detection</title>
      <link>https://arxiv.org/abs/2503.05183</link>
      <description>arXiv:2503.05183v1 Announce Type: cross 
Abstract: Low rank tensor representation (LRTR) methods are very useful for hyperspectral anomaly detection (HAD). To overcome the limitations that they often overlook spectral anomaly and rely on large-scale matrix singular value decomposition, we first apply non-negative matrix factorization (NMF) to alleviate spectral dimensionality redundancy and extract spectral anomaly and then employ LRTR to extract spatial anomaly while mitigating spatial redundancy, yielding a highly efffcient layered tensor decomposition (LTD) framework for HAD. An iterative algorithm based on proximal alternating minimization is developed to solve the proposed LTD model, with convergence guarantees provided. Moreover, we introduce a rank reduction strategy with validation mechanism that adaptively reduces data size while preventing excessive reduction. Theoretically, we rigorously establish the equivalence between the tensor tubal rank and tensor group sparsity regularization (TGSR) and, under mild conditions, demonstrate that the relaxed formulation of TGSR shares the same global minimizers and optimal values as its original counterpart. Experimental results on the Airport-Beach-Urban and MVTec datasets demonstrate that our approach outperforms state-of-the-art methods in the HAD task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05183v1</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Quan Yu, Yu-Hong Dai, Minru Bai</dc:creator>
    </item>
    <item>
      <title>Tractable Representations for Convergent Approximation of Distributional HJB Equations</title>
      <link>https://arxiv.org/abs/2503.05563</link>
      <description>arXiv:2503.05563v1 Announce Type: cross 
Abstract: In reinforcement learning (RL), the long-term behavior of decision-making policies is evaluated based on their average returns. Distributional RL has emerged, presenting techniques for learning return distributions, which provide additional statistics for evaluating policies, incorporating risk-sensitive considerations. When the passage of time cannot naturally be divided into discrete time increments, researchers have studied the continuous-time RL (CTRL) problem, where agent states and decisions evolve continuously. In this setting, the Hamilton-Jacobi-Bellman (HJB) equation is well established as the characterization of the expected return, and many solution methods exist. However, the study of distributional RL in the continuous-time setting is in its infancy. Recent work has established a distributional HJB (DHJB) equation, providing the first characterization of return distributions in CTRL. These equations and their solutions are intractable to solve and represent exactly, requiring novel approximation techniques. This work takes strides towards this end, establishing conditions on the method of parameterizing return distributions under which the DHJB equation can be approximately solved. Particularly, we show that under a certain topological property of the mapping between statistics learned by a distributional RL algorithm and corresponding distributions, approximation of these statistics leads to close approximations of the solution of the DHJB equation. Concretely, we demonstrate that the quantile representation common in distributional RL satisfies this topological property, certifying an efficient approximation algorithm for continuous-time distributional RL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05563v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julie Alhosh, Harley Wiltzer, David Meger</dc:creator>
    </item>
    <item>
      <title>BARK: A Fully Bayesian Tree Kernel for Black-box Optimization</title>
      <link>https://arxiv.org/abs/2503.05574</link>
      <description>arXiv:2503.05574v1 Announce Type: cross 
Abstract: We perform Bayesian optimization using a Gaussian process perspective on Bayesian Additive Regression Trees (BART). Our BART Kernel (BARK) uses tree agreement to define a posterior over piecewise-constant functions, and we explore the space of tree kernels using a Markov chain Monte Carlo approach. Where BART only samples functions, the resulting BARK model obtains samples of Gaussian processes defining distributions over functions, which allow us to build acquisition functions for Bayesian optimization. Our tree-based approach enables global optimization over the surrogate, even for mixed-feature spaces. Moreover, where many previous tree-based kernels provide uncertainty quantification over function values, our sampling scheme captures uncertainty over the tree structure itself. Our experiments show the strong performance of BARK on both synthetic and applied benchmarks, due to the combination of our fully Bayesian surrogate and the optimization procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05574v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Toby Boyne, Jose Pablo Folch, Robert M Lee, Behrang Shafei, Ruth Misener</dc:creator>
    </item>
    <item>
      <title>p-adic Delsarte-Goethals-Seidel-Kabatianskii-Levenshtein-Pfender Bound</title>
      <link>https://arxiv.org/abs/2503.05654</link>
      <description>arXiv:2503.05654v1 Announce Type: cross 
Abstract: We introduce the notion of p-adic spherical codes (in particular, p-adic kissing number problem). We show that the one-line proof for a variant of the Delsarte-Goethals-Seidel-Kabatianskii-Levenshtein upper bound for spherical codes, obtained by Pfender \textit{[J. Combin. Theory Ser. A, 2007]}, extends to p-adic Hilbert spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05654v1</guid>
      <category>math.NT</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>K. Mahesh Krishna</dc:creator>
    </item>
    <item>
      <title>Stable Spare Parts Pooling for Military Weapon Systems</title>
      <link>https://arxiv.org/abs/1811.08145</link>
      <description>arXiv:1811.08145v2 Announce Type: replace 
Abstract: We study under which circumstances Departments of Defenses should be willing to deploy a joint parts part pooling program for their major weapon systems. Using cooperative game theory and Markov Decision Processes, we demonstrate that the type of pooling strategy plays a crucial role in the success of such a joint spare parts pool. More precisely, we show that a joint spare parts pool may not last long -- or even not arise -- if full pooling is applied, while it is stable under threshold pooling.</description>
      <guid isPermaLink="false">oai:arXiv.org:1811.08145v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Loe Schlicher, Marco Slikker, Willem van Jaarsveld</dc:creator>
    </item>
    <item>
      <title>Entropic Risk-Averse Generalized Momentum Methods</title>
      <link>https://arxiv.org/abs/2204.11292</link>
      <description>arXiv:2204.11292v3 Announce Type: replace 
Abstract: In the context of first-order algorithms subject to random gradient noise, we study the trade-offs between the convergence rate (which quantifies how fast the initial conditions are forgotten) and the "risk" of suboptimality, i.e. deviations from the expected suboptimality. We focus on a general class of momentum methods (GMM) which recover popular methods such as gradient descent (GD), accelerated gradient descent (AGD), and heavy-ball (HB) method as special cases depending on the choice of GMM parameters. We use well-known risk measures "entropic risk" and "entropic value at risk" to quantify the risk of suboptimality. For strongly convex smooth minimization, we first obtain new convergence rate results for GMM with a unified theory that is also applicable to both AGD and HB, improving some of the existing results for HB. We then provide explicit bounds on the entropic risk and entropic value at risk of suboptimality at a given iterate which also provides direct bounds on the probability that the suboptimality exceeds a given threshold based on Chernoff's inequality. Our results unveil fundamental trade-offs between the convergence rate and the risk of suboptimality. We then plug the entropic risk and convergence rate estimates we obtained in a computationally tractable optimization framework and propose entropic risk-averse GMM (RA-GMM) and entropic risk-averse AGD (RA-AGD) methods which can select the GMM parameters to systematically trade-off the entropic value at risk with the convergence rate. We show that RA-AGD and RA-GMM lead to improved performance on quadratic optimization and logistic regression problems compared to the standard choice of parameters. To our knowledge, our work is the first to resort to coherent measures to design the parameters of momentum methods in a systematic manner.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.11292v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bugra Can, Mert G\"urb\"uzbalaban</dc:creator>
    </item>
    <item>
      <title>On the $O(\frac{\sqrt{d}}{T^{1/4}})$ Convergence Rate of RMSProp and Its Momentum Extension Measured by $\ell_1$ Norm</title>
      <link>https://arxiv.org/abs/2402.00389</link>
      <description>arXiv:2402.00389v4 Announce Type: replace 
Abstract: Although adaptive gradient methods have been extensively used in deep learning, their convergence rates proved in the literature are all slower than that of SGD, particularly with respect to their dependence on the dimension. This paper considers the classical RMSProp and its momentum extension and establishes the convergence rate of $\frac{1}{T}\sum_{k=1}^T E\left[\|\nabla f(x^k)\|_1\right]\leq O(\frac{\sqrt{d}C}{T^{1/4}})$ measured by $\ell_1$ norm without the bounded gradient assumption, where $d$ is the dimension of the optimization variable, $T$ is the iteration number, and $C$ is a constant identical to that appeared in the optimal convergence rate of SGD. Our convergence rate matches the lower bound with respect to all the coefficients except the dimension $d$. Since $\|x\|_2\ll\|x\|_1\leq\sqrt{d}\|x\|_2$ for problems with extremely large $d$, our convergence rate can be considered to be analogous to the $\frac{1}{T}\sum_{k=1}^T E\left[\|\nabla f(x^k)\|_2\right]\leq O(\frac{C}{T^{1/4}})$ rate of SGD in the ideal case of $\|\nabla f(x)\|_1=\varTheta(\sqrt{d}\|\nabla f(x)\|_2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00389v4</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huan Li, Yiming Dong, Zhouchen Lin</dc:creator>
    </item>
    <item>
      <title>Approximability of the Containment Problem for Zonotopes and Ellipsotopes</title>
      <link>https://arxiv.org/abs/2404.11185</link>
      <description>arXiv:2404.11185v3 Announce Type: replace 
Abstract: The zonotope containment problem, i.e., whether one zonotope is contained in another, is a central problem in control theory. Applications include detecting faults and robustifying controllers by computing invariant sets, and obtain fixed points in reachability analysis. Despite the inherent co-NP-hardness of this problem, an approximation algorithm developed by S. Sadraddini and R. Tedrake has gained widespread recognition for its swift execution and consistent reliability in practice. In our study, we substantiate the precision of the algorithm with a definitive proof, elucidating the empirical accuracy observed in practice. Our proof hinges on establishing a connection between the containment problem and the computation of matrix norms, thereby enabling the extension of the approximation algorithm to encompass ellipsotopes -- a broader class of sets derived from zonotopes. We also explore the computational complexity of the ellipsotope containment problem with a focus on approximability. Finally, we present new methods to compute safe sets for linear dynamical systems, demonstrating the practical relevance of approximating the ellipsotope containment problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11185v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrian Kulmburg, Lukas Sch\"afer, Matthias Althoff</dc:creator>
    </item>
    <item>
      <title>Safe and Efficient Online Convex Optimization with Linear Budget Constraints and Partial Feedback</title>
      <link>https://arxiv.org/abs/2412.03983</link>
      <description>arXiv:2412.03983v2 Announce Type: replace 
Abstract: This paper studies online convex optimization with unknown linear budget constraints, where only the gradient information of the objective and the bandit feedback of constraint functions are observed. We propose a safe and efficient Lyapunov-optimization algorithm (SELO) that can achieve an $O(\sqrt{T})$ regret and zero cumulative constraint violation. The result also implies SELO achieves $O(\sqrt{T})$ regret when the budget is hard and not allowed to be violated. The proposed algorithm is computationally efficient as it resembles a primal-dual algorithm where the primal problem is an unconstrained, strongly convex and smooth problem, and the dual problem has a simple gradient-type update. The algorithm and theory are further justified in a simulated application of energy-efficient task processing in distributed data centers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03983v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shanqi Liu, Xin Liu</dc:creator>
    </item>
    <item>
      <title>On a Lemma by Br\'ezis and Haraux</title>
      <link>https://arxiv.org/abs/2501.11662</link>
      <description>arXiv:2501.11662v3 Announce Type: replace 
Abstract: We propose several applications of an often overlooked part of the 1976 paper by Br\'ezis and Haraux, in which the Br\'ezis--Haraux theorem was established. Our results unify and extend various existing ones on the range of a linearly composite monotone operator and provide new insight into their seminal paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11662v3</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minh N. B\`ui</dc:creator>
    </item>
    <item>
      <title>Cauchy-Schwarz Regularizers</title>
      <link>https://arxiv.org/abs/2503.01639</link>
      <description>arXiv:2503.01639v2 Announce Type: replace 
Abstract: We introduce a novel class of regularization functions, called Cauchy-Schwarz (CS) regularizers, which can be designed to induce a wide range of properties in solution vectors of optimization problems. To demonstrate the versatility of CS regularizers, we derive regularization functions that promote discrete-valued vectors, eigenvectors of a given matrix, and orthogonal matrices. The resulting CS regularizers are simple, differentiable, and can be free of spurious stationary points, making them suitable for gradient-based solvers and large-scale optimization problems. In addition, CS regularizers automatically adapt to the appropriate scale, which is, for example, beneficial when discretizing the weights of neural networks. To demonstrate the efficacy of CS regularizers, we provide results for solving underdetermined systems of linear equations and weight quantization in neural networks. Furthermore, we discuss specializations, variations, and generalizations, which lead to an even broader class of new and possibly more powerful regularizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01639v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sueda Taner, Ziyi Wang, Christoph Studer</dc:creator>
    </item>
    <item>
      <title>Asymptotic behavior of penalty dynamics for constrained variational inequalities</title>
      <link>https://arxiv.org/abs/2503.03902</link>
      <description>arXiv:2503.03902v2 Announce Type: replace 
Abstract: We propose a comprehensive framework for solving constrained variational inequalities via various classes of evolution equations displaying multi-scale aspects. In a Hilbertian framework, the class of dynamical systems we propose combine Tikhonov regularization and exterior penalization terms in order to yield simultaneously strong convergence of trajectories to least norm solutions in the constrained domain. Our construction thus unifies the literature on regularization methods and penalty-term based dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03902v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siqi Qu, Mathias Staudigl, Juan Peypouquet</dc:creator>
    </item>
    <item>
      <title>BSAC-CoEx: Coexistence of URLLC and Distributed Learning Services via Device Selection</title>
      <link>https://arxiv.org/abs/2212.11805</link>
      <description>arXiv:2212.11805v2 Announce Type: replace-cross 
Abstract: Recent advances in distributed intelligence have driven impressive progress across a diverse range of applications, from industrial automation to autonomous transportation. Nevertheless, deploying distributed learning services over wireless networks poses numerous challenges. These arise from inherent uncertainties in wireless environments (e.g., random channel fluctuations), limited resources (e.g., bandwidth and transmit power), and the presence of coexisting services on the network. In this paper, we investigate a mixed service scenario wherein high-priority ultra-reliable low latency communication (URLLC) and low-priority distributed learning services run concurrently over a network. Utilizing device selection, we aim to minimize the convergence time of distributed learning while simultaneously fulfilling the requirements of the URLLC service. We formulate this problem as a Markov decision process and address it via BSAC-CoEx, a framework based on the branching soft actor-critic (BSAC) algorithm that determines each device's participation decision through distinct branches in the actor's neural network. We evaluate our solution with a realistic simulator that is compliant with 3GPP standards for factory automation use cases. Our simulation results confirm that our solution can significantly decrease the training delays of the distributed learning service while keeping the URLLC availability above its required threshold and close to the scenario where URLLC solely consumes all wireless resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.11805v2</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Milad Ganjalizadeh, Hossein Shokri Ghadikolaei, Deniz G\"und\"uz, Marina Petrova</dc:creator>
    </item>
    <item>
      <title>Theoretical and Empirical Advances in Forest Pruning</title>
      <link>https://arxiv.org/abs/2401.05535</link>
      <description>arXiv:2401.05535v4 Announce Type: replace-cross 
Abstract: Regression forests have long delivered state-of-the-art accuracy, often outperforming regression trees and even neural networks, but they suffer from limited interpretability as ensemble methods. In this work, we revisit forest pruning, an approach that aims to have the best of both worlds: the accuracy of regression forests and the interpretability of regression trees. This pursuit, whose foundation lies at the core of random forest theory, has seen vast success in empirical studies. In this paper, we contribute theoretical results that support and qualify those empirical findings; namely, we prove the asymptotic advantage of a Lasso-pruned forest over its unpruned counterpart under weak assumptions, as well as high-probability finite-sample generalization bounds for regression forests pruned according to the main methods, which we then validate by way of simulation. Then, we test the accuracy of pruned regression forests against their unpruned counterparts on 19 different datasets (16 synthetic, 3 real). We find that in the vast majority of scenarios tested, there is at least one forest-pruning method that yields equal or better accuracy than the original full forest (in expectation), while just using a small fraction of the trees. We show that, in some cases, the reduction in the size of the forest is so dramatic that the resulting sub-forest can be meaningfully merged into a single tree, obtaining a level of interpretability that is qualitatively superior to that of the original regression forest, which remains a black box.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05535v4</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Albert Dorador</dc:creator>
    </item>
    <item>
      <title>Stochastic Modified Flows for Riemannian Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2402.03467</link>
      <description>arXiv:2402.03467v2 Announce Type: replace-cross 
Abstract: We give quantitative estimates for the rate of convergence of Riemannian stochastic gradient descent (RSGD) to Riemannian gradient flow and to a diffusion process, the so-called Riemannian stochastic modified flow (RSMF). Using tools from stochastic differential geometry we show that, in the small learning rate regime, RSGD can be approximated by the solution to the RSMF driven by an infinite-dimensional Wiener process. The RSMF accounts for the random fluctuations of RSGD and, thereby, increases the order of approximation compared to the deterministic Riemannian gradient flow. The RSGD is build using the concept of a retraction map, that is, a cost efficient approximation of the exponential map, and we prove quantitative bounds for the weak error of the diffusion approximation under assumptions on the retraction map, the geometry of the manifold, and the random estimators of the gradient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03467v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/24M163863X</arxiv:DOI>
      <arxiv:journal_reference>SIAM J. Control Optim. 62(6): 3288-3314 (2024)</arxiv:journal_reference>
      <dc:creator>Benjamin Gess, Sebastian Kassing, Nimit Rana</dc:creator>
    </item>
    <item>
      <title>Cooperative Nonlinear Guidance Strategies for Guaranteed Pursuit-Evasion</title>
      <link>https://arxiv.org/abs/2402.06176</link>
      <description>arXiv:2402.06176v2 Announce Type: replace-cross 
Abstract: This paper addresses the pursuit-evasion problem involving three agents -- a purser, an evader, and a defender. We develop cooperative guidance laws for the evader-defender team that guarantee that the defender intercepts the pursuer before it reaches the vicinity of the evader. Unlike heuristic methods, optimal control, differential game formulation, and recently proposed time-constrained guidance techniques, we propose a geometric solution to safeguard the evader from the pursuer's incoming threat. The proposed strategy is computationally efficient and expected to be scalable as the number of agents increases. Another alluring feature of the proposed strategy is that the evader-defender team does not require the knowledge of the pursuer's strategy and that the pursuer's interception is guaranteed from arbitrary initial engagement geometries. We further show that the necessary error variables for the evader-defender team vanish within a time that can be exactly prescribed prior to the three-body engagement. Finally, we demonstrate the efficacy of the proposed cooperative defense strategy via simulation in diverse engagement scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06176v2</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Saurabh Kumar, Shashi Ranjan Kumar, Abhinav Sinha</dc:creator>
    </item>
    <item>
      <title>CrowdSurfer: Sampling Optimization Augmented with Vector-Quantized Variational AutoEncoder for Dense Crowd Navigation</title>
      <link>https://arxiv.org/abs/2409.16011</link>
      <description>arXiv:2409.16011v2 Announce Type: replace-cross 
Abstract: Navigation amongst densely packed crowds remains a challenge for mobile robots. The complexity increases further if the environment layout changes, making the prior computed global plan infeasible. In this paper, we show that it is possible to dramatically enhance crowd navigation by just improving the local planner. Our approach combines generative modelling with inference time optimization to generate sophisticated long-horizon local plans at interactive rates. More specifically, we train a Vector Quantized Variational AutoEncoder to learn a prior over the expert trajectory distribution conditioned on the perception input. At run-time, this is used as an initialization for a sampling-based optimizer for further refinement. Our approach does not require any sophisticated prediction of dynamic obstacles and yet provides state-of-the-art performance. In particular, we compare against the recent DRL-VO approach and show a 40% improvement in success rate and a 6% improvement in travel time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16011v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Naman Kumar, Antareep Singha, Laksh Nanwani, Dhruv Potdar, Tarun R, Fatemeh Rastgar, Simon Idoko, Arun Kumar Singh, K. Madhava Krishna</dc:creator>
    </item>
    <item>
      <title>A CAV-based perimeter-free regional traffic control strategy utilizing existing parking infrastructure</title>
      <link>https://arxiv.org/abs/2412.04620</link>
      <description>arXiv:2412.04620v2 Announce Type: replace-cross 
Abstract: This paper proposes a novel perimeter-free regional traffic management strategy for traffic networks under a connected and autonomous vehicle (CAV) environment. The proposed strategy requires CAVs, especially those with long remaining travel distances, to temporarily wait at nearby parking facilities when the network is congested. After a designated holding time, these CAVs are allowed to re-enter the network. Doing so helps reduce congestion and improve overall operational efficiency. Unlike traditional perimeter control approaches that restrict inflows to congested regions, the proposed holding strategy leverages existing parking infrastructure to temporarily hold vehicles in a way that partially avoids local queue accumulation issues. The proposed method can be easily integrated with existing signal control methods and retains the maximum stability property of the original traffic signal control methods. Simulation results show that the proposed strategy not only reduces travel time for vehicles that are not held, but can also reduce travel times for some of the held vehicles as well, which serves as another key merit of the proposed approach. Compared to the two benchmark perimeter control algorithms, the proposed strategy is more robust against demand patterns and generates stronger improvements in the operational efficiency. Importantly, since the proposed strategy requires existing parking infrastructure, its performance has been demonstrated under various configurations of parking locations and capacities. Particularly, it is demonstrated that the utilization of the parking facility consistently improves overall traffic efficiency, regardless of the facility's size. Lastly, the proposed strategy is shown to be beneficial in a partial CAV environment where only a subset of vehicles are available for holding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04620v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Liu, Vikash V. Gayah</dc:creator>
    </item>
    <item>
      <title>Fractional Sobolev paths on Wasserstein spaces and their energy-minimizing particle representations</title>
      <link>https://arxiv.org/abs/2502.12068</link>
      <description>arXiv:2502.12068v3 Announce Type: replace-cross 
Abstract: We study a generalization of Kantorovich's optimal transportation problem. Given a prescribed family of time-dependent probability measures $(\mu_t)$, we aim to find, among all path-continuous stochastic processes whose one-dimensional time marginals coincide with $(\mu_t)$ (if there is any), a process that minimizes a given energy. After discussing a sufficient condition for the energy to ensure the existence of a minimizer, we investigate fractional Sobolev energies. Given a deterministic path $(\mu_t)$ on a $p$-Wasserstein space with fractional Sobolev regularity $W^{\alpha,p}$, where $1/p &lt; \alpha &lt; 1$, we provide conditions under which we prove the existence of a process that minimizes the energy and construct a process that realizes the regularity of $(\mu_t)$. While continuous paths of low regularity on Wasserstein spaces naturally appear in stochastic analysis, they can also arise deterministically as solutions to the continuity equation. This paper is devoted to the deterministic setting to gain some understanding of the required conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12068v3</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ehsan Abedi</dc:creator>
    </item>
    <item>
      <title>Noise-driven Synchronization of Vicsek Model in Mean</title>
      <link>https://arxiv.org/abs/2502.13993</link>
      <description>arXiv:2502.13993v2 Announce Type: replace-cross 
Abstract: The Vicsek model has long stood as a pivotal framework in exploring collective behavior and self-organization, captivating the scientific community with its compelling dynamics. However, understanding how noise influences synchronization within this model and its associated phase transition characteristics has presented significant challenges. While numerous studies have focused on simulations due to the model's mathematical complexity, comprehensive theoretical analyses remain sparse. In this paper, we deliver a rigorous mathematical proof demonstrating that for any initial configuration of the Vicsek model, there exists a bound on noise amplitude such that if the noise amplitude is maintained within this bound, the system will achieve synchronization in mean. This finding not only lays a solid mathematical groundwork for the Vicsek model's phase transition theory but also underscores the critical role of noise in collective dynamics, enhancing our understanding of self-organizing systems in stochastic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13993v2</guid>
      <category>math-ph</category>
      <category>math.DS</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>nlin.AO</category>
      <pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Su, Yongguang Yu, Ge Chen</dc:creator>
    </item>
  </channel>
</rss>
