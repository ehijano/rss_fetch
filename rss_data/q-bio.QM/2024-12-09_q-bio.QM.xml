<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Dec 2024 03:54:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>ProtBoost: protein function prediction with Py-Boost and Graph Neural Networks -- CAFA5 top2 solution</title>
      <link>https://arxiv.org/abs/2412.04529</link>
      <description>arXiv:2412.04529v1 Announce Type: new 
Abstract: Predicting protein properties, functions and localizations are important tasks in bioinformatics. Recent progress in machine learning offers an opportunities for improving existing methods. We developed a new approach called ProtBoost, which relies on the strength of pretrained protein language models, the new Py-Boost gradient boosting method and Graph Neural Networks (GCN). The ProtBoost method was ranked second best model in the recent Critical Assessment of Functional Annotation (CAFA5) international challenge with more than 1600 participants. Py-Boost is the first gradient boosting method capable of predicting thousands of targets simultaneously, making it an ideal fit for tasks like the CAFA challange. Our GCN-based approach performs stacking of many individual models and boosts the performance significantly. Notably, it can be applied to any task where targets are arranged in a hierarchical structure, such as Gene Ontology. Additionally, we introduced new methods for leveraging the graph structure of targets and present an analysis of protein language models for protein function prediction task. ProtBoost is publicly available at: https://github.com/btbpanda/CAFA5-protein-function-prediction-2nd-place.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04529v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Chervov, Anton Vakhrushev, Sergei Fironov, Loredana Martignetti</dc:creator>
    </item>
    <item>
      <title>Improving data sharing and knowledge transfer via the Neuroelectrophysiology Analysis Ontology (NEAO)</title>
      <link>https://arxiv.org/abs/2412.05021</link>
      <description>arXiv:2412.05021v1 Announce Type: new 
Abstract: Describing the processes involved in analyzing data from electrophysiology experiments to investigate the function of neural systems is inherently challenging. On the one hand, data can be analyzed by distinct methods that serve a similar purpose, such as different algorithms to estimate the spectral power content of a measured time series. On the other hand, different software codes can implement the same algorithm for the analysis while adopting different names to identify functions and parameters. Having reproducibility in mind, with these ambiguities the outcomes of the analysis are difficult to report, e.g., in the methods section of a manuscript or on a platform for scientific findings. Here, we illustrate how using an ontology to describe the analysis process can assist in improving clarity, rigour and comprehensibility by complementing, simplifying and classifying the details of the implementation. We implemented the Neuroelectrophysiology Analysis Ontology (NEAO) to define a unified vocabulary and to standardize the descriptions of the processes involved in analyzing data from neuroelectrophysiology experiments. Real-world examples demonstrate how the NEAO can be employed to annotate provenance information describing an analysis process. Based on such provenance, we detail how it can be used to query various types of information (e.g., using knowledge graphs) that enable researchers to find, understand and reuse prior analysis results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05021v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cristiano Andr\'e K\"ohler, Sonja Gr\"un, Michael Denker</dc:creator>
    </item>
    <item>
      <title>Kinetic-Diffusion-Rotation Algorithm for Dose Estimation in Radiation Therapy</title>
      <link>https://arxiv.org/abs/2412.05063</link>
      <description>arXiv:2412.05063v1 Announce Type: new 
Abstract: Monte Carlo methods are state-of-the-art when it comes to dosimetric computations in radiotherapy. However, the execution time of these methods suffers in high-collisional regimes. We address this problem by introducing a kinetic-diffusion particle tracing scheme. This algorithm, first proposed in the context of neutral transport in fusion energy, relies on explicit simulation of the kinetic motion in low-collisional regimes and dynamically switches to motion based on a random walk in high-collisional regimes. The random walk motion maintains the first two moments (mean and variance) of the kinetic motion. We derive an analytic formula for the mean kinetic motion and discuss the addition of a multiple scattering distribution to the algorithm. In contrast to neutral transport, the radiation transfer setting does not readily admit to an analytical expression for the variance of the kinetic motion, and we therefore resort to the use of a lookup table. We test the algorithm for dosimetric computations in radiation therapy on a 2D CT scan of a lung patient. Using a simple particle model, our Python implementation of the algorithm is nearly 33 times faster than an equivalent kinetic simulation at the cost of a small modeling error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05063v1</guid>
      <category>q-bio.QM</category>
      <category>physics.med-ph</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Klaas Willems, Vince Maes, Zhirui Tang, Giovanni Samaey</dc:creator>
    </item>
    <item>
      <title>Generative Humanization for Therapeutic Antibodies</title>
      <link>https://arxiv.org/abs/2412.04737</link>
      <description>arXiv:2412.04737v2 Announce Type: cross 
Abstract: Antibody therapies have been employed to address some of today's most challenging diseases, but must meet many criteria during drug development before reaching a patient. Humanization is a sequence optimization strategy that addresses one critical risk called immunogenicity - a patient's immune response to the drug - by making an antibody more "human-like" in the absence of a predictive lab-based test for immunogenicity. However, existing humanization strategies generally yield very few humanized candidates, which may have degraded biophysical properties or decreased drug efficacy. Here, we re-frame humanization as a conditional generative modeling task, where humanizing mutations are sampled from a language model trained on human antibody data. We describe a sampling process that incorporates models of therapeutic attributes, such as antigen binding affinity, to obtain candidate sequences that have both reduced immunogenicity risk and maintained or improved therapeutic properties, allowing this algorithm to be readily embedded into an iterative antibody optimization campaign. We demonstrate in silico and in lab validation that in real therapeutic programs our generative humanization method produces diverse sets of antibodies that are both (1) highly-human and (2) have favorable therapeutic properties, such as improved binding to target antigens.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04737v2</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cade Gordon, Aniruddh Raghu, Peyton Greenside, Hunter Elliott</dc:creator>
    </item>
    <item>
      <title>Machine learning algorithms to predict the risk of rupture of intracranial aneurysms: a systematic review</title>
      <link>https://arxiv.org/abs/2412.04749</link>
      <description>arXiv:2412.04749v1 Announce Type: cross 
Abstract: Purpose: Subarachnoid haemorrhage is a potentially fatal consequence of intracranial aneurysm rupture, however, it is difficult to predict if aneurysms will rupture. Prophylactic treatment of an intracranial aneurysm also involves risk, hence identifying rupture-prone aneurysms is of substantial clinical importance. This systematic review aims to evaluate the performance of machine learning algorithms for predicting intracranial aneurysm rupture risk.
  Methods: MEDLINE, Embase, Cochrane Library and Web of Science were searched until December 2023. Studies incorporating any machine learning algorithm to predict the risk of rupture of an intracranial aneurysm were included. Risk of bias was assessed using the Prediction Model Risk of Bias Assessment Tool (PROBAST). PROSPERO registration: CRD42023452509. Results: Out of 10,307 records screened, 20 studies met the eligibility criteria for this review incorporating a total of 20,286 aneurysm cases. The machine learning models gave a 0.66-0.90 range for performance accuracy. The models were compared to current clinical standards in six studies and gave mixed results. Most studies posed high or unclear risks of bias and concerns for applicability, limiting the inferences that can be drawn from them. There was insufficient homogenous data for a meta-analysis.
  Conclusions: Machine learning can be applied to predict the risk of rupture for intracranial aneurysms. However, the evidence does not comprehensively demonstrate superiority to existing practice, limiting its role as a clinical adjunct. Further prospective multicentre studies of recent machine learning tools are needed to prove clinical validation before they are implemented in the clinic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04749v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00062-024-01474-4</arxiv:DOI>
      <dc:creator>Karan Daga, Siddharth Agarwal, Zaeem Moti, Matthew BK Lee, Munaib Din, David Wood, Marc Modat, Thomas C Booth</dc:creator>
    </item>
    <item>
      <title>Chimera: Accurate retrosynthesis prediction by ensembling models with diverse inductive biases</title>
      <link>https://arxiv.org/abs/2412.05269</link>
      <description>arXiv:2412.05269v1 Announce Type: cross 
Abstract: Planning and conducting chemical syntheses remains a major bottleneck in the discovery of functional small molecules, and prevents fully leveraging generative AI for molecular inverse design. While early work has shown that ML-based retrosynthesis models can predict reasonable routes, their low accuracy for less frequent, yet important reactions has been pointed out. As multi-step search algorithms are limited to reactions suggested by the underlying model, the applicability of those tools is inherently constrained by the accuracy of retrosynthesis prediction. Inspired by how chemists use different strategies to ideate reactions, we propose Chimera: a framework for building highly accurate reaction models that combine predictions from diverse sources with complementary inductive biases using a learning-based ensembling strategy. We instantiate the framework with two newly developed models, which already by themselves achieve state of the art in their categories. Through experiments across several orders of magnitude in data scale and time-splits, we show Chimera outperforms all major models by a large margin, owing both to the good individual performance of its constituents, but also to the scalability of our ensembling strategy. Moreover, we find that PhD-level organic chemists prefer predictions from Chimera over baselines in terms of quality. Finally, we transfer the largest-scale checkpoint to an internal dataset from a major pharmaceutical company, showing robust generalization under distribution shift. With the new dimension that our framework unlocks, we anticipate further acceleration in the development of even more accurate models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05269v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krzysztof Maziarz, Guoqing Liu, Hubert Misztela, Aleksei Kornev, Piotr Gai\'nski, Holger Hoefling, Mike Fortunato, Rishi Gupta, Marwin Segler</dc:creator>
    </item>
    <item>
      <title>Sifting through the haystack -- efficiently finding rare animal behaviors in large-scale datasets</title>
      <link>https://arxiv.org/abs/2412.03452</link>
      <description>arXiv:2412.03452v2 Announce Type: replace 
Abstract: In the study of animal behavior, researchers often record long continuous videos, accumulating into large-scale datasets. However, the behaviors of interest are often rare compared to routine behaviors. This incurs a heavy cost on manual annotation, forcing users to sift through many samples before finding their needles. We propose a pipeline to efficiently sample rare behaviors from large datasets, enabling the creation of training datasets for rare behavior classifiers. Our method only needs an unlabeled animal pose or acceleration dataset as input and makes no assumptions regarding the type, number, or characteristics of the rare behaviors.
  Our pipeline is based on a recent graph-based anomaly detection model for human behavior, which we apply to this new data domain. It leverages anomaly scores to automatically label normal samples while directing human annotation efforts toward anomalies. In research data, anomalies may come from many different sources (e.g., signal noise versus true rare instances). Hence, the entire labeling budget is focused on the abnormal classes, letting the user review and label samples according to their needs.
  We tested our approach on three datasets of freely-moving animals, acquired in the laboratory and the field. We found that graph-based models are particularly useful when studying motion-based behaviors in animals, yielding good results while using a small labeling budget. Our method consistently outperformed traditional random sampling, offering an average improvement of 70% in performance and creating datasets even when the behavior of interest was only 0.02% of the data. Even when the performance gain was minor (e.g., when the behavior is not rare), our method still reduced the annotation effort by half.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03452v2</guid>
      <category>q-bio.QM</category>
      <category>eess.IV</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shir Bar, Or Hirschorn, Roi Holzman, Shai Avidan</dc:creator>
    </item>
    <item>
      <title>A comprehensive comparison of tools for fitting mutational signatures</title>
      <link>https://arxiv.org/abs/2310.01562</link>
      <description>arXiv:2310.01562v2 Announce Type: replace-cross 
Abstract: Mutational signatures connect characteristic mutational patterns in the genome with biological or chemical processes that take place in cancers. Analysis of mutational signatures can help elucidate tumor evolution, prognosis, and therapeutic strategies. Although tools for extracting mutational signatures de novo have been extensively benchmarked, a similar effort is lacking for tools that fit known mutational signatures to a given catalog of mutations. We fill this gap by comprehensively evaluating twelve signature fitting tools on synthetic mutational catalogs with empirically-driven signature weights corresponding to eight cancer types. On average, SigProfilerSingleSample and SigProfilerAssignment/MuSiCal perform best for small and large numbers of mutations per sample, respectively. We further show that ad hoc constraining the list of reference signatures is likely to produce inferior results. Evaluation of real mutational catalogs suggests that the activity of signatures that are absent in the reference catalog poses considerable problems to all evaluated tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01562v2</guid>
      <category>q-bio.GN</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 09 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41467-024-53711-6</arxiv:DOI>
      <arxiv:journal_reference>Nature Communications 15, 9467 (2024)</arxiv:journal_reference>
      <dc:creator>Mat\'u\v{s} Medo, Charlotte K. Y. Ng, Michaela Medov\'a</dc:creator>
    </item>
  </channel>
</rss>
