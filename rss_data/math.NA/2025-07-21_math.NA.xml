<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Jul 2025 02:26:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Multiresolution local smoothness detection in non-uniformly sampled multivariate signals</title>
      <link>https://arxiv.org/abs/2507.13480</link>
      <description>arXiv:2507.13480v1 Announce Type: new 
Abstract: Inspired by edge detection based on the decay behavior of wavelet coefficients, we introduce a (near) linear-time algorithm for detecting the local regularity in non-uniformly sampled multivariate signals. Our approach quantifies regularity within the framework of microlocal spaces introduced by Jaffard. The central tool in our analysis is the fast samplet transform, a distributional wavelet transform tailored to scattered data. We establish a connection between the decay of samplet coefficients and the pointwise regularity of multivariate signals. As a by product, we derive decay estimates for functions belonging to classical H\"older spaces and Sobolev-Slobodeckij spaces. While traditional wavelets are effective for regularity detection in low-dimensional structured data, samplets demonstrate robust performance even for higher dimensional and scattered data. To illustrate our theoretical findings, we present extensive numerical studies detecting local regularity of one-, two- and three-dimensional signals, ranging from non-uniformly sampled time series over image segmentation to edge detection in point clouds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13480v1</guid>
      <category>math.NA</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sara Avesani, Gianluca Giacchi, Michael Multerer</dc:creator>
    </item>
    <item>
      <title>A priori error analysis of the proximal Galerkin method</title>
      <link>https://arxiv.org/abs/2507.13516</link>
      <description>arXiv:2507.13516v1 Announce Type: new 
Abstract: The proximal Galerkin (PG) method is a finite element method for solving variational problems with inequality constraints. It has several advantages, including constraint-preserving approximations and mesh independence. This paper presents the first abstract a priori error analysis of PG methods, providing a general framework to establish convergence and error estimates. As applications of the framework, we demonstrate optimal convergence rates for both the obstacle and Signorini problems using various finite element subspaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13516v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brendan Keith, Rami Masri, Marius Zeinhofer</dc:creator>
    </item>
    <item>
      <title>Quantifying Ocular Surface Changes with Contact Lens Wear</title>
      <link>https://arxiv.org/abs/2507.13589</link>
      <description>arXiv:2507.13589v1 Announce Type: new 
Abstract: Over 140 million people worldwide and over 45 million people in the United states wear contact lenses; it is estimated 12%-27.4% contact lens users stop wearing them due to discomfort. Contact lens mechanical interactions with the ocular surface have been found to affect the ocular surface. The mechanical interactions between the contact lens and the eye are difficult to measure and calculate in the clinical setting, and the research in this field is limited. This paper presents the first mathematical model that couples the interaction between the contact lens and the open eye, where the contact lens configuration, the contact lens suction pressure, and the deformed ocular shape are all emergent properties of the model. The non-linear coupling between the contact lens and the eye is achieved assuming the the suction pressure under the lens is applied directly to the ocular surface, neglecting the post-lens tear film layer. The contact lens dynamics is modeled using a previous published model. We consider a homogeneous and a heterogeneous linear elastic eye model, different ocular shapes, different lens shapes and lens thickness profiles, and extract lens deformation, lens suction pressure profiles, and ocular deformations and stresses for all the scenarios considered. The model predicts higher ocular deformations and stresses at the center of the eye and in the limbal/scleral region. Accounting for a heterogeneous material eye parameters increases such deformations and stresses. The ocular displacements and stresses increase non-linearly as we increase the stiffness of the contact lens. Inserting a steeper contact lens on the eye results in a reduction of the ocular displacement at the center of the eye and a larger displacement at the edge of the contact lens. The model predictions are compared to experimental data and previously developed mathematical models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13589v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.bio-ph</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucia Carichino, Kara L. Maki, David S. Ross, Riley K. Supple, Evan Rysdam</dc:creator>
    </item>
    <item>
      <title>Interpolation in Polynomial Spaces of p-Degree</title>
      <link>https://arxiv.org/abs/2507.13640</link>
      <description>arXiv:2507.13640v1 Announce Type: new 
Abstract: We recently introduced the Fast Newton Transform (FNT), an algorithm for performing multivariate Newton interpolation in downward closed polynomial spaces of spatial dimension $m$. In this work, we analyze the FNT in the context of a specific family of downward closed sets $A_{m,n,p}$, defined as all multi-indices with $\ell^p$ norm less than $n$ with $p \in [0,\infty]$. These sets induce the downward closed polynomial space $\Pi_{m,n,p}$, within which the FNT algorithm achieves a time complexity of $\mathcal{O}(|A_{m,n,p}|mn)$. We show that this setting, compared to tensor product spaces, yields an improvement in complexity by a factor $\rho_{m,n,p}$, which decays super exponentially with increasing spatial dimension when $m \lesssim n^p$. Additionally, we demonstrate the construction of the hierarchical scheme employed by the FNT and showcase its performance to compute activity scores in sensitivity analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13640v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Phil-Alexander Hofmann, Damar Wicaksono, Michael Hecht</dc:creator>
    </item>
    <item>
      <title>Multiphysics embedding localized orthogonal decomposition for thermomechanical coupling problems</title>
      <link>https://arxiv.org/abs/2507.13644</link>
      <description>arXiv:2507.13644v1 Announce Type: new 
Abstract: Multiscale modeling and analysis of multiphysics coupling processes in highly heterogeneous media present significant challenges. In this paper, we propose a novel multiphysics embedding localized orthogonal decomposition (ME-LOD) method for solving thermomechanical coupling problems, which also provides a systematic approach to address intricate coupling effects in multiphysical systems. Unlike the standard localized orthogonal decomposition (LOD) method that constructs separate multiscale spaces for each physical field, the proposed method features a unified construction for both displacement and temperature. Compared to the standard LOD method, our approach achieves operator stability reconstruction through orthogonalization while preserving computational efficiency. Several numerical experiments demonstrate that the ME-LOD method outperforms the traditional LOD method in accuracy, particularly in cases with significant contrasts in material properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13644v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuzhou Nan, Yajun Wang, Changqing Ye, Xiaofei Guan</dc:creator>
    </item>
    <item>
      <title>Pass-efficient Randomized Algorithms for Low-rank Approximation of Quaternion Matrices</title>
      <link>https://arxiv.org/abs/2507.13731</link>
      <description>arXiv:2507.13731v1 Announce Type: new 
Abstract: Randomized algorithms for low-rank approximation of quaternion matrices have gained increasing attention in recent years. However, existing methods overlook pass efficiency, the ability to limit the number of passes over the input matrix-which is critical in modern computing environments dominated by communication costs. We address this gap by proposing a suite of pass-efficient randomized algorithms that let users directly trade pass budget for approximation accuracy. Our contributions include: (i) a family of arbitrary-pass randomized algorithms for low-rank approximation of quaternion matrices that operate under a user-specified number of matrix views, and (ii) a pass-efficient extension of block Krylov subspace methods that accelerates convergence for matrices with slowly decaying spectra. Furthermore, we establish spectral norm error bounds showing that the expected approximation error decays exponentially with the number of passes. Finally, we validate our framework through extensive numerical experiments and demonstrate its practical relevance across multiple applications, including quaternionic data compression, matrix completion, image super-resolution, and deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13731v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salman Ahmadi-Asl, Malihe Nobakht Kooshkghazi, Valentin Leplat</dc:creator>
    </item>
    <item>
      <title>Newton's method for nonlinear mappings into vector bundles Part II: Application to variational problems</title>
      <link>https://arxiv.org/abs/2507.13836</link>
      <description>arXiv:2507.13836v1 Announce Type: new 
Abstract: We consider the solution of variational equations on manifolds by Newton's method. These problems can be expressed as root finding problems for mappings from infinite dimensional manifolds into dual vector bundles. We derive the differential geometric tools needed for the realization of Newton's method, equipped with an affine covariant damping strategy. We apply Newton's method to a couple of variational problems and show numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13836v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laura Weigl, Ronny Bergmann, Anton Schiela</dc:creator>
    </item>
    <item>
      <title>A stochastic column-block gradient descent method for solving nonlinear systems of equations</title>
      <link>https://arxiv.org/abs/2507.13855</link>
      <description>arXiv:2507.13855v1 Announce Type: new 
Abstract: In this paper, we propose a new stochastic column-block gradient descent method for solving nonlinear systems of equations. It has a descent direction and holds an approximately optimal step size obtained through an optimization problem. We provide a thorough convergence analysis, and derive an upper bound for the convergence rate of the new method. Numerical experiments demonstrate that the proposed method outperforms the existing ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13855v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naiyu Jiang, Wendi Bao, Lili Xing, Weiguo Li</dc:creator>
    </item>
    <item>
      <title>Deep Micro Solvers for Rough-Wall Stokes Flow in a Heterogeneous Multiscale Method</title>
      <link>https://arxiv.org/abs/2507.13902</link>
      <description>arXiv:2507.13902v1 Announce Type: new 
Abstract: We propose a learned precomputation for the heterogeneous multiscale method (HMM) for rough-wall Stokes flow. A Fourier neural operator is used to approximate local averages over microscopic subsets of the flow, which allows to compute an effective slip length of the fluid away from the roughness. The network is designed to map from the local wall geometry to the Riesz representors for the corresponding local flow averages. With such a parameterisation, the network only depends on the local wall geometry and as such can be trained independent of boundary conditions. We perform a detailed theoretical analysis of the statistical error propagation, and prove that under suitable regularity and scaling assumptions, a bounded training loss leads to a bounded error in the resulting macroscopic flow. We then demonstrate on a family of test problems that the learned precomputation performs stably with respect to the scale of the roughness. The accuracy in the HMM solution for the macroscopic flow is comparable to when the local (micro) problems are solved using a classical approach, while the computational cost of solving the micro problems is significantly reduced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13902v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emanuel Str\"om, Anna-Karin Tornberg, Ozan \"Oktem</dc:creator>
    </item>
    <item>
      <title>Convergence rates of curved boundary element methods for the 3D Laplace and Helmholtz equations</title>
      <link>https://arxiv.org/abs/2507.13955</link>
      <description>arXiv:2507.13955v1 Announce Type: new 
Abstract: We establish improved convergence rates for curved boundary element methods applied to the three-dimensional (3D) Laplace and Helmholtz equations with smooth geometry and data. Our analysis relies on a precise analysis of the consistency errors introduced by the perturbed bilinear and sesquilinear forms. We illustrate our results with numerical experiments in 3D based on basis functions and curved triangular elements up to order four.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13955v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luiz Maltez Faria, Pierre Marchand, Hadrien Montanelli</dc:creator>
    </item>
    <item>
      <title>Quantum Wave Atom Transforms</title>
      <link>https://arxiv.org/abs/2507.10739</link>
      <description>arXiv:2507.10739v1 Announce Type: cross 
Abstract: This paper constructs the first quantum algorithm for wavelet packet transforms with a tree structure, sometimes called wave atom transforms. Classically, wave atoms are used to construct sparse representations of differential operators, which enable fast numerical algorithms for partial differential equations. Compared to previous work, our quantum algorithm can implement a larger class of wavelet and wave atom transforms, by using an efficient representation for a larger class of possible tree structures. Our quantum implementation has $O(\mathrm{poly}(n))$ gate complexity for the transform of dimension $2^n$, while classical implementations have $O(n 2^n)$ floating point operations. The result can be used to improve existing quantum algorithms for solving hyperbolic partial differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10739v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marianna Podzorova, Yi-Kai Liu</dc:creator>
    </item>
    <item>
      <title>Graph Neural Network Surrogates for Contacting Deformable Bodies with Necessary and Sufficient Contact Detection</title>
      <link>https://arxiv.org/abs/2507.13459</link>
      <description>arXiv:2507.13459v1 Announce Type: cross 
Abstract: Surrogate models for the rapid inference of nonlinear boundary value problems in mechanics are helpful in a broad range of engineering applications. However, effective surrogate modeling of applications involving the contact of deformable bodies, especially in the context of varying geometries, is still an open issue. In particular, existing methods are confined to rigid body contact or, at best, contact between rigid and soft objects with well-defined contact planes. Furthermore, they employ contact or collision detection filters that serve as a rapid test but use only the necessary and not sufficient conditions for detection. In this work, we present a graph neural network architecture that utilizes continuous collision detection and, for the first time, incorporates sufficient conditions designed for contact between soft deformable bodies. We test its performance on two benchmarks, including a problem in soft tissue mechanics of predicting the closed state of a bioprosthetic aortic valve. We find a regularizing effect on adding additional contact terms to the loss function, leading to better generalization of the network. These benefits hold for simple contact at similar planes and element normal angles, and complex contact at differing planes and element normal angles. We also demonstrate that the framework can handle varying reference geometries. However, such benefits come with high computational costs during training, resulting in a trade-off that may not always be favorable. We quantify the training cost and the resulting inference speedups on various hardware architectures. Importantly, our graph neural network implementation results in up to a thousand-fold speedup for our benchmark problems at inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13459v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Vijay K. Dubey (The University of Texas at Austin), Collin E. Haese (The University of Texas at Austin), Osman G\"ultekin (The University of Texas at Austin), David Dalton (University of Glasgow), Manuel K. Rausch (The University of Texas at Austin), Jan N. Fuhg (The University of Texas at Austin)</dc:creator>
    </item>
    <item>
      <title>Expansive Natural Neural Gradient Flows for Energy Minimization</title>
      <link>https://arxiv.org/abs/2507.13475</link>
      <description>arXiv:2507.13475v1 Announce Type: cross 
Abstract: This paper develops expansive gradient dynamics in deep neural network-induced mapping spaces. Specifically, we generate tools and concepts for minimizing a class of energy functionals in an abstract Hilbert space setting covering a wide scope of applications such as PDEs-based inverse problems and supervised learning. The approach hinges on a Hilbert space metric in the full diffeomorphism mapping space, which could be viewed as a generalized Wasserstein-2 metric. We then study a projection gradient descent method within deep neural network parameterized sets. More importantly, we develop an adaptation and expanding strategy to step-by-step enlarge the deep neural network structures. In particular, the expansion mechanism aims to enhance the alignment of the neural manifold induced natural gradient direction as well as possible with the ideal Hilbert space gradient descent direction leveraging the fact that we can evaluate projections of the Hilbert space gradient. We demonstrate the efficacy of the proposed strategy for several simple model problems for energies arising in the context of supervised learning, model reduction, or inverse problems. In particular, we highlight the importance of assembling the neural flow matrix based on the inner product for the ambient Hilbert space. The actual algorithms are the simplest specifications of a broader spectrum based on a correspondingly wider discussion, postponing a detailed analysis to forthcoming work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13475v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wolfgang Dahmen, Wuchen Li, Yuankai Teng, Zhu Wang</dc:creator>
    </item>
    <item>
      <title>On the time integration for phase field modeling of grain growth in additive manufacturing</title>
      <link>https://arxiv.org/abs/2507.13492</link>
      <description>arXiv:2507.13492v1 Announce Type: cross 
Abstract: Phase field simulations play a key role in the understanding of microstructure evolution in additive manufacturing. However, they have been found extremely computationally expensive. One of the reasons is the small time step requirement to resolve the complex microstructure evolution during the rapid solidification process. This paper investigates the possibility of using a class of stabilized time integration algorithms to accelerate such phase field simulations by increasing the time steps. The specific time integration formulation and theoretical analysis on energy stability were developed, based on a phase field model dedicated to simulating rapid solidification in additive manufacturing. The numerical results confirmed that the proposed method can ensure the numerical stability and a decreasing energy requirement for the phase field simulations with at least two orders-of-magnitude larger time steps over conventional explicit methods. 2D and 3D phase field simulations have been conducted with relevant physical and kinetic parameters for 316L stainless steels. This work provides a numerical framework for efficient phase field simulations and open numerous opportunities for large scale phase field modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13492v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaoqian Yuan, Chinnapat Panwisawas, Ye Lu</dc:creator>
    </item>
    <item>
      <title>Gradient descent avoids strict saddles with a simple line-search method too</title>
      <link>https://arxiv.org/abs/2507.13804</link>
      <description>arXiv:2507.13804v1 Announce Type: cross 
Abstract: It is known that gradient descent (GD) on a $C^2$ cost function generically avoids strict saddle points when using a small, constant step size. However, no such guarantee existed for GD with a line-search method. We provide one for a modified version of the standard Armijo backtracking method with generic, arbitrarily large initial step size. In contrast to previous works, our analysis does not require a globally Lipschitz gradient.
  We extend this to the Riemannian setting (RGD), assuming the retraction is real analytic (though the cost function still only needs to be $C^2$). In closing, we also improve guarantees for RGD with a constant step size in some scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13804v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreea-Alexandra Mu\c{s}at, Nicolas Boumal</dc:creator>
    </item>
    <item>
      <title>Two efficient block preconditioners for the mass-conserved Ohta-Kawasaki equation</title>
      <link>https://arxiv.org/abs/1910.09297</link>
      <description>arXiv:1910.09297v3 Announce Type: replace 
Abstract: In this paper, we propose two efficient block preconditioners to solve the mass-conserved Ohta-Kawasaki equation with finite element discretization. We also study the spectral distribution of these two preconditioners, \textit{i.e.,} Schur complement preconditioner and the modified Hermitian and skew-Hermitian splitting (MHSS in short) preconditioner. Besides, Newton method and Picard method are used to address the implicitly nonlinear term. We rigorously analyze the convergence of Newton method. Finally, we offer numerical examples to support the theoretical analysis and indicate the efficiency of the proposed preconditioners for the mass-conserved Ohta-Kawasaki equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:1910.09297v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Zhang, Shifeng Li, Kai Jiang</dc:creator>
    </item>
    <item>
      <title>An Iteratively Decoupled Algorithm for Multiple-Network Poroelastic Model with Applications in Brain Edema Simulations</title>
      <link>https://arxiv.org/abs/2310.15457</link>
      <description>arXiv:2310.15457v4 Announce Type: replace 
Abstract: In this work, we present an iteratively decoupled algorithm for solving the quasi-static multiple-network poroelastic model. Our approach employs a total-pressure-based formulation with solid displacement, total pressure, and network pressures as primary unknowns. This reformulation decomposes the original problem into a generalized Stokes problem and a parabolic problem, offering key advantages such as reduced elastic locking effects and simplified discretization. The algorithm guarantees unconditional convergence to the solution of the fully coupled system. Numerical experiments demonstrate the accuracy, efficiency, and robustness of the method with respect to physical parameters and discretization. We further apply the algorithm to simulate the brain edema process, showcasing its practical utility in biomechanical modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.15457v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Mingchao Cai, Meng Lei, Jingzhi Li, Jiaao Sun, Feng Wang</dc:creator>
    </item>
    <item>
      <title>Data-Driven Reduced-Order Models for Port-Hamiltonian Systems with Operator Inference</title>
      <link>https://arxiv.org/abs/2501.02183</link>
      <description>arXiv:2501.02183v2 Announce Type: replace 
Abstract: Hamiltonian operator inference has been developed in [Sharma, H., Wang, Z., Kramer, B., Physica D: Nonlinear Phenomena, 431, p.133122, 2022] to learn structure-preserving reduced-order models (ROMs) for Hamiltonian systems. The method constructs a low-dimensional model using only data and knowledge of the functional form of the Hamiltonian. The resulting ROMs preserve the intrinsic structure of the system, ensuring that the mechanical and physical properties of the system are maintained. In this work, we extend this approach to port-Hamiltonian systems, which generalize Hamiltonian systems by including energy dissipation, external input, and output. Based on snapshots of the system's state and output, together with the information about the functional form of the Hamiltonian, reduced operators are inferred through optimization and are then used to construct data-driven ROMs. To further alleviate the complexity of evaluating nonlinear terms in the ROMs, a hyper-reduction method via discrete empirical interpolation is applied. Accordingly, we derive error estimates for the ROM approximations of the state and output. Finally, we demonstrate the structure preservation, as well as the accuracy of the proposed port-Hamiltonian operator inference framework, through numerical experiments on a linear mass-spring-damper problem and a nonlinear Toda lattice problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02183v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuwei Geng, Lili Ju, Boris Kramer, Zhu Wang</dc:creator>
    </item>
    <item>
      <title>PASE: A Massively Parallel Augmented Subspace Eigensolver for Large Scale Eigenvalue Problems</title>
      <link>https://arxiv.org/abs/2502.04589</link>
      <description>arXiv:2502.04589v2 Announce Type: replace 
Abstract: In this paper, we present a novel parallel augmented subspace method and build a package Parallel Augmented Subspace Eigensolver (PASE) for solving large scale eigenvalue problems by the massively parallel finite element discretization. Based on the augmented subspace, solving high dimensional eigenvalue problems can be transformed to solving the corresponding linear equations and low dimensional eigenvalue problems on the augmented subspace. Thus the complexity of solving the eigenvalue problems by augmented subspace method will be comparable to that of solving the same dimensinal linear equations. In order to improve the scalability and efficiency, we also present some implementing techniques for the parallel augmented subspace method. Based on parallel augmented subspace method and the concerned implementing techniques, a package PASE is built for solving large scale eigenvalue problems. Some numerical examples are provided to validate the efficiency and scalability of the proposed numerical methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04589v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yangfei Liao, Haochen Liu, Hehu Xie, Zijing Wang</dc:creator>
    </item>
    <item>
      <title>Efficient numerical method for the Schr\"{o}dinger equation with high-contrast potentials</title>
      <link>https://arxiv.org/abs/2502.06158</link>
      <description>arXiv:2502.06158v2 Announce Type: replace 
Abstract: In this paper, we study the Schr\"{o}dinger equation in the semiclassical regime and with multiscale potential function. We develop the so-called constraint energy minimization generalized multiscale finite element method (CEM-GMsFEM), in the framework of Crank-Nicolson (CN) discretization in time. The localized multiscale basis functions are constructed by addressing the spectral problem and a constrained energy minimization problem related to the Hamiltonian norm. A first-order convergence in the energy norm and second-order convergence in the $L^2$ norm for our numerical scheme are shown, with a relation between oversampling number in the CEM-GMsFEM method, spatial mesh size and the semiclassical parameter provided. Furthermore, we demonstrate the convergence of the proposed Crank-Nicolson CEM-GMsFEM scheme. The convergence requires $H/\sqrt{\Lambda}=O(\varepsilon^{\frac{5}{4}})$, $\Delta t=O(\varepsilon^{\frac{5}{4}})$ if $\varepsilon\leq \delta$; while if $\delta&lt;\varepsilon$, the convergence requires $H/\sqrt{\Lambda}=O(\varepsilon^{\frac{1}{4}}\delta)$, $\Delta t=O(\frac{\delta^2}{\varepsilon^{3/4}})$ (where $H$ represents the maximum diameter of coarse elements, $\Lambda$ is the minimal eigenvalue associated with the eigenvector not included in the auxiliary space, $\Delta t$ is the time step, $0 &lt; \varepsilon\ll 1$ is the Planck constant and $\delta$ describes the multiscale structure of the potential).Several numerical examples including 1D and 2D in space, with high-contrast potential are conducted to demonstrate the efficiency and accuracy of our proposed scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06158v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xingguang Jin, Liu Liu, Xiang Zhong, Eric T. Chung</dc:creator>
    </item>
    <item>
      <title>An Efficient Iterative Decoupling Method for Thermo-Poroelasticity Based on a Four-Field Formulation</title>
      <link>https://arxiv.org/abs/2502.13445</link>
      <description>arXiv:2502.13445v2 Announce Type: replace 
Abstract: This paper studies the thermo-poroelasticity model. By introducing an intermediate variable, we transform the original three-field model into a four-field model. Building upon this four-field model, we present both a coupled finite element method and a decoupled iterative finite element method. We prove the stability and optimal convergence of the coupled finite element method. Furthermore, we establish the convergence of the decoupled iterative method. This paper focuses primarily on analyzing the iterative decoupled algorithm. It demonstrates that the algorithm's convergence does not require any additional assumptions about physical parameters or stabilization parameters. Numerical results are provided to demonstrate the effectiveness and theoretical validity of these new methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13445v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mingchao Cai, Jingzhi Li, Ziliang Li, Qiang Liu</dc:creator>
    </item>
    <item>
      <title>The Riemannian Convex Bundle Method</title>
      <link>https://arxiv.org/abs/2402.13670</link>
      <description>arXiv:2402.13670v3 Announce Type: replace-cross 
Abstract: We introduce the convex bundle method to solve convex, non-smooth optimization problems on Riemannian manifolds of bounded sectional curvature. Each step of our method is based on a model that involves the convex hull of previously collected subgradients, parallelly transported into the current serious iterate. This approach generalizes the dual form of classical bundle subproblems in Euclidean space. We prove that, under mild conditions, the convex bundle method converges to a minimizer. Several numerical examples implemented using Manopt$.$jl illustrate the performance of the proposed method and compare it to the subgradient method, the cyclic proximal point algorithm, as well as the proximal bundle method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13670v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <category>math.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ronny Bergmann, Roland Herzog, Hajg Jasa</dc:creator>
    </item>
    <item>
      <title>Nearest Neighbors GParareal: Improving Scalability of Gaussian Processes for Parallel-in-Time Solvers</title>
      <link>https://arxiv.org/abs/2405.12182</link>
      <description>arXiv:2405.12182v2 Announce Type: replace-cross 
Abstract: With the advent of supercomputers, multi-processor environments and parallel-in-time (PinT) algorithms offer ways to solve initial value problems for ordinary and partial differential equations (ODEs and PDEs) over long time intervals, a task often unfeasible with sequential solvers within realistic time frames. A recent approach, GParareal, combines Gaussian Processes with traditional PinT methodology (Parareal) to achieve faster parallel speed-ups. The method is known to outperform Parareal for low-dimensional ODEs and a limited number of computer cores. Here, we present Nearest Neighbors GParareal (nnGParareal), a novel data-enriched PinT integration algorithm. nnGParareal builds upon GParareal by improving its scalability properties for higher-dimensional systems and increased processor count. Through data reduction, the model complexity is reduced from cubic to log-linear in the sample size, yielding a fast and automated procedure to integrate initial value problems over long time intervals. First, we provide both an upper bound for the error and theoretical details on the speed-up benefits. Then, we empirically illustrate the superior performance of nnGParareal, compared to GParareal and Parareal, on nine different systems with unique features (e.g., stiff, chaotic, high-dimensional, or challenging-to-learn systems).</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12182v2</guid>
      <category>stat.CO</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guglielmo Gattiglio, Lyudmila Grigoryeva, Massimiliano Tamborrino</dc:creator>
    </item>
    <item>
      <title>On the optimal approximation of Sobolev and Besov functions using deep ReLU neural networks</title>
      <link>https://arxiv.org/abs/2409.00901</link>
      <description>arXiv:2409.00901v3 Announce Type: replace-cross 
Abstract: This paper studies the problem of how efficiently functions in the Sobolev spaces $\mathcal{W}^{s,q}([0,1]^d)$ and Besov spaces $\mathcal{B}^s_{q,r}([0,1]^d)$ can be approximated by deep ReLU neural networks with width $W$ and depth $L$, when the error is measured in the $L^p([0,1]^d)$ norm. This problem has been studied by several recent works, which obtained the approximation rate $\mathcal{O}((WL)^{-2s/d})$ up to logarithmic factors when $p=q=\infty$, and the rate $\mathcal{O}(L^{-2s/d})$ for networks with fixed width when the Sobolev embedding condition $1/q -1/p&lt;s/d$ holds. We generalize these results by showing that the rate $\mathcal{O}((WL)^{-2s/d})$ indeed holds under the Sobolev embedding condition. It is known that this rate is optimal up to logarithmic factors. The key tool in our proof is a novel encoding of sparse vectors by using deep ReLU neural networks with varied width and depth, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00901v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.acha.2025.101797</arxiv:DOI>
      <dc:creator>Yunfei Yang</dc:creator>
    </item>
    <item>
      <title>$\epsilon$-rank and the Staircase Phenomenon: New Insights into Neural Network Training Dynamics</title>
      <link>https://arxiv.org/abs/2412.05144</link>
      <description>arXiv:2412.05144v3 Announce Type: replace-cross 
Abstract: Understanding the training dynamics of deep neural networks (DNNs), particularly how they evolve low-dimensional features from high-dimensional data, remains a central challenge in deep learning theory. In this work, we introduce the concept of $\epsilon$-rank, a novel metric quantifying the effective feature of neuron functions in the terminal hidden layer. Through extensive experiments across diverse tasks, we observe a universal staircase phenomenon: during training process implemented by the standard stochastic gradient descent methods, the decline of the loss function is accompanied by an increase in the $\epsilon$-rank and exhibits a staircase pattern. Theoretically, we rigorously prove a negative correlation between the loss lower bound and $\epsilon$-rank, demonstrating that a high $\epsilon$-rank is essential for significant loss reduction. Moreover, numerical evidences show that within the same deep neural network, the $\epsilon$-rank of the subsequent hidden layer is higher than that of the previous hidden layer. Based on these observations, to eliminate the staircase phenomenon, we propose a novel pre-training strategy on the initial hidden layer that elevates the $\epsilon$-rank of the terminal hidden layer. Numerical experiments validate its effectiveness in reducing training time and improving accuracy across various tasks. Therefore, the newly introduced concept of $\epsilon$-rank is a computable quantity that serves as an intrinsic effective metric characteristic for deep neural networks, providing a novel perspective for understanding the training dynamics of neural networks and offering a theoretical foundation for designing efficient training strategies in practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05144v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiang Yang, Yuxiang Zhao, Quanhui Zhu</dc:creator>
    </item>
  </channel>
</rss>
