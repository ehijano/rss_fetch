<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Jun 2024 04:00:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Method for finding solution to "quasidifferentiable" differential inclusion</title>
      <link>https://arxiv.org/abs/2406.15384</link>
      <description>arXiv:2406.15384v1 Announce Type: new 
Abstract: The paper explores the differential inclusion of a special form. It is supposed that the support function of the set in the right-hand side of an inclusion may contain the sum of the maximum and the minimum of the finite number of continuously differentiable (in phase coordinates) functions. It is required to find a trajectory that would satisfy differential inclusion with the boundary conditions prescribed and simultaneously lie on the surface given. We give substantial examples of problems where such differential inclusions may occur: models of discontinuous systems, linear control systems where the control function or/and disturbance of the right-hand side is/are known to be subject to some nonsmooth (in phase vector) constraints, some real mechanical models and differential inclusions per se with special geometrical structure of the right-hand side. The initial problem is reduced to a variational one. It is proved that the resulting functional to be minimized is quasidifferentiable. The necessary minimum conditions in terms of quasidifferential are formulated. The steepest (or the quasidifferential) descent method in a classical form is then applied to find stationary points of the functional obtained. Herewith, the functional is constructed in such a way that one can verify whether the stationary point constructed is indeed a global minimum point of the problem. The ``weak'' convergence of the method proposed is proved for some particular cases. The method constructed is illustrated by numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15384v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Fominyh</dc:creator>
    </item>
    <item>
      <title>A novel dual-stage algorithm for capacitated arc routing problems with time-dependent service costs</title>
      <link>https://arxiv.org/abs/2406.15416</link>
      <description>arXiv:2406.15416v1 Announce Type: new 
Abstract: This paper focuses on solving the capacitated arc routing problem with time-dependent service costs (CARPTDSC), which is motivated by winter gritting applications. In the current literature, exact algorithms designed for CARPTDSC can only handle small-scale instances, while heuristic algorithms fail to obtain high-quality solutions. To overcome these limitations, we propose a novel dual-stage algorithm, called MAENS-GN, that consists of a routing stage and a vehicle departure time optimization stage. The former obtains the routing plan, while the the latter determines the vehicle departure time. Importantly, existing literature often ignores the characteristic information contained in the relationship between the route cost and the vehicle departure time. The most significant innovation in this paper lies in the exploitation of this characteristic information during the vehicle departure time optimization stage. Specifically, we conduct a detailed analysis of this relationship under various scenarios and employ tailored methods to obtain the (approximately) optimal vehicle departure time. Furthermore, we propose an improved initialization strategy that considers time-dependent characteristics to achieve better solution quality. In addition to the modified benchmark test sets, we also experiment on a real-world test set. Experimental results demonstrate that MAENS-GN can obtain high-quality solutions on both small-scale and larger-scale instances of CARPTDSC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15416v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingya Li, Shengcai Liu, Juan Zou, Ke Tang</dc:creator>
    </item>
    <item>
      <title>Sufficient D-Stability Conditions for Non-Square Matrices</title>
      <link>https://arxiv.org/abs/2406.15440</link>
      <description>arXiv:2406.15440v1 Announce Type: new 
Abstract: This note explores the extension of D-stability to non-square matrices, applicable to distributed/decentralized controllability analysis. We first present a definition of D-stability for non-square matrices, directly extending from square matrices. We propose sufficient conditions for specific configurations of non-square matrices. Finally, we consider the selection of configurations to ensure the D-stability of a given non-square system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15440v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhao Tong, Steven W. Su</dc:creator>
    </item>
    <item>
      <title>A Note for CPS Data-driven Approaches Developed in the IDS Lab</title>
      <link>https://arxiv.org/abs/2406.15496</link>
      <description>arXiv:2406.15496v1 Announce Type: new 
Abstract: The rapid evolution of Cyber-Physical Systems (CPS) across various domains like mobility systems, networked control systems, sustainable manufacturing, smart power grids, and the Internet of Things necessitates innovative solutions that merge control and learning [1]. Traditional model-based control methodologies often fail to adapt to the dynamism and complexity of modern CPS. This report outlines a comprehensive approach undertaken by the Information and Decision Science (IDS) Lab, focusing on integrating data-driven techniques with control strategies to enhance CPS performance, particularly in the context of energy efficiency and environmental impact. CPS are intricate networks where physical and software components are deeply intertwined, operating as systems of systems. These systems are characterized by their informationally decentralized nature, posing significant challenges in optimization and control. Classical control methods depend heavily on precise models, which often do not capture the full complexity of real-world CPS. As these systems generate large volumes of real-time data, there is a growing need for control algorithms that can leverage this data effectively. The IDS Lab is at the forefront of developing such data-driven approaches for CPS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15496v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas A. Malikopoulos</dc:creator>
    </item>
    <item>
      <title>Data representation with optimal transport</title>
      <link>https://arxiv.org/abs/2406.15503</link>
      <description>arXiv:2406.15503v1 Announce Type: new 
Abstract: Optimal transport has been used to define bijective nonlinear transforms and different transport-related metrics for discriminating data and signals. Here we briefly describe the advances in this topic with the main applications and properties in each case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15503v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Roc\'io D\'iaz Mart\'in, Ivan V. Medri, Gustavo Kunde Rohde</dc:creator>
    </item>
    <item>
      <title>Stochastic Scheduling with Abandonments via Greedy Strategies</title>
      <link>https://arxiv.org/abs/2406.15691</link>
      <description>arXiv:2406.15691v1 Announce Type: new 
Abstract: Motivated by applications where impatience is pervasive and service times are uncertain, we study a scheduling model where jobs may depart at an unknown point in time and service times are stochastic. Initially, we have access to a single server and $n$ jobs with known non-negative values: these jobs have unknown stochastic service and departure times with known distributional information, which we assume to be independent. When the server is free, we can run an available job which occupies the server for an unknown amount of time, and collect its value. The objective is to maximize the expected total value obtained from jobs run on the server. Natural formulations of this problem suffer from the curse of dimensionality. In fact, this problem is NP-hard even in the deterministic case. Hence, we focus on efficiently computable approximation algorithms that can provide high expected reward compared to the optimal expected value. Towards this end, we first provide a compact linear programming (LP) relaxation that gives an upper bound on the expected value obtained by the optimal policy. Then we design a polynomial-time algorithm that is nearly a $(1/2)\cdot (1-1/e)$-approximation to the optimal LP value (so also to the optimal expected value). We next shift our focus to the case of independent and identically distributed (i.i.d.) service times. In this case, we show that the greedy policy that always runs the highest-valued job whenever the server is free obtains a $1/2$-approximation to the optimal expected value. Our approaches extend effortlessly and we demonstrate their flexibility by providing approximations to natural extensions of our problem. Finally, we evaluate our LP-based policies and the greedy policy empirically on synthetic and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15691v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yihua Xu, Rohan Ghuge, Sebastian Perez-Salazar</dc:creator>
    </item>
    <item>
      <title>Efficient Low-rank Identification via Accelerated Iteratively Reweighted Nuclear Norm Minimization</title>
      <link>https://arxiv.org/abs/2406.15713</link>
      <description>arXiv:2406.15713v1 Announce Type: new 
Abstract: This paper considers the problem of minimizing the sum of a smooth function and the Schatten-$p$ norm of the matrix. Our contribution involves proposing accelerated iteratively reweighted nuclear norm methods designed for solving the nonconvex low-rank minimization problem. Two major novelties characterize our approach. Firstly, the proposed method possesses a rank identification property, enabling the provable identification of the "correct" rank of the stationary point within a finite number of iterations. Secondly, we introduce an adaptive updating strategy for smoothing parameters. This strategy automatically fixes parameters associated with zero singular values as constants upon detecting the "correct" rank while quickly driving the rest parameters to zero. This adaptive behavior transforms the algorithm into one that effectively solves smooth problems after a few iterations, setting our work apart from existing iteratively reweighted methods for low-rank optimization. We prove the global convergence of the proposed algorithm, guaranteeing that every limit point of the iterates is a critical point. Furthermore, a local convergence rate analysis is provided under the Kurdyka-{\L}ojasiewicz property. We conduct numerical experiments using both synthetic and real data to showcase our algorithm's efficiency and superiority over existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15713v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wang, Ye Wang, Xiangyu Yang</dc:creator>
    </item>
    <item>
      <title>Complexity of Adagrad and other first-order methods for nonconvex optimization problems with bounds and convex constraints</title>
      <link>https://arxiv.org/abs/2406.15793</link>
      <description>arXiv:2406.15793v1 Announce Type: new 
Abstract: A parametric class of trust-region algorithms for constrained nonconvex optimization is analyzed, where the objective function is never computed. By defining appropriate first-order stationarity criteria, we are able to extend the Adagrad method to the newly considered problem and retrieve the standard complexity rate of the projected gradient method that uses both the gradient and objective function values. Furthermore, we propose an additional iteration-dependent scaling with slightly inferior theoretical guarantees. In both cases, the bounds are essentially sharp, and curvature information can be used to compute the stepsize. The adaptation of the algorithm to the convex constrained case is discussed, and initial experimental results for noisy bound-constrained instances illustrate the benefits of the objective-free approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15793v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Serge Gratton, Sadok Jerad, Philippe L. Toint</dc:creator>
    </item>
    <item>
      <title>Blackwell optimality and policy stability for long-run risk sensitive stochastic control</title>
      <link>https://arxiv.org/abs/2406.15952</link>
      <description>arXiv:2406.15952v1 Announce Type: new 
Abstract: This paper analyzes the stability of optimal policies in the long-run stochastic control framework with an averaged risk-sensitive criterion for discrete-time MDPs on finite state-action space. In particular, we study the robustness of optimal controls when perturbations to the risk-aversion parameter are applied, and investigate the Blackwell property, together with its link to the risk-sensitive vanishing discount approximation framework. Finally, we present examples that help to better understand the intricacies of the risk-sensitive control framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15952v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicole B\"auerle, Marcin Pitera, {\L}ukasz Stettner</dc:creator>
    </item>
    <item>
      <title>Single Element Error Correction/ in a Euclidean Distance Matrix</title>
      <link>https://arxiv.org/abs/2406.15969</link>
      <description>arXiv:2406.15969v1 Announce Type: new 
Abstract: We consider the \emph{exact} error correction of a noisy Euclidean distance matrix, EDM, where the elements are the squared distances between $n$ points in $R^d$. For our problem we are given two facts: (i) the embedding dimension, $d$, (ii) \emph{exactly one} distance in the data is corrupted by \emph{nonzero noise}. But we do \underline{not} know the magnitude nor position of the noise. Thus there is a combinatorial element to the problem. We present three solution techniques. These use three divide and conquer strategies in combination with three versions of facial reduction that use: exposing vectors, facial vectors, and Gale transforms. This sheds light on the connections between the various forms of facial reduction related to Gale transforms. Our highly successful empirics confirm the success of these approaches as we can solve huge problems of the order of $100,000$ nodes in approximately one minute to machine precision. \\Our algorithm depends on identifying whether a principal submatrix of the \EDM contains the corrupted element. We provide a theorem for doing this that is related to the existing results for identifying \emph{yielding} elements, i.e.,~we provide a characterization for guaranteeing the perturbed EDM remains an EDM with embedding dimension $d$. The characterization is particularly simple in the $d=2$ case. \\In addition, we characterize when the intuitive approach of the nearest EDM problem, solves our problem. In fact, we show that this happens if, and only if, the original distance element is $0$, degenerate, and the perturbation is negative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15969v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdo Alfakih, Woosuk L. Jung, Henry Wolkowicz, Tina Xu</dc:creator>
    </item>
    <item>
      <title>Multi-Period Stochastic Logistic Hub Capacity Planning for Relay Transportation</title>
      <link>https://arxiv.org/abs/2406.16010</link>
      <description>arXiv:2406.16010v1 Announce Type: new 
Abstract: This study focuses on relay transport carriers (RTCs) that contract with hub providers to lease hub capacity and employ relay transportation via hubs. It enables long-haul freight shipments to be transported by multiple short-haul drivers commuting between fixed-base hubs, promoting a driver-friendly approach. Inspired by Physical Internet, our paper addresses the multi-period capacity planning of logistic hubs within relay networks, accounting for uncertainty in demand and travel times. We model the problem as a two-stage stochastic optimization to determine the dynamic logistic hub throughput capacities for each planning period, ensuring the fulfillment of logistic demand while simultaneously minimizing both hub and transportation costs. This optimization problem falls within the NP-hard complexity class. To alleviate the inherent challenges in solving this problem, we employ a scenario reduction algorithm based on the fast forward selection (FFS) method to reduce computational effort while preserving approximation quality. Experiments with an automotive-delivery RTC in the Southeastern US demonstrate that our capacity planning model enables RTCs to proactively respond to dynamic circumstances, curtail avoidable expenditures, and enhance overall logistical efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16010v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyue Liu, Jingze Li, Mathieu Dahan, Benoit Montreuil</dc:creator>
    </item>
    <item>
      <title>A four-operator splitting algorithm for nonconvex and nonsmooth optimization</title>
      <link>https://arxiv.org/abs/2406.16025</link>
      <description>arXiv:2406.16025v1 Announce Type: new 
Abstract: In this work, we address a class of nonconvex nonsmooth optimization problems where the objective function is the sum of two smooth functions (one of which is proximable) and two nonsmooth functions (one weakly convex and proximable and the other continuous and weakly concave). We introduce a new splitting algorithm that extends the Davis-Yin splitting (DYS) algorithm to handle such four-term nonconvex nonsmooth problems. We prove that with appropriately chosen step sizes, our algorithm exhibits global subsequential convergence to stationary points with a stationarity measure converging at a rate of $1/k$. When specialized to the setting of the DYS algorithm, our results allow for larger stepsizes compared to existing bounds in the literature. Experimental results demonstrate the practical applicability and effectiveness of our proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16025v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Harold Alcantara, Ching-pei Lee, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Lipschitz continuity of solution multifunctions of extended $\ell_1$ regularization problems</title>
      <link>https://arxiv.org/abs/2406.16053</link>
      <description>arXiv:2406.16053v1 Announce Type: new 
Abstract: In this paper we obtain a verifiable sufficient condition for a polyhedral multifunction to be Lipschitz continuous on its domain. We apply this sufficient condition to establish the Lipschitz continuity of the solution multifunction for an extended $\ell_1$ regularization problem with respect to the regularization parameter and the observation parameter under the assumption that the data matrix is of full row rank. In doing so, we show that the solution multifunction is a polyhedral one by expressing its graph as the union of the polyhedral cones constructed by the index sets defined by nonempty faces of the feasible set of an extended dual $\ell_1$ regularization problem. We demonstrate that the domain of the solution multifunction is partitioned as the union of the projections of the above polyhedral cones onto the parameters space and that the graph of the restriction of the multifunction on each of these projections is convex. In comparing with the existing result of the local Lipschitz continuity of the Lasso problem in the literature where certain linear independence condition was assumed, our condition (i.e., full row rank of data matrix) is very weak and our result (i.e., Lipschitz continuity on the domain) is much more stronger. As corollaries of the Lipschitz continuity of the solution multifunction, we show that the single-valuedness and linearity (or piecewise linearity) of the solution multifunction on a particular polyhedral set of the domain are equivalent to certain linear independence conditions of the corresponding columns of the data matrix proposed in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16053v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Kaiwen Meng, Pengcheng Wu, Xiaoqi Yang</dc:creator>
    </item>
    <item>
      <title>An accessibility condition for discrete-time linear systems on Lie groups</title>
      <link>https://arxiv.org/abs/2406.16237</link>
      <description>arXiv:2406.16237v1 Announce Type: new 
Abstract: In this paper, we characterize the accessibility of discrete-time linear control systems on Lie groups. Using an exceptional notion of derivative, we construct a subalgebra $\mathfrak{h}$ based on the infinitesimal automorphism of the system such that if its dimension is maximal, the system is accessible. Our criteria provide simple conditions in a general context for the discrete-time case. Additionally, we prove a sufficient condition for local controllability at the identity using the infinitesimal automorphism, akin to the ad-rank condition in the continuous case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16237v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thiago Matheus Cavalheiro, Alexandre Jos\'e Santana, Eduardo Celso Viscovini</dc:creator>
    </item>
    <item>
      <title>On a variant of Schu's lemma</title>
      <link>https://arxiv.org/abs/2406.16378</link>
      <description>arXiv:2406.16378v1 Announce Type: new 
Abstract: In this note we show that a false statement obtained by replacing a "lim" by "limsup" for a sequence in Lemma 1.3 of the paper [J. Schu: Weak and strong convergence to fixed points of asymptotically nonexpansive mappings, Bull. Austral. Math. Soc. 43 (1991), 153--159] is used in many papers. We do not know which is the first paper that used that false assertion, but the first one that we identified is from 2005 and the last one is from 2024.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16378v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C. Zalinescu</dc:creator>
    </item>
    <item>
      <title>An irreversible investment problem with a learning-by-doing feature</title>
      <link>https://arxiv.org/abs/2406.16493</link>
      <description>arXiv:2406.16493v1 Announce Type: new 
Abstract: We study a model of irreversible investment for a decision-maker who has the possibility to gradually invest in a project with unknown value. In this setting, we introduce and explore a feature of "learning-by-doing", where the learning rate of the unknown project value is increasing in the decision-maker's level of investment in the project. We show that, under some conditions on the functional dependence of the learning rate on the level of investment (the "signal-to-noise" ratio), the optimal strategy is to invest gradually in the project so that a two-dimensional sufficient statistic reflects below a monotone boundary. Moreover, this boundary is characterised as the solution of a differential problem. Finally, we also formulate and solve a discrete version of the problem, which mirrors and complements the continuous version.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16493v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Ekstr\"om, Yerkin Kitapbayev, Alessandro Milazzo, Topias Tolonen-Weckstr\"om</dc:creator>
    </item>
    <item>
      <title>Optimal Control of the Nonlinear Stochastic Fokker--Planck Equation</title>
      <link>https://arxiv.org/abs/2406.16512</link>
      <description>arXiv:2406.16512v1 Announce Type: new 
Abstract: We consider a control problem for the nonlinear stochastic Fokker--Planck equation. This equation describes the evolution of the distribution of nonlocally interacting particles affected by a common source of noise. The system is directed by a controller that acts on the drift term with the goal of minimising a cost functional. We establish the well-posedness of the state equation, prove the existence of optimal controls, and formulate a stochastic maximum principle (SMP) that provides necessary and sufficient optimality conditions for the control problem. The adjoint process arising in the SMP is characterised by a nonlocal (semi)linear backward SPDE for which we study existence and uniqueness. We also rigorously connect the control problem for the nonlinear stochastic Fokker--Planck equation to the control of the corresponding McKean--Vlasov SDE that describes the motion of a representative particle. Our work extends existing results for the control of the Fokker--Planck equation to nonlinear and stochastic dynamics. In particular, the sufficient SMP, which we obtain by exploiting the special structure of the Fokker--Planck equation, seems to be novel even in the linear deterministic setting. We illustrate our results with an application to a model of government interventions in financial systems, supplemented by numerical illustrations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16512v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Hambly, Philipp Jettkant</dc:creator>
    </item>
    <item>
      <title>Differentiable Distributionally Robust Optimization Layers</title>
      <link>https://arxiv.org/abs/2406.16571</link>
      <description>arXiv:2406.16571v1 Announce Type: new 
Abstract: In recent years, there has been a growing research interest in decision-focused learning, which embeds optimization problems as a layer in learning pipelines and demonstrates a superior performance than the prediction-focused approach. However, for distributionally robust optimization (DRO), a popular paradigm for decision-making under uncertainty, it is still unknown how to embed it as a layer, i.e., how to differentiate decisions with respect to an ambiguity set. In this paper, we develop such differentiable DRO layers for generic mixed-integer DRO problems with parameterized second-order conic ambiguity sets and discuss its extension to Wasserstein ambiguity sets. To differentiate the mixed-integer decisions, we propose a novel dual-view methodology by handling continuous and discrete parts of decisions via different principles. Specifically, we construct a differentiable energy-based surrogate to implement the dual-view methodology and use importance sampling to estimate its gradient. We further prove that such a surrogate enjoys the asymptotic convergency under regularization. As an application of the proposed differentiable DRO layers, we develop a novel decision-focused learning pipeline for contextual distributionally robust decision-making tasks and compare it with the prediction-focused approach in experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16571v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xutao Ma, Chao Ning, Wenli Du</dc:creator>
    </item>
    <item>
      <title>Analysis of a Class of Stochastic Component-Wise Soft-Clipping Schemes</title>
      <link>https://arxiv.org/abs/2406.16640</link>
      <description>arXiv:2406.16640v1 Announce Type: new 
Abstract: Choosing the optimization algorithm that performs best on a given machine learning problem is often delicate, and there is no guarantee that current state-of-the-art algorithms will perform well across all tasks. Consequently, the more reliable methods that one has at hand, the larger the likelihood of a good end result. To this end, we introduce and analyze a large class of stochastic so-called soft-clipping schemes with a broad range of applications. Despite the wide adoption of clipping techniques in practice, soft-clipping methods have not been analyzed to a large extent in the literature. In particular, a rigorous mathematical analysis is lacking in the general, nonlinear case. Our analysis lays a theoretical foundation for a large class of such schemes, and motivates their usage.
  In particular, under standard assumptions such as Lipschitz continuous gradients of the objective function, we give rigorous proofs of convergence in expectation. These include rates in both the convex and the non-convex case, as well as almost sure convergence to a stationary point in the non-convex case. The computational cost of the analyzed schemes is essentially the same as that of stochastic gradient descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16640v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M{\aa}ns Williamson, Monika Eisenmann, Tony Stillfjord</dc:creator>
    </item>
    <item>
      <title>Almost sure convergence of stochastic Hamiltonian descent methods</title>
      <link>https://arxiv.org/abs/2406.16649</link>
      <description>arXiv:2406.16649v1 Announce Type: new 
Abstract: Gradient normalization and soft clipping are two popular techniques for tackling instability issues and improving convergence of stochastic gradient descent (SGD) with momentum. In this article, we study these types of methods through the lens of dissipative Hamiltonian systems. Gradient normalization and certain types of soft clipping algorithms can be seen as (stochastic) implicit-explicit Euler discretizations of dissipative Hamiltonian systems, where the kinetic energy function determines the type of clipping that is applied. We make use of unified theory from dynamical systems to show that all of these schemes converge almost surely to stationary points of the objective function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16649v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M{\aa}ns Williamson, Tony Stillfjord</dc:creator>
    </item>
    <item>
      <title>Partial classification of spectrum maximizing products for pairs of $2\times2$ matrices</title>
      <link>https://arxiv.org/abs/2406.16680</link>
      <description>arXiv:2406.16680v1 Announce Type: new 
Abstract: Experiments suggest that typical finite families of square matrices admit spectrum maximizing products (SMPs), that is, products that attain the joint spectral radius (JSR). Furthermore, those SMPs are often combinatorially "simple." In this paper, we consider pairs of real $2 \times 2$ matrices. We identify regions in the space of such pairs where SMPs are guaranteed to exist and to have a simple structure. We also identify another region where SMPs may fail to exist (in fact, this region includes all known counterexamples to the finiteness conjecture), but nevertheless a Sturmian maximizing measure exists. Though our results apply to a large chunk of the space of pairs of $2 \times 2$ matrices, including for instance all pairs of non-negative matrices, they leave out certain "wild" regions where more complicated behavior is possible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16680v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Laskawiec</dc:creator>
    </item>
    <item>
      <title>Backstepping control for the sterile mosquitoes technique: stabilization of extinction equilibrium</title>
      <link>https://arxiv.org/abs/2406.16719</link>
      <description>arXiv:2406.16719v1 Announce Type: new 
Abstract: The control of a mosquito population using the sterile insect technique is considered. Building on a model-based approach, where the control input is the release rate of sterilized males, we propose a non-negative backstepping control law capable of globally stabilizing the extinction equilibrium of the system. A simulation study supports and validates the theoretical findings, showing the efficacy of the approach both on a reduced model, used for control design, and on a complete model of the mosquito population dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16719v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrea Cristofaro, Luca Rossi</dc:creator>
    </item>
    <item>
      <title>Introducing Moment: A toolkit for semi-definite programming with moment matrices</title>
      <link>https://arxiv.org/abs/2406.15559</link>
      <description>arXiv:2406.15559v1 Announce Type: cross 
Abstract: Non-commutative polynomial optimization is a powerful technique with numerous applications in quantum nonlocality, quantum key distribution, causal inference, many-body physics, amongst others. The standard approach is to reduce such optimizations to a hierarchy of semi-definite programs, which can be solved numerically using well-understood interior-point methods. A key, but computationally costly, step is the formulation of moment matrices, whose size (and hence cost) grows exponentially with the depth of the hierarchy. It is therefore essential to have highly-optimized software to construct moment matrices. Here, we introduce Moment: a toolkit that produces moment matrix relaxations from the specification of a non-commutative optimization problem. In order to obtain the absolute best performance, Moment is written in C++, and for convenience of use provides an interface via MATLAB. We benchmark Moment's performance, and see that it can be up to four orders of magnitude faster than current software with similar functionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15559v1</guid>
      <category>quant-ph</category>
      <category>cs.MS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew J. P. Garner, Mateus Ara\'ujo</dc:creator>
    </item>
    <item>
      <title>Simulation-Optimization Approaches for the Network Immunization Problem with Quarantining</title>
      <link>https://arxiv.org/abs/2406.15814</link>
      <description>arXiv:2406.15814v1 Announce Type: cross 
Abstract: Vaccination has played an important role in preventing the spread of infectious diseases. However, the limited availability of vaccines and personnel at the roll-out of a new vaccine, as well as the costs of vaccination campaigns, might limit how many people can be vaccinated. Network immunization thus focuses on selecting a fixed-size subset of individuals to vaccinate so as to minimize the disease spread. In this paper, we consider simulation-optimization approaches for this selection problem. Here, the simulation of disease spread in an activity-based contact graph allows us to consider the effect of contact tracing and a limited willingness to test and quarantine. First, we develop a stochastic programming algorithm based on sampling infection forests from the simulation. Second, we propose a genetic algorithm that is tailored to the immunization problem and combines simulation runs of different sizes to balance the time needed to find promising solutions with the uncertainty resulting from simulation. Both approaches are tested on data from a major university in Denmark and disease characteristics representing those of COVID-19. Our results show that the proposed methods are competitive with a large number of centrality-based measures over a range of disease parameters and that the proposed methods are able to outperform them for a considerable number of these instances. Finally, we compare network immunization against our previously proposed approach of limiting distinct contacts. Although, independently, network immunization has a larger impact in reducing disease spread, we show that the combination of both methods reduces the disease spread even further.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15814v1</guid>
      <category>physics.soc-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rowan Hoogervorst, Evelien van der Hurk, David Pisinger</dc:creator>
    </item>
    <item>
      <title>Approximate Bayesian Computation sequential Monte Carlo via random forests</title>
      <link>https://arxiv.org/abs/2406.15865</link>
      <description>arXiv:2406.15865v1 Announce Type: cross 
Abstract: Approximate Bayesian Computation (ABC) is a popular inference method when likelihoods are hard to come by. Practical bottlenecks of ABC applications include selecting statistics that summarize the data without losing too much information or introducing uncertainty, and choosing distance functions and tolerance thresholds that balance accuracy and computational efficiency. Recent studies have shown that ABC methods using random forest (RF) methodology perform well while circumventing many of ABC's drawbacks. However, RF construction is computationally expensive for large numbers of trees and model simulations, and there can be high uncertainty in the posterior if the prior distribution is uninformative. Here we adapt distributional random forests to the ABC setting, and introduce Approximate Bayesian Computation sequential Monte Carlo with random forests (ABC-SMC-(D)RF). This updates the prior distribution iteratively to focus on the most likely regions in the parameter space. We show that ABC-SMC-(D)RF can accurately infer posterior distributions for a wide range of deterministic and stochastic models in different scientific areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15865v1</guid>
      <category>stat.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Khanh N. Dinh, Zijin Xiang, Zhihan Liu, Simon Tavar\'e</dc:creator>
    </item>
    <item>
      <title>Sub-Riemannian geodesics on the Heisenberg 3D nil-manifold</title>
      <link>https://arxiv.org/abs/2406.16065</link>
      <description>arXiv:2406.16065v1 Announce Type: cross 
Abstract: We study the projection of the left-invariant sub-Riemannian structure on the 3D Heisenberg group $G$ to the Heisenberg 3D nil-manifold~$M$ -- the compact homogeneous space of $G$ by the discrete Heisenberg group.
  First we describe dynamical properties of the geodesic flow for $M$: periodic and dense orbits, and a dynamical characterization of the normal Hamiltonian flow of Pontryagin maximum principle. Then we obtain sharp twoside bounds of sub-Riemannian balls and distance in~$G$, and on this basis we estimate the cut time for sub-Riemannian geodesics in $M$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16065v1</guid>
      <category>math.DG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Glutsyuk, Yu. Sachkov</dc:creator>
    </item>
    <item>
      <title>Frequency Constrained MPC for Efficient Grid Side Operation of Wind Power Conversion Systems</title>
      <link>https://arxiv.org/abs/2406.16158</link>
      <description>arXiv:2406.16158v1 Announce Type: cross 
Abstract: Model predictive control (MPC) has proven its applicability in power conversion control with its fast dynamic response to reference changes while ensuring critical system constraints are satisfied. Even then, the computational burden still remains a challenge for many MPC variants. In this regard, this paper formulates an indirect MPC scheme for grid-side wind converters. A quadratic program with linear constraints is solved in a receding horizon fashion with a subsequent PWM modulator. To facilitate its solution within a few hundreds of microseconds, its decision variables (modulating signals) are restricted to a specific frequency content. This approach limits the increase in problem size due to horizon length. In case studies, the proposed MPC exhibits fast response in faults and operates the converter within its safety limits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16158v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Orcun Karaca, Georgios Darivianakis</dc:creator>
    </item>
    <item>
      <title>A Python Benchmark Functions Framework for Numerical Optimisation Problems</title>
      <link>https://arxiv.org/abs/2406.16195</link>
      <description>arXiv:2406.16195v1 Announce Type: cross 
Abstract: This work proposes a framework of benchmark functions designed to facilitate the creation of test cases for numerical optimisation techniques. The framework, written in Python 3, is designed to be easy to install, use, and expand. The collection includes some of the most used multi-modal continuous functions present in literature, which can be instantiated using an arbitrary number of dimensions. Meta-information of each benchmark function, like search boundaries and position of known optima, are included and made easily accessible through class methods. Built-in interactive visualisation capabilities, baseline techniques, and rigorous testing protocols complement the features of the framework. The framework can be found here: \url{https://gitlab.com/luca.baronti/python_benchmark_functions</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16195v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Baronti, Marco Castellani</dc:creator>
    </item>
    <item>
      <title>Jacobian Descent for Multi-Objective Optimization</title>
      <link>https://arxiv.org/abs/2406.16232</link>
      <description>arXiv:2406.16232v1 Announce Type: cross 
Abstract: Many optimization problems are inherently multi-objective. To address them, we formalize Jacobian descent (JD), a direct generalization of gradient descent for vector-valued functions. Each step of this algorithm relies on a Jacobian matrix consisting of one gradient per objective. The aggregator, responsible for reducing this matrix into an update vector, characterizes JD. While the multi-task learning literature already contains a variety of aggregators, they often lack some natural properties. In particular, the update should not conflict with any objective and should scale proportionally to the norm of each gradient. We propose a new aggregator specifically designed to satisfy this. Emphasizing conflict between objectives, we then highlight direct applications for our methods. Most notably, we introduce instance-wise risk minimization (IWRM), a learning paradigm in which the loss of each training example is considered a separate objective. On simple image classification tasks, IWRM exhibits promising results compared to the direct minimization of the average loss. The performance of our aggregator in those experiments also corroborates our theoretical findings. Lastly, as speed is the main limitation of JD, we provide a path towards a more efficient implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16232v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre Quinton, Val\'erian Rey</dc:creator>
    </item>
    <item>
      <title>Discrete-time Integral Resonant Control of Negative Imaginary Systems: Application to a High-speed Nanopositioner</title>
      <link>https://arxiv.org/abs/2406.16263</link>
      <description>arXiv:2406.16263v1 Announce Type: cross 
Abstract: We propose a discrete-time integral resonant control (IRC) approach for negative imaginary (NI) systems, which overcomes several limitations of continuous-time IRC. We show that a discrete-time IRC has a step-advanced negative imaginary property. A zero-order hold-sampled NI system can be asymptotically stabilized using a discrete-time IRC with suitable parameters. A hardware experiment is conducted where a high-speed flexure-guided nanopositioner is efficiently damped using the proposed discrete-time IRC with the discrete-time controller being implemented in FPGA hardware at the sampling rate of 1.25 MHz.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16263v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanghong Shi, Erfan Khodabakhshi, Prosanto Biswas, Ian R. Petersen, S. O. Reza Moheimani</dc:creator>
    </item>
    <item>
      <title>Gradient enhanced ADMM Algorithm for dynamic optimal transport on surfaces</title>
      <link>https://arxiv.org/abs/2406.16285</link>
      <description>arXiv:2406.16285v1 Announce Type: cross 
Abstract: A gradient enhanced ADMM algorithm for optimal transport on general surfaces is proposed in this paper. Based on Benamou and Brenier's dynamical formulation, we combine gradient recovery techniques on surfaces with the ADMM algorithm, not only improving the computational accuracy, but also providing a novel method to deal with dual variables in the algorithm. This method avoids the use of stagger grids, has better accuracy and is more robust comparing to other averaging techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16285v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guozhi Dong, Hailong Guo, Chengrun Jiang, Zuoqiang Shi</dc:creator>
    </item>
    <item>
      <title>Constrained recursive kernel density/regression estimation by stochastic quasi-gradient methods</title>
      <link>https://arxiv.org/abs/2406.16550</link>
      <description>arXiv:2406.16550v1 Announce Type: cross 
Abstract: The paper considers nonparametric kernel density/regression estimation from a stochastic optimization point of view. The estimation problem is represented through a family of stochastic optimization problems. Recursive constrained estimators are obtained by application of stochastic (quasi)gradient methods to these problems, classical kernel estimates are derived as particular cases. Accuracy and rate of convergence of the obtained estimates are established, and asymptotically optimal estimation procedure parameters are found. The case of moving density/regression is particularly studied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16550v1</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladimir Norkin, Vladimir Kirilyuk</dc:creator>
    </item>
    <item>
      <title>Cubic regularized subspace Newton for non-convex optimization</title>
      <link>https://arxiv.org/abs/2406.16666</link>
      <description>arXiv:2406.16666v1 Announce Type: cross 
Abstract: This paper addresses the optimization problem of minimizing non-convex continuous functions, which is relevant in the context of high-dimensional machine learning applications characterized by over-parametrization. We analyze a randomized coordinate second-order method named SSCN which can be interpreted as applying cubic regularization in random subspaces. This approach effectively reduces the computational complexity associated with utilizing second-order information, rendering it applicable in higher-dimensional scenarios. Theoretically, we establish convergence guarantees for non-convex functions, with interpolating rates for arbitrary subspace sizes and allowing inexact curvature estimation. When increasing subspace size, our complexity matches $\mathcal{O}(\epsilon^{-3/2})$ of the cubic regularization (CR) rate. Additionally, we propose an adaptive sampling scheme ensuring exact convergence rate of $\mathcal{O}(\epsilon^{-3/2}, \epsilon^{-3})$ to a second-order stationary point, even without sampling all coordinates. Experimental results demonstrate substantial speed-ups achieved by SSCN compared to conventional first-order methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16666v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jim Zhao, Aurelien Lucchi, Nikita Doikov</dc:creator>
    </item>
    <item>
      <title>Koopman Operator-based Detection-Isolation of Cyberattack: A Case Study on Electric Vehicle Charging</title>
      <link>https://arxiv.org/abs/2406.16780</link>
      <description>arXiv:2406.16780v1 Announce Type: cross 
Abstract: One of the key challenges towards the reliable operation of cyber-physical systems (CPS) is the threat of cyberattacks on system actuation signals and measurements. In recent years, system theoretic research has focused on effectively detecting and isolating these cyberattacks to ensure proper restorative measures. Although both model-based and model-free approaches have been used in this context, the latter are increasingly becoming more popular as complexities and model uncertainties in CPS increases. Thus, in this paper we propose a Koopman operator-based model-free cyberattack detection-isolation scheme for CPS. The algorithm uses limited system measurements for its training and generates real-time detection-isolation flags. Furthermore, we present a simulation case study to detect and isolate actuation and sensor attacks in a Lithium-ion battery system of a plug-in electric vehicle during charging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16780v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanchita Ghosh, Tanushree Roy</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of a stochastic heavy-ball method for linear ill-posed problems</title>
      <link>https://arxiv.org/abs/2406.16814</link>
      <description>arXiv:2406.16814v1 Announce Type: cross 
Abstract: In this paper we consider a stochastic heavy-ball method for solving linear ill-posed inverse problems. With suitable choices of the step-sizes and the momentum coefficients, we establish the regularization property of the method under {\it a priori} selection of the stopping index and derive the rate of convergence under a benchmark source condition on the sought solution. Numerical results are provided to test the performance of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16814v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qinian Jin, Yanjun Liu</dc:creator>
    </item>
    <item>
      <title>Tight Remainder-Form Decomposition Functions with Applications to Constrained Reachability and Guaranteed State Estimation</title>
      <link>https://arxiv.org/abs/2103.08638</link>
      <description>arXiv:2103.08638v2 Announce Type: replace 
Abstract: This paper proposes a tractable family of remainder-form mixed-monotone decomposition functions that are useful for over-approximating the image set of nonlinear mappings in reachability and estimation problems. Our approach applies to a new class of nonsmooth, discontinuous nonlinear systems that we call either-sided locally Lipschitz semicontinuous (ELLS) systems, which we show to be a strict superset of locally Lipschitz continuous (LLC) systems, thus expanding the set of systems that are formally known to be mixed-monotone. In addition, we derive lower and upper bounds for the over-approximation error and show that the lower bound is achieved with our proposed approach, i.e., our approach constructs the tightest, tractable remainder-form mixed-monotone decomposition function. Moreover, we introduce a set inversion algorithm that along with the proposed decomposition functions, can be used for constrained reachability analysis and guaranteed state estimation for continuous- and discrete-time systems with bounded noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.08638v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2023.3250515</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Automatic Control ( Volume: 68, Issue: 12, December 2023)</arxiv:journal_reference>
      <dc:creator>Mohammad Khajenejad, Sze Zheng Yong</dc:creator>
    </item>
    <item>
      <title>A Stochastic Operator Framework for Optimization and Learning with Sub-Weibull Errors</title>
      <link>https://arxiv.org/abs/2105.09884</link>
      <description>arXiv:2105.09884v4 Announce Type: replace 
Abstract: This paper proposes a framework to study the convergence of stochastic optimization and learning algorithms. The framework is modeled over the different challenges that these algorithms pose, such as (i) the presence of random additive errors (e.g. due to stochastic gradients), and (ii) random coordinate updates (e.g. due to asynchrony in distributed set-ups). The paper covers both convex and strongly convex problems, and it also analyzes online scenarios, involving changes in the data and costs. The paper relies on interpreting stochastic algorithms as the iterated application of stochastic operators, thus allowing us to use the powerful tools of operator theory. In particular, we consider operators characterized by additive errors with sub-Weibull distribution (which parameterize a broad class of errors by their tail probability), and random updates. In this framework we derive convergence results in mean and in high probability, by providing bounds to the distance of the current iteration from a solution of the optimization or learning problem. The contributions are discussed in light of federated learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.09884v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Bastianello, Liam Madden, Ruggero Carli, Emiliano Dall'Anese</dc:creator>
    </item>
    <item>
      <title>Optimizing for Strategy Diversity in the Design of Video Games</title>
      <link>https://arxiv.org/abs/2106.11538</link>
      <description>arXiv:2106.11538v2 Announce Type: replace 
Abstract: We consider the problem of designing a linear program that has diverse solutions as the right-hand side varies. This problem arises in video game settings where designers aim to have players use different "weapons" or "tactics" as they progress. We model this design question as a choice over the constraint matrix $A$ and cost vector $c$ to maximize the number of possible \emph{supports} of unique optimal solutions (what we call "loadouts") of Linear Programs $\max\{c^\top x \mid Ax \le b, x \ge 0\}$ with nonnegative data considered over all resource vectors $b$. We provide an upper bound on the optimal number of loadouts and provide a family of constructions that have an asymptotically optimal number of loadouts. The upper bound is based on a connection between our problem and the study of triangulations of point sets arising from polyhedral combinatorics, and specifically the combinatorics of the cyclic polytope. Our asymptotically optimal construction also draws inspiration from the properties of the cyclic polytope.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.11538v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oussama Hanguir, Will Ma, Christopher Thomas Ryan</dc:creator>
    </item>
    <item>
      <title>Privacy-Preserving Convex Optimization: When Differential Privacy Meets Stochastic Programming</title>
      <link>https://arxiv.org/abs/2209.14152</link>
      <description>arXiv:2209.14152v2 Announce Type: replace 
Abstract: Convex optimization finds many real-life applications, where--optimized on real data--optimization results may expose private data attributes (e.g., individual health records, commercial information), thus leading to privacy breaches. To avoid these breaches and formally guarantee privacy to optimization data owners, we develop a new privacy-preserving perturbation strategy for convex optimization programs by combining stochastic (chance-constrained) programming and differential privacy. Unlike standard noise-additive strategies, which perturb either optimization data or optimization results, we express the optimization variables as functions of the random perturbation using linear decision rules; we then optimize these rules to accommodate the perturbation within the problem's feasible region by enforcing chance constraints. This way, the perturbation is feasible and makes different, yet adjacent in the sense of a given distance function, optimization datasets statistically similar in randomized optimization results, thereby enabling probabilistic differential privacy guarantees. The chance-constrained optimization additionally internalizes the conditional value-at-risk measure to model the tolerance towards the worst-case realizations of the optimality loss w.r.t. the non-private solution. We demonstrate the privacy properties of our perturbation strategy analytically and through optimization and machine learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.14152v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vladimir Dvorkin, Ferdinando Fioretto, Pascal Van Hentenryck, Pierre Pinson, Jalal Kazempour</dc:creator>
    </item>
    <item>
      <title>Input-output linearization and decoupling of mechanical control systems</title>
      <link>https://arxiv.org/abs/2309.02872</link>
      <description>arXiv:2309.02872v3 Announce Type: replace 
Abstract: In this work, we present a problem of simultaneous input-output feedback linearization and decoupling (non-interacting) for mechanical control systems with outputs. We show that the natural requirement of preserving mechanical structure of the system and of transformations imposes supplementary conditions when compared to the classical solution of the same problem for general control systems. These conditions can be expressed using objects on the configuration space only. We illustrate our results with several examples of mechanical control systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.02872v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcin Nowicki, Witold Respondek</dc:creator>
    </item>
    <item>
      <title>Relaxed optimal control for the stochastic Landau-Lifshitz-Gilbert equation</title>
      <link>https://arxiv.org/abs/2309.12556</link>
      <description>arXiv:2309.12556v2 Announce Type: replace 
Abstract: We consider the stochastic Landau-Lifshitz-Gilbert equation, perturbed by a real-valued Wiener process. We add an external control to the effective field as an attempt to drive the magnetization to a desired state and also to control thermal fluctuations. We use the theory of Young measures to relax the given control problem along with the associated cost. We consider a control operator that can depend (possibly non-linearly) on both the control and the associated solution. Moreover, we consider a fairly general associated cost functional without any special convexity assumption. We use certain compactness arguments, along with the Jakubowski version of the Skorohod Theorem to show that the relaxed problem admits an optimal control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.12556v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soham Gokhale</dc:creator>
    </item>
    <item>
      <title>Globally Solving a Class of Bilevel Programs with Spatial Price Equilibrium Constraints</title>
      <link>https://arxiv.org/abs/2309.13502</link>
      <description>arXiv:2309.13502v3 Announce Type: replace 
Abstract: Bilevel programs with spatial price equilibrium constraints are strategic models that consider a price competition at the lower level. These models find application in facility location-price models, optimal bidding in power networks, and integration of renewable energy sources in distribution networks. In this paper, for the case where the equilibrium at the lower level can be formulated as an optimization problem, we introduce an enhanced single-level formulation based on duality and show that its relaxation is stronger than the single-level formulation obtained using KKT conditions. Compared to the literature [1, 2], this new formulation (i) is computationally friendly to global solution strategies using branch-and-bound, and (ii) can tackle instances of larger size. Further, we develop a heuristic procedure to find feasible solutions inside of the branch-and-bound tree that is effective on instances of large size and produces solutions whose objective values are close to the relaxation bound. We demonstrate the benefits of this formulation and heuristic through an extensive numerical study on synthetic instances of Equilibrium Facility Location [3] and on standard IEEE bus networks for planning renewable generation capacity under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.13502v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akshit Goyal, Jean-Philippe P. Richard</dc:creator>
    </item>
    <item>
      <title>Bregman Proximal Method for Efficient Communications under Similarity</title>
      <link>https://arxiv.org/abs/2311.06953</link>
      <description>arXiv:2311.06953v2 Announce Type: replace 
Abstract: We propose a novel distributed method for monotone variational inequalities and convex-concave saddle point problems arising in various machine learning applications such as game theory and adversarial training. By exploiting \textit{similarity} our algorithm overcomes communication bottleneck which is a major issue in distributed optimization. The proposed algorithm enjoys optimal communication complexity of $\delta/\epsilon$, where $\epsilon$ measures the non-optimality gap function, and $\delta$ is a parameter of similarity. All the existing distributed algorithms achieving this bound essentially utilize the Euclidean setup. In contrast to them, our algorithm is built upon Bregman proximal maps and it is compatible with an arbitrary Bregman divergence. Thanks to this, it has more flexibility to fit the problem geometry than algorithms with the Euclidean setup. Thereby the proposed method bridges the gap between the Euclidean and non-Euclidean setting. By using the restart technique, we extend our algorithm to variational inequalities with $\mu$-strongly monotone operator, resulting in optimal communication complexity of $\delta/\mu$ (up to a logarithmic factor). Our theoretical results are confirmed by numerical experiments on a stochastic matrix game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06953v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Beznosikov, Darina Dvinskikh, Andrei Semenov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Interconnection of (Q,S,R)-Dissipative Systems in Discrete Time</title>
      <link>https://arxiv.org/abs/2311.08088</link>
      <description>arXiv:2311.08088v3 Announce Type: replace 
Abstract: Discrete-time systems cannot be passive unless there is a direct feedthrough from the input to the output. For passivity-based control to be exploited nevertheless, some authors introduce virtual outputs, while others rely on continuous-time passivity and then apply discretization techniques that preserve passivity in discrete time. Here we argue that quadratic supply rates incorporate and extend the effect of virtual outputs, allowing one to exploit dissipativity properties directly in discrete time. We derive decentralized (Q,S,R)-dissipativity conditions for a set of nonlinear systems interconnected with arbitrary topology, so that the overall network is guaranteed to be stable. For linear systems, we develop dissipative control conditions that are linear in the supply rate matrices. To demonstrate the validity of our methods, we provide numerical examples in the context of islanded microgrids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.08088v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Martinelli, Ahmed Aboudonia, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Best of Many in Both Worlds: Online Resource Allocation with Predictions under Unknown Arrival Model</title>
      <link>https://arxiv.org/abs/2402.13530</link>
      <description>arXiv:2402.13530v2 Announce Type: replace 
Abstract: Online decision-makers often obtain predictions on future variables, such as arrivals, demands, inventories, and so on. These predictions can be generated from simple forecasting algorithms for univariate time-series, all the way to state-of-the-art machine learning models that leverage multiple time-series and additional feature information. However, the prediction accuracy is unknown to decision-makers a priori, hence blindly following the predictions can be harmful. In this paper, we address this problem by developing algorithms that utilize predictions in a manner that is robust to the unknown prediction accuracy.
  We consider the Online Resource Allocation Problem, a generic model for online decision-making, in which a limited amount of resources may be used to satisfy a sequence of arriving requests. Prior work has characterized the best achievable performances when the arrivals are either generated stochastically (i.i.d.) or completely adversarially, and shown that algorithms exist which match these bounds under both arrival models, without ``knowing'' the underlying model. To this backdrop, we introduce predictions in the form of shadow prices on each type of resource. Prediction accuracy is naturally defined to be the distance between the predictions and the actual shadow prices.
  We tightly characterize, via a formal lower bound, the extent to which any algorithm can optimally leverage predictions (that is, to ``follow'' the predictions when accurate, and ``ignore'' them when inaccurate) without knowing the prediction accuracy or the underlying arrival model. Our main contribution is then an algorithm which achieves this lower bound. Finally, we empirically validate our algorithm with a large-scale experiment on real data from the retailer H&amp;M.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13530v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lin An, Andrew A. Li, Benjamin Moseley, Gabriel Visotsky</dc:creator>
    </item>
    <item>
      <title>CBX: Python and Julia packages for consensus-based interacting particle methods</title>
      <link>https://arxiv.org/abs/2403.14470</link>
      <description>arXiv:2403.14470v2 Announce Type: replace 
Abstract: We introduce CBXPy and ConsensusBasedX.jl, Python and Julia implementations of consensus-based interacting particle systems (CBX), which generalise consensus-based optimization methods (CBO) for global, derivative-free optimisation. The raison d'\^etre of our libraries is twofold: on the one hand, to offer high-performance implementations of CBX methods that the community can use directly, while on the other, providing a general interface that can accommodate and be extended to further variations of the CBX family. Python and Julia were selected as the leading high-level languages in terms of usage and performance, as well as their popularity among the scientific computing community. Both libraries have been developed with a common ethos, ensuring a similar API and core functionality, while leveraging the strengths of each language and writing idiomatic code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14470v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.21105/joss.06611</arxiv:DOI>
      <arxiv:journal_reference>Journal of Open Source Software (2024) 9(98)</arxiv:journal_reference>
      <dc:creator>Rafael Bailo, Alethea Barbaro, Susana N. Gomes, Konstantin Riedl, Tim Roith, Claudia Totzeck, Urbain Vaes</dc:creator>
    </item>
    <item>
      <title>Convergence of SGD with momentum in the nonconvex case: A time window-based analysis</title>
      <link>https://arxiv.org/abs/2405.16954</link>
      <description>arXiv:2405.16954v2 Announce Type: replace 
Abstract: We propose a novel time window-based analysis technique to investigate the convergence properties of the stochastic gradient descent method with momentum (SGDM) in nonconvex settings. Despite its popularity, the convergence behavior of SGDM remains less understood in nonconvex scenarios. This is primarily due to the absence of a sufficient descent property and challenges in simultaneously controlling the momentum and stochastic errors in an almost sure sense. To address these challenges, we investigate the behavior of SGDM over specific time windows, rather than examining the descent of consecutive iterates as in traditional studies. This time window-based approach simplifies the convergence analysis and enables us to establish the first iterate convergence result for SGDM under the Kurdyka-Lojasiewicz (KL) property. We further provide local convergence rates which depend on the underlying KL exponent and the utilized step size schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16954v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junwen Qiu, Bohao Ma, Andre Milzarek</dc:creator>
    </item>
    <item>
      <title>Provably Feasible and Stable White-Box Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2406.01763</link>
      <description>arXiv:2406.01763v4 Announce Type: replace 
Abstract: We study the problem of Trajectory Optimization (TO) for a general class of stiff and constrained dynamic systems. We establish a set of mild assumptions, under which we show that TO converges numerically stably to a locally optimal and feasible solution up to arbitrary user-specified error tolerance. Our key observation is that all prior works use SQP as a black-box solver, where a TO problem is formulated as a Nonlinear Program (NLP) and the underlying SQP solver is not allowed to modify the NLP. Instead, we propose a white-box TO solver, where the SQP solver is informed with characteristics of the objective function and the dynamic system. It then uses these characteristics to derive approximate dynamic systems and customize the discretization schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01763v4</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zherong Pan, Yifan Zhu</dc:creator>
    </item>
    <item>
      <title>The Role of Level-Set Geometry on the Performance of PDHG for Conic Linear Optimization</title>
      <link>https://arxiv.org/abs/2406.01942</link>
      <description>arXiv:2406.01942v2 Announce Type: replace 
Abstract: We consider solving huge-scale instances of (convex) conic linear optimization problems, at the scale where matrix-factorization-free methods are attractive or necessary. The restarted primal-dual hybrid gradient method (rPDHG) -- with heuristic enhancements and GPU implementation -- has been very successful in solving huge-scale linear programming (LP) problems; however its application to more general conic convex optimization problems is not so well-studied. We analyze the theoretical and practical performance of rPDHG for general (convex) conic linear optimization, and LP as a special case thereof. We show a relationship between the geometry of the primal-dual (sub-)level sets $W_\varepsilon$ and the convergence rate of rPDHG. Specifically, we prove a bound on the convergence rate of rPDHG that improves when there is a primal-dual (sub-)level set $W_\varepsilon$ for which (i) $W_\varepsilon$ is close to the optimal solution set (in Hausdorff distance), and (ii) the ratio of the diameter to the "conic radius" of $W_\varepsilon$ is small. And in the special case of LP problems, the performance of rPDHG is bounded only by this ratio applied to the (sub-)level set corresponding to the best non-optimal extreme point. Depending on the problem instance, this ratio can take on extreme values and can result in poor performance of rPDHG both in theory and in practice. To address this issue, we show how central-path-based linear transformations -- including conic rescaling -- can markedly enhance the convergence rate of rPDHG. Furthermore, we present computational results that demonstrate how such rescalings can accelerate convergence to high-accuracy solutions, and lead to more efficient methods for huge-scale linear optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01942v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zikai Xiong, Robert M. Freund</dc:creator>
    </item>
    <item>
      <title>Stackelberg Games with $k$-Submodular Function under Distributional Risk-Receptiveness and Robustness</title>
      <link>https://arxiv.org/abs/2406.13023</link>
      <description>arXiv:2406.13023v2 Announce Type: replace 
Abstract: We study submodular optimization in adversarial context, applicable to machine learning problems such as feature selection using data susceptible to uncertainties and attacks. We focus on Stackelberg games between an attacker (or interdictor) and a defender where the attacker aims to minimize the defender's objective of maximizing a $k$-submodular function. We allow uncertainties arising from the success of attacks and inherent data noise, and address challenges due to incomplete knowledge of the probability distribution of random parameters. Specifically, we introduce Distributionally Risk-Averse $k$-Submodular Interdiction Problem (DRA $k$-SIP) and Distributionally Risk-Receptive $k$-Submodular Interdiction Problem (DRR $k$-SIP) along with finitely convergent exact algorithms for solving them. The DRA $k$-SIP solution allows risk-averse interdictor to develop robust strategies for real-world uncertainties. Conversely, DRR $k$-SIP solution suggests aggressive tactics for attackers, willing to embrace (distributional) risk to inflict maximum damage, identifying critical vulnerable components, which can be used for the defender's defensive strategies. The optimal values derived from both DRA $k$-SIP and DRR $k$-SIP offer a confidence interval-like range for the expected value of the defender's objective function, capturing distributional ambiguity. We conduct computational experiments using instances of feature selection and sensor placement problems, and Wisconsin breast cancer data and synthetic data, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13023v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seonghun Park, Manish Bansal</dc:creator>
    </item>
    <item>
      <title>Trim turnpikes for optimal control problems with symmetries</title>
      <link>https://arxiv.org/abs/2406.14286</link>
      <description>arXiv:2406.14286v2 Announce Type: replace 
Abstract: Motivated by mechanical systems with symmetries, we focus on optimal control problems possessing symmetries. Following recent works, which generalized the classical concept of static turnpike to manifold turnpike, we extend the exponential turnpike property to the exponential trim turnpike for control systems with symmetries induced by abelian or non-abelian groups. Our analysis is mainly based on the geometric reduction of control systems with symmetries. More concretely, we first reduce the control system on the quotient space and state the turnpike theorem for the reduced problem. Then we use the group properties to obtain the trim turnpike theorem for the full problem. Finally, we illustrate our results on the Kepler problem and the Rigid body problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14286v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kathrin Fla{\ss}kamp, Sofya Maslovskaya, Sina Ober-Bl\"obaum, Boris Wembe</dc:creator>
    </item>
    <item>
      <title>Function approximation by neural nets in the mean-field regime: Entropic regularization and controlled McKean-Vlasov dynamics</title>
      <link>https://arxiv.org/abs/2002.01987</link>
      <description>arXiv:2002.01987v4 Announce Type: replace-cross 
Abstract: We consider the problem of function approximation by two-layer neural nets with random weights that are "nearly Gaussian" in the sense of Kullback-Leibler divergence. Our setting is the mean-field limit, where the finite population of neurons in the hidden layer is replaced by a continuous ensemble. We show that the problem can be phrased as global minimization of a free energy functional on the space of (finite-length) paths over probability measures on the weights. This functional trades off the $L^2$ approximation risk of the terminal measure against the KL divergence of the path with respect to an isotropic Brownian motion prior. We characterize the unique global minimizer and examine the dynamics in the space of probability measures over weights that can achieve it. In particular, we show that the optimal path-space measure corresponds to the F\"ollmer drift, the solution to a McKean-Vlasov optimal control problem closely related to the classic Schr\"odinger bridge problem. While the F\"ollmer drift cannot in general be obtained in closed form, thus limiting its potential algorithmic utility, we illustrate the viability of the mean-field Langevin diffusion as a finite-time approximation under various conditions on entropic regularization. Specifically, we show that it closely tracks the F\"ollmer drift when the regularization is such that the minimizing density is log-concave.</description>
      <guid isPermaLink="false">oai:arXiv.org:2002.01987v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Belinda Tzen, Maxim Raginsky</dc:creator>
    </item>
    <item>
      <title>Projection-free Online Learning over Strongly Convex Sets</title>
      <link>https://arxiv.org/abs/2010.08177</link>
      <description>arXiv:2010.08177v2 Announce Type: replace-cross 
Abstract: To efficiently solve online problems with complicated constraints, projection-free algorithms including online frank-wolfe (OFW) and its variants have received significant interest recently. However, in the general case, existing efficient projection-free algorithms only achieved the regret bound of $O(T^{3/4})$, which is worse than the regret of projection-based algorithms, where $T$ is the number of decision rounds. In this paper, we study the special case of online learning over strongly convex sets, for which we first prove that OFW can enjoy a better regret bound of $O(T^{2/3})$ for general convex losses. The key idea is to refine the decaying step-size in the original OFW by a simple line search rule. Furthermore, for strongly convex losses, we propose a strongly convex variant of OFW by redefining the surrogate loss function in OFW. We show that it achieves a regret bound of $O(T^{2/3})$ over general convex sets and a better regret bound of $O(\sqrt{T})$ over strongly convex sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.08177v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanyu Wan, Lijun Zhang</dc:creator>
    </item>
    <item>
      <title>Underlying Flag Polymatroids</title>
      <link>https://arxiv.org/abs/2207.12221</link>
      <description>arXiv:2207.12221v3 Announce Type: replace-cross 
Abstract: We describe a natural geometric relationship between matroids and underlying flag matroids by relating the geometry of the greedy algorithm to monotone path polytopes. This perspective allows us to generalize the construction of underlying flag matroids to polymatroids. We show that the polytopes associated to underlying flag polymatroid are simple by proving that they are normally equivalent to certain nestohedra. We use this to show that polymatroids realized by subspace arrangements give rise to smooth toric varieties in flag varieties and we interpret our construction in terms of toric quotients. We give various examples that illustrate the rich combinatorial structure of flag polymatroids. Finally, we study general monotone paths on polymatroid polytopes, that relate to the enumeration of certain Young tableaux.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.12221v3</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander E. Black, Raman Sanyal</dc:creator>
    </item>
    <item>
      <title>Provable Adaptivity of Adam under Non-uniform Smoothness</title>
      <link>https://arxiv.org/abs/2208.09900</link>
      <description>arXiv:2208.09900v2 Announce Type: replace-cross 
Abstract: Adam is widely adopted in practical applications due to its fast convergence. However, its theoretical analysis is still far from satisfactory. Existing convergence analyses for Adam rely on the bounded smoothness assumption, referred to as the \emph{L-smooth condition}. Unfortunately, this assumption does not hold for many deep learning tasks. Moreover, we believe that this assumption obscures the true benefit of Adam, as the algorithm can adapt its update magnitude according to local smoothness. This important feature of Adam becomes irrelevant when assuming globally bounded smoothness. This paper studies the convergence of randomly reshuffled Adam (RR Adam) with diminishing learning rate, which is the major version of Adam adopted in deep learning tasks. We present the first convergence analysis of RR Adam without the bounded smoothness assumption. We demonstrate that RR Adam can maintain its convergence properties when smoothness is linearly bounded by the gradient norm, referred to as the \emph{$(L_0, L_1)$-smooth condition. We further compare Adam to SGD when both methods use diminishing learning rate. We refine the existing lower bound of SGD and show that SGD can be slower than Adam. To our knowledge, this is the first time that Adam and SGD are rigorously compared in the same setting and the advantage of Adam is revealed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.09900v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bohan Wang, Yushun Zhang, Huishuai Zhang, Qi Meng, Ruoyu Sun, Zhi-Ming Ma, Tie-Yan Liu, Zhi-Quan Luo, Wei Chen</dc:creator>
    </item>
    <item>
      <title>Comparison of High-Dimensional Bayesian Optimization Algorithms on BBOB</title>
      <link>https://arxiv.org/abs/2303.00890</link>
      <description>arXiv:2303.00890v3 Announce Type: replace-cross 
Abstract: Bayesian Optimization (BO) is a class of black-box, surrogate-based heuristics that can efficiently optimize problems that are expensive to evaluate, and hence admit only small evaluation budgets. BO is particularly popular for solving numerical optimization problems in industry, where the evaluation of objective functions often relies on time-consuming simulations or physical experiments. However, many industrial problems depend on a large number of parameters. This poses a challenge for BO algorithms, whose performance is often reported to suffer when the dimension grows beyond 15 variables. Although many new algorithms have been proposed to address this problem, it is not well understood which one is the best for which optimization scenario.
  In this work, we compare five state-of-the-art high-dimensional BO algorithms, with vanilla BO and CMA-ES on the 24 BBOB functions of the COCO environment at increasing dimensionality, ranging from 10 to 60 variables. Our results confirm the superiority of BO over CMA-ES for limited evaluation budgets and suggest that the most promising approach to improve BO is the use of trust regions. However, we also observe significant performance differences for different function landscapes and budget exploitation phases, indicating improvement potential, e.g., through hybridization of algorithmic components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.00890v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria Laura Santoni, Elena Raponi, Renato De Leone, Carola Doerr</dc:creator>
    </item>
    <item>
      <title>Feedback linearization through the lens of data</title>
      <link>https://arxiv.org/abs/2308.11229</link>
      <description>arXiv:2308.11229v2 Announce Type: replace-cross 
Abstract: Controlling nonlinear systems, especially when data are being used to offset uncertainties in the model, is hard. A natural approach when dealing with the challenges of nonlinear control is to reduce the system to a linear one via change of coordinates and feedback, an approach commonly known as feedback linearization. Here we consider the feedback linearization problem of an unknown system when the solution must be found using experimental data. We propose a new method that learns the change of coordinates and the linearizing controller from a library (a dictionary) of candidate functions with a simple algebraic procedure - the computation of the null space of a data-dependent matrix. Remarkably, we show that the solution is valid over the entire state space of interest and not just on the dataset used to determine the solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.11229v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C. De Persis, D. Gadginmath, F. Pasqualetti, P. Tesi</dc:creator>
    </item>
    <item>
      <title>The $\omega$-Condition Number for Optimal Preconditioning and Low Rank Generalized Jacobian Updating</title>
      <link>https://arxiv.org/abs/2308.13195</link>
      <description>arXiv:2308.13195v2 Announce Type: replace-cross 
Abstract: Preconditioning is essential in iterative methods for solving linear systems. It is also the implicit objective in updating approximations of Jacobians in optimization methods, e.g., in quasi-Newton methods. Motivated by the latter, we study a nonclassic matrix condition number, the $\omega$-condition number. We do this in the context of optimal conditioning for: (i) our application to low rank updating of generalized Jacobians; (ii) iterative methods for linear systems: (iia) clustering of eigenvalues and (iib) convergence rates.
  For a positive definite matrix, the $\omega$-condition measure is the ratio of the arithmetic and geometric means of the eigenvalues. In particular, our applications concentrate on linear systems with low rank updates of ill-conditioned positive definite matrices. These systems arise in the context of nonsmooth Newton methods using generalized Jacobians. We are able to use optimality conditions and derive explicit formulae for $\omega$-optimal preconditioners and preconditioned updates. Connections to partial Cholesky sparse preconditioners are made.
  Evaluating or estimating the classical condition number $\kappa$ can be expensive. We show that the $\omega$-condition number can be evaluated explicitly following a Cholesky or LU factorization. Moreover, the simplicity of $\omega$ allows for the derivation of formulae for optimal preconditioning in various scenarios, i.e., this avoids the need for expensive algorithmic calculations. Our empirics show that $\omega$ estimates the actual condition of a linear system significantly better. Moreover, our empirical results show a significant decrease in the number of iterations required for a requested accuracy in the residual during an iterative method, i.e., these results confirm the efficacy of using the $\omega$-condition number compared to the classical condition number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13195v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Woosuk L. Jung, David Torregrosa-Bel\'en, Henry Wolkowicz</dc:creator>
    </item>
    <item>
      <title>Theory of Compression Channels for Postselected Quantum Metrology</title>
      <link>https://arxiv.org/abs/2311.06679</link>
      <description>arXiv:2311.06679v3 Announce Type: replace-cross 
Abstract: Postselected quantum metrological scheme is especially advantageous when the final measurements are either very noisy or expensive in practical experiments. In this work, we put forward a general theory on the compression channels in postselected quantum metrology. We define the basic notions characterizing the compression quality and illuminate the underlying structure of lossless compression channels. Previous experiments on Postselected optical phase estimation and weak-value amplification are shown to be particular cases of this general theory. Furthermore, for two categories of bipartite systems, we show that the compression loss can be made arbitrarily small even when the compression channel acts only on one subsystem. These findings can be employed to distribute quantum measurements so that the measurement noise and cost are dramatically reduced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06679v3</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevLett.132.250802</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Lett. 132, 250802(2024)</arxiv:journal_reference>
      <dc:creator>Jing Yang</dc:creator>
    </item>
    <item>
      <title>Who Plays First? Optimizing the Order of Play in Stackelberg Games with Many Robots</title>
      <link>https://arxiv.org/abs/2402.09246</link>
      <description>arXiv:2402.09246v3 Announce Type: replace-cross 
Abstract: We consider the multi-agent spatial navigation problem of computing the socially optimal order of play, i.e., the sequence in which the agents commit to their decisions, and its associated equilibrium in an N-player Stackelberg trajectory game. We model this problem as a mixed-integer optimization problem over the space of all possible Stackelberg games associated with the order of play's permutations. To solve the problem, we introduce Branch and Play (B&amp;P), an efficient and exact algorithm that provably converges to a socially optimal order of play and its Stackelberg equilibrium. As a subroutine for B&amp;P, we employ and extend sequential trajectory planning, i.e., a popular multi-agent control approach, to scalably compute valid local Stackelberg equilibria for any given order of play. We demonstrate the practical utility of B&amp;P to coordinate air traffic control, swarm formation, and delivery vehicle fleets. We find that B&amp;P consistently outperforms various baselines, and computes the socially optimal equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09246v3</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haimin Hu, Gabriele Dragotto, Zixu Zhang, Kaiqu Liang, Bartolomeo Stellato, Jaime F. Fisac</dc:creator>
    </item>
  </channel>
</rss>
