<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 Aug 2024 04:08:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 23 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>SPORTSCausal: Spill-Over Time Series Causal Inference</title>
      <link>https://arxiv.org/abs/2408.11951</link>
      <description>arXiv:2408.11951v1 Announce Type: new 
Abstract: Randomized controlled trials (RCTs) have long been the gold standard for causal inference across various fields, including business analysis, economic studies, sociology, clinical research, and network learning. The primary advantage of RCTs over observational studies lies in their ability to significantly reduce noise from individual variance. However, RCTs depend on strong assumptions, such as group independence, time independence, and group randomness, which are not always feasible in real-world applications. Traditional inferential methods, including analysis of covariance (ANCOVA), often fail when these assumptions do not hold. In this paper, we propose a novel approach named \textbf{Sp}ill\textbf{o}ve\textbf{r} \textbf{T}ime \textbf{S}eries \textbf{Causal} (\verb+SPORTSCausal+), which enables the estimation of treatment effects without relying on these stringent assumptions. We demonstrate the practical applicability of \verb+SPORTSCausal+ through a real-world budget-control experiment. In this experiment, data was collected from both a 5\% live experiment and a 50\% live experiment using the same treatment. Due to the spillover effect, the vanilla estimation of the treatment effect was not robust across different treatment sizes, whereas \verb+SPORTSCausal+ provided a robust estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11951v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carol Liu</dc:creator>
    </item>
    <item>
      <title>Momentum Informed Inflation-at-Risk</title>
      <link>https://arxiv.org/abs/2408.12286</link>
      <description>arXiv:2408.12286v1 Announce Type: new 
Abstract: Growth-at-Risk has recently become a key measure of macroeconomic tail-risk, which has seen it be researched extensively. Surprisingly, the same cannot be said for Inflation-at-Risk where both tails, deflation and high inflation, are of key concern to policymakers, which has seen comparatively much less research. This paper will tackle this gap and provide estimates for Inflation-at-Risk. The key insight of the paper is that inflation is best characterised by a combination of two types of nonlinearities: quantile variation, and conditioning on the momentum of inflation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12286v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tibor Szendrei, Arnab Bhattacharjee</dc:creator>
    </item>
    <item>
      <title>Integrating an agent-based behavioral model in microtransit forecasting and revenue management</title>
      <link>https://arxiv.org/abs/2408.12577</link>
      <description>arXiv:2408.12577v1 Announce Type: new 
Abstract: As an IT-enabled multi-passenger mobility service, microtransit has the potential to improve accessibility, reduce congestion, and enhance flexibility in transportation options. However, due to its heterogeneous impacts on different communities and population segments, there is a need for better tools in microtransit forecast and revenue management, especially when actual usage data are limited. We propose a novel framework based on an agent-based mixed logit model estimated with microtransit usage data and synthetic trip data. The framework involves estimating a lower-branch mode choice model with synthetic trip data, combining lower-branch parameters with microtransit data to estimate an upper-branch ride pass subscription model, and applying the nested model to evaluate microtransit pricing and subsidy policies. The framework enables further decision-support analysis to consider diverse travel patterns and heterogeneous tastes of the total population. We test the framework in a case study with synthetic trip data from Replica Inc. and microtransit data from Arlington Via. The lower-branch model result in a rho-square value of 0.603 on weekdays and 0.576 on weekends. Predictions made by the upper-branch model closely match the marginal subscription data. In a ride pass pricing policy scenario, we show that a discount in weekly pass (from $25 to $18.9) and monthly pass (from $80 to $71.5) would surprisingly increase total revenue by $102/day. In an event- or place-based subsidy policy scenario, we show that a 100% fare discount would reduce 80 car trips during peak hours at AT&amp;T Stadium, requiring a subsidy of $32,068/year.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12577v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Xiyuan Ren, Joseph Y. J. Chow, Venktesh Pandey, Linfei Yuan</dc:creator>
    </item>
    <item>
      <title>Valuing an Engagement Surface using a Large Scale Dynamic Causal Model</title>
      <link>https://arxiv.org/abs/2408.11967</link>
      <description>arXiv:2408.11967v1 Announce Type: cross 
Abstract: With recent rapid growth in online shopping, AI-powered Engagement Surfaces (ES) have become ubiquitous across retail services. These engagement surfaces perform an increasing range of functions, including recommending new products for purchase, reminding customers of their orders and providing delivery notifications. Understanding the causal effect of engagement surfaces on value driven for customers and businesses remains an open scientific question. In this paper, we develop a dynamic causal model at scale to disentangle value attributable to an ES, and to assess its effectiveness. We demonstrate the application of this model to inform business decision-making by understanding returns on investment in the ES, and identifying product lines and features where the ES adds the most value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11967v1</guid>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhimanyu Mukerji, Sushant More, Ashwin Viswanathan Kannan, Lakshmi Ravi, Hua Chen, Naman Kohli, Chris Khawand, Dinesh Mandalapu</dc:creator>
    </item>
    <item>
      <title>An Econometric Analysis of Large Flexible Cryptocurrency-mining Consumers in Electricity Markets</title>
      <link>https://arxiv.org/abs/2408.12014</link>
      <description>arXiv:2408.12014v1 Announce Type: cross 
Abstract: In recent years, power grids have seen a surge in large cryptocurrency mining firms, with individual consumption levels reaching 700MW. This study examines the behavior of these firms in Texas, focusing on how their consumption is influenced by cryptocurrency conversion rates, electricity prices, local weather, and other factors. We transform the skewed electricity consumption data of these firms, perform correlation analysis, and apply a seasonal autoregressive moving average model for analysis. Our findings reveal that, surprisingly, short-term mining electricity consumption is not correlated with cryptocurrency conversion rates. Instead, the primary influencers are the temperature and electricity prices. These firms also respond to avoid transmission and distribution network (T\&amp;D) charges -- famously known as four Coincident peak (4CP) charges -- during summer times. As the scale of these firms is likely to surge in future years, the developed electricity consumption model can be used to generate public, synthetic datasets to understand the overall impact on power grid. The developed model could also lead to better pricing mechanisms to effectively use the flexibility of these resources towards improving power grid reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12014v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>econ.EM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Subir Majumder, Ignacio Aravena, Le Xie</dc:creator>
    </item>
    <item>
      <title>Enhancing Causal Discovery in Financial Networks with Piecewise Quantile Regression</title>
      <link>https://arxiv.org/abs/2408.12210</link>
      <description>arXiv:2408.12210v1 Announce Type: cross 
Abstract: Financial networks can be constructed using statistical dependencies found within the price series of speculative assets. Across the various methods used to infer these networks, there is a general reliance on predictive modelling to capture cross-correlation effects. These methods usually model the flow of mean-response information, or the propagation of volatility and risk within the market. Such techniques, though insightful, don't fully capture the broader distribution-level causality that is possible within speculative markets. This paper introduces a novel approach, combining quantile regression with a piecewise linear embedding scheme - allowing us to construct causality networks that identify the complex tail interactions inherent to financial markets. Applying this method to 260 cryptocurrency return series, we uncover significant tail-tail causal effects and substantial causal asymmetry. We identify a propensity for coins to be self-influencing, with comparatively sparse cross variable effects. Assessing all link types in conjunction, Bitcoin stands out as the primary influencer - a nuance that is missed in conventional linear mean-response analyses. Our findings introduce a comprehensive framework for modelling distributional causality, paving the way towards more holistic representations of causality in financial markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12210v1</guid>
      <category>q-fin.ST</category>
      <category>econ.EM</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cameron Cornell, Lewis Mitchell, Matthew Roughan</dc:creator>
    </item>
    <item>
      <title>Estimating a k-modal nonparametric mixed logit model with market-level data</title>
      <link>https://arxiv.org/abs/2309.13159</link>
      <description>arXiv:2309.13159v2 Announce Type: replace 
Abstract: We propose a group-level agent-based mixed (GLAM) logit model that is estimated using market-level choice share data. The model non-parametrically represents taste heterogeneity through market-specific parameters by solving a multiagent inverse utility maximization problem, addressing the limitations of existing market-level choice models with parametric taste heterogeneity. A case study of mode choice in New York State is conducted using synthetic population data of 53.55 million trips made by 19.53 million residents in 2019. These trips are aggregated based on population segments and census block group-level origin-destination (OD) pairs, resulting in 120,740 markets/agents. We benchmark in-sample and out-of-sample predictive performance of the GLAM logit model against multinomial logit, nested logit, inverse product differentiation logit, and random coefficient logit (RCL) models. The results show that GLAM logit outperforms benchmark models, improving the overall in-sample predictive accuracy from 78.7% to 96.71% and out-of-sample accuracy from 65.30% to 81.78%. The price elasticities and diversion ratios retrieved from GLAM logit and benchmark models exhibit similar substitution patterns among the six travel modes. GLAM logit is scalable and computationally efficient, taking less than one-tenth of the time taken to estimate the RCL model. The agent-specific parameters in GLAM logit provide additional insights such as value-of-time (VOT) across segments and regions, which has been further utilized to demonstrate its application in analyzing NYS travelers' mode choice response to the congestion pricing. The agent-specific parameters in GLAM logit facilitate their seamless integration into supply-side optimization models for revenue management and system design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.13159v2</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Xiyuan Ren, Joseph Y. J. Chow, Prateek Bansal</dc:creator>
    </item>
    <item>
      <title>Estimating Treatment Effects using Multiple Surrogates: The Role of the Surrogate Score and the Surrogate Index</title>
      <link>https://arxiv.org/abs/1603.09326</link>
      <description>arXiv:1603.09326v5 Announce Type: replace-cross 
Abstract: Estimating the long-term effects of treatments is of interest in many fields. A common challenge in estimating such treatment effects is that long-term outcomes are unobserved in the time frame needed to make policy decisions. One approach to overcome this missing data problem is to analyze treatments effects on an intermediate outcome, often called a statistical surrogate, if it satisfies the condition that treatment and outcome are independent conditional on the statistical surrogate. The validity of the surrogacy condition is often controversial. Here we exploit that fact that in modern datasets, researchers often observe a large number, possibly hundreds or thousands, of intermediate outcomes, thought to lie on or close to the causal chain between the treatment and the long-term outcome of interest. Even if none of the individual proxies satisfies the statistical surrogacy criterion by itself, using multiple proxies can be useful in causal inference. We focus primarily on a setting with two samples, an experimental sample containing data about the treatment indicator and the surrogates and an observational sample containing information about the surrogates and the primary outcome. We state assumptions under which the average treatment effect be identified and estimated with a high-dimensional vector of proxies that collectively satisfy the surrogacy assumption, and derive the bias from violations of the surrogacy assumption, and show that even if the primary outcome is also observed in the experimental sample, there is still information to be gained from using surrogates.</description>
      <guid isPermaLink="false">oai:arXiv.org:1603.09326v5</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Susan Athey, Raj Chetty, Guido Imbens, Hyunseung Kang</dc:creator>
    </item>
    <item>
      <title>$\rho$-GNF: A Copula-based Sensitivity Analysis to Unobserved Confounding Using Normalizing Flows</title>
      <link>https://arxiv.org/abs/2209.07111</link>
      <description>arXiv:2209.07111v2 Announce Type: replace-cross 
Abstract: We propose a novel sensitivity analysis to unobserved confounding in observational studies using copulas and normalizing flows. Using the idea of interventional equivalence of structural causal models, we develop $\rho$-GNF ($\rho$-graphical normalizing flow), where $\rho{\in}[-1,+1]$ is a bounded sensitivity parameter. This parameter represents the back-door non-causal association due to unobserved confounding, and which is encoded with a Gaussian copula. In other words, the $\rho$-GNF enables scholars to estimate the average causal effect (ACE) as a function of $\rho$, while accounting for various assumed strengths of the unobserved confounding. The output of the $\rho$-GNF is what we denote as the $\rho_{curve}$ that provides the bounds for the ACE given an interval of assumed $\rho$ values. In particular, the $\rho_{curve}$ enables scholars to identify the confounding strength required to nullify the ACE, similar to other sensitivity analysis methods (e.g., the E-value). Leveraging on experiments from simulated and real-world data, we show the benefits of $\rho$-GNF. One benefit is that the $\rho$-GNF uses a Gaussian copula to encode the distribution of the unobserved causes, which is commonly used in many applied settings. This distributional assumption produces narrower ACE bounds compared to other popular sensitivity analysis methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.07111v2</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sourabh Balgi, Jose M. Pe\~na, Adel Daoud</dc:creator>
    </item>
    <item>
      <title>kendallknight: Efficient Implementation of Kendall's Correlation Coefficient Computation</title>
      <link>https://arxiv.org/abs/2408.09618</link>
      <description>arXiv:2408.09618v2 Announce Type: replace-cross 
Abstract: The kendallknight package introduces an efficient implementation of Kendall's correlation coefficient computation, significantly improving the processing time for large datasets without sacrificing accuracy. The kendallknight package, following Knight (1966) and posterior literature, reduces the computational complexity resulting in drastic reductions in computation time, transforming operations that would take minutes or hours into milliseconds or minutes, while maintaining precision and correctly handling edge cases and errors. The package is particularly advantageous in econometric and statistical contexts where rapid and accurate calculation of Kendall's correlation coefficient is desirable. Benchmarks demonstrate substantial performance gains over the base R implementation, especially for large datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09618v2</guid>
      <category>stat.CO</category>
      <category>cs.DS</category>
      <category>econ.EM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mauricio Vargas Sep\'ulveda</dc:creator>
    </item>
  </channel>
</rss>
