<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Apr 2024 04:00:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Intelligent Optimization of Mine Environmental Damage Assessment and Repair Strategies Based on Deep Learning</title>
      <link>https://arxiv.org/abs/2404.01624</link>
      <description>arXiv:2404.01624v1 Announce Type: new 
Abstract: In recent decades, financial quantification has emerged and matured rapidly. For financial institutions such as funds, investment institutions are increasingly dissatisfied with the situation of passively constructing investment portfolios with average market returns, and are paying more and more attention to active quantitative strategy investment portfolios. This requires the introduction of active stock investment fund management models. Currently, in my country's stock fund investment market, there are many active quantitative investment strategies, and the algorithms used vary widely, such as SVM, random forest, RNN recurrent memory network, etc. This article focuses on this trend, using the emerging LSTM-GRU gate-controlled long short-term memory network model in the field of financial stock investment as a basis to build a set of active investment stock strategies, and combining it with SVM, which has been widely used in the field of quantitative stock investment. Comparing models such as RNN, theoretically speaking, compared to SVM that simply relies on kernel functions for high-order mapping and classification of data, neural network algorithms such as RNN and LSTM-GRU have better principles and are more suitable for processing financial stock data. Then, through multiple By comparison, it was finally found that the LSTM- GRU gate-controlled long short-term memory network has a better accuracy. By selecting the LSTM-GRU algorithm to construct a trading strategy based on the Shanghai and Shenzhen 300 Index constituent stocks, the parameters were adjusted and the neural layer connection was adjusted. Finally, It has significantly outperformed the benchmark index CSI 300 over the long term. The conclusion of this article is that the research results can provide certain quantitative strategy references for financial institutions to construct active stock investment portfolios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01624v1</guid>
      <category>cs.CE</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qishuo Cheng</dc:creator>
    </item>
    <item>
      <title>Enhancing Portfolio Optimization with Transformer-GAN Integration: A Novel Approach in the Black-Litterman Framework</title>
      <link>https://arxiv.org/abs/2404.02029</link>
      <description>arXiv:2404.02029v1 Announce Type: new 
Abstract: This study presents an innovative approach to portfolio optimization by integrating Transformer models with Generative Adversarial Networks (GANs) within the Black-Litterman (BL) framework. Capitalizing on Transformers' ability to discern long-range dependencies and GANs' proficiency in generating accurate predictive models, our method enhances the generation of refined predictive views for BL portfolio allocations. This fusion of our model with BL's structured method for merging objective views with market equilibrium offers a potent tool for modern portfolio management, outperforming traditional forecasting methods. Our integrated approach not only demonstrates the potential to improve investment decision-making but also contributes a new approach to capture the complexities of financial markets for robust portfolio optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02029v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enmin Zhu</dc:creator>
    </item>
    <item>
      <title>Detection of Temporality at Discourse Level on Financial News by Combining Natural Language Processing and Machine Learning</title>
      <link>https://arxiv.org/abs/2404.01337</link>
      <description>arXiv:2404.01337v1 Announce Type: cross 
Abstract: Finance-related news such as Bloomberg News, CNN Business and Forbes are valuable sources of real data for market screening systems. In news, an expert shares opinions beyond plain technical analyses that include context such as political, sociological and cultural factors. In the same text, the expert often discusses the performance of different assets. Some key statements are mere descriptions of past events while others are predictions. Therefore, understanding the temporality of the key statements in a text is essential to separate context information from valuable predictions. We propose a novel system to detect the temporality of finance-related news at discourse level that combines Natural Language Processing and Machine Learning techniques, and exploits sophisticated features such as syntactic and semantic dependencies. More specifically, we seek to extract the dominant tenses of the main statements, which may be either explicit or implicit. We have tested our system on a labelled dataset of finance-related news annotated by researchers with knowledge in the field. Experimental results reveal a high detection precision compared to an alternative rule-based baseline approach. Ultimately, this research contributes to the state-of-the-art of market screening by identifying predictive knowledge for financial decision making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01337v1</guid>
      <category>cs.CL</category>
      <category>cs.CE</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>q-fin.ST</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.eswa.2022.116648</arxiv:DOI>
      <dc:creator>Silvia Garc\'ia-M\'endez, Francisco de Arriba-P\'erez, Ana Barros-Vila, Francisco J. Gonz\'alez-Casta\~no</dc:creator>
    </item>
    <item>
      <title>Automatic detection of relevant information, predictions and forecasts in financial news through topic modelling with Latent Dirichlet Allocation</title>
      <link>https://arxiv.org/abs/2404.01338</link>
      <description>arXiv:2404.01338v1 Announce Type: cross 
Abstract: Financial news items are unstructured sources of information that can be mined to extract knowledge for market screening applications. Manual extraction of relevant information from the continuous stream of finance-related news is cumbersome and beyond the skills of many investors, who, at most, can follow a few sources and authors. Accordingly, we focus on the analysis of financial news to identify relevant text and, within that text, forecasts and predictions. We propose a novel Natural Language Processing (NLP) system to assist investors in the detection of relevant financial events in unstructured textual sources by considering both relevance and temporality at the discursive level. Firstly, we segment the text to group together closely related text. Secondly, we apply co-reference resolution to discover internal dependencies within segments. Finally, we perform relevant topic modelling with Latent Dirichlet Allocation (LDA) to separate relevant from less relevant text and then analyse the relevant text using a Machine Learning-oriented temporal approach to identify predictions and speculative statements. We created an experimental data set composed of 2,158 financial news items that were manually labelled by NLP researchers to evaluate our solution. The ROUGE-L values for the identification of relevant text and predictions/forecasts were 0.662 and 0.982, respectively. To our knowledge, this is the first work to jointly consider relevance and temporality at the discursive level. It contributes to the transfer of human associative discourse capabilities to expert systems through the combination of multi-paragraph topic segmentation and co-reference resolution to separate author expression patterns, topic modelling with LDA to detect relevant text, and discursive temporality analysis to identify forecasts and predictions within this text.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01338v1</guid>
      <category>cs.CL</category>
      <category>cs.CE</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>q-fin.ST</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10489-023-04452-4</arxiv:DOI>
      <dc:creator>Silvia Garc\'ia-M\'endez, Francisco de Arriba-P\'erez, Ana Barros-Vila, Francisco J. Gonz\'alez-Casta\~no, Enrique Costa-Montenegro</dc:creator>
    </item>
    <item>
      <title>BERTopic-Driven Stock Market Predictions: Unraveling Sentiment Insights</title>
      <link>https://arxiv.org/abs/2404.02053</link>
      <description>arXiv:2404.02053v1 Announce Type: cross 
Abstract: This paper explores the intersection of Natural Language Processing (NLP) and financial analysis, focusing on the impact of sentiment analysis in stock price prediction. We employ BERTopic, an advanced NLP technique, to analyze the sentiment of topics derived from stock market comments. Our methodology integrates this sentiment analysis with various deep learning models, renowned for their effectiveness in time series and stock prediction tasks. Through comprehensive experiments, we demonstrate that incorporating topic sentiment notably enhances the performance of these models. The results indicate that topics in stock market comments provide implicit, valuable insights into stock market volatility and price trends. This study contributes to the field by showcasing the potential of NLP in enriching financial analysis and opens up avenues for further research into real-time sentiment analysis and the exploration of emotional and contextual aspects of market sentiment. The integration of advanced NLP techniques like BERTopic with traditional financial analysis methods marks a step forward in developing more sophisticated tools for understanding and predicting market behaviors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02053v1</guid>
      <category>cs.CL</category>
      <category>cs.CE</category>
      <category>q-fin.ST</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enmin Zhu</dc:creator>
    </item>
    <item>
      <title>Neural Ordinary Differential Equation based Sequential Image Registration for Dynamic Characterization</title>
      <link>https://arxiv.org/abs/2404.02106</link>
      <description>arXiv:2404.02106v1 Announce Type: cross 
Abstract: Deformable image registration (DIR) is crucial in medical image analysis, enabling the exploration of biological dynamics such as organ motions and longitudinal changes in imaging. Leveraging Neural Ordinary Differential Equations (ODE) for registration, this extension work discusses how this framework can aid in the characterization of sequential biological processes. Utilizing the Neural ODE's ability to model state derivatives with neural networks, our Neural Ordinary Differential Equation Optimization-based (NODEO) framework considers voxels as particles within a dynamic system, defining deformation fields through the integration of neural differential equations. This method learns dynamics directly from data, bypassing the need for physical priors, making it exceptionally suitable for medical scenarios where such priors are unavailable or inapplicable. Consequently, the framework can discern underlying dynamics and use sequence data to regularize the transformation trajectory. We evaluated our framework on two clinical datasets: one for cardiac motion tracking and another for longitudinal brain MRI analysis. Demonstrating its efficacy in both 2D and 3D imaging scenarios, our framework offers flexibility and model agnosticism, capable of managing image sequences and facilitating label propagation throughout these sequences. This study provides a comprehensive understanding of how the Neural ODE-based framework uniquely benefits the image registration challenge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02106v1</guid>
      <category>cs.CV</category>
      <category>cs.CE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Wu, Mengjin Dong, Rohit Jena, Chen Qin, James C. Gee</dc:creator>
    </item>
    <item>
      <title>MAgNET: A Graph U-Net Architecture for Mesh-Based Simulations</title>
      <link>https://arxiv.org/abs/2211.00713</link>
      <description>arXiv:2211.00713v3 Announce Type: replace-cross 
Abstract: In many cutting-edge applications, high-fidelity computational models prove to be too slow for practical use and are therefore replaced by much faster surrogate models. Recently, deep learning techniques have increasingly been utilized to accelerate such predictions. To enable learning on large-dimensional and complex data, specific neural network architectures have been developed, including convolutional and graph neural networks. In this work, we present a novel encoder-decoder geometric deep learning framework called MAgNET, which extends the well-known convolutional neural networks to accommodate arbitrary graph-structured data. MAgNET consists of innovative Multichannel Aggregation (MAg) layers and graph pooling/unpooling layers, forming a graph U-Net architecture that is analogous to convolutional U-Nets. We demonstrate the predictive capabilities of MAgNET in surrogate modeling for non-linear finite element simulations in the mechanics of solids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.00713v3</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.engappai.2024.108055</arxiv:DOI>
      <arxiv:journal_reference>Engineering Applications of Artificial Intelligence, Volume 133, Part B, 2024, 108055</arxiv:journal_reference>
      <dc:creator>Saurabh Deshpande, St\'ephane P. A. Bordas, Jakub Lengiewicz</dc:creator>
    </item>
    <item>
      <title>Efficient tensor network simulation of IBM's largest quantum processors</title>
      <link>https://arxiv.org/abs/2309.15642</link>
      <description>arXiv:2309.15642v3 Announce Type: replace-cross 
Abstract: We show how quantum-inspired 2d tensor networks can be used to efficiently and accurately simulate the largest quantum processors from IBM, namely Eagle (127 qubits), Osprey (433 qubits) and Condor (1121 qubits). We simulate the dynamics of a complex quantum many-body system -specifically, the kicked Ising experiment considered recently by IBM in Nature 618, p. 500-505 (2023)- using graph-based Projected Entangled Pair States (gPEPS), which was proposed by some of us in PRB 99, 195105 (2019). Our results show that simple tensor updates are already sufficient to achieve very large unprecedented accuracy with remarkably low computational resources for this model. Apart from simulating the original experiment for 127 qubits, we also extend our results to 433 and 1121 qubits, and for evolution times around 8 times longer, thus setting a benchmark for the newest IBM quantum machines. We also report accurate simulations for infinitely-many qubits. Our results show that gPEPS are a natural tool to efficiently simulate quantum computers with an underlying lattice-based qubit connectivity, such as all quantum processors based on superconducting qubits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15642v3</guid>
      <category>quant-ph</category>
      <category>cond-mat.str-el</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Phys. Rev. Research 6, 013326 (2024)</arxiv:journal_reference>
      <dc:creator>Siddhartha Patra, Saeed S. Jahromi, Sukhbinder Singh, Roman Orus</dc:creator>
    </item>
    <item>
      <title>XLB: A differentiable massively parallel lattice Boltzmann library in Python</title>
      <link>https://arxiv.org/abs/2311.16080</link>
      <description>arXiv:2311.16080v3 Announce Type: replace-cross 
Abstract: The lattice Boltzmann method (LBM) has emerged as a prominent technique for solving fluid dynamics problems due to its algorithmic potential for computational scalability. We introduce XLB library, a Python-based differentiable LBM library based on the JAX platform. The architecture of XLB is predicated upon ensuring accessibility, extensibility, and computational performance, enabling scaling effectively across CPU, TPU, multi-GPU, and distributed multi-GPU or TPU systems. The library can be readily augmented with novel boundary conditions, collision models, or multi-physics simulation capabilities. XLB's differentiability and data structure is compatible with the extensive JAX-based machine learning ecosystem, enabling it to address physics-based machine learning, optimization, and inverse problems. XLB has been successfully scaled to handle simulations with billions of cells, achieving giga-scale lattice updates per second. XLB is released under the permissive Apache-2.0 license and is available on GitHub at https://github.com/Autodesk/XLB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.16080v3</guid>
      <category>physics.comp-ph</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cpc.2024.109187</arxiv:DOI>
      <dc:creator>Mohammadmehdi Ataei, Hesam Salehipour</dc:creator>
    </item>
  </channel>
</rss>
