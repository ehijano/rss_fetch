<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Jan 2025 02:27:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Coverage errors for Student's t confidence intervals comparable to those in Hall (1988)</title>
      <link>https://arxiv.org/abs/2501.07645</link>
      <description>arXiv:2501.07645v1 Announce Type: new 
Abstract: Table 1 of Hall (1988) contains asymptotic coverage error formulas for some nonparametric approximate 95% confidence intervals for the mean based on $n$ IID samples. The table includes an entry for an interval based on the central limit theorem using Gaussian quantiles and the Gaussian maximum likelihood variance estimate. It is missing an entry for the very widely used Student $t$ confidence intervals. This note makes a mild numerical correction for the Gaussian entry and provides an entry for the Student $t$ intervals. For skewness $\gamma$ and kurtosis $\kappa$, the corrected Gaussian formula is $0.14\kappa -2.16\gamma^2-3.42$ and the formula for the $t$ intervals is $0.14\kappa -2.16\gamma^2$. The impetus to revisit this estimate arose from the surprisingly robust performance of Student's t statistic in randomized quasi-Monte Carlo sampling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07645v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Art B. Owen</dc:creator>
    </item>
    <item>
      <title>Nonparametric estimation of the multivariate Spearman's footrule: a further discussion</title>
      <link>https://arxiv.org/abs/2501.07665</link>
      <description>arXiv:2501.07665v1 Announce Type: new 
Abstract: In this paper, we propose two new estimators of the multivariate rank correlation coefficient Spearman's footrule which are based on two general estimators for Average Orthant Dependence measures. We compare the new proposals with a previous estimator existing in the literature and show that the three estimators are asymptotically equivalent, but, in small samples, one of the proposed estimators outperforms the others. We also analyse Pitman efficiency of these indices to test for multivariate independence as compared to multivariate versions of Kendall's tau and Spearman's rho.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07665v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.fss.2023.02.010</arxiv:DOI>
      <arxiv:journal_reference>Fuzzy Sets and Systems, volume 467 (2023), article 108489</arxiv:journal_reference>
      <dc:creator>Ana P\'erez, Mercedes Prieto-Alaiz, Fernando Chamizo, Eckhard Liebscher, Manuel \'Ubeda-Flores</dc:creator>
    </item>
    <item>
      <title>Maximum likelihood estimation in the sparse Rasch model</title>
      <link>https://arxiv.org/abs/2501.07770</link>
      <description>arXiv:2501.07770v1 Announce Type: new 
Abstract: The Rasch model has been widely used to analyse item response data in psychometrics and educational assessments. When the number of individuals and items are large, it may be impractical to provide all possible responses. It is desirable to study sparse item response experiments. Here, we propose to use the Erd\H{o}s\textendash R\'enyi random sampling design, where an individual responds to an item with low probability $p$. We prove the uniform consistency of the maximum likelihood estimator %by developing a leave-one-out method for the Rasch model when both the number of individuals, $r$, and the number of items, $t$, approach infinity. Sampling probability $p$ can be as small as $\max\{\log r/r, \log t/t\}$ up to a constant factor, which is a fundamental requirement to guarantee the connection of the sampling graph by the theory of the Erd\H{o}s\textendash R\'enyi graph. The key technique behind this significant advancement is a powerful leave-one-out method for the Rasch model. We further establish the asymptotical normality of the MLE by using a simple matrix to approximate the inverse of the Fisher information matrix. The theoretical results are corroborated by simulation studies and an analysis of a large item-response dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07770v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pai Peng, Lianqiang Qu, Qiuping Wang, Shufang Wang, Ting Yan</dc:creator>
    </item>
    <item>
      <title>Bridging Root-$n$ and Non-standard Asymptotics: Dimension-agnostic Adaptive Inference in M-Estimation</title>
      <link>https://arxiv.org/abs/2501.07772</link>
      <description>arXiv:2501.07772v1 Announce Type: new 
Abstract: This manuscript studies a general approach to construct confidence sets for the solution of population-level optimization, commonly referred to as M-estimation. Statistical inference for M-estimation poses significant challenges due to the non-standard limiting behaviors of the corresponding estimator, which arise in settings with increasing dimension of parameters, non-smooth objectives, or constraints. We propose a simple and unified method that guarantees validity in both regular and irregular cases. Moreover, we provide a comprehensive width analysis of the proposed confidence set, showing that the convergence rate of the diameter is adaptive to the unknown degree of instance-specific regularity. We apply the proposed method to several high-dimensional and irregular statistical problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07772v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kenta Takatsu, Arun Kumar Kuchibhotla</dc:creator>
    </item>
    <item>
      <title>A portmanteau test for multivariate non-stationary functional time series with an increasing number of lags</title>
      <link>https://arxiv.org/abs/2501.00118</link>
      <description>arXiv:2501.00118v1 Announce Type: cross 
Abstract: Multivariate locally stationary functional time series provide a flexible framework for modeling complex data structures exhibiting both temporal and spatial dependencies while allowing for time-varying data generating mechanism. In this paper, we introduce a specialized portmanteau-type test tailored for assessing white noise assumptions for multivariate locally stationary functional time series without dimension reduction. A simple bootstrap procedure is proposed to implement the test because the limiting distribution can be non-standard or even does not exist. Our approach is based on a new Gaussian approximation result for a maximum of degenerate $U$-statistics of second-order functional time series, which is of independent interest. Through theoretical analysis and simulation studies, we demonstrate the efficacy and adaptability of the proposed method in detecting departures from white noise assumptions in multivariate locally stationary functional time series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00118v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lujia Bai, Holger Dette, Weichi Wu</dc:creator>
    </item>
    <item>
      <title>Mixing time for a noisy SIS model on graphs</title>
      <link>https://arxiv.org/abs/2501.07738</link>
      <description>arXiv:2501.07738v1 Announce Type: cross 
Abstract: We study the mixing time of the noisy SIS (Susceptible-Infected-Susceptible) model on graphs. The noisy SIS model is a variant of the standard SIS model, which allows individuals to become infected not just due to contacts with infected individuals but also due to external noise. We show that, under strong external noise, the mixing time is of order $O(n \log n)$. Additionally, we demonstrate that the mixing time on random graphs, namely Erd\"os--R\'enyi graphs, regular multigraphs, and Galton--Watson trees, is also of order $O(n \log n)$ with high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07738v1</guid>
      <category>math.PR</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.ST</category>
      <category>q-bio.PE</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wasiur R. KhudaBukhsh, Yangrui Xiang</dc:creator>
    </item>
    <item>
      <title>On the Statistical Capacity of Deep Generative Models</title>
      <link>https://arxiv.org/abs/2501.07763</link>
      <description>arXiv:2501.07763v1 Announce Type: cross 
Abstract: Deep generative models are routinely used in generating samples from complex, high-dimensional distributions. Despite their apparent successes, their statistical properties are not well understood. A common assumption is that with enough training data and sufficiently large neural networks, deep generative model samples will have arbitrarily small errors in sampling from any continuous target distribution. We set up a unifying framework that debunks this belief. We demonstrate that broad classes of deep generative models, including variational autoencoders and generative adversarial networks, are not universal generators. Under the predominant case of Gaussian latent variables, these models can only generate concentrated samples that exhibit light tails. Using tools from concentration of measure and convex geometry, we give analogous results for more general log-concave and strongly log-concave latent variable distributions. We extend our results to diffusion models via a reduction argument. We use the Gromov--Levy inequality to give similar guarantees when the latent variables lie on manifolds with positive Ricci curvature. These results shed light on the limited capacity of common deep generative models to handle heavy tails. We illustrate the empirical relevance of our work with simulations and financial data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07763v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edric Tam, David B. Dunson</dc:creator>
    </item>
    <item>
      <title>Distributed Nonparametric Estimation: from Sparse to Dense Samples per Terminal</title>
      <link>https://arxiv.org/abs/2501.07879</link>
      <description>arXiv:2501.07879v1 Announce Type: cross 
Abstract: Consider the communication-constrained problem of nonparametric function estimation, in which each distributed terminal holds multiple i.i.d. samples. Under certain regularity assumptions, we characterize the minimax optimal rates for all regimes, and identify phase transitions of the optimal rates as the samples per terminal vary from sparse to dense. This fully solves the problem left open by previous works, whose scopes are limited to regimes with either dense samples or a single sample per terminal. To achieve the optimal rates, we design a layered estimation protocol by exploiting protocols for the parametric density estimation problem. We show the optimality of the protocol using information-theoretic methods and strong data processing inequalities, and incorporating the classic balls and bins model. The optimal rates are immediate for various special cases such as density estimation, Gaussian, binary, Poisson and heteroskedastic regression models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07879v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deheng Yuan, Tao Guo, Zhongyi Huang</dc:creator>
    </item>
    <item>
      <title>Some observations on the ambivalent role of symmetries in Bayesian inference problems</title>
      <link>https://arxiv.org/abs/2501.07975</link>
      <description>arXiv:2501.07975v1 Announce Type: cross 
Abstract: We collect in this note some observations on the role of symmetries in Bayesian inference problems, that can be useful or detrimental depending on the way they act on the signal and on the observations. We emphasize in particular the need to gauge away unobservable invariances in the definition of a distance between a signal and its estimator, and the consequences this implies for the statistical mechanics treatment of such models, taking as a motivating example the extensive rank matrix factorization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07975v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guilhem Semerjian</dc:creator>
    </item>
    <item>
      <title>Gradient Equilibrium in Online Learning: Theory and Applications</title>
      <link>https://arxiv.org/abs/2501.08330</link>
      <description>arXiv:2501.08330v1 Announce Type: cross 
Abstract: We present a new perspective on online learning that we refer to as gradient equilibrium: a sequence of iterates achieves gradient equilibrium if the average of gradients of losses along the sequence converges to zero. In general, this condition is not implied by nor implies sublinear regret. It turns out that gradient equilibrium is achievable by standard online learning methods such as gradient descent and mirror descent with constant step sizes (rather than decaying step sizes, as is usually required for no regret). Further, as we show through examples, gradient equilibrium translates into an interpretable and meaningful property in online prediction problems spanning regression, classification, quantile estimation, and others. Notably, we show that the gradient equilibrium framework can be used to develop a debiasing scheme for black-box predictions under arbitrary distribution shift, based on simple post hoc online descent updates. We also show that post hoc gradient updates can be used to calibrate predicted quantiles under distribution shift, and that the framework leads to unbiased Elo scores for pairwise preference prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08330v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anastasios N. Angelopoulos, Michael I. Jordan, Ryan J. Tibshirani</dc:creator>
    </item>
    <item>
      <title>Assessing the size of spatial extreme events using local coefficients based on excursion sets</title>
      <link>https://arxiv.org/abs/2310.09075</link>
      <description>arXiv:2310.09075v2 Announce Type: replace 
Abstract: Extreme events arising in georeferenced processes can take various forms, such as occurring in isolated patches or stretching contiguously over large areas, and can further vary with the spatial location and the extremeness of the events. We use excursion sets above threshold exceedances in data observed over a two-dimensional grid of rectangular pixels to propose a general family of coefficients that assess spatial-extent properties relevant for risk assessment, and study five candidate coefficients from this family. These coefficients are defined locally and interpreted as a spatial distance from a reference site where the threshold is exceeded. We develop statistical inference and discuss robustness to boundary effects and resolution of the pixel grid. To statistically extrapolate coefficients towards very high threshold levels, we formulate a semiparametric model and estimate a parameter characterizing how coefficients scale with the quantile level of the threshold. The utility of the new coefficients is illustrated through simulated data, as well as in an application to gridded daily temperature in continental France. We find notable differences in estimated coefficient maps between climate model simulations and observation-based reanalysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09075v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan Cotsakis, Elena Di Bernardino, Thomas Opitz</dc:creator>
    </item>
    <item>
      <title>Consistency Theory of General Nonparametric Classification Methods in Cognitive Diagnosis</title>
      <link>https://arxiv.org/abs/2312.11437</link>
      <description>arXiv:2312.11437v3 Announce Type: replace 
Abstract: Cognitive diagnosis models have been popularly used in fields such as education, psychology, and social sciences. While parametric likelihood estimation is a prevailing method for fitting cognitive diagnosis models, nonparametric methodologies are attracting increasing attention due to their ease of implementation and robustness, particularly when sample sizes are relatively small. However, existing clustering consistency results of the nonparametric estimation methods often rely on certain restrictive conditions, which may not be easily satisfied in practice. In this article, the clustering consistency of the general nonparametric classification method is reestablished under weaker and more practical conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11437v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengyu Cui, Yanlong Liu, Gongjun Xu</dc:creator>
    </item>
    <item>
      <title>Optimal estimation of the null distribution in large-scale inference</title>
      <link>https://arxiv.org/abs/2401.06350</link>
      <description>arXiv:2401.06350v2 Announce Type: replace 
Abstract: The advent of large-scale inference has spurred reexamination of conventional statistical thinking. In a Gaussian model for $n$ many $z$-scores with at most $k &lt; \frac{n}{2}$ nonnulls, Efron suggests estimating the location and scale parameters of the null distribution. Placing no assumptions on the nonnull effects, the statistical task can be viewed as a robust estimation problem. However, the best known robust estimators fail to be consistent in the regime $k \asymp n$ which is especially relevant in large-scale inference. The failure of estimators which are minimax rate-optimal with respect to other formulations of robustness (e.g. Huber's contamination model) might suggest the impossibility of consistent estimation in this regime and, consequently, a major weakness of Efron's suggestion. A sound evaluation of Efron's model thus requires a complete understanding of consistency. We sharply characterize the regime of $k$ for which consistent estimation is possible and further establish the minimax estimation rates. It is shown consistent estimation of the location parameter is possible if and only if $\frac{n}{2} - k = \omega(\sqrt{n})$, and consistent estimation of the scale parameter is possible in the entire regime $k &lt; \frac{n}{2}$. Faster rates than those in Huber's contamination model are achievable by exploiting the Gaussian character of the data. The minimax upper bound is obtained by considering estimators based on the empirical characteristic function. The minimax lower bound involves constructing two marginal distributions whose characteristic functions match on a wide interval containing zero. The construction notably differs from those in the literature by sharply capturing a scaling of $n-2k$ in the minimax estimation rate of the location.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06350v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Subhodh Kotekal, Chao Gao</dc:creator>
    </item>
    <item>
      <title>Adaptive Ridge Approach to Heteroscedastic Regression</title>
      <link>https://arxiv.org/abs/2402.13642</link>
      <description>arXiv:2402.13642v3 Announce Type: replace 
Abstract: We propose an adaptive ridge (AR) estimation scheme for a heteroscedastic linear regression model with log-linear noise in data. We simultaneously estimate the mean and variance parameters, demonstrating new asymptotic distributional and tightness properties in a sparse setting. We also show that estimates for zero parameters shrink with more iterations under suitable assumptions for tuning parameters. Aspects of application and possible generalizations are presented through simulations and real data examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13642v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ka Long Keith Ho, Hiroki Masuda</dc:creator>
    </item>
    <item>
      <title>Bayesian Nonparametric Inference in McKean-Vlasov models</title>
      <link>https://arxiv.org/abs/2404.16742</link>
      <description>arXiv:2404.16742v3 Announce Type: replace 
Abstract: We consider nonparametric statistical inference on a periodic interaction potential $W$ from noisy discrete space-time measurements of solutions $\rho=\rho_W$ of the nonlinear McKean-Vlasov equation, describing the probability density of the mean field limit of an interacting particle system. We show how Gaussian process priors assigned to $W$ give rise to posterior mean estimators that exhibit fast convergence rates for the implied estimated densities $\bar \rho$ towards $\rho_W$. We further show that if the initial condition $\phi$ is not too smooth and satisfies a standard deconvolvability condition, then one can consistently infer Sobolev-regular potentials $W$ at convergence rates $N^{-\theta}$ for appropriate $\theta&gt;0$, where $N$ is the number of measurements. The exponent $\theta$ can be taken to approach $1/2$ as the regularity of $W$ increases corresponding to `near-parametric' models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16742v3</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richard Nickl, Grigorios A. Pavliotis, Kolyan Ray</dc:creator>
    </item>
    <item>
      <title>Least-Squares Estimator for cumulative INAR($\infty$) processes</title>
      <link>https://arxiv.org/abs/2412.01569</link>
      <description>arXiv:2412.01569v2 Announce Type: replace 
Abstract: We explore the cumulative INAR($\infty$) process, an infinite-order extension of integer-valued autoregressive models, providing deeper insights into count time series of infinite order. Introducing a novel framework, we define a distance metric within the parameter space of the INAR($\infty$) model, which improves parameter estimation capabilities. Employing a least-squares estimator, we derive its theoretical properties, demonstrating its equivalence to a norm-based metric and establishing its optimality within this framework.
  To validate the estimator's performance, we conduct comprehensive numerical experiments with sample sizes $T=200$ and $T=500$. These simulations reveal that the estimator accurately recovers the true parameters and exhibits asymptotic normality, as confirmed by statistical tests and visual assessments such as histograms and Q--Q plots. Our findings provide empirical support for the theoretical underpinnings of the cumulative INAR($\infty$) model and affirm the efficacy of the proposed estimation method. This work not only deepens the understanding of infinite-order count time series models but also establishes parallels with continuous-time Hawkes processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01569v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaohong Duan, Yingli Wang, Ping He</dc:creator>
    </item>
    <item>
      <title>On kernel mode estimation under RLT and WOD model</title>
      <link>https://arxiv.org/abs/2412.07874</link>
      <description>arXiv:2412.07874v3 Announce Type: replace 
Abstract: Let $(X_N)_{N\geq 1}$ denote a sequence of real random variables and let $\vartheta$ be the mode of the random variable of interest $X$. In this paper, we study the kernel mode estimator (say) $\vartheta_n$ when the data are widely orthant dependent (WOD) and subject to Random Left Truncation (RLT) mechanism. We establish the uniform consistency rate of the density estimator (say) $f_n$ of the underlying density $f$ as well as the almost sure convergence rate of $\vartheta_n$. The performance of the estimators are illustrated via some simulation studies and applied on a real dataset of car brake pads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07874v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohamed Kaber El Alem, Zohra Guessoum, Abdelkader Tatachak</dc:creator>
    </item>
    <item>
      <title>Multiple testing in multi-stream sequential change detection</title>
      <link>https://arxiv.org/abs/2501.04130</link>
      <description>arXiv:2501.04130v2 Announce Type: replace 
Abstract: Multi-stream sequential change detection involves simultaneously monitoring many streams of data and trying to detect when their distributions change, if at all. Here, we theoretically study multiple testing issues that arise from detecting changes in many streams. We point out that any algorithm with finite average run length (ARL) must have a trivial worst-case false detection rate (FDR), family-wise error rate (FWER), and per-family error rate (PFER); thus, any attempt to control these Type I error metrics is fundamentally in conflict with the desire for a finite ARL (which is typically necessary in order to have a small detection delay). One of our contributions is to define a new class of metrics which can be controlled, called error over patience (EOP). We propose algorithms that combine the recent e-detector framework (which generalizes the Shiryaev-Roberts and CUSUM methods) with the recent e-Benjamini-Hochberg procedure and e-Bonferroni procedures. We prove that these algorithms control the EOP at any desired level under very general dependence structures on the data within and across the streams. In fact, we prove a more general error control that holds uniformly over all stopping times and provides a smooth trade-off between the conflicting metrics. Additionally, if finiteness of the ARL is forfeited, we show that our algorithms control the Type I error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04130v2</guid>
      <category>math.ST</category>
      <category>eess.SP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanjit Dandapanthula, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Pathwise guessing in categorical time series with unbounded alphabets</title>
      <link>https://arxiv.org/abs/2501.06547</link>
      <description>arXiv:2501.06547v2 Announce Type: replace 
Abstract: The following learning problem arises naturally in various applications: Given a finite sample from a categorical or count time series, can we learn a function of the sample that (nearly) maximizes the probability of correctly guessing the values of a given portion of the data using the values from the remaining parts? Unlike the classical task of estimating conditional probabilities in a stochastic process, our approach avoids explicitly estimating these probabilities. We propose a non-parametric guessing function with a learning rate that is independent of the alphabet size. Our analysis focuses on a broad class of time series models that encompasses finite-order Markov chains, some hidden Markov chains, Poisson regression for count process, and one-dimensional Gibbs measures. Additionally, we establish a minimax lower bound for the rate of convergence of the risk associated with our guessing problem. This lower bound matches the upper bound achieved by our estimator up to a logarithmic factor, demonstrating its near-optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06547v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. -R. Chazottes, S. Gallo, D. Takahashi</dc:creator>
    </item>
    <item>
      <title>Degree-heterogeneous Latent Class Analysis for High-dimensional Discrete Data</title>
      <link>https://arxiv.org/abs/2402.18745</link>
      <description>arXiv:2402.18745v4 Announce Type: replace-cross 
Abstract: The latent class model is a widely used mixture model for multivariate discrete data. Besides the existence of qualitatively heterogeneous latent classes, real data often exhibit additional quantitative heterogeneity nested within each latent class. The modern latent class analysis also faces extra challenges, including the high-dimensionality, sparsity, and heteroskedastic noise inherent in discrete data. Motivated by these phenomena, we introduce the Degree-heterogeneous Latent Class Model and propose an easy-to-implement HeteroClustering algorithm for it. HeteroClustering uses heteroskedastic PCA with $\ell_2$ normalization to remove degree effects and perform clustering in the top singular subspace of the data matrix. We establish the result of exact clustering under minimal signal-to-noise conditions. We further investigate the estimation and inference of the high-dimensional continuous item parameters in the model, which are crucial to interpreting and finding useful markers for latent classes. We provide comprehensive procedures for global testing and multiple testing of these parameters with valid error controls. The superior performance of our methods is demonstrated through extensive simulations and applications to three diverse real-world datasets from political voting records, genetic variations, and single-cell sequencing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18745v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongyuan Lyu, Ling Chen, Yuqi Gu</dc:creator>
    </item>
    <item>
      <title>Statistical inference of convex order by Wasserstein projection</title>
      <link>https://arxiv.org/abs/2406.02840</link>
      <description>arXiv:2406.02840v3 Announce Type: replace-cross 
Abstract: Ranking distributions according to a stochastic order has wide applications in diverse areas. Although stochastic dominance has received much attention, convex order, particularly in general dimensions, has yet to be investigated from a statistical point of view. This article addresses this gap by introducing a simple statistical test for convex order based on the Wasserstein projection distance. This projection distance not only encodes whether two distributions are indeed in convex order, but also quantifies the deviation from the desired convex order and produces an optimal convex order approximation. Lipschitz stability of the backward and forward Wasserstein projection distance is proved, which leads to elegant consistency and concentration results of the estimator we employ as our test statistic. Combining these with state of the art results regarding the convergence rate of empirical distributions, we also derive upper bounds for the $p$-value and type I error of our test statistic, as well as upper bounds on the type II error for an appropriate class of strict alternatives. With proper choices of families of distributions, we further attain that the power of the proposed test increases to one as the number of samples grows to infinity. Lastly, we provide an efficient numerical scheme for our test statistic, by way of an entropic Frank-Wolfe algorithm. Experiments based on synthetic data sets illuminate the success of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02840v3</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jakwang Kim, Young-Heon Kim, Yuanlong Ruan, Andrew Warren</dc:creator>
    </item>
    <item>
      <title>Regression Adjustment for Estimating Distributional Treatment Effects in Randomized Controlled Trials</title>
      <link>https://arxiv.org/abs/2407.14074</link>
      <description>arXiv:2407.14074v2 Announce Type: replace-cross 
Abstract: In this paper, we address the issue of estimating and inferring distributional treatment effects in randomized experiments. The distributional treatment effect provides a more comprehensive understanding of treatment heterogeneity compared to average treatment effects. We propose a regression adjustment method that utilizes distributional regression and pre-treatment information, establishing theoretical efficiency gains without imposing restrictive distributional assumptions. We develop a practical inferential framework and demonstrate its advantages through extensive simulations. Analyzing water conservation policies, our method reveals that behavioral nudges systematically shift consumption from high to moderate levels. Examining health insurance coverage, we show the treatment reduces the probability of zero doctor visits by 6.6 percentage points while increasing the likelihood of 3-6 visits. In both applications, our regression adjustment method substantially improves precision and identifies treatment effects that were statistically insignificant under conventional approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14074v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tatsushi Oka, Shota Yasui, Yuta Hayakawa, Undral Byambadalai</dc:creator>
    </item>
    <item>
      <title>Sharp Matrix Empirical Bernstein Inequalities</title>
      <link>https://arxiv.org/abs/2411.09516</link>
      <description>arXiv:2411.09516v3 Announce Type: replace-cross 
Abstract: We present two sharp empirical Bernstein inequalities for symmetric random matrices with bounded eigenvalues. By sharp, we mean that both inequalities adapt to the unknown variance in a tight manner: the deviation captured by the first-order $1/\sqrt{n}$ term asymptotically matches the matrix Bernstein inequality exactly, including constants, the latter requiring knowledge of the variance. Our first inequality holds for the sample mean of independent matrices, and our second inequality holds for a mean estimator under martingale dependence at stopping times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09516v3</guid>
      <category>math.PR</category>
      <category>math.FA</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongjian Wang, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Monotone Curve Estimation via Convex Duality</title>
      <link>https://arxiv.org/abs/2501.06975</link>
      <description>arXiv:2501.06975v2 Announce Type: replace-cross 
Abstract: A principal curve serves as a powerful tool for uncovering underlying structures of data through 1-dimensional smooth and continuous representations. On the basis of optimal transport theories, this paper introduces a novel principal curve framework constrained by monotonicity with rigorous theoretical justifications. We establish statistical guarantees for our monotone curve estimate, including expected empirical and generalized mean squared errors, while proving the existence of such estimates. These statistical foundations justify adopting the popular early stopping procedure in machine learning to implement our numeric algorithm with neural networks. Comprehensive simulation studies reveal that the proposed monotone curve estimate outperforms competing methods in terms of accuracy when the data exhibits a monotonic structure. Moreover, through two real-world applications on future prices of copper, gold, and silver, and avocado prices and sales volume, we underline the robustness of our curve estimate against variable transformation, further confirming its effective applicability for noisy and complex data sets. We believe that this monotone curve-fitting framework offers significant potential for numerous applications where monotonic relationships are intrinsic or need to be imposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06975v2</guid>
      <category>stat.ME</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 15 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tongseok Lim, Kyeongsik Nam, Jinwon Sohn</dc:creator>
    </item>
  </channel>
</rss>
