<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Oct 2024 02:05:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Quantitative Monoidal Algebra: Axiomatising Distance with String Diagrams</title>
      <link>https://arxiv.org/abs/2410.09229</link>
      <description>arXiv:2410.09229v1 Announce Type: new 
Abstract: (Symmetric) monoidal theories encapsulate presentations by generators and equations for (symmetric) monoidal categories. Terms of a monoidal theory are typically represented pictorially using string diagrams. In this work we introduce and study a quantitative version of monoidal theories, where instead of equality one may reason more abstractly about distance between string diagrams. This is in analogy with quantitative algebraic theories by Mardare et al., but developed in a monoidal rather than cartesian setting. Our framework paves the way for a quantitative analysis of string diagrammatic calculi for resource-sensitive processes, as found e.g. in quantum theory, machine learning, cryptography, and digital circuit theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09229v1</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriele Lobbia, Wojciech R\'o\.zowski, Ralph Sarkis, Fabio Zanasi</dc:creator>
    </item>
    <item>
      <title>Hybrid Modal Operators for Definite Descriptions</title>
      <link>https://arxiv.org/abs/2410.10439</link>
      <description>arXiv:2410.10439v1 Announce Type: new 
Abstract: In this paper, we study computational complexity and expressive power of modal operators for definite descriptions, which correspond to statements `the modal world which satisfies formula \(varphi\)'. We show that adding such operators to the basic (propositional) modal language has a price of increasing complexity of the satisfiability problem from PSpace to ExpTime. However, if formulas corresponding to descriptions are Boolean only, there is no increase of complexity. Furthermore, we compare definite descriptions with the related operators from hybrid and counting logics. We prove that the operators for definite descriptions are strictly more expressive than hybrid operators, but strictly less expressive than counting operators. We show that over linear structures the same expressive power results hold as in the general case; in contrast, if the linear structures are isomorphic to integers, definite descriptions become as expressive as counting operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10439v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-43619-2_48</arxiv:DOI>
      <dc:creator>Przemys{\l}aw Andrzej Wa{\l}\k{e}ga, Micha{\l} Zawidzki</dc:creator>
    </item>
    <item>
      <title>Compositional Shielding and Reinforcement Learning for Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2410.10460</link>
      <description>arXiv:2410.10460v1 Announce Type: new 
Abstract: Deep reinforcement learning has emerged as a powerful tool for obtaining high-performance policies. However, the safety of these policies has been a long-standing issue. One promising paradigm to guarantee safety is a shield, which shields a policy from making unsafe actions. However, computing a shield scales exponentially in the number of state variables. This is a particular concern in multi-agent systems with many agents. In this work, we propose a novel approach for multi-agent shielding. We address scalability by computing individual shields for each agent. The challenge is that typical safety specifications are global properties, but the shields of individual agents only ensure local properties. Our key to overcome this challenge is to apply assume-guarantee reasoning. Specifically, we present a sound proof rule that decomposes a (global, complex) safety specification into (local, simple) obligations for the shields of the individual agents. Moreover, we show that applying the shields during reinforcement learning significantly improves the quality of the policies obtained for a given training budget. We demonstrate the effectiveness and scalability of our multi-agent shielding framework in two case studies, reducing the computation time from hours to seconds and achieving fast learning convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10460v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asger Horn Brorholt, Kim Guldstrand Larsen, Christian Schilling</dc:creator>
    </item>
    <item>
      <title>Effectful Mealy Machines: Bisimulation and Trace</title>
      <link>https://arxiv.org/abs/2410.10627</link>
      <description>arXiv:2410.10627v1 Announce Type: new 
Abstract: We introduce effectful Mealy machines - a general notion of Mealy machine with global effects - and give them semantics in terms of both effectful bisimilarity and traces. Bisimilarity of effectful Mealy machines is characterised syntactically in terms of uniform feedback. Traces of effectful Mealy machines are given a novel semantic coinductive universe, in terms of effectful streams. We prove that effectful streams generalise a standard notion of causal process, capturing existing flavours of Mealy machine, bisimilarity, and trace.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10627v1</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Filippo Bonchi, Elena Di Lavore, Mario Rom\'an</dc:creator>
    </item>
    <item>
      <title>A Simple Formal Language for Probabilistic Decision Problems</title>
      <link>https://arxiv.org/abs/2410.10643</link>
      <description>arXiv:2410.10643v1 Announce Type: new 
Abstract: Probabilistic puzzles can be confusing, partly because they are formulated in natural languages - full of unclarities and ambiguities - and partly because there is no widely accepted and intuitive formal language to express them. We propose a simple formal language with arrow notation ($\gets$) for sampling from a distribution and with observe statements for conditioning (updating, belief revision). We demonstrate the usefulness of this simple language by solving several famous puzzles from probabilistic decision theory. The operational semantics of our language is expressed via the (finite, discrete) subdistribution monad. Our broader message is that proper formalisation dispels confusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10643v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elena Di Lavore, Bart Jacobs, Mario Rom\'an</dc:creator>
    </item>
    <item>
      <title>Exact Exploration</title>
      <link>https://arxiv.org/abs/2410.10706</link>
      <description>arXiv:2410.10706v1 Announce Type: new 
Abstract: Recent analysis of classical algorithms resulted in their axiomatization as transition systems satisfying some simple postulates, and in the formulation of the Abstract State Machine Theorem, which assures us that any classical algorithm can be emulated step-by-step by a most general model of computation, called an ``abstract state machine''. We refine that analysis to take details of intra-step behavior into account, and show that there is in fact an abstract state machine that not only has the same state transitions as does a given algorithm but also performs the exact same tests on states when determining how to proceed to the next state. This enhancement allows the inclusion -- within the abstract-state-machine framework -- of algorithms whose states only have partially-defined equality, or employ other native partial functions, as is the case, for instance, with inversion of a matrix of computable reals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10706v1</guid>
      <category>cs.LO</category>
      <category>cs.DS</category>
      <category>cs.SE</category>
      <category>math.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>A shorter version in CSL 2010, 19th EACSL Annual Conference on Computer Science Logic, Springer Lecture Notes in Computer Science 6247, 2010, 140--154</arxiv:journal_reference>
      <dc:creator>Andreas Blass, Nachum Dershowitz, Yuri Gurevich</dc:creator>
    </item>
    <item>
      <title>Equitable Access to Justice: Logical LLMs Show Promise</title>
      <link>https://arxiv.org/abs/2410.09904</link>
      <description>arXiv:2410.09904v1 Announce Type: cross 
Abstract: The costs and complexity of the American judicial system limit access to legal solutions for many Americans. Large language models (LLMs) hold great potential to improve access to justice. However, a major challenge in applying AI and LLMs in legal contexts, where consistency and reliability are crucial, is the need for System 2 reasoning. In this paper, we explore the integration of LLMs with logic programming to enhance their ability to reason, bringing their strategic capabilities closer to that of a skilled lawyer. Our objective is to translate laws and contracts into logic programs that can be applied to specific legal cases, with a focus on insurance contracts. We demonstrate that while GPT-4o fails to encode a simple health insurance contract into logical code, the recently released OpenAI o1-preview model succeeds, exemplifying how LLMs with advanced System 2 reasoning capabilities can expand access to justice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09904v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuj Kant, Manav Kant, Marzieh Nabi, Preston Carlson, Megan Ma</dc:creator>
    </item>
    <item>
      <title>Dualformer: Controllable Fast and Slow Thinking by Learning with Randomized Reasoning Traces</title>
      <link>https://arxiv.org/abs/2410.09918</link>
      <description>arXiv:2410.09918v1 Announce Type: cross 
Abstract: In human cognition theory, human thinking is governed by two systems: the fast and intuitive System 1 and the slower but more deliberative System 2. Recent studies have shown that incorporating System 2 process into Transformers including large language models (LLMs), significantly enhances their reasoning capabilities. Nevertheless, models that purely resemble System 2 thinking require substantially higher computational costs and are much slower to respond. To address this challenge, we present Dualformer, a single Transformer model that seamlessly integrates both the fast and slow reasoning modes. Dualformer is obtained by training on data with randomized reasoning traces, where different parts of the traces are dropped during training. The dropping strategies are specifically tailored according to the trace structure, analogous to analyzing our thinking process and creating shortcuts with patterns. At inference time, our model can be configured to output only the solutions (fast mode) or both the reasoning chain and the final solution (slow mode), or automatically decide which mode to engage (auto mode). In all cases, Dualformer outperforms the corresponding baseline models in both performance and computational efficiency: (1) in slow mode, Dualformer optimally solves unseen 30 x 30 maze navigation tasks 97.6% of the time, surpassing the Searchformer (trained on data with complete reasoning traces) baseline performance of 93.3%, while only using 45.5% fewer reasoning steps; (2) in fast mode, Dualformer completes those tasks with an 80% optimal rate, significantly outperforming the Solution-Only model (trained on solution-only data), which has an optimal rate of only 30%. For math problems, our techniques have also achieved improved performance with LLM fine-tuning, showing its generalization beyond task-specific models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09918v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>DiJia Su, Sainbayar Sukhbaatar, Michael Rabbat, Yuandong Tian, Qinqing Zheng</dc:creator>
    </item>
    <item>
      <title>Measurability in the Fundamental Theorem of Statistical Learning</title>
      <link>https://arxiv.org/abs/2410.10243</link>
      <description>arXiv:2410.10243v1 Announce Type: cross 
Abstract: The Fundamental Theorem of Statistical Learning states that a hypothesis space is PAC learnable if and only if its VC dimension is finite. For the agnostic model of PAC learning, the literature so far presents proofs of this theorem that often tacitly impose several measurability assumptions on the involved sets and functions. We scrutinize these proofs from a measure-theoretic perspective in order to extract the assumptions needed for a rigorous argument. This leads to a sound statement as well as a detailed and self-contained proof of the Fundamental Theorem of Statistical Learning in the agnostic setting, showcasing the minimal measurability requirements needed. We then discuss applications in Model Theory, considering NIP and o-minimal structures. Our main theorem presents sufficient conditions for the PAC learnability of hypothesis spaces defined over o-minimal expansions of the reals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10243v1</guid>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lothar Sebastian Krapp, Laura Wirth</dc:creator>
    </item>
    <item>
      <title>A Curry-Howard Correspondence for Linear, Reversible Computation</title>
      <link>https://arxiv.org/abs/2302.11887</link>
      <description>arXiv:2302.11887v4 Announce Type: replace 
Abstract: In this paper, we present a linear and reversible programming language with inductives types and recursion. The semantics of the languages is based on pattern-matching; we show how ensuring syntactical exhaustivity and non-overlapping of clauses is enough to ensure reversibility. The language allows to represent any Primitive Recursive Function. We then give a Curry-Howard correspondence with the logic $\mu$MALL: linear logic extended with least fixed points allowing inductive statements. The critical part of our work is to show how primitive recursion yields circular proofs that satisfy $\mu$MALL validity criterion and how the language simulates the cut-elimination procedure of $\mu$MALL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.11887v4</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.CSL.2023.13</arxiv:DOI>
      <arxiv:journal_reference>31st EACSL Annual Conference on Computer Science Logic (CSL 2023)</arxiv:journal_reference>
      <dc:creator>Kostia Chardonnet, Alexis Saurin, Beno\^it Valiron</dc:creator>
    </item>
    <item>
      <title>Translating Three-Variable First-Order Predicate Logic to Relation Algebra, Implemented using Z3</title>
      <link>https://arxiv.org/abs/2308.02513</link>
      <description>arXiv:2308.02513v3 Announce Type: replace 
Abstract: This paper presents the development of a software tool that enables the translation of first-order predicate logic with at most three variables into relation algebra. The tool was developed using the Z3 theorem prover, leveraging its capabilities to enhance reliability, generate code, and expedite development. The resulting standalone Python program allows users to translate first-order logic formulas into relation algebra, eliminating the need to work with relation algebra explicitly. This paper outlines the theoretical background of first-order logic, relation algebra, and the translation process. It also describes the implementation details, including validation of the software tool using Z3 for testing correctness. By demonstrating the feasibility of utilizing first-order logic as an alternative language for expressing relation algebra, this tool paves the way for integrating first-order logic into tools traditionally relying on relation algebra as input.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.02513v3</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anthony Brogni, Sebastiaan J. C. Joosten</dc:creator>
    </item>
    <item>
      <title>A Resolution-Based Interactive Proof System for UNSAT</title>
      <link>https://arxiv.org/abs/2401.14996</link>
      <description>arXiv:2401.14996v2 Announce Type: replace 
Abstract: Modern SAT or QBF solvers are expected to produce correctness certificates. However, certificates have worst-case exponential size (unless $\textsf{NP}=\textsf{coNP}$), and at recent SAT competitions the largest certificates of unsatisfiability are starting to reach terabyte size.
  Recently, Couillard, Czerner, Esparza, and Majumdar have suggested to replace certificates with interactive proof systems based on the $\textsf{IP}=\textsf{PSPACE}$ theorem. They have presented an interactive protocol between a prover and a verifier for an extension of QBF. The overall running time of the protocol is linear in the time needed by a standard BDD-based algorithm, and the time invested by the verifier is polynomial in the size of the formula. (So, in particular, the verifier never has to read or process exponentially long certificates). We call such an interactive protocol competitive with the BDD algorithm for solving QBF.
  While BDD-algorithms are state-of-the-art for certain classes of QBF instances, no modern (UN)SAT solver is based on BDDs. For this reason, we initiate the study of interactive certification for more practical SAT algorithms. In particular, we address the question whether interactive protocols can be competitive with some variant of resolution. We present two contributions. First, we prove a theorem that reduces the problem of finding competitive interactive protocols to finding an arithmetisation of formulas satisfying certain commutativity properties. (Arithmetisation is the fundamental technique underlying the $\textsf{IP}=\textsf{PSPACE}$ theorem.) Then, we apply the theorem to give the first interactive protocol for the Davis-Putnam resolution procedure. We also report on an implementation and give some experimental results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14996v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philipp Czerner, Javier Esparza, Valentin Krasotin, Adrian Krauss</dc:creator>
    </item>
    <item>
      <title>Transformer Encoder Satisfiability: Complexity and Impact on Formal Reasoning</title>
      <link>https://arxiv.org/abs/2405.18548</link>
      <description>arXiv:2405.18548v2 Announce Type: replace 
Abstract: We analyse the complexity of the satisfiability problem (SAT) for transformer encoders (TE), naturally occurring in formal verification or interpretation tasks. We find that SAT is undecidable when considering TE as they are commonly studied in the expressiveness community. Furthermore, we identify practical scenarios where SAT is decidable and establish corresponding complexity bounds. Beyond trivial cases, we find that quantized TE -- those restricted by fixed -- width arithmetic-lead to the decidability of SAT due to their limited attention capabilities. However, the problem remains difficult, as we establish scenarios where SAT is NEXPTIME-hard and others where it is solvable in NEXPTIME for quantized TE. To complement our complexity results, we place our findings and their implications in the broader context of formal reasoning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18548v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco S\"alzer, Eric Alsmann, Martin Lange</dc:creator>
    </item>
    <item>
      <title>PolyHorn: A Polynomial Horn Clause Solver</title>
      <link>https://arxiv.org/abs/2408.03796</link>
      <description>arXiv:2408.03796v2 Announce Type: replace 
Abstract: Polynomial Horn clauses with existentially and universally quantified variables arise in many problems of verification and program analysis. We present PolyHorn which is a tool for solving polynomial Horn clauses in which variables on both sides of the implication are real valued or unbounded integers. Our tool provides a unified framework for polynomial Horn clause solving problems that arise in several papers in the literature. Our experimental evaluation over a wide range of benchmarks shows the applicability of the tool as well as its benefits as opposed to simply using existing SMT solvers to solve such constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03796v2</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krishnendu Chatterjee, Amir Kafshdar Goharshady, Ehsan Kafshdar Goharshady, Mehrdad Karrabi, Milad Saadat, Maximilian Seeliger, {\DJ}or{\dj}e \v{Z}ikeli\'c</dc:creator>
    </item>
    <item>
      <title>A Mathematical Model of Package Management Systems</title>
      <link>https://arxiv.org/abs/2302.05417</link>
      <description>arXiv:2302.05417v3 Announce Type: replace-cross 
Abstract: This paper brings mathematical tools to bear on the study of package dependencies in software systems. We introduce structures known as Dependency Structures with Choice (DSC) that provide a mathematical account of such dependencies, inspired by the definition of general event structures in the study of concurrency. We equip DSCs with a particular notion of morphism and show that the category of DSCs is isomorphic to the category of antimatroids. We study the exactness properties of these equivalent categories, and show that they are finitely complete, have finite coproducts but not all coequalizers. Further, we construct a functor from a category of DSCs equipped with a certain subclass of morphisms to the opposite of the category of finite distributive lattices, making use of a simple finite characterization of the Bruns-Lakser completion, and finally, we introduce a formal account of versions of packages and introduce a mathematical account of package version-bound policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.05417v3</guid>
      <category>math.CT</category>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Gershom Bazerman, Emilio Minichiello, Raymond Puzio</dc:creator>
    </item>
    <item>
      <title>Conditional and Modal Reasoning in Large Language Models</title>
      <link>https://arxiv.org/abs/2401.17169</link>
      <description>arXiv:2401.17169v4 Announce Type: replace-cross 
Abstract: The reasoning abilities of large language models (LLMs) are the topic of a growing body of research in AI and cognitive science. In this paper, we probe the extent to which twenty-nine LLMs are able to distinguish logically correct inferences from logically fallacious ones. We focus on inference patterns involving conditionals (e.g., 'If Ann has a queen, then Bob has a jack') and epistemic modals (e.g., 'Ann might have an ace', 'Bob must have a king'). These inferences have been of special interest to logicians, philosophers, and linguists, since they play a central role in the fundamental human ability to reason about distal possibilities. Assessing LLMs on these inferences is thus highly relevant to the question of how much the reasoning abilities of LLMs match those of humans. All the LLMs we tested make some basic mistakes with conditionals or modals, though zero-shot chain-of-thought prompting helps them make fewer mistakes. Even the best performing LLMs make basic errors in modal reasoning, display logically inconsistent judgments across inference patterns involving epistemic modals and conditionals, and give answers about complex conditional inferences that do not match reported human judgments. These results highlight gaps in basic logical reasoning in today's LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17169v4</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday, Matthew Mandelkern, Cedegao E. Zhang</dc:creator>
    </item>
    <item>
      <title>On the formalization of the notion of an interactive algorithm</title>
      <link>https://arxiv.org/abs/2405.19037</link>
      <description>arXiv:2405.19037v2 Announce Type: replace-cross 
Abstract: An earlier paper gives an account of a quest for a satisfactory formalization of the classical informal notion of an algorithm. In this paper, an attempt is made to generalize the results of that quest to the informal notion of an interactive algorithm. The notion of an interactive proto-algorithm is introduced. Interactive algorithms are expected to be equivalence classes of interactive proto-algorithms under an appropriate equivalence relation. As in the non-interactive case, three equivalence relations are defined. Two of them are deemed to be bounds for an appropriate equivalence relation and the third is likely an appropriate one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19037v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>C. A. Middelburg</dc:creator>
    </item>
    <item>
      <title>Process-Driven Autoformalization in Lean 4</title>
      <link>https://arxiv.org/abs/2406.01940</link>
      <description>arXiv:2406.01940v2 Announce Type: replace-cross 
Abstract: Autoformalization, the conversion of natural language mathematics into formal languages, offers significant potential for advancing mathematical reasoning. However, existing efforts are limited to formal languages with substantial online corpora and struggle to keep pace with rapidly evolving languages like Lean 4. To bridge this gap, we propose a new benchmark \textbf{Form}alization for \textbf{L}ean~\textbf{4} (\textbf{\name}) designed to evaluate the autoformalization capabilities of large language models (LLMs). This benchmark encompasses a comprehensive assessment of questions, answers, formal statements, and proofs. Additionally, we introduce a \textbf{P}rocess-\textbf{S}upervised \textbf{V}erifier (\textbf{PSV}) model that leverages the precise feedback from Lean 4 compilers to enhance autoformalization. Our experiments demonstrate that the PSV method improves autoformalization, enabling higher accuracy using less filtered training data. Furthermore, when fine-tuned with data containing detailed process information, PSV can leverage the data more effectively, leading to more significant improvements in autoformalization for Lean 4. Our dataset and code are available at \url{https://github.com/rookie-joe/PDA}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01940v2</guid>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianqiao Lu, Yingjia Wan, Zhengying Liu, Yinya Huang, Jing Xiong, Chengwu Liu, Jianhao Shen, Hui Jin, Jipeng Zhang, Haiming Wang, Zhicheng Yang, Jing Tang, Zhijiang Guo</dc:creator>
    </item>
    <item>
      <title>Reasoning Around Paradox with Grounded Deduction</title>
      <link>https://arxiv.org/abs/2409.08243</link>
      <description>arXiv:2409.08243v2 Announce Type: replace-cross 
Abstract: How can we reason around logical paradoxes without falling into them? This paper introduces grounded deduction or GD, a Kripke-inspired approach to first-order logic and arithmetic that is neither classical nor intuitionistic, but nevertheless appears both pragmatically usable and intuitively justifiable. GD permits the direct expression of unrestricted recursive definitions - including paradoxical ones such as 'L := not L' - while adding dynamic typing premises to certain inference rules so that such paradoxes do not lead to inconsistency. This paper constitutes a preliminary development and investigation of grounded deduction, to be extended with further elaboration and deeper analysis of its intriguing properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08243v2</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bryan Ford</dc:creator>
    </item>
    <item>
      <title>MARS: A neurosymbolic approach for interpretable drug discovery</title>
      <link>https://arxiv.org/abs/2410.05289</link>
      <description>arXiv:2410.05289v2 Announce Type: replace-cross 
Abstract: Neurosymbolic (NeSy) artificial intelligence describes the combination of logic or rule-based techniques with neural networks. Compared to neural approaches, NeSy methods often possess enhanced interpretability, which is particularly promising for biomedical applications like drug discovery. However, since interpretability is broadly defined, there are no clear guidelines for assessing the biological plausibility of model interpretations. To assess interpretability in the context of drug discovery, we devise a novel prediction task, called drug mechanism-of-action (MoA) deconvolution, with an associated, tailored knowledge graph (KG), MoA-net. We then develop the MoA Retrieval System (MARS), a NeSy approach for drug discovery which leverages logical rules with learned rule weights. Using this interpretable feature alongside domain knowledge, we find that MARS and other NeSy approaches on KGs are susceptible to reasoning shortcuts, in which the prediction of true labels is driven by "degree-bias" rather than the domain-based rules. Subsequently, we demonstrate ways to identify and mitigate this. Thereafter, MARS achieves performance on par with current state-of-the-art models while producing model interpretations aligned with known MoAs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.05289v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lauren Nicole DeLong, Yojana Gadiya, Paola Galdi, Jacques D. Fleuriot, Daniel Domingo-Fern\'andez</dc:creator>
    </item>
    <item>
      <title>LeanAgent: Lifelong Learning for Formal Theorem Proving</title>
      <link>https://arxiv.org/abs/2410.06209</link>
      <description>arXiv:2410.06209v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have been successful in mathematical reasoning tasks such as formal theorem proving when integrated with interactive proof assistants like Lean. Existing approaches involve training or fine-tuning an LLM on a specific dataset to perform well on particular domains, such as undergraduate-level mathematics. These methods struggle with generalizability to advanced mathematics. A fundamental limitation is that these approaches operate on static domains, failing to capture how mathematicians often work across multiple domains and projects simultaneously or cyclically. We present LeanAgent, a novel lifelong learning framework for theorem proving that continuously generalizes to and improves on ever-expanding mathematical knowledge without forgetting previously learned knowledge. LeanAgent introduces several key innovations, including a curriculum learning strategy that optimizes the learning trajectory in terms of mathematical difficulty, a dynamic database for efficient management of evolving mathematical knowledge, and progressive training to balance stability and plasticity. LeanAgent successfully proves 162 theorems previously unproved by humans across 23 diverse Lean repositories, many from advanced mathematics. It performs up to 11$\times$ better than the static LLM baseline, proving challenging theorems in domains like abstract algebra and algebraic topology while showcasing a clear progression of learning from basic concepts to advanced topics. In addition, we analyze LeanAgent's superior performance on key lifelong learning metrics. LeanAgent achieves exceptional scores in stability and backward transfer, where learning new tasks improves performance on previously learned tasks. This emphasizes LeanAgent's continuous generalizability and improvement, explaining its superior theorem proving performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06209v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Tue, 15 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adarsh Kumarappan, Mo Tiwari, Peiyang Song, Robert Joseph George, Chaowei Xiao, Anima Anandkumar</dc:creator>
    </item>
  </channel>
</rss>
