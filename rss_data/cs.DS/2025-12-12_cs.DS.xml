<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Dec 2025 05:00:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Universal Hirschberg for Width Bounded Dynamic Programs</title>
      <link>https://arxiv.org/abs/2512.10132</link>
      <description>arXiv:2512.10132v1 Announce Type: new 
Abstract: Hirschberg's algorithm (1975) reduces the space complexity for the longest common subsequence problem from $O(N^2)$ to $O(N)$ via recursive midpoint bisection on a grid dynamic program (DP). We show that the underlying idea generalizes to a broad class of dynamic programs with local dependencies on directed acyclic graphs (DP DAGs). Modeling a DP as deterministic time evolution over a topologically ordered DAG with frontier width $\omega$ and bounded in-degree, and assuming a max-type semiring with deterministic tie breaking, we prove that in a standard offline random-access model any such DP admits deterministic traceback in space $O(\omega \log T + (\log T)^{O(1)})$ cells over a fixed finite alphabet, where $T$ is the number of states. Our construction replaces backward dynamic programs by forward-only recomputation and organizes the time order into a height-compressed recursion tree whose nodes expose small "middle frontiers'' across which every optimal path must pass. The framework yields near-optimal traceback bounds for asymmetric and banded sequence alignment, one-dimensional recurrences, and dynamic-programming formulations on graphs of bounded pathwidth. We also show that an $\Omega(\omega)$ space term (in bits) is unavoidable in forward single-pass models and discuss conjectured $\sqrt{T}$-type barriers in streaming settings, supporting the view that space-efficient traceback is a structural property of width-bounded DP DAGs rather than a peculiarity of grid-based algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10132v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Logan Nye</dc:creator>
    </item>
    <item>
      <title>Approximate Counting in Local Lemma Regimes</title>
      <link>https://arxiv.org/abs/2512.10134</link>
      <description>arXiv:2512.10134v1 Announce Type: new 
Abstract: We establish efficient approximate counting algorithms for several natural problems in local lemma regimes. In particular, we consider the probability of intersection of events and the dimension of intersection of subspaces. Our approach is based on the cluster expansion method. We obtain fully polynomial-time approximation schemes for both the probability of intersection and the dimension of intersection for commuting projectors. For general projectors, we provide two algorithms: a fully polynomial-time approximation scheme under a global inclusion-exclusion stability condition, and an efficient affine approximation under a spectral gap assumption. As corollaries of our results, we obtain efficient algorithms for approximating the number of satisfying assignments of conjunctive normal form formulae and the dimension of satisfying subspaces of quantum satisfiability formulae.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10134v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <category>quant-ph</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryan L. Mann, Gabriel Waite</dc:creator>
    </item>
    <item>
      <title>Efficient Defective Clique Enumeration and Search with Worst-Case Optimal Search Space</title>
      <link>https://arxiv.org/abs/2512.10354</link>
      <description>arXiv:2512.10354v1 Announce Type: new 
Abstract: A $k$-defective clique is a relaxation of the traditional clique definition, allowing up to $k$ missing edges. This relaxation is crucial in various real-world applications such as link prediction, community detection, and social network analysis. Although the problems of enumerating maximal $k$-defective cliques and searching a maximum $k$-defective clique have been extensively studied, existing algorithms suffer from limitations such as the combinatorial explosion of small partial solutions and sub-optimal search spaces. To address these limitations, we propose a novel clique-first branch-and-bound framework that first generates cliques and then adds missing edges. Furthermore, we introduce a new pivoting technique that achieves a search space size of $\mathcal{O}(3^{\frac{n}{3}} \cdot n^k)$, where $n$ is the number of vertices in the input graph. We prove that the worst-case number of maximal $k$-defective cliques is $\Omega(3^{\frac{n}{3}} \cdot n^k)$ when $k$ is a constant, establishing that our algorithm's search space is worst-case optimal. Leveraging the diameter-two property of defective cliques, we further reduce the search space size to $\mathcal{O}(n \cdot 3^{\frac{\delta}{3}} \cdot (\delta \Delta)^k)$, where $\delta$ is the degeneracy and $\Delta$ is the maximum degree of the input graph. We also propose an efficient framework for maximum $k$-defective clique search based on our branch-and-bound, together with practical techniques to reduce the search space. Experiments on real-world benchmark datasets with more than 1 million edges demonstrate that each of our proposed algorithms for maximal $k$-defective clique enumeration and maximum $k$-defective clique search outperforms the respective state-of-the-art algorithms by up to four orders of magnitude in terms of processing time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10354v1</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3769787</arxiv:DOI>
      <dc:creator>Jihoon Jang, Yehyun Nam, Kunsoo Park, Hyunjoon Kim</dc:creator>
    </item>
    <item>
      <title>Semi-Robust Communication Complexity of Maximum Matching</title>
      <link>https://arxiv.org/abs/2512.10532</link>
      <description>arXiv:2512.10532v1 Announce Type: new 
Abstract: We study the one-way two-party communication complexity of Maximum Matching in the semi-robust setting where the edges of a maximum matching are randomly partitioned between Alice and Bob, but all remaining edges of the input graph are adversarially partitioned between the two parties.
  We show that the simple protocol where Alice solely communicates a lexicographically-first maximum matching of their edges to Bob is surprisingly powerful: We prove that it yields a $3/4$-approximation in expectation and that our analysis is tight.
  The semi-robust setting is at least as hard as the fully robust setting. In this setting, all edges of the input graph are randomly partitioned between Alice and Bob, and the state-of-the-art result is a fairly involved $5/6$-approximation protocol that is based on the computation of edge-degree constrained subgraphs [Azarmehr, Behnezhad, ICALP'23]. Our protocol also immediately yields a $3/4$-approximation in the fully robust setting. One may wonder whether an improved analysis of our protocol in the fully robust setting is possible: While we cannot rule this out, we give an instance where our protocol only achieves a $0.832 &lt; 5/6 = 0.83$-approximation. Hence, while our simple protocol performs surprisingly well, it cannot be used to improve over the state-of-the-art in the fully robust setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10532v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Cipriani Huete, Adithya Diddapur, Pavel Dvo\v{r}\'ak, Christian Konrad</dc:creator>
    </item>
    <item>
      <title>Optimal learning of quantum channels in diamond distance</title>
      <link>https://arxiv.org/abs/2512.10214</link>
      <description>arXiv:2512.10214v1 Announce Type: cross 
Abstract: Quantum process tomography, the task of estimating an unknown quantum channel, is a central problem in quantum information theory and a key primitive for characterising noisy quantum devices. A long-standing open question is to determine the optimal number of uses of an unknown channel required to learn it in diamond distance, the standard measure of worst-case distinguishability between quantum processes. Here we show that a quantum channel acting on a $d$-dimensional system can be estimated to accuracy $\varepsilon$ in diamond distance using $O(d^4/\varepsilon^2)$ channel uses. This scaling is essentially optimal, as it matches lower bounds up to logarithmic factors. Our analysis extends to channels with input and output dimensions $d_{\mathrm{in}}$ and $d_{\mathrm{out}}$ and Kraus rank at most $k$, for which $O(d_{\mathrm{in}} d_{\mathrm{out}} k/\varepsilon^2)$ channel uses suffice, interpolating between unitary and fully generic channels. As by-products, we obtain, to the best of our knowledge, the first essentially optimal strategies for operator-norm learning of binary POVMs and isometries, and we recover optimal trace-distance tomography for fixed-rank states. Our approach consists of using the channel only non-adaptively to prepare copies of the Choi state, purify them in parallel, perform sample-optimal pure-state tomography on the purifications, and analyse the resulting estimator directly in diamond distance via its semidefinite-program characterisation. While the sample complexity of state tomography in trace distance is by now well understood, our results finally settle the corresponding problem for quantum channels in diamond distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10214v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonio Anna Mele, Lennart Bittel</dc:creator>
    </item>
    <item>
      <title>Efficient Hypergraph Pattern Matching via Match-and-Filter and Intersection Constraint</title>
      <link>https://arxiv.org/abs/2512.10621</link>
      <description>arXiv:2512.10621v1 Announce Type: cross 
Abstract: A hypergraph is a generalization of a graph, in which a hyperedge can connect multiple vertices, modeling complex relationships involving multiple vertices simultaneously. Hypergraph pattern matching, which is to find all isomorphic embeddings of a query hypergraph in a data hypergraph, is one of the fundamental problems. In this paper, we present a novel algorithm for hypergraph pattern matching by introducing (1) the intersection constraint, a necessary and sufficient condition for valid embeddings, which significantly speeds up the verification process, (2) the candidate hyperedge space, a data structure that stores potential mappings between hyperedges in the query hypergraph and the data hypergraph, and (3) the Match-and-Filter framework, which interleaves matching and filtering operations to maintain only compatible candidates in the candidate hyperedge space during backtracking. Experimental results on real-world datasets demonstrate that our algorithm significantly outperforms the state-of-the-art algorithms, by up to orders of magnitude in terms of query processing time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10621v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siwoo Song, Wonseok Shin, Kunsoo Park, Giuseppe F. Italiano, Zhengyi Yang, Wenjie Zhang</dc:creator>
    </item>
    <item>
      <title>Equivalent Instances for Scheduling and Packing Problems</title>
      <link>https://arxiv.org/abs/2512.10635</link>
      <description>arXiv:2512.10635v1 Announce Type: cross 
Abstract: Two instances $(I,k)$ and $(I',k')$ of a parameterized problem $P$ are equivalent if they have the same set of solutions (static equivalent) or if the set of solutions of $(I,k)$ can be constructed by the set of solutions for $(I',k')$ and some computable pre-solutions. If the algorithm constructing such a (static) equivalent instance whose size is polynomial bounded runs in fixed-parameter tractable (FPT) time, we say that there exists a (static) equivalent instance for this problem. In this paper we present (static) equivalent instances for Scheduling and Knapsack problems. We improve the bound for the $\ell_1$-norm of an equivalent vector given by Eisenbrand, Hunkenschr\"oder, Klein, Kouteck\'y, Levin, and Onn and show how this yields equivalent instances for integer linear programs (ILPs) and related problems. We obtain an $O(MN^2\log(NU))$ static equivalent instance for feasibility ILPs where $M$ is the number of constraints, $N$ is the number of variables and $U$ is an upper bound for the $\ell_\infty$-norm of the smallest feasible solution. With this, we get an $O(n^2\log(n))$ static equivalent instance for Knapsack where $n$ is the number of items. Moreover, we give an $O(M^2N\log(NM\Delta))$ kernel for feasibility ILPs where $\Delta$ is an upper bound for the $\ell_\infty$-norm of the given constraint matrix.
  Using balancing results by Knop et al., the ConfILP and a proximity result by Eisenbrand and Weismantel we give an $O(d^2\log(p_{\max}))$ equivalent instance for LoadBalancing, a generalization of scheduling problems. Here $d$ is the number of different processing times and $p_{\max}$ is the largest processing time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10635v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Klaus Jansen, Kai Kahler, Corinna Wambsganz</dc:creator>
    </item>
    <item>
      <title>The Localization Method for High-Dimensional Inequalities</title>
      <link>https://arxiv.org/abs/2512.10848</link>
      <description>arXiv:2512.10848v1 Announce Type: cross 
Abstract: We survey the localization method for proving inequalities in high dimension, pioneered by Lov\'asz and Simonovits (1993), and its stochastic extension developed by Eldan (2012). The method has found applications in a surprising wide variety of settings, ranging from its original motivation in isoperimetric inequalities to optimization, concentration of measure, and bounding the mixing rate of Markov chains. At heart, the method converts a given instance of an inequality (for a set or distribution in high dimension) into a highly structured instance, often just one-dimensional.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10848v1</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>math.FA</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunbum Kook, Santosh S. Vempala</dc:creator>
    </item>
    <item>
      <title>Almost Tight Additive Guarantees for $k$-Edge-Connectivity</title>
      <link>https://arxiv.org/abs/2506.20906</link>
      <description>arXiv:2506.20906v3 Announce Type: replace 
Abstract: We consider the \emph{$k$-edge connected spanning subgraph} (kECSS) problem, where we are given an undirected graph $G = (V, E)$ with nonnegative edge costs $\{c_e\}_{e\in E}$, and we seek a minimum-cost \emph{$k$-edge connected} subgraph $H$ of $G$. For even $k$, we present a polytime algorithm that computes a $(k-2)$-edge connected subgraph of cost at most the optimal value $LP^*$ of the natural LP-relaxation for kECSS; for odd $k$, we obtain a $(k-3)$-edge connected subgraph of cost at most $LP^*$. Since kECSS is APX-hard for all $k\geq 2$, our results are nearly optimal. They also significantly improve upon the recent work of Hershkowitz et al., both in terms of solution quality and the simplicity of algorithm and its analysis. Our techniques also yield an alternate guarantee, where we obtain a $(k-1)$-edge connected subgraph of cost at most $1.5\cdot LP^*$; with unit edge costs, the cost guarantee improves to $(1+\frac{4}{3k})\cdot LP^*$, which improves upon the state-of-the-art approximation for unit edge costs, but with a unit loss in edge connectivity.
  Our kECSS-result also yields results for the \emph{$k$-edge connected spanning multigraph} (kECSM) problem, where multiple copies of an edge can be selected: we obtain a $(1+2/k)$-approximation algorithm for even $k$, and a $(1+3/k)$-approximation algorithm for odd $k$.
  Our techniques extend to the degree-bounded versions of kECSS and kECSM, wherein we also impose degree lower- and upper- bounds on the nodes. We obtain the same cost and connectivity guarantees for these degree-bounded versions with an additive violation of (roughly) $2$ for the degree bounds. These are the first results for degree-bounded \{kECSS,kECSM\} of the form where the cost of the solution obtained is at most the optimum, and the connectivity constraints are violated by an additive constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20906v3</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 12 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhil Kumar, Chaitanya Swamy</dc:creator>
    </item>
  </channel>
</rss>
